diff --git a/Documentation/devicetree/bindings/net/hisilicon-femac.txt b/Documentation/devicetree/bindings/net/hisilicon-femac.txt
index d11af5e..ef9e641 100644
--- a/Documentation/devicetree/bindings/net/hisilicon-femac.txt
+++ b/Documentation/devicetree/bindings/net/hisilicon-femac.txt
@@ -4,7 +4,9 @@ Required properties:
 - compatible: should contain one of the following version strings:
 	* "hisilicon,hisi-femac-v1"
 	* "hisilicon,hisi-femac-v2"
-	and the soc string "hisilicon,hi3516cv300-femac".
+	and one of the following soc strings:
+	* "hisilicon,hi3516cv300-femac"
+	* "hisilicon,hi3536dv100-femac"
 - reg: specifies base physical address(s) and size of the device registers.
   The first region is the MAC core register base and size.
   The second region is the global MAC control register.
diff --git a/Documentation/devicetree/bindings/net/hisilicon-gemac-mdio.txt b/Documentation/devicetree/bindings/net/hisilicon-gemac-mdio.txt
new file mode 100644
index 0000000..c6f8202
--- /dev/null
+++ b/Documentation/devicetree/bindings/net/hisilicon-gemac-mdio.txt
@@ -0,0 +1,22 @@
+Hisilicon Gigabit Ethernet MDIO Controller interface
+
+Required properties:
+- compatible: should be "hisilicon,hisi-gemac-mdio".
+- reg: address and length of the register set for the device.
+- clocks: A phandle to the reference clock for this device.
+
+- PHY subnode: inherits from phy binding [1]
+[1] Documentation/devicetree/bindings/net/phy.txt
+
+Example:
+mdio: mdio@100503c0 {
+	compatible = "hisilicon,hisi-gemac-mdio";
+	reg = <0x100503c0 0x20>;
+	clocks = <&crg HI3519V100_MDIO_CLK>;
+	#address-cells = <1>;
+	#size-cells = <0>;
+
+	phy0: phy@1 {
+		reg = <1>;
+	};
+};
diff --git a/Documentation/devicetree/bindings/net/hisilicon-higmac.txt b/Documentation/devicetree/bindings/net/hisilicon-higmac.txt
new file mode 100644
index 0000000..ea096d2
--- /dev/null
+++ b/Documentation/devicetree/bindings/net/hisilicon-higmac.txt
@@ -0,0 +1,52 @@
+Hisilicon higmac controller
+
+Required properties:
+- compatible: should be "hisilicon,higmac" and one of the following:
+	- "hisilicon,higmac-v1"
+	- "hisilicon,higmac-v2"
+	- "hisilicon,higmac-v3"
+	- "hisilicon,higmac-v4"
+	- "hisilicon,higmac-v5"
+- reg: specifies base physical address(s) and size of the device registers.
+  The first region is the MAC register base and size.
+  The second region is external interface control register.
+- interrupts: should contain the MAC interrupt.
+- #address-cells: must be <1>.
+- #size-cells: must be <0>.
+- phy-mode: see ethernet.txt [1].
+- phy-handle: see ethernet.txt [1].
+- mac-address: see ethernet.txt [1].
+- clocks: clock phandle and specifier pair.
+- resets: reset controller phandle and specifier pair.
+
+- PHY subnode: inherits from phy binding [2]
+
+[1] Documentation/devicetree/bindings/net/ethernet.txt
+[2] Documentation/devicetree/bindings/net/phy.txt
+
+Example:
+	higmac: ethernet@10050000 {
+		compatible = "hisilicon,higmac";
+		reg = <0x10050000 0x1000>,<0x120100ec 0x4>;
+		interrupts = <0 25 4>;
+		#address-cells = <1>;
+		#size-cells = <0>;
+		phy-mode = "rgmii";
+		phy-handle = <&eth_phy>;
+		mac-address = [00 00 00 00 00 00];
+		clocks = <&clock HI3519_ETH_CLK>,
+				<&clock HI3519_ETH_MACIF_CLK>;
+		clock-names = "higmac_clk",
+				"macif_clk";
+
+		resets = <&clock 0xcc 0>,
+				<&clock 0xcc 2>,
+				<&clock 0xcc 7>;
+		reset-names = "port_reset",
+				"macif_reset",
+				"phy_reset";
+
+		eth_phy: ethernet-phy@1 {
+			reg = <1>;
+		};
+	};
diff --git a/Documentation/networking/phy.txt b/Documentation/networking/phy.txt
index 7ab9404..501222b 100644
--- a/Documentation/networking/phy.txt
+++ b/Documentation/networking/phy.txt
@@ -347,3 +347,12 @@ Board Fixups
  The stubs set one of the two matching criteria, and set the other one to
  match anything.
 
+ When phy_register_fixup() or *_for_uid()/*_for_id() is called at module,
+ unregister fixup and free allocate memory are required.
+
+ Call one of following function before unloading module.
+
+ int phy_unregister_fixup(const char *phy_id, u32 phy_uid, u32 phy_uid_mask);
+ int phy_unregister_fixup_for_uid(u32 phy_uid, u32 phy_uid_mask);
+ int phy_register_fixup_for_id(const char *phy_id);
+
diff --git a/arch/arm/Kconfig b/arch/arm/Kconfig
index b5d529f..100df1d 100644
--- a/arch/arm/Kconfig
+++ b/arch/arm/Kconfig
@@ -747,6 +747,8 @@ source "arch/arm/mach-highbank/Kconfig"
 
 source "arch/arm/mach-hisi/Kconfig"
 
+source "arch/arm/mach-hibvt/Kconfig"
+
 source "arch/arm/mach-integrator/Kconfig"
 
 source "arch/arm/mach-iop32x/Kconfig"
diff --git a/arch/arm/Kconfig.debug b/arch/arm/Kconfig.debug
index d83f7c3..4a150d5 100644
--- a/arch/arm/Kconfig.debug
+++ b/arch/arm/Kconfig.debug
@@ -287,6 +287,22 @@ choice
 		  Say Y here if you want kernel low-level debugging support
 		  on HI3620 UART.
 
+	config DEBUG_HI3516A_UART
+		bool "Hisilicon Hi3516A Debug UART"
+		depends on ARCH_HI3516A
+		select DEBUG_UART_PL01X
+		help
+			Say Y here if you want kernel low-level debugging support
+			on HI3516A UART.
+
+	config DEBUG_HI3536DV100_UART
+		bool "Hisilicon Hi3536DV100 Debug UART"
+		depends on ARCH_HI3536DV100
+		select DEBUG_UART_PL01X
+		help
+			Say Y here if you want kernel low-level debugging support
+			on HI3536DV100 UART.
+
 	config DEBUG_HIGHBANK_UART
 		bool "Kernel low-level debugging messages via Highbank UART"
 		depends on ARCH_HIGHBANK
@@ -1530,6 +1546,8 @@ config DEBUG_UART_PHYS
 	default 0xf991e000 if DEBUG_QCOM_UARTDM
 	default 0xfc00c000 if DEBUG_AT91_SAMA5D4_USART3
 	default 0xfcb00000 if DEBUG_HI3620_UART
+	default 0x20080000 if DEBUG_HI3516A_UART
+	default 0x12080000 if DEBUG_HI3536DV100_UART
 	default 0xfd883000 if DEBUG_ALPINE_UART0
 	default 0xfe800000 if ARCH_IOP32X
 	default 0xff690000 if DEBUG_RK32_UART2
@@ -1619,6 +1637,8 @@ config DEBUG_UART_VIRT
 	default 0xfe300000 if DEBUG_BCM_KONA_UART
 	default 0xfe800000 if ARCH_IOP32X
 	default 0xfeb00000 if DEBUG_HI3620_UART || DEBUG_HIX5HD2_UART
+	default 0xfe900000 if DEBUG_HI3516A_UART
+	default 0xfe480000 if DEBUG_HI3536DV100_UART
 	default 0xfeb24000 if DEBUG_RK3X_UART0
 	default 0xfeb26000 if DEBUG_RK3X_UART1
 	default 0xfeb30c00 if DEBUG_KEYSTONE_UART0
diff --git a/arch/arm/Makefile b/arch/arm/Makefile
index 6be9ee1..53409ce 100644
--- a/arch/arm/Makefile
+++ b/arch/arm/Makefile
@@ -170,6 +170,7 @@ machine-$(CONFIG_ARCH_FOOTBRIDGE)	+= footbridge
 machine-$(CONFIG_ARCH_GEMINI)		+= gemini
 machine-$(CONFIG_ARCH_HIGHBANK)		+= highbank
 machine-$(CONFIG_ARCH_HISI)		+= hisi
+machine-$(CONFIG_ARCH_HISI_BVT)		+= hibvt
 machine-$(CONFIG_ARCH_INTEGRATOR)	+= integrator
 machine-$(CONFIG_ARCH_IOP13XX)		+= iop13xx
 machine-$(CONFIG_ARCH_IOP32X)		+= iop32x
@@ -268,6 +269,10 @@ endif
 endif
 endif
 
+ifeq ($(CONFIG_ARCH_HISI_BVT),y)
+KBUILD_CPPFLAGS += $(patsubst %,-I%include,$(machdirs) $(platdirs))
+endif
+
 export	TEXT_OFFSET GZFLAGS MMUEXT
 
 # Do we have FASTFPE?
diff --git a/arch/arm/boot/Makefile b/arch/arm/boot/Makefile
index 50f8d1b..9732bdf 100644
--- a/arch/arm/boot/Makefile
+++ b/arch/arm/boot/Makefile
@@ -16,6 +16,8 @@ OBJCOPYFLAGS	:=-O binary -R .comment -S
 ifneq ($(MACHINE),)
 include $(MACHINE)/Makefile.boot
 endif
+include $(srctree)/arch/arm/mach-hibvt/Makefile.boot
+include $(srctree)/arch/arm/boot/dts/Makefile
 
 # Note: the following conditions must always be true:
 #   ZRELADDR == virt_to_phys(PAGE_OFFSET + TEXT_OFFSET)
@@ -24,10 +26,12 @@ endif
 ZRELADDR    := $(zreladdr-y)
 PARAMS_PHYS := $(params_phys-y)
 INITRD_PHYS := $(initrd_phys-y)
+DTB_OBJS ?= $(dtb-y)
+DTB_OBJS_FULL := $(addprefix $(obj)/dts/,$(DTB_OBJS))
 
 export ZRELADDR INITRD_PHYS PARAMS_PHYS
 
-targets := Image zImage xipImage bootpImage uImage
+targets := Image zImage xipImage bootpImage uImage zImage-dtb
 
 ifeq ($(CONFIG_XIP_KERNEL),y)
 
@@ -55,6 +59,10 @@ $(obj)/compressed/vmlinux: $(obj)/Image FORCE
 $(obj)/zImage:	$(obj)/compressed/vmlinux FORCE
 	$(call if_changed,objcopy)
 
+$(obj)/zImage-dtb:	$(obj)/zImage $(DTB_OBJS_FULL) FORCE
+	@cat $(obj)/zImage $(DTB_OBJS_FULL) > $@
+	@$(kecho) '  Kernel: $@ is ready'
+
 endif
 
 ifneq ($(LOADADDR),)
@@ -75,7 +83,7 @@ if [ $(words $(UIMAGE_LOADADDR)) -ne 1 ]; then \
 	false; \
 fi
 
-$(obj)/uImage:	$(obj)/zImage FORCE
+$(obj)/uImage:	$(obj)/zImage-dtb FORCE
 	@$(check_for_multiple_loadaddr)
 	$(call if_changed,uimage)
 
diff --git a/arch/arm/boot/compressed/head.S b/arch/arm/boot/compressed/head.S
index fc6d541..9c0a324 100644
--- a/arch/arm/boot/compressed/head.S
+++ b/arch/arm/boot/compressed/head.S
@@ -218,6 +218,20 @@ not_angel:
 		addcc	r0, r0, pc
 		cmpcc	r4, r0
 		orrcc	r4, r4, #1		@ remember we skipped cache_on
+
+/*TODO all the Cortex-A7 Single Core must fix this bug */
+#if defined(CONFIG_ARCH_HI3516A) || defined(CONFIG_ARCH_HI3536DV100)
+/*
+ * This is a bug on Cortex-A7 MPCORE. see buglist of Cortex-A7
+ * The D-caches are disabled when ACTLR.SMP is set to 0 regardless of the
+ * value of the cache enable bit. so we must set SMP bit of ACTLR register
+ * before enable D cache
+ */
+		mrc     p15, 0, r0, c1, c0, 1
+		orr     r0, #(1 << 6)
+		mcr     p15, 0, r0, c1, c0, 1
+#endif
+
 		blcs	cache_on
 
 restart:	adr	r0, LC0
diff --git a/arch/arm/boot/dts/Makefile b/arch/arm/boot/dts/Makefile
index 7037201..e79e35e 100644
--- a/arch/arm/boot/dts/Makefile
+++ b/arch/arm/boot/dts/Makefile
@@ -174,6 +174,10 @@ dtb-$(CONFIG_ARCH_HISI) += \
 	hi3519-demb.dtb
 dtb-$(CONFIG_ARCH_HIX5HD2) += \
 	hisi-x5hd2-dkb.dtb
+dtb-$(CONFIG_ARCH_HI3516A) += \
+	hi3516a-demb.dtb
+dtb-$(CONFIG_ARCH_HI3536DV100) += \
+	hi3536dv100-demb.dtb
 dtb-$(CONFIG_ARCH_INTEGRATOR) += \
 	integratorap.dtb \
 	integratorcp.dtb
diff --git a/arch/arm/boot/dts/hi3516a-demb.dts b/arch/arm/boot/dts/hi3516a-demb.dts
new file mode 100644
index 0000000..ca9f7bc
--- /dev/null
+++ b/arch/arm/boot/dts/hi3516a-demb.dts
@@ -0,0 +1,233 @@
+/*
+ * Copyright (c) 2013-2014 Linaro Ltd.
+ * Copyright (c) 2015-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+/dts-v1/;
+#include "hi3516a.dtsi"
+
+/ {
+	model = "Hisilicon HI3516A DEMO Board";
+	compatible = "hiSilicon,hi3516a";
+
+	cpus {
+		#address-cells = <1>;
+		#size-cells = <0>;
+
+		cpu@0 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a7";
+			reg = <0>;
+
+			operating-points = <
+				/* KHz    uV */
+				 600000 1100000
+				 732000 1200000
+				 850000 1300000
+				 500000 1060000
+				 400000 1020000
+		    >;
+
+			clocks = <&clock HI3516A_A7_MUX>,
+				<&clock HI3516A_FIXED_400M>,
+				<&clock HI3516A_FIXED_500M>,
+				<&clock HI3516A_APLL_CLK>;
+			clock-names = "a7_mux","400m", "500m","apll";
+
+			vcc-supply = <&a7_regulator>;
+		};
+	};
+
+	avs {
+		compatible = "hi3516a,avs";
+		avs-num = <2>;
+		avs-name-array = "cpu-avs","media-avs";
+		cpu_avs: cpu_avs{
+			avs-name = "cpu-avs";
+			opp-num = <5>;
+			opp-freq = <600000 732000 850000 500000 400000>;
+			opp-volt-min = <940000 1000000 1070000 940000 940000>;
+			opp-hpm = <270 325 365 255 240>;
+			opp-div = <11 14 16 10 8>;
+			opp-volt-max = <1310000>;
+		};
+
+		media_avs: media_avs{
+			avs-name = "media-avs";
+			opp-num = <5>;
+			opp-freq = <0 1 2 3 4>;
+			opp-volt-min = <930000 930000 930000 930000 930000>;
+			opp-hpm = <245 245 245 260 285>;
+			opp-div = <3 3 4 5 5>;
+			opp-volt-max = <1310000>;
+		};
+	};
+
+	memory {
+		device_type = "memory";
+		reg = <0x80000000 0x40000000>;
+	};
+};
+
+&uart0 {
+	status = "okay";
+};
+
+&dual_timer0 {
+	status = "okay";
+};
+
+&hidmac {
+	status = "okay";
+};
+
+&i2c_bus0 {
+	status = "okay";
+};
+
+&i2c_bus1 {
+	status = "okay";
+};
+
+&i2c_bus2 {
+	status = "okay";
+};
+
+&spi_bus0{
+	status = "okay";
+	num-cs = <1>;
+
+	spidev@0 {
+		compatible = "rohm,dh2228fv";
+		reg = <0>;
+		pl022,interface = <0>;
+		pl022,com_mode = <0>;
+		spi-max-frequency = <24000000>;
+	};
+};
+
+&spi_bus1{
+	status = "okay";
+	num-cs = <3>;
+
+	spidev@0 {
+		compatible = "rohm,dh2228fv";
+		reg = <0>;
+		pl022,interface = <0>;
+		pl022,com_mode = <0>;
+		spi-max-frequency = <24000000>;
+	};
+
+	spidev@1 {
+		compatible = "rohm,dh2228fv";
+		reg = <1>;
+		pl022,interface = <0>;
+		pl022,com_mode = <0>;
+		spi-max-frequency = <24000000>;
+	};
+
+	spidev@2 {
+		compatible = "rohm,dh2228fv";
+		reg = <2>;
+		pl022,interface = <0>;
+		pl022,com_mode = <0>;
+		spi-max-frequency = <24000000>;
+	};
+};
+
+&mdio {
+	ethphy: ethernet-phy@1 {
+		reg = <1>;
+	};
+};
+
+&higmac {
+	phy-handle = <&ethphy>;
+	phy-mode = "rgmii";
+};
+
+&mmc0 {
+	status = "okay";
+};
+
+&mmc1 {
+	status = "okay";
+};
+
+&gpio_chip0 {
+	status = "okay";
+};
+
+&gpio_chip1 {
+	status = "okay";
+};
+
+&gpio_chip2 {
+	status = "okay";
+};
+
+&gpio_chip3 {
+	status = "okay";
+};
+
+&gpio_chip4 {
+	status = "okay";
+};
+
+&gpio_chip5 {
+	status = "okay";
+};
+
+&gpio_chip6 {
+	status = "okay";
+};
+
+&gpio_chip7 {
+	status = "okay";
+};
+
+&gpio_chip8 {
+	status = "okay";
+};
+
+&gpio_chip9 {
+	status = "okay";
+};
+
+&gpio_chip10 {
+	status = "okay";
+};
+
+&gpio_chip11 {
+	status = "okay";
+};
+
+&gpio_chip12 {
+	status = "okay";
+};
+
+&gpio_chip13 {
+	status = "okay";
+};
+
+&gpio_chip14 {
+	status = "okay";
+};
+
+&gpio_chip15 {
+	status = "okay";
+};
diff --git a/arch/arm/boot/dts/hi3516a.dtsi b/arch/arm/boot/dts/hi3516a.dtsi
new file mode 100644
index 0000000..d8bba13
--- /dev/null
+++ b/arch/arm/boot/dts/hi3516a.dtsi
@@ -0,0 +1,691 @@
+/*
+ * Copyright (c) 2013-2014 Linaro Ltd.
+ * Copyright (c) 2015-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "skeleton.dtsi"
+#include <dt-bindings/clock/hi3516a-clock.h>
+
+/ {
+	aliases {
+		serial0 = &uart0;
+		i2c0 = &i2c_bus0;
+		i2c1 = &i2c_bus1;
+		i2c2 = &i2c_bus2;
+		spi0 = &spi_bus0;
+		spi1 = &spi_bus1;
+		gpio0 = &gpio_chip0;
+		gpio1 = &gpio_chip1;
+		gpio2 = &gpio_chip2;
+		gpio3 = &gpio_chip3;
+		gpio4 = &gpio_chip4;
+		gpio5 = &gpio_chip5;
+		gpio6 = &gpio_chip6;
+		gpio7 = &gpio_chip7;
+		gpio8 = &gpio_chip8;
+		gpio9 = &gpio_chip9;
+		gpio10 = &gpio_chip10;
+		gpio11 = &gpio_chip11;
+		gpio12 = &gpio_chip12;
+		gpio13 = &gpio_chip13;
+		gpio14 = &gpio_chip14;
+		gpio15 = &gpio_chip15;
+	};
+
+	clock: clock@20030000 {
+		compatible = "hisilicon,hi3516a-clock";
+		#address-cells = <1>;
+		#size-cells = <1>;
+		#clock-cells = <1>;
+		#reset-cells = <2>;
+		reg = <0x20030000 0x1000>;
+	};
+
+	gic: interrupt-controller@20300000 {
+		compatible = "arm,cortex-a7-gic";
+		#interrupt-cells = <3>;
+		#address-cells = <0>;
+		interrupt-controller;
+		/* gic dist base, gic cpu base , no virtual support */
+		reg = <0x20301000 0x1000>, <0x20302000 0x100>;
+	};
+
+	sysctrl: system-controller@20050000 {
+		compatible = "hisilicon,sysctrl";
+		reg = <0x20050000 0x1000>;
+		reboot-offset = <0x4>;
+		#clock-cells = <1>;
+	};
+
+	soc {
+		#address-cells = <1>;
+		#size-cells = <1>;
+		compatible = "simple-bus";
+		interrupt-parent = <&gic>;
+		ranges;
+
+		clk_3m: clk_3m {
+			compatible = "fixed-clock";
+			#clock-cells = <0>;
+			clock-frequency = <3000000>;
+		};
+
+		clk_apb: clk_apb {
+			compatible = "fixed-clock";
+			#clock-cells = <0>;
+			clock-frequency = <50000000>;
+		};
+
+		pmu {
+			compatible = "arm,cortex-a7-pmu";
+			interrupts = <0 32 4>;
+		};
+
+		amba {
+			#address-cells = <1>;
+			#size-cells = <1>;
+			compatible = "arm,amba-bus";
+			ranges;
+
+			uart0: uart@20080000 {
+				compatible = "arm,pl011", "arm,primecell";
+				reg = <0x20080000 0x1000>;
+				interrupts = <0 8 4>;
+				clocks = <&clock HI3516A_UART0_CLK>;
+				clock-names = "apb_pclk";
+				status = "disabled";
+			};
+
+			uart1: uart@20090000 {
+				compatible = "arm,pl011", "arm,primecell";
+				reg = <0x20090000 0x1000>;
+				interrupts = <0 9 4>;
+				clocks = <&clock HI3516A_UART1_CLK>;
+				clock-names = "apb_pclk";
+				status = "disabled";
+			};
+
+			uart2: uart@200a0000 {
+				compatible = "arm,pl011", "arm,primecell";
+				reg = <0x200a0000 0x1000>;
+				interrupts = <0 10 4>;
+				clocks = <&clock HI3516A_UART2_CLK>;
+				clock-names = "apb_pclk";
+				status = "disabled";
+			};
+
+			uart3: uart@20230000 {
+				compatible = "arm,pl011", "arm,primecell";
+				reg = <0x20230000 0x1000>;
+				interrupts = <0 11 4>;
+				clocks = <&clock HI3516A_UART3_CLK>;
+				clock-names = "apb_pclk";
+				status = "disabled";
+			};
+
+		};
+
+		usb_phy: phy {
+			compatible = "hisilicon,hisi-usb-phy";
+			reg = <0x20030000 0x10000>, <0x20120000 0x10000>,
+				<0x20050000 0x10000>;
+			#phy-cells = <0>;
+		};
+
+		ehci@0x100b0000 {
+			compatible = "generic-ehci";
+			reg = <0x100b0000 0x10000>;
+			interrupts = <0 21 4>;
+
+			clocks = <&clock HI3516A_USB2_CTRL_UTMI0_REQ>,
+					<&clock HI3516A_USB2_HRST_REQ>;
+			clock-names = "usb2_cttl_utmi0_req", "usb2_hrst_req";
+		};
+
+		ohci@0x100a0000 {
+			compatible = "generic-ohci";
+			reg = <0x100a0000 0x10000>;
+			interrupts = <0 22 4>;
+
+			clocks = <&clock HI3516A_USB2_CTRL_UTMI0_REQ>,
+					<&clock HI3516A_USB2_HRST_REQ>;
+			clock-names = "usb2_cttl_utmi0_req", "usb2_hrst_req";
+		};
+
+		hiudc@0x10080000 {
+			compatible = "hiudc";
+			reg = <0x10080000 0x10000>;
+			interrupts = <0 23 4>;
+
+			clocks = <&clock HI3516A_USB2_HRST_REQ>;
+			clock-names = "clk";
+		};
+
+		dual_timer0: dual_timer@20000000 {
+			compatible = "arm,sp804", "arm,primecell";
+			interrupts = <0 3 4>;
+			reg = <0x20000000 0x1000>;
+			clocks = <&clk_apb>, <&clk_3m>, <&clk_apb>;
+			clock-names = "timer00", "timer01", "apb_pclk";
+			status = "disabled";
+		};
+
+		dual_timer1: dual_timer@20010000 {
+			compatible = "arm,sp804", "arm,primecell";
+			/* timer0 & timer1 */
+			interrupts = <0 4 4>;
+			reg = <0x20010000 0x1000>;
+			clocks = <&clk_3m>, <&clk_3m>, <&clk_apb>;
+			clock-names = "timer12", "timer13", "apb_pclk";
+			status = "disabled";
+		};
+
+		hidmac: hidma-controller@10060000 {
+			compatible = "hisilicon,hisi-dmac";
+			reg = <0x10060000 0x1000>;
+			interrupts = <0 5 4>;
+			clocks = <&clock HI3516A_DMAC_CLK>;
+			clock-names = "dmac_clk";
+			resets = <&clock 0xd8 4>;
+			reset-names = "dma-reset";
+			#dma-cells = <2>;
+			status = "disabled";
+		};
+
+		i2c_bus0: i2c@200d0000 {
+			compatible = "hisilicon,hisi-i2c-hisilicon";
+			reg = <0x200d0000 0x100>;
+			interrupts = <0 14 4>;
+			clocks = <&clock HI3516A_SYSAXI_CLK>;
+			clock-frequency = <100000>;
+			io-size = <0x1000>;
+			id = <0>;
+			status = "disabled";
+		};
+
+		i2c_bus1: i2c@20240000 {
+			compatible = "hisilicon,hisi-i2c-hisilicon";
+			reg = <0x20240000 0x100>;
+			interrupts = <0 57 4>;
+			clocks = <&clock HI3516A_SYSAXI_CLK>;
+			clock-frequency = <100000>;
+			io-size = <0x1000>;
+			id = <1>;
+			status = "disabled";
+		};
+
+		i2c_bus2: i2c@20250000 {
+			compatible = "hisilicon,hisi-i2c-hisilicon";
+			reg = <0x20250000 0x100>;
+			interrupts = <0 58 4>;
+			clocks = <&clock HI3516A_SYSAXI_CLK>;
+			clock-frequency = <100000>;
+			io-size = <0x1000>;
+			id = <2>;
+			status = "disabled";
+		};
+
+		spi_bus0: spi@200c0000 {
+				compatible = "arm,pl022", "arm,primecell";
+				arm,primecell-periphid = <0x00800022>;
+				reg = <0x200c0000 0x1000>;
+				interrupts = <0 12 4>;
+				clocks = <&clock HI3516A_SPI0_CLK>;
+				clock-names = "apb_pclk";
+				status = "disabled";
+				#address-cells = <1>;
+				#size-cells = <0>;
+		};
+
+		spi_bus1: spi@200e0000 {
+				compatible = "arm,pl022", "arm,primecell";
+				arm,primecell-periphid = <0x00800022>;
+				reg = <0x200e0000 0x1000>, <0x20120004 0x4>;
+				interrupts = <0 13 4>;
+				clocks = <&clock HI3516A_SPI1_CLK>;
+				clock-names = "apb_pclk";
+				status = "disabled";
+				#address-cells = <1>;
+				#size-cells = <0>;
+				hisi,spi_cs_sb = <26>;
+				hisi,spi_cs_mask_bit = <0x0c000000>;
+		};
+
+		hisfc350: spi_nor_controller@10010000 {
+			compatible = "hisilicon,hisi-spi-nor";
+			interrupts = <0 17 4>;
+			reg = <0x10010000 0x1000>, <0x58000000 0x1000000>;
+			reg-names = "control", "memory";
+			clocks = <&clock HI3516A_SNOR_CLK>;
+			assigned-clocks = <&clock HI3516A_SNOR_CLK>;
+			assigned-clock-rates = <24000000>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+
+			hi_sfc {
+				compatible = "jedec,spi-nor";
+				reg = <1>;
+			};
+		};
+
+		hisnfc100: spi_nand_controller@10040000 {
+			compatible = "hisilicon,hisi-spi-nand";
+			reg = <0x10040000 0x1000>, <0x54000000 0x1000000>;
+			reg-names = "control", "memory";
+			clocks = <&clock HI3516A_SNAND_CLK>;
+			assigned-clocks = <&clock HI3516A_SNAND_CLK>;
+			assigned-clock-rates = <24000000>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+
+			hinand {
+				compatible = "jedec,spi-nand";
+				reg = <1>;
+			};
+		};
+
+		hinfc610: nand_controller@10000000 {
+			compatible = "hisilicon,hisi-parallel-nand";
+			reg = <0x10000000 0x1000>, <0x50000000 0x1000000>;
+			reg-names = "control", "memory";
+			clocks = <&clock HI3516A_NAND_CLK>;
+			assigned-clocks = <&clock HI3516A_NAND_CLK>;
+			assigned-clock-rates = <198000000>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+
+			hinand {
+				compatible = "jedec,parallel-nand";
+				reg = <1>;
+			};
+		};
+
+		gpio_chip0: gpio_chip@20140000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x20140000 0x10000>;
+			interrupts = <0 47 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip1: gpio_chip@20150000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x20150000 0x10000>;
+			interrupts = <0 48 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip2: gpio_chip@20160000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x20160000 0x10000>;
+			interrupts = <0 49 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip3: gpio_chip@20170000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x20170000 0x10000>;
+			interrupts = <0 50 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip4: gpio_chip@20180000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x20180000 0x10000>;
+			interrupts = <0 51 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip5: gpio_chip@20190000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x20190000 0x10000>;
+			interrupts = <0 52 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip6: gpio_chip@201a0000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x201a0000 0x10000>;
+			interrupts = <0 53 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip7: gpio_chip@201b0000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x201b0000 0x10000>;
+			interrupts = <0 54 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip8: gpio_chip@201c0000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x201c0000 0x10000>;
+			interrupts = <0 55 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip9: gpio_chip@201d0000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x201d0000 0x10000>;
+			interrupts = <0 55 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip10: gpio_chip@201e0000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x201e0000 0x10000>;
+			interrupts = <0 54 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip11: gpio_chip@201f0000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x201f0000 0x10000>;
+			interrupts = <0 53 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip12: gpio_chip@20200000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x20200000 0x10000>;
+			interrupts = <0 52 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip13: gpio_chip@20210000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x20210000 0x10000>;
+			interrupts = <0 51 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip14: gpio_chip@20220000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x20220000 0x10000>;
+			interrupts = <0 50 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip15: gpio_chip@20260000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x20260000 0x10000>;
+			interrupts = <0 49 4>;
+			clocks = <&clock  HI3516A_SYSAXI_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		regulators@20270000 {
+			compatible = "hi3516a,regulators";
+			reg = <0x20270000 0x1000>;
+			regulator-num = <2>;
+			regulator-name-array = "regulator-a7","regulator-media";
+
+			a7_regulator: a7_regulator{
+				regulator-name = "regulator-a7";
+				regulator-min-microvolt = <800000>;
+				regulator-max-microvolt = <1310000>;
+				regulator-always-on;
+				reg_offset = <0x4>;
+			};
+
+			media_regulator: media_regulator{
+				regulator-name = "regulator-media";
+				regulator-min-microvolt = <800000>;
+				regulator-max-microvolt = <1310000>;
+				regulator-always-on;
+				reg_offset = <0xC>;
+			};
+		};
+		mdio: mdio@100903c0 {
+			compatible = "hisilicon,hisi-gemac-mdio";
+			reg = <0x100903c0 0x20>;
+			clocks = <&clock HI3516A_ETH_CLK>,
+					<&clock HI3516A_ETH_PHY_MUX>;
+			assigned-clocks = <&clock HI3516A_ETH_PHY_MUX>;
+			assigned-clock-rates = <25000000>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+		};
+
+		higmac: ethernet@10090000 {
+			compatible = "hisilicon,higmac";
+			reg = <0x10090000 0x1000>,<0x200300ec 0x4>;
+			interrupts = <0 25 4>;
+
+			clocks = <&clock HI3516A_ETH_CLK>,
+					<&clock HI3516A_ETH_MACIF_CLK>;
+			clock-names = "higmac_clk",
+					"macif_clk";
+
+			resets = <&clock 0xcc 0>,
+					<&clock 0xcc 2>;
+			reset-names = "port_reset",
+					"macif_reset";
+
+			mac-address = [00 00 00 00 00 00];
+		};
+
+		mmc0: himci.SD@0x206e0000 {
+			compatible = "hisilicon,hi3516a-himci";
+			reg = <0x206e0000 0x1000>;
+			interrupts = <0 19 4>;
+			clocks = <&clock HI3516A_MMC0_CLK>;
+			clock-names = "mmc_clk";
+			resets = <&clock 0xc4 0>;
+			reset-names = "mmc_reset";
+			max-frequency = <100000000>;
+			bus-width = <4>;
+			cap-sd-highspeed;
+			sd-uhs-sdr12;
+			sd-uhs-sdr25;
+			sd-uhs-sdr50;
+			sd-uhs-sdr104;
+			devid = <0>;
+			status = "disabled";
+		};
+
+		mmc1: himci.SD@0x206f0000 {
+			compatible = "hisilicon,hi3516a-himci";
+			reg = <0x206f0000 0x1000>;
+			interrupts = <0 20 4>;
+			clocks = <&clock HI3516A_MMC1_CLK>;
+			clock-names = "mmc_clk";
+			resets = <&clock 0xc4 8>;
+			reset-names = "mmc_reset";
+			max-frequency = <100000000>;
+			bus-width = <4>;
+			cap-sd-highspeed;
+			sd-uhs-sdr12;
+			sd-uhs-sdr25;
+			sd-uhs-sdr50;
+			sd-uhs-sdr104;
+			devid = <1>;
+			status = "disabled";
+		};
+	};
+
+	media {
+		#address-cells = <1>;
+		#size-cells = <1>;
+		compatible = "simple-bus";
+		interrupt-parent = <&gic>;
+		ranges;
+
+		sys: sys@20030000 {
+			compatible = "hisilicon,hi35xx_sys";
+			reg = <0x20030000 0x10000>, <0x20050000 0x10000>,
+				<0x20110000 0x10000>, <0x20120000 0x10000>;
+			reg-names = "crg", "sys", "ddr", "misc";
+		};
+
+		audio: audio@20650000 {
+			compatible = "hisilicon,hi35xx_aiao";
+			interrupts = <0 39 4>;
+			reg = <0x20650000 0x10000>;
+			reg-names = "aiao";
+		};
+
+		ive: ive@206a0000 {
+			compatible = "hisilicon,hi35xx_ive";
+			interrupts = <0 45 4>;
+			reg = <0x206a0000 0x10000>;
+		};
+
+		vda: vda@206c0000 {
+			compatible = "hisilicon,hi35xx_vda";
+			interrupts = <0 44 4>;
+			reg = <0x206c0000 0x10000>;
+		};
+
+		mipi: mipi@20680000 {
+			compatible = "hisilicon,hi35xx_mipi";
+			interrupts = <0 34 4>;
+			reg = <0x20680000 0x10000>;
+		};
+
+		isp: isp@20580000 {
+			compatible = "hisilicon,hi35xx_isp";
+			interrupts = <0 35 4>;
+			reg = <0x20580000 0x10000>, <0x205a0000 0x20000>;
+			reg-names = "reg_vicap_base_va", "reg_isp_base_va";
+		};
+
+		viu: viu@20580000 {
+			compatible = "hisilicon,hi35xx_viu";
+			interrupts = <0 35 4>;
+			reg = <0x20580000 0x40000>;
+		};
+
+		vou: vou@205c0000 {
+			compatible = "hisilicon,hi35xx_vou";
+			interrupts = <0 33 4>;
+			reg = <0x205c0000 0x10000>;
+		};
+
+		vgs: vgs@20630000 {
+			compatible = "hisilicon,hi35xx_vgs";
+			interrupts = <0 38 4>;
+			reg = <0x20630000 0x10000>;
+		};
+
+		vpss: vpss@20600000 {
+			compatible = "hisilicon,hi35xx_vpss";
+			interrupts = <0 36 4>;
+			reg = <0x20600000 0x10000>;
+		};
+
+		vedu: vedu@20640000 {
+				compatible = "hisilicon,hi35xx_vedu";
+				interrupts = <0 43 4>;
+				reg = <0x20640000 0x10000>;
+		};
+		
+		avc: avc@20620000 {
+				compatible = "hisilicon,hi35xx_avc";
+				interrupts = <0 40 4>;
+				reg = <0x20620000 0x10000>;
+		};
+
+		jpege: jpege@20660000 {
+				compatible = "hisilicon,hi35xx_jpege";
+				interrupts = <0 41 4>;
+				reg = <0x20660000 0x10000>;
+		};
+		
+		tde: tde@20610000 {
+			compatible = "hisilicon,hi35xx_tde";
+			interrupts = <0 37 4>;
+			reg = <0x20610000 0x10000>;
+		};
+
+		pwm: pwm@20130000 {
+			compatible = "hisilicon,hi3516cv300-pwm";
+			reg = <0x20130000 0x10000>;
+		};
+
+		wtdg: wtdg@20040000 {
+			compatible = "hisilicon,hi_wdg";
+			reg = <0x20040000 0x10000>;
+			reg-names = "wtdg";
+		};
+
+		rtc: rtc@20060000 {
+			compatible = "hisilicon,hi_rtc";
+			interrupts = <0 7 4>, <0 56 4>;
+			interrupt-names = "rtc", "rtc_temp";
+			reg = <0x20060000 0x10000>;
+		};
+
+		ir: ir@20070000{
+			compatible = "hisilicon,hi_ir";
+			interrupts = <0 15 4>;
+			reg = <0x20070000 0x10000>;
+		};
+		
+		cipher: cipher@100c0000{
+			compatible = "hisilicon,hi_cipher";
+			interrupts = <0 26 4>;
+			reg = <0x100c0000 0x10000>;
+		};
+	};
+};
diff --git a/arch/arm/boot/dts/hi3536dv100-demb.dts b/arch/arm/boot/dts/hi3536dv100-demb.dts
new file mode 100644
index 0000000..cb6968f
--- /dev/null
+++ b/arch/arm/boot/dts/hi3536dv100-demb.dts
@@ -0,0 +1,192 @@
+/*
+ * Copyright (c) 2013-2014 Linaro Ltd.
+ * Copyright (c) 2015-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+/dts-v1/;
+#include "hi3536dv100.dtsi"
+
+/ {
+	model = "Hisilicon HI3536DV100 DEMO Board";
+	compatible = "hisilicon,hi3536dv100";
+
+	memory {
+		device_type = "memory";
+		reg = <0x80000000 0x20000000>;
+	};
+};
+
+&uart0 {
+	status = "okay";
+};
+
+&i2c_bus0 {
+    status = "okay";
+    clock-frequency = <100000>;
+};
+
+&dual_timer0 {
+	status = "okay";
+};
+
+&mdio0 {
+	hisilicon,phy-reset-delays-us = <10000 20000 150000>;
+	phy0: ethernet-phy@1 {
+		reg = <1>;
+	};
+};
+
+&hisi_femac0 {
+	mac-address = [00 00 00 00 00 00];
+	phy-mode = "mii";
+	phy-handle = <&phy0>;
+};
+
+&hisfc {
+	hi_sfc {
+		   compatible = "jedec,spi-nor";
+		   reg = <0>;
+		   spi-max-frequency = <160000000>;
+	};
+};
+
+&hisnfc {
+	hinand {
+		   compatible = "jedec,spi-nand";
+		   reg = <0>;
+		   spi-max-frequency = <160000000>;
+	};
+};
+
+&hidmac {
+	status = "okay";
+};
+
+&gpio_chip0 {
+	status = "okay";
+};
+
+&gpio_chip1 {
+	status = "okay";
+};
+
+&gpio_chip2 {
+	status = "okay";
+};
+
+&gpio_chip3 {
+	status = "okay";
+};
+
+&gpio_chip4 {
+	status = "okay";
+};
+
+&gpio_chip5 {
+	status = "okay";
+};
+
+&pmux {
+
+	i2s1_pmux: i2s1_pmux {
+		pinctrl-single,pins = <
+			0x0070 0x2
+			0x0078 0x2
+			0x007c 0x2
+			0x0090 0x2
+			0x0094 0x2
+		>;
+	};
+	i2s2_pmux: i2s2_pmux {
+		pinctrl-single,pins = <
+			0x0040 0x3 /*I2S_SD_RX*/
+			0x0044 0x3 /*I2S_MCLK*/
+			0x0048 0x3 /*I2S_WS*/
+			0x004c 0x3 /*I2S_BCLK*/
+			0x0050 0x3 /*I2S_SD_TX*/
+		>;
+	};
+};
+
+&sys_config_ctrl {
+	padctrl-ability,demo = <
+		0x120f08ac 0xb0
+		0x120f08b4 0xb0
+		0x120f08b8 0xb0
+		0x120f08cc 0xb0
+		0x120f08d0 0xb0
+	>;
+	padctrl-ability,sck = <
+		0x120f0868 0x80
+		0x120f086c 0xa0
+		0x120f0870 0xa0
+		0x120f0874 0xa0
+		0x120f0878 0xa0
+	>;
+	sysctrl-ddr,pins = <
+		0x12120078  0x55322100  /* JPGD - JPGE - TFE - VGS - VDH - A7 - VDP - AIAO */
+		0x1212007c  0x65665526  /* FMC - DMA1 - DMA9 - DDRT - SATA - ETH1 - ETH0 - VOIE */
+		0x12120080  0x66666666  /*     -      -      -      -      -      - CIPHER - USB */
+		0x12120084  0x55522100  /* JPGD - JPGE - TFE - VGS - VDH - A7 - VDP - AIAO */
+		0x12120088  0x65665526  /* FMC - DMA1 - DMA9 - DDRT - SATA - ETH1 - ETH0 - VOIE */
+		0x1212008c  0x66626666  /*      -      -      -      -      -      - CIPHER - USB */
+		0x12120094  0x10        /* aio_vdp_axi_pri*/
+		0x12120090  0x80020000	/* aio_vdp_axi_timeout*/
+		0x12110020  0x000fff01  /* AXI_ACTION[19:8]:wr_rcv_mode=0,12ports */
+		0x12110200  0x00200000  /* ports0  */
+		0x12110210  0x00300000  /* ports1  */
+		0x12110220  0x00300000  /* ports2  */
+		0x12110230  0x00300000  /* ports3  */
+		0x12110240  0x00300000  /* ports4  */
+		0x12110250  0x00300000  /* ports5  */
+		0x12110260  0x00300000  /* ports6  */
+		0x12110270  0x00300000  /* ports7  */
+		0x12110204  0x76543210  /* ports0  */
+		0x12110214  0x76543210  /* ports1  */
+		0x12110224  0x76543210  /* ports2  */
+		0x12110234  0x76543210	/* ports3	*/
+		0x12110244  0x76543210  /* ports4	*/
+		0x12110254  0x76543210  /* ports5   */
+		0x12110264  0x76543210  /* ports6   */
+		0x12110274  0x76543210  /* ports7   */
+		0x12110208  0x76543210  /* ports0   */
+		0x12110218  0x76543210  /* ports1   */
+		0x12110228  0x76543210  /* ports2   */
+		0x12110238  0x76543210  /* ports3   */
+		0x12110248  0x76543210  /* ports4   */
+		0x12110258  0x76543210  /* ports5   */
+		0x12110268  0x76543210  /* ports6   */
+		0x12110278  0x76543210  /* ports7   */
+		0x12114000  0x00000002  /*qosb_push_ctrl  */
+		0x1211410c  0x0000000a  /*qosb_dmc_lvl    */
+		0x12114110  0x0000000a  /*qosb_dmc_lvl    */
+		0x1211408c  0xb3032010  /*qosb_wbuf_ctrl  */
+		0x12114090  0xb3032010  /*qosb_wbuf_ctrl   */
+		0x121140f4  0x00000033  /*row-hit enable   */
+		0x121140ec  0x00000044  /*row-hit          */
+		0x121140f0  0x00003333  /*row-hit          */
+		0x121141f4  0x00000000  /*qosb_wbuf_pri_ctrl*/
+		0x121141f0  0x00000001  /*enable qosbuf timeout,through prilvl to remap timeout level*/
+		0x1211409c  0x0000000a  /* wr_tout3 ~wr_tout0   */
+		0x121140ac  0x0000000a  /* rd_tout3 ~rd_tout0   */
+		0x121141f8  0x00800002  /* qosb_rhit_ctrl,open_window=128,close_window=2*/
+	>;
+	pinctrl-names = "demo", "sck", "default";
+	pinctrl-0 = <&i2s1_pmux>;
+	pinctrl-1 = <&i2s2_pmux>;
+	pinctrl-2 = <>;
+};
diff --git a/arch/arm/boot/dts/hi3536dv100.dtsi b/arch/arm/boot/dts/hi3536dv100.dtsi
new file mode 100644
index 0000000..968d91d
--- /dev/null
+++ b/arch/arm/boot/dts/hi3536dv100.dtsi
@@ -0,0 +1,441 @@
+/*
+ * Copyright (c) 2013-2014 Linaro Ltd.
+ * Copyright (c) 2015-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "skeleton.dtsi"
+#include <dt-bindings/clock/hi3536dv100-clock.h>
+/ {
+	aliases {
+		serial0 = &uart0;
+		i2c0 = &i2c_bus0;
+		gpio0 = &gpio_chip0;
+		gpio1 = &gpio_chip1;
+		gpio2 = &gpio_chip2;
+		gpio3 = &gpio_chip3;
+		gpio4 = &gpio_chip4;
+		gpio5 = &gpio_chip5;
+	};
+
+	cpus {
+		#address-cells = <1>;
+		#size-cells = <0>;
+
+		cpu@0 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a7";
+			reg = <0>;
+		};
+	};
+
+	clock: clock@12040000 {
+		compatible = "hisilicon,hi3536dv100-clock";
+		#address-cells = <1>;
+		#size-cells = <1>;
+		#clock-cells = <1>;
+		#reset-cells = <2>;
+		reg = <0x12040000 0x1000>;
+	};
+
+	gic: interrupt-controller@10300000 {
+		compatible = "arm,cortex-a7-gic";
+		#interrupt-cells = <3>;
+		#address-cells = <0>;
+		interrupt-controller;
+		/* gic dist base, gic cpu base , no virtual support */
+		reg = <0x10301000 0x1000>, <0x10302000 0x100>;
+	 };
+
+	soc {
+		#address-cells = <1>;
+		#size-cells = <1>;
+		compatible = "simple-bus";
+		interrupt-parent = <&gic>;
+		ranges;
+
+		clk_3m: clk_3m {
+			compatible = "fixed-clock";
+			#clock-cells = <0>;
+			clock-frequency = <3000000>;
+		};
+
+		clk_apb: clk_apb {
+			compatible = "fixed-clock";
+			#clock-cells = <0>;
+			clock-frequency = <50000000>;
+		};
+
+		pmu {
+			compatible = "arm,cortex-a7-pmu";
+			interrupts = <0 54 4>;
+		};
+
+		sysctrl: system-controller@12050000 {
+			compatible = "hisilicon,sysctrl";
+			reg = <0x12050000 0x1000>;
+			reboot-offset = <0x4>;
+			#clock-cells = <1>;
+		};
+
+		amba {
+			#address-cells = <1>;
+			#size-cells = <1>;
+			compatible = "arm,amba-bus";
+			ranges;
+
+			dual_timer0: dual_timer@12000000 {
+				compatible = "arm,sp804", "arm,primecell";
+				/* timer0 & timer1 */
+				interrupts = <0 1 4>;
+				reg = <0x12000000 0x1000>;
+				clocks = <&clk_3m>, <&clk_3m>, <&clk_apb>;
+				clock-names = "timer00", "timer01", "apb_pclk";
+				status = "disabled";
+			};
+
+			dual_timer1: dual_timer@12010000 {
+				compatible = "arm,sp804", "arm,primecell";
+				/* timer2 & timer3 */
+				interrupts = <0 2 4>;
+				reg = <0x12010000 0x1000>;
+				clocks = <&clk_3m>, <&clk_3m>, <&clk_apb>;
+				clock-names = "timer10", "timer11", "apb_pclk";
+				status = "disabled";
+			};
+
+			dual_timer2: dual_timer@12020000 {
+				compatible = "arm,sp804", "arm,primecell";
+				/* timer4 & timer5 */
+				interrupts = <0 3 4>;
+				reg = <0x12020000 0x1000>;
+				clocks = <&clk_3m>, <&clk_3m>, <&clk_apb>;
+				clock-names = "timer20", "timer21", "apb_pclk";
+				status = "disabled";
+			};
+
+			dual_timer3: dual_timer@12030000 {
+				compatible = "arm,sp804", "arm,primecell";
+				/* timer6 & timer7 */
+				interrupts = <0 4 4>;
+				reg = <0x12030000 0x1000>;
+				clocks = <&clk_3m>, <&clk_3m>, <&clk_apb>;
+				clock-names = "timer30", "timer31", "apb_pclk";
+				status = "disabled";
+			};
+
+			uart0: uart@12080000 {
+				compatible = "arm,pl011", "arm,primecell";
+				reg = <0x12080000 0x1000>;
+				interrupts = <0 6 4>;
+				clocks = <&clock HI3536DV100_UART0_CLK>;
+				clock-names = "apb_pclk";
+				status = "disabled";
+			};
+
+			uart1: uart@12090000 {
+				compatible = "arm,pl011", "arm,primecell";
+				reg = <0x12090000 0x1000>;
+				interrupts = <0 7 4>;
+				clocks = <&clock HI3536DV100_UART1_CLK>;
+				clock-names = "apb_pclk";
+				status = "disabled";
+			};
+
+			uart2: uart@120a0000 {
+				compatible = "arm,pl011", "arm,primecell";
+				reg = <0x120a0000 0x1000>;
+				interrupts = <0 8 4>;
+				clocks = <&clock HI3536DV100_UART2_CLK>;
+				clock-names = "apb_pclk";
+				status = "disabled";
+			};
+
+		};
+
+		i2c_bus0: i2c@120c0000 {
+			compatible = "hisilicon,hi3536dv100-i2c",
+					"hisilicon,hibvt-i2c";
+			reg = <0x120c0000 0x1000>;
+			clocks = <&clock HI3536DV100_SYSAPB_CLK>;
+			status = "disabled";
+		};
+
+		sata_phy: phy@10030000 {
+			compatible = "hisilicon,hisi-sata-phy";
+			reg = <0x10030000 0x10000>;
+			#phy-cells = <0>;
+		};
+
+		ahci: sata@10030000 {
+			compatible = "hisilicon,hisi-ahci";
+			reg = <0x10030000 0x1000>;
+			interrupts = <0 17 4>;
+			phys = <&sata_phy>;
+			phy-names = "sata-phy";
+			#address-cells = <1>;
+			#size-cells = <0>;
+		};
+
+		mdio0: mdio@10011100 {
+			compatible = "hisilicon,hisi-femac-mdio";
+			reg = <0x10011100 0x10>, <0x12120064 0x4>,
+				<0x12121000 0x4>;
+			clocks = <&clock HI3536DV100_ETH0_CLK>,
+				<&clock HI3536DV100_ETH0_PHY_CLK>;
+			clock-names = "mdio", "phy";
+			resets = <&clock 0xc4 3>, <&clock 0xc4 9>;
+			reset-names = "external-phy", "internal-phy";
+			#address-cells = <1>;
+			#size-cells = <0>;
+		};
+
+		hisi_femac0: ethernet@10010000 {
+			compatible = "hisilicon,hi3536dv100-femac",
+				"hisilicon,hisi-femac-v2";
+			reg = <0x10010000 0x1000>,<0x10011300 0x200>;
+			interrupts = <0 11 4>;
+			clocks = <&clock HI3536DV100_ETH0_CLK>;
+			resets = <&clock 0xc4 0>;
+			reset-names = "mac";
+		};
+
+		usb_phy: usbphy {
+			compatible = "hisilicon,hisi-usb-phy";
+			reg = <0x12040000 0x1000>, <0x12120000 0x10000>;
+		};
+
+		ehci@0x11010000 {
+			compatible = "generic-ehci";
+			reg = <0x11010000 0x10000>;
+			interrupts = <0 19 4>;
+		};
+
+		ohci@0x11000000 {
+			compatible = "generic-ohci";
+			reg = <0x11000000 0x10000>;
+			interrupts = <0 18 4>;
+		};
+
+		fmc: flash-memory-controller@10000000 {
+			compatible = "hisilicon,hisi-fmc";
+			reg = <0x10000000 0x1000>, <0x14000000 0x1000000>;
+			reg-names = "control", "memory";
+			clocks = <&clock HI3536DV100_FMC_CLK>;
+			#address-cells = <1>;
+			#size-cells = <0>;
+
+			hisfc:spi-nor@0 {
+					compatible = "hisilicon,fmc-spi-nor";
+					assigned-clocks = <&clock HI3536DV100_FMC_CLK>;
+					assigned-clock-rates = <24000000>;
+					#address-cells = <1>;
+					#size-cells = <0>;
+			};
+
+			hisnfc:spi-nand@0 {
+					compatible = "hisilicon,fmc-spi-nand";
+					assigned-clocks = <&clock HI3536DV100_FMC_CLK>;
+					assigned-clock-rates = <24000000>;
+					#address-cells = <1>;
+					#size-cells = <0>;
+			};
+		};
+
+		hidmac: hidma-controller@11020000 {
+			compatible = "hisilicon,hisi-dmac";
+			reg = <0x11020000 0x1000>;
+			interrupts = <0 14 4>;
+			clocks = <&clock HI3536DV100_DMAC_CLK>;
+			clock-names = "dmac_clk";
+			resets = <&clock 0xc8 4>;
+			reset-names = "dma-reset";
+			#dma-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip0: gpio_chip@12150000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x12150000 0x10000>;
+			interrupts = <0 55 4>;
+			clocks = <&clock  HI3536DV100_SYSAPB_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip1: gpio_chip@12160000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x12160000 0x10000>;
+			interrupts = <0 56 4>;
+			clocks = <&clock  HI3536DV100_SYSAPB_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip2: gpio_chip@12170000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x12170000 0x10000>;
+			interrupts = <0 57 4>;
+			clocks = <&clock  HI3536DV100_SYSAPB_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip3: gpio_chip@12180000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x12180000 0x10000>;
+			interrupts = <0 58 4>;
+			clocks = <&clock  HI3536DV100_SYSAPB_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip4: gpio_chip@12190000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x12190000 0x10000>;
+			interrupts = <0 59 4>;
+			clocks = <&clock  HI3536DV100_SYSAPB_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		gpio_chip5: gpio_chip@121a0000 {
+			compatible = "arm,pl061", "arm,primecell";
+			reg = <0x121a0000 0x10000>;
+			interrupts = <0 60 4>;
+			clocks = <&clock  HI3536DV100_SYSAPB_CLK>;
+			clock-names = "apb_pclk";
+			#gpio-cells = <2>;
+			status = "disabled";
+		};
+
+		pmux: pinmux@120F0000 {
+			compatible = "pinctrl-single";
+			reg = <0x120F0000 0x3A8>;
+			#address-cells = <1>;
+			#size-cells = <1>;
+			#gpio-range-cells = <3>;
+			ranges;
+
+			pinctrl-single,register-width = <32>;
+			pinctrl-single,function-mask = <7>;
+			/* pin base, nr pins & gpio function */
+			pinctrl-single,gpio-range = <&range 0 54 0
+				&range 55 6 1 &range 61 5 0>;
+
+			range: gpio-range {
+				#pinctrl-single,gpio-range-cells = <3>;
+			};
+		};
+	};
+
+	media {
+		#address-cells = <1>;
+		#size-cells = <1>;
+		compatible = "simple-bus";
+		interrupt-parent = <&gic>;
+		ranges;
+
+		osal: osal {
+			compatible = "hisilicon,osal";
+		};
+
+		sys: sys@12040000 {
+			compatible = "hisilicon,hi35xx_sys";
+			reg = <0x12040000 0x10000>, <0x12050000 0x10000>,
+				<0x12110000 0x10000>, <0x12120000 0x10000>;
+			reg-names = "crg", "sys", "ddr", "misc";
+		};
+
+		rtc: rtc@120b0000 {
+			compatible = "hisilicon,hi35xx-rtc";
+			interrupts = <0 5 4>;
+			reg = <0x120b0000 0x10000>;
+		};
+
+		vou: vou@13020000 {
+			compatible = "hisilicon,hi35xx_vou";
+			interrupts = <0 34 4>;
+			reg = <0x13020000 0x10000>;
+		};
+
+		vgs: vgs@13100000 {
+			compatible = "hisilicon,hi35xx_vgs";
+			interrupts = <0 28 4>;
+			reg = <0x13100000 0x10000>;
+		};
+
+		audio: audio@13040000 {
+			compatible = "hisilicon,hi35xx_aiao";
+			interrupts = <0 32 4>;
+			reg = <0x13040000 0x10000>, <0x130500d0 0x10000>;
+			reg-names = "aiao", "acodec";
+		};
+
+		vdec: vdec@13200000 {
+			compatible = "hisilicon,hi35xx_vdec";
+			interrupts = <0 21 4>, <0 23 4>;
+			interrupt-names = "vdm", "scd";
+			reg = <0x13200000 0xc000>, <0x1320c000 0x4000>;
+			reg-names = "vdm", "scd";
+		};
+
+		tde: tde@13130000 {
+			compatible = "hisilicon,hi35xx_tde";
+			interrupts = <0 29 4>;
+			reg = <0x13130000 0x1000>;
+		};
+
+		jpgd: jpgd@13110000 {
+			compatible = "hisilicon,hi35xx_jpgd";
+			interrupts = <0 31 4>;
+			interrupt-names = "jpgd";
+			reg = <0x13110000 0x10000>;
+			reg-names = "jpgd";
+		};
+
+		hiir: hiir@0x12140000 {
+			compatible = "hisilicon,hi_ir";
+			interrupts = <0 9 4>;
+			reg = <0x12140000 0x10000>;
+		};
+
+		cipher: cipher@0x11030000 {
+			compatible = "hisilicon,hi_isr";
+			interrupts = <0 13 4>;
+			reg = <0x11030000 0x10000>;
+		};
+
+		jpege: jpege@13120000 {
+			compatible = "hisilicon,hi35xx_jpege";
+			interrupts = <0 30 4>;
+			reg = <0x13120000 0x10000>;
+		};
+
+		pin_ctrl_ddr: pin_ctrl_ddr {
+			compatible = "hisilicon,pinctrl-ddr";
+		};
+
+		sys_config_ctrl: sys_config_ctrl {
+			compatible = "hisilicon,sys_config_ctrl";
+		};
+	};
+};
diff --git a/arch/arm/configs/hi3516a_full_defconfig b/arch/arm/configs/hi3516a_full_defconfig
new file mode 100644
index 0000000..7601981
--- /dev/null
+++ b/arch/arm/configs/hi3516a_full_defconfig
@@ -0,0 +1,2723 @@
+#
+# Automatically generated file; DO NOT EDIT.
+# Linux/arm 4.9.37 Kernel Configuration
+#
+CONFIG_ARM=y
+CONFIG_ARM_HAS_SG_CHAIN=y
+CONFIG_MIGHT_HAVE_PCI=y
+CONFIG_SYS_SUPPORTS_APM_EMULATION=y
+CONFIG_HAVE_PROC_CPU=y
+CONFIG_STACKTRACE_SUPPORT=y
+CONFIG_LOCKDEP_SUPPORT=y
+CONFIG_TRACE_IRQFLAGS_SUPPORT=y
+CONFIG_RWSEM_XCHGADD_ALGORITHM=y
+CONFIG_FIX_EARLYCON_MEM=y
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_NEED_DMA_MAP_STATE=y
+CONFIG_ARCH_SUPPORTS_UPROBES=y
+CONFIG_VECTORS_BASE=0xffff0000
+CONFIG_ARM_PATCH_PHYS_VIRT=y
+CONFIG_GENERIC_BUG=y
+CONFIG_PGTABLE_LEVELS=2
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+CONFIG_IRQ_WORK=y
+CONFIG_BUILDTIME_EXTABLE_SORT=y
+
+#
+# General setup
+#
+CONFIG_BROKEN_ON_SMP=y
+CONFIG_INIT_ENV_ARG_LIMIT=32
+CONFIG_CROSS_COMPILE=""
+# CONFIG_COMPILE_TEST is not set
+CONFIG_LOCALVERSION=""
+# CONFIG_LOCALVERSION_AUTO is not set
+CONFIG_HAVE_KERNEL_GZIP=y
+CONFIG_HAVE_KERNEL_LZMA=y
+CONFIG_HAVE_KERNEL_XZ=y
+CONFIG_HAVE_KERNEL_LZO=y
+CONFIG_HAVE_KERNEL_LZ4=y
+CONFIG_KERNEL_GZIP=y
+# CONFIG_KERNEL_LZMA is not set
+# CONFIG_KERNEL_XZ is not set
+# CONFIG_KERNEL_LZO is not set
+# CONFIG_KERNEL_LZ4 is not set
+CONFIG_DEFAULT_HOSTNAME="(none)"
+CONFIG_SWAP=y
+CONFIG_SYSVIPC=y
+CONFIG_SYSVIPC_SYSCTL=y
+# CONFIG_POSIX_MQUEUE is not set
+CONFIG_CROSS_MEMORY_ATTACH=y
+CONFIG_FHANDLE=y
+CONFIG_USELIB=y
+# CONFIG_AUDIT is not set
+CONFIG_HAVE_ARCH_AUDITSYSCALL=y
+
+#
+# IRQ subsystem
+#
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_GENERIC_IRQ_SHOW=y
+CONFIG_GENERIC_IRQ_SHOW_LEVEL=y
+CONFIG_HARDIRQS_SW_RESEND=y
+CONFIG_IRQ_DOMAIN=y
+CONFIG_IRQ_DOMAIN_HIERARCHY=y
+CONFIG_HANDLE_DOMAIN_IRQ=y
+CONFIG_IRQ_FORCED_THREADING=y
+CONFIG_SPARSE_IRQ=y
+CONFIG_ARCH_CLOCKSOURCE_DATA=y
+CONFIG_GENERIC_TIME_VSYSCALL=y
+CONFIG_GENERIC_CLOCKEVENTS=y
+
+#
+# Timers subsystem
+#
+CONFIG_HZ_PERIODIC=y
+# CONFIG_NO_HZ_IDLE is not set
+# CONFIG_NO_HZ is not set
+# CONFIG_HIGH_RES_TIMERS is not set
+
+#
+# CPU/Task time and stats accounting
+#
+CONFIG_TICK_CPU_ACCOUNTING=y
+# CONFIG_VIRT_CPU_ACCOUNTING_GEN is not set
+CONFIG_IRQ_TIME_ACCOUNTING=y
+# CONFIG_BSD_PROCESS_ACCT is not set
+# CONFIG_TASKSTATS is not set
+
+#
+# RCU Subsystem
+#
+CONFIG_TINY_RCU=y
+# CONFIG_RCU_EXPERT is not set
+CONFIG_SRCU=y
+# CONFIG_TASKS_RCU is not set
+# CONFIG_RCU_STALL_COMMON is not set
+# CONFIG_TREE_RCU_TRACE is not set
+# CONFIG_RCU_EXPEDITE_BOOT is not set
+# CONFIG_BUILD_BIN2C is not set
+# CONFIG_IKCONFIG is not set
+CONFIG_LOG_BUF_SHIFT=17
+CONFIG_NMI_LOG_BUF_SHIFT=13
+CONFIG_GENERIC_SCHED_CLOCK=y
+CONFIG_CGROUPS=y
+# CONFIG_MEMCG is not set
+# CONFIG_BLK_CGROUP is not set
+# CONFIG_CGROUP_SCHED is not set
+# CONFIG_CGROUP_PIDS is not set
+CONFIG_CGROUP_FREEZER=y
+# CONFIG_CPUSETS is not set
+# CONFIG_CGROUP_DEVICE is not set
+# CONFIG_CGROUP_CPUACCT is not set
+# CONFIG_CGROUP_DEBUG is not set
+# CONFIG_CHECKPOINT_RESTORE is not set
+CONFIG_NAMESPACES=y
+CONFIG_UTS_NS=y
+CONFIG_IPC_NS=y
+# CONFIG_USER_NS is not set
+CONFIG_PID_NS=y
+CONFIG_NET_NS=y
+# CONFIG_SCHED_AUTOGROUP is not set
+# CONFIG_SYSFS_DEPRECATED is not set
+# CONFIG_RELAY is not set
+CONFIG_BLK_DEV_INITRD=y
+CONFIG_INITRAMFS_SOURCE=""
+CONFIG_RD_GZIP=y
+# CONFIG_RD_BZIP2 is not set
+# CONFIG_RD_LZMA is not set
+# CONFIG_RD_XZ is not set
+# CONFIG_RD_LZO is not set
+CONFIG_RD_LZ4=y
+CONFIG_CC_OPTIMIZE_FOR_PERFORMANCE=y
+# CONFIG_CC_OPTIMIZE_FOR_SIZE is not set
+CONFIG_SYSCTL=y
+CONFIG_ANON_INODES=y
+CONFIG_HAVE_UID16=y
+CONFIG_BPF=y
+# CONFIG_EXPERT is not set
+CONFIG_UID16=y
+CONFIG_MULTIUSER=y
+# CONFIG_SGETMASK_SYSCALL is not set
+CONFIG_SYSFS_SYSCALL=y
+# CONFIG_SYSCTL_SYSCALL is not set
+CONFIG_KALLSYMS=y
+# CONFIG_KALLSYMS_ALL is not set
+# CONFIG_KALLSYMS_ABSOLUTE_PERCPU is not set
+CONFIG_KALLSYMS_BASE_RELATIVE=y
+CONFIG_PRINTK=y
+CONFIG_PRINTK_NMI=y
+CONFIG_BUG=y
+CONFIG_ELF_CORE=y
+CONFIG_BASE_FULL=y
+CONFIG_FUTEX=y
+CONFIG_EPOLL=y
+CONFIG_SIGNALFD=y
+CONFIG_TIMERFD=y
+CONFIG_EVENTFD=y
+# CONFIG_BPF_SYSCALL is not set
+CONFIG_SHMEM=y
+CONFIG_AIO=y
+CONFIG_ADVISE_SYSCALLS=y
+# CONFIG_USERFAULTFD is not set
+CONFIG_MEMBARRIER=y
+# CONFIG_EMBEDDED is not set
+CONFIG_HAVE_PERF_EVENTS=y
+CONFIG_PERF_USE_VMALLOC=y
+
+#
+# Kernel Performance Events And Counters
+#
+# CONFIG_PERF_EVENTS is not set
+CONFIG_VM_EVENT_COUNTERS=y
+CONFIG_SLUB_DEBUG=y
+CONFIG_COMPAT_BRK=y
+# CONFIG_SLAB is not set
+CONFIG_SLUB=y
+# CONFIG_SLAB_FREELIST_RANDOM is not set
+# CONFIG_SYSTEM_DATA_VERIFICATION is not set
+# CONFIG_PROFILING is not set
+CONFIG_HAVE_OPROFILE=y
+# CONFIG_KPROBES is not set
+# CONFIG_JUMP_LABEL is not set
+# CONFIG_UPROBES is not set
+# CONFIG_HAVE_64BIT_ALIGNED_ACCESS is not set
+CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS=y
+CONFIG_ARCH_USE_BUILTIN_BSWAP=y
+CONFIG_HAVE_KPROBES=y
+CONFIG_HAVE_KRETPROBES=y
+CONFIG_HAVE_OPTPROBES=y
+CONFIG_HAVE_NMI=y
+CONFIG_HAVE_ARCH_TRACEHOOK=y
+CONFIG_HAVE_DMA_CONTIGUOUS=y
+CONFIG_GENERIC_SMP_IDLE_THREAD=y
+CONFIG_GENERIC_IDLE_POLL_SETUP=y
+CONFIG_HAVE_REGS_AND_STACK_ACCESS_API=y
+CONFIG_HAVE_CLK=y
+CONFIG_HAVE_DMA_API_DEBUG=y
+CONFIG_HAVE_PERF_REGS=y
+CONFIG_HAVE_PERF_USER_STACK_DUMP=y
+CONFIG_HAVE_ARCH_JUMP_LABEL=y
+CONFIG_ARCH_WANT_IPC_PARSE_VERSION=y
+CONFIG_HAVE_ARCH_SECCOMP_FILTER=y
+CONFIG_HAVE_GCC_PLUGINS=y
+# CONFIG_GCC_PLUGINS is not set
+CONFIG_HAVE_CC_STACKPROTECTOR=y
+# CONFIG_CC_STACKPROTECTOR is not set
+CONFIG_CC_STACKPROTECTOR_NONE=y
+# CONFIG_CC_STACKPROTECTOR_REGULAR is not set
+# CONFIG_CC_STACKPROTECTOR_STRONG is not set
+CONFIG_HAVE_CONTEXT_TRACKING=y
+CONFIG_HAVE_VIRT_CPU_ACCOUNTING_GEN=y
+CONFIG_HAVE_IRQ_TIME_ACCOUNTING=y
+CONFIG_HAVE_MOD_ARCH_SPECIFIC=y
+CONFIG_MODULES_USE_ELF_REL=y
+CONFIG_ARCH_HAS_ELF_RANDOMIZE=y
+CONFIG_HAVE_ARCH_MMAP_RND_BITS=y
+CONFIG_HAVE_EXIT_THREAD=y
+CONFIG_ARCH_MMAP_RND_BITS_MIN=8
+CONFIG_ARCH_MMAP_RND_BITS_MAX=16
+CONFIG_ARCH_MMAP_RND_BITS=8
+# CONFIG_HAVE_ARCH_HASH is not set
+# CONFIG_ISA_BUS_API is not set
+CONFIG_CLONE_BACKWARDS=y
+CONFIG_OLD_SIGSUSPEND3=y
+CONFIG_OLD_SIGACTION=y
+# CONFIG_CPU_NO_EFFICIENT_FFS is not set
+# CONFIG_HAVE_ARCH_VMAP_STACK is not set
+
+#
+# GCOV-based kernel profiling
+#
+CONFIG_ARCH_HAS_GCOV_PROFILE_ALL=y
+CONFIG_HAVE_GENERIC_DMA_COHERENT=y
+CONFIG_SLABINFO=y
+CONFIG_RT_MUTEXES=y
+CONFIG_BASE_SMALL=0
+CONFIG_MODULES=y
+# CONFIG_MODULE_FORCE_LOAD is not set
+CONFIG_MODULE_UNLOAD=y
+# CONFIG_MODULE_FORCE_UNLOAD is not set
+# CONFIG_MODVERSIONS is not set
+# CONFIG_MODULE_SRCVERSION_ALL is not set
+# CONFIG_MODULE_SIG is not set
+# CONFIG_MODULE_COMPRESS is not set
+# CONFIG_TRIM_UNUSED_KSYMS is not set
+CONFIG_BLOCK=y
+CONFIG_LBDAF=y
+CONFIG_BLK_DEV_BSG=y
+# CONFIG_BLK_DEV_BSGLIB is not set
+# CONFIG_BLK_DEV_INTEGRITY is not set
+CONFIG_BLK_CMDLINE_PARSER=y
+
+#
+# Partition Types
+#
+CONFIG_PARTITION_ADVANCED=y
+# CONFIG_ACORN_PARTITION is not set
+# CONFIG_AIX_PARTITION is not set
+# CONFIG_OSF_PARTITION is not set
+# CONFIG_AMIGA_PARTITION is not set
+# CONFIG_ATARI_PARTITION is not set
+# CONFIG_MAC_PARTITION is not set
+CONFIG_MSDOS_PARTITION=y
+# CONFIG_BSD_DISKLABEL is not set
+# CONFIG_MINIX_SUBPARTITION is not set
+# CONFIG_SOLARIS_X86_PARTITION is not set
+# CONFIG_UNIXWARE_DISKLABEL is not set
+# CONFIG_LDM_PARTITION is not set
+# CONFIG_SGI_PARTITION is not set
+# CONFIG_ULTRIX_PARTITION is not set
+# CONFIG_SUN_PARTITION is not set
+# CONFIG_KARMA_PARTITION is not set
+CONFIG_EFI_PARTITION=y
+# CONFIG_SYSV68_PARTITION is not set
+CONFIG_CMDLINE_PARTITION=y
+
+#
+# IO Schedulers
+#
+CONFIG_IOSCHED_NOOP=y
+CONFIG_IOSCHED_DEADLINE=y
+CONFIG_IOSCHED_CFQ=y
+CONFIG_DEFAULT_DEADLINE=y
+# CONFIG_DEFAULT_CFQ is not set
+# CONFIG_DEFAULT_NOOP is not set
+CONFIG_DEFAULT_IOSCHED="deadline"
+CONFIG_INLINE_SPIN_UNLOCK_IRQ=y
+CONFIG_INLINE_READ_UNLOCK=y
+CONFIG_INLINE_READ_UNLOCK_IRQ=y
+CONFIG_INLINE_WRITE_UNLOCK=y
+CONFIG_INLINE_WRITE_UNLOCK_IRQ=y
+CONFIG_ARCH_SUPPORTS_ATOMIC_RMW=y
+CONFIG_FREEZER=y
+
+#
+# System Type
+#
+CONFIG_MMU=y
+CONFIG_ARCH_MULTIPLATFORM=y
+# CONFIG_ARCH_GEMINI is not set
+# CONFIG_ARCH_EBSA110 is not set
+# CONFIG_ARCH_EP93XX is not set
+# CONFIG_ARCH_FOOTBRIDGE is not set
+# CONFIG_ARCH_NETX is not set
+# CONFIG_ARCH_IOP13XX is not set
+# CONFIG_ARCH_IOP32X is not set
+# CONFIG_ARCH_IOP33X is not set
+# CONFIG_ARCH_IXP4XX is not set
+# CONFIG_ARCH_DOVE is not set
+# CONFIG_ARCH_KS8695 is not set
+# CONFIG_ARCH_W90X900 is not set
+# CONFIG_ARCH_LPC32XX is not set
+# CONFIG_ARCH_PXA is not set
+# CONFIG_ARCH_RPC is not set
+# CONFIG_ARCH_SA1100 is not set
+# CONFIG_ARCH_S3C24XX is not set
+# CONFIG_ARCH_DAVINCI is not set
+# CONFIG_ARCH_OMAP1 is not set
+
+#
+# Multiple platform selection
+#
+
+#
+# CPU Core family selection
+#
+# CONFIG_ARCH_MULTI_V6 is not set
+CONFIG_ARCH_MULTI_V7=y
+CONFIG_ARCH_MULTI_V6_V7=y
+# CONFIG_ARCH_MULTI_CPU_AUTO is not set
+# CONFIG_ARCH_VIRT is not set
+# CONFIG_ARCH_MVEBU is not set
+# CONFIG_ARCH_ALPINE is not set
+# CONFIG_ARCH_ARTPEC is not set
+# CONFIG_ARCH_AT91 is not set
+# CONFIG_ARCH_BCM is not set
+# CONFIG_ARCH_BERLIN is not set
+# CONFIG_ARCH_DIGICOLOR is not set
+# CONFIG_ARCH_HIGHBANK is not set
+# CONFIG_ARCH_HISI is not set
+CONFIG_ARCH_HISI_BVT=y
+
+#
+# Hisilicon BVT platform type
+#
+CONFIG_HI_ZRELADDR=0x80008000
+CONFIG_HI_PARAMS_PHYS=0x00000100
+CONFIG_HI_INITRD_PHYS=0x00800000
+CONFIG_ARCH_HI3516A=y
+# CONFIG_ARCH_HI3536DV100 is not set
+# CONFIG_ARCH_KEYSTONE is not set
+# CONFIG_ARCH_MESON is not set
+# CONFIG_ARCH_MXC is not set
+# CONFIG_ARCH_MEDIATEK is not set
+
+#
+# TI OMAP/AM/DM/DRA Family
+#
+# CONFIG_ARCH_OMAP3 is not set
+# CONFIG_ARCH_OMAP4 is not set
+# CONFIG_SOC_OMAP5 is not set
+# CONFIG_SOC_AM33XX is not set
+# CONFIG_SOC_AM43XX is not set
+# CONFIG_SOC_DRA7XX is not set
+# CONFIG_ARCH_MMP is not set
+# CONFIG_ARCH_QCOM is not set
+# CONFIG_ARCH_REALVIEW is not set
+# CONFIG_ARCH_ROCKCHIP is not set
+# CONFIG_ARCH_SOCFPGA is not set
+# CONFIG_PLAT_SPEAR is not set
+# CONFIG_ARCH_STI is not set
+# CONFIG_ARCH_S5PV210 is not set
+# CONFIG_ARCH_EXYNOS is not set
+# CONFIG_ARCH_RENESAS is not set
+# CONFIG_ARCH_SUNXI is not set
+# CONFIG_ARCH_SIRF is not set
+# CONFIG_ARCH_TANGO is not set
+# CONFIG_ARCH_TEGRA is not set
+# CONFIG_ARCH_UNIPHIER is not set
+# CONFIG_ARCH_U8500 is not set
+# CONFIG_ARCH_VEXPRESS is not set
+# CONFIG_ARCH_WM8850 is not set
+# CONFIG_ARCH_ZX is not set
+# CONFIG_ARCH_ZYNQ is not set
+
+#
+# Processor Type
+#
+CONFIG_CPU_V7=y
+CONFIG_CPU_32v6K=y
+CONFIG_CPU_32v7=y
+CONFIG_CPU_ABRT_EV7=y
+CONFIG_CPU_PABRT_V7=y
+CONFIG_CPU_CACHE_V7=y
+CONFIG_CPU_CACHE_VIPT=y
+CONFIG_CPU_COPY_V6=y
+CONFIG_CPU_TLB_V7=y
+CONFIG_CPU_HAS_ASID=y
+CONFIG_CPU_CP15=y
+CONFIG_CPU_CP15_MMU=y
+
+#
+# Processor Features
+#
+# CONFIG_ARM_LPAE is not set
+# CONFIG_ARCH_PHYS_ADDR_T_64BIT is not set
+CONFIG_ARM_THUMB=y
+# CONFIG_ARM_THUMBEE is not set
+CONFIG_ARM_VIRT_EXT=y
+# CONFIG_SWP_EMULATE is not set
+# CONFIG_CPU_ICACHE_DISABLE is not set
+# CONFIG_CPU_DCACHE_DISABLE is not set
+# CONFIG_CPU_BPREDICT_DISABLE is not set
+CONFIG_KUSER_HELPERS=y
+CONFIG_VDSO=y
+CONFIG_MIGHT_HAVE_CACHE_L2X0=y
+# CONFIG_CACHE_L2X0 is not set
+CONFIG_ARM_L1_CACHE_SHIFT_6=y
+CONFIG_ARM_L1_CACHE_SHIFT=6
+CONFIG_ARM_DMA_MEM_BUFFERABLE=y
+# CONFIG_DEBUG_RODATA is not set
+CONFIG_MULTI_IRQ_HANDLER=y
+# CONFIG_ARM_ERRATA_430973 is not set
+# CONFIG_ARM_ERRATA_720789 is not set
+# CONFIG_ARM_ERRATA_754322 is not set
+# CONFIG_ARM_ERRATA_775420 is not set
+# CONFIG_ARM_ERRATA_773022 is not set
+# CONFIG_ARM_ERRATA_818325_852422 is not set
+# CONFIG_ARM_ERRATA_821420 is not set
+# CONFIG_ARM_ERRATA_825619 is not set
+# CONFIG_ARM_ERRATA_852421 is not set
+# CONFIG_ARM_ERRATA_852423 is not set
+
+#
+# Bus support
+#
+# CONFIG_PCI is not set
+# CONFIG_PCI_DOMAINS_GENERIC is not set
+# CONFIG_PCI_SYSCALL is not set
+# CONFIG_PCCARD is not set
+
+#
+# Kernel Features
+#
+CONFIG_HAVE_SMP=y
+# CONFIG_SMP is not set
+CONFIG_HAVE_ARM_ARCH_TIMER=y
+CONFIG_VMSPLIT_3G=y
+# CONFIG_VMSPLIT_3G_OPT is not set
+# CONFIG_VMSPLIT_2G is not set
+# CONFIG_VMSPLIT_1G is not set
+CONFIG_PAGE_OFFSET=0xC0000000
+# CONFIG_ARM_PSCI is not set
+CONFIG_ARCH_NR_GPIO=0
+CONFIG_PREEMPT_NONE=y
+# CONFIG_PREEMPT_VOLUNTARY is not set
+# CONFIG_PREEMPT is not set
+CONFIG_HZ_FIXED=0
+CONFIG_HZ_100=y
+# CONFIG_HZ_200 is not set
+# CONFIG_HZ_250 is not set
+# CONFIG_HZ_300 is not set
+# CONFIG_HZ_500 is not set
+# CONFIG_HZ_1000 is not set
+CONFIG_HZ=100
+# CONFIG_SCHED_HRTICK is not set
+# CONFIG_THUMB2_KERNEL is not set
+CONFIG_ARM_PATCH_IDIV=y
+CONFIG_AEABI=y
+# CONFIG_OABI_COMPAT is not set
+# CONFIG_ARCH_SPARSEMEM_DEFAULT is not set
+# CONFIG_ARCH_SELECT_MEMORY_MODEL is not set
+CONFIG_HAVE_ARCH_PFN_VALID=y
+# CONFIG_HIGHMEM is not set
+# CONFIG_CPU_SW_DOMAIN_PAN is not set
+CONFIG_ARCH_WANT_GENERAL_HUGETLB=y
+# CONFIG_ARM_MODULE_PLTS is not set
+CONFIG_FLATMEM=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+CONFIG_HAVE_MEMBLOCK=y
+CONFIG_NO_BOOTMEM=y
+# CONFIG_HAVE_BOOTMEM_INFO_NODE is not set
+CONFIG_SPLIT_PTLOCK_CPUS=4
+CONFIG_COMPACTION=y
+CONFIG_MIGRATION=y
+# CONFIG_PHYS_ADDR_T_64BIT is not set
+# CONFIG_KSM is not set
+CONFIG_DEFAULT_MMAP_MIN_ADDR=4096
+CONFIG_NEED_PER_CPU_KM=y
+# CONFIG_CLEANCACHE is not set
+# CONFIG_FRONTSWAP is not set
+# CONFIG_CMA is not set
+# CONFIG_ZPOOL is not set
+# CONFIG_ZBUD is not set
+# CONFIG_ZSMALLOC is not set
+CONFIG_GENERIC_EARLY_IOREMAP=y
+# CONFIG_IDLE_PAGE_TRACKING is not set
+CONFIG_FORCE_MAX_ZONEORDER=11
+CONFIG_ALIGNMENT_TRAP=y
+# CONFIG_UACCESS_WITH_MEMCPY is not set
+# CONFIG_SECCOMP is not set
+CONFIG_SWIOTLB=y
+CONFIG_IOMMU_HELPER=y
+# CONFIG_PARAVIRT is not set
+# CONFIG_PARAVIRT_TIME_ACCOUNTING is not set
+# CONFIG_XEN is not set
+
+#
+# Boot options
+#
+CONFIG_USE_OF=y
+CONFIG_ATAGS=y
+# CONFIG_DEPRECATED_PARAM_STRUCT is not set
+CONFIG_ZBOOT_ROM_TEXT=0
+CONFIG_ZBOOT_ROM_BSS=0
+CONFIG_ARM_APPENDED_DTB=y
+CONFIG_ARM_ATAG_DTB_COMPAT=y
+CONFIG_ARM_ATAG_DTB_COMPAT_CMDLINE_FROM_BOOTLOADER=y
+# CONFIG_ARM_ATAG_DTB_COMPAT_CMDLINE_EXTEND is not set
+CONFIG_CMDLINE=""
+# CONFIG_KEXEC is not set
+# CONFIG_CRASH_DUMP is not set
+CONFIG_AUTO_ZRELADDR=y
+# CONFIG_EFI is not set
+
+#
+# CPU Power Management
+#
+
+#
+# CPU Frequency scaling
+#
+CONFIG_CPU_FREQ=y
+CONFIG_CPU_FREQ_GOV_ATTR_SET=y
+CONFIG_CPU_FREQ_GOV_COMMON=y
+CONFIG_CPU_FREQ_STAT=y
+# CONFIG_CPU_FREQ_STAT_DETAILS is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_PERFORMANCE is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_POWERSAVE is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_USERSPACE is not set
+CONFIG_CPU_FREQ_DEFAULT_GOV_ONDEMAND=y
+# CONFIG_CPU_FREQ_DEFAULT_GOV_CONSERVATIVE is not set
+CONFIG_CPU_FREQ_GOV_PERFORMANCE=y
+# CONFIG_CPU_FREQ_GOV_POWERSAVE is not set
+CONFIG_CPU_FREQ_GOV_USERSPACE=y
+CONFIG_CPU_FREQ_GOV_ONDEMAND=y
+# CONFIG_CPU_FREQ_GOV_CONSERVATIVE is not set
+
+#
+# CPU frequency scaling drivers
+#
+CONFIG_CPUFREQ_DT=y
+CONFIG_CPUFREQ_DT_PLATDEV=y
+# CONFIG_ARM_KIRKWOOD_CPUFREQ is not set
+# CONFIG_QORIQ_CPUFREQ is not set
+
+#
+# CPU Idle
+#
+# CONFIG_CPU_IDLE is not set
+# CONFIG_ARCH_NEEDS_CPU_IDLE_COUPLED is not set
+
+#
+# Floating point emulation
+#
+
+#
+# At least one emulation must be selected
+#
+CONFIG_VFP=y
+CONFIG_VFPv3=y
+CONFIG_NEON=y
+# CONFIG_KERNEL_MODE_NEON is not set
+
+#
+# Userspace binary formats
+#
+CONFIG_BINFMT_ELF=y
+CONFIG_ELFCORE=y
+CONFIG_CORE_DUMP_DEFAULT_ELF_HEADERS=y
+CONFIG_BINFMT_SCRIPT=y
+# CONFIG_BINFMT_FLAT is not set
+# CONFIG_HAVE_AOUT is not set
+# CONFIG_BINFMT_MISC is not set
+CONFIG_COREDUMP=y
+
+#
+# Power management options
+#
+CONFIG_SUSPEND=y
+CONFIG_SUSPEND_FREEZER=y
+CONFIG_HIBERNATE_CALLBACKS=y
+CONFIG_HIBERNATION=y
+CONFIG_PM_STD_PARTITION=""
+CONFIG_PM_SLEEP=y
+# CONFIG_PM_AUTOSLEEP is not set
+# CONFIG_PM_WAKELOCKS is not set
+CONFIG_PM=y
+CONFIG_PM_DEBUG=y
+# CONFIG_PM_ADVANCED_DEBUG is not set
+CONFIG_PM_SLEEP_DEBUG=y
+# CONFIG_APM_EMULATION is not set
+CONFIG_PM_OPP=y
+CONFIG_PM_CLK=y
+# CONFIG_WQ_POWER_EFFICIENT_DEFAULT is not set
+CONFIG_CPU_PM=y
+CONFIG_ARCH_SUSPEND_POSSIBLE=y
+CONFIG_ARM_CPU_SUSPEND=y
+CONFIG_ARCH_HIBERNATION_POSSIBLE=y
+CONFIG_NET=y
+
+#
+# Networking options
+#
+CONFIG_PACKET=y
+# CONFIG_PACKET_DIAG is not set
+CONFIG_UNIX=y
+# CONFIG_UNIX_DIAG is not set
+CONFIG_XFRM=y
+CONFIG_XFRM_ALGO=y
+CONFIG_XFRM_USER=y
+# CONFIG_XFRM_SUB_POLICY is not set
+# CONFIG_XFRM_MIGRATE is not set
+# CONFIG_XFRM_STATISTICS is not set
+CONFIG_NET_KEY=y
+# CONFIG_NET_KEY_MIGRATE is not set
+CONFIG_INET=y
+CONFIG_IP_MULTICAST=y
+CONFIG_IP_ADVANCED_ROUTER=y
+# CONFIG_IP_FIB_TRIE_STATS is not set
+CONFIG_IP_MULTIPLE_TABLES=y
+CONFIG_IP_ROUTE_MULTIPATH=y
+CONFIG_IP_ROUTE_VERBOSE=y
+CONFIG_IP_PNP=y
+# CONFIG_IP_PNP_DHCP is not set
+# CONFIG_IP_PNP_BOOTP is not set
+# CONFIG_IP_PNP_RARP is not set
+# CONFIG_NET_IPIP is not set
+# CONFIG_NET_IPGRE_DEMUX is not set
+# CONFIG_NET_IP_TUNNEL is not set
+CONFIG_IP_MROUTE=y
+# CONFIG_IP_MROUTE_MULTIPLE_TABLES is not set
+CONFIG_IP_PIMSM_V1=y
+CONFIG_IP_PIMSM_V2=y
+CONFIG_SYN_COOKIES=y
+# CONFIG_NET_UDP_TUNNEL is not set
+# CONFIG_NET_FOU is not set
+# CONFIG_INET_AH is not set
+# CONFIG_INET_ESP is not set
+# CONFIG_INET_IPCOMP is not set
+# CONFIG_INET_XFRM_TUNNEL is not set
+# CONFIG_INET_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_TRANSPORT is not set
+# CONFIG_INET_XFRM_MODE_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_BEET is not set
+CONFIG_INET_DIAG=y
+CONFIG_INET_TCP_DIAG=y
+# CONFIG_INET_UDP_DIAG is not set
+# CONFIG_INET_DIAG_DESTROY is not set
+CONFIG_TCP_CONG_ADVANCED=y
+CONFIG_TCP_CONG_BIC=m
+CONFIG_TCP_CONG_CUBIC=y
+CONFIG_TCP_CONG_WESTWOOD=m
+CONFIG_TCP_CONG_HTCP=m
+# CONFIG_TCP_CONG_HSTCP is not set
+# CONFIG_TCP_CONG_HYBLA is not set
+# CONFIG_TCP_CONG_VEGAS is not set
+# CONFIG_TCP_CONG_NV is not set
+# CONFIG_TCP_CONG_SCALABLE is not set
+# CONFIG_TCP_CONG_LP is not set
+# CONFIG_TCP_CONG_VENO is not set
+# CONFIG_TCP_CONG_YEAH is not set
+# CONFIG_TCP_CONG_ILLINOIS is not set
+# CONFIG_TCP_CONG_DCTCP is not set
+# CONFIG_TCP_CONG_CDG is not set
+# CONFIG_TCP_CONG_BBR is not set
+CONFIG_DEFAULT_CUBIC=y
+# CONFIG_DEFAULT_RENO is not set
+CONFIG_DEFAULT_TCP_CONG="cubic"
+CONFIG_TCP_MD5SIG=y
+# CONFIG_IPV6 is not set
+# CONFIG_NETWORK_SECMARK is not set
+# CONFIG_NET_PTP_CLASSIFY is not set
+# CONFIG_NETWORK_PHY_TIMESTAMPING is not set
+# CONFIG_NETFILTER is not set
+# CONFIG_IP_DCCP is not set
+# CONFIG_IP_SCTP is not set
+# CONFIG_RDS is not set
+# CONFIG_TIPC is not set
+# CONFIG_ATM is not set
+# CONFIG_L2TP is not set
+# CONFIG_BRIDGE is not set
+CONFIG_HAVE_NET_DSA=y
+# CONFIG_VLAN_8021Q is not set
+# CONFIG_DECNET is not set
+# CONFIG_LLC2 is not set
+# CONFIG_IPX is not set
+# CONFIG_ATALK is not set
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_PHONET is not set
+# CONFIG_IEEE802154 is not set
+# CONFIG_NET_SCHED is not set
+# CONFIG_DCB is not set
+CONFIG_DNS_RESOLVER=y
+# CONFIG_BATMAN_ADV is not set
+# CONFIG_OPENVSWITCH is not set
+# CONFIG_VSOCKETS is not set
+# CONFIG_NETLINK_DIAG is not set
+# CONFIG_MPLS is not set
+# CONFIG_HSR is not set
+# CONFIG_NET_SWITCHDEV is not set
+# CONFIG_NET_L3_MASTER_DEV is not set
+# CONFIG_NET_NCSI is not set
+# CONFIG_SOCK_CGROUP_DATA is not set
+# CONFIG_CGROUP_NET_PRIO is not set
+# CONFIG_CGROUP_NET_CLASSID is not set
+CONFIG_NET_RX_BUSY_POLL=y
+CONFIG_BQL=y
+# CONFIG_BPF_JIT is not set
+
+#
+# Network testing
+#
+# CONFIG_NET_PKTGEN is not set
+# CONFIG_HAMRADIO is not set
+# CONFIG_CAN is not set
+# CONFIG_IRDA is not set
+# CONFIG_BT is not set
+# CONFIG_AF_RXRPC is not set
+# CONFIG_AF_KCM is not set
+# CONFIG_STREAM_PARSER is not set
+CONFIG_FIB_RULES=y
+CONFIG_WIRELESS=y
+CONFIG_WEXT_CORE=y
+CONFIG_WEXT_PROC=y
+CONFIG_CFG80211=m
+# CONFIG_NL80211_TESTMODE is not set
+# CONFIG_CFG80211_DEVELOPER_WARNINGS is not set
+CONFIG_CFG80211_DEFAULT_PS=y
+# CONFIG_CFG80211_INTERNAL_REGDB is not set
+CONFIG_CFG80211_CRDA_SUPPORT=y
+CONFIG_CFG80211_WEXT=y
+# CONFIG_LIB80211 is not set
+CONFIG_MAC80211=m
+CONFIG_MAC80211_HAS_RC=y
+CONFIG_MAC80211_RC_MINSTREL=y
+CONFIG_MAC80211_RC_MINSTREL_HT=y
+# CONFIG_MAC80211_RC_MINSTREL_VHT is not set
+CONFIG_MAC80211_RC_DEFAULT_MINSTREL=y
+CONFIG_MAC80211_RC_DEFAULT="minstrel_ht"
+CONFIG_MAC80211_MESH=y
+# CONFIG_MAC80211_MESSAGE_TRACING is not set
+# CONFIG_MAC80211_DEBUG_MENU is not set
+CONFIG_MAC80211_STA_HASH_MAX_SIZE=0
+# CONFIG_WIMAX is not set
+# CONFIG_RFKILL is not set
+# CONFIG_RFKILL_REGULATOR is not set
+# CONFIG_NET_9P is not set
+# CONFIG_CAIF is not set
+# CONFIG_CEPH_LIB is not set
+# CONFIG_NFC is not set
+# CONFIG_LWTUNNEL is not set
+# CONFIG_DST_CACHE is not set
+# CONFIG_NET_DEVLINK is not set
+CONFIG_MAY_USE_DEVLINK=y
+CONFIG_HAVE_CBPF_JIT=y
+
+#
+# Device Drivers
+#
+CONFIG_ARM_AMBA=y
+
+#
+# Generic Driver Options
+#
+# CONFIG_UEVENT_HELPER is not set
+CONFIG_DEVTMPFS=y
+# CONFIG_DEVTMPFS_MOUNT is not set
+CONFIG_STANDALONE=y
+# CONFIG_PREVENT_FIRMWARE_BUILD is not set
+CONFIG_FW_LOADER=y
+CONFIG_FIRMWARE_IN_KERNEL=y
+CONFIG_EXTRA_FIRMWARE=""
+# CONFIG_FW_LOADER_USER_HELPER_FALLBACK is not set
+CONFIG_ALLOW_DEV_COREDUMP=y
+# CONFIG_DEBUG_DRIVER is not set
+# CONFIG_DEBUG_DEVRES is not set
+# CONFIG_DEBUG_TEST_DRIVER_REMOVE is not set
+# CONFIG_SYS_HYPERVISOR is not set
+# CONFIG_GENERIC_CPU_DEVICES is not set
+# CONFIG_DMA_SHARED_BUFFER is not set
+
+#
+# Bus devices
+#
+# CONFIG_BRCMSTB_GISB_ARB is not set
+# CONFIG_VEXPRESS_CONFIG is not set
+# CONFIG_CONNECTOR is not set
+CONFIG_MTD=y
+# CONFIG_MTD_TESTS is not set
+# CONFIG_MTD_REDBOOT_PARTS is not set
+CONFIG_MTD_CMDLINE_PARTS=y
+# CONFIG_MTD_AFS_PARTS is not set
+CONFIG_MTD_OF_PARTS=y
+# CONFIG_MTD_AR7_PARTS is not set
+
+#
+# User Modules And Translation Layers
+#
+CONFIG_MTD_BLKDEVS=y
+CONFIG_MTD_BLOCK=y
+# CONFIG_FTL is not set
+# CONFIG_NFTL is not set
+# CONFIG_INFTL is not set
+# CONFIG_RFD_FTL is not set
+# CONFIG_SSFDC is not set
+# CONFIG_SM_FTL is not set
+# CONFIG_MTD_OOPS is not set
+# CONFIG_MTD_SWAP is not set
+# CONFIG_MTD_PARTITIONED_MASTER is not set
+
+#
+# RAM/ROM/Flash chip drivers
+#
+# CONFIG_MTD_CFI is not set
+# CONFIG_MTD_JEDECPROBE is not set
+CONFIG_MTD_MAP_BANK_WIDTH_1=y
+CONFIG_MTD_MAP_BANK_WIDTH_2=y
+CONFIG_MTD_MAP_BANK_WIDTH_4=y
+# CONFIG_MTD_MAP_BANK_WIDTH_8 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_16 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_32 is not set
+CONFIG_MTD_CFI_I1=y
+CONFIG_MTD_CFI_I2=y
+# CONFIG_MTD_CFI_I4 is not set
+# CONFIG_MTD_CFI_I8 is not set
+# CONFIG_MTD_RAM is not set
+# CONFIG_MTD_ROM is not set
+# CONFIG_MTD_ABSENT is not set
+
+#
+# Mapping drivers for chip access
+#
+# CONFIG_MTD_COMPLEX_MAPPINGS is not set
+# CONFIG_MTD_PLATRAM is not set
+
+#
+# Self-contained MTD device drivers
+#
+# CONFIG_MTD_DATAFLASH is not set
+# CONFIG_MTD_M25P80 is not set
+# CONFIG_MTD_SST25L is not set
+# CONFIG_MTD_SLRAM is not set
+# CONFIG_MTD_PHRAM is not set
+# CONFIG_MTD_MTDRAM is not set
+# CONFIG_MTD_BLOCK2MTD is not set
+
+#
+# Disk-On-Chip Device Drivers
+#
+# CONFIG_MTD_DOCG3 is not set
+CONFIG_MTD_NAND_ECC=y
+# CONFIG_MTD_NAND_ECC_SMC is not set
+CONFIG_MTD_NAND=y
+# CONFIG_MTD_NAND_ECC_BCH is not set
+# CONFIG_MTD_SM_COMMON is not set
+# CONFIG_MTD_NAND_DENALI_DT is not set
+# CONFIG_MTD_NAND_GPIO is not set
+# CONFIG_MTD_NAND_OMAP_BCH_BUILD is not set
+CONFIG_MTD_NAND_IDS=y
+# CONFIG_MTD_NAND_DISKONCHIP is not set
+# CONFIG_MTD_NAND_DOCG4 is not set
+# CONFIG_MTD_NAND_NANDSIM is not set
+# CONFIG_MTD_NAND_BRCMNAND is not set
+# CONFIG_MTD_NAND_PLATFORM is not set
+# CONFIG_MTD_NAND_HISI504 is not set
+# CONFIG_MTD_NAND_MTK is not set
+# CONFIG_MTD_SPI_NAND_HISI_BVT is not set
+CONFIG_MTD_NAND_HINFC610=y
+CONFIG_HINFC610_MAX_CHIP=1
+CONFIG_HINFC610_DBG_NAND_DEBUG=y
+CONFIG_HINFC610_DBG_NAND_DUMP=y
+CONFIG_HINFC610_DBG_NAND_ERASE_COUNT=y
+CONFIG_HINFC610_DBG_NAND_ECC_COUNT=y
+CONFIG_HINFC610_DBG_NAND_READ_RETRY=y
+CONFIG_HINFC610_AUTO_PAGESIZE_ECC=y
+# CONFIG_HINFC610_PAGESIZE_AUTO_ECC_NONE is not set
+# CONFIG_MTD_ONENAND is not set
+
+#
+# LPDDR & LPDDR2 PCM memory drivers
+#
+# CONFIG_MTD_LPDDR is not set
+# CONFIG_MTD_LPDDR2_NVM is not set
+CONFIG_MTD_SPI_NOR=y
+# CONFIG_MTD_MT81xx_NOR is not set
+# CONFIG_MTD_SPI_NOR_USE_4K_SECTORS is not set
+# CONFIG_SPI_CADENCE_QUADSPI is not set
+# CONFIG_SPI_HISI_SFC is not set
+CONFIG_MTD_SPI_IDS=y
+CONFIG_CLOSE_SPI_8PIN_4IO=y
+CONFIG_MTD_HISFC350=y
+CONFIG_HISFC350_SYSCTRL_ADDRESS=0x20030000
+CONFIG_HISFC350_CHIP_NUM=2
+# CONFIG_HISFC350_SHOW_CYCLE_TIMING is not set
+# CONFIG_HISFC350_ENABLE_CHIPSELECT_0 is not set
+CONFIG_HISFC350_ENABLE_CHIPSELECT_1=y
+# CONFIG_HISFC350_ENABLE_INTR_DMA is not set
+CONFIG_CMD_SPI_BLOCK_PROTECTION=y
+CONFIG_MTD_UBI=y
+CONFIG_MTD_UBI_WL_THRESHOLD=4096
+CONFIG_MTD_UBI_BEB_LIMIT=20
+# CONFIG_MTD_UBI_FASTMAP is not set
+# CONFIG_MTD_UBI_GLUEBI is not set
+# CONFIG_MTD_UBI_BLOCK is not set
+CONFIG_DTC=y
+CONFIG_OF=y
+# CONFIG_OF_UNITTEST is not set
+CONFIG_OF_FLATTREE=y
+CONFIG_OF_EARLY_FLATTREE=y
+CONFIG_OF_ADDRESS=y
+CONFIG_OF_IRQ=y
+CONFIG_OF_NET=y
+CONFIG_OF_MDIO=y
+CONFIG_OF_RESERVED_MEM=y
+# CONFIG_OF_OVERLAY is not set
+CONFIG_ARCH_MIGHT_HAVE_PC_PARPORT=y
+# CONFIG_PARPORT is not set
+CONFIG_BLK_DEV=y
+# CONFIG_BLK_DEV_NULL_BLK is not set
+# CONFIG_BLK_DEV_COW_COMMON is not set
+# CONFIG_BLK_DEV_LOOP is not set
+# CONFIG_BLK_DEV_DRBD is not set
+# CONFIG_BLK_DEV_NBD is not set
+CONFIG_BLK_DEV_RAM=y
+CONFIG_BLK_DEV_RAM_COUNT=16
+CONFIG_BLK_DEV_RAM_SIZE=65536
+# CONFIG_CDROM_PKTCDVD is not set
+# CONFIG_ATA_OVER_ETH is not set
+# CONFIG_MG_DISK is not set
+# CONFIG_BLK_DEV_RBD is not set
+# CONFIG_NVME_TARGET is not set
+
+#
+# Misc devices
+#
+# CONFIG_SENSORS_LIS3LV02D is not set
+# CONFIG_AD525X_DPOT is not set
+# CONFIG_DUMMY_IRQ is not set
+# CONFIG_ICS932S401 is not set
+# CONFIG_ENCLOSURE_SERVICES is not set
+# CONFIG_APDS9802ALS is not set
+# CONFIG_ISL29003 is not set
+# CONFIG_ISL29020 is not set
+# CONFIG_SENSORS_TSL2550 is not set
+# CONFIG_SENSORS_BH1770 is not set
+# CONFIG_SENSORS_APDS990X is not set
+# CONFIG_HMC6352 is not set
+# CONFIG_DS1682 is not set
+# CONFIG_TI_DAC7512 is not set
+# CONFIG_USB_SWITCH_FSA9480 is not set
+# CONFIG_LATTICE_ECP3_CONFIG is not set
+# CONFIG_SRAM is not set
+# CONFIG_C2PORT is not set
+
+#
+# EEPROM support
+#
+# CONFIG_EEPROM_AT24 is not set
+# CONFIG_EEPROM_AT25 is not set
+# CONFIG_EEPROM_LEGACY is not set
+# CONFIG_EEPROM_MAX6875 is not set
+# CONFIG_EEPROM_93CX6 is not set
+# CONFIG_EEPROM_93XX46 is not set
+
+#
+# Texas Instruments shared transport line discipline
+#
+# CONFIG_TI_ST is not set
+# CONFIG_SENSORS_LIS3_SPI is not set
+# CONFIG_SENSORS_LIS3_I2C is not set
+
+#
+# Altera FPGA firmware download module
+#
+# CONFIG_ALTERA_STAPL is not set
+
+#
+# Intel MIC Bus Driver
+#
+
+#
+# SCIF Bus Driver
+#
+
+#
+# VOP Bus Driver
+#
+
+#
+# Intel MIC Host Driver
+#
+
+#
+# Intel MIC Card Driver
+#
+
+#
+# SCIF Driver
+#
+
+#
+# Intel MIC Coprocessor State Management (COSM) Drivers
+#
+
+#
+# VOP Driver
+#
+# CONFIG_ECHO is not set
+# CONFIG_CXL_BASE is not set
+# CONFIG_CXL_AFU_DRIVER_OPS is not set
+
+#
+# SCSI device support
+#
+CONFIG_SCSI_MOD=y
+# CONFIG_RAID_ATTRS is not set
+CONFIG_SCSI=y
+CONFIG_SCSI_DMA=y
+CONFIG_SCSI_NETLINK=y
+# CONFIG_SCSI_MQ_DEFAULT is not set
+CONFIG_SCSI_PROC_FS=y
+
+#
+# SCSI support type (disk, tape, CD-ROM)
+#
+CONFIG_BLK_DEV_SD=y
+# CONFIG_CHR_DEV_ST is not set
+# CONFIG_CHR_DEV_OSST is not set
+# CONFIG_BLK_DEV_SR is not set
+# CONFIG_CHR_DEV_SG is not set
+# CONFIG_CHR_DEV_SCH is not set
+# CONFIG_SCSI_CONSTANTS is not set
+# CONFIG_SCSI_LOGGING is not set
+# CONFIG_SCSI_SCAN_ASYNC is not set
+
+#
+# SCSI Transports
+#
+# CONFIG_SCSI_SPI_ATTRS is not set
+CONFIG_SCSI_FC_ATTRS=y
+# CONFIG_SCSI_ISCSI_ATTRS is not set
+# CONFIG_SCSI_SAS_ATTRS is not set
+# CONFIG_SCSI_SAS_LIBSAS is not set
+# CONFIG_SCSI_SRP_ATTRS is not set
+CONFIG_SCSI_LOWLEVEL=y
+# CONFIG_ISCSI_TCP is not set
+# CONFIG_ISCSI_BOOT_SYSFS is not set
+# CONFIG_SCSI_UFSHCD is not set
+# CONFIG_LIBFC is not set
+# CONFIG_SCSI_DEBUG is not set
+# CONFIG_SCSI_DH is not set
+# CONFIG_SCSI_OSD_INITIATOR is not set
+# CONFIG_ATA is not set
+# CONFIG_MD is not set
+# CONFIG_TARGET_CORE is not set
+CONFIG_NETDEVICES=y
+CONFIG_NET_CORE=y
+# CONFIG_BONDING is not set
+# CONFIG_DUMMY is not set
+# CONFIG_EQUALIZER is not set
+# CONFIG_NET_TEAM is not set
+# CONFIG_MACVLAN is not set
+# CONFIG_VXLAN is not set
+# CONFIG_MACSEC is not set
+# CONFIG_NETCONSOLE is not set
+# CONFIG_NETPOLL is not set
+# CONFIG_NET_POLL_CONTROLLER is not set
+# CONFIG_TUN is not set
+# CONFIG_TUN_VNET_CROSS_LE is not set
+# CONFIG_VETH is not set
+# CONFIG_NLMON is not set
+
+#
+# CAIF transport drivers
+#
+
+#
+# Distributed Switch Architecture drivers
+#
+CONFIG_ETHERNET=y
+# CONFIG_ALTERA_TSE is not set
+# CONFIG_NET_VENDOR_AMAZON is not set
+# CONFIG_NET_VENDOR_ARC is not set
+# CONFIG_NET_VENDOR_AURORA is not set
+# CONFIG_NET_CADENCE is not set
+# CONFIG_NET_VENDOR_BROADCOM is not set
+# CONFIG_NET_VENDOR_CIRRUS is not set
+# CONFIG_DM9000 is not set
+# CONFIG_DNET is not set
+# CONFIG_NET_VENDOR_EZCHIP is not set
+# CONFIG_NET_VENDOR_FARADAY is not set
+CONFIG_NET_VENDOR_HISILICON=y
+# CONFIG_HIX5HD2_GMAC is not set
+# CONFIG_HISI_FEMAC is not set
+# CONFIG_HIP04_ETH is not set
+# CONFIG_HNS is not set
+# CONFIG_HNS_DSAF is not set
+# CONFIG_HNS_ENET is not set
+CONFIG_HIETH_GMAC=y
+# CONFIG_HIGMAC_DESC_4WORD is not set
+# CONFIG_HIGMAC_RXCSUM is not set
+CONFIG_RX_FLOW_CTRL_SUPPORT=y
+CONFIG_TX_FLOW_CTRL_SUPPORT=y
+CONFIG_TX_FLOW_CTRL_PAUSE_TIME=0xFFFF
+CONFIG_TX_FLOW_CTRL_PAUSE_INTERVAL=0xFFFF
+CONFIG_TX_FLOW_CTRL_ACTIVE_THRESHOLD=16
+CONFIG_TX_FLOW_CTRL_DEACTIVE_THRESHOLD=32
+# CONFIG_NET_VENDOR_INTEL is not set
+# CONFIG_NET_VENDOR_MARVELL is not set
+# CONFIG_NET_VENDOR_MICREL is not set
+# CONFIG_NET_VENDOR_MICROCHIP is not set
+# CONFIG_NET_VENDOR_NATSEMI is not set
+# CONFIG_NET_VENDOR_NETRONOME is not set
+# CONFIG_ETHOC is not set
+# CONFIG_NET_VENDOR_QUALCOMM is not set
+# CONFIG_NET_VENDOR_RENESAS is not set
+# CONFIG_NET_VENDOR_ROCKER is not set
+# CONFIG_NET_VENDOR_SAMSUNG is not set
+# CONFIG_NET_VENDOR_SEEQ is not set
+# CONFIG_NET_VENDOR_SMSC is not set
+# CONFIG_NET_VENDOR_STMICRO is not set
+# CONFIG_NET_VENDOR_SYNOPSYS is not set
+# CONFIG_NET_VENDOR_VIA is not set
+# CONFIG_NET_VENDOR_WIZNET is not set
+CONFIG_PHYLIB=y
+CONFIG_SWPHY=y
+
+#
+# MDIO bus device drivers
+#
+# CONFIG_MDIO_BCM_UNIMAC is not set
+# CONFIG_MDIO_BITBANG is not set
+# CONFIG_MDIO_BUS_MUX_GPIO is not set
+# CONFIG_MDIO_BUS_MUX_MMIOREG is not set
+# CONFIG_MDIO_HISI_FEMAC is not set
+CONFIG_MDIO_HISI_GEMAC=y
+
+#
+# MII PHY device drivers
+#
+# CONFIG_AMD_PHY is not set
+# CONFIG_AQUANTIA_PHY is not set
+# CONFIG_AT803X_PHY is not set
+# CONFIG_BCM7XXX_PHY is not set
+# CONFIG_BCM87XX_PHY is not set
+# CONFIG_BROADCOM_PHY is not set
+# CONFIG_CICADA_PHY is not set
+# CONFIG_DAVICOM_PHY is not set
+# CONFIG_DP83848_PHY is not set
+# CONFIG_DP83867_PHY is not set
+CONFIG_FIXED_PHY=y
+# CONFIG_ICPLUS_PHY is not set
+# CONFIG_INTEL_XWAY_PHY is not set
+# CONFIG_LSI_ET1011C_PHY is not set
+# CONFIG_LXT_PHY is not set
+# CONFIG_MARVELL_PHY is not set
+# CONFIG_MICREL_PHY is not set
+# CONFIG_MICROCHIP_PHY is not set
+# CONFIG_MICROSEMI_PHY is not set
+# CONFIG_NATIONAL_PHY is not set
+# CONFIG_QSEMI_PHY is not set
+# CONFIG_REALTEK_PHY is not set
+# CONFIG_SMSC_PHY is not set
+# CONFIG_STE10XP is not set
+# CONFIG_TERANETICS_PHY is not set
+# CONFIG_VITESSE_PHY is not set
+# CONFIG_XILINX_GMII2RGMII is not set
+# CONFIG_MICREL_KS8995MA is not set
+# CONFIG_PPP is not set
+# CONFIG_SLIP is not set
+CONFIG_USB_NET_DRIVERS=y
+# CONFIG_USB_CATC is not set
+# CONFIG_USB_KAWETH is not set
+# CONFIG_USB_PEGASUS is not set
+# CONFIG_USB_RTL8150 is not set
+# CONFIG_USB_RTL8152 is not set
+# CONFIG_USB_LAN78XX is not set
+# CONFIG_USB_USBNET is not set
+# CONFIG_USB_IPHETH is not set
+# CONFIG_WLAN is not set
+
+#
+# Enable WiMAX (Networking options) to see the WiMAX drivers
+#
+# CONFIG_WAN is not set
+# CONFIG_ISDN is not set
+# CONFIG_NVM is not set
+
+#
+# Input device support
+#
+CONFIG_INPUT=y
+# CONFIG_INPUT_FF_MEMLESS is not set
+# CONFIG_INPUT_POLLDEV is not set
+# CONFIG_INPUT_SPARSEKMAP is not set
+# CONFIG_INPUT_MATRIXKMAP is not set
+
+#
+# Userland interfaces
+#
+CONFIG_INPUT_MOUSEDEV=y
+CONFIG_INPUT_MOUSEDEV_PSAUX=y
+CONFIG_INPUT_MOUSEDEV_SCREEN_X=1024
+CONFIG_INPUT_MOUSEDEV_SCREEN_Y=768
+# CONFIG_INPUT_JOYDEV is not set
+CONFIG_INPUT_EVDEV=y
+# CONFIG_INPUT_EVBUG is not set
+
+#
+# Input Device Drivers
+#
+CONFIG_INPUT_KEYBOARD=y
+# CONFIG_KEYBOARD_ADP5588 is not set
+# CONFIG_KEYBOARD_ADP5589 is not set
+CONFIG_KEYBOARD_ATKBD=y
+# CONFIG_KEYBOARD_QT1070 is not set
+# CONFIG_KEYBOARD_QT2160 is not set
+# CONFIG_KEYBOARD_LKKBD is not set
+# CONFIG_KEYBOARD_GPIO is not set
+# CONFIG_KEYBOARD_GPIO_POLLED is not set
+# CONFIG_KEYBOARD_TCA6416 is not set
+# CONFIG_KEYBOARD_TCA8418 is not set
+# CONFIG_KEYBOARD_MATRIX is not set
+# CONFIG_KEYBOARD_LM8333 is not set
+# CONFIG_KEYBOARD_MAX7359 is not set
+# CONFIG_KEYBOARD_MCS is not set
+# CONFIG_KEYBOARD_MPR121 is not set
+# CONFIG_KEYBOARD_NEWTON is not set
+# CONFIG_KEYBOARD_OPENCORES is not set
+# CONFIG_KEYBOARD_SAMSUNG is not set
+# CONFIG_KEYBOARD_STOWAWAY is not set
+# CONFIG_KEYBOARD_SUNKBD is not set
+# CONFIG_KEYBOARD_OMAP4 is not set
+# CONFIG_KEYBOARD_XTKBD is not set
+# CONFIG_KEYBOARD_CAP11XX is not set
+# CONFIG_KEYBOARD_BCM is not set
+CONFIG_INPUT_MOUSE=y
+CONFIG_MOUSE_PS2=y
+CONFIG_MOUSE_PS2_ALPS=y
+CONFIG_MOUSE_PS2_BYD=y
+CONFIG_MOUSE_PS2_LOGIPS2PP=y
+CONFIG_MOUSE_PS2_SYNAPTICS=y
+CONFIG_MOUSE_PS2_CYPRESS=y
+CONFIG_MOUSE_PS2_TRACKPOINT=y
+# CONFIG_MOUSE_PS2_ELANTECH is not set
+# CONFIG_MOUSE_PS2_SENTELIC is not set
+# CONFIG_MOUSE_PS2_TOUCHKIT is not set
+CONFIG_MOUSE_PS2_FOCALTECH=y
+# CONFIG_MOUSE_SERIAL is not set
+# CONFIG_MOUSE_APPLETOUCH is not set
+# CONFIG_MOUSE_BCM5974 is not set
+# CONFIG_MOUSE_CYAPA is not set
+# CONFIG_MOUSE_ELAN_I2C is not set
+# CONFIG_MOUSE_VSXXXAA is not set
+# CONFIG_MOUSE_GPIO is not set
+# CONFIG_MOUSE_SYNAPTICS_I2C is not set
+# CONFIG_MOUSE_SYNAPTICS_USB is not set
+# CONFIG_INPUT_JOYSTICK is not set
+# CONFIG_INPUT_TABLET is not set
+# CONFIG_INPUT_TOUCHSCREEN is not set
+CONFIG_INPUT_MISC=y
+# CONFIG_INPUT_AD714X is not set
+# CONFIG_INPUT_ATMEL_CAPTOUCH is not set
+# CONFIG_INPUT_BMA150 is not set
+# CONFIG_INPUT_E3X0_BUTTON is not set
+# CONFIG_INPUT_MMA8450 is not set
+# CONFIG_INPUT_MPU3050 is not set
+# CONFIG_INPUT_GP2A is not set
+# CONFIG_INPUT_GPIO_BEEPER is not set
+# CONFIG_INPUT_GPIO_TILT_POLLED is not set
+# CONFIG_INPUT_GPIO_DECODER is not set
+# CONFIG_INPUT_ATI_REMOTE2 is not set
+# CONFIG_INPUT_KEYSPAN_REMOTE is not set
+# CONFIG_INPUT_KXTJ9 is not set
+# CONFIG_INPUT_POWERMATE is not set
+# CONFIG_INPUT_YEALINK is not set
+# CONFIG_INPUT_CM109 is not set
+# CONFIG_INPUT_REGULATOR_HAPTIC is not set
+CONFIG_INPUT_UINPUT=y
+# CONFIG_INPUT_PCF8574 is not set
+# CONFIG_INPUT_GPIO_ROTARY_ENCODER is not set
+# CONFIG_INPUT_ADXL34X is not set
+# CONFIG_INPUT_CMA3000 is not set
+# CONFIG_INPUT_DRV260X_HAPTICS is not set
+# CONFIG_INPUT_DRV2665_HAPTICS is not set
+# CONFIG_INPUT_DRV2667_HAPTICS is not set
+# CONFIG_RMI4_CORE is not set
+
+#
+# Hardware I/O ports
+#
+CONFIG_SERIO=y
+CONFIG_SERIO_SERPORT=y
+# CONFIG_SERIO_AMBAKMI is not set
+CONFIG_SERIO_LIBPS2=y
+# CONFIG_SERIO_RAW is not set
+# CONFIG_SERIO_ALTERA_PS2 is not set
+# CONFIG_SERIO_PS2MULT is not set
+# CONFIG_SERIO_ARC_PS2 is not set
+# CONFIG_SERIO_APBPS2 is not set
+# CONFIG_USERIO is not set
+# CONFIG_GAMEPORT is not set
+
+#
+# Character devices
+#
+CONFIG_TTY=y
+CONFIG_VT=y
+CONFIG_CONSOLE_TRANSLATIONS=y
+CONFIG_VT_CONSOLE=y
+CONFIG_VT_CONSOLE_SLEEP=y
+CONFIG_HW_CONSOLE=y
+# CONFIG_VT_HW_CONSOLE_BINDING is not set
+CONFIG_UNIX98_PTYS=y
+# CONFIG_LEGACY_PTYS is not set
+# CONFIG_SERIAL_NONSTANDARD is not set
+# CONFIG_N_GSM is not set
+# CONFIG_TRACE_SINK is not set
+CONFIG_DEVMEM=y
+# CONFIG_DEVKMEM is not set
+
+#
+# Serial drivers
+#
+CONFIG_SERIAL_EARLYCON=y
+# CONFIG_SERIAL_8250 is not set
+
+#
+# Non-8250 serial port support
+#
+# CONFIG_SERIAL_AMBA_PL010 is not set
+CONFIG_SERIAL_AMBA_PL011=y
+CONFIG_SERIAL_AMBA_PL011_CONSOLE=y
+# CONFIG_SERIAL_EARLYCON_ARM_SEMIHOST is not set
+# CONFIG_SERIAL_MAX3100 is not set
+# CONFIG_SERIAL_MAX310X is not set
+# CONFIG_SERIAL_UARTLITE is not set
+CONFIG_SERIAL_CORE=y
+CONFIG_SERIAL_CORE_CONSOLE=y
+# CONFIG_SERIAL_SCCNXP is not set
+# CONFIG_SERIAL_SC16IS7XX is not set
+# CONFIG_SERIAL_BCM63XX is not set
+# CONFIG_SERIAL_ALTERA_JTAGUART is not set
+# CONFIG_SERIAL_ALTERA_UART is not set
+# CONFIG_SERIAL_IFX6X60 is not set
+# CONFIG_SERIAL_XILINX_PS_UART is not set
+# CONFIG_SERIAL_ARC is not set
+# CONFIG_SERIAL_FSL_LPUART is not set
+# CONFIG_SERIAL_CONEXANT_DIGICOLOR is not set
+# CONFIG_SERIAL_ST_ASC is not set
+# CONFIG_SERIAL_STM32 is not set
+# CONFIG_HVC_DCC is not set
+# CONFIG_IPMI_HANDLER is not set
+# CONFIG_HW_RANDOM is not set
+# CONFIG_R3964 is not set
+# CONFIG_RAW_DRIVER is not set
+# CONFIG_TCG_TPM is not set
+# CONFIG_XILLYBUS is not set
+
+#
+# I2C support
+#
+CONFIG_I2C=y
+CONFIG_I2C_BOARDINFO=y
+CONFIG_I2C_COMPAT=y
+CONFIG_I2C_CHARDEV=y
+# CONFIG_I2C_MUX is not set
+CONFIG_I2C_HELPER_AUTO=y
+
+#
+# I2C Hardware Bus support
+#
+
+#
+# I2C system bus drivers (mostly embedded / system-on-chip)
+#
+# CONFIG_I2C_CBUS_GPIO is not set
+# CONFIG_I2C_DESIGNWARE_PLATFORM is not set
+# CONFIG_I2C_EMEV2 is not set
+# CONFIG_I2C_GPIO is not set
+# CONFIG_I2C_HIBVT is not set
+# CONFIG_I2C_NOMADIK is not set
+# CONFIG_I2C_OCORES is not set
+# CONFIG_I2C_PCA_PLATFORM is not set
+# CONFIG_I2C_PXA_PCI is not set
+# CONFIG_I2C_RK3X is not set
+# CONFIG_I2C_SIMTEC is not set
+# CONFIG_I2C_XILINX is not set
+
+#
+# External I2C/SMBus adapter drivers
+#
+# CONFIG_I2C_DIOLAN_U2C is not set
+# CONFIG_I2C_PARPORT_LIGHT is not set
+# CONFIG_I2C_ROBOTFUZZ_OSIF is not set
+# CONFIG_I2C_TAOS_EVM is not set
+# CONFIG_I2C_TINY_USB is not set
+
+#
+# Other I2C/SMBus bus drivers
+#
+CONFIG_I2C_HISI=y
+# CONFIG_I2C_STUB is not set
+# CONFIG_I2C_SLAVE is not set
+# CONFIG_I2C_DEBUG_CORE is not set
+# CONFIG_I2C_DEBUG_ALGO is not set
+# CONFIG_I2C_DEBUG_BUS is not set
+CONFIG_SPI=y
+# CONFIG_SPI_DEBUG is not set
+CONFIG_SPI_MASTER=y
+
+#
+# SPI Master Controller Drivers
+#
+# CONFIG_SPI_ALTERA is not set
+# CONFIG_SPI_AXI_SPI_ENGINE is not set
+# CONFIG_SPI_BITBANG is not set
+# CONFIG_SPI_CADENCE is not set
+# CONFIG_SPI_DESIGNWARE is not set
+# CONFIG_SPI_GPIO is not set
+# CONFIG_SPI_FSL_SPI is not set
+# CONFIG_SPI_OC_TINY is not set
+CONFIG_SPI_PL022=y
+# CONFIG_SPI_PXA2XX_PCI is not set
+# CONFIG_SPI_ROCKCHIP is not set
+# CONFIG_SPI_SC18IS602 is not set
+# CONFIG_SPI_XCOMM is not set
+# CONFIG_SPI_XILINX is not set
+# CONFIG_SPI_ZYNQMP_GQSPI is not set
+
+#
+# SPI Protocol Masters
+#
+CONFIG_SPI_SPIDEV=y
+# CONFIG_SPI_LOOPBACK_TEST is not set
+# CONFIG_SPI_TLE62X0 is not set
+# CONFIG_SPMI is not set
+# CONFIG_HSI is not set
+
+#
+# PPS support
+#
+# CONFIG_PPS is not set
+
+#
+# PPS generators support
+#
+
+#
+# PTP clock support
+#
+# CONFIG_PTP_1588_CLOCK is not set
+
+#
+# Enable PHYLIB and NETWORK_PHY_TIMESTAMPING to see the additional clocks.
+#
+CONFIG_ARCH_HAVE_CUSTOM_GPIO_H=y
+CONFIG_GPIOLIB=y
+CONFIG_OF_GPIO=y
+CONFIG_GPIOLIB_IRQCHIP=y
+# CONFIG_DEBUG_GPIO is not set
+CONFIG_GPIO_SYSFS=y
+
+#
+# Memory mapped GPIO drivers
+#
+# CONFIG_GPIO_74XX_MMIO is not set
+# CONFIG_GPIO_ALTERA is not set
+# CONFIG_GPIO_DWAPB is not set
+# CONFIG_GPIO_EM is not set
+# CONFIG_GPIO_GENERIC_PLATFORM is not set
+# CONFIG_GPIO_GRGPIO is not set
+# CONFIG_GPIO_MOCKUP is not set
+# CONFIG_GPIO_MPC8XXX is not set
+CONFIG_GPIO_PL061=y
+# CONFIG_GPIO_XILINX is not set
+# CONFIG_GPIO_ZEVIO is not set
+# CONFIG_GPIO_ZX is not set
+
+#
+# I2C GPIO expanders
+#
+# CONFIG_GPIO_ADP5588 is not set
+# CONFIG_GPIO_ADNP is not set
+# CONFIG_GPIO_MAX7300 is not set
+# CONFIG_GPIO_MAX732X is not set
+# CONFIG_GPIO_PCA953X is not set
+# CONFIG_GPIO_PCF857X is not set
+# CONFIG_GPIO_SX150X is not set
+# CONFIG_GPIO_TPIC2810 is not set
+# CONFIG_GPIO_TS4900 is not set
+
+#
+# MFD GPIO expanders
+#
+# CONFIG_HTC_EGPIO is not set
+
+#
+# SPI GPIO expanders
+#
+# CONFIG_GPIO_74X164 is not set
+# CONFIG_GPIO_MAX7301 is not set
+# CONFIG_GPIO_MC33880 is not set
+# CONFIG_GPIO_PISOSR is not set
+
+#
+# SPI or I2C GPIO expanders
+#
+# CONFIG_GPIO_MCP23S08 is not set
+
+#
+# USB GPIO expanders
+#
+# CONFIG_W1 is not set
+# CONFIG_POWER_AVS is not set
+CONFIG_POWER_RESET=y
+# CONFIG_POWER_RESET_BRCMKONA is not set
+# CONFIG_POWER_RESET_GPIO is not set
+# CONFIG_POWER_RESET_GPIO_RESTART is not set
+CONFIG_POWER_RESET_HISI=y
+# CONFIG_POWER_RESET_LTC2952 is not set
+# CONFIG_POWER_RESET_RESTART is not set
+# CONFIG_POWER_RESET_SYSCON is not set
+# CONFIG_POWER_RESET_SYSCON_POWEROFF is not set
+CONFIG_POWER_SUPPLY=y
+# CONFIG_POWER_SUPPLY_DEBUG is not set
+# CONFIG_PDA_POWER is not set
+# CONFIG_TEST_POWER is not set
+# CONFIG_BATTERY_DS2780 is not set
+# CONFIG_BATTERY_DS2781 is not set
+# CONFIG_BATTERY_DS2782 is not set
+# CONFIG_BATTERY_SBS is not set
+# CONFIG_BATTERY_BQ27XXX is not set
+# CONFIG_BATTERY_MAX17040 is not set
+# CONFIG_BATTERY_MAX17042 is not set
+# CONFIG_CHARGER_MAX8903 is not set
+# CONFIG_CHARGER_LP8727 is not set
+# CONFIG_CHARGER_GPIO is not set
+# CONFIG_CHARGER_MANAGER is not set
+# CONFIG_CHARGER_BQ2415X is not set
+# CONFIG_CHARGER_BQ24190 is not set
+# CONFIG_CHARGER_BQ24735 is not set
+# CONFIG_CHARGER_BQ25890 is not set
+# CONFIG_CHARGER_SMB347 is not set
+# CONFIG_BATTERY_GAUGE_LTC2941 is not set
+# CONFIG_CHARGER_RT9455 is not set
+# CONFIG_HWMON is not set
+# CONFIG_THERMAL is not set
+# CONFIG_WATCHDOG is not set
+CONFIG_SSB_POSSIBLE=y
+
+#
+# Sonics Silicon Backplane
+#
+# CONFIG_SSB is not set
+CONFIG_BCMA_POSSIBLE=y
+
+#
+# Broadcom specific AMBA
+#
+# CONFIG_BCMA is not set
+
+#
+# Multifunction device drivers
+#
+# CONFIG_MFD_CORE is not set
+# CONFIG_MFD_ACT8945A is not set
+# CONFIG_MFD_AS3711 is not set
+# CONFIG_MFD_AS3722 is not set
+# CONFIG_PMIC_ADP5520 is not set
+# CONFIG_MFD_AAT2870_CORE is not set
+# CONFIG_MFD_ATMEL_FLEXCOM is not set
+# CONFIG_MFD_ATMEL_HLCDC is not set
+# CONFIG_MFD_BCM590XX is not set
+# CONFIG_MFD_AXP20X_I2C is not set
+# CONFIG_MFD_CROS_EC is not set
+# CONFIG_MFD_ASIC3 is not set
+# CONFIG_PMIC_DA903X is not set
+# CONFIG_MFD_DA9052_SPI is not set
+# CONFIG_MFD_DA9052_I2C is not set
+# CONFIG_MFD_DA9055 is not set
+# CONFIG_MFD_DA9062 is not set
+# CONFIG_MFD_DA9063 is not set
+# CONFIG_MFD_DA9150 is not set
+# CONFIG_MFD_DLN2 is not set
+# CONFIG_MFD_EXYNOS_LPASS is not set
+# CONFIG_MFD_MC13XXX_SPI is not set
+# CONFIG_MFD_MC13XXX_I2C is not set
+# CONFIG_MFD_HI6421_PMIC is not set
+# CONFIG_MFD_HISI_FMC is not set
+# CONFIG_HTC_PASIC3 is not set
+# CONFIG_HTC_I2CPLD is not set
+# CONFIG_INTEL_SOC_PMIC is not set
+# CONFIG_MFD_KEMPLD is not set
+# CONFIG_MFD_88PM800 is not set
+# CONFIG_MFD_88PM805 is not set
+# CONFIG_MFD_88PM860X is not set
+# CONFIG_MFD_MAX14577 is not set
+# CONFIG_MFD_MAX77620 is not set
+# CONFIG_MFD_MAX77686 is not set
+# CONFIG_MFD_MAX77693 is not set
+# CONFIG_MFD_MAX77843 is not set
+# CONFIG_MFD_MAX8907 is not set
+# CONFIG_MFD_MAX8925 is not set
+# CONFIG_MFD_MAX8997 is not set
+# CONFIG_MFD_MAX8998 is not set
+# CONFIG_MFD_MT6397 is not set
+# CONFIG_MFD_MENF21BMC is not set
+# CONFIG_EZX_PCAP is not set
+# CONFIG_MFD_VIPERBOARD is not set
+# CONFIG_MFD_RETU is not set
+# CONFIG_MFD_PCF50633 is not set
+# CONFIG_MFD_PM8921_CORE is not set
+# CONFIG_MFD_RT5033 is not set
+# CONFIG_MFD_RTSX_USB is not set
+# CONFIG_MFD_RC5T583 is not set
+# CONFIG_MFD_RK808 is not set
+# CONFIG_MFD_RN5T618 is not set
+# CONFIG_MFD_SEC_CORE is not set
+# CONFIG_MFD_SI476X_CORE is not set
+# CONFIG_MFD_SM501 is not set
+# CONFIG_MFD_SKY81452 is not set
+# CONFIG_MFD_SMSC is not set
+# CONFIG_ABX500_CORE is not set
+# CONFIG_MFD_STMPE is not set
+# CONFIG_MFD_SYSCON is not set
+# CONFIG_MFD_TI_AM335X_TSCADC is not set
+# CONFIG_MFD_LP3943 is not set
+# CONFIG_MFD_LP8788 is not set
+# CONFIG_MFD_PALMAS is not set
+# CONFIG_TPS6105X is not set
+# CONFIG_TPS65010 is not set
+# CONFIG_TPS6507X is not set
+# CONFIG_MFD_TPS65086 is not set
+# CONFIG_MFD_TPS65090 is not set
+# CONFIG_MFD_TPS65217 is not set
+# CONFIG_MFD_TI_LP873X is not set
+# CONFIG_MFD_TPS65218 is not set
+# CONFIG_MFD_TPS6586X is not set
+# CONFIG_MFD_TPS65910 is not set
+# CONFIG_MFD_TPS65912_I2C is not set
+# CONFIG_MFD_TPS65912_SPI is not set
+# CONFIG_MFD_TPS80031 is not set
+# CONFIG_TWL4030_CORE is not set
+# CONFIG_TWL6040_CORE is not set
+# CONFIG_MFD_WL1273_CORE is not set
+# CONFIG_MFD_LM3533 is not set
+# CONFIG_MFD_TC3589X is not set
+# CONFIG_MFD_TMIO is not set
+# CONFIG_MFD_T7L66XB is not set
+# CONFIG_MFD_TC6387XB is not set
+# CONFIG_MFD_TC6393XB is not set
+# CONFIG_MFD_ARIZONA_I2C is not set
+# CONFIG_MFD_ARIZONA_SPI is not set
+# CONFIG_MFD_WM8400 is not set
+# CONFIG_MFD_WM831X_I2C is not set
+# CONFIG_MFD_WM831X_SPI is not set
+# CONFIG_MFD_WM8350_I2C is not set
+# CONFIG_MFD_WM8994 is not set
+CONFIG_REGULATOR=y
+# CONFIG_REGULATOR_DEBUG is not set
+# CONFIG_REGULATOR_FIXED_VOLTAGE is not set
+# CONFIG_REGULATOR_VIRTUAL_CONSUMER is not set
+# CONFIG_REGULATOR_USERSPACE_CONSUMER is not set
+# CONFIG_REGULATOR_ACT8865 is not set
+# CONFIG_REGULATOR_AD5398 is not set
+# CONFIG_REGULATOR_DA9210 is not set
+# CONFIG_REGULATOR_DA9211 is not set
+# CONFIG_REGULATOR_FAN53555 is not set
+# CONFIG_REGULATOR_GPIO is not set
+# CONFIG_REGULATOR_ISL9305 is not set
+# CONFIG_REGULATOR_ISL6271A is not set
+# CONFIG_REGULATOR_LP3971 is not set
+# CONFIG_REGULATOR_LP3972 is not set
+# CONFIG_REGULATOR_LP872X is not set
+# CONFIG_REGULATOR_LP8755 is not set
+# CONFIG_REGULATOR_LTC3589 is not set
+# CONFIG_REGULATOR_LTC3676 is not set
+# CONFIG_REGULATOR_MAX1586 is not set
+# CONFIG_REGULATOR_MAX8649 is not set
+# CONFIG_REGULATOR_MAX8660 is not set
+# CONFIG_REGULATOR_MAX8952 is not set
+# CONFIG_REGULATOR_MT6311 is not set
+# CONFIG_REGULATOR_PFUZE100 is not set
+# CONFIG_REGULATOR_PV88060 is not set
+# CONFIG_REGULATOR_PV88080 is not set
+# CONFIG_REGULATOR_PV88090 is not set
+# CONFIG_REGULATOR_TPS51632 is not set
+# CONFIG_REGULATOR_TPS62360 is not set
+# CONFIG_REGULATOR_TPS65023 is not set
+# CONFIG_REGULATOR_TPS6507X is not set
+# CONFIG_REGULATOR_TPS6524X is not set
+# CONFIG_MEDIA_SUPPORT is not set
+
+#
+# Graphics support
+#
+# CONFIG_IMX_IPUV3_CORE is not set
+# CONFIG_DRM is not set
+
+#
+# ACP (Audio CoProcessor) Configuration
+#
+
+#
+# Frame buffer Devices
+#
+CONFIG_FB=y
+# CONFIG_FIRMWARE_EDID is not set
+CONFIG_FB_CMDLINE=y
+CONFIG_FB_NOTIFY=y
+# CONFIG_FB_DDC is not set
+# CONFIG_FB_BOOT_VESA_SUPPORT is not set
+# CONFIG_FB_CFB_FILLRECT is not set
+# CONFIG_FB_CFB_COPYAREA is not set
+# CONFIG_FB_CFB_IMAGEBLIT is not set
+# CONFIG_FB_CFB_REV_PIXELS_IN_BYTE is not set
+# CONFIG_FB_SYS_FILLRECT is not set
+# CONFIG_FB_SYS_COPYAREA is not set
+# CONFIG_FB_SYS_IMAGEBLIT is not set
+# CONFIG_FB_FOREIGN_ENDIAN is not set
+# CONFIG_FB_SYS_FOPS is not set
+# CONFIG_FB_SVGALIB is not set
+# CONFIG_FB_MACMODES is not set
+# CONFIG_FB_BACKLIGHT is not set
+# CONFIG_FB_MODE_HELPERS is not set
+# CONFIG_FB_TILEBLITTING is not set
+
+#
+# Frame buffer hardware drivers
+#
+# CONFIG_FB_ARMCLCD is not set
+# CONFIG_FB_OPENCORES is not set
+# CONFIG_FB_S1D13XXX is not set
+# CONFIG_FB_SMSCUFX is not set
+# CONFIG_FB_UDL is not set
+# CONFIG_FB_IBM_GXT4500 is not set
+# CONFIG_FB_VIRTUAL is not set
+# CONFIG_FB_METRONOME is not set
+# CONFIG_FB_BROADSHEET is not set
+# CONFIG_FB_AUO_K190X is not set
+# CONFIG_FB_SIMPLE is not set
+# CONFIG_FB_SSD1307 is not set
+# CONFIG_BACKLIGHT_LCD_SUPPORT is not set
+# CONFIG_VGASTATE is not set
+
+#
+# Console display driver support
+#
+CONFIG_DUMMY_CONSOLE=y
+# CONFIG_FRAMEBUFFER_CONSOLE is not set
+# CONFIG_LOGO is not set
+# CONFIG_SOUND is not set
+
+#
+# HID support
+#
+CONFIG_HID=y
+# CONFIG_HID_BATTERY_STRENGTH is not set
+# CONFIG_HIDRAW is not set
+# CONFIG_UHID is not set
+CONFIG_HID_GENERIC=y
+
+#
+# Special HID drivers
+#
+# CONFIG_HID_A4TECH is not set
+# CONFIG_HID_ACRUX is not set
+# CONFIG_HID_APPLE is not set
+# CONFIG_HID_APPLEIR is not set
+# CONFIG_HID_AUREAL is not set
+# CONFIG_HID_BELKIN is not set
+# CONFIG_HID_BETOP_FF is not set
+# CONFIG_HID_CHERRY is not set
+# CONFIG_HID_CHICONY is not set
+# CONFIG_HID_CMEDIA is not set
+# CONFIG_HID_CP2112 is not set
+# CONFIG_HID_CYPRESS is not set
+# CONFIG_HID_DRAGONRISE is not set
+# CONFIG_HID_EMS_FF is not set
+# CONFIG_HID_ELECOM is not set
+# CONFIG_HID_ELO is not set
+# CONFIG_HID_EZKEY is not set
+# CONFIG_HID_GEMBIRD is not set
+# CONFIG_HID_GFRM is not set
+# CONFIG_HID_HOLTEK is not set
+# CONFIG_HID_KEYTOUCH is not set
+# CONFIG_HID_KYE is not set
+# CONFIG_HID_UCLOGIC is not set
+# CONFIG_HID_WALTOP is not set
+# CONFIG_HID_GYRATION is not set
+# CONFIG_HID_ICADE is not set
+# CONFIG_HID_TWINHAN is not set
+# CONFIG_HID_KENSINGTON is not set
+# CONFIG_HID_LCPOWER is not set
+# CONFIG_HID_LENOVO is not set
+# CONFIG_HID_LOGITECH is not set
+# CONFIG_HID_MAGICMOUSE is not set
+CONFIG_HID_MICROSOFT=y
+# CONFIG_HID_MONTEREY is not set
+# CONFIG_HID_MULTITOUCH is not set
+# CONFIG_HID_NTRIG is not set
+# CONFIG_HID_ORTEK is not set
+# CONFIG_HID_PANTHERLORD is not set
+# CONFIG_HID_PENMOUNT is not set
+# CONFIG_HID_PETALYNX is not set
+# CONFIG_HID_PICOLCD is not set
+# CONFIG_HID_PLANTRONICS is not set
+# CONFIG_HID_PRIMAX is not set
+# CONFIG_HID_ROCCAT is not set
+# CONFIG_HID_SAITEK is not set
+# CONFIG_HID_SAMSUNG is not set
+# CONFIG_HID_SPEEDLINK is not set
+# CONFIG_HID_STEELSERIES is not set
+# CONFIG_HID_SUNPLUS is not set
+# CONFIG_HID_RMI is not set
+# CONFIG_HID_GREENASIA is not set
+# CONFIG_HID_SMARTJOYPLUS is not set
+# CONFIG_HID_TIVO is not set
+# CONFIG_HID_TOPSEED is not set
+# CONFIG_HID_THRUSTMASTER is not set
+# CONFIG_HID_WACOM is not set
+# CONFIG_HID_XINMO is not set
+# CONFIG_HID_ZEROPLUS is not set
+# CONFIG_HID_ZYDACRON is not set
+# CONFIG_HID_SENSOR_HUB is not set
+# CONFIG_HID_ALPS is not set
+
+#
+# USB HID support
+#
+CONFIG_USB_HID=y
+# CONFIG_HID_PID is not set
+# CONFIG_USB_HIDDEV is not set
+
+#
+# I2C HID support
+#
+# CONFIG_I2C_HID is not set
+CONFIG_USB_OHCI_LITTLE_ENDIAN=y
+CONFIG_USB_SUPPORT=y
+CONFIG_USB_COMMON=y
+CONFIG_USB_ARCH_HAS_HCD=y
+CONFIG_USB=y
+# CONFIG_USB_ANNOUNCE_NEW_DEVICES is not set
+
+#
+# Miscellaneous USB options
+#
+CONFIG_USB_DEFAULT_PERSIST=y
+# CONFIG_USB_DYNAMIC_MINORS is not set
+# CONFIG_USB_OTG is not set
+# CONFIG_USB_OTG_WHITELIST is not set
+# CONFIG_USB_MON is not set
+# CONFIG_USB_WUSB_CBAF is not set
+
+#
+# USB Host Controller Drivers
+#
+# CONFIG_USB_C67X00_HCD is not set
+# CONFIG_USB_XHCI_HCD is not set
+CONFIG_USB_EHCI_HCD=y
+# CONFIG_USB_EHCI_ROOT_HUB_TT is not set
+CONFIG_USB_EHCI_TT_NEWSCHED=y
+CONFIG_USB_EHCI_HCD_PLATFORM=y
+# CONFIG_USB_OXU210HP_HCD is not set
+# CONFIG_USB_ISP116X_HCD is not set
+# CONFIG_USB_ISP1362_HCD is not set
+# CONFIG_USB_FOTG210_HCD is not set
+# CONFIG_USB_MAX3421_HCD is not set
+CONFIG_USB_OHCI_HCD=y
+CONFIG_USB_OHCI_HCD_PLATFORM=y
+# CONFIG_USB_SL811_HCD is not set
+# CONFIG_USB_R8A66597_HCD is not set
+# CONFIG_USB_HCD_TEST_MODE is not set
+
+#
+# USB Device Class drivers
+#
+# CONFIG_USB_ACM is not set
+# CONFIG_USB_PRINTER is not set
+# CONFIG_USB_WDM is not set
+# CONFIG_USB_TMC is not set
+
+#
+# NOTE: USB_STORAGE depends on SCSI but BLK_DEV_SD may
+#
+
+#
+# also be needed; see USB_STORAGE Help for more info
+#
+CONFIG_USB_STORAGE=y
+# CONFIG_USB_STORAGE_DEBUG is not set
+# CONFIG_USB_STORAGE_REALTEK is not set
+# CONFIG_USB_STORAGE_DATAFAB is not set
+# CONFIG_USB_STORAGE_FREECOM is not set
+# CONFIG_USB_STORAGE_ISD200 is not set
+# CONFIG_USB_STORAGE_USBAT is not set
+# CONFIG_USB_STORAGE_SDDR09 is not set
+# CONFIG_USB_STORAGE_SDDR55 is not set
+# CONFIG_USB_STORAGE_JUMPSHOT is not set
+# CONFIG_USB_STORAGE_ALAUDA is not set
+# CONFIG_USB_STORAGE_ONETOUCH is not set
+# CONFIG_USB_STORAGE_KARMA is not set
+# CONFIG_USB_STORAGE_CYPRESS_ATACB is not set
+# CONFIG_USB_STORAGE_ENE_UB6250 is not set
+# CONFIG_USB_UAS is not set
+
+#
+# USB Imaging devices
+#
+# CONFIG_USB_MDC800 is not set
+# CONFIG_USB_MICROTEK is not set
+# CONFIG_USBIP_CORE is not set
+# CONFIG_USB_MUSB_HDRC is not set
+# CONFIG_USB_DWC3 is not set
+# CONFIG_USB_DWC2 is not set
+# CONFIG_USB_CHIPIDEA is not set
+# CONFIG_USB_ISP1760 is not set
+
+#
+# USB port drivers
+#
+# CONFIG_USB_SERIAL is not set
+
+#
+# USB Miscellaneous drivers
+#
+# CONFIG_USB_EMI62 is not set
+# CONFIG_USB_EMI26 is not set
+# CONFIG_USB_ADUTUX is not set
+# CONFIG_USB_SEVSEG is not set
+# CONFIG_USB_RIO500 is not set
+# CONFIG_USB_LEGOTOWER is not set
+# CONFIG_USB_LCD is not set
+# CONFIG_USB_CYPRESS_CY7C63 is not set
+# CONFIG_USB_CYTHERM is not set
+# CONFIG_USB_IDMOUSE is not set
+# CONFIG_USB_FTDI_ELAN is not set
+# CONFIG_USB_APPLEDISPLAY is not set
+# CONFIG_USB_SISUSBVGA is not set
+# CONFIG_USB_LD is not set
+# CONFIG_USB_TRANCEVIBRATOR is not set
+# CONFIG_USB_IOWARRIOR is not set
+# CONFIG_USB_TEST is not set
+# CONFIG_USB_EHSET_TEST_FIXTURE is not set
+# CONFIG_USB_ISIGHTFW is not set
+# CONFIG_USB_YUREX is not set
+# CONFIG_USB_EZUSB_FX2 is not set
+# CONFIG_USB_HSIC_USB3503 is not set
+# CONFIG_USB_HSIC_USB4604 is not set
+# CONFIG_USB_LINK_LAYER_TEST is not set
+
+#
+# USB Physical Layer drivers
+#
+# CONFIG_USB_PHY is not set
+# CONFIG_NOP_USB_XCEIV is not set
+# CONFIG_USB_GPIO_VBUS is not set
+# CONFIG_USB_ISP1301 is not set
+# CONFIG_USB_ULPI is not set
+# CONFIG_USB_GADGET is not set
+# CONFIG_USB_ULPI_BUS is not set
+# CONFIG_UWB is not set
+CONFIG_MMC=y
+# CONFIG_MMC_DEBUG is not set
+CONFIG_PWRSEQ_EMMC=y
+CONFIG_PWRSEQ_SIMPLE=y
+
+#
+# MMC/SD/SDIO Card Drivers
+#
+CONFIG_MMC_BLOCK=y
+CONFIG_MMC_BLOCK_MINORS=8
+CONFIG_MMC_BLOCK_BOUNCE=y
+# CONFIG_SDIO_UART is not set
+# CONFIG_MMC_TEST is not set
+
+#
+# MMC/SD/SDIO Host Controller Drivers
+#
+# CONFIG_MMC_ARMMMCI is not set
+# CONFIG_MMC_SDHCI is not set
+# CONFIG_MMC_SPI is not set
+# CONFIG_MMC_DW is not set
+# CONFIG_MMC_VUB300 is not set
+# CONFIG_MMC_USHC is not set
+# CONFIG_MMC_USDHI6ROL0 is not set
+# CONFIG_MMC_MTK is not set
+CONFIG_HIMCI=y
+CONFIG_SEND_AUTO_STOP=y
+# CONFIG_MEMSTICK is not set
+# CONFIG_NEW_LEDS is not set
+# CONFIG_ACCESSIBILITY is not set
+CONFIG_EDAC_ATOMIC_SCRUB=y
+CONFIG_EDAC_SUPPORT=y
+# CONFIG_EDAC is not set
+CONFIG_RTC_LIB=y
+# CONFIG_RTC_CLASS is not set
+# CONFIG_DMADEVICES is not set
+
+#
+# DMABUF options
+#
+# CONFIG_SYNC_FILE is not set
+# CONFIG_AUXDISPLAY is not set
+# CONFIG_UIO is not set
+# CONFIG_VIRT_DRIVERS is not set
+
+#
+# Virtio drivers
+#
+# CONFIG_VIRTIO_MMIO is not set
+
+#
+# Microsoft Hyper-V guest support
+#
+# CONFIG_STAGING is not set
+# CONFIG_GOLDFISH is not set
+# CONFIG_CHROME_PLATFORMS is not set
+CONFIG_CLKDEV_LOOKUP=y
+CONFIG_HAVE_CLK_PREPARE=y
+CONFIG_COMMON_CLK=y
+
+#
+# Common Clock Framework
+#
+# CONFIG_COMMON_CLK_SI5351 is not set
+# CONFIG_COMMON_CLK_SI514 is not set
+# CONFIG_COMMON_CLK_SI570 is not set
+# CONFIG_COMMON_CLK_CDCE706 is not set
+# CONFIG_COMMON_CLK_CDCE925 is not set
+# CONFIG_COMMON_CLK_CS2000_CP is not set
+# CONFIG_CLK_QORIQ is not set
+# CONFIG_COMMON_CLK_NXP is not set
+# CONFIG_COMMON_CLK_PXA is not set
+# CONFIG_COMMON_CLK_PIC32 is not set
+CONFIG_COMMON_CLK_HI3516A=y
+CONFIG_RESET_HISI=y
+
+#
+# Hardware Spinlock drivers
+#
+
+#
+# Clock Source drivers
+#
+CONFIG_CLKSRC_OF=y
+CONFIG_CLKSRC_PROBE=y
+CONFIG_CLKSRC_MMIO=y
+CONFIG_ARM_ARCH_TIMER=y
+CONFIG_ARM_ARCH_TIMER_EVTSTREAM=y
+CONFIG_ARM_TIMER_SP804=y
+# CONFIG_ATMEL_PIT is not set
+# CONFIG_SH_TIMER_CMT is not set
+# CONFIG_SH_TIMER_MTU2 is not set
+# CONFIG_SH_TIMER_TMU is not set
+# CONFIG_EM_TIMER_STI is not set
+# CONFIG_MAILBOX is not set
+# CONFIG_IOMMU_SUPPORT is not set
+
+#
+# Remoteproc drivers
+#
+# CONFIG_STE_MODEM_RPROC is not set
+
+#
+# Rpmsg drivers
+#
+
+#
+# SOC (System On Chip) specific Drivers
+#
+
+#
+# Broadcom SoC drivers
+#
+# CONFIG_SOC_BRCMSTB is not set
+# CONFIG_SUNXI_SRAM is not set
+# CONFIG_SOC_TI is not set
+# CONFIG_PM_DEVFREQ is not set
+# CONFIG_EXTCON is not set
+# CONFIG_MEMORY is not set
+# CONFIG_IIO is not set
+# CONFIG_PWM is not set
+CONFIG_IRQCHIP=y
+CONFIG_ARM_GIC=y
+CONFIG_ARM_GIC_MAX_NR=1
+# CONFIG_IPACK_BUS is not set
+CONFIG_ARCH_HAS_RESET_CONTROLLER=y
+CONFIG_RESET_CONTROLLER=y
+# CONFIG_RESET_ATH79 is not set
+# CONFIG_RESET_BERLIN is not set
+# CONFIG_RESET_LPC18XX is not set
+# CONFIG_RESET_MESON is not set
+# CONFIG_RESET_PISTACHIO is not set
+# CONFIG_RESET_SOCFPGA is not set
+# CONFIG_RESET_STM32 is not set
+# CONFIG_RESET_SUNXI is not set
+# CONFIG_TI_SYSCON_RESET is not set
+# CONFIG_RESET_ZYNQ is not set
+# CONFIG_FMC is not set
+
+#
+# PHY Subsystem
+#
+CONFIG_GENERIC_PHY=y
+# CONFIG_PHY_PXA_28NM_HSIC is not set
+# CONFIG_PHY_PXA_28NM_USB2 is not set
+# CONFIG_BCM_KONA_USB2_PHY is not set
+CONFIG_PHY_HISI_USB2=y
+# CONFIG_POWERCAP is not set
+# CONFIG_MCB is not set
+
+#
+# Performance monitor support
+#
+# CONFIG_RAS is not set
+
+#
+# Android
+#
+# CONFIG_ANDROID is not set
+# CONFIG_NVMEM is not set
+# CONFIG_STM is not set
+# CONFIG_INTEL_TH is not set
+
+#
+# FPGA Configuration Support
+#
+# CONFIG_FPGA is not set
+CONFIG_HI_DMAC=y
+CONFIG_HI_DMAC_CHANNEL_NUM=4
+
+#
+# Firmware Drivers
+#
+# CONFIG_FIRMWARE_MEMMAP is not set
+# CONFIG_FW_CFG_SYSFS is not set
+CONFIG_HAVE_ARM_SMCCC=y
+
+#
+# File systems
+#
+CONFIG_DCACHE_WORD_ACCESS=y
+# CONFIG_EXT2_FS is not set
+# CONFIG_EXT3_FS is not set
+CONFIG_EXT4_FS=y
+CONFIG_EXT4_USE_FOR_EXT2=y
+# CONFIG_EXT4_FS_POSIX_ACL is not set
+# CONFIG_EXT4_FS_SECURITY is not set
+# CONFIG_EXT4_ENCRYPTION is not set
+# CONFIG_EXT4_DEBUG is not set
+CONFIG_JBD2=y
+# CONFIG_JBD2_DEBUG is not set
+CONFIG_FS_MBCACHE=y
+# CONFIG_REISERFS_FS is not set
+# CONFIG_JFS_FS is not set
+# CONFIG_XFS_FS is not set
+# CONFIG_GFS2_FS is not set
+# CONFIG_OCFS2_FS is not set
+# CONFIG_BTRFS_FS is not set
+# CONFIG_NILFS2_FS is not set
+# CONFIG_F2FS_FS is not set
+CONFIG_FS_POSIX_ACL=y
+CONFIG_EXPORTFS=y
+# CONFIG_EXPORTFS_BLOCK_OPS is not set
+CONFIG_FILE_LOCKING=y
+CONFIG_MANDATORY_FILE_LOCKING=y
+# CONFIG_FS_ENCRYPTION is not set
+CONFIG_FSNOTIFY=y
+CONFIG_DNOTIFY=y
+CONFIG_INOTIFY_USER=y
+# CONFIG_FANOTIFY is not set
+# CONFIG_QUOTA is not set
+# CONFIG_QUOTACTL is not set
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_FUSE_FS is not set
+# CONFIG_OVERLAY_FS is not set
+
+#
+# Caches
+#
+# CONFIG_FSCACHE is not set
+
+#
+# CD-ROM/DVD Filesystems
+#
+# CONFIG_ISO9660_FS is not set
+# CONFIG_UDF_FS is not set
+
+#
+# DOS/FAT/NT Filesystems
+#
+CONFIG_FAT_FS=y
+CONFIG_MSDOS_FS=y
+CONFIG_VFAT_FS=y
+CONFIG_FAT_DEFAULT_CODEPAGE=437
+CONFIG_FAT_DEFAULT_IOCHARSET="iso8859-1"
+# CONFIG_FAT_DEFAULT_UTF8 is not set
+# CONFIG_NTFS_FS is not set
+
+#
+# Pseudo filesystems
+#
+CONFIG_PROC_FS=y
+CONFIG_PROC_SYSCTL=y
+CONFIG_PROC_PAGE_MONITOR=y
+# CONFIG_PROC_CHILDREN is not set
+CONFIG_KERNFS=y
+CONFIG_SYSFS=y
+CONFIG_TMPFS=y
+# CONFIG_TMPFS_POSIX_ACL is not set
+# CONFIG_TMPFS_XATTR is not set
+# CONFIG_HUGETLB_PAGE is not set
+CONFIG_CONFIGFS_FS=m
+CONFIG_MISC_FILESYSTEMS=y
+# CONFIG_ORANGEFS_FS is not set
+# CONFIG_ADFS_FS is not set
+# CONFIG_AFFS_FS is not set
+# CONFIG_ECRYPT_FS is not set
+# CONFIG_HFS_FS is not set
+# CONFIG_HFSPLUS_FS is not set
+# CONFIG_BEFS_FS is not set
+# CONFIG_BFS_FS is not set
+# CONFIG_EFS_FS is not set
+CONFIG_YAFFS_FS=y
+CONFIG_YAFFS_YAFFS1=y
+# CONFIG_YAFFS_9BYTE_TAGS is not set
+# CONFIG_YAFFS_DOES_ECC is not set
+CONFIG_YAFFS_YAFFS2=y
+CONFIG_YAFFS_AUTO_YAFFS2=y
+# CONFIG_YAFFS_DISABLE_TAGS_ECC is not set
+# CONFIG_YAFFS_ALWAYS_CHECK_CHUNK_ERASED is not set
+# CONFIG_YAFFS_EMPTY_LOST_AND_FOUND is not set
+# CONFIG_YAFFS_DISABLE_BLOCK_REFRESHING is not set
+# CONFIG_YAFFS_DISABLE_BACKGROUND is not set
+# CONFIG_YAFFS_DISABLE_BAD_BLOCK_MARKING is not set
+CONFIG_YAFFS_XATTR=y
+CONFIG_JFFS2_FS=y
+CONFIG_JFFS2_FS_DEBUG=0
+CONFIG_JFFS2_FS_WRITEBUFFER=y
+# CONFIG_JFFS2_FS_WBUF_VERIFY is not set
+# CONFIG_JFFS2_SUMMARY is not set
+# CONFIG_JFFS2_FS_XATTR is not set
+# CONFIG_JFFS2_COMPRESSION_OPTIONS is not set
+CONFIG_JFFS2_ZLIB=y
+# CONFIG_JFFS2_LZO is not set
+CONFIG_JFFS2_RTIME=y
+# CONFIG_JFFS2_RUBIN is not set
+CONFIG_UBIFS_FS=y
+# CONFIG_UBIFS_FS_ADVANCED_COMPR is not set
+CONFIG_UBIFS_FS_LZO=y
+CONFIG_UBIFS_FS_ZLIB=y
+# CONFIG_UBIFS_ATIME_SUPPORT is not set
+# CONFIG_LOGFS is not set
+CONFIG_CRAMFS=y
+# CONFIG_SQUASHFS is not set
+# CONFIG_VXFS_FS is not set
+# CONFIG_MINIX_FS is not set
+# CONFIG_OMFS_FS is not set
+# CONFIG_HPFS_FS is not set
+# CONFIG_QNX4FS_FS is not set
+# CONFIG_QNX6FS_FS is not set
+# CONFIG_ROMFS_FS is not set
+# CONFIG_PSTORE is not set
+# CONFIG_SYSV_FS is not set
+# CONFIG_UFS_FS is not set
+CONFIG_NETWORK_FILESYSTEMS=y
+CONFIG_NFS_FS=y
+CONFIG_NFS_V2=y
+CONFIG_NFS_V3=y
+CONFIG_NFS_V3_ACL=y
+CONFIG_NFS_V4=y
+# CONFIG_NFS_SWAP is not set
+# CONFIG_NFS_V4_1 is not set
+CONFIG_ROOT_NFS=y
+# CONFIG_NFS_USE_LEGACY_DNS is not set
+CONFIG_NFS_USE_KERNEL_DNS=y
+# CONFIG_NFSD is not set
+CONFIG_GRACE_PERIOD=y
+CONFIG_LOCKD=y
+CONFIG_LOCKD_V4=y
+CONFIG_NFS_ACL_SUPPORT=y
+CONFIG_NFS_COMMON=y
+CONFIG_SUNRPC=y
+CONFIG_SUNRPC_GSS=y
+# CONFIG_SUNRPC_DEBUG is not set
+# CONFIG_CEPH_FS is not set
+# CONFIG_CIFS is not set
+# CONFIG_NCP_FS is not set
+# CONFIG_CODA_FS is not set
+# CONFIG_AFS_FS is not set
+CONFIG_NLS=y
+CONFIG_NLS_DEFAULT="iso8859-1"
+CONFIG_NLS_CODEPAGE_437=y
+# CONFIG_NLS_CODEPAGE_737 is not set
+# CONFIG_NLS_CODEPAGE_775 is not set
+# CONFIG_NLS_CODEPAGE_850 is not set
+# CONFIG_NLS_CODEPAGE_852 is not set
+# CONFIG_NLS_CODEPAGE_855 is not set
+# CONFIG_NLS_CODEPAGE_857 is not set
+# CONFIG_NLS_CODEPAGE_860 is not set
+# CONFIG_NLS_CODEPAGE_861 is not set
+# CONFIG_NLS_CODEPAGE_862 is not set
+# CONFIG_NLS_CODEPAGE_863 is not set
+# CONFIG_NLS_CODEPAGE_864 is not set
+# CONFIG_NLS_CODEPAGE_865 is not set
+# CONFIG_NLS_CODEPAGE_866 is not set
+# CONFIG_NLS_CODEPAGE_869 is not set
+# CONFIG_NLS_CODEPAGE_936 is not set
+# CONFIG_NLS_CODEPAGE_950 is not set
+# CONFIG_NLS_CODEPAGE_932 is not set
+# CONFIG_NLS_CODEPAGE_949 is not set
+# CONFIG_NLS_CODEPAGE_874 is not set
+# CONFIG_NLS_ISO8859_8 is not set
+# CONFIG_NLS_CODEPAGE_1250 is not set
+# CONFIG_NLS_CODEPAGE_1251 is not set
+# CONFIG_NLS_ASCII is not set
+CONFIG_NLS_ISO8859_1=y
+# CONFIG_NLS_ISO8859_2 is not set
+# CONFIG_NLS_ISO8859_3 is not set
+# CONFIG_NLS_ISO8859_4 is not set
+# CONFIG_NLS_ISO8859_5 is not set
+# CONFIG_NLS_ISO8859_6 is not set
+# CONFIG_NLS_ISO8859_7 is not set
+# CONFIG_NLS_ISO8859_9 is not set
+# CONFIG_NLS_ISO8859_13 is not set
+# CONFIG_NLS_ISO8859_14 is not set
+# CONFIG_NLS_ISO8859_15 is not set
+# CONFIG_NLS_KOI8_R is not set
+# CONFIG_NLS_KOI8_U is not set
+# CONFIG_NLS_MAC_ROMAN is not set
+# CONFIG_NLS_MAC_CELTIC is not set
+# CONFIG_NLS_MAC_CENTEURO is not set
+# CONFIG_NLS_MAC_CROATIAN is not set
+# CONFIG_NLS_MAC_CYRILLIC is not set
+# CONFIG_NLS_MAC_GAELIC is not set
+# CONFIG_NLS_MAC_GREEK is not set
+# CONFIG_NLS_MAC_ICELAND is not set
+# CONFIG_NLS_MAC_INUIT is not set
+# CONFIG_NLS_MAC_ROMANIAN is not set
+# CONFIG_NLS_MAC_TURKISH is not set
+CONFIG_NLS_UTF8=y
+# CONFIG_DLM is not set
+
+#
+# Kernel hacking
+#
+
+#
+# printk and dmesg options
+#
+# CONFIG_PRINTK_TIME is not set
+CONFIG_MESSAGE_LOGLEVEL_DEFAULT=4
+# CONFIG_BOOT_PRINTK_DELAY is not set
+
+#
+# Compile-time checks and compiler options
+#
+# CONFIG_DEBUG_INFO is not set
+# CONFIG_ENABLE_WARN_DEPRECATED is not set
+# CONFIG_ENABLE_MUST_CHECK is not set
+CONFIG_FRAME_WARN=1024
+# CONFIG_STRIP_ASM_SYMS is not set
+# CONFIG_READABLE_ASM is not set
+# CONFIG_UNUSED_SYMBOLS is not set
+# CONFIG_PAGE_OWNER is not set
+# CONFIG_DEBUG_FS is not set
+# CONFIG_HEADERS_CHECK is not set
+# CONFIG_DEBUG_SECTION_MISMATCH is not set
+CONFIG_SECTION_MISMATCH_WARN_ONLY=y
+CONFIG_FRAME_POINTER=y
+# CONFIG_DEBUG_FORCE_WEAK_PER_CPU is not set
+# CONFIG_MAGIC_SYSRQ is not set
+CONFIG_DEBUG_KERNEL=y
+
+#
+# Memory Debugging
+#
+# CONFIG_PAGE_EXTENSION is not set
+# CONFIG_PAGE_POISONING is not set
+# CONFIG_DEBUG_OBJECTS is not set
+# CONFIG_SLUB_DEBUG_ON is not set
+# CONFIG_SLUB_STATS is not set
+CONFIG_HAVE_DEBUG_KMEMLEAK=y
+# CONFIG_DEBUG_KMEMLEAK is not set
+# CONFIG_DEBUG_STACK_USAGE is not set
+# CONFIG_DEBUG_VM is not set
+CONFIG_DEBUG_MEMORY_INIT=y
+# CONFIG_DEBUG_SHIRQ is not set
+
+#
+# Debug Lockups and Hangs
+#
+# CONFIG_LOCKUP_DETECTOR is not set
+# CONFIG_DETECT_HUNG_TASK is not set
+# CONFIG_WQ_WATCHDOG is not set
+# CONFIG_PANIC_ON_OOPS is not set
+CONFIG_PANIC_ON_OOPS_VALUE=0
+CONFIG_PANIC_TIMEOUT=0
+# CONFIG_SCHED_DEBUG is not set
+# CONFIG_SCHED_INFO is not set
+# CONFIG_SCHEDSTATS is not set
+# CONFIG_SCHED_STACK_END_CHECK is not set
+# CONFIG_DEBUG_TIMEKEEPING is not set
+# CONFIG_TIMER_STATS is not set
+
+#
+# Lock Debugging (spinlocks, mutexes, etc...)
+#
+# CONFIG_DEBUG_RT_MUTEXES is not set
+# CONFIG_DEBUG_SPINLOCK is not set
+CONFIG_DEBUG_MUTEXES=y
+# CONFIG_DEBUG_WW_MUTEX_SLOWPATH is not set
+# CONFIG_DEBUG_LOCK_ALLOC is not set
+# CONFIG_PROVE_LOCKING is not set
+# CONFIG_LOCK_STAT is not set
+# CONFIG_DEBUG_ATOMIC_SLEEP is not set
+# CONFIG_DEBUG_LOCKING_API_SELFTESTS is not set
+# CONFIG_LOCK_TORTURE_TEST is not set
+CONFIG_STACKTRACE=y
+# CONFIG_DEBUG_KOBJECT is not set
+CONFIG_DEBUG_BUGVERBOSE=y
+# CONFIG_DEBUG_LIST is not set
+# CONFIG_DEBUG_PI_LIST is not set
+# CONFIG_DEBUG_SG is not set
+# CONFIG_DEBUG_NOTIFIERS is not set
+# CONFIG_DEBUG_CREDENTIALS is not set
+
+#
+# RCU Debugging
+#
+# CONFIG_PROVE_RCU is not set
+# CONFIG_SPARSE_RCU_POINTER is not set
+# CONFIG_TORTURE_TEST is not set
+# CONFIG_RCU_PERF_TEST is not set
+# CONFIG_RCU_TORTURE_TEST is not set
+# CONFIG_RCU_TRACE is not set
+# CONFIG_RCU_EQS_DEBUG is not set
+# CONFIG_DEBUG_WQ_FORCE_RR_CPU is not set
+# CONFIG_DEBUG_BLOCK_EXT_DEVT is not set
+# CONFIG_NOTIFIER_ERROR_INJECTION is not set
+# CONFIG_FAULT_INJECTION is not set
+# CONFIG_LATENCYTOP is not set
+CONFIG_HAVE_FUNCTION_TRACER=y
+CONFIG_HAVE_FUNCTION_GRAPH_TRACER=y
+CONFIG_HAVE_DYNAMIC_FTRACE=y
+CONFIG_HAVE_FTRACE_MCOUNT_RECORD=y
+CONFIG_HAVE_SYSCALL_TRACEPOINTS=y
+CONFIG_HAVE_C_RECORDMCOUNT=y
+CONFIG_TRACING_SUPPORT=y
+# CONFIG_FTRACE is not set
+
+#
+# Runtime Testing
+#
+# CONFIG_TEST_LIST_SORT is not set
+# CONFIG_BACKTRACE_SELF_TEST is not set
+# CONFIG_RBTREE_TEST is not set
+# CONFIG_INTERVAL_TREE_TEST is not set
+# CONFIG_PERCPU_TEST is not set
+# CONFIG_ATOMIC64_SELFTEST is not set
+# CONFIG_TEST_HEXDUMP is not set
+# CONFIG_TEST_STRING_HELPERS is not set
+# CONFIG_TEST_KSTRTOX is not set
+# CONFIG_TEST_PRINTF is not set
+# CONFIG_TEST_BITMAP is not set
+# CONFIG_TEST_UUID is not set
+# CONFIG_TEST_RHASHTABLE is not set
+# CONFIG_TEST_HASH is not set
+# CONFIG_DMA_API_DEBUG is not set
+# CONFIG_TEST_LKM is not set
+# CONFIG_TEST_USER_COPY is not set
+# CONFIG_TEST_BPF is not set
+# CONFIG_TEST_FIRMWARE is not set
+# CONFIG_TEST_UDELAY is not set
+# CONFIG_MEMTEST is not set
+# CONFIG_TEST_STATIC_KEYS is not set
+# CONFIG_SAMPLES is not set
+CONFIG_HAVE_ARCH_KGDB=y
+# CONFIG_KGDB is not set
+# CONFIG_ARCH_WANTS_UBSAN_NO_NULL is not set
+# CONFIG_UBSAN is not set
+CONFIG_ARCH_HAS_DEVMEM_IS_ALLOWED=y
+CONFIG_STRICT_DEVMEM=y
+# CONFIG_IO_STRICT_DEVMEM is not set
+# CONFIG_ARM_PTDUMP is not set
+# CONFIG_ARM_UNWIND is not set
+# CONFIG_DEBUG_USER is not set
+# CONFIG_DEBUG_LL is not set
+CONFIG_DEBUG_LL_INCLUDE="mach/debug-macro.S"
+# CONFIG_DEBUG_UART_8250 is not set
+CONFIG_UNCOMPRESS_INCLUDE="debug/uncompress.h"
+# CONFIG_PID_IN_CONTEXTIDR is not set
+# CONFIG_DEBUG_SET_MODULE_RONX is not set
+# CONFIG_CORESIGHT is not set
+
+#
+# Security options
+#
+CONFIG_KEYS=y
+# CONFIG_PERSISTENT_KEYRINGS is not set
+# CONFIG_ENCRYPTED_KEYS is not set
+# CONFIG_KEY_DH_OPERATIONS is not set
+# CONFIG_SECURITY_DMESG_RESTRICT is not set
+# CONFIG_SECURITY is not set
+# CONFIG_SECURITYFS is not set
+CONFIG_HAVE_HARDENED_USERCOPY_ALLOCATOR=y
+CONFIG_HAVE_ARCH_HARDENED_USERCOPY=y
+# CONFIG_HARDENED_USERCOPY is not set
+CONFIG_DEFAULT_SECURITY_DAC=y
+CONFIG_DEFAULT_SECURITY=""
+CONFIG_CRYPTO=y
+
+#
+# Crypto core or helper
+#
+CONFIG_CRYPTO_ALGAPI=y
+CONFIG_CRYPTO_ALGAPI2=y
+CONFIG_CRYPTO_AEAD=m
+CONFIG_CRYPTO_AEAD2=y
+CONFIG_CRYPTO_BLKCIPHER=y
+CONFIG_CRYPTO_BLKCIPHER2=y
+CONFIG_CRYPTO_HASH=y
+CONFIG_CRYPTO_HASH2=y
+CONFIG_CRYPTO_RNG=m
+CONFIG_CRYPTO_RNG2=y
+CONFIG_CRYPTO_RNG_DEFAULT=m
+CONFIG_CRYPTO_AKCIPHER2=y
+CONFIG_CRYPTO_KPP2=y
+# CONFIG_CRYPTO_RSA is not set
+# CONFIG_CRYPTO_DH is not set
+# CONFIG_CRYPTO_ECDH is not set
+CONFIG_CRYPTO_MANAGER=m
+CONFIG_CRYPTO_MANAGER2=y
+# CONFIG_CRYPTO_USER is not set
+CONFIG_CRYPTO_MANAGER_DISABLE_TESTS=y
+CONFIG_CRYPTO_GF128MUL=m
+CONFIG_CRYPTO_NULL=m
+CONFIG_CRYPTO_NULL2=y
+CONFIG_CRYPTO_WORKQUEUE=y
+# CONFIG_CRYPTO_CRYPTD is not set
+# CONFIG_CRYPTO_MCRYPTD is not set
+# CONFIG_CRYPTO_AUTHENC is not set
+# CONFIG_CRYPTO_TEST is not set
+
+#
+# Authenticated Encryption with Associated Data
+#
+CONFIG_CRYPTO_CCM=m
+CONFIG_CRYPTO_GCM=m
+# CONFIG_CRYPTO_CHACHA20POLY1305 is not set
+CONFIG_CRYPTO_SEQIV=m
+CONFIG_CRYPTO_ECHAINIV=m
+
+#
+# Block modes
+#
+# CONFIG_CRYPTO_CBC is not set
+CONFIG_CRYPTO_CTR=m
+# CONFIG_CRYPTO_CTS is not set
+# CONFIG_CRYPTO_ECB is not set
+# CONFIG_CRYPTO_LRW is not set
+# CONFIG_CRYPTO_PCBC is not set
+# CONFIG_CRYPTO_XTS is not set
+# CONFIG_CRYPTO_KEYWRAP is not set
+
+#
+# Hash modes
+#
+# CONFIG_CRYPTO_CMAC is not set
+CONFIG_CRYPTO_HMAC=m
+# CONFIG_CRYPTO_XCBC is not set
+# CONFIG_CRYPTO_VMAC is not set
+
+#
+# Digest
+#
+CONFIG_CRYPTO_CRC32C=y
+# CONFIG_CRYPTO_CRC32 is not set
+CONFIG_CRYPTO_CRCT10DIF=y
+CONFIG_CRYPTO_GHASH=m
+# CONFIG_CRYPTO_POLY1305 is not set
+# CONFIG_CRYPTO_MD4 is not set
+CONFIG_CRYPTO_MD5=y
+# CONFIG_CRYPTO_MICHAEL_MIC is not set
+# CONFIG_CRYPTO_RMD128 is not set
+# CONFIG_CRYPTO_RMD160 is not set
+# CONFIG_CRYPTO_RMD256 is not set
+# CONFIG_CRYPTO_RMD320 is not set
+CONFIG_CRYPTO_SHA1=y
+CONFIG_CRYPTO_SHA256=y
+# CONFIG_CRYPTO_SHA512 is not set
+# CONFIG_CRYPTO_SHA3 is not set
+# CONFIG_CRYPTO_TGR192 is not set
+# CONFIG_CRYPTO_WP512 is not set
+
+#
+# Ciphers
+#
+CONFIG_CRYPTO_AES=y
+# CONFIG_CRYPTO_ANUBIS is not set
+CONFIG_CRYPTO_ARC4=y
+# CONFIG_CRYPTO_BLOWFISH is not set
+# CONFIG_CRYPTO_CAMELLIA is not set
+# CONFIG_CRYPTO_CAST5 is not set
+# CONFIG_CRYPTO_CAST6 is not set
+# CONFIG_CRYPTO_DES is not set
+# CONFIG_CRYPTO_FCRYPT is not set
+# CONFIG_CRYPTO_KHAZAD is not set
+# CONFIG_CRYPTO_SALSA20 is not set
+# CONFIG_CRYPTO_CHACHA20 is not set
+# CONFIG_CRYPTO_SEED is not set
+# CONFIG_CRYPTO_SERPENT is not set
+# CONFIG_CRYPTO_TEA is not set
+# CONFIG_CRYPTO_TWOFISH is not set
+
+#
+# Compression
+#
+CONFIG_CRYPTO_DEFLATE=y
+CONFIG_CRYPTO_LZO=y
+# CONFIG_CRYPTO_842 is not set
+# CONFIG_CRYPTO_LZ4 is not set
+# CONFIG_CRYPTO_LZ4HC is not set
+
+#
+# Random Number Generation
+#
+# CONFIG_CRYPTO_ANSI_CPRNG is not set
+CONFIG_CRYPTO_DRBG_MENU=m
+CONFIG_CRYPTO_DRBG_HMAC=y
+# CONFIG_CRYPTO_DRBG_HASH is not set
+# CONFIG_CRYPTO_DRBG_CTR is not set
+CONFIG_CRYPTO_DRBG=m
+CONFIG_CRYPTO_JITTERENTROPY=m
+# CONFIG_CRYPTO_USER_API_HASH is not set
+# CONFIG_CRYPTO_USER_API_SKCIPHER is not set
+# CONFIG_CRYPTO_USER_API_RNG is not set
+# CONFIG_CRYPTO_USER_API_AEAD is not set
+# CONFIG_CRYPTO_HW is not set
+# CONFIG_ASYMMETRIC_KEY_TYPE is not set
+
+#
+# Certificates for signature checking
+#
+# CONFIG_ARM_CRYPTO is not set
+# CONFIG_BINARY_PRINTF is not set
+
+#
+# Library routines
+#
+CONFIG_BITREVERSE=y
+CONFIG_HAVE_ARCH_BITREVERSE=y
+CONFIG_RATIONAL=y
+CONFIG_GENERIC_STRNCPY_FROM_USER=y
+CONFIG_GENERIC_STRNLEN_USER=y
+CONFIG_GENERIC_NET_UTILS=y
+CONFIG_GENERIC_PCI_IOMAP=y
+CONFIG_GENERIC_IO=y
+CONFIG_ARCH_USE_CMPXCHG_LOCKREF=y
+CONFIG_CRC_CCITT=y
+CONFIG_CRC16=y
+CONFIG_CRC_T10DIF=y
+CONFIG_CRC_ITU_T=y
+CONFIG_CRC32=y
+# CONFIG_CRC32_SELFTEST is not set
+CONFIG_CRC32_SLICEBY8=y
+# CONFIG_CRC32_SLICEBY4 is not set
+# CONFIG_CRC32_SARWATE is not set
+# CONFIG_CRC32_BIT is not set
+# CONFIG_CRC7 is not set
+CONFIG_LIBCRC32C=y
+# CONFIG_CRC8 is not set
+# CONFIG_AUDIT_ARCH_COMPAT_GENERIC is not set
+# CONFIG_RANDOM32_SELFTEST is not set
+CONFIG_ZLIB_INFLATE=y
+CONFIG_ZLIB_DEFLATE=y
+CONFIG_LZO_COMPRESS=y
+CONFIG_LZO_DECOMPRESS=y
+CONFIG_LZ4_DECOMPRESS=y
+CONFIG_XZ_DEC=y
+CONFIG_XZ_DEC_X86=y
+CONFIG_XZ_DEC_POWERPC=y
+CONFIG_XZ_DEC_IA64=y
+CONFIG_XZ_DEC_ARM=y
+CONFIG_XZ_DEC_ARMTHUMB=y
+CONFIG_XZ_DEC_SPARC=y
+CONFIG_XZ_DEC_BCJ=y
+# CONFIG_XZ_DEC_TEST is not set
+CONFIG_DECOMPRESS_GZIP=y
+CONFIG_DECOMPRESS_LZ4=y
+CONFIG_GENERIC_ALLOCATOR=y
+CONFIG_ASSOCIATIVE_ARRAY=y
+CONFIG_HAS_IOMEM=y
+CONFIG_HAS_IOPORT_MAP=y
+CONFIG_HAS_DMA=y
+CONFIG_DQL=y
+CONFIG_NLATTR=y
+# CONFIG_CORDIC is not set
+# CONFIG_DDR is not set
+# CONFIG_IRQ_POLL is not set
+CONFIG_LIBFDT=y
+CONFIG_OID_REGISTRY=y
+# CONFIG_SG_SPLIT is not set
+CONFIG_SG_POOL=y
+CONFIG_ARCH_HAS_SG_CHAIN=y
+CONFIG_SBITMAP=y
+# CONFIG_VIRTUALIZATION is not set
diff --git a/arch/arm/configs/hi3516a_mini_defconfig b/arch/arm/configs/hi3516a_mini_defconfig
new file mode 100644
index 0000000..70133e1
--- /dev/null
+++ b/arch/arm/configs/hi3516a_mini_defconfig
@@ -0,0 +1,2323 @@
+#
+# Automatically generated file; DO NOT EDIT.
+# Linux/arm 4.9.37 Kernel Configuration
+#
+CONFIG_ARM=y
+CONFIG_ARM_HAS_SG_CHAIN=y
+CONFIG_MIGHT_HAVE_PCI=y
+CONFIG_SYS_SUPPORTS_APM_EMULATION=y
+CONFIG_HAVE_PROC_CPU=y
+CONFIG_STACKTRACE_SUPPORT=y
+CONFIG_LOCKDEP_SUPPORT=y
+CONFIG_TRACE_IRQFLAGS_SUPPORT=y
+CONFIG_RWSEM_XCHGADD_ALGORITHM=y
+CONFIG_FIX_EARLYCON_MEM=y
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_NEED_DMA_MAP_STATE=y
+CONFIG_ARCH_SUPPORTS_UPROBES=y
+CONFIG_VECTORS_BASE=0xffff0000
+CONFIG_ARM_PATCH_PHYS_VIRT=y
+CONFIG_GENERIC_BUG=y
+CONFIG_PGTABLE_LEVELS=2
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+CONFIG_IRQ_WORK=y
+CONFIG_BUILDTIME_EXTABLE_SORT=y
+
+#
+# General setup
+#
+CONFIG_BROKEN_ON_SMP=y
+CONFIG_INIT_ENV_ARG_LIMIT=32
+CONFIG_CROSS_COMPILE=""
+# CONFIG_COMPILE_TEST is not set
+CONFIG_LOCALVERSION=""
+# CONFIG_LOCALVERSION_AUTO is not set
+CONFIG_HAVE_KERNEL_GZIP=y
+CONFIG_HAVE_KERNEL_LZMA=y
+CONFIG_HAVE_KERNEL_XZ=y
+CONFIG_HAVE_KERNEL_LZO=y
+CONFIG_HAVE_KERNEL_LZ4=y
+CONFIG_KERNEL_GZIP=y
+# CONFIG_KERNEL_LZMA is not set
+# CONFIG_KERNEL_XZ is not set
+# CONFIG_KERNEL_LZO is not set
+# CONFIG_KERNEL_LZ4 is not set
+CONFIG_DEFAULT_HOSTNAME="(none)"
+CONFIG_SWAP=y
+CONFIG_SYSVIPC=y
+CONFIG_SYSVIPC_SYSCTL=y
+# CONFIG_POSIX_MQUEUE is not set
+CONFIG_CROSS_MEMORY_ATTACH=y
+CONFIG_FHANDLE=y
+CONFIG_USELIB=y
+# CONFIG_AUDIT is not set
+CONFIG_HAVE_ARCH_AUDITSYSCALL=y
+
+#
+# IRQ subsystem
+#
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_GENERIC_IRQ_SHOW=y
+CONFIG_GENERIC_IRQ_SHOW_LEVEL=y
+CONFIG_HARDIRQS_SW_RESEND=y
+CONFIG_IRQ_DOMAIN=y
+CONFIG_IRQ_DOMAIN_HIERARCHY=y
+CONFIG_HANDLE_DOMAIN_IRQ=y
+CONFIG_IRQ_FORCED_THREADING=y
+CONFIG_SPARSE_IRQ=y
+CONFIG_ARCH_CLOCKSOURCE_DATA=y
+CONFIG_GENERIC_TIME_VSYSCALL=y
+CONFIG_GENERIC_CLOCKEVENTS=y
+
+#
+# Timers subsystem
+#
+CONFIG_HZ_PERIODIC=y
+# CONFIG_NO_HZ_IDLE is not set
+# CONFIG_NO_HZ is not set
+# CONFIG_HIGH_RES_TIMERS is not set
+
+#
+# CPU/Task time and stats accounting
+#
+CONFIG_TICK_CPU_ACCOUNTING=y
+# CONFIG_VIRT_CPU_ACCOUNTING_GEN is not set
+CONFIG_IRQ_TIME_ACCOUNTING=y
+# CONFIG_BSD_PROCESS_ACCT is not set
+# CONFIG_TASKSTATS is not set
+
+#
+# RCU Subsystem
+#
+CONFIG_TINY_RCU=y
+# CONFIG_RCU_EXPERT is not set
+CONFIG_SRCU=y
+# CONFIG_TASKS_RCU is not set
+# CONFIG_RCU_STALL_COMMON is not set
+# CONFIG_TREE_RCU_TRACE is not set
+# CONFIG_RCU_EXPEDITE_BOOT is not set
+# CONFIG_BUILD_BIN2C is not set
+# CONFIG_IKCONFIG is not set
+CONFIG_LOG_BUF_SHIFT=17
+CONFIG_NMI_LOG_BUF_SHIFT=13
+CONFIG_GENERIC_SCHED_CLOCK=y
+CONFIG_CGROUPS=y
+# CONFIG_MEMCG is not set
+# CONFIG_BLK_CGROUP is not set
+# CONFIG_CGROUP_SCHED is not set
+# CONFIG_CGROUP_PIDS is not set
+CONFIG_CGROUP_FREEZER=y
+# CONFIG_CPUSETS is not set
+# CONFIG_CGROUP_DEVICE is not set
+# CONFIG_CGROUP_CPUACCT is not set
+# CONFIG_CGROUP_DEBUG is not set
+# CONFIG_CHECKPOINT_RESTORE is not set
+CONFIG_NAMESPACES=y
+CONFIG_UTS_NS=y
+CONFIG_IPC_NS=y
+# CONFIG_USER_NS is not set
+CONFIG_PID_NS=y
+CONFIG_NET_NS=y
+# CONFIG_SCHED_AUTOGROUP is not set
+# CONFIG_SYSFS_DEPRECATED is not set
+# CONFIG_RELAY is not set
+CONFIG_BLK_DEV_INITRD=y
+CONFIG_INITRAMFS_SOURCE=""
+CONFIG_RD_GZIP=y
+# CONFIG_RD_BZIP2 is not set
+# CONFIG_RD_LZMA is not set
+# CONFIG_RD_XZ is not set
+# CONFIG_RD_LZO is not set
+CONFIG_RD_LZ4=y
+CONFIG_CC_OPTIMIZE_FOR_PERFORMANCE=y
+# CONFIG_CC_OPTIMIZE_FOR_SIZE is not set
+CONFIG_SYSCTL=y
+CONFIG_ANON_INODES=y
+CONFIG_HAVE_UID16=y
+CONFIG_BPF=y
+# CONFIG_EXPERT is not set
+CONFIG_UID16=y
+CONFIG_MULTIUSER=y
+# CONFIG_SGETMASK_SYSCALL is not set
+CONFIG_SYSFS_SYSCALL=y
+# CONFIG_SYSCTL_SYSCALL is not set
+CONFIG_KALLSYMS=y
+# CONFIG_KALLSYMS_ALL is not set
+# CONFIG_KALLSYMS_ABSOLUTE_PERCPU is not set
+CONFIG_KALLSYMS_BASE_RELATIVE=y
+CONFIG_PRINTK=y
+CONFIG_PRINTK_NMI=y
+CONFIG_BUG=y
+CONFIG_ELF_CORE=y
+CONFIG_BASE_FULL=y
+CONFIG_FUTEX=y
+CONFIG_EPOLL=y
+CONFIG_SIGNALFD=y
+CONFIG_TIMERFD=y
+CONFIG_EVENTFD=y
+# CONFIG_BPF_SYSCALL is not set
+CONFIG_SHMEM=y
+CONFIG_AIO=y
+CONFIG_ADVISE_SYSCALLS=y
+# CONFIG_USERFAULTFD is not set
+CONFIG_MEMBARRIER=y
+# CONFIG_EMBEDDED is not set
+CONFIG_HAVE_PERF_EVENTS=y
+CONFIG_PERF_USE_VMALLOC=y
+
+#
+# Kernel Performance Events And Counters
+#
+# CONFIG_PERF_EVENTS is not set
+CONFIG_VM_EVENT_COUNTERS=y
+CONFIG_SLUB_DEBUG=y
+CONFIG_COMPAT_BRK=y
+# CONFIG_SLAB is not set
+CONFIG_SLUB=y
+# CONFIG_SLAB_FREELIST_RANDOM is not set
+# CONFIG_SYSTEM_DATA_VERIFICATION is not set
+# CONFIG_PROFILING is not set
+CONFIG_HAVE_OPROFILE=y
+# CONFIG_KPROBES is not set
+# CONFIG_JUMP_LABEL is not set
+# CONFIG_UPROBES is not set
+# CONFIG_HAVE_64BIT_ALIGNED_ACCESS is not set
+CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS=y
+CONFIG_ARCH_USE_BUILTIN_BSWAP=y
+CONFIG_HAVE_KPROBES=y
+CONFIG_HAVE_KRETPROBES=y
+CONFIG_HAVE_OPTPROBES=y
+CONFIG_HAVE_NMI=y
+CONFIG_HAVE_ARCH_TRACEHOOK=y
+CONFIG_HAVE_DMA_CONTIGUOUS=y
+CONFIG_GENERIC_SMP_IDLE_THREAD=y
+CONFIG_GENERIC_IDLE_POLL_SETUP=y
+CONFIG_HAVE_REGS_AND_STACK_ACCESS_API=y
+CONFIG_HAVE_CLK=y
+CONFIG_HAVE_DMA_API_DEBUG=y
+CONFIG_HAVE_PERF_REGS=y
+CONFIG_HAVE_PERF_USER_STACK_DUMP=y
+CONFIG_HAVE_ARCH_JUMP_LABEL=y
+CONFIG_ARCH_WANT_IPC_PARSE_VERSION=y
+CONFIG_HAVE_ARCH_SECCOMP_FILTER=y
+CONFIG_HAVE_GCC_PLUGINS=y
+# CONFIG_GCC_PLUGINS is not set
+CONFIG_HAVE_CC_STACKPROTECTOR=y
+# CONFIG_CC_STACKPROTECTOR is not set
+CONFIG_CC_STACKPROTECTOR_NONE=y
+# CONFIG_CC_STACKPROTECTOR_REGULAR is not set
+# CONFIG_CC_STACKPROTECTOR_STRONG is not set
+CONFIG_HAVE_CONTEXT_TRACKING=y
+CONFIG_HAVE_VIRT_CPU_ACCOUNTING_GEN=y
+CONFIG_HAVE_IRQ_TIME_ACCOUNTING=y
+CONFIG_HAVE_MOD_ARCH_SPECIFIC=y
+CONFIG_MODULES_USE_ELF_REL=y
+CONFIG_ARCH_HAS_ELF_RANDOMIZE=y
+CONFIG_HAVE_ARCH_MMAP_RND_BITS=y
+CONFIG_HAVE_EXIT_THREAD=y
+CONFIG_ARCH_MMAP_RND_BITS_MIN=8
+CONFIG_ARCH_MMAP_RND_BITS_MAX=16
+CONFIG_ARCH_MMAP_RND_BITS=8
+# CONFIG_HAVE_ARCH_HASH is not set
+# CONFIG_ISA_BUS_API is not set
+CONFIG_CLONE_BACKWARDS=y
+CONFIG_OLD_SIGSUSPEND3=y
+CONFIG_OLD_SIGACTION=y
+# CONFIG_CPU_NO_EFFICIENT_FFS is not set
+# CONFIG_HAVE_ARCH_VMAP_STACK is not set
+
+#
+# GCOV-based kernel profiling
+#
+CONFIG_ARCH_HAS_GCOV_PROFILE_ALL=y
+CONFIG_HAVE_GENERIC_DMA_COHERENT=y
+CONFIG_SLABINFO=y
+CONFIG_RT_MUTEXES=y
+CONFIG_BASE_SMALL=0
+CONFIG_MODULES=y
+# CONFIG_MODULE_FORCE_LOAD is not set
+CONFIG_MODULE_UNLOAD=y
+# CONFIG_MODULE_FORCE_UNLOAD is not set
+# CONFIG_MODVERSIONS is not set
+# CONFIG_MODULE_SRCVERSION_ALL is not set
+# CONFIG_MODULE_SIG is not set
+# CONFIG_MODULE_COMPRESS is not set
+# CONFIG_TRIM_UNUSED_KSYMS is not set
+CONFIG_BLOCK=y
+CONFIG_LBDAF=y
+CONFIG_BLK_DEV_BSG=y
+# CONFIG_BLK_DEV_BSGLIB is not set
+# CONFIG_BLK_DEV_INTEGRITY is not set
+CONFIG_BLK_CMDLINE_PARSER=y
+
+#
+# Partition Types
+#
+CONFIG_PARTITION_ADVANCED=y
+# CONFIG_ACORN_PARTITION is not set
+# CONFIG_AIX_PARTITION is not set
+# CONFIG_OSF_PARTITION is not set
+# CONFIG_AMIGA_PARTITION is not set
+# CONFIG_ATARI_PARTITION is not set
+# CONFIG_MAC_PARTITION is not set
+CONFIG_MSDOS_PARTITION=y
+# CONFIG_BSD_DISKLABEL is not set
+# CONFIG_MINIX_SUBPARTITION is not set
+# CONFIG_SOLARIS_X86_PARTITION is not set
+# CONFIG_UNIXWARE_DISKLABEL is not set
+# CONFIG_LDM_PARTITION is not set
+# CONFIG_SGI_PARTITION is not set
+# CONFIG_ULTRIX_PARTITION is not set
+# CONFIG_SUN_PARTITION is not set
+# CONFIG_KARMA_PARTITION is not set
+CONFIG_EFI_PARTITION=y
+# CONFIG_SYSV68_PARTITION is not set
+CONFIG_CMDLINE_PARTITION=y
+
+#
+# IO Schedulers
+#
+CONFIG_IOSCHED_NOOP=y
+CONFIG_IOSCHED_DEADLINE=y
+CONFIG_IOSCHED_CFQ=y
+CONFIG_DEFAULT_DEADLINE=y
+# CONFIG_DEFAULT_CFQ is not set
+# CONFIG_DEFAULT_NOOP is not set
+CONFIG_DEFAULT_IOSCHED="deadline"
+CONFIG_INLINE_SPIN_UNLOCK_IRQ=y
+CONFIG_INLINE_READ_UNLOCK=y
+CONFIG_INLINE_READ_UNLOCK_IRQ=y
+CONFIG_INLINE_WRITE_UNLOCK=y
+CONFIG_INLINE_WRITE_UNLOCK_IRQ=y
+CONFIG_ARCH_SUPPORTS_ATOMIC_RMW=y
+CONFIG_FREEZER=y
+
+#
+# System Type
+#
+CONFIG_MMU=y
+CONFIG_ARCH_MULTIPLATFORM=y
+# CONFIG_ARCH_GEMINI is not set
+# CONFIG_ARCH_EBSA110 is not set
+# CONFIG_ARCH_EP93XX is not set
+# CONFIG_ARCH_FOOTBRIDGE is not set
+# CONFIG_ARCH_NETX is not set
+# CONFIG_ARCH_IOP13XX is not set
+# CONFIG_ARCH_IOP32X is not set
+# CONFIG_ARCH_IOP33X is not set
+# CONFIG_ARCH_IXP4XX is not set
+# CONFIG_ARCH_DOVE is not set
+# CONFIG_ARCH_KS8695 is not set
+# CONFIG_ARCH_W90X900 is not set
+# CONFIG_ARCH_LPC32XX is not set
+# CONFIG_ARCH_PXA is not set
+# CONFIG_ARCH_RPC is not set
+# CONFIG_ARCH_SA1100 is not set
+# CONFIG_ARCH_S3C24XX is not set
+# CONFIG_ARCH_DAVINCI is not set
+# CONFIG_ARCH_OMAP1 is not set
+
+#
+# Multiple platform selection
+#
+
+#
+# CPU Core family selection
+#
+# CONFIG_ARCH_MULTI_V6 is not set
+CONFIG_ARCH_MULTI_V7=y
+CONFIG_ARCH_MULTI_V6_V7=y
+# CONFIG_ARCH_MULTI_CPU_AUTO is not set
+# CONFIG_ARCH_VIRT is not set
+# CONFIG_ARCH_MVEBU is not set
+# CONFIG_ARCH_ALPINE is not set
+# CONFIG_ARCH_ARTPEC is not set
+# CONFIG_ARCH_AT91 is not set
+# CONFIG_ARCH_BCM is not set
+# CONFIG_ARCH_BERLIN is not set
+# CONFIG_ARCH_DIGICOLOR is not set
+# CONFIG_ARCH_HIGHBANK is not set
+# CONFIG_ARCH_HISI is not set
+CONFIG_ARCH_HISI_BVT=y
+
+#
+# Hisilicon BVT platform type
+#
+CONFIG_HI_ZRELADDR=0x80008000
+CONFIG_HI_PARAMS_PHYS=0x00000100
+CONFIG_HI_INITRD_PHYS=0x00800000
+CONFIG_ARCH_HI3516A=y
+# CONFIG_ARCH_HI3536DV100 is not set
+# CONFIG_ARCH_KEYSTONE is not set
+# CONFIG_ARCH_MESON is not set
+# CONFIG_ARCH_MXC is not set
+# CONFIG_ARCH_MEDIATEK is not set
+
+#
+# TI OMAP/AM/DM/DRA Family
+#
+# CONFIG_ARCH_OMAP3 is not set
+# CONFIG_ARCH_OMAP4 is not set
+# CONFIG_SOC_OMAP5 is not set
+# CONFIG_SOC_AM33XX is not set
+# CONFIG_SOC_AM43XX is not set
+# CONFIG_SOC_DRA7XX is not set
+# CONFIG_ARCH_MMP is not set
+# CONFIG_ARCH_QCOM is not set
+# CONFIG_ARCH_REALVIEW is not set
+# CONFIG_ARCH_ROCKCHIP is not set
+# CONFIG_ARCH_SOCFPGA is not set
+# CONFIG_PLAT_SPEAR is not set
+# CONFIG_ARCH_STI is not set
+# CONFIG_ARCH_S5PV210 is not set
+# CONFIG_ARCH_EXYNOS is not set
+# CONFIG_ARCH_RENESAS is not set
+# CONFIG_ARCH_SUNXI is not set
+# CONFIG_ARCH_SIRF is not set
+# CONFIG_ARCH_TANGO is not set
+# CONFIG_ARCH_TEGRA is not set
+# CONFIG_ARCH_UNIPHIER is not set
+# CONFIG_ARCH_U8500 is not set
+# CONFIG_ARCH_VEXPRESS is not set
+# CONFIG_ARCH_WM8850 is not set
+# CONFIG_ARCH_ZX is not set
+# CONFIG_ARCH_ZYNQ is not set
+
+#
+# Processor Type
+#
+CONFIG_CPU_V7=y
+CONFIG_CPU_32v6K=y
+CONFIG_CPU_32v7=y
+CONFIG_CPU_ABRT_EV7=y
+CONFIG_CPU_PABRT_V7=y
+CONFIG_CPU_CACHE_V7=y
+CONFIG_CPU_CACHE_VIPT=y
+CONFIG_CPU_COPY_V6=y
+CONFIG_CPU_TLB_V7=y
+CONFIG_CPU_HAS_ASID=y
+CONFIG_CPU_CP15=y
+CONFIG_CPU_CP15_MMU=y
+
+#
+# Processor Features
+#
+# CONFIG_ARM_LPAE is not set
+# CONFIG_ARCH_PHYS_ADDR_T_64BIT is not set
+CONFIG_ARM_THUMB=y
+# CONFIG_ARM_THUMBEE is not set
+CONFIG_ARM_VIRT_EXT=y
+# CONFIG_SWP_EMULATE is not set
+# CONFIG_CPU_ICACHE_DISABLE is not set
+# CONFIG_CPU_DCACHE_DISABLE is not set
+# CONFIG_CPU_BPREDICT_DISABLE is not set
+CONFIG_KUSER_HELPERS=y
+CONFIG_VDSO=y
+CONFIG_MIGHT_HAVE_CACHE_L2X0=y
+# CONFIG_CACHE_L2X0 is not set
+CONFIG_ARM_L1_CACHE_SHIFT_6=y
+CONFIG_ARM_L1_CACHE_SHIFT=6
+CONFIG_ARM_DMA_MEM_BUFFERABLE=y
+# CONFIG_DEBUG_RODATA is not set
+CONFIG_MULTI_IRQ_HANDLER=y
+# CONFIG_ARM_ERRATA_430973 is not set
+# CONFIG_ARM_ERRATA_720789 is not set
+# CONFIG_ARM_ERRATA_754322 is not set
+# CONFIG_ARM_ERRATA_775420 is not set
+# CONFIG_ARM_ERRATA_773022 is not set
+# CONFIG_ARM_ERRATA_818325_852422 is not set
+# CONFIG_ARM_ERRATA_821420 is not set
+# CONFIG_ARM_ERRATA_825619 is not set
+# CONFIG_ARM_ERRATA_852421 is not set
+# CONFIG_ARM_ERRATA_852423 is not set
+
+#
+# Bus support
+#
+# CONFIG_PCI is not set
+# CONFIG_PCI_DOMAINS_GENERIC is not set
+# CONFIG_PCI_SYSCALL is not set
+# CONFIG_PCCARD is not set
+
+#
+# Kernel Features
+#
+CONFIG_HAVE_SMP=y
+# CONFIG_SMP is not set
+CONFIG_HAVE_ARM_ARCH_TIMER=y
+CONFIG_VMSPLIT_3G=y
+# CONFIG_VMSPLIT_3G_OPT is not set
+# CONFIG_VMSPLIT_2G is not set
+# CONFIG_VMSPLIT_1G is not set
+CONFIG_PAGE_OFFSET=0xC0000000
+# CONFIG_ARM_PSCI is not set
+CONFIG_ARCH_NR_GPIO=0
+CONFIG_PREEMPT_NONE=y
+# CONFIG_PREEMPT_VOLUNTARY is not set
+# CONFIG_PREEMPT is not set
+CONFIG_HZ_FIXED=0
+CONFIG_HZ_100=y
+# CONFIG_HZ_200 is not set
+# CONFIG_HZ_250 is not set
+# CONFIG_HZ_300 is not set
+# CONFIG_HZ_500 is not set
+# CONFIG_HZ_1000 is not set
+CONFIG_HZ=100
+# CONFIG_SCHED_HRTICK is not set
+# CONFIG_THUMB2_KERNEL is not set
+CONFIG_ARM_PATCH_IDIV=y
+CONFIG_AEABI=y
+# CONFIG_OABI_COMPAT is not set
+# CONFIG_ARCH_SPARSEMEM_DEFAULT is not set
+# CONFIG_ARCH_SELECT_MEMORY_MODEL is not set
+CONFIG_HAVE_ARCH_PFN_VALID=y
+# CONFIG_HIGHMEM is not set
+# CONFIG_CPU_SW_DOMAIN_PAN is not set
+CONFIG_ARCH_WANT_GENERAL_HUGETLB=y
+# CONFIG_ARM_MODULE_PLTS is not set
+CONFIG_FLATMEM=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+CONFIG_HAVE_MEMBLOCK=y
+CONFIG_NO_BOOTMEM=y
+# CONFIG_HAVE_BOOTMEM_INFO_NODE is not set
+CONFIG_SPLIT_PTLOCK_CPUS=4
+CONFIG_COMPACTION=y
+CONFIG_MIGRATION=y
+# CONFIG_PHYS_ADDR_T_64BIT is not set
+# CONFIG_KSM is not set
+CONFIG_DEFAULT_MMAP_MIN_ADDR=4096
+CONFIG_NEED_PER_CPU_KM=y
+# CONFIG_CLEANCACHE is not set
+# CONFIG_FRONTSWAP is not set
+# CONFIG_CMA is not set
+# CONFIG_ZPOOL is not set
+# CONFIG_ZBUD is not set
+# CONFIG_ZSMALLOC is not set
+CONFIG_GENERIC_EARLY_IOREMAP=y
+# CONFIG_IDLE_PAGE_TRACKING is not set
+CONFIG_FORCE_MAX_ZONEORDER=11
+CONFIG_ALIGNMENT_TRAP=y
+# CONFIG_UACCESS_WITH_MEMCPY is not set
+# CONFIG_SECCOMP is not set
+CONFIG_SWIOTLB=y
+CONFIG_IOMMU_HELPER=y
+# CONFIG_PARAVIRT is not set
+# CONFIG_PARAVIRT_TIME_ACCOUNTING is not set
+# CONFIG_XEN is not set
+
+#
+# Boot options
+#
+CONFIG_USE_OF=y
+CONFIG_ATAGS=y
+# CONFIG_DEPRECATED_PARAM_STRUCT is not set
+CONFIG_ZBOOT_ROM_TEXT=0
+CONFIG_ZBOOT_ROM_BSS=0
+CONFIG_ARM_APPENDED_DTB=y
+CONFIG_ARM_ATAG_DTB_COMPAT=y
+CONFIG_ARM_ATAG_DTB_COMPAT_CMDLINE_FROM_BOOTLOADER=y
+# CONFIG_ARM_ATAG_DTB_COMPAT_CMDLINE_EXTEND is not set
+CONFIG_CMDLINE=""
+# CONFIG_KEXEC is not set
+# CONFIG_CRASH_DUMP is not set
+CONFIG_AUTO_ZRELADDR=y
+# CONFIG_EFI is not set
+
+#
+# CPU Power Management
+#
+
+#
+# CPU Frequency scaling
+#
+CONFIG_CPU_FREQ=y
+CONFIG_CPU_FREQ_GOV_ATTR_SET=y
+CONFIG_CPU_FREQ_GOV_COMMON=y
+CONFIG_CPU_FREQ_STAT=y
+# CONFIG_CPU_FREQ_STAT_DETAILS is not set
+CONFIG_CPU_FREQ_DEFAULT_GOV_PERFORMANCE=y
+# CONFIG_CPU_FREQ_DEFAULT_GOV_POWERSAVE is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_USERSPACE is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_ONDEMAND is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_CONSERVATIVE is not set
+CONFIG_CPU_FREQ_GOV_PERFORMANCE=y
+# CONFIG_CPU_FREQ_GOV_POWERSAVE is not set
+CONFIG_CPU_FREQ_GOV_USERSPACE=y
+CONFIG_CPU_FREQ_GOV_ONDEMAND=y
+# CONFIG_CPU_FREQ_GOV_CONSERVATIVE is not set
+
+#
+# CPU frequency scaling drivers
+#
+CONFIG_CPUFREQ_DT=y
+CONFIG_CPUFREQ_DT_PLATDEV=y
+# CONFIG_ARM_KIRKWOOD_CPUFREQ is not set
+# CONFIG_QORIQ_CPUFREQ is not set
+
+#
+# CPU Idle
+#
+# CONFIG_CPU_IDLE is not set
+# CONFIG_ARCH_NEEDS_CPU_IDLE_COUPLED is not set
+
+#
+# Floating point emulation
+#
+
+#
+# At least one emulation must be selected
+#
+CONFIG_VFP=y
+CONFIG_VFPv3=y
+CONFIG_NEON=y
+# CONFIG_KERNEL_MODE_NEON is not set
+
+#
+# Userspace binary formats
+#
+CONFIG_BINFMT_ELF=y
+CONFIG_ELFCORE=y
+CONFIG_CORE_DUMP_DEFAULT_ELF_HEADERS=y
+CONFIG_BINFMT_SCRIPT=y
+# CONFIG_BINFMT_FLAT is not set
+# CONFIG_HAVE_AOUT is not set
+# CONFIG_BINFMT_MISC is not set
+CONFIG_COREDUMP=y
+
+#
+# Power management options
+#
+CONFIG_SUSPEND=y
+CONFIG_SUSPEND_FREEZER=y
+CONFIG_HIBERNATE_CALLBACKS=y
+CONFIG_HIBERNATION=y
+CONFIG_PM_STD_PARTITION=""
+CONFIG_PM_SLEEP=y
+# CONFIG_PM_AUTOSLEEP is not set
+# CONFIG_PM_WAKELOCKS is not set
+CONFIG_PM=y
+CONFIG_PM_DEBUG=y
+# CONFIG_PM_ADVANCED_DEBUG is not set
+CONFIG_PM_SLEEP_DEBUG=y
+# CONFIG_APM_EMULATION is not set
+CONFIG_PM_OPP=y
+CONFIG_PM_CLK=y
+# CONFIG_WQ_POWER_EFFICIENT_DEFAULT is not set
+CONFIG_CPU_PM=y
+CONFIG_ARCH_SUSPEND_POSSIBLE=y
+CONFIG_ARM_CPU_SUSPEND=y
+CONFIG_ARCH_HIBERNATION_POSSIBLE=y
+CONFIG_NET=y
+
+#
+# Networking options
+#
+CONFIG_PACKET=y
+# CONFIG_PACKET_DIAG is not set
+CONFIG_UNIX=y
+# CONFIG_UNIX_DIAG is not set
+CONFIG_XFRM=y
+CONFIG_XFRM_ALGO=y
+CONFIG_XFRM_USER=y
+# CONFIG_XFRM_SUB_POLICY is not set
+# CONFIG_XFRM_MIGRATE is not set
+# CONFIG_XFRM_STATISTICS is not set
+CONFIG_NET_KEY=y
+# CONFIG_NET_KEY_MIGRATE is not set
+CONFIG_INET=y
+CONFIG_IP_MULTICAST=y
+CONFIG_IP_ADVANCED_ROUTER=y
+# CONFIG_IP_FIB_TRIE_STATS is not set
+CONFIG_IP_MULTIPLE_TABLES=y
+CONFIG_IP_ROUTE_MULTIPATH=y
+CONFIG_IP_ROUTE_VERBOSE=y
+CONFIG_IP_PNP=y
+# CONFIG_IP_PNP_DHCP is not set
+# CONFIG_IP_PNP_BOOTP is not set
+# CONFIG_IP_PNP_RARP is not set
+# CONFIG_NET_IPIP is not set
+# CONFIG_NET_IPGRE_DEMUX is not set
+# CONFIG_NET_IP_TUNNEL is not set
+CONFIG_IP_MROUTE=y
+# CONFIG_IP_MROUTE_MULTIPLE_TABLES is not set
+CONFIG_IP_PIMSM_V1=y
+CONFIG_IP_PIMSM_V2=y
+CONFIG_SYN_COOKIES=y
+# CONFIG_NET_UDP_TUNNEL is not set
+# CONFIG_NET_FOU is not set
+# CONFIG_INET_AH is not set
+# CONFIG_INET_ESP is not set
+# CONFIG_INET_IPCOMP is not set
+# CONFIG_INET_XFRM_TUNNEL is not set
+# CONFIG_INET_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_TRANSPORT is not set
+# CONFIG_INET_XFRM_MODE_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_BEET is not set
+CONFIG_INET_DIAG=y
+CONFIG_INET_TCP_DIAG=y
+# CONFIG_INET_UDP_DIAG is not set
+# CONFIG_INET_DIAG_DESTROY is not set
+CONFIG_TCP_CONG_ADVANCED=y
+CONFIG_TCP_CONG_BIC=m
+CONFIG_TCP_CONG_CUBIC=y
+CONFIG_TCP_CONG_WESTWOOD=m
+CONFIG_TCP_CONG_HTCP=m
+# CONFIG_TCP_CONG_HSTCP is not set
+# CONFIG_TCP_CONG_HYBLA is not set
+# CONFIG_TCP_CONG_VEGAS is not set
+# CONFIG_TCP_CONG_NV is not set
+# CONFIG_TCP_CONG_SCALABLE is not set
+# CONFIG_TCP_CONG_LP is not set
+# CONFIG_TCP_CONG_VENO is not set
+# CONFIG_TCP_CONG_YEAH is not set
+# CONFIG_TCP_CONG_ILLINOIS is not set
+# CONFIG_TCP_CONG_DCTCP is not set
+# CONFIG_TCP_CONG_CDG is not set
+# CONFIG_TCP_CONG_BBR is not set
+CONFIG_DEFAULT_CUBIC=y
+# CONFIG_DEFAULT_RENO is not set
+CONFIG_DEFAULT_TCP_CONG="cubic"
+CONFIG_TCP_MD5SIG=y
+# CONFIG_IPV6 is not set
+# CONFIG_NETWORK_SECMARK is not set
+# CONFIG_NET_PTP_CLASSIFY is not set
+# CONFIG_NETWORK_PHY_TIMESTAMPING is not set
+# CONFIG_NETFILTER is not set
+# CONFIG_IP_DCCP is not set
+# CONFIG_IP_SCTP is not set
+# CONFIG_RDS is not set
+# CONFIG_TIPC is not set
+# CONFIG_ATM is not set
+# CONFIG_L2TP is not set
+# CONFIG_BRIDGE is not set
+CONFIG_HAVE_NET_DSA=y
+# CONFIG_VLAN_8021Q is not set
+# CONFIG_DECNET is not set
+# CONFIG_LLC2 is not set
+# CONFIG_IPX is not set
+# CONFIG_ATALK is not set
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_PHONET is not set
+# CONFIG_IEEE802154 is not set
+# CONFIG_NET_SCHED is not set
+# CONFIG_DCB is not set
+CONFIG_DNS_RESOLVER=y
+# CONFIG_BATMAN_ADV is not set
+# CONFIG_OPENVSWITCH is not set
+# CONFIG_VSOCKETS is not set
+# CONFIG_NETLINK_DIAG is not set
+# CONFIG_MPLS is not set
+# CONFIG_HSR is not set
+# CONFIG_NET_SWITCHDEV is not set
+# CONFIG_NET_L3_MASTER_DEV is not set
+# CONFIG_NET_NCSI is not set
+# CONFIG_SOCK_CGROUP_DATA is not set
+# CONFIG_CGROUP_NET_PRIO is not set
+# CONFIG_CGROUP_NET_CLASSID is not set
+CONFIG_NET_RX_BUSY_POLL=y
+CONFIG_BQL=y
+# CONFIG_BPF_JIT is not set
+
+#
+# Network testing
+#
+# CONFIG_NET_PKTGEN is not set
+# CONFIG_HAMRADIO is not set
+# CONFIG_CAN is not set
+# CONFIG_IRDA is not set
+# CONFIG_BT is not set
+# CONFIG_AF_RXRPC is not set
+# CONFIG_AF_KCM is not set
+# CONFIG_STREAM_PARSER is not set
+CONFIG_FIB_RULES=y
+# CONFIG_WIRELESS is not set
+# CONFIG_WIMAX is not set
+# CONFIG_RFKILL is not set
+# CONFIG_RFKILL_REGULATOR is not set
+# CONFIG_NET_9P is not set
+# CONFIG_CAIF is not set
+# CONFIG_CEPH_LIB is not set
+# CONFIG_NFC is not set
+# CONFIG_LWTUNNEL is not set
+# CONFIG_DST_CACHE is not set
+# CONFIG_NET_DEVLINK is not set
+CONFIG_MAY_USE_DEVLINK=y
+CONFIG_HAVE_CBPF_JIT=y
+
+#
+# Device Drivers
+#
+CONFIG_ARM_AMBA=y
+
+#
+# Generic Driver Options
+#
+# CONFIG_UEVENT_HELPER is not set
+CONFIG_DEVTMPFS=y
+# CONFIG_DEVTMPFS_MOUNT is not set
+CONFIG_STANDALONE=y
+# CONFIG_PREVENT_FIRMWARE_BUILD is not set
+CONFIG_FW_LOADER=y
+CONFIG_FIRMWARE_IN_KERNEL=y
+CONFIG_EXTRA_FIRMWARE=""
+# CONFIG_FW_LOADER_USER_HELPER_FALLBACK is not set
+CONFIG_ALLOW_DEV_COREDUMP=y
+# CONFIG_DEBUG_DRIVER is not set
+# CONFIG_DEBUG_DEVRES is not set
+# CONFIG_DEBUG_TEST_DRIVER_REMOVE is not set
+# CONFIG_SYS_HYPERVISOR is not set
+# CONFIG_GENERIC_CPU_DEVICES is not set
+# CONFIG_DMA_SHARED_BUFFER is not set
+
+#
+# Bus devices
+#
+# CONFIG_BRCMSTB_GISB_ARB is not set
+# CONFIG_VEXPRESS_CONFIG is not set
+# CONFIG_CONNECTOR is not set
+CONFIG_MTD=y
+# CONFIG_MTD_TESTS is not set
+# CONFIG_MTD_REDBOOT_PARTS is not set
+CONFIG_MTD_CMDLINE_PARTS=y
+# CONFIG_MTD_AFS_PARTS is not set
+CONFIG_MTD_OF_PARTS=y
+# CONFIG_MTD_AR7_PARTS is not set
+
+#
+# User Modules And Translation Layers
+#
+CONFIG_MTD_BLKDEVS=y
+CONFIG_MTD_BLOCK=y
+# CONFIG_FTL is not set
+# CONFIG_NFTL is not set
+# CONFIG_INFTL is not set
+# CONFIG_RFD_FTL is not set
+# CONFIG_SSFDC is not set
+# CONFIG_SM_FTL is not set
+# CONFIG_MTD_OOPS is not set
+# CONFIG_MTD_SWAP is not set
+# CONFIG_MTD_PARTITIONED_MASTER is not set
+
+#
+# RAM/ROM/Flash chip drivers
+#
+# CONFIG_MTD_CFI is not set
+# CONFIG_MTD_JEDECPROBE is not set
+CONFIG_MTD_MAP_BANK_WIDTH_1=y
+CONFIG_MTD_MAP_BANK_WIDTH_2=y
+CONFIG_MTD_MAP_BANK_WIDTH_4=y
+# CONFIG_MTD_MAP_BANK_WIDTH_8 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_16 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_32 is not set
+CONFIG_MTD_CFI_I1=y
+CONFIG_MTD_CFI_I2=y
+# CONFIG_MTD_CFI_I4 is not set
+# CONFIG_MTD_CFI_I8 is not set
+# CONFIG_MTD_RAM is not set
+# CONFIG_MTD_ROM is not set
+# CONFIG_MTD_ABSENT is not set
+
+#
+# Mapping drivers for chip access
+#
+# CONFIG_MTD_COMPLEX_MAPPINGS is not set
+# CONFIG_MTD_PLATRAM is not set
+
+#
+# Self-contained MTD device drivers
+#
+# CONFIG_MTD_DATAFLASH is not set
+# CONFIG_MTD_M25P80 is not set
+# CONFIG_MTD_SST25L is not set
+# CONFIG_MTD_SLRAM is not set
+# CONFIG_MTD_PHRAM is not set
+# CONFIG_MTD_MTDRAM is not set
+# CONFIG_MTD_BLOCK2MTD is not set
+
+#
+# Disk-On-Chip Device Drivers
+#
+# CONFIG_MTD_DOCG3 is not set
+CONFIG_MTD_NAND_ECC=y
+# CONFIG_MTD_NAND_ECC_SMC is not set
+CONFIG_MTD_NAND=y
+# CONFIG_MTD_NAND_ECC_BCH is not set
+# CONFIG_MTD_SM_COMMON is not set
+# CONFIG_MTD_NAND_DENALI_DT is not set
+# CONFIG_MTD_NAND_OMAP_BCH_BUILD is not set
+CONFIG_MTD_NAND_IDS=y
+# CONFIG_MTD_NAND_DISKONCHIP is not set
+# CONFIG_MTD_NAND_DOCG4 is not set
+# CONFIG_MTD_NAND_NANDSIM is not set
+# CONFIG_MTD_NAND_BRCMNAND is not set
+# CONFIG_MTD_NAND_PLATFORM is not set
+# CONFIG_MTD_NAND_HISI504 is not set
+# CONFIG_MTD_NAND_MTK is not set
+# CONFIG_MTD_SPI_NAND_HISI_BVT is not set
+CONFIG_MTD_NAND_HINFC610=y
+CONFIG_HINFC610_MAX_CHIP=1
+CONFIG_HINFC610_DBG_NAND_DEBUG=y
+CONFIG_HINFC610_DBG_NAND_DUMP=y
+CONFIG_HINFC610_DBG_NAND_ERASE_COUNT=y
+CONFIG_HINFC610_DBG_NAND_ECC_COUNT=y
+CONFIG_HINFC610_DBG_NAND_READ_RETRY=y
+CONFIG_HINFC610_AUTO_PAGESIZE_ECC=y
+# CONFIG_HINFC610_PAGESIZE_AUTO_ECC_NONE is not set
+# CONFIG_MTD_ONENAND is not set
+
+#
+# LPDDR & LPDDR2 PCM memory drivers
+#
+# CONFIG_MTD_LPDDR is not set
+# CONFIG_MTD_LPDDR2_NVM is not set
+CONFIG_MTD_SPI_NOR=y
+# CONFIG_MTD_MT81xx_NOR is not set
+# CONFIG_MTD_SPI_NOR_USE_4K_SECTORS is not set
+# CONFIG_SPI_CADENCE_QUADSPI is not set
+# CONFIG_SPI_HISI_SFC is not set
+CONFIG_MTD_SPI_IDS=y
+CONFIG_CLOSE_SPI_8PIN_4IO=y
+CONFIG_MTD_HISFC350=y
+CONFIG_HISFC350_SYSCTRL_ADDRESS=0x20030000
+CONFIG_HISFC350_CHIP_NUM=2
+# CONFIG_HISFC350_SHOW_CYCLE_TIMING is not set
+# CONFIG_HISFC350_ENABLE_CHIPSELECT_0 is not set
+CONFIG_HISFC350_ENABLE_CHIPSELECT_1=y
+# CONFIG_HISFC350_ENABLE_INTR_DMA is not set
+CONFIG_CMD_SPI_BLOCK_PROTECTION=y
+# CONFIG_MTD_UBI is not set
+CONFIG_DTC=y
+CONFIG_OF=y
+# CONFIG_OF_UNITTEST is not set
+CONFIG_OF_FLATTREE=y
+CONFIG_OF_EARLY_FLATTREE=y
+CONFIG_OF_ADDRESS=y
+CONFIG_OF_IRQ=y
+CONFIG_OF_NET=y
+CONFIG_OF_MDIO=y
+CONFIG_OF_RESERVED_MEM=y
+# CONFIG_OF_OVERLAY is not set
+CONFIG_ARCH_MIGHT_HAVE_PC_PARPORT=y
+# CONFIG_PARPORT is not set
+CONFIG_BLK_DEV=y
+# CONFIG_BLK_DEV_NULL_BLK is not set
+# CONFIG_BLK_DEV_COW_COMMON is not set
+# CONFIG_BLK_DEV_LOOP is not set
+# CONFIG_BLK_DEV_DRBD is not set
+# CONFIG_BLK_DEV_NBD is not set
+CONFIG_BLK_DEV_RAM=y
+CONFIG_BLK_DEV_RAM_COUNT=16
+CONFIG_BLK_DEV_RAM_SIZE=65536
+# CONFIG_CDROM_PKTCDVD is not set
+# CONFIG_ATA_OVER_ETH is not set
+# CONFIG_BLK_DEV_RBD is not set
+# CONFIG_NVME_TARGET is not set
+
+#
+# Misc devices
+#
+# CONFIG_SENSORS_LIS3LV02D is not set
+# CONFIG_AD525X_DPOT is not set
+# CONFIG_DUMMY_IRQ is not set
+# CONFIG_ICS932S401 is not set
+# CONFIG_ENCLOSURE_SERVICES is not set
+# CONFIG_APDS9802ALS is not set
+# CONFIG_ISL29003 is not set
+# CONFIG_ISL29020 is not set
+# CONFIG_SENSORS_TSL2550 is not set
+# CONFIG_SENSORS_BH1770 is not set
+# CONFIG_SENSORS_APDS990X is not set
+# CONFIG_HMC6352 is not set
+# CONFIG_DS1682 is not set
+# CONFIG_TI_DAC7512 is not set
+# CONFIG_USB_SWITCH_FSA9480 is not set
+# CONFIG_LATTICE_ECP3_CONFIG is not set
+# CONFIG_SRAM is not set
+# CONFIG_C2PORT is not set
+
+#
+# EEPROM support
+#
+# CONFIG_EEPROM_AT24 is not set
+# CONFIG_EEPROM_AT25 is not set
+# CONFIG_EEPROM_LEGACY is not set
+# CONFIG_EEPROM_MAX6875 is not set
+# CONFIG_EEPROM_93CX6 is not set
+# CONFIG_EEPROM_93XX46 is not set
+
+#
+# Texas Instruments shared transport line discipline
+#
+# CONFIG_SENSORS_LIS3_SPI is not set
+# CONFIG_SENSORS_LIS3_I2C is not set
+
+#
+# Altera FPGA firmware download module
+#
+# CONFIG_ALTERA_STAPL is not set
+
+#
+# Intel MIC Bus Driver
+#
+
+#
+# SCIF Bus Driver
+#
+
+#
+# VOP Bus Driver
+#
+
+#
+# Intel MIC Host Driver
+#
+
+#
+# Intel MIC Card Driver
+#
+
+#
+# SCIF Driver
+#
+
+#
+# Intel MIC Coprocessor State Management (COSM) Drivers
+#
+
+#
+# VOP Driver
+#
+# CONFIG_ECHO is not set
+# CONFIG_CXL_BASE is not set
+# CONFIG_CXL_AFU_DRIVER_OPS is not set
+
+#
+# SCSI device support
+#
+CONFIG_SCSI_MOD=y
+# CONFIG_RAID_ATTRS is not set
+# CONFIG_SCSI is not set
+# CONFIG_SCSI_DMA is not set
+# CONFIG_SCSI_NETLINK is not set
+# CONFIG_ATA is not set
+# CONFIG_MD is not set
+CONFIG_NETDEVICES=y
+CONFIG_NET_CORE=y
+# CONFIG_BONDING is not set
+# CONFIG_DUMMY is not set
+# CONFIG_EQUALIZER is not set
+# CONFIG_NET_TEAM is not set
+# CONFIG_MACVLAN is not set
+# CONFIG_VXLAN is not set
+# CONFIG_MACSEC is not set
+# CONFIG_NETCONSOLE is not set
+# CONFIG_NETPOLL is not set
+# CONFIG_NET_POLL_CONTROLLER is not set
+# CONFIG_TUN is not set
+# CONFIG_TUN_VNET_CROSS_LE is not set
+# CONFIG_VETH is not set
+# CONFIG_NLMON is not set
+
+#
+# CAIF transport drivers
+#
+
+#
+# Distributed Switch Architecture drivers
+#
+CONFIG_ETHERNET=y
+# CONFIG_ALTERA_TSE is not set
+# CONFIG_NET_VENDOR_AMAZON is not set
+# CONFIG_NET_VENDOR_ARC is not set
+# CONFIG_NET_VENDOR_AURORA is not set
+# CONFIG_NET_CADENCE is not set
+# CONFIG_NET_VENDOR_BROADCOM is not set
+# CONFIG_NET_VENDOR_CIRRUS is not set
+# CONFIG_DM9000 is not set
+# CONFIG_DNET is not set
+# CONFIG_NET_VENDOR_EZCHIP is not set
+# CONFIG_NET_VENDOR_FARADAY is not set
+CONFIG_NET_VENDOR_HISILICON=y
+# CONFIG_HIX5HD2_GMAC is not set
+# CONFIG_HISI_FEMAC is not set
+# CONFIG_HIP04_ETH is not set
+# CONFIG_HNS is not set
+# CONFIG_HNS_DSAF is not set
+# CONFIG_HNS_ENET is not set
+CONFIG_HIETH_GMAC=y
+# CONFIG_HIGMAC_DESC_4WORD is not set
+# CONFIG_HIGMAC_RXCSUM is not set
+CONFIG_RX_FLOW_CTRL_SUPPORT=y
+CONFIG_TX_FLOW_CTRL_SUPPORT=y
+CONFIG_TX_FLOW_CTRL_PAUSE_TIME=0xFFFF
+CONFIG_TX_FLOW_CTRL_PAUSE_INTERVAL=0xFFFF
+CONFIG_TX_FLOW_CTRL_ACTIVE_THRESHOLD=16
+CONFIG_TX_FLOW_CTRL_DEACTIVE_THRESHOLD=32
+# CONFIG_NET_VENDOR_INTEL is not set
+# CONFIG_NET_VENDOR_MARVELL is not set
+# CONFIG_NET_VENDOR_MICREL is not set
+# CONFIG_NET_VENDOR_MICROCHIP is not set
+# CONFIG_NET_VENDOR_NATSEMI is not set
+# CONFIG_NET_VENDOR_NETRONOME is not set
+# CONFIG_ETHOC is not set
+# CONFIG_NET_VENDOR_QUALCOMM is not set
+# CONFIG_NET_VENDOR_RENESAS is not set
+# CONFIG_NET_VENDOR_ROCKER is not set
+# CONFIG_NET_VENDOR_SAMSUNG is not set
+# CONFIG_NET_VENDOR_SEEQ is not set
+# CONFIG_NET_VENDOR_SMSC is not set
+# CONFIG_NET_VENDOR_STMICRO is not set
+# CONFIG_NET_VENDOR_SYNOPSYS is not set
+# CONFIG_NET_VENDOR_VIA is not set
+# CONFIG_NET_VENDOR_WIZNET is not set
+CONFIG_PHYLIB=y
+CONFIG_SWPHY=y
+
+#
+# MDIO bus device drivers
+#
+# CONFIG_MDIO_BCM_UNIMAC is not set
+# CONFIG_MDIO_BITBANG is not set
+# CONFIG_MDIO_BUS_MUX_MMIOREG is not set
+# CONFIG_MDIO_HISI_FEMAC is not set
+CONFIG_MDIO_HISI_GEMAC=y
+
+#
+# MII PHY device drivers
+#
+# CONFIG_AMD_PHY is not set
+# CONFIG_AQUANTIA_PHY is not set
+# CONFIG_AT803X_PHY is not set
+# CONFIG_BCM7XXX_PHY is not set
+# CONFIG_BCM87XX_PHY is not set
+# CONFIG_BROADCOM_PHY is not set
+# CONFIG_CICADA_PHY is not set
+# CONFIG_DAVICOM_PHY is not set
+# CONFIG_DP83848_PHY is not set
+# CONFIG_DP83867_PHY is not set
+CONFIG_FIXED_PHY=y
+# CONFIG_ICPLUS_PHY is not set
+# CONFIG_INTEL_XWAY_PHY is not set
+# CONFIG_LSI_ET1011C_PHY is not set
+# CONFIG_LXT_PHY is not set
+# CONFIG_MARVELL_PHY is not set
+# CONFIG_MICREL_PHY is not set
+# CONFIG_MICROCHIP_PHY is not set
+# CONFIG_MICROSEMI_PHY is not set
+# CONFIG_NATIONAL_PHY is not set
+# CONFIG_QSEMI_PHY is not set
+# CONFIG_REALTEK_PHY is not set
+# CONFIG_SMSC_PHY is not set
+# CONFIG_STE10XP is not set
+# CONFIG_TERANETICS_PHY is not set
+# CONFIG_VITESSE_PHY is not set
+# CONFIG_XILINX_GMII2RGMII is not set
+# CONFIG_MICREL_KS8995MA is not set
+# CONFIG_PPP is not set
+# CONFIG_SLIP is not set
+
+#
+# Host-side USB support is needed for USB Network Adapter support
+#
+# CONFIG_WLAN is not set
+
+#
+# Enable WiMAX (Networking options) to see the WiMAX drivers
+#
+# CONFIG_WAN is not set
+# CONFIG_ISDN is not set
+# CONFIG_NVM is not set
+
+#
+# Input device support
+#
+CONFIG_INPUT=y
+# CONFIG_INPUT_FF_MEMLESS is not set
+# CONFIG_INPUT_POLLDEV is not set
+# CONFIG_INPUT_SPARSEKMAP is not set
+# CONFIG_INPUT_MATRIXKMAP is not set
+
+#
+# Userland interfaces
+#
+CONFIG_INPUT_MOUSEDEV=y
+CONFIG_INPUT_MOUSEDEV_PSAUX=y
+CONFIG_INPUT_MOUSEDEV_SCREEN_X=1024
+CONFIG_INPUT_MOUSEDEV_SCREEN_Y=768
+# CONFIG_INPUT_JOYDEV is not set
+CONFIG_INPUT_EVDEV=y
+# CONFIG_INPUT_EVBUG is not set
+
+#
+# Input Device Drivers
+#
+CONFIG_INPUT_KEYBOARD=y
+# CONFIG_KEYBOARD_ADP5588 is not set
+# CONFIG_KEYBOARD_ADP5589 is not set
+CONFIG_KEYBOARD_ATKBD=y
+# CONFIG_KEYBOARD_QT1070 is not set
+# CONFIG_KEYBOARD_QT2160 is not set
+# CONFIG_KEYBOARD_LKKBD is not set
+# CONFIG_KEYBOARD_TCA6416 is not set
+# CONFIG_KEYBOARD_TCA8418 is not set
+# CONFIG_KEYBOARD_LM8333 is not set
+# CONFIG_KEYBOARD_MAX7359 is not set
+# CONFIG_KEYBOARD_MCS is not set
+# CONFIG_KEYBOARD_MPR121 is not set
+# CONFIG_KEYBOARD_NEWTON is not set
+# CONFIG_KEYBOARD_OPENCORES is not set
+# CONFIG_KEYBOARD_SAMSUNG is not set
+# CONFIG_KEYBOARD_STOWAWAY is not set
+# CONFIG_KEYBOARD_SUNKBD is not set
+# CONFIG_KEYBOARD_OMAP4 is not set
+# CONFIG_KEYBOARD_XTKBD is not set
+# CONFIG_KEYBOARD_CAP11XX is not set
+# CONFIG_KEYBOARD_BCM is not set
+CONFIG_INPUT_MOUSE=y
+CONFIG_MOUSE_PS2=y
+CONFIG_MOUSE_PS2_ALPS=y
+CONFIG_MOUSE_PS2_BYD=y
+CONFIG_MOUSE_PS2_LOGIPS2PP=y
+CONFIG_MOUSE_PS2_SYNAPTICS=y
+CONFIG_MOUSE_PS2_CYPRESS=y
+CONFIG_MOUSE_PS2_TRACKPOINT=y
+# CONFIG_MOUSE_PS2_ELANTECH is not set
+# CONFIG_MOUSE_PS2_SENTELIC is not set
+# CONFIG_MOUSE_PS2_TOUCHKIT is not set
+CONFIG_MOUSE_PS2_FOCALTECH=y
+# CONFIG_MOUSE_SERIAL is not set
+# CONFIG_MOUSE_CYAPA is not set
+# CONFIG_MOUSE_ELAN_I2C is not set
+# CONFIG_MOUSE_VSXXXAA is not set
+# CONFIG_MOUSE_SYNAPTICS_I2C is not set
+# CONFIG_INPUT_JOYSTICK is not set
+# CONFIG_INPUT_TABLET is not set
+# CONFIG_INPUT_TOUCHSCREEN is not set
+CONFIG_INPUT_MISC=y
+# CONFIG_INPUT_AD714X is not set
+# CONFIG_INPUT_ATMEL_CAPTOUCH is not set
+# CONFIG_INPUT_BMA150 is not set
+# CONFIG_INPUT_E3X0_BUTTON is not set
+# CONFIG_INPUT_MMA8450 is not set
+# CONFIG_INPUT_MPU3050 is not set
+# CONFIG_INPUT_KXTJ9 is not set
+# CONFIG_INPUT_REGULATOR_HAPTIC is not set
+CONFIG_INPUT_UINPUT=y
+# CONFIG_INPUT_PCF8574 is not set
+# CONFIG_INPUT_ADXL34X is not set
+# CONFIG_INPUT_CMA3000 is not set
+# CONFIG_INPUT_DRV2665_HAPTICS is not set
+# CONFIG_INPUT_DRV2667_HAPTICS is not set
+# CONFIG_RMI4_CORE is not set
+
+#
+# Hardware I/O ports
+#
+CONFIG_SERIO=y
+CONFIG_SERIO_SERPORT=y
+# CONFIG_SERIO_AMBAKMI is not set
+CONFIG_SERIO_LIBPS2=y
+# CONFIG_SERIO_RAW is not set
+# CONFIG_SERIO_ALTERA_PS2 is not set
+# CONFIG_SERIO_PS2MULT is not set
+# CONFIG_SERIO_ARC_PS2 is not set
+# CONFIG_SERIO_APBPS2 is not set
+# CONFIG_USERIO is not set
+# CONFIG_GAMEPORT is not set
+
+#
+# Character devices
+#
+CONFIG_TTY=y
+CONFIG_VT=y
+CONFIG_CONSOLE_TRANSLATIONS=y
+CONFIG_VT_CONSOLE=y
+CONFIG_VT_CONSOLE_SLEEP=y
+CONFIG_HW_CONSOLE=y
+# CONFIG_VT_HW_CONSOLE_BINDING is not set
+CONFIG_UNIX98_PTYS=y
+# CONFIG_LEGACY_PTYS is not set
+# CONFIG_SERIAL_NONSTANDARD is not set
+# CONFIG_N_GSM is not set
+# CONFIG_TRACE_SINK is not set
+CONFIG_DEVMEM=y
+# CONFIG_DEVKMEM is not set
+
+#
+# Serial drivers
+#
+CONFIG_SERIAL_EARLYCON=y
+# CONFIG_SERIAL_8250 is not set
+
+#
+# Non-8250 serial port support
+#
+# CONFIG_SERIAL_AMBA_PL010 is not set
+CONFIG_SERIAL_AMBA_PL011=y
+CONFIG_SERIAL_AMBA_PL011_CONSOLE=y
+# CONFIG_SERIAL_EARLYCON_ARM_SEMIHOST is not set
+# CONFIG_SERIAL_MAX3100 is not set
+# CONFIG_SERIAL_MAX310X is not set
+# CONFIG_SERIAL_UARTLITE is not set
+CONFIG_SERIAL_CORE=y
+CONFIG_SERIAL_CORE_CONSOLE=y
+# CONFIG_SERIAL_SCCNXP is not set
+# CONFIG_SERIAL_SC16IS7XX is not set
+# CONFIG_SERIAL_BCM63XX is not set
+# CONFIG_SERIAL_ALTERA_JTAGUART is not set
+# CONFIG_SERIAL_ALTERA_UART is not set
+# CONFIG_SERIAL_XILINX_PS_UART is not set
+# CONFIG_SERIAL_ARC is not set
+# CONFIG_SERIAL_FSL_LPUART is not set
+# CONFIG_SERIAL_CONEXANT_DIGICOLOR is not set
+# CONFIG_SERIAL_ST_ASC is not set
+# CONFIG_SERIAL_STM32 is not set
+# CONFIG_HVC_DCC is not set
+# CONFIG_IPMI_HANDLER is not set
+# CONFIG_HW_RANDOM is not set
+# CONFIG_R3964 is not set
+# CONFIG_RAW_DRIVER is not set
+# CONFIG_TCG_TPM is not set
+# CONFIG_XILLYBUS is not set
+
+#
+# I2C support
+#
+CONFIG_I2C=y
+CONFIG_I2C_BOARDINFO=y
+CONFIG_I2C_COMPAT=y
+CONFIG_I2C_CHARDEV=y
+# CONFIG_I2C_MUX is not set
+CONFIG_I2C_HELPER_AUTO=y
+
+#
+# I2C Hardware Bus support
+#
+
+#
+# I2C system bus drivers (mostly embedded / system-on-chip)
+#
+# CONFIG_I2C_DESIGNWARE_PLATFORM is not set
+# CONFIG_I2C_EMEV2 is not set
+# CONFIG_I2C_HIBVT is not set
+# CONFIG_I2C_NOMADIK is not set
+# CONFIG_I2C_OCORES is not set
+# CONFIG_I2C_PCA_PLATFORM is not set
+# CONFIG_I2C_PXA_PCI is not set
+# CONFIG_I2C_RK3X is not set
+# CONFIG_I2C_SIMTEC is not set
+# CONFIG_I2C_XILINX is not set
+
+#
+# External I2C/SMBus adapter drivers
+#
+# CONFIG_I2C_PARPORT_LIGHT is not set
+# CONFIG_I2C_TAOS_EVM is not set
+
+#
+# Other I2C/SMBus bus drivers
+#
+CONFIG_I2C_HISI=y
+# CONFIG_I2C_STUB is not set
+# CONFIG_I2C_SLAVE is not set
+# CONFIG_I2C_DEBUG_CORE is not set
+# CONFIG_I2C_DEBUG_ALGO is not set
+# CONFIG_I2C_DEBUG_BUS is not set
+CONFIG_SPI=y
+# CONFIG_SPI_DEBUG is not set
+CONFIG_SPI_MASTER=y
+
+#
+# SPI Master Controller Drivers
+#
+# CONFIG_SPI_ALTERA is not set
+# CONFIG_SPI_AXI_SPI_ENGINE is not set
+# CONFIG_SPI_BITBANG is not set
+# CONFIG_SPI_CADENCE is not set
+# CONFIG_SPI_DESIGNWARE is not set
+# CONFIG_SPI_FSL_SPI is not set
+CONFIG_SPI_PL022=y
+# CONFIG_SPI_PXA2XX_PCI is not set
+# CONFIG_SPI_ROCKCHIP is not set
+# CONFIG_SPI_SC18IS602 is not set
+# CONFIG_SPI_XCOMM is not set
+# CONFIG_SPI_XILINX is not set
+# CONFIG_SPI_ZYNQMP_GQSPI is not set
+
+#
+# SPI Protocol Masters
+#
+CONFIG_SPI_SPIDEV=y
+# CONFIG_SPI_LOOPBACK_TEST is not set
+# CONFIG_SPI_TLE62X0 is not set
+# CONFIG_SPMI is not set
+# CONFIG_HSI is not set
+
+#
+# PPS support
+#
+# CONFIG_PPS is not set
+
+#
+# PPS generators support
+#
+
+#
+# PTP clock support
+#
+# CONFIG_PTP_1588_CLOCK is not set
+
+#
+# Enable PHYLIB and NETWORK_PHY_TIMESTAMPING to see the additional clocks.
+#
+CONFIG_ARCH_HAVE_CUSTOM_GPIO_H=y
+# CONFIG_GPIOLIB is not set
+# CONFIG_W1 is not set
+# CONFIG_POWER_AVS is not set
+CONFIG_POWER_RESET=y
+# CONFIG_POWER_RESET_BRCMKONA is not set
+CONFIG_POWER_RESET_HISI=y
+# CONFIG_POWER_RESET_RESTART is not set
+# CONFIG_POWER_RESET_SYSCON is not set
+# CONFIG_POWER_RESET_SYSCON_POWEROFF is not set
+CONFIG_POWER_SUPPLY=y
+# CONFIG_POWER_SUPPLY_DEBUG is not set
+# CONFIG_PDA_POWER is not set
+# CONFIG_TEST_POWER is not set
+# CONFIG_BATTERY_DS2780 is not set
+# CONFIG_BATTERY_DS2781 is not set
+# CONFIG_BATTERY_DS2782 is not set
+# CONFIG_BATTERY_SBS is not set
+# CONFIG_BATTERY_BQ27XXX is not set
+# CONFIG_BATTERY_MAX17040 is not set
+# CONFIG_BATTERY_MAX17042 is not set
+# CONFIG_CHARGER_MAX8903 is not set
+# CONFIG_CHARGER_LP8727 is not set
+# CONFIG_CHARGER_MANAGER is not set
+# CONFIG_CHARGER_BQ2415X is not set
+# CONFIG_CHARGER_SMB347 is not set
+# CONFIG_BATTERY_GAUGE_LTC2941 is not set
+# CONFIG_HWMON is not set
+# CONFIG_THERMAL is not set
+# CONFIG_WATCHDOG is not set
+CONFIG_SSB_POSSIBLE=y
+
+#
+# Sonics Silicon Backplane
+#
+# CONFIG_SSB is not set
+CONFIG_BCMA_POSSIBLE=y
+
+#
+# Broadcom specific AMBA
+#
+# CONFIG_BCMA is not set
+
+#
+# Multifunction device drivers
+#
+# CONFIG_MFD_CORE is not set
+# CONFIG_MFD_ACT8945A is not set
+# CONFIG_MFD_AS3711 is not set
+# CONFIG_MFD_AS3722 is not set
+# CONFIG_PMIC_ADP5520 is not set
+# CONFIG_MFD_ATMEL_FLEXCOM is not set
+# CONFIG_MFD_ATMEL_HLCDC is not set
+# CONFIG_MFD_BCM590XX is not set
+# CONFIG_MFD_AXP20X_I2C is not set
+# CONFIG_MFD_CROS_EC is not set
+# CONFIG_PMIC_DA903X is not set
+# CONFIG_MFD_DA9052_SPI is not set
+# CONFIG_MFD_DA9052_I2C is not set
+# CONFIG_MFD_DA9055 is not set
+# CONFIG_MFD_DA9062 is not set
+# CONFIG_MFD_DA9063 is not set
+# CONFIG_MFD_DA9150 is not set
+# CONFIG_MFD_EXYNOS_LPASS is not set
+# CONFIG_MFD_MC13XXX_SPI is not set
+# CONFIG_MFD_MC13XXX_I2C is not set
+# CONFIG_MFD_HI6421_PMIC is not set
+# CONFIG_MFD_HISI_FMC is not set
+# CONFIG_HTC_PASIC3 is not set
+# CONFIG_MFD_KEMPLD is not set
+# CONFIG_MFD_88PM800 is not set
+# CONFIG_MFD_88PM805 is not set
+# CONFIG_MFD_88PM860X is not set
+# CONFIG_MFD_MAX14577 is not set
+# CONFIG_MFD_MAX77620 is not set
+# CONFIG_MFD_MAX77686 is not set
+# CONFIG_MFD_MAX77693 is not set
+# CONFIG_MFD_MAX77843 is not set
+# CONFIG_MFD_MAX8907 is not set
+# CONFIG_MFD_MAX8925 is not set
+# CONFIG_MFD_MAX8997 is not set
+# CONFIG_MFD_MAX8998 is not set
+# CONFIG_MFD_MT6397 is not set
+# CONFIG_MFD_MENF21BMC is not set
+# CONFIG_EZX_PCAP is not set
+# CONFIG_MFD_RETU is not set
+# CONFIG_MFD_PCF50633 is not set
+# CONFIG_MFD_PM8921_CORE is not set
+# CONFIG_MFD_RT5033 is not set
+# CONFIG_MFD_RC5T583 is not set
+# CONFIG_MFD_RK808 is not set
+# CONFIG_MFD_RN5T618 is not set
+# CONFIG_MFD_SEC_CORE is not set
+# CONFIG_MFD_SI476X_CORE is not set
+# CONFIG_MFD_SM501 is not set
+# CONFIG_MFD_SKY81452 is not set
+# CONFIG_MFD_SMSC is not set
+# CONFIG_ABX500_CORE is not set
+# CONFIG_MFD_STMPE is not set
+# CONFIG_MFD_SYSCON is not set
+# CONFIG_MFD_TI_AM335X_TSCADC is not set
+# CONFIG_MFD_LP3943 is not set
+# CONFIG_MFD_LP8788 is not set
+# CONFIG_MFD_PALMAS is not set
+# CONFIG_TPS6105X is not set
+# CONFIG_TPS6507X is not set
+# CONFIG_MFD_TPS65086 is not set
+# CONFIG_MFD_TPS65090 is not set
+# CONFIG_MFD_TPS65217 is not set
+# CONFIG_MFD_TI_LP873X is not set
+# CONFIG_MFD_TPS65218 is not set
+# CONFIG_MFD_TPS6586X is not set
+# CONFIG_MFD_TPS65912_I2C is not set
+# CONFIG_MFD_TPS65912_SPI is not set
+# CONFIG_MFD_TPS80031 is not set
+# CONFIG_TWL4030_CORE is not set
+# CONFIG_TWL6040_CORE is not set
+# CONFIG_MFD_WL1273_CORE is not set
+# CONFIG_MFD_LM3533 is not set
+# CONFIG_MFD_TC3589X is not set
+# CONFIG_MFD_TMIO is not set
+# CONFIG_MFD_T7L66XB is not set
+# CONFIG_MFD_TC6387XB is not set
+# CONFIG_MFD_TC6393XB is not set
+# CONFIG_MFD_ARIZONA_I2C is not set
+# CONFIG_MFD_ARIZONA_SPI is not set
+# CONFIG_MFD_WM8400 is not set
+# CONFIG_MFD_WM831X_I2C is not set
+# CONFIG_MFD_WM831X_SPI is not set
+# CONFIG_MFD_WM8350_I2C is not set
+# CONFIG_MFD_WM8994 is not set
+CONFIG_REGULATOR=y
+# CONFIG_REGULATOR_DEBUG is not set
+# CONFIG_REGULATOR_FIXED_VOLTAGE is not set
+# CONFIG_REGULATOR_VIRTUAL_CONSUMER is not set
+# CONFIG_REGULATOR_USERSPACE_CONSUMER is not set
+# CONFIG_REGULATOR_ACT8865 is not set
+# CONFIG_REGULATOR_AD5398 is not set
+# CONFIG_REGULATOR_DA9210 is not set
+# CONFIG_REGULATOR_DA9211 is not set
+# CONFIG_REGULATOR_FAN53555 is not set
+# CONFIG_REGULATOR_ISL9305 is not set
+# CONFIG_REGULATOR_ISL6271A is not set
+# CONFIG_REGULATOR_LP3971 is not set
+# CONFIG_REGULATOR_LP3972 is not set
+# CONFIG_REGULATOR_LP872X is not set
+# CONFIG_REGULATOR_LP8755 is not set
+# CONFIG_REGULATOR_LTC3589 is not set
+# CONFIG_REGULATOR_LTC3676 is not set
+# CONFIG_REGULATOR_MAX1586 is not set
+# CONFIG_REGULATOR_MAX8649 is not set
+# CONFIG_REGULATOR_MAX8660 is not set
+# CONFIG_REGULATOR_MAX8952 is not set
+# CONFIG_REGULATOR_MT6311 is not set
+# CONFIG_REGULATOR_PFUZE100 is not set
+# CONFIG_REGULATOR_PV88060 is not set
+# CONFIG_REGULATOR_PV88080 is not set
+# CONFIG_REGULATOR_PV88090 is not set
+# CONFIG_REGULATOR_TPS51632 is not set
+# CONFIG_REGULATOR_TPS62360 is not set
+# CONFIG_REGULATOR_TPS65023 is not set
+# CONFIG_REGULATOR_TPS6507X is not set
+# CONFIG_REGULATOR_TPS6524X is not set
+# CONFIG_MEDIA_SUPPORT is not set
+
+#
+# Graphics support
+#
+# CONFIG_IMX_IPUV3_CORE is not set
+# CONFIG_DRM is not set
+
+#
+# ACP (Audio CoProcessor) Configuration
+#
+
+#
+# Frame buffer Devices
+#
+CONFIG_FB=y
+# CONFIG_FIRMWARE_EDID is not set
+CONFIG_FB_CMDLINE=y
+CONFIG_FB_NOTIFY=y
+# CONFIG_FB_DDC is not set
+# CONFIG_FB_BOOT_VESA_SUPPORT is not set
+# CONFIG_FB_CFB_FILLRECT is not set
+# CONFIG_FB_CFB_COPYAREA is not set
+# CONFIG_FB_CFB_IMAGEBLIT is not set
+# CONFIG_FB_CFB_REV_PIXELS_IN_BYTE is not set
+# CONFIG_FB_SYS_FILLRECT is not set
+# CONFIG_FB_SYS_COPYAREA is not set
+# CONFIG_FB_SYS_IMAGEBLIT is not set
+# CONFIG_FB_FOREIGN_ENDIAN is not set
+# CONFIG_FB_SYS_FOPS is not set
+# CONFIG_FB_SVGALIB is not set
+# CONFIG_FB_MACMODES is not set
+# CONFIG_FB_BACKLIGHT is not set
+# CONFIG_FB_MODE_HELPERS is not set
+# CONFIG_FB_TILEBLITTING is not set
+
+#
+# Frame buffer hardware drivers
+#
+# CONFIG_FB_ARMCLCD is not set
+# CONFIG_FB_OPENCORES is not set
+# CONFIG_FB_S1D13XXX is not set
+# CONFIG_FB_IBM_GXT4500 is not set
+# CONFIG_FB_VIRTUAL is not set
+# CONFIG_FB_METRONOME is not set
+# CONFIG_FB_BROADSHEET is not set
+# CONFIG_FB_AUO_K190X is not set
+# CONFIG_FB_SIMPLE is not set
+# CONFIG_BACKLIGHT_LCD_SUPPORT is not set
+# CONFIG_VGASTATE is not set
+
+#
+# Console display driver support
+#
+CONFIG_DUMMY_CONSOLE=y
+# CONFIG_FRAMEBUFFER_CONSOLE is not set
+# CONFIG_LOGO is not set
+# CONFIG_SOUND is not set
+
+#
+# HID support
+#
+# CONFIG_HID is not set
+
+#
+# I2C HID support
+#
+# CONFIG_I2C_HID is not set
+CONFIG_USB_OHCI_LITTLE_ENDIAN=y
+# CONFIG_USB_SUPPORT is not set
+# CONFIG_UWB is not set
+# CONFIG_MMC is not set
+# CONFIG_MEMSTICK is not set
+# CONFIG_NEW_LEDS is not set
+# CONFIG_ACCESSIBILITY is not set
+CONFIG_EDAC_ATOMIC_SCRUB=y
+CONFIG_EDAC_SUPPORT=y
+# CONFIG_EDAC is not set
+CONFIG_RTC_LIB=y
+# CONFIG_RTC_CLASS is not set
+# CONFIG_DMADEVICES is not set
+
+#
+# DMABUF options
+#
+# CONFIG_SYNC_FILE is not set
+# CONFIG_AUXDISPLAY is not set
+# CONFIG_UIO is not set
+# CONFIG_VIRT_DRIVERS is not set
+
+#
+# Virtio drivers
+#
+# CONFIG_VIRTIO_MMIO is not set
+
+#
+# Microsoft Hyper-V guest support
+#
+# CONFIG_STAGING is not set
+# CONFIG_GOLDFISH is not set
+# CONFIG_CHROME_PLATFORMS is not set
+CONFIG_CLKDEV_LOOKUP=y
+CONFIG_HAVE_CLK_PREPARE=y
+CONFIG_COMMON_CLK=y
+
+#
+# Common Clock Framework
+#
+# CONFIG_COMMON_CLK_SI5351 is not set
+# CONFIG_COMMON_CLK_SI514 is not set
+# CONFIG_COMMON_CLK_SI570 is not set
+# CONFIG_COMMON_CLK_CDCE706 is not set
+# CONFIG_COMMON_CLK_CDCE925 is not set
+# CONFIG_COMMON_CLK_CS2000_CP is not set
+# CONFIG_CLK_QORIQ is not set
+# CONFIG_COMMON_CLK_NXP is not set
+# CONFIG_COMMON_CLK_PXA is not set
+# CONFIG_COMMON_CLK_PIC32 is not set
+CONFIG_COMMON_CLK_HI3516A=y
+CONFIG_RESET_HISI=y
+
+#
+# Hardware Spinlock drivers
+#
+
+#
+# Clock Source drivers
+#
+CONFIG_CLKSRC_OF=y
+CONFIG_CLKSRC_PROBE=y
+CONFIG_CLKSRC_MMIO=y
+CONFIG_ARM_ARCH_TIMER=y
+CONFIG_ARM_ARCH_TIMER_EVTSTREAM=y
+CONFIG_ARM_TIMER_SP804=y
+# CONFIG_ATMEL_PIT is not set
+# CONFIG_SH_TIMER_CMT is not set
+# CONFIG_SH_TIMER_MTU2 is not set
+# CONFIG_SH_TIMER_TMU is not set
+# CONFIG_EM_TIMER_STI is not set
+# CONFIG_MAILBOX is not set
+# CONFIG_IOMMU_SUPPORT is not set
+
+#
+# Remoteproc drivers
+#
+# CONFIG_STE_MODEM_RPROC is not set
+
+#
+# Rpmsg drivers
+#
+
+#
+# SOC (System On Chip) specific Drivers
+#
+
+#
+# Broadcom SoC drivers
+#
+# CONFIG_SOC_BRCMSTB is not set
+# CONFIG_SUNXI_SRAM is not set
+# CONFIG_SOC_TI is not set
+# CONFIG_PM_DEVFREQ is not set
+# CONFIG_EXTCON is not set
+# CONFIG_MEMORY is not set
+# CONFIG_IIO is not set
+# CONFIG_PWM is not set
+CONFIG_IRQCHIP=y
+CONFIG_ARM_GIC=y
+CONFIG_ARM_GIC_MAX_NR=1
+# CONFIG_IPACK_BUS is not set
+CONFIG_ARCH_HAS_RESET_CONTROLLER=y
+CONFIG_RESET_CONTROLLER=y
+# CONFIG_RESET_ATH79 is not set
+# CONFIG_RESET_BERLIN is not set
+# CONFIG_RESET_LPC18XX is not set
+# CONFIG_RESET_MESON is not set
+# CONFIG_RESET_PISTACHIO is not set
+# CONFIG_RESET_SOCFPGA is not set
+# CONFIG_RESET_STM32 is not set
+# CONFIG_RESET_SUNXI is not set
+# CONFIG_TI_SYSCON_RESET is not set
+# CONFIG_RESET_ZYNQ is not set
+# CONFIG_FMC is not set
+
+#
+# PHY Subsystem
+#
+CONFIG_GENERIC_PHY=y
+# CONFIG_PHY_PXA_28NM_HSIC is not set
+# CONFIG_PHY_PXA_28NM_USB2 is not set
+# CONFIG_BCM_KONA_USB2_PHY is not set
+CONFIG_PHY_HISI_USB2=y
+# CONFIG_POWERCAP is not set
+# CONFIG_MCB is not set
+
+#
+# Performance monitor support
+#
+# CONFIG_RAS is not set
+
+#
+# Android
+#
+# CONFIG_ANDROID is not set
+# CONFIG_NVMEM is not set
+# CONFIG_STM is not set
+# CONFIG_INTEL_TH is not set
+
+#
+# FPGA Configuration Support
+#
+# CONFIG_FPGA is not set
+CONFIG_HI_DMAC=y
+CONFIG_HI_DMAC_CHANNEL_NUM=4
+
+#
+# Firmware Drivers
+#
+# CONFIG_FIRMWARE_MEMMAP is not set
+# CONFIG_FW_CFG_SYSFS is not set
+CONFIG_HAVE_ARM_SMCCC=y
+
+#
+# File systems
+#
+CONFIG_DCACHE_WORD_ACCESS=y
+# CONFIG_EXT2_FS is not set
+# CONFIG_EXT3_FS is not set
+CONFIG_EXT4_FS=y
+CONFIG_EXT4_USE_FOR_EXT2=y
+# CONFIG_EXT4_FS_POSIX_ACL is not set
+# CONFIG_EXT4_FS_SECURITY is not set
+# CONFIG_EXT4_ENCRYPTION is not set
+# CONFIG_EXT4_DEBUG is not set
+CONFIG_JBD2=y
+# CONFIG_JBD2_DEBUG is not set
+CONFIG_FS_MBCACHE=y
+# CONFIG_REISERFS_FS is not set
+# CONFIG_JFS_FS is not set
+# CONFIG_XFS_FS is not set
+# CONFIG_GFS2_FS is not set
+# CONFIG_OCFS2_FS is not set
+# CONFIG_BTRFS_FS is not set
+# CONFIG_NILFS2_FS is not set
+# CONFIG_F2FS_FS is not set
+CONFIG_FS_POSIX_ACL=y
+CONFIG_EXPORTFS=y
+# CONFIG_EXPORTFS_BLOCK_OPS is not set
+CONFIG_FILE_LOCKING=y
+CONFIG_MANDATORY_FILE_LOCKING=y
+# CONFIG_FS_ENCRYPTION is not set
+CONFIG_FSNOTIFY=y
+CONFIG_DNOTIFY=y
+CONFIG_INOTIFY_USER=y
+# CONFIG_FANOTIFY is not set
+# CONFIG_QUOTA is not set
+# CONFIG_QUOTACTL is not set
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_FUSE_FS is not set
+# CONFIG_OVERLAY_FS is not set
+
+#
+# Caches
+#
+# CONFIG_FSCACHE is not set
+
+#
+# CD-ROM/DVD Filesystems
+#
+# CONFIG_ISO9660_FS is not set
+# CONFIG_UDF_FS is not set
+
+#
+# DOS/FAT/NT Filesystems
+#
+CONFIG_FAT_FS=y
+CONFIG_MSDOS_FS=y
+CONFIG_VFAT_FS=y
+CONFIG_FAT_DEFAULT_CODEPAGE=437
+CONFIG_FAT_DEFAULT_IOCHARSET="iso8859-1"
+# CONFIG_FAT_DEFAULT_UTF8 is not set
+# CONFIG_NTFS_FS is not set
+
+#
+# Pseudo filesystems
+#
+CONFIG_PROC_FS=y
+CONFIG_PROC_SYSCTL=y
+CONFIG_PROC_PAGE_MONITOR=y
+# CONFIG_PROC_CHILDREN is not set
+CONFIG_KERNFS=y
+CONFIG_SYSFS=y
+CONFIG_TMPFS=y
+# CONFIG_TMPFS_POSIX_ACL is not set
+# CONFIG_TMPFS_XATTR is not set
+# CONFIG_HUGETLB_PAGE is not set
+CONFIG_CONFIGFS_FS=m
+CONFIG_MISC_FILESYSTEMS=y
+# CONFIG_ORANGEFS_FS is not set
+# CONFIG_ADFS_FS is not set
+# CONFIG_AFFS_FS is not set
+# CONFIG_ECRYPT_FS is not set
+# CONFIG_HFS_FS is not set
+# CONFIG_HFSPLUS_FS is not set
+# CONFIG_BEFS_FS is not set
+# CONFIG_BFS_FS is not set
+# CONFIG_EFS_FS is not set
+CONFIG_YAFFS_FS=y
+CONFIG_YAFFS_YAFFS1=y
+# CONFIG_YAFFS_9BYTE_TAGS is not set
+# CONFIG_YAFFS_DOES_ECC is not set
+CONFIG_YAFFS_YAFFS2=y
+CONFIG_YAFFS_AUTO_YAFFS2=y
+# CONFIG_YAFFS_DISABLE_TAGS_ECC is not set
+# CONFIG_YAFFS_ALWAYS_CHECK_CHUNK_ERASED is not set
+# CONFIG_YAFFS_EMPTY_LOST_AND_FOUND is not set
+# CONFIG_YAFFS_DISABLE_BLOCK_REFRESHING is not set
+# CONFIG_YAFFS_DISABLE_BACKGROUND is not set
+# CONFIG_YAFFS_DISABLE_BAD_BLOCK_MARKING is not set
+CONFIG_YAFFS_XATTR=y
+CONFIG_JFFS2_FS=y
+CONFIG_JFFS2_FS_DEBUG=0
+CONFIG_JFFS2_FS_WRITEBUFFER=y
+# CONFIG_JFFS2_FS_WBUF_VERIFY is not set
+# CONFIG_JFFS2_SUMMARY is not set
+# CONFIG_JFFS2_FS_XATTR is not set
+# CONFIG_JFFS2_COMPRESSION_OPTIONS is not set
+CONFIG_JFFS2_ZLIB=y
+# CONFIG_JFFS2_LZO is not set
+CONFIG_JFFS2_RTIME=y
+# CONFIG_JFFS2_RUBIN is not set
+# CONFIG_LOGFS is not set
+CONFIG_CRAMFS=y
+# CONFIG_SQUASHFS is not set
+# CONFIG_VXFS_FS is not set
+# CONFIG_MINIX_FS is not set
+# CONFIG_OMFS_FS is not set
+# CONFIG_HPFS_FS is not set
+# CONFIG_QNX4FS_FS is not set
+# CONFIG_QNX6FS_FS is not set
+# CONFIG_ROMFS_FS is not set
+# CONFIG_PSTORE is not set
+# CONFIG_SYSV_FS is not set
+# CONFIG_UFS_FS is not set
+CONFIG_NETWORK_FILESYSTEMS=y
+CONFIG_NFS_FS=y
+CONFIG_NFS_V2=y
+CONFIG_NFS_V3=y
+CONFIG_NFS_V3_ACL=y
+CONFIG_NFS_V4=y
+# CONFIG_NFS_SWAP is not set
+# CONFIG_NFS_V4_1 is not set
+CONFIG_ROOT_NFS=y
+# CONFIG_NFS_USE_LEGACY_DNS is not set
+CONFIG_NFS_USE_KERNEL_DNS=y
+# CONFIG_NFSD is not set
+CONFIG_GRACE_PERIOD=y
+CONFIG_LOCKD=y
+CONFIG_LOCKD_V4=y
+CONFIG_NFS_ACL_SUPPORT=y
+CONFIG_NFS_COMMON=y
+CONFIG_SUNRPC=y
+CONFIG_SUNRPC_GSS=y
+# CONFIG_SUNRPC_DEBUG is not set
+# CONFIG_CEPH_FS is not set
+# CONFIG_CIFS is not set
+# CONFIG_NCP_FS is not set
+# CONFIG_CODA_FS is not set
+# CONFIG_AFS_FS is not set
+CONFIG_NLS=y
+CONFIG_NLS_DEFAULT="iso8859-1"
+CONFIG_NLS_CODEPAGE_437=y
+# CONFIG_NLS_CODEPAGE_737 is not set
+# CONFIG_NLS_CODEPAGE_775 is not set
+# CONFIG_NLS_CODEPAGE_850 is not set
+# CONFIG_NLS_CODEPAGE_852 is not set
+# CONFIG_NLS_CODEPAGE_855 is not set
+# CONFIG_NLS_CODEPAGE_857 is not set
+# CONFIG_NLS_CODEPAGE_860 is not set
+# CONFIG_NLS_CODEPAGE_861 is not set
+# CONFIG_NLS_CODEPAGE_862 is not set
+# CONFIG_NLS_CODEPAGE_863 is not set
+# CONFIG_NLS_CODEPAGE_864 is not set
+# CONFIG_NLS_CODEPAGE_865 is not set
+# CONFIG_NLS_CODEPAGE_866 is not set
+# CONFIG_NLS_CODEPAGE_869 is not set
+# CONFIG_NLS_CODEPAGE_936 is not set
+# CONFIG_NLS_CODEPAGE_950 is not set
+# CONFIG_NLS_CODEPAGE_932 is not set
+# CONFIG_NLS_CODEPAGE_949 is not set
+# CONFIG_NLS_CODEPAGE_874 is not set
+# CONFIG_NLS_ISO8859_8 is not set
+# CONFIG_NLS_CODEPAGE_1250 is not set
+# CONFIG_NLS_CODEPAGE_1251 is not set
+# CONFIG_NLS_ASCII is not set
+CONFIG_NLS_ISO8859_1=y
+# CONFIG_NLS_ISO8859_2 is not set
+# CONFIG_NLS_ISO8859_3 is not set
+# CONFIG_NLS_ISO8859_4 is not set
+# CONFIG_NLS_ISO8859_5 is not set
+# CONFIG_NLS_ISO8859_6 is not set
+# CONFIG_NLS_ISO8859_7 is not set
+# CONFIG_NLS_ISO8859_9 is not set
+# CONFIG_NLS_ISO8859_13 is not set
+# CONFIG_NLS_ISO8859_14 is not set
+# CONFIG_NLS_ISO8859_15 is not set
+# CONFIG_NLS_KOI8_R is not set
+# CONFIG_NLS_KOI8_U is not set
+# CONFIG_NLS_MAC_ROMAN is not set
+# CONFIG_NLS_MAC_CELTIC is not set
+# CONFIG_NLS_MAC_CENTEURO is not set
+# CONFIG_NLS_MAC_CROATIAN is not set
+# CONFIG_NLS_MAC_CYRILLIC is not set
+# CONFIG_NLS_MAC_GAELIC is not set
+# CONFIG_NLS_MAC_GREEK is not set
+# CONFIG_NLS_MAC_ICELAND is not set
+# CONFIG_NLS_MAC_INUIT is not set
+# CONFIG_NLS_MAC_ROMANIAN is not set
+# CONFIG_NLS_MAC_TURKISH is not set
+CONFIG_NLS_UTF8=y
+# CONFIG_DLM is not set
+
+#
+# Kernel hacking
+#
+
+#
+# printk and dmesg options
+#
+# CONFIG_PRINTK_TIME is not set
+CONFIG_MESSAGE_LOGLEVEL_DEFAULT=4
+# CONFIG_BOOT_PRINTK_DELAY is not set
+
+#
+# Compile-time checks and compiler options
+#
+# CONFIG_DEBUG_INFO is not set
+# CONFIG_ENABLE_WARN_DEPRECATED is not set
+# CONFIG_ENABLE_MUST_CHECK is not set
+CONFIG_FRAME_WARN=1024
+# CONFIG_STRIP_ASM_SYMS is not set
+# CONFIG_READABLE_ASM is not set
+# CONFIG_UNUSED_SYMBOLS is not set
+# CONFIG_PAGE_OWNER is not set
+# CONFIG_DEBUG_FS is not set
+# CONFIG_HEADERS_CHECK is not set
+# CONFIG_DEBUG_SECTION_MISMATCH is not set
+CONFIG_SECTION_MISMATCH_WARN_ONLY=y
+CONFIG_FRAME_POINTER=y
+# CONFIG_DEBUG_FORCE_WEAK_PER_CPU is not set
+# CONFIG_MAGIC_SYSRQ is not set
+CONFIG_DEBUG_KERNEL=y
+
+#
+# Memory Debugging
+#
+# CONFIG_PAGE_EXTENSION is not set
+# CONFIG_PAGE_POISONING is not set
+# CONFIG_DEBUG_OBJECTS is not set
+# CONFIG_SLUB_DEBUG_ON is not set
+# CONFIG_SLUB_STATS is not set
+CONFIG_HAVE_DEBUG_KMEMLEAK=y
+# CONFIG_DEBUG_KMEMLEAK is not set
+# CONFIG_DEBUG_STACK_USAGE is not set
+# CONFIG_DEBUG_VM is not set
+CONFIG_DEBUG_MEMORY_INIT=y
+# CONFIG_DEBUG_SHIRQ is not set
+
+#
+# Debug Lockups and Hangs
+#
+# CONFIG_LOCKUP_DETECTOR is not set
+# CONFIG_DETECT_HUNG_TASK is not set
+# CONFIG_WQ_WATCHDOG is not set
+# CONFIG_PANIC_ON_OOPS is not set
+CONFIG_PANIC_ON_OOPS_VALUE=0
+CONFIG_PANIC_TIMEOUT=0
+# CONFIG_SCHED_DEBUG is not set
+# CONFIG_SCHED_INFO is not set
+# CONFIG_SCHEDSTATS is not set
+# CONFIG_SCHED_STACK_END_CHECK is not set
+# CONFIG_DEBUG_TIMEKEEPING is not set
+# CONFIG_TIMER_STATS is not set
+
+#
+# Lock Debugging (spinlocks, mutexes, etc...)
+#
+# CONFIG_DEBUG_RT_MUTEXES is not set
+# CONFIG_DEBUG_SPINLOCK is not set
+CONFIG_DEBUG_MUTEXES=y
+# CONFIG_DEBUG_WW_MUTEX_SLOWPATH is not set
+# CONFIG_DEBUG_LOCK_ALLOC is not set
+# CONFIG_PROVE_LOCKING is not set
+# CONFIG_LOCK_STAT is not set
+# CONFIG_DEBUG_ATOMIC_SLEEP is not set
+# CONFIG_DEBUG_LOCKING_API_SELFTESTS is not set
+# CONFIG_LOCK_TORTURE_TEST is not set
+CONFIG_STACKTRACE=y
+# CONFIG_DEBUG_KOBJECT is not set
+CONFIG_DEBUG_BUGVERBOSE=y
+# CONFIG_DEBUG_LIST is not set
+# CONFIG_DEBUG_PI_LIST is not set
+# CONFIG_DEBUG_SG is not set
+# CONFIG_DEBUG_NOTIFIERS is not set
+# CONFIG_DEBUG_CREDENTIALS is not set
+
+#
+# RCU Debugging
+#
+# CONFIG_PROVE_RCU is not set
+# CONFIG_SPARSE_RCU_POINTER is not set
+# CONFIG_TORTURE_TEST is not set
+# CONFIG_RCU_PERF_TEST is not set
+# CONFIG_RCU_TORTURE_TEST is not set
+# CONFIG_RCU_TRACE is not set
+# CONFIG_RCU_EQS_DEBUG is not set
+# CONFIG_DEBUG_WQ_FORCE_RR_CPU is not set
+# CONFIG_DEBUG_BLOCK_EXT_DEVT is not set
+# CONFIG_NOTIFIER_ERROR_INJECTION is not set
+# CONFIG_FAULT_INJECTION is not set
+# CONFIG_LATENCYTOP is not set
+CONFIG_HAVE_FUNCTION_TRACER=y
+CONFIG_HAVE_FUNCTION_GRAPH_TRACER=y
+CONFIG_HAVE_DYNAMIC_FTRACE=y
+CONFIG_HAVE_FTRACE_MCOUNT_RECORD=y
+CONFIG_HAVE_SYSCALL_TRACEPOINTS=y
+CONFIG_HAVE_C_RECORDMCOUNT=y
+CONFIG_TRACING_SUPPORT=y
+# CONFIG_FTRACE is not set
+
+#
+# Runtime Testing
+#
+# CONFIG_TEST_LIST_SORT is not set
+# CONFIG_BACKTRACE_SELF_TEST is not set
+# CONFIG_RBTREE_TEST is not set
+# CONFIG_INTERVAL_TREE_TEST is not set
+# CONFIG_PERCPU_TEST is not set
+# CONFIG_ATOMIC64_SELFTEST is not set
+# CONFIG_TEST_HEXDUMP is not set
+# CONFIG_TEST_STRING_HELPERS is not set
+# CONFIG_TEST_KSTRTOX is not set
+# CONFIG_TEST_PRINTF is not set
+# CONFIG_TEST_BITMAP is not set
+# CONFIG_TEST_UUID is not set
+# CONFIG_TEST_RHASHTABLE is not set
+# CONFIG_TEST_HASH is not set
+# CONFIG_DMA_API_DEBUG is not set
+# CONFIG_TEST_LKM is not set
+# CONFIG_TEST_USER_COPY is not set
+# CONFIG_TEST_BPF is not set
+# CONFIG_TEST_FIRMWARE is not set
+# CONFIG_TEST_UDELAY is not set
+# CONFIG_MEMTEST is not set
+# CONFIG_TEST_STATIC_KEYS is not set
+# CONFIG_SAMPLES is not set
+CONFIG_HAVE_ARCH_KGDB=y
+# CONFIG_KGDB is not set
+# CONFIG_ARCH_WANTS_UBSAN_NO_NULL is not set
+# CONFIG_UBSAN is not set
+CONFIG_ARCH_HAS_DEVMEM_IS_ALLOWED=y
+CONFIG_STRICT_DEVMEM=y
+# CONFIG_IO_STRICT_DEVMEM is not set
+# CONFIG_ARM_PTDUMP is not set
+# CONFIG_ARM_UNWIND is not set
+# CONFIG_DEBUG_USER is not set
+# CONFIG_DEBUG_LL is not set
+CONFIG_DEBUG_LL_INCLUDE="mach/debug-macro.S"
+# CONFIG_DEBUG_UART_8250 is not set
+CONFIG_UNCOMPRESS_INCLUDE="debug/uncompress.h"
+# CONFIG_PID_IN_CONTEXTIDR is not set
+# CONFIG_DEBUG_SET_MODULE_RONX is not set
+# CONFIG_CORESIGHT is not set
+
+#
+# Security options
+#
+CONFIG_KEYS=y
+# CONFIG_PERSISTENT_KEYRINGS is not set
+# CONFIG_ENCRYPTED_KEYS is not set
+# CONFIG_KEY_DH_OPERATIONS is not set
+# CONFIG_SECURITY_DMESG_RESTRICT is not set
+# CONFIG_SECURITY is not set
+# CONFIG_SECURITYFS is not set
+CONFIG_HAVE_HARDENED_USERCOPY_ALLOCATOR=y
+CONFIG_HAVE_ARCH_HARDENED_USERCOPY=y
+# CONFIG_HARDENED_USERCOPY is not set
+CONFIG_DEFAULT_SECURITY_DAC=y
+CONFIG_DEFAULT_SECURITY=""
+CONFIG_CRYPTO=y
+
+#
+# Crypto core or helper
+#
+CONFIG_CRYPTO_ALGAPI=y
+CONFIG_CRYPTO_ALGAPI2=y
+CONFIG_CRYPTO_AEAD=m
+CONFIG_CRYPTO_AEAD2=y
+CONFIG_CRYPTO_BLKCIPHER=y
+CONFIG_CRYPTO_BLKCIPHER2=y
+CONFIG_CRYPTO_HASH=y
+CONFIG_CRYPTO_HASH2=y
+CONFIG_CRYPTO_RNG=m
+CONFIG_CRYPTO_RNG2=y
+CONFIG_CRYPTO_RNG_DEFAULT=m
+CONFIG_CRYPTO_AKCIPHER2=y
+CONFIG_CRYPTO_KPP2=y
+# CONFIG_CRYPTO_RSA is not set
+# CONFIG_CRYPTO_DH is not set
+# CONFIG_CRYPTO_ECDH is not set
+CONFIG_CRYPTO_MANAGER=m
+CONFIG_CRYPTO_MANAGER2=y
+# CONFIG_CRYPTO_USER is not set
+CONFIG_CRYPTO_MANAGER_DISABLE_TESTS=y
+CONFIG_CRYPTO_GF128MUL=m
+CONFIG_CRYPTO_NULL=m
+CONFIG_CRYPTO_NULL2=y
+CONFIG_CRYPTO_WORKQUEUE=y
+# CONFIG_CRYPTO_CRYPTD is not set
+# CONFIG_CRYPTO_MCRYPTD is not set
+# CONFIG_CRYPTO_AUTHENC is not set
+# CONFIG_CRYPTO_TEST is not set
+
+#
+# Authenticated Encryption with Associated Data
+#
+CONFIG_CRYPTO_CCM=m
+CONFIG_CRYPTO_GCM=m
+# CONFIG_CRYPTO_CHACHA20POLY1305 is not set
+CONFIG_CRYPTO_SEQIV=m
+CONFIG_CRYPTO_ECHAINIV=m
+
+#
+# Block modes
+#
+# CONFIG_CRYPTO_CBC is not set
+CONFIG_CRYPTO_CTR=m
+# CONFIG_CRYPTO_CTS is not set
+# CONFIG_CRYPTO_ECB is not set
+# CONFIG_CRYPTO_LRW is not set
+# CONFIG_CRYPTO_PCBC is not set
+# CONFIG_CRYPTO_XTS is not set
+# CONFIG_CRYPTO_KEYWRAP is not set
+
+#
+# Hash modes
+#
+# CONFIG_CRYPTO_CMAC is not set
+CONFIG_CRYPTO_HMAC=m
+# CONFIG_CRYPTO_XCBC is not set
+# CONFIG_CRYPTO_VMAC is not set
+
+#
+# Digest
+#
+CONFIG_CRYPTO_CRC32C=y
+# CONFIG_CRYPTO_CRC32 is not set
+CONFIG_CRYPTO_CRCT10DIF=y
+CONFIG_CRYPTO_GHASH=m
+# CONFIG_CRYPTO_POLY1305 is not set
+# CONFIG_CRYPTO_MD4 is not set
+CONFIG_CRYPTO_MD5=y
+# CONFIG_CRYPTO_MICHAEL_MIC is not set
+# CONFIG_CRYPTO_RMD128 is not set
+# CONFIG_CRYPTO_RMD160 is not set
+# CONFIG_CRYPTO_RMD256 is not set
+# CONFIG_CRYPTO_RMD320 is not set
+CONFIG_CRYPTO_SHA1=y
+CONFIG_CRYPTO_SHA256=y
+# CONFIG_CRYPTO_SHA512 is not set
+# CONFIG_CRYPTO_SHA3 is not set
+# CONFIG_CRYPTO_TGR192 is not set
+# CONFIG_CRYPTO_WP512 is not set
+
+#
+# Ciphers
+#
+CONFIG_CRYPTO_AES=y
+# CONFIG_CRYPTO_ANUBIS is not set
+CONFIG_CRYPTO_ARC4=y
+# CONFIG_CRYPTO_BLOWFISH is not set
+# CONFIG_CRYPTO_CAMELLIA is not set
+# CONFIG_CRYPTO_CAST5 is not set
+# CONFIG_CRYPTO_CAST6 is not set
+# CONFIG_CRYPTO_DES is not set
+# CONFIG_CRYPTO_FCRYPT is not set
+# CONFIG_CRYPTO_KHAZAD is not set
+# CONFIG_CRYPTO_SALSA20 is not set
+# CONFIG_CRYPTO_CHACHA20 is not set
+# CONFIG_CRYPTO_SEED is not set
+# CONFIG_CRYPTO_SERPENT is not set
+# CONFIG_CRYPTO_TEA is not set
+# CONFIG_CRYPTO_TWOFISH is not set
+
+#
+# Compression
+#
+CONFIG_CRYPTO_DEFLATE=y
+CONFIG_CRYPTO_LZO=y
+# CONFIG_CRYPTO_842 is not set
+# CONFIG_CRYPTO_LZ4 is not set
+# CONFIG_CRYPTO_LZ4HC is not set
+
+#
+# Random Number Generation
+#
+# CONFIG_CRYPTO_ANSI_CPRNG is not set
+CONFIG_CRYPTO_DRBG_MENU=m
+CONFIG_CRYPTO_DRBG_HMAC=y
+# CONFIG_CRYPTO_DRBG_HASH is not set
+# CONFIG_CRYPTO_DRBG_CTR is not set
+CONFIG_CRYPTO_DRBG=m
+CONFIG_CRYPTO_JITTERENTROPY=m
+# CONFIG_CRYPTO_USER_API_HASH is not set
+# CONFIG_CRYPTO_USER_API_SKCIPHER is not set
+# CONFIG_CRYPTO_USER_API_RNG is not set
+# CONFIG_CRYPTO_USER_API_AEAD is not set
+# CONFIG_CRYPTO_HW is not set
+# CONFIG_ASYMMETRIC_KEY_TYPE is not set
+
+#
+# Certificates for signature checking
+#
+# CONFIG_ARM_CRYPTO is not set
+# CONFIG_BINARY_PRINTF is not set
+
+#
+# Library routines
+#
+CONFIG_BITREVERSE=y
+CONFIG_HAVE_ARCH_BITREVERSE=y
+CONFIG_RATIONAL=y
+CONFIG_GENERIC_STRNCPY_FROM_USER=y
+CONFIG_GENERIC_STRNLEN_USER=y
+CONFIG_GENERIC_NET_UTILS=y
+CONFIG_GENERIC_PCI_IOMAP=y
+CONFIG_GENERIC_IO=y
+CONFIG_ARCH_USE_CMPXCHG_LOCKREF=y
+CONFIG_CRC_CCITT=y
+CONFIG_CRC16=y
+CONFIG_CRC_T10DIF=y
+CONFIG_CRC_ITU_T=y
+CONFIG_CRC32=y
+# CONFIG_CRC32_SELFTEST is not set
+CONFIG_CRC32_SLICEBY8=y
+# CONFIG_CRC32_SLICEBY4 is not set
+# CONFIG_CRC32_SARWATE is not set
+# CONFIG_CRC32_BIT is not set
+# CONFIG_CRC7 is not set
+CONFIG_LIBCRC32C=y
+# CONFIG_CRC8 is not set
+# CONFIG_AUDIT_ARCH_COMPAT_GENERIC is not set
+# CONFIG_RANDOM32_SELFTEST is not set
+CONFIG_ZLIB_INFLATE=y
+CONFIG_ZLIB_DEFLATE=y
+CONFIG_LZO_COMPRESS=y
+CONFIG_LZO_DECOMPRESS=y
+CONFIG_LZ4_DECOMPRESS=y
+CONFIG_XZ_DEC=y
+CONFIG_XZ_DEC_X86=y
+CONFIG_XZ_DEC_POWERPC=y
+CONFIG_XZ_DEC_IA64=y
+CONFIG_XZ_DEC_ARM=y
+CONFIG_XZ_DEC_ARMTHUMB=y
+CONFIG_XZ_DEC_SPARC=y
+CONFIG_XZ_DEC_BCJ=y
+# CONFIG_XZ_DEC_TEST is not set
+CONFIG_DECOMPRESS_GZIP=y
+CONFIG_DECOMPRESS_LZ4=y
+CONFIG_GENERIC_ALLOCATOR=y
+CONFIG_ASSOCIATIVE_ARRAY=y
+CONFIG_HAS_IOMEM=y
+CONFIG_HAS_IOPORT_MAP=y
+CONFIG_HAS_DMA=y
+CONFIG_DQL=y
+CONFIG_NLATTR=y
+# CONFIG_CORDIC is not set
+# CONFIG_DDR is not set
+# CONFIG_IRQ_POLL is not set
+CONFIG_LIBFDT=y
+CONFIG_OID_REGISTRY=y
+# CONFIG_SG_SPLIT is not set
+# CONFIG_SG_POOL is not set
+CONFIG_ARCH_HAS_SG_CHAIN=y
+CONFIG_SBITMAP=y
+# CONFIG_VIRTUALIZATION is not set
diff --git a/arch/arm/configs/hi3516a_spinand_defconfig b/arch/arm/configs/hi3516a_spinand_defconfig
new file mode 100644
index 0000000..0ca4ac7d
--- /dev/null
+++ b/arch/arm/configs/hi3516a_spinand_defconfig
@@ -0,0 +1,2719 @@
+#
+# Automatically generated file; DO NOT EDIT.
+# Linux/arm 4.9.37 Kernel Configuration
+#
+CONFIG_ARM=y
+CONFIG_ARM_HAS_SG_CHAIN=y
+CONFIG_MIGHT_HAVE_PCI=y
+CONFIG_SYS_SUPPORTS_APM_EMULATION=y
+CONFIG_HAVE_PROC_CPU=y
+CONFIG_STACKTRACE_SUPPORT=y
+CONFIG_LOCKDEP_SUPPORT=y
+CONFIG_TRACE_IRQFLAGS_SUPPORT=y
+CONFIG_RWSEM_XCHGADD_ALGORITHM=y
+CONFIG_FIX_EARLYCON_MEM=y
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_NEED_DMA_MAP_STATE=y
+CONFIG_ARCH_SUPPORTS_UPROBES=y
+CONFIG_VECTORS_BASE=0xffff0000
+CONFIG_ARM_PATCH_PHYS_VIRT=y
+CONFIG_GENERIC_BUG=y
+CONFIG_PGTABLE_LEVELS=2
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+CONFIG_IRQ_WORK=y
+CONFIG_BUILDTIME_EXTABLE_SORT=y
+
+#
+# General setup
+#
+CONFIG_BROKEN_ON_SMP=y
+CONFIG_INIT_ENV_ARG_LIMIT=32
+CONFIG_CROSS_COMPILE=""
+# CONFIG_COMPILE_TEST is not set
+CONFIG_LOCALVERSION=""
+# CONFIG_LOCALVERSION_AUTO is not set
+CONFIG_HAVE_KERNEL_GZIP=y
+CONFIG_HAVE_KERNEL_LZMA=y
+CONFIG_HAVE_KERNEL_XZ=y
+CONFIG_HAVE_KERNEL_LZO=y
+CONFIG_HAVE_KERNEL_LZ4=y
+CONFIG_KERNEL_GZIP=y
+# CONFIG_KERNEL_LZMA is not set
+# CONFIG_KERNEL_XZ is not set
+# CONFIG_KERNEL_LZO is not set
+# CONFIG_KERNEL_LZ4 is not set
+CONFIG_DEFAULT_HOSTNAME="(none)"
+CONFIG_SWAP=y
+CONFIG_SYSVIPC=y
+CONFIG_SYSVIPC_SYSCTL=y
+# CONFIG_POSIX_MQUEUE is not set
+CONFIG_CROSS_MEMORY_ATTACH=y
+CONFIG_FHANDLE=y
+CONFIG_USELIB=y
+# CONFIG_AUDIT is not set
+CONFIG_HAVE_ARCH_AUDITSYSCALL=y
+
+#
+# IRQ subsystem
+#
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_GENERIC_IRQ_SHOW=y
+CONFIG_GENERIC_IRQ_SHOW_LEVEL=y
+CONFIG_HARDIRQS_SW_RESEND=y
+CONFIG_IRQ_DOMAIN=y
+CONFIG_IRQ_DOMAIN_HIERARCHY=y
+CONFIG_HANDLE_DOMAIN_IRQ=y
+CONFIG_IRQ_FORCED_THREADING=y
+CONFIG_SPARSE_IRQ=y
+CONFIG_ARCH_CLOCKSOURCE_DATA=y
+CONFIG_GENERIC_TIME_VSYSCALL=y
+CONFIG_GENERIC_CLOCKEVENTS=y
+
+#
+# Timers subsystem
+#
+CONFIG_HZ_PERIODIC=y
+# CONFIG_NO_HZ_IDLE is not set
+# CONFIG_NO_HZ is not set
+# CONFIG_HIGH_RES_TIMERS is not set
+
+#
+# CPU/Task time and stats accounting
+#
+CONFIG_TICK_CPU_ACCOUNTING=y
+# CONFIG_VIRT_CPU_ACCOUNTING_GEN is not set
+CONFIG_IRQ_TIME_ACCOUNTING=y
+# CONFIG_BSD_PROCESS_ACCT is not set
+# CONFIG_TASKSTATS is not set
+
+#
+# RCU Subsystem
+#
+CONFIG_TINY_RCU=y
+# CONFIG_RCU_EXPERT is not set
+CONFIG_SRCU=y
+# CONFIG_TASKS_RCU is not set
+# CONFIG_RCU_STALL_COMMON is not set
+# CONFIG_TREE_RCU_TRACE is not set
+# CONFIG_RCU_EXPEDITE_BOOT is not set
+# CONFIG_BUILD_BIN2C is not set
+# CONFIG_IKCONFIG is not set
+CONFIG_LOG_BUF_SHIFT=17
+CONFIG_NMI_LOG_BUF_SHIFT=13
+CONFIG_GENERIC_SCHED_CLOCK=y
+CONFIG_CGROUPS=y
+# CONFIG_MEMCG is not set
+# CONFIG_BLK_CGROUP is not set
+# CONFIG_CGROUP_SCHED is not set
+# CONFIG_CGROUP_PIDS is not set
+CONFIG_CGROUP_FREEZER=y
+# CONFIG_CPUSETS is not set
+# CONFIG_CGROUP_DEVICE is not set
+# CONFIG_CGROUP_CPUACCT is not set
+# CONFIG_CGROUP_DEBUG is not set
+# CONFIG_CHECKPOINT_RESTORE is not set
+CONFIG_NAMESPACES=y
+CONFIG_UTS_NS=y
+CONFIG_IPC_NS=y
+# CONFIG_USER_NS is not set
+CONFIG_PID_NS=y
+CONFIG_NET_NS=y
+# CONFIG_SCHED_AUTOGROUP is not set
+# CONFIG_SYSFS_DEPRECATED is not set
+# CONFIG_RELAY is not set
+CONFIG_BLK_DEV_INITRD=y
+CONFIG_INITRAMFS_SOURCE=""
+CONFIG_RD_GZIP=y
+# CONFIG_RD_BZIP2 is not set
+# CONFIG_RD_LZMA is not set
+# CONFIG_RD_XZ is not set
+# CONFIG_RD_LZO is not set
+CONFIG_RD_LZ4=y
+CONFIG_CC_OPTIMIZE_FOR_PERFORMANCE=y
+# CONFIG_CC_OPTIMIZE_FOR_SIZE is not set
+CONFIG_SYSCTL=y
+CONFIG_ANON_INODES=y
+CONFIG_HAVE_UID16=y
+CONFIG_BPF=y
+# CONFIG_EXPERT is not set
+CONFIG_UID16=y
+CONFIG_MULTIUSER=y
+# CONFIG_SGETMASK_SYSCALL is not set
+CONFIG_SYSFS_SYSCALL=y
+# CONFIG_SYSCTL_SYSCALL is not set
+CONFIG_KALLSYMS=y
+# CONFIG_KALLSYMS_ALL is not set
+# CONFIG_KALLSYMS_ABSOLUTE_PERCPU is not set
+CONFIG_KALLSYMS_BASE_RELATIVE=y
+CONFIG_PRINTK=y
+CONFIG_PRINTK_NMI=y
+CONFIG_BUG=y
+CONFIG_ELF_CORE=y
+CONFIG_BASE_FULL=y
+CONFIG_FUTEX=y
+CONFIG_EPOLL=y
+CONFIG_SIGNALFD=y
+CONFIG_TIMERFD=y
+CONFIG_EVENTFD=y
+# CONFIG_BPF_SYSCALL is not set
+CONFIG_SHMEM=y
+CONFIG_AIO=y
+CONFIG_ADVISE_SYSCALLS=y
+# CONFIG_USERFAULTFD is not set
+CONFIG_MEMBARRIER=y
+# CONFIG_EMBEDDED is not set
+CONFIG_HAVE_PERF_EVENTS=y
+CONFIG_PERF_USE_VMALLOC=y
+
+#
+# Kernel Performance Events And Counters
+#
+# CONFIG_PERF_EVENTS is not set
+CONFIG_VM_EVENT_COUNTERS=y
+CONFIG_SLUB_DEBUG=y
+CONFIG_COMPAT_BRK=y
+# CONFIG_SLAB is not set
+CONFIG_SLUB=y
+# CONFIG_SLAB_FREELIST_RANDOM is not set
+# CONFIG_SYSTEM_DATA_VERIFICATION is not set
+# CONFIG_PROFILING is not set
+CONFIG_HAVE_OPROFILE=y
+# CONFIG_KPROBES is not set
+# CONFIG_JUMP_LABEL is not set
+# CONFIG_UPROBES is not set
+# CONFIG_HAVE_64BIT_ALIGNED_ACCESS is not set
+CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS=y
+CONFIG_ARCH_USE_BUILTIN_BSWAP=y
+CONFIG_HAVE_KPROBES=y
+CONFIG_HAVE_KRETPROBES=y
+CONFIG_HAVE_OPTPROBES=y
+CONFIG_HAVE_NMI=y
+CONFIG_HAVE_ARCH_TRACEHOOK=y
+CONFIG_HAVE_DMA_CONTIGUOUS=y
+CONFIG_GENERIC_SMP_IDLE_THREAD=y
+CONFIG_GENERIC_IDLE_POLL_SETUP=y
+CONFIG_HAVE_REGS_AND_STACK_ACCESS_API=y
+CONFIG_HAVE_CLK=y
+CONFIG_HAVE_DMA_API_DEBUG=y
+CONFIG_HAVE_PERF_REGS=y
+CONFIG_HAVE_PERF_USER_STACK_DUMP=y
+CONFIG_HAVE_ARCH_JUMP_LABEL=y
+CONFIG_ARCH_WANT_IPC_PARSE_VERSION=y
+CONFIG_HAVE_ARCH_SECCOMP_FILTER=y
+CONFIG_HAVE_GCC_PLUGINS=y
+# CONFIG_GCC_PLUGINS is not set
+CONFIG_HAVE_CC_STACKPROTECTOR=y
+# CONFIG_CC_STACKPROTECTOR is not set
+CONFIG_CC_STACKPROTECTOR_NONE=y
+# CONFIG_CC_STACKPROTECTOR_REGULAR is not set
+# CONFIG_CC_STACKPROTECTOR_STRONG is not set
+CONFIG_HAVE_CONTEXT_TRACKING=y
+CONFIG_HAVE_VIRT_CPU_ACCOUNTING_GEN=y
+CONFIG_HAVE_IRQ_TIME_ACCOUNTING=y
+CONFIG_HAVE_MOD_ARCH_SPECIFIC=y
+CONFIG_MODULES_USE_ELF_REL=y
+CONFIG_ARCH_HAS_ELF_RANDOMIZE=y
+CONFIG_HAVE_ARCH_MMAP_RND_BITS=y
+CONFIG_HAVE_EXIT_THREAD=y
+CONFIG_ARCH_MMAP_RND_BITS_MIN=8
+CONFIG_ARCH_MMAP_RND_BITS_MAX=16
+CONFIG_ARCH_MMAP_RND_BITS=8
+# CONFIG_HAVE_ARCH_HASH is not set
+# CONFIG_ISA_BUS_API is not set
+CONFIG_CLONE_BACKWARDS=y
+CONFIG_OLD_SIGSUSPEND3=y
+CONFIG_OLD_SIGACTION=y
+# CONFIG_CPU_NO_EFFICIENT_FFS is not set
+# CONFIG_HAVE_ARCH_VMAP_STACK is not set
+
+#
+# GCOV-based kernel profiling
+#
+CONFIG_ARCH_HAS_GCOV_PROFILE_ALL=y
+CONFIG_HAVE_GENERIC_DMA_COHERENT=y
+CONFIG_SLABINFO=y
+CONFIG_RT_MUTEXES=y
+CONFIG_BASE_SMALL=0
+CONFIG_MODULES=y
+# CONFIG_MODULE_FORCE_LOAD is not set
+CONFIG_MODULE_UNLOAD=y
+# CONFIG_MODULE_FORCE_UNLOAD is not set
+# CONFIG_MODVERSIONS is not set
+# CONFIG_MODULE_SRCVERSION_ALL is not set
+# CONFIG_MODULE_SIG is not set
+# CONFIG_MODULE_COMPRESS is not set
+# CONFIG_TRIM_UNUSED_KSYMS is not set
+CONFIG_BLOCK=y
+CONFIG_LBDAF=y
+CONFIG_BLK_DEV_BSG=y
+# CONFIG_BLK_DEV_BSGLIB is not set
+# CONFIG_BLK_DEV_INTEGRITY is not set
+CONFIG_BLK_CMDLINE_PARSER=y
+
+#
+# Partition Types
+#
+CONFIG_PARTITION_ADVANCED=y
+# CONFIG_ACORN_PARTITION is not set
+# CONFIG_AIX_PARTITION is not set
+# CONFIG_OSF_PARTITION is not set
+# CONFIG_AMIGA_PARTITION is not set
+# CONFIG_ATARI_PARTITION is not set
+# CONFIG_MAC_PARTITION is not set
+CONFIG_MSDOS_PARTITION=y
+# CONFIG_BSD_DISKLABEL is not set
+# CONFIG_MINIX_SUBPARTITION is not set
+# CONFIG_SOLARIS_X86_PARTITION is not set
+# CONFIG_UNIXWARE_DISKLABEL is not set
+# CONFIG_LDM_PARTITION is not set
+# CONFIG_SGI_PARTITION is not set
+# CONFIG_ULTRIX_PARTITION is not set
+# CONFIG_SUN_PARTITION is not set
+# CONFIG_KARMA_PARTITION is not set
+CONFIG_EFI_PARTITION=y
+# CONFIG_SYSV68_PARTITION is not set
+CONFIG_CMDLINE_PARTITION=y
+
+#
+# IO Schedulers
+#
+CONFIG_IOSCHED_NOOP=y
+CONFIG_IOSCHED_DEADLINE=y
+CONFIG_IOSCHED_CFQ=y
+CONFIG_DEFAULT_DEADLINE=y
+# CONFIG_DEFAULT_CFQ is not set
+# CONFIG_DEFAULT_NOOP is not set
+CONFIG_DEFAULT_IOSCHED="deadline"
+CONFIG_INLINE_SPIN_UNLOCK_IRQ=y
+CONFIG_INLINE_READ_UNLOCK=y
+CONFIG_INLINE_READ_UNLOCK_IRQ=y
+CONFIG_INLINE_WRITE_UNLOCK=y
+CONFIG_INLINE_WRITE_UNLOCK_IRQ=y
+CONFIG_ARCH_SUPPORTS_ATOMIC_RMW=y
+CONFIG_FREEZER=y
+
+#
+# System Type
+#
+CONFIG_MMU=y
+CONFIG_ARCH_MULTIPLATFORM=y
+# CONFIG_ARCH_GEMINI is not set
+# CONFIG_ARCH_EBSA110 is not set
+# CONFIG_ARCH_EP93XX is not set
+# CONFIG_ARCH_FOOTBRIDGE is not set
+# CONFIG_ARCH_NETX is not set
+# CONFIG_ARCH_IOP13XX is not set
+# CONFIG_ARCH_IOP32X is not set
+# CONFIG_ARCH_IOP33X is not set
+# CONFIG_ARCH_IXP4XX is not set
+# CONFIG_ARCH_DOVE is not set
+# CONFIG_ARCH_KS8695 is not set
+# CONFIG_ARCH_W90X900 is not set
+# CONFIG_ARCH_LPC32XX is not set
+# CONFIG_ARCH_PXA is not set
+# CONFIG_ARCH_RPC is not set
+# CONFIG_ARCH_SA1100 is not set
+# CONFIG_ARCH_S3C24XX is not set
+# CONFIG_ARCH_DAVINCI is not set
+# CONFIG_ARCH_OMAP1 is not set
+
+#
+# Multiple platform selection
+#
+
+#
+# CPU Core family selection
+#
+# CONFIG_ARCH_MULTI_V6 is not set
+CONFIG_ARCH_MULTI_V7=y
+CONFIG_ARCH_MULTI_V6_V7=y
+# CONFIG_ARCH_MULTI_CPU_AUTO is not set
+# CONFIG_ARCH_VIRT is not set
+# CONFIG_ARCH_MVEBU is not set
+# CONFIG_ARCH_ALPINE is not set
+# CONFIG_ARCH_ARTPEC is not set
+# CONFIG_ARCH_AT91 is not set
+# CONFIG_ARCH_BCM is not set
+# CONFIG_ARCH_BERLIN is not set
+# CONFIG_ARCH_DIGICOLOR is not set
+# CONFIG_ARCH_HIGHBANK is not set
+# CONFIG_ARCH_HISI is not set
+CONFIG_ARCH_HISI_BVT=y
+
+#
+# Hisilicon BVT platform type
+#
+CONFIG_HI_ZRELADDR=0x80008000
+CONFIG_HI_PARAMS_PHYS=0x00000100
+CONFIG_HI_INITRD_PHYS=0x00800000
+CONFIG_ARCH_HI3516A=y
+# CONFIG_ARCH_HI3536DV100 is not set
+# CONFIG_ARCH_KEYSTONE is not set
+# CONFIG_ARCH_MESON is not set
+# CONFIG_ARCH_MXC is not set
+# CONFIG_ARCH_MEDIATEK is not set
+
+#
+# TI OMAP/AM/DM/DRA Family
+#
+# CONFIG_ARCH_OMAP3 is not set
+# CONFIG_ARCH_OMAP4 is not set
+# CONFIG_SOC_OMAP5 is not set
+# CONFIG_SOC_AM33XX is not set
+# CONFIG_SOC_AM43XX is not set
+# CONFIG_SOC_DRA7XX is not set
+# CONFIG_ARCH_MMP is not set
+# CONFIG_ARCH_QCOM is not set
+# CONFIG_ARCH_REALVIEW is not set
+# CONFIG_ARCH_ROCKCHIP is not set
+# CONFIG_ARCH_SOCFPGA is not set
+# CONFIG_PLAT_SPEAR is not set
+# CONFIG_ARCH_STI is not set
+# CONFIG_ARCH_S5PV210 is not set
+# CONFIG_ARCH_EXYNOS is not set
+# CONFIG_ARCH_RENESAS is not set
+# CONFIG_ARCH_SUNXI is not set
+# CONFIG_ARCH_SIRF is not set
+# CONFIG_ARCH_TANGO is not set
+# CONFIG_ARCH_TEGRA is not set
+# CONFIG_ARCH_UNIPHIER is not set
+# CONFIG_ARCH_U8500 is not set
+# CONFIG_ARCH_VEXPRESS is not set
+# CONFIG_ARCH_WM8850 is not set
+# CONFIG_ARCH_ZX is not set
+# CONFIG_ARCH_ZYNQ is not set
+
+#
+# Processor Type
+#
+CONFIG_CPU_V7=y
+CONFIG_CPU_32v6K=y
+CONFIG_CPU_32v7=y
+CONFIG_CPU_ABRT_EV7=y
+CONFIG_CPU_PABRT_V7=y
+CONFIG_CPU_CACHE_V7=y
+CONFIG_CPU_CACHE_VIPT=y
+CONFIG_CPU_COPY_V6=y
+CONFIG_CPU_TLB_V7=y
+CONFIG_CPU_HAS_ASID=y
+CONFIG_CPU_CP15=y
+CONFIG_CPU_CP15_MMU=y
+
+#
+# Processor Features
+#
+# CONFIG_ARM_LPAE is not set
+# CONFIG_ARCH_PHYS_ADDR_T_64BIT is not set
+CONFIG_ARM_THUMB=y
+# CONFIG_ARM_THUMBEE is not set
+CONFIG_ARM_VIRT_EXT=y
+# CONFIG_SWP_EMULATE is not set
+# CONFIG_CPU_ICACHE_DISABLE is not set
+# CONFIG_CPU_DCACHE_DISABLE is not set
+# CONFIG_CPU_BPREDICT_DISABLE is not set
+CONFIG_KUSER_HELPERS=y
+CONFIG_VDSO=y
+CONFIG_MIGHT_HAVE_CACHE_L2X0=y
+# CONFIG_CACHE_L2X0 is not set
+CONFIG_ARM_L1_CACHE_SHIFT_6=y
+CONFIG_ARM_L1_CACHE_SHIFT=6
+CONFIG_ARM_DMA_MEM_BUFFERABLE=y
+# CONFIG_DEBUG_RODATA is not set
+CONFIG_MULTI_IRQ_HANDLER=y
+# CONFIG_ARM_ERRATA_430973 is not set
+# CONFIG_ARM_ERRATA_720789 is not set
+# CONFIG_ARM_ERRATA_754322 is not set
+# CONFIG_ARM_ERRATA_775420 is not set
+# CONFIG_ARM_ERRATA_773022 is not set
+# CONFIG_ARM_ERRATA_818325_852422 is not set
+# CONFIG_ARM_ERRATA_821420 is not set
+# CONFIG_ARM_ERRATA_825619 is not set
+# CONFIG_ARM_ERRATA_852421 is not set
+# CONFIG_ARM_ERRATA_852423 is not set
+
+#
+# Bus support
+#
+# CONFIG_PCI is not set
+# CONFIG_PCI_DOMAINS_GENERIC is not set
+# CONFIG_PCI_SYSCALL is not set
+# CONFIG_PCCARD is not set
+
+#
+# Kernel Features
+#
+CONFIG_HAVE_SMP=y
+# CONFIG_SMP is not set
+CONFIG_HAVE_ARM_ARCH_TIMER=y
+CONFIG_VMSPLIT_3G=y
+# CONFIG_VMSPLIT_3G_OPT is not set
+# CONFIG_VMSPLIT_2G is not set
+# CONFIG_VMSPLIT_1G is not set
+CONFIG_PAGE_OFFSET=0xC0000000
+# CONFIG_ARM_PSCI is not set
+CONFIG_ARCH_NR_GPIO=0
+CONFIG_PREEMPT_NONE=y
+# CONFIG_PREEMPT_VOLUNTARY is not set
+# CONFIG_PREEMPT is not set
+CONFIG_HZ_FIXED=0
+CONFIG_HZ_100=y
+# CONFIG_HZ_200 is not set
+# CONFIG_HZ_250 is not set
+# CONFIG_HZ_300 is not set
+# CONFIG_HZ_500 is not set
+# CONFIG_HZ_1000 is not set
+CONFIG_HZ=100
+# CONFIG_SCHED_HRTICK is not set
+# CONFIG_THUMB2_KERNEL is not set
+CONFIG_ARM_PATCH_IDIV=y
+CONFIG_AEABI=y
+# CONFIG_OABI_COMPAT is not set
+# CONFIG_ARCH_SPARSEMEM_DEFAULT is not set
+# CONFIG_ARCH_SELECT_MEMORY_MODEL is not set
+CONFIG_HAVE_ARCH_PFN_VALID=y
+# CONFIG_HIGHMEM is not set
+# CONFIG_CPU_SW_DOMAIN_PAN is not set
+CONFIG_ARCH_WANT_GENERAL_HUGETLB=y
+# CONFIG_ARM_MODULE_PLTS is not set
+CONFIG_FLATMEM=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+CONFIG_HAVE_MEMBLOCK=y
+CONFIG_NO_BOOTMEM=y
+# CONFIG_HAVE_BOOTMEM_INFO_NODE is not set
+CONFIG_SPLIT_PTLOCK_CPUS=4
+CONFIG_COMPACTION=y
+CONFIG_MIGRATION=y
+# CONFIG_PHYS_ADDR_T_64BIT is not set
+# CONFIG_KSM is not set
+CONFIG_DEFAULT_MMAP_MIN_ADDR=4096
+CONFIG_NEED_PER_CPU_KM=y
+# CONFIG_CLEANCACHE is not set
+# CONFIG_FRONTSWAP is not set
+# CONFIG_CMA is not set
+# CONFIG_ZPOOL is not set
+# CONFIG_ZBUD is not set
+# CONFIG_ZSMALLOC is not set
+CONFIG_GENERIC_EARLY_IOREMAP=y
+# CONFIG_IDLE_PAGE_TRACKING is not set
+CONFIG_FORCE_MAX_ZONEORDER=11
+CONFIG_ALIGNMENT_TRAP=y
+# CONFIG_UACCESS_WITH_MEMCPY is not set
+# CONFIG_SECCOMP is not set
+CONFIG_SWIOTLB=y
+CONFIG_IOMMU_HELPER=y
+# CONFIG_PARAVIRT is not set
+# CONFIG_PARAVIRT_TIME_ACCOUNTING is not set
+# CONFIG_XEN is not set
+
+#
+# Boot options
+#
+CONFIG_USE_OF=y
+CONFIG_ATAGS=y
+# CONFIG_DEPRECATED_PARAM_STRUCT is not set
+CONFIG_ZBOOT_ROM_TEXT=0
+CONFIG_ZBOOT_ROM_BSS=0
+CONFIG_ARM_APPENDED_DTB=y
+CONFIG_ARM_ATAG_DTB_COMPAT=y
+CONFIG_ARM_ATAG_DTB_COMPAT_CMDLINE_FROM_BOOTLOADER=y
+# CONFIG_ARM_ATAG_DTB_COMPAT_CMDLINE_EXTEND is not set
+CONFIG_CMDLINE=""
+# CONFIG_KEXEC is not set
+# CONFIG_CRASH_DUMP is not set
+CONFIG_AUTO_ZRELADDR=y
+# CONFIG_EFI is not set
+
+#
+# CPU Power Management
+#
+
+#
+# CPU Frequency scaling
+#
+CONFIG_CPU_FREQ=y
+CONFIG_CPU_FREQ_GOV_ATTR_SET=y
+CONFIG_CPU_FREQ_GOV_COMMON=y
+CONFIG_CPU_FREQ_STAT=y
+# CONFIG_CPU_FREQ_STAT_DETAILS is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_PERFORMANCE is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_POWERSAVE is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_USERSPACE is not set
+CONFIG_CPU_FREQ_DEFAULT_GOV_ONDEMAND=y
+# CONFIG_CPU_FREQ_DEFAULT_GOV_CONSERVATIVE is not set
+CONFIG_CPU_FREQ_GOV_PERFORMANCE=y
+# CONFIG_CPU_FREQ_GOV_POWERSAVE is not set
+CONFIG_CPU_FREQ_GOV_USERSPACE=y
+CONFIG_CPU_FREQ_GOV_ONDEMAND=y
+# CONFIG_CPU_FREQ_GOV_CONSERVATIVE is not set
+
+#
+# CPU frequency scaling drivers
+#
+CONFIG_CPUFREQ_DT=y
+CONFIG_CPUFREQ_DT_PLATDEV=y
+# CONFIG_ARM_KIRKWOOD_CPUFREQ is not set
+# CONFIG_QORIQ_CPUFREQ is not set
+
+#
+# CPU Idle
+#
+# CONFIG_CPU_IDLE is not set
+# CONFIG_ARCH_NEEDS_CPU_IDLE_COUPLED is not set
+
+#
+# Floating point emulation
+#
+
+#
+# At least one emulation must be selected
+#
+CONFIG_VFP=y
+CONFIG_VFPv3=y
+CONFIG_NEON=y
+# CONFIG_KERNEL_MODE_NEON is not set
+
+#
+# Userspace binary formats
+#
+CONFIG_BINFMT_ELF=y
+CONFIG_ELFCORE=y
+CONFIG_CORE_DUMP_DEFAULT_ELF_HEADERS=y
+CONFIG_BINFMT_SCRIPT=y
+# CONFIG_BINFMT_FLAT is not set
+# CONFIG_HAVE_AOUT is not set
+# CONFIG_BINFMT_MISC is not set
+CONFIG_COREDUMP=y
+
+#
+# Power management options
+#
+CONFIG_SUSPEND=y
+CONFIG_SUSPEND_FREEZER=y
+CONFIG_HIBERNATE_CALLBACKS=y
+CONFIG_HIBERNATION=y
+CONFIG_PM_STD_PARTITION=""
+CONFIG_PM_SLEEP=y
+# CONFIG_PM_AUTOSLEEP is not set
+# CONFIG_PM_WAKELOCKS is not set
+CONFIG_PM=y
+CONFIG_PM_DEBUG=y
+# CONFIG_PM_ADVANCED_DEBUG is not set
+CONFIG_PM_SLEEP_DEBUG=y
+# CONFIG_APM_EMULATION is not set
+CONFIG_PM_OPP=y
+CONFIG_PM_CLK=y
+# CONFIG_WQ_POWER_EFFICIENT_DEFAULT is not set
+CONFIG_CPU_PM=y
+CONFIG_ARCH_SUSPEND_POSSIBLE=y
+CONFIG_ARM_CPU_SUSPEND=y
+CONFIG_ARCH_HIBERNATION_POSSIBLE=y
+CONFIG_NET=y
+
+#
+# Networking options
+#
+CONFIG_PACKET=y
+# CONFIG_PACKET_DIAG is not set
+CONFIG_UNIX=y
+# CONFIG_UNIX_DIAG is not set
+CONFIG_XFRM=y
+CONFIG_XFRM_ALGO=y
+CONFIG_XFRM_USER=y
+# CONFIG_XFRM_SUB_POLICY is not set
+# CONFIG_XFRM_MIGRATE is not set
+# CONFIG_XFRM_STATISTICS is not set
+CONFIG_NET_KEY=y
+# CONFIG_NET_KEY_MIGRATE is not set
+CONFIG_INET=y
+CONFIG_IP_MULTICAST=y
+CONFIG_IP_ADVANCED_ROUTER=y
+# CONFIG_IP_FIB_TRIE_STATS is not set
+CONFIG_IP_MULTIPLE_TABLES=y
+CONFIG_IP_ROUTE_MULTIPATH=y
+CONFIG_IP_ROUTE_VERBOSE=y
+CONFIG_IP_PNP=y
+# CONFIG_IP_PNP_DHCP is not set
+# CONFIG_IP_PNP_BOOTP is not set
+# CONFIG_IP_PNP_RARP is not set
+# CONFIG_NET_IPIP is not set
+# CONFIG_NET_IPGRE_DEMUX is not set
+# CONFIG_NET_IP_TUNNEL is not set
+CONFIG_IP_MROUTE=y
+# CONFIG_IP_MROUTE_MULTIPLE_TABLES is not set
+CONFIG_IP_PIMSM_V1=y
+CONFIG_IP_PIMSM_V2=y
+CONFIG_SYN_COOKIES=y
+# CONFIG_NET_UDP_TUNNEL is not set
+# CONFIG_NET_FOU is not set
+# CONFIG_INET_AH is not set
+# CONFIG_INET_ESP is not set
+# CONFIG_INET_IPCOMP is not set
+# CONFIG_INET_XFRM_TUNNEL is not set
+# CONFIG_INET_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_TRANSPORT is not set
+# CONFIG_INET_XFRM_MODE_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_BEET is not set
+CONFIG_INET_DIAG=y
+CONFIG_INET_TCP_DIAG=y
+# CONFIG_INET_UDP_DIAG is not set
+# CONFIG_INET_DIAG_DESTROY is not set
+CONFIG_TCP_CONG_ADVANCED=y
+CONFIG_TCP_CONG_BIC=m
+CONFIG_TCP_CONG_CUBIC=y
+CONFIG_TCP_CONG_WESTWOOD=m
+CONFIG_TCP_CONG_HTCP=m
+# CONFIG_TCP_CONG_HSTCP is not set
+# CONFIG_TCP_CONG_HYBLA is not set
+# CONFIG_TCP_CONG_VEGAS is not set
+# CONFIG_TCP_CONG_NV is not set
+# CONFIG_TCP_CONG_SCALABLE is not set
+# CONFIG_TCP_CONG_LP is not set
+# CONFIG_TCP_CONG_VENO is not set
+# CONFIG_TCP_CONG_YEAH is not set
+# CONFIG_TCP_CONG_ILLINOIS is not set
+# CONFIG_TCP_CONG_DCTCP is not set
+# CONFIG_TCP_CONG_CDG is not set
+# CONFIG_TCP_CONG_BBR is not set
+CONFIG_DEFAULT_CUBIC=y
+# CONFIG_DEFAULT_RENO is not set
+CONFIG_DEFAULT_TCP_CONG="cubic"
+CONFIG_TCP_MD5SIG=y
+# CONFIG_IPV6 is not set
+# CONFIG_NETWORK_SECMARK is not set
+# CONFIG_NET_PTP_CLASSIFY is not set
+# CONFIG_NETWORK_PHY_TIMESTAMPING is not set
+# CONFIG_NETFILTER is not set
+# CONFIG_IP_DCCP is not set
+# CONFIG_IP_SCTP is not set
+# CONFIG_RDS is not set
+# CONFIG_TIPC is not set
+# CONFIG_ATM is not set
+# CONFIG_L2TP is not set
+# CONFIG_BRIDGE is not set
+CONFIG_HAVE_NET_DSA=y
+# CONFIG_VLAN_8021Q is not set
+# CONFIG_DECNET is not set
+# CONFIG_LLC2 is not set
+# CONFIG_IPX is not set
+# CONFIG_ATALK is not set
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_PHONET is not set
+# CONFIG_IEEE802154 is not set
+# CONFIG_NET_SCHED is not set
+# CONFIG_DCB is not set
+CONFIG_DNS_RESOLVER=y
+# CONFIG_BATMAN_ADV is not set
+# CONFIG_OPENVSWITCH is not set
+# CONFIG_VSOCKETS is not set
+# CONFIG_NETLINK_DIAG is not set
+# CONFIG_MPLS is not set
+# CONFIG_HSR is not set
+# CONFIG_NET_SWITCHDEV is not set
+# CONFIG_NET_L3_MASTER_DEV is not set
+# CONFIG_NET_NCSI is not set
+# CONFIG_SOCK_CGROUP_DATA is not set
+# CONFIG_CGROUP_NET_PRIO is not set
+# CONFIG_CGROUP_NET_CLASSID is not set
+CONFIG_NET_RX_BUSY_POLL=y
+CONFIG_BQL=y
+# CONFIG_BPF_JIT is not set
+
+#
+# Network testing
+#
+# CONFIG_NET_PKTGEN is not set
+# CONFIG_HAMRADIO is not set
+# CONFIG_CAN is not set
+# CONFIG_IRDA is not set
+# CONFIG_BT is not set
+# CONFIG_AF_RXRPC is not set
+# CONFIG_AF_KCM is not set
+# CONFIG_STREAM_PARSER is not set
+CONFIG_FIB_RULES=y
+CONFIG_WIRELESS=y
+CONFIG_WEXT_CORE=y
+CONFIG_WEXT_PROC=y
+CONFIG_CFG80211=m
+# CONFIG_NL80211_TESTMODE is not set
+# CONFIG_CFG80211_DEVELOPER_WARNINGS is not set
+CONFIG_CFG80211_DEFAULT_PS=y
+# CONFIG_CFG80211_INTERNAL_REGDB is not set
+CONFIG_CFG80211_CRDA_SUPPORT=y
+CONFIG_CFG80211_WEXT=y
+# CONFIG_LIB80211 is not set
+CONFIG_MAC80211=m
+CONFIG_MAC80211_HAS_RC=y
+CONFIG_MAC80211_RC_MINSTREL=y
+CONFIG_MAC80211_RC_MINSTREL_HT=y
+# CONFIG_MAC80211_RC_MINSTREL_VHT is not set
+CONFIG_MAC80211_RC_DEFAULT_MINSTREL=y
+CONFIG_MAC80211_RC_DEFAULT="minstrel_ht"
+CONFIG_MAC80211_MESH=y
+# CONFIG_MAC80211_MESSAGE_TRACING is not set
+# CONFIG_MAC80211_DEBUG_MENU is not set
+CONFIG_MAC80211_STA_HASH_MAX_SIZE=0
+# CONFIG_WIMAX is not set
+# CONFIG_RFKILL is not set
+# CONFIG_RFKILL_REGULATOR is not set
+# CONFIG_NET_9P is not set
+# CONFIG_CAIF is not set
+# CONFIG_CEPH_LIB is not set
+# CONFIG_NFC is not set
+# CONFIG_LWTUNNEL is not set
+# CONFIG_DST_CACHE is not set
+# CONFIG_NET_DEVLINK is not set
+CONFIG_MAY_USE_DEVLINK=y
+CONFIG_HAVE_CBPF_JIT=y
+
+#
+# Device Drivers
+#
+CONFIG_ARM_AMBA=y
+
+#
+# Generic Driver Options
+#
+# CONFIG_UEVENT_HELPER is not set
+CONFIG_DEVTMPFS=y
+# CONFIG_DEVTMPFS_MOUNT is not set
+CONFIG_STANDALONE=y
+# CONFIG_PREVENT_FIRMWARE_BUILD is not set
+CONFIG_FW_LOADER=y
+CONFIG_FIRMWARE_IN_KERNEL=y
+CONFIG_EXTRA_FIRMWARE=""
+# CONFIG_FW_LOADER_USER_HELPER_FALLBACK is not set
+CONFIG_ALLOW_DEV_COREDUMP=y
+# CONFIG_DEBUG_DRIVER is not set
+# CONFIG_DEBUG_DEVRES is not set
+# CONFIG_DEBUG_TEST_DRIVER_REMOVE is not set
+# CONFIG_SYS_HYPERVISOR is not set
+# CONFIG_GENERIC_CPU_DEVICES is not set
+# CONFIG_DMA_SHARED_BUFFER is not set
+
+#
+# Bus devices
+#
+# CONFIG_BRCMSTB_GISB_ARB is not set
+# CONFIG_VEXPRESS_CONFIG is not set
+# CONFIG_CONNECTOR is not set
+CONFIG_MTD=y
+# CONFIG_MTD_TESTS is not set
+# CONFIG_MTD_REDBOOT_PARTS is not set
+CONFIG_MTD_CMDLINE_PARTS=y
+# CONFIG_MTD_AFS_PARTS is not set
+CONFIG_MTD_OF_PARTS=y
+# CONFIG_MTD_AR7_PARTS is not set
+
+#
+# User Modules And Translation Layers
+#
+CONFIG_MTD_BLKDEVS=y
+CONFIG_MTD_BLOCK=y
+# CONFIG_FTL is not set
+# CONFIG_NFTL is not set
+# CONFIG_INFTL is not set
+# CONFIG_RFD_FTL is not set
+# CONFIG_SSFDC is not set
+# CONFIG_SM_FTL is not set
+# CONFIG_MTD_OOPS is not set
+# CONFIG_MTD_SWAP is not set
+# CONFIG_MTD_PARTITIONED_MASTER is not set
+
+#
+# RAM/ROM/Flash chip drivers
+#
+# CONFIG_MTD_CFI is not set
+# CONFIG_MTD_JEDECPROBE is not set
+CONFIG_MTD_MAP_BANK_WIDTH_1=y
+CONFIG_MTD_MAP_BANK_WIDTH_2=y
+CONFIG_MTD_MAP_BANK_WIDTH_4=y
+# CONFIG_MTD_MAP_BANK_WIDTH_8 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_16 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_32 is not set
+CONFIG_MTD_CFI_I1=y
+CONFIG_MTD_CFI_I2=y
+# CONFIG_MTD_CFI_I4 is not set
+# CONFIG_MTD_CFI_I8 is not set
+# CONFIG_MTD_RAM is not set
+# CONFIG_MTD_ROM is not set
+# CONFIG_MTD_ABSENT is not set
+
+#
+# Mapping drivers for chip access
+#
+# CONFIG_MTD_COMPLEX_MAPPINGS is not set
+# CONFIG_MTD_PLATRAM is not set
+
+#
+# Self-contained MTD device drivers
+#
+# CONFIG_MTD_DATAFLASH is not set
+# CONFIG_MTD_M25P80 is not set
+# CONFIG_MTD_SST25L is not set
+# CONFIG_MTD_SLRAM is not set
+# CONFIG_MTD_PHRAM is not set
+# CONFIG_MTD_MTDRAM is not set
+# CONFIG_MTD_BLOCK2MTD is not set
+
+#
+# Disk-On-Chip Device Drivers
+#
+# CONFIG_MTD_DOCG3 is not set
+CONFIG_MTD_NAND_ECC=y
+# CONFIG_MTD_NAND_ECC_SMC is not set
+CONFIG_MTD_NAND=y
+# CONFIG_MTD_NAND_ECC_BCH is not set
+# CONFIG_MTD_SM_COMMON is not set
+# CONFIG_MTD_NAND_DENALI_DT is not set
+# CONFIG_MTD_NAND_GPIO is not set
+# CONFIG_MTD_NAND_OMAP_BCH_BUILD is not set
+CONFIG_MTD_NAND_IDS=y
+# CONFIG_MTD_NAND_DISKONCHIP is not set
+# CONFIG_MTD_NAND_DOCG4 is not set
+# CONFIG_MTD_NAND_NANDSIM is not set
+# CONFIG_MTD_NAND_BRCMNAND is not set
+# CONFIG_MTD_NAND_PLATFORM is not set
+# CONFIG_MTD_NAND_HISI504 is not set
+# CONFIG_MTD_NAND_MTK is not set
+CONFIG_MTD_SPI_NAND_HISI_BVT=y
+CONFIG_MTD_NAND_HISNFC100=y
+CONFIG_HISNFC100_MAX_CHIP=1
+CONFIG_HISNFC100_HARDWARE_PAGESIZE_ECC=y
+# CONFIG_HISNFC100_AUTO_PAGESIZE_ECC is not set
+# CONFIG_HISNFC100_PAGESIZE_AUTO_ECC_NONE is not set
+# CONFIG_MTD_ONENAND is not set
+
+#
+# LPDDR & LPDDR2 PCM memory drivers
+#
+# CONFIG_MTD_LPDDR is not set
+# CONFIG_MTD_LPDDR2_NVM is not set
+CONFIG_MTD_SPI_NOR=y
+# CONFIG_MTD_MT81xx_NOR is not set
+# CONFIG_MTD_SPI_NOR_USE_4K_SECTORS is not set
+# CONFIG_SPI_CADENCE_QUADSPI is not set
+# CONFIG_SPI_HISI_SFC is not set
+CONFIG_MTD_SPI_IDS=y
+CONFIG_CLOSE_SPI_8PIN_4IO=y
+CONFIG_MTD_HISFC350=y
+CONFIG_HISFC350_SYSCTRL_ADDRESS=0x20030000
+CONFIG_HISFC350_CHIP_NUM=2
+# CONFIG_HISFC350_SHOW_CYCLE_TIMING is not set
+# CONFIG_HISFC350_ENABLE_CHIPSELECT_0 is not set
+CONFIG_HISFC350_ENABLE_CHIPSELECT_1=y
+# CONFIG_HISFC350_ENABLE_INTR_DMA is not set
+CONFIG_CMD_SPI_BLOCK_PROTECTION=y
+CONFIG_MTD_UBI=y
+CONFIG_MTD_UBI_WL_THRESHOLD=4096
+CONFIG_MTD_UBI_BEB_LIMIT=20
+# CONFIG_MTD_UBI_FASTMAP is not set
+# CONFIG_MTD_UBI_GLUEBI is not set
+# CONFIG_MTD_UBI_BLOCK is not set
+CONFIG_DTC=y
+CONFIG_OF=y
+# CONFIG_OF_UNITTEST is not set
+CONFIG_OF_FLATTREE=y
+CONFIG_OF_EARLY_FLATTREE=y
+CONFIG_OF_ADDRESS=y
+CONFIG_OF_IRQ=y
+CONFIG_OF_NET=y
+CONFIG_OF_MDIO=y
+CONFIG_OF_RESERVED_MEM=y
+# CONFIG_OF_OVERLAY is not set
+CONFIG_ARCH_MIGHT_HAVE_PC_PARPORT=y
+# CONFIG_PARPORT is not set
+CONFIG_BLK_DEV=y
+# CONFIG_BLK_DEV_NULL_BLK is not set
+# CONFIG_BLK_DEV_COW_COMMON is not set
+# CONFIG_BLK_DEV_LOOP is not set
+# CONFIG_BLK_DEV_DRBD is not set
+# CONFIG_BLK_DEV_NBD is not set
+CONFIG_BLK_DEV_RAM=y
+CONFIG_BLK_DEV_RAM_COUNT=16
+CONFIG_BLK_DEV_RAM_SIZE=65536
+# CONFIG_CDROM_PKTCDVD is not set
+# CONFIG_ATA_OVER_ETH is not set
+# CONFIG_MG_DISK is not set
+# CONFIG_BLK_DEV_RBD is not set
+# CONFIG_NVME_TARGET is not set
+
+#
+# Misc devices
+#
+# CONFIG_SENSORS_LIS3LV02D is not set
+# CONFIG_AD525X_DPOT is not set
+# CONFIG_DUMMY_IRQ is not set
+# CONFIG_ICS932S401 is not set
+# CONFIG_ENCLOSURE_SERVICES is not set
+# CONFIG_APDS9802ALS is not set
+# CONFIG_ISL29003 is not set
+# CONFIG_ISL29020 is not set
+# CONFIG_SENSORS_TSL2550 is not set
+# CONFIG_SENSORS_BH1770 is not set
+# CONFIG_SENSORS_APDS990X is not set
+# CONFIG_HMC6352 is not set
+# CONFIG_DS1682 is not set
+# CONFIG_TI_DAC7512 is not set
+# CONFIG_USB_SWITCH_FSA9480 is not set
+# CONFIG_LATTICE_ECP3_CONFIG is not set
+# CONFIG_SRAM is not set
+# CONFIG_C2PORT is not set
+
+#
+# EEPROM support
+#
+# CONFIG_EEPROM_AT24 is not set
+# CONFIG_EEPROM_AT25 is not set
+# CONFIG_EEPROM_LEGACY is not set
+# CONFIG_EEPROM_MAX6875 is not set
+# CONFIG_EEPROM_93CX6 is not set
+# CONFIG_EEPROM_93XX46 is not set
+
+#
+# Texas Instruments shared transport line discipline
+#
+# CONFIG_TI_ST is not set
+# CONFIG_SENSORS_LIS3_SPI is not set
+# CONFIG_SENSORS_LIS3_I2C is not set
+
+#
+# Altera FPGA firmware download module
+#
+# CONFIG_ALTERA_STAPL is not set
+
+#
+# Intel MIC Bus Driver
+#
+
+#
+# SCIF Bus Driver
+#
+
+#
+# VOP Bus Driver
+#
+
+#
+# Intel MIC Host Driver
+#
+
+#
+# Intel MIC Card Driver
+#
+
+#
+# SCIF Driver
+#
+
+#
+# Intel MIC Coprocessor State Management (COSM) Drivers
+#
+
+#
+# VOP Driver
+#
+# CONFIG_ECHO is not set
+# CONFIG_CXL_BASE is not set
+# CONFIG_CXL_AFU_DRIVER_OPS is not set
+
+#
+# SCSI device support
+#
+CONFIG_SCSI_MOD=y
+# CONFIG_RAID_ATTRS is not set
+CONFIG_SCSI=y
+CONFIG_SCSI_DMA=y
+CONFIG_SCSI_NETLINK=y
+# CONFIG_SCSI_MQ_DEFAULT is not set
+CONFIG_SCSI_PROC_FS=y
+
+#
+# SCSI support type (disk, tape, CD-ROM)
+#
+CONFIG_BLK_DEV_SD=y
+# CONFIG_CHR_DEV_ST is not set
+# CONFIG_CHR_DEV_OSST is not set
+# CONFIG_BLK_DEV_SR is not set
+# CONFIG_CHR_DEV_SG is not set
+# CONFIG_CHR_DEV_SCH is not set
+# CONFIG_SCSI_CONSTANTS is not set
+# CONFIG_SCSI_LOGGING is not set
+# CONFIG_SCSI_SCAN_ASYNC is not set
+
+#
+# SCSI Transports
+#
+# CONFIG_SCSI_SPI_ATTRS is not set
+CONFIG_SCSI_FC_ATTRS=y
+# CONFIG_SCSI_ISCSI_ATTRS is not set
+# CONFIG_SCSI_SAS_ATTRS is not set
+# CONFIG_SCSI_SAS_LIBSAS is not set
+# CONFIG_SCSI_SRP_ATTRS is not set
+CONFIG_SCSI_LOWLEVEL=y
+# CONFIG_ISCSI_TCP is not set
+# CONFIG_ISCSI_BOOT_SYSFS is not set
+# CONFIG_SCSI_UFSHCD is not set
+# CONFIG_LIBFC is not set
+# CONFIG_SCSI_DEBUG is not set
+# CONFIG_SCSI_DH is not set
+# CONFIG_SCSI_OSD_INITIATOR is not set
+# CONFIG_ATA is not set
+# CONFIG_MD is not set
+# CONFIG_TARGET_CORE is not set
+CONFIG_NETDEVICES=y
+CONFIG_NET_CORE=y
+# CONFIG_BONDING is not set
+# CONFIG_DUMMY is not set
+# CONFIG_EQUALIZER is not set
+# CONFIG_NET_TEAM is not set
+# CONFIG_MACVLAN is not set
+# CONFIG_VXLAN is not set
+# CONFIG_MACSEC is not set
+# CONFIG_NETCONSOLE is not set
+# CONFIG_NETPOLL is not set
+# CONFIG_NET_POLL_CONTROLLER is not set
+# CONFIG_TUN is not set
+# CONFIG_TUN_VNET_CROSS_LE is not set
+# CONFIG_VETH is not set
+# CONFIG_NLMON is not set
+
+#
+# CAIF transport drivers
+#
+
+#
+# Distributed Switch Architecture drivers
+#
+CONFIG_ETHERNET=y
+# CONFIG_ALTERA_TSE is not set
+# CONFIG_NET_VENDOR_AMAZON is not set
+# CONFIG_NET_VENDOR_ARC is not set
+# CONFIG_NET_VENDOR_AURORA is not set
+# CONFIG_NET_CADENCE is not set
+# CONFIG_NET_VENDOR_BROADCOM is not set
+# CONFIG_NET_VENDOR_CIRRUS is not set
+# CONFIG_DM9000 is not set
+# CONFIG_DNET is not set
+# CONFIG_NET_VENDOR_EZCHIP is not set
+# CONFIG_NET_VENDOR_FARADAY is not set
+CONFIG_NET_VENDOR_HISILICON=y
+# CONFIG_HIX5HD2_GMAC is not set
+# CONFIG_HISI_FEMAC is not set
+# CONFIG_HIP04_ETH is not set
+# CONFIG_HNS is not set
+# CONFIG_HNS_DSAF is not set
+# CONFIG_HNS_ENET is not set
+CONFIG_HIETH_GMAC=y
+# CONFIG_HIGMAC_DESC_4WORD is not set
+# CONFIG_HIGMAC_RXCSUM is not set
+CONFIG_RX_FLOW_CTRL_SUPPORT=y
+CONFIG_TX_FLOW_CTRL_SUPPORT=y
+CONFIG_TX_FLOW_CTRL_PAUSE_TIME=0xFFFF
+CONFIG_TX_FLOW_CTRL_PAUSE_INTERVAL=0xFFFF
+CONFIG_TX_FLOW_CTRL_ACTIVE_THRESHOLD=16
+CONFIG_TX_FLOW_CTRL_DEACTIVE_THRESHOLD=32
+# CONFIG_NET_VENDOR_INTEL is not set
+# CONFIG_NET_VENDOR_MARVELL is not set
+# CONFIG_NET_VENDOR_MICREL is not set
+# CONFIG_NET_VENDOR_MICROCHIP is not set
+# CONFIG_NET_VENDOR_NATSEMI is not set
+# CONFIG_NET_VENDOR_NETRONOME is not set
+# CONFIG_ETHOC is not set
+# CONFIG_NET_VENDOR_QUALCOMM is not set
+# CONFIG_NET_VENDOR_RENESAS is not set
+# CONFIG_NET_VENDOR_ROCKER is not set
+# CONFIG_NET_VENDOR_SAMSUNG is not set
+# CONFIG_NET_VENDOR_SEEQ is not set
+# CONFIG_NET_VENDOR_SMSC is not set
+# CONFIG_NET_VENDOR_STMICRO is not set
+# CONFIG_NET_VENDOR_SYNOPSYS is not set
+# CONFIG_NET_VENDOR_VIA is not set
+# CONFIG_NET_VENDOR_WIZNET is not set
+CONFIG_PHYLIB=y
+CONFIG_SWPHY=y
+
+#
+# MDIO bus device drivers
+#
+# CONFIG_MDIO_BCM_UNIMAC is not set
+# CONFIG_MDIO_BITBANG is not set
+# CONFIG_MDIO_BUS_MUX_GPIO is not set
+# CONFIG_MDIO_BUS_MUX_MMIOREG is not set
+# CONFIG_MDIO_HISI_FEMAC is not set
+CONFIG_MDIO_HISI_GEMAC=y
+
+#
+# MII PHY device drivers
+#
+# CONFIG_AMD_PHY is not set
+# CONFIG_AQUANTIA_PHY is not set
+# CONFIG_AT803X_PHY is not set
+# CONFIG_BCM7XXX_PHY is not set
+# CONFIG_BCM87XX_PHY is not set
+# CONFIG_BROADCOM_PHY is not set
+# CONFIG_CICADA_PHY is not set
+# CONFIG_DAVICOM_PHY is not set
+# CONFIG_DP83848_PHY is not set
+# CONFIG_DP83867_PHY is not set
+CONFIG_FIXED_PHY=y
+# CONFIG_ICPLUS_PHY is not set
+# CONFIG_INTEL_XWAY_PHY is not set
+# CONFIG_LSI_ET1011C_PHY is not set
+# CONFIG_LXT_PHY is not set
+# CONFIG_MARVELL_PHY is not set
+# CONFIG_MICREL_PHY is not set
+# CONFIG_MICROCHIP_PHY is not set
+# CONFIG_MICROSEMI_PHY is not set
+# CONFIG_NATIONAL_PHY is not set
+# CONFIG_QSEMI_PHY is not set
+# CONFIG_REALTEK_PHY is not set
+# CONFIG_SMSC_PHY is not set
+# CONFIG_STE10XP is not set
+# CONFIG_TERANETICS_PHY is not set
+# CONFIG_VITESSE_PHY is not set
+# CONFIG_XILINX_GMII2RGMII is not set
+# CONFIG_MICREL_KS8995MA is not set
+# CONFIG_PPP is not set
+# CONFIG_SLIP is not set
+CONFIG_USB_NET_DRIVERS=y
+# CONFIG_USB_CATC is not set
+# CONFIG_USB_KAWETH is not set
+# CONFIG_USB_PEGASUS is not set
+# CONFIG_USB_RTL8150 is not set
+# CONFIG_USB_RTL8152 is not set
+# CONFIG_USB_LAN78XX is not set
+# CONFIG_USB_USBNET is not set
+# CONFIG_USB_IPHETH is not set
+# CONFIG_WLAN is not set
+
+#
+# Enable WiMAX (Networking options) to see the WiMAX drivers
+#
+# CONFIG_WAN is not set
+# CONFIG_ISDN is not set
+# CONFIG_NVM is not set
+
+#
+# Input device support
+#
+CONFIG_INPUT=y
+# CONFIG_INPUT_FF_MEMLESS is not set
+# CONFIG_INPUT_POLLDEV is not set
+# CONFIG_INPUT_SPARSEKMAP is not set
+# CONFIG_INPUT_MATRIXKMAP is not set
+
+#
+# Userland interfaces
+#
+CONFIG_INPUT_MOUSEDEV=y
+CONFIG_INPUT_MOUSEDEV_PSAUX=y
+CONFIG_INPUT_MOUSEDEV_SCREEN_X=1024
+CONFIG_INPUT_MOUSEDEV_SCREEN_Y=768
+# CONFIG_INPUT_JOYDEV is not set
+CONFIG_INPUT_EVDEV=y
+# CONFIG_INPUT_EVBUG is not set
+
+#
+# Input Device Drivers
+#
+CONFIG_INPUT_KEYBOARD=y
+# CONFIG_KEYBOARD_ADP5588 is not set
+# CONFIG_KEYBOARD_ADP5589 is not set
+CONFIG_KEYBOARD_ATKBD=y
+# CONFIG_KEYBOARD_QT1070 is not set
+# CONFIG_KEYBOARD_QT2160 is not set
+# CONFIG_KEYBOARD_LKKBD is not set
+# CONFIG_KEYBOARD_GPIO is not set
+# CONFIG_KEYBOARD_GPIO_POLLED is not set
+# CONFIG_KEYBOARD_TCA6416 is not set
+# CONFIG_KEYBOARD_TCA8418 is not set
+# CONFIG_KEYBOARD_MATRIX is not set
+# CONFIG_KEYBOARD_LM8333 is not set
+# CONFIG_KEYBOARD_MAX7359 is not set
+# CONFIG_KEYBOARD_MCS is not set
+# CONFIG_KEYBOARD_MPR121 is not set
+# CONFIG_KEYBOARD_NEWTON is not set
+# CONFIG_KEYBOARD_OPENCORES is not set
+# CONFIG_KEYBOARD_SAMSUNG is not set
+# CONFIG_KEYBOARD_STOWAWAY is not set
+# CONFIG_KEYBOARD_SUNKBD is not set
+# CONFIG_KEYBOARD_OMAP4 is not set
+# CONFIG_KEYBOARD_XTKBD is not set
+# CONFIG_KEYBOARD_CAP11XX is not set
+# CONFIG_KEYBOARD_BCM is not set
+CONFIG_INPUT_MOUSE=y
+CONFIG_MOUSE_PS2=y
+CONFIG_MOUSE_PS2_ALPS=y
+CONFIG_MOUSE_PS2_BYD=y
+CONFIG_MOUSE_PS2_LOGIPS2PP=y
+CONFIG_MOUSE_PS2_SYNAPTICS=y
+CONFIG_MOUSE_PS2_CYPRESS=y
+CONFIG_MOUSE_PS2_TRACKPOINT=y
+# CONFIG_MOUSE_PS2_ELANTECH is not set
+# CONFIG_MOUSE_PS2_SENTELIC is not set
+# CONFIG_MOUSE_PS2_TOUCHKIT is not set
+CONFIG_MOUSE_PS2_FOCALTECH=y
+# CONFIG_MOUSE_SERIAL is not set
+# CONFIG_MOUSE_APPLETOUCH is not set
+# CONFIG_MOUSE_BCM5974 is not set
+# CONFIG_MOUSE_CYAPA is not set
+# CONFIG_MOUSE_ELAN_I2C is not set
+# CONFIG_MOUSE_VSXXXAA is not set
+# CONFIG_MOUSE_GPIO is not set
+# CONFIG_MOUSE_SYNAPTICS_I2C is not set
+# CONFIG_MOUSE_SYNAPTICS_USB is not set
+# CONFIG_INPUT_JOYSTICK is not set
+# CONFIG_INPUT_TABLET is not set
+# CONFIG_INPUT_TOUCHSCREEN is not set
+CONFIG_INPUT_MISC=y
+# CONFIG_INPUT_AD714X is not set
+# CONFIG_INPUT_ATMEL_CAPTOUCH is not set
+# CONFIG_INPUT_BMA150 is not set
+# CONFIG_INPUT_E3X0_BUTTON is not set
+# CONFIG_INPUT_MMA8450 is not set
+# CONFIG_INPUT_MPU3050 is not set
+# CONFIG_INPUT_GP2A is not set
+# CONFIG_INPUT_GPIO_BEEPER is not set
+# CONFIG_INPUT_GPIO_TILT_POLLED is not set
+# CONFIG_INPUT_GPIO_DECODER is not set
+# CONFIG_INPUT_ATI_REMOTE2 is not set
+# CONFIG_INPUT_KEYSPAN_REMOTE is not set
+# CONFIG_INPUT_KXTJ9 is not set
+# CONFIG_INPUT_POWERMATE is not set
+# CONFIG_INPUT_YEALINK is not set
+# CONFIG_INPUT_CM109 is not set
+# CONFIG_INPUT_REGULATOR_HAPTIC is not set
+CONFIG_INPUT_UINPUT=y
+# CONFIG_INPUT_PCF8574 is not set
+# CONFIG_INPUT_GPIO_ROTARY_ENCODER is not set
+# CONFIG_INPUT_ADXL34X is not set
+# CONFIG_INPUT_CMA3000 is not set
+# CONFIG_INPUT_DRV260X_HAPTICS is not set
+# CONFIG_INPUT_DRV2665_HAPTICS is not set
+# CONFIG_INPUT_DRV2667_HAPTICS is not set
+# CONFIG_RMI4_CORE is not set
+
+#
+# Hardware I/O ports
+#
+CONFIG_SERIO=y
+CONFIG_SERIO_SERPORT=y
+# CONFIG_SERIO_AMBAKMI is not set
+CONFIG_SERIO_LIBPS2=y
+# CONFIG_SERIO_RAW is not set
+# CONFIG_SERIO_ALTERA_PS2 is not set
+# CONFIG_SERIO_PS2MULT is not set
+# CONFIG_SERIO_ARC_PS2 is not set
+# CONFIG_SERIO_APBPS2 is not set
+# CONFIG_USERIO is not set
+# CONFIG_GAMEPORT is not set
+
+#
+# Character devices
+#
+CONFIG_TTY=y
+CONFIG_VT=y
+CONFIG_CONSOLE_TRANSLATIONS=y
+CONFIG_VT_CONSOLE=y
+CONFIG_VT_CONSOLE_SLEEP=y
+CONFIG_HW_CONSOLE=y
+# CONFIG_VT_HW_CONSOLE_BINDING is not set
+CONFIG_UNIX98_PTYS=y
+# CONFIG_LEGACY_PTYS is not set
+# CONFIG_SERIAL_NONSTANDARD is not set
+# CONFIG_N_GSM is not set
+# CONFIG_TRACE_SINK is not set
+CONFIG_DEVMEM=y
+# CONFIG_DEVKMEM is not set
+
+#
+# Serial drivers
+#
+CONFIG_SERIAL_EARLYCON=y
+# CONFIG_SERIAL_8250 is not set
+
+#
+# Non-8250 serial port support
+#
+# CONFIG_SERIAL_AMBA_PL010 is not set
+CONFIG_SERIAL_AMBA_PL011=y
+CONFIG_SERIAL_AMBA_PL011_CONSOLE=y
+# CONFIG_SERIAL_EARLYCON_ARM_SEMIHOST is not set
+# CONFIG_SERIAL_MAX3100 is not set
+# CONFIG_SERIAL_MAX310X is not set
+# CONFIG_SERIAL_UARTLITE is not set
+CONFIG_SERIAL_CORE=y
+CONFIG_SERIAL_CORE_CONSOLE=y
+# CONFIG_SERIAL_SCCNXP is not set
+# CONFIG_SERIAL_SC16IS7XX is not set
+# CONFIG_SERIAL_BCM63XX is not set
+# CONFIG_SERIAL_ALTERA_JTAGUART is not set
+# CONFIG_SERIAL_ALTERA_UART is not set
+# CONFIG_SERIAL_IFX6X60 is not set
+# CONFIG_SERIAL_XILINX_PS_UART is not set
+# CONFIG_SERIAL_ARC is not set
+# CONFIG_SERIAL_FSL_LPUART is not set
+# CONFIG_SERIAL_CONEXANT_DIGICOLOR is not set
+# CONFIG_SERIAL_ST_ASC is not set
+# CONFIG_SERIAL_STM32 is not set
+# CONFIG_HVC_DCC is not set
+# CONFIG_IPMI_HANDLER is not set
+# CONFIG_HW_RANDOM is not set
+# CONFIG_R3964 is not set
+# CONFIG_RAW_DRIVER is not set
+# CONFIG_TCG_TPM is not set
+# CONFIG_XILLYBUS is not set
+
+#
+# I2C support
+#
+CONFIG_I2C=y
+CONFIG_I2C_BOARDINFO=y
+CONFIG_I2C_COMPAT=y
+CONFIG_I2C_CHARDEV=y
+# CONFIG_I2C_MUX is not set
+CONFIG_I2C_HELPER_AUTO=y
+
+#
+# I2C Hardware Bus support
+#
+
+#
+# I2C system bus drivers (mostly embedded / system-on-chip)
+#
+# CONFIG_I2C_CBUS_GPIO is not set
+# CONFIG_I2C_DESIGNWARE_PLATFORM is not set
+# CONFIG_I2C_EMEV2 is not set
+# CONFIG_I2C_GPIO is not set
+# CONFIG_I2C_HIBVT is not set
+# CONFIG_I2C_NOMADIK is not set
+# CONFIG_I2C_OCORES is not set
+# CONFIG_I2C_PCA_PLATFORM is not set
+# CONFIG_I2C_PXA_PCI is not set
+# CONFIG_I2C_RK3X is not set
+# CONFIG_I2C_SIMTEC is not set
+# CONFIG_I2C_XILINX is not set
+
+#
+# External I2C/SMBus adapter drivers
+#
+# CONFIG_I2C_DIOLAN_U2C is not set
+# CONFIG_I2C_PARPORT_LIGHT is not set
+# CONFIG_I2C_ROBOTFUZZ_OSIF is not set
+# CONFIG_I2C_TAOS_EVM is not set
+# CONFIG_I2C_TINY_USB is not set
+
+#
+# Other I2C/SMBus bus drivers
+#
+CONFIG_I2C_HISI=y
+# CONFIG_I2C_STUB is not set
+# CONFIG_I2C_SLAVE is not set
+# CONFIG_I2C_DEBUG_CORE is not set
+# CONFIG_I2C_DEBUG_ALGO is not set
+# CONFIG_I2C_DEBUG_BUS is not set
+CONFIG_SPI=y
+# CONFIG_SPI_DEBUG is not set
+CONFIG_SPI_MASTER=y
+
+#
+# SPI Master Controller Drivers
+#
+# CONFIG_SPI_ALTERA is not set
+# CONFIG_SPI_AXI_SPI_ENGINE is not set
+# CONFIG_SPI_BITBANG is not set
+# CONFIG_SPI_CADENCE is not set
+# CONFIG_SPI_DESIGNWARE is not set
+# CONFIG_SPI_GPIO is not set
+# CONFIG_SPI_FSL_SPI is not set
+# CONFIG_SPI_OC_TINY is not set
+CONFIG_SPI_PL022=y
+# CONFIG_SPI_PXA2XX_PCI is not set
+# CONFIG_SPI_ROCKCHIP is not set
+# CONFIG_SPI_SC18IS602 is not set
+# CONFIG_SPI_XCOMM is not set
+# CONFIG_SPI_XILINX is not set
+# CONFIG_SPI_ZYNQMP_GQSPI is not set
+
+#
+# SPI Protocol Masters
+#
+CONFIG_SPI_SPIDEV=y
+# CONFIG_SPI_LOOPBACK_TEST is not set
+# CONFIG_SPI_TLE62X0 is not set
+# CONFIG_SPMI is not set
+# CONFIG_HSI is not set
+
+#
+# PPS support
+#
+# CONFIG_PPS is not set
+
+#
+# PPS generators support
+#
+
+#
+# PTP clock support
+#
+# CONFIG_PTP_1588_CLOCK is not set
+
+#
+# Enable PHYLIB and NETWORK_PHY_TIMESTAMPING to see the additional clocks.
+#
+CONFIG_ARCH_HAVE_CUSTOM_GPIO_H=y
+CONFIG_GPIOLIB=y
+CONFIG_OF_GPIO=y
+CONFIG_GPIOLIB_IRQCHIP=y
+# CONFIG_DEBUG_GPIO is not set
+CONFIG_GPIO_SYSFS=y
+
+#
+# Memory mapped GPIO drivers
+#
+# CONFIG_GPIO_74XX_MMIO is not set
+# CONFIG_GPIO_ALTERA is not set
+# CONFIG_GPIO_DWAPB is not set
+# CONFIG_GPIO_EM is not set
+# CONFIG_GPIO_GENERIC_PLATFORM is not set
+# CONFIG_GPIO_GRGPIO is not set
+# CONFIG_GPIO_MOCKUP is not set
+# CONFIG_GPIO_MPC8XXX is not set
+CONFIG_GPIO_PL061=y
+# CONFIG_GPIO_XILINX is not set
+# CONFIG_GPIO_ZEVIO is not set
+# CONFIG_GPIO_ZX is not set
+
+#
+# I2C GPIO expanders
+#
+# CONFIG_GPIO_ADP5588 is not set
+# CONFIG_GPIO_ADNP is not set
+# CONFIG_GPIO_MAX7300 is not set
+# CONFIG_GPIO_MAX732X is not set
+# CONFIG_GPIO_PCA953X is not set
+# CONFIG_GPIO_PCF857X is not set
+# CONFIG_GPIO_SX150X is not set
+# CONFIG_GPIO_TPIC2810 is not set
+# CONFIG_GPIO_TS4900 is not set
+
+#
+# MFD GPIO expanders
+#
+# CONFIG_HTC_EGPIO is not set
+
+#
+# SPI GPIO expanders
+#
+# CONFIG_GPIO_74X164 is not set
+# CONFIG_GPIO_MAX7301 is not set
+# CONFIG_GPIO_MC33880 is not set
+# CONFIG_GPIO_PISOSR is not set
+
+#
+# SPI or I2C GPIO expanders
+#
+# CONFIG_GPIO_MCP23S08 is not set
+
+#
+# USB GPIO expanders
+#
+# CONFIG_W1 is not set
+# CONFIG_POWER_AVS is not set
+CONFIG_POWER_RESET=y
+# CONFIG_POWER_RESET_BRCMKONA is not set
+# CONFIG_POWER_RESET_GPIO is not set
+# CONFIG_POWER_RESET_GPIO_RESTART is not set
+CONFIG_POWER_RESET_HISI=y
+# CONFIG_POWER_RESET_LTC2952 is not set
+# CONFIG_POWER_RESET_RESTART is not set
+# CONFIG_POWER_RESET_SYSCON is not set
+# CONFIG_POWER_RESET_SYSCON_POWEROFF is not set
+CONFIG_POWER_SUPPLY=y
+# CONFIG_POWER_SUPPLY_DEBUG is not set
+# CONFIG_PDA_POWER is not set
+# CONFIG_TEST_POWER is not set
+# CONFIG_BATTERY_DS2780 is not set
+# CONFIG_BATTERY_DS2781 is not set
+# CONFIG_BATTERY_DS2782 is not set
+# CONFIG_BATTERY_SBS is not set
+# CONFIG_BATTERY_BQ27XXX is not set
+# CONFIG_BATTERY_MAX17040 is not set
+# CONFIG_BATTERY_MAX17042 is not set
+# CONFIG_CHARGER_MAX8903 is not set
+# CONFIG_CHARGER_LP8727 is not set
+# CONFIG_CHARGER_GPIO is not set
+# CONFIG_CHARGER_MANAGER is not set
+# CONFIG_CHARGER_BQ2415X is not set
+# CONFIG_CHARGER_BQ24190 is not set
+# CONFIG_CHARGER_BQ24735 is not set
+# CONFIG_CHARGER_BQ25890 is not set
+# CONFIG_CHARGER_SMB347 is not set
+# CONFIG_BATTERY_GAUGE_LTC2941 is not set
+# CONFIG_CHARGER_RT9455 is not set
+# CONFIG_HWMON is not set
+# CONFIG_THERMAL is not set
+# CONFIG_WATCHDOG is not set
+CONFIG_SSB_POSSIBLE=y
+
+#
+# Sonics Silicon Backplane
+#
+# CONFIG_SSB is not set
+CONFIG_BCMA_POSSIBLE=y
+
+#
+# Broadcom specific AMBA
+#
+# CONFIG_BCMA is not set
+
+#
+# Multifunction device drivers
+#
+# CONFIG_MFD_CORE is not set
+# CONFIG_MFD_ACT8945A is not set
+# CONFIG_MFD_AS3711 is not set
+# CONFIG_MFD_AS3722 is not set
+# CONFIG_PMIC_ADP5520 is not set
+# CONFIG_MFD_AAT2870_CORE is not set
+# CONFIG_MFD_ATMEL_FLEXCOM is not set
+# CONFIG_MFD_ATMEL_HLCDC is not set
+# CONFIG_MFD_BCM590XX is not set
+# CONFIG_MFD_AXP20X_I2C is not set
+# CONFIG_MFD_CROS_EC is not set
+# CONFIG_MFD_ASIC3 is not set
+# CONFIG_PMIC_DA903X is not set
+# CONFIG_MFD_DA9052_SPI is not set
+# CONFIG_MFD_DA9052_I2C is not set
+# CONFIG_MFD_DA9055 is not set
+# CONFIG_MFD_DA9062 is not set
+# CONFIG_MFD_DA9063 is not set
+# CONFIG_MFD_DA9150 is not set
+# CONFIG_MFD_DLN2 is not set
+# CONFIG_MFD_EXYNOS_LPASS is not set
+# CONFIG_MFD_MC13XXX_SPI is not set
+# CONFIG_MFD_MC13XXX_I2C is not set
+# CONFIG_MFD_HI6421_PMIC is not set
+# CONFIG_MFD_HISI_FMC is not set
+# CONFIG_HTC_PASIC3 is not set
+# CONFIG_HTC_I2CPLD is not set
+# CONFIG_INTEL_SOC_PMIC is not set
+# CONFIG_MFD_KEMPLD is not set
+# CONFIG_MFD_88PM800 is not set
+# CONFIG_MFD_88PM805 is not set
+# CONFIG_MFD_88PM860X is not set
+# CONFIG_MFD_MAX14577 is not set
+# CONFIG_MFD_MAX77620 is not set
+# CONFIG_MFD_MAX77686 is not set
+# CONFIG_MFD_MAX77693 is not set
+# CONFIG_MFD_MAX77843 is not set
+# CONFIG_MFD_MAX8907 is not set
+# CONFIG_MFD_MAX8925 is not set
+# CONFIG_MFD_MAX8997 is not set
+# CONFIG_MFD_MAX8998 is not set
+# CONFIG_MFD_MT6397 is not set
+# CONFIG_MFD_MENF21BMC is not set
+# CONFIG_EZX_PCAP is not set
+# CONFIG_MFD_VIPERBOARD is not set
+# CONFIG_MFD_RETU is not set
+# CONFIG_MFD_PCF50633 is not set
+# CONFIG_MFD_PM8921_CORE is not set
+# CONFIG_MFD_RT5033 is not set
+# CONFIG_MFD_RTSX_USB is not set
+# CONFIG_MFD_RC5T583 is not set
+# CONFIG_MFD_RK808 is not set
+# CONFIG_MFD_RN5T618 is not set
+# CONFIG_MFD_SEC_CORE is not set
+# CONFIG_MFD_SI476X_CORE is not set
+# CONFIG_MFD_SM501 is not set
+# CONFIG_MFD_SKY81452 is not set
+# CONFIG_MFD_SMSC is not set
+# CONFIG_ABX500_CORE is not set
+# CONFIG_MFD_STMPE is not set
+# CONFIG_MFD_SYSCON is not set
+# CONFIG_MFD_TI_AM335X_TSCADC is not set
+# CONFIG_MFD_LP3943 is not set
+# CONFIG_MFD_LP8788 is not set
+# CONFIG_MFD_PALMAS is not set
+# CONFIG_TPS6105X is not set
+# CONFIG_TPS65010 is not set
+# CONFIG_TPS6507X is not set
+# CONFIG_MFD_TPS65086 is not set
+# CONFIG_MFD_TPS65090 is not set
+# CONFIG_MFD_TPS65217 is not set
+# CONFIG_MFD_TI_LP873X is not set
+# CONFIG_MFD_TPS65218 is not set
+# CONFIG_MFD_TPS6586X is not set
+# CONFIG_MFD_TPS65910 is not set
+# CONFIG_MFD_TPS65912_I2C is not set
+# CONFIG_MFD_TPS65912_SPI is not set
+# CONFIG_MFD_TPS80031 is not set
+# CONFIG_TWL4030_CORE is not set
+# CONFIG_TWL6040_CORE is not set
+# CONFIG_MFD_WL1273_CORE is not set
+# CONFIG_MFD_LM3533 is not set
+# CONFIG_MFD_TC3589X is not set
+# CONFIG_MFD_TMIO is not set
+# CONFIG_MFD_T7L66XB is not set
+# CONFIG_MFD_TC6387XB is not set
+# CONFIG_MFD_TC6393XB is not set
+# CONFIG_MFD_ARIZONA_I2C is not set
+# CONFIG_MFD_ARIZONA_SPI is not set
+# CONFIG_MFD_WM8400 is not set
+# CONFIG_MFD_WM831X_I2C is not set
+# CONFIG_MFD_WM831X_SPI is not set
+# CONFIG_MFD_WM8350_I2C is not set
+# CONFIG_MFD_WM8994 is not set
+CONFIG_REGULATOR=y
+# CONFIG_REGULATOR_DEBUG is not set
+# CONFIG_REGULATOR_FIXED_VOLTAGE is not set
+# CONFIG_REGULATOR_VIRTUAL_CONSUMER is not set
+# CONFIG_REGULATOR_USERSPACE_CONSUMER is not set
+# CONFIG_REGULATOR_ACT8865 is not set
+# CONFIG_REGULATOR_AD5398 is not set
+# CONFIG_REGULATOR_DA9210 is not set
+# CONFIG_REGULATOR_DA9211 is not set
+# CONFIG_REGULATOR_FAN53555 is not set
+# CONFIG_REGULATOR_GPIO is not set
+# CONFIG_REGULATOR_ISL9305 is not set
+# CONFIG_REGULATOR_ISL6271A is not set
+# CONFIG_REGULATOR_LP3971 is not set
+# CONFIG_REGULATOR_LP3972 is not set
+# CONFIG_REGULATOR_LP872X is not set
+# CONFIG_REGULATOR_LP8755 is not set
+# CONFIG_REGULATOR_LTC3589 is not set
+# CONFIG_REGULATOR_LTC3676 is not set
+# CONFIG_REGULATOR_MAX1586 is not set
+# CONFIG_REGULATOR_MAX8649 is not set
+# CONFIG_REGULATOR_MAX8660 is not set
+# CONFIG_REGULATOR_MAX8952 is not set
+# CONFIG_REGULATOR_MT6311 is not set
+# CONFIG_REGULATOR_PFUZE100 is not set
+# CONFIG_REGULATOR_PV88060 is not set
+# CONFIG_REGULATOR_PV88080 is not set
+# CONFIG_REGULATOR_PV88090 is not set
+# CONFIG_REGULATOR_TPS51632 is not set
+# CONFIG_REGULATOR_TPS62360 is not set
+# CONFIG_REGULATOR_TPS65023 is not set
+# CONFIG_REGULATOR_TPS6507X is not set
+# CONFIG_REGULATOR_TPS6524X is not set
+# CONFIG_MEDIA_SUPPORT is not set
+
+#
+# Graphics support
+#
+# CONFIG_IMX_IPUV3_CORE is not set
+# CONFIG_DRM is not set
+
+#
+# ACP (Audio CoProcessor) Configuration
+#
+
+#
+# Frame buffer Devices
+#
+CONFIG_FB=y
+# CONFIG_FIRMWARE_EDID is not set
+CONFIG_FB_CMDLINE=y
+CONFIG_FB_NOTIFY=y
+# CONFIG_FB_DDC is not set
+# CONFIG_FB_BOOT_VESA_SUPPORT is not set
+# CONFIG_FB_CFB_FILLRECT is not set
+# CONFIG_FB_CFB_COPYAREA is not set
+# CONFIG_FB_CFB_IMAGEBLIT is not set
+# CONFIG_FB_CFB_REV_PIXELS_IN_BYTE is not set
+# CONFIG_FB_SYS_FILLRECT is not set
+# CONFIG_FB_SYS_COPYAREA is not set
+# CONFIG_FB_SYS_IMAGEBLIT is not set
+# CONFIG_FB_FOREIGN_ENDIAN is not set
+# CONFIG_FB_SYS_FOPS is not set
+# CONFIG_FB_SVGALIB is not set
+# CONFIG_FB_MACMODES is not set
+# CONFIG_FB_BACKLIGHT is not set
+# CONFIG_FB_MODE_HELPERS is not set
+# CONFIG_FB_TILEBLITTING is not set
+
+#
+# Frame buffer hardware drivers
+#
+# CONFIG_FB_ARMCLCD is not set
+# CONFIG_FB_OPENCORES is not set
+# CONFIG_FB_S1D13XXX is not set
+# CONFIG_FB_SMSCUFX is not set
+# CONFIG_FB_UDL is not set
+# CONFIG_FB_IBM_GXT4500 is not set
+# CONFIG_FB_VIRTUAL is not set
+# CONFIG_FB_METRONOME is not set
+# CONFIG_FB_BROADSHEET is not set
+# CONFIG_FB_AUO_K190X is not set
+# CONFIG_FB_SIMPLE is not set
+# CONFIG_FB_SSD1307 is not set
+# CONFIG_BACKLIGHT_LCD_SUPPORT is not set
+# CONFIG_VGASTATE is not set
+
+#
+# Console display driver support
+#
+CONFIG_DUMMY_CONSOLE=y
+# CONFIG_FRAMEBUFFER_CONSOLE is not set
+# CONFIG_LOGO is not set
+# CONFIG_SOUND is not set
+
+#
+# HID support
+#
+CONFIG_HID=y
+# CONFIG_HID_BATTERY_STRENGTH is not set
+# CONFIG_HIDRAW is not set
+# CONFIG_UHID is not set
+CONFIG_HID_GENERIC=y
+
+#
+# Special HID drivers
+#
+# CONFIG_HID_A4TECH is not set
+# CONFIG_HID_ACRUX is not set
+# CONFIG_HID_APPLE is not set
+# CONFIG_HID_APPLEIR is not set
+# CONFIG_HID_AUREAL is not set
+# CONFIG_HID_BELKIN is not set
+# CONFIG_HID_BETOP_FF is not set
+# CONFIG_HID_CHERRY is not set
+# CONFIG_HID_CHICONY is not set
+# CONFIG_HID_CMEDIA is not set
+# CONFIG_HID_CP2112 is not set
+# CONFIG_HID_CYPRESS is not set
+# CONFIG_HID_DRAGONRISE is not set
+# CONFIG_HID_EMS_FF is not set
+# CONFIG_HID_ELECOM is not set
+# CONFIG_HID_ELO is not set
+# CONFIG_HID_EZKEY is not set
+# CONFIG_HID_GEMBIRD is not set
+# CONFIG_HID_GFRM is not set
+# CONFIG_HID_HOLTEK is not set
+# CONFIG_HID_KEYTOUCH is not set
+# CONFIG_HID_KYE is not set
+# CONFIG_HID_UCLOGIC is not set
+# CONFIG_HID_WALTOP is not set
+# CONFIG_HID_GYRATION is not set
+# CONFIG_HID_ICADE is not set
+# CONFIG_HID_TWINHAN is not set
+# CONFIG_HID_KENSINGTON is not set
+# CONFIG_HID_LCPOWER is not set
+# CONFIG_HID_LENOVO is not set
+# CONFIG_HID_LOGITECH is not set
+# CONFIG_HID_MAGICMOUSE is not set
+CONFIG_HID_MICROSOFT=y
+# CONFIG_HID_MONTEREY is not set
+# CONFIG_HID_MULTITOUCH is not set
+# CONFIG_HID_NTRIG is not set
+# CONFIG_HID_ORTEK is not set
+# CONFIG_HID_PANTHERLORD is not set
+# CONFIG_HID_PENMOUNT is not set
+# CONFIG_HID_PETALYNX is not set
+# CONFIG_HID_PICOLCD is not set
+# CONFIG_HID_PLANTRONICS is not set
+# CONFIG_HID_PRIMAX is not set
+# CONFIG_HID_ROCCAT is not set
+# CONFIG_HID_SAITEK is not set
+# CONFIG_HID_SAMSUNG is not set
+# CONFIG_HID_SPEEDLINK is not set
+# CONFIG_HID_STEELSERIES is not set
+# CONFIG_HID_SUNPLUS is not set
+# CONFIG_HID_RMI is not set
+# CONFIG_HID_GREENASIA is not set
+# CONFIG_HID_SMARTJOYPLUS is not set
+# CONFIG_HID_TIVO is not set
+# CONFIG_HID_TOPSEED is not set
+# CONFIG_HID_THRUSTMASTER is not set
+# CONFIG_HID_WACOM is not set
+# CONFIG_HID_XINMO is not set
+# CONFIG_HID_ZEROPLUS is not set
+# CONFIG_HID_ZYDACRON is not set
+# CONFIG_HID_SENSOR_HUB is not set
+# CONFIG_HID_ALPS is not set
+
+#
+# USB HID support
+#
+CONFIG_USB_HID=y
+# CONFIG_HID_PID is not set
+# CONFIG_USB_HIDDEV is not set
+
+#
+# I2C HID support
+#
+# CONFIG_I2C_HID is not set
+CONFIG_USB_OHCI_LITTLE_ENDIAN=y
+CONFIG_USB_SUPPORT=y
+CONFIG_USB_COMMON=y
+CONFIG_USB_ARCH_HAS_HCD=y
+CONFIG_USB=y
+# CONFIG_USB_ANNOUNCE_NEW_DEVICES is not set
+
+#
+# Miscellaneous USB options
+#
+CONFIG_USB_DEFAULT_PERSIST=y
+# CONFIG_USB_DYNAMIC_MINORS is not set
+# CONFIG_USB_OTG is not set
+# CONFIG_USB_OTG_WHITELIST is not set
+# CONFIG_USB_MON is not set
+# CONFIG_USB_WUSB_CBAF is not set
+
+#
+# USB Host Controller Drivers
+#
+# CONFIG_USB_C67X00_HCD is not set
+# CONFIG_USB_XHCI_HCD is not set
+CONFIG_USB_EHCI_HCD=y
+# CONFIG_USB_EHCI_ROOT_HUB_TT is not set
+CONFIG_USB_EHCI_TT_NEWSCHED=y
+CONFIG_USB_EHCI_HCD_PLATFORM=y
+# CONFIG_USB_OXU210HP_HCD is not set
+# CONFIG_USB_ISP116X_HCD is not set
+# CONFIG_USB_ISP1362_HCD is not set
+# CONFIG_USB_FOTG210_HCD is not set
+# CONFIG_USB_MAX3421_HCD is not set
+CONFIG_USB_OHCI_HCD=y
+CONFIG_USB_OHCI_HCD_PLATFORM=y
+# CONFIG_USB_SL811_HCD is not set
+# CONFIG_USB_R8A66597_HCD is not set
+# CONFIG_USB_HCD_TEST_MODE is not set
+
+#
+# USB Device Class drivers
+#
+# CONFIG_USB_ACM is not set
+# CONFIG_USB_PRINTER is not set
+# CONFIG_USB_WDM is not set
+# CONFIG_USB_TMC is not set
+
+#
+# NOTE: USB_STORAGE depends on SCSI but BLK_DEV_SD may
+#
+
+#
+# also be needed; see USB_STORAGE Help for more info
+#
+CONFIG_USB_STORAGE=y
+# CONFIG_USB_STORAGE_DEBUG is not set
+# CONFIG_USB_STORAGE_REALTEK is not set
+# CONFIG_USB_STORAGE_DATAFAB is not set
+# CONFIG_USB_STORAGE_FREECOM is not set
+# CONFIG_USB_STORAGE_ISD200 is not set
+# CONFIG_USB_STORAGE_USBAT is not set
+# CONFIG_USB_STORAGE_SDDR09 is not set
+# CONFIG_USB_STORAGE_SDDR55 is not set
+# CONFIG_USB_STORAGE_JUMPSHOT is not set
+# CONFIG_USB_STORAGE_ALAUDA is not set
+# CONFIG_USB_STORAGE_ONETOUCH is not set
+# CONFIG_USB_STORAGE_KARMA is not set
+# CONFIG_USB_STORAGE_CYPRESS_ATACB is not set
+# CONFIG_USB_STORAGE_ENE_UB6250 is not set
+# CONFIG_USB_UAS is not set
+
+#
+# USB Imaging devices
+#
+# CONFIG_USB_MDC800 is not set
+# CONFIG_USB_MICROTEK is not set
+# CONFIG_USBIP_CORE is not set
+# CONFIG_USB_MUSB_HDRC is not set
+# CONFIG_USB_DWC3 is not set
+# CONFIG_USB_DWC2 is not set
+# CONFIG_USB_CHIPIDEA is not set
+# CONFIG_USB_ISP1760 is not set
+
+#
+# USB port drivers
+#
+# CONFIG_USB_SERIAL is not set
+
+#
+# USB Miscellaneous drivers
+#
+# CONFIG_USB_EMI62 is not set
+# CONFIG_USB_EMI26 is not set
+# CONFIG_USB_ADUTUX is not set
+# CONFIG_USB_SEVSEG is not set
+# CONFIG_USB_RIO500 is not set
+# CONFIG_USB_LEGOTOWER is not set
+# CONFIG_USB_LCD is not set
+# CONFIG_USB_CYPRESS_CY7C63 is not set
+# CONFIG_USB_CYTHERM is not set
+# CONFIG_USB_IDMOUSE is not set
+# CONFIG_USB_FTDI_ELAN is not set
+# CONFIG_USB_APPLEDISPLAY is not set
+# CONFIG_USB_SISUSBVGA is not set
+# CONFIG_USB_LD is not set
+# CONFIG_USB_TRANCEVIBRATOR is not set
+# CONFIG_USB_IOWARRIOR is not set
+# CONFIG_USB_TEST is not set
+# CONFIG_USB_EHSET_TEST_FIXTURE is not set
+# CONFIG_USB_ISIGHTFW is not set
+# CONFIG_USB_YUREX is not set
+# CONFIG_USB_EZUSB_FX2 is not set
+# CONFIG_USB_HSIC_USB3503 is not set
+# CONFIG_USB_HSIC_USB4604 is not set
+# CONFIG_USB_LINK_LAYER_TEST is not set
+
+#
+# USB Physical Layer drivers
+#
+# CONFIG_USB_PHY is not set
+# CONFIG_NOP_USB_XCEIV is not set
+# CONFIG_USB_GPIO_VBUS is not set
+# CONFIG_USB_ISP1301 is not set
+# CONFIG_USB_ULPI is not set
+# CONFIG_USB_GADGET is not set
+# CONFIG_USB_ULPI_BUS is not set
+# CONFIG_UWB is not set
+CONFIG_MMC=y
+# CONFIG_MMC_DEBUG is not set
+CONFIG_PWRSEQ_EMMC=y
+CONFIG_PWRSEQ_SIMPLE=y
+
+#
+# MMC/SD/SDIO Card Drivers
+#
+CONFIG_MMC_BLOCK=y
+CONFIG_MMC_BLOCK_MINORS=8
+CONFIG_MMC_BLOCK_BOUNCE=y
+# CONFIG_SDIO_UART is not set
+# CONFIG_MMC_TEST is not set
+
+#
+# MMC/SD/SDIO Host Controller Drivers
+#
+# CONFIG_MMC_ARMMMCI is not set
+# CONFIG_MMC_SDHCI is not set
+# CONFIG_MMC_SPI is not set
+# CONFIG_MMC_DW is not set
+# CONFIG_MMC_VUB300 is not set
+# CONFIG_MMC_USHC is not set
+# CONFIG_MMC_USDHI6ROL0 is not set
+# CONFIG_MMC_MTK is not set
+CONFIG_HIMCI=y
+CONFIG_SEND_AUTO_STOP=y
+# CONFIG_MEMSTICK is not set
+# CONFIG_NEW_LEDS is not set
+# CONFIG_ACCESSIBILITY is not set
+CONFIG_EDAC_ATOMIC_SCRUB=y
+CONFIG_EDAC_SUPPORT=y
+# CONFIG_EDAC is not set
+CONFIG_RTC_LIB=y
+# CONFIG_RTC_CLASS is not set
+# CONFIG_DMADEVICES is not set
+
+#
+# DMABUF options
+#
+# CONFIG_SYNC_FILE is not set
+# CONFIG_AUXDISPLAY is not set
+# CONFIG_UIO is not set
+# CONFIG_VIRT_DRIVERS is not set
+
+#
+# Virtio drivers
+#
+# CONFIG_VIRTIO_MMIO is not set
+
+#
+# Microsoft Hyper-V guest support
+#
+# CONFIG_STAGING is not set
+# CONFIG_GOLDFISH is not set
+# CONFIG_CHROME_PLATFORMS is not set
+CONFIG_CLKDEV_LOOKUP=y
+CONFIG_HAVE_CLK_PREPARE=y
+CONFIG_COMMON_CLK=y
+
+#
+# Common Clock Framework
+#
+# CONFIG_COMMON_CLK_SI5351 is not set
+# CONFIG_COMMON_CLK_SI514 is not set
+# CONFIG_COMMON_CLK_SI570 is not set
+# CONFIG_COMMON_CLK_CDCE706 is not set
+# CONFIG_COMMON_CLK_CDCE925 is not set
+# CONFIG_COMMON_CLK_CS2000_CP is not set
+# CONFIG_CLK_QORIQ is not set
+# CONFIG_COMMON_CLK_NXP is not set
+# CONFIG_COMMON_CLK_PXA is not set
+# CONFIG_COMMON_CLK_PIC32 is not set
+CONFIG_COMMON_CLK_HI3516A=y
+CONFIG_RESET_HISI=y
+
+#
+# Hardware Spinlock drivers
+#
+
+#
+# Clock Source drivers
+#
+CONFIG_CLKSRC_OF=y
+CONFIG_CLKSRC_PROBE=y
+CONFIG_CLKSRC_MMIO=y
+CONFIG_ARM_ARCH_TIMER=y
+CONFIG_ARM_ARCH_TIMER_EVTSTREAM=y
+CONFIG_ARM_TIMER_SP804=y
+# CONFIG_ATMEL_PIT is not set
+# CONFIG_SH_TIMER_CMT is not set
+# CONFIG_SH_TIMER_MTU2 is not set
+# CONFIG_SH_TIMER_TMU is not set
+# CONFIG_EM_TIMER_STI is not set
+# CONFIG_MAILBOX is not set
+# CONFIG_IOMMU_SUPPORT is not set
+
+#
+# Remoteproc drivers
+#
+# CONFIG_STE_MODEM_RPROC is not set
+
+#
+# Rpmsg drivers
+#
+
+#
+# SOC (System On Chip) specific Drivers
+#
+
+#
+# Broadcom SoC drivers
+#
+# CONFIG_SOC_BRCMSTB is not set
+# CONFIG_SUNXI_SRAM is not set
+# CONFIG_SOC_TI is not set
+# CONFIG_PM_DEVFREQ is not set
+# CONFIG_EXTCON is not set
+# CONFIG_MEMORY is not set
+# CONFIG_IIO is not set
+# CONFIG_PWM is not set
+CONFIG_IRQCHIP=y
+CONFIG_ARM_GIC=y
+CONFIG_ARM_GIC_MAX_NR=1
+# CONFIG_IPACK_BUS is not set
+CONFIG_ARCH_HAS_RESET_CONTROLLER=y
+CONFIG_RESET_CONTROLLER=y
+# CONFIG_RESET_ATH79 is not set
+# CONFIG_RESET_BERLIN is not set
+# CONFIG_RESET_LPC18XX is not set
+# CONFIG_RESET_MESON is not set
+# CONFIG_RESET_PISTACHIO is not set
+# CONFIG_RESET_SOCFPGA is not set
+# CONFIG_RESET_STM32 is not set
+# CONFIG_RESET_SUNXI is not set
+# CONFIG_TI_SYSCON_RESET is not set
+# CONFIG_RESET_ZYNQ is not set
+# CONFIG_FMC is not set
+
+#
+# PHY Subsystem
+#
+CONFIG_GENERIC_PHY=y
+# CONFIG_PHY_PXA_28NM_HSIC is not set
+# CONFIG_PHY_PXA_28NM_USB2 is not set
+# CONFIG_BCM_KONA_USB2_PHY is not set
+CONFIG_PHY_HISI_USB2=y
+# CONFIG_POWERCAP is not set
+# CONFIG_MCB is not set
+
+#
+# Performance monitor support
+#
+# CONFIG_RAS is not set
+
+#
+# Android
+#
+# CONFIG_ANDROID is not set
+# CONFIG_NVMEM is not set
+# CONFIG_STM is not set
+# CONFIG_INTEL_TH is not set
+
+#
+# FPGA Configuration Support
+#
+# CONFIG_FPGA is not set
+CONFIG_HI_DMAC=y
+CONFIG_HI_DMAC_CHANNEL_NUM=4
+
+#
+# Firmware Drivers
+#
+# CONFIG_FIRMWARE_MEMMAP is not set
+# CONFIG_FW_CFG_SYSFS is not set
+CONFIG_HAVE_ARM_SMCCC=y
+
+#
+# File systems
+#
+CONFIG_DCACHE_WORD_ACCESS=y
+# CONFIG_EXT2_FS is not set
+# CONFIG_EXT3_FS is not set
+CONFIG_EXT4_FS=y
+CONFIG_EXT4_USE_FOR_EXT2=y
+# CONFIG_EXT4_FS_POSIX_ACL is not set
+# CONFIG_EXT4_FS_SECURITY is not set
+# CONFIG_EXT4_ENCRYPTION is not set
+# CONFIG_EXT4_DEBUG is not set
+CONFIG_JBD2=y
+# CONFIG_JBD2_DEBUG is not set
+CONFIG_FS_MBCACHE=y
+# CONFIG_REISERFS_FS is not set
+# CONFIG_JFS_FS is not set
+# CONFIG_XFS_FS is not set
+# CONFIG_GFS2_FS is not set
+# CONFIG_OCFS2_FS is not set
+# CONFIG_BTRFS_FS is not set
+# CONFIG_NILFS2_FS is not set
+# CONFIG_F2FS_FS is not set
+CONFIG_FS_POSIX_ACL=y
+CONFIG_EXPORTFS=y
+# CONFIG_EXPORTFS_BLOCK_OPS is not set
+CONFIG_FILE_LOCKING=y
+CONFIG_MANDATORY_FILE_LOCKING=y
+# CONFIG_FS_ENCRYPTION is not set
+CONFIG_FSNOTIFY=y
+CONFIG_DNOTIFY=y
+CONFIG_INOTIFY_USER=y
+# CONFIG_FANOTIFY is not set
+# CONFIG_QUOTA is not set
+# CONFIG_QUOTACTL is not set
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_FUSE_FS is not set
+# CONFIG_OVERLAY_FS is not set
+
+#
+# Caches
+#
+# CONFIG_FSCACHE is not set
+
+#
+# CD-ROM/DVD Filesystems
+#
+# CONFIG_ISO9660_FS is not set
+# CONFIG_UDF_FS is not set
+
+#
+# DOS/FAT/NT Filesystems
+#
+CONFIG_FAT_FS=y
+CONFIG_MSDOS_FS=y
+CONFIG_VFAT_FS=y
+CONFIG_FAT_DEFAULT_CODEPAGE=437
+CONFIG_FAT_DEFAULT_IOCHARSET="iso8859-1"
+# CONFIG_FAT_DEFAULT_UTF8 is not set
+# CONFIG_NTFS_FS is not set
+
+#
+# Pseudo filesystems
+#
+CONFIG_PROC_FS=y
+CONFIG_PROC_SYSCTL=y
+CONFIG_PROC_PAGE_MONITOR=y
+# CONFIG_PROC_CHILDREN is not set
+CONFIG_KERNFS=y
+CONFIG_SYSFS=y
+CONFIG_TMPFS=y
+# CONFIG_TMPFS_POSIX_ACL is not set
+# CONFIG_TMPFS_XATTR is not set
+# CONFIG_HUGETLB_PAGE is not set
+CONFIG_CONFIGFS_FS=m
+CONFIG_MISC_FILESYSTEMS=y
+# CONFIG_ORANGEFS_FS is not set
+# CONFIG_ADFS_FS is not set
+# CONFIG_AFFS_FS is not set
+# CONFIG_ECRYPT_FS is not set
+# CONFIG_HFS_FS is not set
+# CONFIG_HFSPLUS_FS is not set
+# CONFIG_BEFS_FS is not set
+# CONFIG_BFS_FS is not set
+# CONFIG_EFS_FS is not set
+CONFIG_YAFFS_FS=y
+CONFIG_YAFFS_YAFFS1=y
+# CONFIG_YAFFS_9BYTE_TAGS is not set
+# CONFIG_YAFFS_DOES_ECC is not set
+CONFIG_YAFFS_YAFFS2=y
+CONFIG_YAFFS_AUTO_YAFFS2=y
+# CONFIG_YAFFS_DISABLE_TAGS_ECC is not set
+# CONFIG_YAFFS_ALWAYS_CHECK_CHUNK_ERASED is not set
+# CONFIG_YAFFS_EMPTY_LOST_AND_FOUND is not set
+# CONFIG_YAFFS_DISABLE_BLOCK_REFRESHING is not set
+# CONFIG_YAFFS_DISABLE_BACKGROUND is not set
+# CONFIG_YAFFS_DISABLE_BAD_BLOCK_MARKING is not set
+CONFIG_YAFFS_XATTR=y
+CONFIG_JFFS2_FS=y
+CONFIG_JFFS2_FS_DEBUG=0
+CONFIG_JFFS2_FS_WRITEBUFFER=y
+# CONFIG_JFFS2_FS_WBUF_VERIFY is not set
+# CONFIG_JFFS2_SUMMARY is not set
+# CONFIG_JFFS2_FS_XATTR is not set
+# CONFIG_JFFS2_COMPRESSION_OPTIONS is not set
+CONFIG_JFFS2_ZLIB=y
+# CONFIG_JFFS2_LZO is not set
+CONFIG_JFFS2_RTIME=y
+# CONFIG_JFFS2_RUBIN is not set
+CONFIG_UBIFS_FS=y
+# CONFIG_UBIFS_FS_ADVANCED_COMPR is not set
+CONFIG_UBIFS_FS_LZO=y
+CONFIG_UBIFS_FS_ZLIB=y
+# CONFIG_UBIFS_ATIME_SUPPORT is not set
+# CONFIG_LOGFS is not set
+CONFIG_CRAMFS=y
+# CONFIG_SQUASHFS is not set
+# CONFIG_VXFS_FS is not set
+# CONFIG_MINIX_FS is not set
+# CONFIG_OMFS_FS is not set
+# CONFIG_HPFS_FS is not set
+# CONFIG_QNX4FS_FS is not set
+# CONFIG_QNX6FS_FS is not set
+# CONFIG_ROMFS_FS is not set
+# CONFIG_PSTORE is not set
+# CONFIG_SYSV_FS is not set
+# CONFIG_UFS_FS is not set
+CONFIG_NETWORK_FILESYSTEMS=y
+CONFIG_NFS_FS=y
+CONFIG_NFS_V2=y
+CONFIG_NFS_V3=y
+CONFIG_NFS_V3_ACL=y
+CONFIG_NFS_V4=y
+# CONFIG_NFS_SWAP is not set
+# CONFIG_NFS_V4_1 is not set
+CONFIG_ROOT_NFS=y
+# CONFIG_NFS_USE_LEGACY_DNS is not set
+CONFIG_NFS_USE_KERNEL_DNS=y
+# CONFIG_NFSD is not set
+CONFIG_GRACE_PERIOD=y
+CONFIG_LOCKD=y
+CONFIG_LOCKD_V4=y
+CONFIG_NFS_ACL_SUPPORT=y
+CONFIG_NFS_COMMON=y
+CONFIG_SUNRPC=y
+CONFIG_SUNRPC_GSS=y
+# CONFIG_SUNRPC_DEBUG is not set
+# CONFIG_CEPH_FS is not set
+# CONFIG_CIFS is not set
+# CONFIG_NCP_FS is not set
+# CONFIG_CODA_FS is not set
+# CONFIG_AFS_FS is not set
+CONFIG_NLS=y
+CONFIG_NLS_DEFAULT="iso8859-1"
+CONFIG_NLS_CODEPAGE_437=y
+# CONFIG_NLS_CODEPAGE_737 is not set
+# CONFIG_NLS_CODEPAGE_775 is not set
+# CONFIG_NLS_CODEPAGE_850 is not set
+# CONFIG_NLS_CODEPAGE_852 is not set
+# CONFIG_NLS_CODEPAGE_855 is not set
+# CONFIG_NLS_CODEPAGE_857 is not set
+# CONFIG_NLS_CODEPAGE_860 is not set
+# CONFIG_NLS_CODEPAGE_861 is not set
+# CONFIG_NLS_CODEPAGE_862 is not set
+# CONFIG_NLS_CODEPAGE_863 is not set
+# CONFIG_NLS_CODEPAGE_864 is not set
+# CONFIG_NLS_CODEPAGE_865 is not set
+# CONFIG_NLS_CODEPAGE_866 is not set
+# CONFIG_NLS_CODEPAGE_869 is not set
+# CONFIG_NLS_CODEPAGE_936 is not set
+# CONFIG_NLS_CODEPAGE_950 is not set
+# CONFIG_NLS_CODEPAGE_932 is not set
+# CONFIG_NLS_CODEPAGE_949 is not set
+# CONFIG_NLS_CODEPAGE_874 is not set
+# CONFIG_NLS_ISO8859_8 is not set
+# CONFIG_NLS_CODEPAGE_1250 is not set
+# CONFIG_NLS_CODEPAGE_1251 is not set
+# CONFIG_NLS_ASCII is not set
+CONFIG_NLS_ISO8859_1=y
+# CONFIG_NLS_ISO8859_2 is not set
+# CONFIG_NLS_ISO8859_3 is not set
+# CONFIG_NLS_ISO8859_4 is not set
+# CONFIG_NLS_ISO8859_5 is not set
+# CONFIG_NLS_ISO8859_6 is not set
+# CONFIG_NLS_ISO8859_7 is not set
+# CONFIG_NLS_ISO8859_9 is not set
+# CONFIG_NLS_ISO8859_13 is not set
+# CONFIG_NLS_ISO8859_14 is not set
+# CONFIG_NLS_ISO8859_15 is not set
+# CONFIG_NLS_KOI8_R is not set
+# CONFIG_NLS_KOI8_U is not set
+# CONFIG_NLS_MAC_ROMAN is not set
+# CONFIG_NLS_MAC_CELTIC is not set
+# CONFIG_NLS_MAC_CENTEURO is not set
+# CONFIG_NLS_MAC_CROATIAN is not set
+# CONFIG_NLS_MAC_CYRILLIC is not set
+# CONFIG_NLS_MAC_GAELIC is not set
+# CONFIG_NLS_MAC_GREEK is not set
+# CONFIG_NLS_MAC_ICELAND is not set
+# CONFIG_NLS_MAC_INUIT is not set
+# CONFIG_NLS_MAC_ROMANIAN is not set
+# CONFIG_NLS_MAC_TURKISH is not set
+CONFIG_NLS_UTF8=y
+# CONFIG_DLM is not set
+
+#
+# Kernel hacking
+#
+
+#
+# printk and dmesg options
+#
+# CONFIG_PRINTK_TIME is not set
+CONFIG_MESSAGE_LOGLEVEL_DEFAULT=4
+# CONFIG_BOOT_PRINTK_DELAY is not set
+
+#
+# Compile-time checks and compiler options
+#
+# CONFIG_DEBUG_INFO is not set
+# CONFIG_ENABLE_WARN_DEPRECATED is not set
+# CONFIG_ENABLE_MUST_CHECK is not set
+CONFIG_FRAME_WARN=1024
+# CONFIG_STRIP_ASM_SYMS is not set
+# CONFIG_READABLE_ASM is not set
+# CONFIG_UNUSED_SYMBOLS is not set
+# CONFIG_PAGE_OWNER is not set
+# CONFIG_DEBUG_FS is not set
+# CONFIG_HEADERS_CHECK is not set
+# CONFIG_DEBUG_SECTION_MISMATCH is not set
+CONFIG_SECTION_MISMATCH_WARN_ONLY=y
+CONFIG_FRAME_POINTER=y
+# CONFIG_DEBUG_FORCE_WEAK_PER_CPU is not set
+# CONFIG_MAGIC_SYSRQ is not set
+CONFIG_DEBUG_KERNEL=y
+
+#
+# Memory Debugging
+#
+# CONFIG_PAGE_EXTENSION is not set
+# CONFIG_PAGE_POISONING is not set
+# CONFIG_DEBUG_OBJECTS is not set
+# CONFIG_SLUB_DEBUG_ON is not set
+# CONFIG_SLUB_STATS is not set
+CONFIG_HAVE_DEBUG_KMEMLEAK=y
+# CONFIG_DEBUG_KMEMLEAK is not set
+# CONFIG_DEBUG_STACK_USAGE is not set
+# CONFIG_DEBUG_VM is not set
+CONFIG_DEBUG_MEMORY_INIT=y
+# CONFIG_DEBUG_SHIRQ is not set
+
+#
+# Debug Lockups and Hangs
+#
+# CONFIG_LOCKUP_DETECTOR is not set
+# CONFIG_DETECT_HUNG_TASK is not set
+# CONFIG_WQ_WATCHDOG is not set
+# CONFIG_PANIC_ON_OOPS is not set
+CONFIG_PANIC_ON_OOPS_VALUE=0
+CONFIG_PANIC_TIMEOUT=0
+# CONFIG_SCHED_DEBUG is not set
+# CONFIG_SCHED_INFO is not set
+# CONFIG_SCHEDSTATS is not set
+# CONFIG_SCHED_STACK_END_CHECK is not set
+# CONFIG_DEBUG_TIMEKEEPING is not set
+# CONFIG_TIMER_STATS is not set
+
+#
+# Lock Debugging (spinlocks, mutexes, etc...)
+#
+# CONFIG_DEBUG_RT_MUTEXES is not set
+# CONFIG_DEBUG_SPINLOCK is not set
+CONFIG_DEBUG_MUTEXES=y
+# CONFIG_DEBUG_WW_MUTEX_SLOWPATH is not set
+# CONFIG_DEBUG_LOCK_ALLOC is not set
+# CONFIG_PROVE_LOCKING is not set
+# CONFIG_LOCK_STAT is not set
+# CONFIG_DEBUG_ATOMIC_SLEEP is not set
+# CONFIG_DEBUG_LOCKING_API_SELFTESTS is not set
+# CONFIG_LOCK_TORTURE_TEST is not set
+CONFIG_STACKTRACE=y
+# CONFIG_DEBUG_KOBJECT is not set
+CONFIG_DEBUG_BUGVERBOSE=y
+# CONFIG_DEBUG_LIST is not set
+# CONFIG_DEBUG_PI_LIST is not set
+# CONFIG_DEBUG_SG is not set
+# CONFIG_DEBUG_NOTIFIERS is not set
+# CONFIG_DEBUG_CREDENTIALS is not set
+
+#
+# RCU Debugging
+#
+# CONFIG_PROVE_RCU is not set
+# CONFIG_SPARSE_RCU_POINTER is not set
+# CONFIG_TORTURE_TEST is not set
+# CONFIG_RCU_PERF_TEST is not set
+# CONFIG_RCU_TORTURE_TEST is not set
+# CONFIG_RCU_TRACE is not set
+# CONFIG_RCU_EQS_DEBUG is not set
+# CONFIG_DEBUG_WQ_FORCE_RR_CPU is not set
+# CONFIG_DEBUG_BLOCK_EXT_DEVT is not set
+# CONFIG_NOTIFIER_ERROR_INJECTION is not set
+# CONFIG_FAULT_INJECTION is not set
+# CONFIG_LATENCYTOP is not set
+CONFIG_HAVE_FUNCTION_TRACER=y
+CONFIG_HAVE_FUNCTION_GRAPH_TRACER=y
+CONFIG_HAVE_DYNAMIC_FTRACE=y
+CONFIG_HAVE_FTRACE_MCOUNT_RECORD=y
+CONFIG_HAVE_SYSCALL_TRACEPOINTS=y
+CONFIG_HAVE_C_RECORDMCOUNT=y
+CONFIG_TRACING_SUPPORT=y
+# CONFIG_FTRACE is not set
+
+#
+# Runtime Testing
+#
+# CONFIG_TEST_LIST_SORT is not set
+# CONFIG_BACKTRACE_SELF_TEST is not set
+# CONFIG_RBTREE_TEST is not set
+# CONFIG_INTERVAL_TREE_TEST is not set
+# CONFIG_PERCPU_TEST is not set
+# CONFIG_ATOMIC64_SELFTEST is not set
+# CONFIG_TEST_HEXDUMP is not set
+# CONFIG_TEST_STRING_HELPERS is not set
+# CONFIG_TEST_KSTRTOX is not set
+# CONFIG_TEST_PRINTF is not set
+# CONFIG_TEST_BITMAP is not set
+# CONFIG_TEST_UUID is not set
+# CONFIG_TEST_RHASHTABLE is not set
+# CONFIG_TEST_HASH is not set
+# CONFIG_DMA_API_DEBUG is not set
+# CONFIG_TEST_LKM is not set
+# CONFIG_TEST_USER_COPY is not set
+# CONFIG_TEST_BPF is not set
+# CONFIG_TEST_FIRMWARE is not set
+# CONFIG_TEST_UDELAY is not set
+# CONFIG_MEMTEST is not set
+# CONFIG_TEST_STATIC_KEYS is not set
+# CONFIG_SAMPLES is not set
+CONFIG_HAVE_ARCH_KGDB=y
+# CONFIG_KGDB is not set
+# CONFIG_ARCH_WANTS_UBSAN_NO_NULL is not set
+# CONFIG_UBSAN is not set
+CONFIG_ARCH_HAS_DEVMEM_IS_ALLOWED=y
+CONFIG_STRICT_DEVMEM=y
+# CONFIG_IO_STRICT_DEVMEM is not set
+# CONFIG_ARM_PTDUMP is not set
+# CONFIG_ARM_UNWIND is not set
+# CONFIG_DEBUG_USER is not set
+# CONFIG_DEBUG_LL is not set
+CONFIG_DEBUG_LL_INCLUDE="mach/debug-macro.S"
+# CONFIG_DEBUG_UART_8250 is not set
+CONFIG_UNCOMPRESS_INCLUDE="debug/uncompress.h"
+# CONFIG_PID_IN_CONTEXTIDR is not set
+# CONFIG_DEBUG_SET_MODULE_RONX is not set
+# CONFIG_CORESIGHT is not set
+
+#
+# Security options
+#
+CONFIG_KEYS=y
+# CONFIG_PERSISTENT_KEYRINGS is not set
+# CONFIG_ENCRYPTED_KEYS is not set
+# CONFIG_KEY_DH_OPERATIONS is not set
+# CONFIG_SECURITY_DMESG_RESTRICT is not set
+# CONFIG_SECURITY is not set
+# CONFIG_SECURITYFS is not set
+CONFIG_HAVE_HARDENED_USERCOPY_ALLOCATOR=y
+CONFIG_HAVE_ARCH_HARDENED_USERCOPY=y
+# CONFIG_HARDENED_USERCOPY is not set
+CONFIG_DEFAULT_SECURITY_DAC=y
+CONFIG_DEFAULT_SECURITY=""
+CONFIG_CRYPTO=y
+
+#
+# Crypto core or helper
+#
+CONFIG_CRYPTO_ALGAPI=y
+CONFIG_CRYPTO_ALGAPI2=y
+CONFIG_CRYPTO_AEAD=m
+CONFIG_CRYPTO_AEAD2=y
+CONFIG_CRYPTO_BLKCIPHER=y
+CONFIG_CRYPTO_BLKCIPHER2=y
+CONFIG_CRYPTO_HASH=y
+CONFIG_CRYPTO_HASH2=y
+CONFIG_CRYPTO_RNG=m
+CONFIG_CRYPTO_RNG2=y
+CONFIG_CRYPTO_RNG_DEFAULT=m
+CONFIG_CRYPTO_AKCIPHER2=y
+CONFIG_CRYPTO_KPP2=y
+# CONFIG_CRYPTO_RSA is not set
+# CONFIG_CRYPTO_DH is not set
+# CONFIG_CRYPTO_ECDH is not set
+CONFIG_CRYPTO_MANAGER=m
+CONFIG_CRYPTO_MANAGER2=y
+# CONFIG_CRYPTO_USER is not set
+CONFIG_CRYPTO_MANAGER_DISABLE_TESTS=y
+CONFIG_CRYPTO_GF128MUL=m
+CONFIG_CRYPTO_NULL=m
+CONFIG_CRYPTO_NULL2=y
+CONFIG_CRYPTO_WORKQUEUE=y
+# CONFIG_CRYPTO_CRYPTD is not set
+# CONFIG_CRYPTO_MCRYPTD is not set
+# CONFIG_CRYPTO_AUTHENC is not set
+# CONFIG_CRYPTO_TEST is not set
+
+#
+# Authenticated Encryption with Associated Data
+#
+CONFIG_CRYPTO_CCM=m
+CONFIG_CRYPTO_GCM=m
+# CONFIG_CRYPTO_CHACHA20POLY1305 is not set
+CONFIG_CRYPTO_SEQIV=m
+CONFIG_CRYPTO_ECHAINIV=m
+
+#
+# Block modes
+#
+# CONFIG_CRYPTO_CBC is not set
+CONFIG_CRYPTO_CTR=m
+# CONFIG_CRYPTO_CTS is not set
+# CONFIG_CRYPTO_ECB is not set
+# CONFIG_CRYPTO_LRW is not set
+# CONFIG_CRYPTO_PCBC is not set
+# CONFIG_CRYPTO_XTS is not set
+# CONFIG_CRYPTO_KEYWRAP is not set
+
+#
+# Hash modes
+#
+# CONFIG_CRYPTO_CMAC is not set
+CONFIG_CRYPTO_HMAC=m
+# CONFIG_CRYPTO_XCBC is not set
+# CONFIG_CRYPTO_VMAC is not set
+
+#
+# Digest
+#
+CONFIG_CRYPTO_CRC32C=y
+# CONFIG_CRYPTO_CRC32 is not set
+CONFIG_CRYPTO_CRCT10DIF=y
+CONFIG_CRYPTO_GHASH=m
+# CONFIG_CRYPTO_POLY1305 is not set
+# CONFIG_CRYPTO_MD4 is not set
+CONFIG_CRYPTO_MD5=y
+# CONFIG_CRYPTO_MICHAEL_MIC is not set
+# CONFIG_CRYPTO_RMD128 is not set
+# CONFIG_CRYPTO_RMD160 is not set
+# CONFIG_CRYPTO_RMD256 is not set
+# CONFIG_CRYPTO_RMD320 is not set
+CONFIG_CRYPTO_SHA1=y
+CONFIG_CRYPTO_SHA256=y
+# CONFIG_CRYPTO_SHA512 is not set
+# CONFIG_CRYPTO_SHA3 is not set
+# CONFIG_CRYPTO_TGR192 is not set
+# CONFIG_CRYPTO_WP512 is not set
+
+#
+# Ciphers
+#
+CONFIG_CRYPTO_AES=y
+# CONFIG_CRYPTO_ANUBIS is not set
+CONFIG_CRYPTO_ARC4=y
+# CONFIG_CRYPTO_BLOWFISH is not set
+# CONFIG_CRYPTO_CAMELLIA is not set
+# CONFIG_CRYPTO_CAST5 is not set
+# CONFIG_CRYPTO_CAST6 is not set
+# CONFIG_CRYPTO_DES is not set
+# CONFIG_CRYPTO_FCRYPT is not set
+# CONFIG_CRYPTO_KHAZAD is not set
+# CONFIG_CRYPTO_SALSA20 is not set
+# CONFIG_CRYPTO_CHACHA20 is not set
+# CONFIG_CRYPTO_SEED is not set
+# CONFIG_CRYPTO_SERPENT is not set
+# CONFIG_CRYPTO_TEA is not set
+# CONFIG_CRYPTO_TWOFISH is not set
+
+#
+# Compression
+#
+CONFIG_CRYPTO_DEFLATE=y
+CONFIG_CRYPTO_LZO=y
+# CONFIG_CRYPTO_842 is not set
+# CONFIG_CRYPTO_LZ4 is not set
+# CONFIG_CRYPTO_LZ4HC is not set
+
+#
+# Random Number Generation
+#
+# CONFIG_CRYPTO_ANSI_CPRNG is not set
+CONFIG_CRYPTO_DRBG_MENU=m
+CONFIG_CRYPTO_DRBG_HMAC=y
+# CONFIG_CRYPTO_DRBG_HASH is not set
+# CONFIG_CRYPTO_DRBG_CTR is not set
+CONFIG_CRYPTO_DRBG=m
+CONFIG_CRYPTO_JITTERENTROPY=m
+# CONFIG_CRYPTO_USER_API_HASH is not set
+# CONFIG_CRYPTO_USER_API_SKCIPHER is not set
+# CONFIG_CRYPTO_USER_API_RNG is not set
+# CONFIG_CRYPTO_USER_API_AEAD is not set
+# CONFIG_CRYPTO_HW is not set
+# CONFIG_ASYMMETRIC_KEY_TYPE is not set
+
+#
+# Certificates for signature checking
+#
+# CONFIG_ARM_CRYPTO is not set
+# CONFIG_BINARY_PRINTF is not set
+
+#
+# Library routines
+#
+CONFIG_BITREVERSE=y
+CONFIG_HAVE_ARCH_BITREVERSE=y
+CONFIG_RATIONAL=y
+CONFIG_GENERIC_STRNCPY_FROM_USER=y
+CONFIG_GENERIC_STRNLEN_USER=y
+CONFIG_GENERIC_NET_UTILS=y
+CONFIG_GENERIC_PCI_IOMAP=y
+CONFIG_GENERIC_IO=y
+CONFIG_ARCH_USE_CMPXCHG_LOCKREF=y
+CONFIG_CRC_CCITT=y
+CONFIG_CRC16=y
+CONFIG_CRC_T10DIF=y
+CONFIG_CRC_ITU_T=y
+CONFIG_CRC32=y
+# CONFIG_CRC32_SELFTEST is not set
+CONFIG_CRC32_SLICEBY8=y
+# CONFIG_CRC32_SLICEBY4 is not set
+# CONFIG_CRC32_SARWATE is not set
+# CONFIG_CRC32_BIT is not set
+# CONFIG_CRC7 is not set
+CONFIG_LIBCRC32C=y
+# CONFIG_CRC8 is not set
+# CONFIG_AUDIT_ARCH_COMPAT_GENERIC is not set
+# CONFIG_RANDOM32_SELFTEST is not set
+CONFIG_ZLIB_INFLATE=y
+CONFIG_ZLIB_DEFLATE=y
+CONFIG_LZO_COMPRESS=y
+CONFIG_LZO_DECOMPRESS=y
+CONFIG_LZ4_DECOMPRESS=y
+CONFIG_XZ_DEC=y
+CONFIG_XZ_DEC_X86=y
+CONFIG_XZ_DEC_POWERPC=y
+CONFIG_XZ_DEC_IA64=y
+CONFIG_XZ_DEC_ARM=y
+CONFIG_XZ_DEC_ARMTHUMB=y
+CONFIG_XZ_DEC_SPARC=y
+CONFIG_XZ_DEC_BCJ=y
+# CONFIG_XZ_DEC_TEST is not set
+CONFIG_DECOMPRESS_GZIP=y
+CONFIG_DECOMPRESS_LZ4=y
+CONFIG_GENERIC_ALLOCATOR=y
+CONFIG_ASSOCIATIVE_ARRAY=y
+CONFIG_HAS_IOMEM=y
+CONFIG_HAS_IOPORT_MAP=y
+CONFIG_HAS_DMA=y
+CONFIG_DQL=y
+CONFIG_NLATTR=y
+# CONFIG_CORDIC is not set
+# CONFIG_DDR is not set
+# CONFIG_IRQ_POLL is not set
+CONFIG_LIBFDT=y
+CONFIG_OID_REGISTRY=y
+# CONFIG_SG_SPLIT is not set
+CONFIG_SG_POOL=y
+CONFIG_ARCH_HAS_SG_CHAIN=y
+CONFIG_SBITMAP=y
+# CONFIG_VIRTUALIZATION is not set
diff --git a/arch/arm/configs/hi3516a_spinand_mini_defconfig b/arch/arm/configs/hi3516a_spinand_mini_defconfig
new file mode 100644
index 0000000..2b0a3cd
--- /dev/null
+++ b/arch/arm/configs/hi3516a_spinand_mini_defconfig
@@ -0,0 +1,2319 @@
+#
+# Automatically generated file; DO NOT EDIT.
+# Linux/arm 4.9.37 Kernel Configuration
+#
+CONFIG_ARM=y
+CONFIG_ARM_HAS_SG_CHAIN=y
+CONFIG_MIGHT_HAVE_PCI=y
+CONFIG_SYS_SUPPORTS_APM_EMULATION=y
+CONFIG_HAVE_PROC_CPU=y
+CONFIG_STACKTRACE_SUPPORT=y
+CONFIG_LOCKDEP_SUPPORT=y
+CONFIG_TRACE_IRQFLAGS_SUPPORT=y
+CONFIG_RWSEM_XCHGADD_ALGORITHM=y
+CONFIG_FIX_EARLYCON_MEM=y
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_NEED_DMA_MAP_STATE=y
+CONFIG_ARCH_SUPPORTS_UPROBES=y
+CONFIG_VECTORS_BASE=0xffff0000
+CONFIG_ARM_PATCH_PHYS_VIRT=y
+CONFIG_GENERIC_BUG=y
+CONFIG_PGTABLE_LEVELS=2
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+CONFIG_IRQ_WORK=y
+CONFIG_BUILDTIME_EXTABLE_SORT=y
+
+#
+# General setup
+#
+CONFIG_BROKEN_ON_SMP=y
+CONFIG_INIT_ENV_ARG_LIMIT=32
+CONFIG_CROSS_COMPILE=""
+# CONFIG_COMPILE_TEST is not set
+CONFIG_LOCALVERSION=""
+# CONFIG_LOCALVERSION_AUTO is not set
+CONFIG_HAVE_KERNEL_GZIP=y
+CONFIG_HAVE_KERNEL_LZMA=y
+CONFIG_HAVE_KERNEL_XZ=y
+CONFIG_HAVE_KERNEL_LZO=y
+CONFIG_HAVE_KERNEL_LZ4=y
+CONFIG_KERNEL_GZIP=y
+# CONFIG_KERNEL_LZMA is not set
+# CONFIG_KERNEL_XZ is not set
+# CONFIG_KERNEL_LZO is not set
+# CONFIG_KERNEL_LZ4 is not set
+CONFIG_DEFAULT_HOSTNAME="(none)"
+CONFIG_SWAP=y
+CONFIG_SYSVIPC=y
+CONFIG_SYSVIPC_SYSCTL=y
+# CONFIG_POSIX_MQUEUE is not set
+CONFIG_CROSS_MEMORY_ATTACH=y
+CONFIG_FHANDLE=y
+CONFIG_USELIB=y
+# CONFIG_AUDIT is not set
+CONFIG_HAVE_ARCH_AUDITSYSCALL=y
+
+#
+# IRQ subsystem
+#
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_GENERIC_IRQ_SHOW=y
+CONFIG_GENERIC_IRQ_SHOW_LEVEL=y
+CONFIG_HARDIRQS_SW_RESEND=y
+CONFIG_IRQ_DOMAIN=y
+CONFIG_IRQ_DOMAIN_HIERARCHY=y
+CONFIG_HANDLE_DOMAIN_IRQ=y
+CONFIG_IRQ_FORCED_THREADING=y
+CONFIG_SPARSE_IRQ=y
+CONFIG_ARCH_CLOCKSOURCE_DATA=y
+CONFIG_GENERIC_TIME_VSYSCALL=y
+CONFIG_GENERIC_CLOCKEVENTS=y
+
+#
+# Timers subsystem
+#
+CONFIG_HZ_PERIODIC=y
+# CONFIG_NO_HZ_IDLE is not set
+# CONFIG_NO_HZ is not set
+# CONFIG_HIGH_RES_TIMERS is not set
+
+#
+# CPU/Task time and stats accounting
+#
+CONFIG_TICK_CPU_ACCOUNTING=y
+# CONFIG_VIRT_CPU_ACCOUNTING_GEN is not set
+CONFIG_IRQ_TIME_ACCOUNTING=y
+# CONFIG_BSD_PROCESS_ACCT is not set
+# CONFIG_TASKSTATS is not set
+
+#
+# RCU Subsystem
+#
+CONFIG_TINY_RCU=y
+# CONFIG_RCU_EXPERT is not set
+CONFIG_SRCU=y
+# CONFIG_TASKS_RCU is not set
+# CONFIG_RCU_STALL_COMMON is not set
+# CONFIG_TREE_RCU_TRACE is not set
+# CONFIG_RCU_EXPEDITE_BOOT is not set
+# CONFIG_BUILD_BIN2C is not set
+# CONFIG_IKCONFIG is not set
+CONFIG_LOG_BUF_SHIFT=17
+CONFIG_NMI_LOG_BUF_SHIFT=13
+CONFIG_GENERIC_SCHED_CLOCK=y
+CONFIG_CGROUPS=y
+# CONFIG_MEMCG is not set
+# CONFIG_BLK_CGROUP is not set
+# CONFIG_CGROUP_SCHED is not set
+# CONFIG_CGROUP_PIDS is not set
+CONFIG_CGROUP_FREEZER=y
+# CONFIG_CPUSETS is not set
+# CONFIG_CGROUP_DEVICE is not set
+# CONFIG_CGROUP_CPUACCT is not set
+# CONFIG_CGROUP_DEBUG is not set
+# CONFIG_CHECKPOINT_RESTORE is not set
+CONFIG_NAMESPACES=y
+CONFIG_UTS_NS=y
+CONFIG_IPC_NS=y
+# CONFIG_USER_NS is not set
+CONFIG_PID_NS=y
+CONFIG_NET_NS=y
+# CONFIG_SCHED_AUTOGROUP is not set
+# CONFIG_SYSFS_DEPRECATED is not set
+# CONFIG_RELAY is not set
+CONFIG_BLK_DEV_INITRD=y
+CONFIG_INITRAMFS_SOURCE=""
+CONFIG_RD_GZIP=y
+# CONFIG_RD_BZIP2 is not set
+# CONFIG_RD_LZMA is not set
+# CONFIG_RD_XZ is not set
+# CONFIG_RD_LZO is not set
+CONFIG_RD_LZ4=y
+CONFIG_CC_OPTIMIZE_FOR_PERFORMANCE=y
+# CONFIG_CC_OPTIMIZE_FOR_SIZE is not set
+CONFIG_SYSCTL=y
+CONFIG_ANON_INODES=y
+CONFIG_HAVE_UID16=y
+CONFIG_BPF=y
+# CONFIG_EXPERT is not set
+CONFIG_UID16=y
+CONFIG_MULTIUSER=y
+# CONFIG_SGETMASK_SYSCALL is not set
+CONFIG_SYSFS_SYSCALL=y
+# CONFIG_SYSCTL_SYSCALL is not set
+CONFIG_KALLSYMS=y
+# CONFIG_KALLSYMS_ALL is not set
+# CONFIG_KALLSYMS_ABSOLUTE_PERCPU is not set
+CONFIG_KALLSYMS_BASE_RELATIVE=y
+CONFIG_PRINTK=y
+CONFIG_PRINTK_NMI=y
+CONFIG_BUG=y
+CONFIG_ELF_CORE=y
+CONFIG_BASE_FULL=y
+CONFIG_FUTEX=y
+CONFIG_EPOLL=y
+CONFIG_SIGNALFD=y
+CONFIG_TIMERFD=y
+CONFIG_EVENTFD=y
+# CONFIG_BPF_SYSCALL is not set
+CONFIG_SHMEM=y
+CONFIG_AIO=y
+CONFIG_ADVISE_SYSCALLS=y
+# CONFIG_USERFAULTFD is not set
+CONFIG_MEMBARRIER=y
+# CONFIG_EMBEDDED is not set
+CONFIG_HAVE_PERF_EVENTS=y
+CONFIG_PERF_USE_VMALLOC=y
+
+#
+# Kernel Performance Events And Counters
+#
+# CONFIG_PERF_EVENTS is not set
+CONFIG_VM_EVENT_COUNTERS=y
+CONFIG_SLUB_DEBUG=y
+CONFIG_COMPAT_BRK=y
+# CONFIG_SLAB is not set
+CONFIG_SLUB=y
+# CONFIG_SLAB_FREELIST_RANDOM is not set
+# CONFIG_SYSTEM_DATA_VERIFICATION is not set
+# CONFIG_PROFILING is not set
+CONFIG_HAVE_OPROFILE=y
+# CONFIG_KPROBES is not set
+# CONFIG_JUMP_LABEL is not set
+# CONFIG_UPROBES is not set
+# CONFIG_HAVE_64BIT_ALIGNED_ACCESS is not set
+CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS=y
+CONFIG_ARCH_USE_BUILTIN_BSWAP=y
+CONFIG_HAVE_KPROBES=y
+CONFIG_HAVE_KRETPROBES=y
+CONFIG_HAVE_OPTPROBES=y
+CONFIG_HAVE_NMI=y
+CONFIG_HAVE_ARCH_TRACEHOOK=y
+CONFIG_HAVE_DMA_CONTIGUOUS=y
+CONFIG_GENERIC_SMP_IDLE_THREAD=y
+CONFIG_GENERIC_IDLE_POLL_SETUP=y
+CONFIG_HAVE_REGS_AND_STACK_ACCESS_API=y
+CONFIG_HAVE_CLK=y
+CONFIG_HAVE_DMA_API_DEBUG=y
+CONFIG_HAVE_PERF_REGS=y
+CONFIG_HAVE_PERF_USER_STACK_DUMP=y
+CONFIG_HAVE_ARCH_JUMP_LABEL=y
+CONFIG_ARCH_WANT_IPC_PARSE_VERSION=y
+CONFIG_HAVE_ARCH_SECCOMP_FILTER=y
+CONFIG_HAVE_GCC_PLUGINS=y
+# CONFIG_GCC_PLUGINS is not set
+CONFIG_HAVE_CC_STACKPROTECTOR=y
+# CONFIG_CC_STACKPROTECTOR is not set
+CONFIG_CC_STACKPROTECTOR_NONE=y
+# CONFIG_CC_STACKPROTECTOR_REGULAR is not set
+# CONFIG_CC_STACKPROTECTOR_STRONG is not set
+CONFIG_HAVE_CONTEXT_TRACKING=y
+CONFIG_HAVE_VIRT_CPU_ACCOUNTING_GEN=y
+CONFIG_HAVE_IRQ_TIME_ACCOUNTING=y
+CONFIG_HAVE_MOD_ARCH_SPECIFIC=y
+CONFIG_MODULES_USE_ELF_REL=y
+CONFIG_ARCH_HAS_ELF_RANDOMIZE=y
+CONFIG_HAVE_ARCH_MMAP_RND_BITS=y
+CONFIG_HAVE_EXIT_THREAD=y
+CONFIG_ARCH_MMAP_RND_BITS_MIN=8
+CONFIG_ARCH_MMAP_RND_BITS_MAX=16
+CONFIG_ARCH_MMAP_RND_BITS=8
+# CONFIG_HAVE_ARCH_HASH is not set
+# CONFIG_ISA_BUS_API is not set
+CONFIG_CLONE_BACKWARDS=y
+CONFIG_OLD_SIGSUSPEND3=y
+CONFIG_OLD_SIGACTION=y
+# CONFIG_CPU_NO_EFFICIENT_FFS is not set
+# CONFIG_HAVE_ARCH_VMAP_STACK is not set
+
+#
+# GCOV-based kernel profiling
+#
+CONFIG_ARCH_HAS_GCOV_PROFILE_ALL=y
+CONFIG_HAVE_GENERIC_DMA_COHERENT=y
+CONFIG_SLABINFO=y
+CONFIG_RT_MUTEXES=y
+CONFIG_BASE_SMALL=0
+CONFIG_MODULES=y
+# CONFIG_MODULE_FORCE_LOAD is not set
+CONFIG_MODULE_UNLOAD=y
+# CONFIG_MODULE_FORCE_UNLOAD is not set
+# CONFIG_MODVERSIONS is not set
+# CONFIG_MODULE_SRCVERSION_ALL is not set
+# CONFIG_MODULE_SIG is not set
+# CONFIG_MODULE_COMPRESS is not set
+# CONFIG_TRIM_UNUSED_KSYMS is not set
+CONFIG_BLOCK=y
+CONFIG_LBDAF=y
+CONFIG_BLK_DEV_BSG=y
+# CONFIG_BLK_DEV_BSGLIB is not set
+# CONFIG_BLK_DEV_INTEGRITY is not set
+CONFIG_BLK_CMDLINE_PARSER=y
+
+#
+# Partition Types
+#
+CONFIG_PARTITION_ADVANCED=y
+# CONFIG_ACORN_PARTITION is not set
+# CONFIG_AIX_PARTITION is not set
+# CONFIG_OSF_PARTITION is not set
+# CONFIG_AMIGA_PARTITION is not set
+# CONFIG_ATARI_PARTITION is not set
+# CONFIG_MAC_PARTITION is not set
+CONFIG_MSDOS_PARTITION=y
+# CONFIG_BSD_DISKLABEL is not set
+# CONFIG_MINIX_SUBPARTITION is not set
+# CONFIG_SOLARIS_X86_PARTITION is not set
+# CONFIG_UNIXWARE_DISKLABEL is not set
+# CONFIG_LDM_PARTITION is not set
+# CONFIG_SGI_PARTITION is not set
+# CONFIG_ULTRIX_PARTITION is not set
+# CONFIG_SUN_PARTITION is not set
+# CONFIG_KARMA_PARTITION is not set
+CONFIG_EFI_PARTITION=y
+# CONFIG_SYSV68_PARTITION is not set
+CONFIG_CMDLINE_PARTITION=y
+
+#
+# IO Schedulers
+#
+CONFIG_IOSCHED_NOOP=y
+CONFIG_IOSCHED_DEADLINE=y
+CONFIG_IOSCHED_CFQ=y
+CONFIG_DEFAULT_DEADLINE=y
+# CONFIG_DEFAULT_CFQ is not set
+# CONFIG_DEFAULT_NOOP is not set
+CONFIG_DEFAULT_IOSCHED="deadline"
+CONFIG_INLINE_SPIN_UNLOCK_IRQ=y
+CONFIG_INLINE_READ_UNLOCK=y
+CONFIG_INLINE_READ_UNLOCK_IRQ=y
+CONFIG_INLINE_WRITE_UNLOCK=y
+CONFIG_INLINE_WRITE_UNLOCK_IRQ=y
+CONFIG_ARCH_SUPPORTS_ATOMIC_RMW=y
+CONFIG_FREEZER=y
+
+#
+# System Type
+#
+CONFIG_MMU=y
+CONFIG_ARCH_MULTIPLATFORM=y
+# CONFIG_ARCH_GEMINI is not set
+# CONFIG_ARCH_EBSA110 is not set
+# CONFIG_ARCH_EP93XX is not set
+# CONFIG_ARCH_FOOTBRIDGE is not set
+# CONFIG_ARCH_NETX is not set
+# CONFIG_ARCH_IOP13XX is not set
+# CONFIG_ARCH_IOP32X is not set
+# CONFIG_ARCH_IOP33X is not set
+# CONFIG_ARCH_IXP4XX is not set
+# CONFIG_ARCH_DOVE is not set
+# CONFIG_ARCH_KS8695 is not set
+# CONFIG_ARCH_W90X900 is not set
+# CONFIG_ARCH_LPC32XX is not set
+# CONFIG_ARCH_PXA is not set
+# CONFIG_ARCH_RPC is not set
+# CONFIG_ARCH_SA1100 is not set
+# CONFIG_ARCH_S3C24XX is not set
+# CONFIG_ARCH_DAVINCI is not set
+# CONFIG_ARCH_OMAP1 is not set
+
+#
+# Multiple platform selection
+#
+
+#
+# CPU Core family selection
+#
+# CONFIG_ARCH_MULTI_V6 is not set
+CONFIG_ARCH_MULTI_V7=y
+CONFIG_ARCH_MULTI_V6_V7=y
+# CONFIG_ARCH_MULTI_CPU_AUTO is not set
+# CONFIG_ARCH_VIRT is not set
+# CONFIG_ARCH_MVEBU is not set
+# CONFIG_ARCH_ALPINE is not set
+# CONFIG_ARCH_ARTPEC is not set
+# CONFIG_ARCH_AT91 is not set
+# CONFIG_ARCH_BCM is not set
+# CONFIG_ARCH_BERLIN is not set
+# CONFIG_ARCH_DIGICOLOR is not set
+# CONFIG_ARCH_HIGHBANK is not set
+# CONFIG_ARCH_HISI is not set
+CONFIG_ARCH_HISI_BVT=y
+
+#
+# Hisilicon BVT platform type
+#
+CONFIG_HI_ZRELADDR=0x80008000
+CONFIG_HI_PARAMS_PHYS=0x00000100
+CONFIG_HI_INITRD_PHYS=0x00800000
+CONFIG_ARCH_HI3516A=y
+# CONFIG_ARCH_HI3536DV100 is not set
+# CONFIG_ARCH_KEYSTONE is not set
+# CONFIG_ARCH_MESON is not set
+# CONFIG_ARCH_MXC is not set
+# CONFIG_ARCH_MEDIATEK is not set
+
+#
+# TI OMAP/AM/DM/DRA Family
+#
+# CONFIG_ARCH_OMAP3 is not set
+# CONFIG_ARCH_OMAP4 is not set
+# CONFIG_SOC_OMAP5 is not set
+# CONFIG_SOC_AM33XX is not set
+# CONFIG_SOC_AM43XX is not set
+# CONFIG_SOC_DRA7XX is not set
+# CONFIG_ARCH_MMP is not set
+# CONFIG_ARCH_QCOM is not set
+# CONFIG_ARCH_REALVIEW is not set
+# CONFIG_ARCH_ROCKCHIP is not set
+# CONFIG_ARCH_SOCFPGA is not set
+# CONFIG_PLAT_SPEAR is not set
+# CONFIG_ARCH_STI is not set
+# CONFIG_ARCH_S5PV210 is not set
+# CONFIG_ARCH_EXYNOS is not set
+# CONFIG_ARCH_RENESAS is not set
+# CONFIG_ARCH_SUNXI is not set
+# CONFIG_ARCH_SIRF is not set
+# CONFIG_ARCH_TANGO is not set
+# CONFIG_ARCH_TEGRA is not set
+# CONFIG_ARCH_UNIPHIER is not set
+# CONFIG_ARCH_U8500 is not set
+# CONFIG_ARCH_VEXPRESS is not set
+# CONFIG_ARCH_WM8850 is not set
+# CONFIG_ARCH_ZX is not set
+# CONFIG_ARCH_ZYNQ is not set
+
+#
+# Processor Type
+#
+CONFIG_CPU_V7=y
+CONFIG_CPU_32v6K=y
+CONFIG_CPU_32v7=y
+CONFIG_CPU_ABRT_EV7=y
+CONFIG_CPU_PABRT_V7=y
+CONFIG_CPU_CACHE_V7=y
+CONFIG_CPU_CACHE_VIPT=y
+CONFIG_CPU_COPY_V6=y
+CONFIG_CPU_TLB_V7=y
+CONFIG_CPU_HAS_ASID=y
+CONFIG_CPU_CP15=y
+CONFIG_CPU_CP15_MMU=y
+
+#
+# Processor Features
+#
+# CONFIG_ARM_LPAE is not set
+# CONFIG_ARCH_PHYS_ADDR_T_64BIT is not set
+CONFIG_ARM_THUMB=y
+# CONFIG_ARM_THUMBEE is not set
+CONFIG_ARM_VIRT_EXT=y
+# CONFIG_SWP_EMULATE is not set
+# CONFIG_CPU_ICACHE_DISABLE is not set
+# CONFIG_CPU_DCACHE_DISABLE is not set
+# CONFIG_CPU_BPREDICT_DISABLE is not set
+CONFIG_KUSER_HELPERS=y
+CONFIG_VDSO=y
+CONFIG_MIGHT_HAVE_CACHE_L2X0=y
+# CONFIG_CACHE_L2X0 is not set
+CONFIG_ARM_L1_CACHE_SHIFT_6=y
+CONFIG_ARM_L1_CACHE_SHIFT=6
+CONFIG_ARM_DMA_MEM_BUFFERABLE=y
+# CONFIG_DEBUG_RODATA is not set
+CONFIG_MULTI_IRQ_HANDLER=y
+# CONFIG_ARM_ERRATA_430973 is not set
+# CONFIG_ARM_ERRATA_720789 is not set
+# CONFIG_ARM_ERRATA_754322 is not set
+# CONFIG_ARM_ERRATA_775420 is not set
+# CONFIG_ARM_ERRATA_773022 is not set
+# CONFIG_ARM_ERRATA_818325_852422 is not set
+# CONFIG_ARM_ERRATA_821420 is not set
+# CONFIG_ARM_ERRATA_825619 is not set
+# CONFIG_ARM_ERRATA_852421 is not set
+# CONFIG_ARM_ERRATA_852423 is not set
+
+#
+# Bus support
+#
+# CONFIG_PCI is not set
+# CONFIG_PCI_DOMAINS_GENERIC is not set
+# CONFIG_PCI_SYSCALL is not set
+# CONFIG_PCCARD is not set
+
+#
+# Kernel Features
+#
+CONFIG_HAVE_SMP=y
+# CONFIG_SMP is not set
+CONFIG_HAVE_ARM_ARCH_TIMER=y
+CONFIG_VMSPLIT_3G=y
+# CONFIG_VMSPLIT_3G_OPT is not set
+# CONFIG_VMSPLIT_2G is not set
+# CONFIG_VMSPLIT_1G is not set
+CONFIG_PAGE_OFFSET=0xC0000000
+# CONFIG_ARM_PSCI is not set
+CONFIG_ARCH_NR_GPIO=0
+CONFIG_PREEMPT_NONE=y
+# CONFIG_PREEMPT_VOLUNTARY is not set
+# CONFIG_PREEMPT is not set
+CONFIG_HZ_FIXED=0
+CONFIG_HZ_100=y
+# CONFIG_HZ_200 is not set
+# CONFIG_HZ_250 is not set
+# CONFIG_HZ_300 is not set
+# CONFIG_HZ_500 is not set
+# CONFIG_HZ_1000 is not set
+CONFIG_HZ=100
+# CONFIG_SCHED_HRTICK is not set
+# CONFIG_THUMB2_KERNEL is not set
+CONFIG_ARM_PATCH_IDIV=y
+CONFIG_AEABI=y
+# CONFIG_OABI_COMPAT is not set
+# CONFIG_ARCH_SPARSEMEM_DEFAULT is not set
+# CONFIG_ARCH_SELECT_MEMORY_MODEL is not set
+CONFIG_HAVE_ARCH_PFN_VALID=y
+# CONFIG_HIGHMEM is not set
+# CONFIG_CPU_SW_DOMAIN_PAN is not set
+CONFIG_ARCH_WANT_GENERAL_HUGETLB=y
+# CONFIG_ARM_MODULE_PLTS is not set
+CONFIG_FLATMEM=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+CONFIG_HAVE_MEMBLOCK=y
+CONFIG_NO_BOOTMEM=y
+# CONFIG_HAVE_BOOTMEM_INFO_NODE is not set
+CONFIG_SPLIT_PTLOCK_CPUS=4
+CONFIG_COMPACTION=y
+CONFIG_MIGRATION=y
+# CONFIG_PHYS_ADDR_T_64BIT is not set
+# CONFIG_KSM is not set
+CONFIG_DEFAULT_MMAP_MIN_ADDR=4096
+CONFIG_NEED_PER_CPU_KM=y
+# CONFIG_CLEANCACHE is not set
+# CONFIG_FRONTSWAP is not set
+# CONFIG_CMA is not set
+# CONFIG_ZPOOL is not set
+# CONFIG_ZBUD is not set
+# CONFIG_ZSMALLOC is not set
+CONFIG_GENERIC_EARLY_IOREMAP=y
+# CONFIG_IDLE_PAGE_TRACKING is not set
+CONFIG_FORCE_MAX_ZONEORDER=11
+CONFIG_ALIGNMENT_TRAP=y
+# CONFIG_UACCESS_WITH_MEMCPY is not set
+# CONFIG_SECCOMP is not set
+CONFIG_SWIOTLB=y
+CONFIG_IOMMU_HELPER=y
+# CONFIG_PARAVIRT is not set
+# CONFIG_PARAVIRT_TIME_ACCOUNTING is not set
+# CONFIG_XEN is not set
+
+#
+# Boot options
+#
+CONFIG_USE_OF=y
+CONFIG_ATAGS=y
+# CONFIG_DEPRECATED_PARAM_STRUCT is not set
+CONFIG_ZBOOT_ROM_TEXT=0
+CONFIG_ZBOOT_ROM_BSS=0
+CONFIG_ARM_APPENDED_DTB=y
+CONFIG_ARM_ATAG_DTB_COMPAT=y
+CONFIG_ARM_ATAG_DTB_COMPAT_CMDLINE_FROM_BOOTLOADER=y
+# CONFIG_ARM_ATAG_DTB_COMPAT_CMDLINE_EXTEND is not set
+CONFIG_CMDLINE=""
+# CONFIG_KEXEC is not set
+# CONFIG_CRASH_DUMP is not set
+CONFIG_AUTO_ZRELADDR=y
+# CONFIG_EFI is not set
+
+#
+# CPU Power Management
+#
+
+#
+# CPU Frequency scaling
+#
+CONFIG_CPU_FREQ=y
+CONFIG_CPU_FREQ_GOV_ATTR_SET=y
+CONFIG_CPU_FREQ_GOV_COMMON=y
+CONFIG_CPU_FREQ_STAT=y
+# CONFIG_CPU_FREQ_STAT_DETAILS is not set
+CONFIG_CPU_FREQ_DEFAULT_GOV_PERFORMANCE=y
+# CONFIG_CPU_FREQ_DEFAULT_GOV_POWERSAVE is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_USERSPACE is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_ONDEMAND is not set
+# CONFIG_CPU_FREQ_DEFAULT_GOV_CONSERVATIVE is not set
+CONFIG_CPU_FREQ_GOV_PERFORMANCE=y
+# CONFIG_CPU_FREQ_GOV_POWERSAVE is not set
+CONFIG_CPU_FREQ_GOV_USERSPACE=y
+CONFIG_CPU_FREQ_GOV_ONDEMAND=y
+# CONFIG_CPU_FREQ_GOV_CONSERVATIVE is not set
+
+#
+# CPU frequency scaling drivers
+#
+CONFIG_CPUFREQ_DT=y
+CONFIG_CPUFREQ_DT_PLATDEV=y
+# CONFIG_ARM_KIRKWOOD_CPUFREQ is not set
+# CONFIG_QORIQ_CPUFREQ is not set
+
+#
+# CPU Idle
+#
+# CONFIG_CPU_IDLE is not set
+# CONFIG_ARCH_NEEDS_CPU_IDLE_COUPLED is not set
+
+#
+# Floating point emulation
+#
+
+#
+# At least one emulation must be selected
+#
+CONFIG_VFP=y
+CONFIG_VFPv3=y
+CONFIG_NEON=y
+# CONFIG_KERNEL_MODE_NEON is not set
+
+#
+# Userspace binary formats
+#
+CONFIG_BINFMT_ELF=y
+CONFIG_ELFCORE=y
+CONFIG_CORE_DUMP_DEFAULT_ELF_HEADERS=y
+CONFIG_BINFMT_SCRIPT=y
+# CONFIG_BINFMT_FLAT is not set
+# CONFIG_HAVE_AOUT is not set
+# CONFIG_BINFMT_MISC is not set
+CONFIG_COREDUMP=y
+
+#
+# Power management options
+#
+CONFIG_SUSPEND=y
+CONFIG_SUSPEND_FREEZER=y
+CONFIG_HIBERNATE_CALLBACKS=y
+CONFIG_HIBERNATION=y
+CONFIG_PM_STD_PARTITION=""
+CONFIG_PM_SLEEP=y
+# CONFIG_PM_AUTOSLEEP is not set
+# CONFIG_PM_WAKELOCKS is not set
+CONFIG_PM=y
+CONFIG_PM_DEBUG=y
+# CONFIG_PM_ADVANCED_DEBUG is not set
+CONFIG_PM_SLEEP_DEBUG=y
+# CONFIG_APM_EMULATION is not set
+CONFIG_PM_OPP=y
+CONFIG_PM_CLK=y
+# CONFIG_WQ_POWER_EFFICIENT_DEFAULT is not set
+CONFIG_CPU_PM=y
+CONFIG_ARCH_SUSPEND_POSSIBLE=y
+CONFIG_ARM_CPU_SUSPEND=y
+CONFIG_ARCH_HIBERNATION_POSSIBLE=y
+CONFIG_NET=y
+
+#
+# Networking options
+#
+CONFIG_PACKET=y
+# CONFIG_PACKET_DIAG is not set
+CONFIG_UNIX=y
+# CONFIG_UNIX_DIAG is not set
+CONFIG_XFRM=y
+CONFIG_XFRM_ALGO=y
+CONFIG_XFRM_USER=y
+# CONFIG_XFRM_SUB_POLICY is not set
+# CONFIG_XFRM_MIGRATE is not set
+# CONFIG_XFRM_STATISTICS is not set
+CONFIG_NET_KEY=y
+# CONFIG_NET_KEY_MIGRATE is not set
+CONFIG_INET=y
+CONFIG_IP_MULTICAST=y
+CONFIG_IP_ADVANCED_ROUTER=y
+# CONFIG_IP_FIB_TRIE_STATS is not set
+CONFIG_IP_MULTIPLE_TABLES=y
+CONFIG_IP_ROUTE_MULTIPATH=y
+CONFIG_IP_ROUTE_VERBOSE=y
+CONFIG_IP_PNP=y
+# CONFIG_IP_PNP_DHCP is not set
+# CONFIG_IP_PNP_BOOTP is not set
+# CONFIG_IP_PNP_RARP is not set
+# CONFIG_NET_IPIP is not set
+# CONFIG_NET_IPGRE_DEMUX is not set
+# CONFIG_NET_IP_TUNNEL is not set
+CONFIG_IP_MROUTE=y
+# CONFIG_IP_MROUTE_MULTIPLE_TABLES is not set
+CONFIG_IP_PIMSM_V1=y
+CONFIG_IP_PIMSM_V2=y
+CONFIG_SYN_COOKIES=y
+# CONFIG_NET_UDP_TUNNEL is not set
+# CONFIG_NET_FOU is not set
+# CONFIG_INET_AH is not set
+# CONFIG_INET_ESP is not set
+# CONFIG_INET_IPCOMP is not set
+# CONFIG_INET_XFRM_TUNNEL is not set
+# CONFIG_INET_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_TRANSPORT is not set
+# CONFIG_INET_XFRM_MODE_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_BEET is not set
+CONFIG_INET_DIAG=y
+CONFIG_INET_TCP_DIAG=y
+# CONFIG_INET_UDP_DIAG is not set
+# CONFIG_INET_DIAG_DESTROY is not set
+CONFIG_TCP_CONG_ADVANCED=y
+CONFIG_TCP_CONG_BIC=m
+CONFIG_TCP_CONG_CUBIC=y
+CONFIG_TCP_CONG_WESTWOOD=m
+CONFIG_TCP_CONG_HTCP=m
+# CONFIG_TCP_CONG_HSTCP is not set
+# CONFIG_TCP_CONG_HYBLA is not set
+# CONFIG_TCP_CONG_VEGAS is not set
+# CONFIG_TCP_CONG_NV is not set
+# CONFIG_TCP_CONG_SCALABLE is not set
+# CONFIG_TCP_CONG_LP is not set
+# CONFIG_TCP_CONG_VENO is not set
+# CONFIG_TCP_CONG_YEAH is not set
+# CONFIG_TCP_CONG_ILLINOIS is not set
+# CONFIG_TCP_CONG_DCTCP is not set
+# CONFIG_TCP_CONG_CDG is not set
+# CONFIG_TCP_CONG_BBR is not set
+CONFIG_DEFAULT_CUBIC=y
+# CONFIG_DEFAULT_RENO is not set
+CONFIG_DEFAULT_TCP_CONG="cubic"
+CONFIG_TCP_MD5SIG=y
+# CONFIG_IPV6 is not set
+# CONFIG_NETWORK_SECMARK is not set
+# CONFIG_NET_PTP_CLASSIFY is not set
+# CONFIG_NETWORK_PHY_TIMESTAMPING is not set
+# CONFIG_NETFILTER is not set
+# CONFIG_IP_DCCP is not set
+# CONFIG_IP_SCTP is not set
+# CONFIG_RDS is not set
+# CONFIG_TIPC is not set
+# CONFIG_ATM is not set
+# CONFIG_L2TP is not set
+# CONFIG_BRIDGE is not set
+CONFIG_HAVE_NET_DSA=y
+# CONFIG_VLAN_8021Q is not set
+# CONFIG_DECNET is not set
+# CONFIG_LLC2 is not set
+# CONFIG_IPX is not set
+# CONFIG_ATALK is not set
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_PHONET is not set
+# CONFIG_IEEE802154 is not set
+# CONFIG_NET_SCHED is not set
+# CONFIG_DCB is not set
+CONFIG_DNS_RESOLVER=y
+# CONFIG_BATMAN_ADV is not set
+# CONFIG_OPENVSWITCH is not set
+# CONFIG_VSOCKETS is not set
+# CONFIG_NETLINK_DIAG is not set
+# CONFIG_MPLS is not set
+# CONFIG_HSR is not set
+# CONFIG_NET_SWITCHDEV is not set
+# CONFIG_NET_L3_MASTER_DEV is not set
+# CONFIG_NET_NCSI is not set
+# CONFIG_SOCK_CGROUP_DATA is not set
+# CONFIG_CGROUP_NET_PRIO is not set
+# CONFIG_CGROUP_NET_CLASSID is not set
+CONFIG_NET_RX_BUSY_POLL=y
+CONFIG_BQL=y
+# CONFIG_BPF_JIT is not set
+
+#
+# Network testing
+#
+# CONFIG_NET_PKTGEN is not set
+# CONFIG_HAMRADIO is not set
+# CONFIG_CAN is not set
+# CONFIG_IRDA is not set
+# CONFIG_BT is not set
+# CONFIG_AF_RXRPC is not set
+# CONFIG_AF_KCM is not set
+# CONFIG_STREAM_PARSER is not set
+CONFIG_FIB_RULES=y
+# CONFIG_WIRELESS is not set
+# CONFIG_WIMAX is not set
+# CONFIG_RFKILL is not set
+# CONFIG_RFKILL_REGULATOR is not set
+# CONFIG_NET_9P is not set
+# CONFIG_CAIF is not set
+# CONFIG_CEPH_LIB is not set
+# CONFIG_NFC is not set
+# CONFIG_LWTUNNEL is not set
+# CONFIG_DST_CACHE is not set
+# CONFIG_NET_DEVLINK is not set
+CONFIG_MAY_USE_DEVLINK=y
+CONFIG_HAVE_CBPF_JIT=y
+
+#
+# Device Drivers
+#
+CONFIG_ARM_AMBA=y
+
+#
+# Generic Driver Options
+#
+# CONFIG_UEVENT_HELPER is not set
+CONFIG_DEVTMPFS=y
+# CONFIG_DEVTMPFS_MOUNT is not set
+CONFIG_STANDALONE=y
+# CONFIG_PREVENT_FIRMWARE_BUILD is not set
+CONFIG_FW_LOADER=y
+CONFIG_FIRMWARE_IN_KERNEL=y
+CONFIG_EXTRA_FIRMWARE=""
+# CONFIG_FW_LOADER_USER_HELPER_FALLBACK is not set
+CONFIG_ALLOW_DEV_COREDUMP=y
+# CONFIG_DEBUG_DRIVER is not set
+# CONFIG_DEBUG_DEVRES is not set
+# CONFIG_DEBUG_TEST_DRIVER_REMOVE is not set
+# CONFIG_SYS_HYPERVISOR is not set
+# CONFIG_GENERIC_CPU_DEVICES is not set
+# CONFIG_DMA_SHARED_BUFFER is not set
+
+#
+# Bus devices
+#
+# CONFIG_BRCMSTB_GISB_ARB is not set
+# CONFIG_VEXPRESS_CONFIG is not set
+# CONFIG_CONNECTOR is not set
+CONFIG_MTD=y
+# CONFIG_MTD_TESTS is not set
+# CONFIG_MTD_REDBOOT_PARTS is not set
+CONFIG_MTD_CMDLINE_PARTS=y
+# CONFIG_MTD_AFS_PARTS is not set
+CONFIG_MTD_OF_PARTS=y
+# CONFIG_MTD_AR7_PARTS is not set
+
+#
+# User Modules And Translation Layers
+#
+CONFIG_MTD_BLKDEVS=y
+CONFIG_MTD_BLOCK=y
+# CONFIG_FTL is not set
+# CONFIG_NFTL is not set
+# CONFIG_INFTL is not set
+# CONFIG_RFD_FTL is not set
+# CONFIG_SSFDC is not set
+# CONFIG_SM_FTL is not set
+# CONFIG_MTD_OOPS is not set
+# CONFIG_MTD_SWAP is not set
+# CONFIG_MTD_PARTITIONED_MASTER is not set
+
+#
+# RAM/ROM/Flash chip drivers
+#
+# CONFIG_MTD_CFI is not set
+# CONFIG_MTD_JEDECPROBE is not set
+CONFIG_MTD_MAP_BANK_WIDTH_1=y
+CONFIG_MTD_MAP_BANK_WIDTH_2=y
+CONFIG_MTD_MAP_BANK_WIDTH_4=y
+# CONFIG_MTD_MAP_BANK_WIDTH_8 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_16 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_32 is not set
+CONFIG_MTD_CFI_I1=y
+CONFIG_MTD_CFI_I2=y
+# CONFIG_MTD_CFI_I4 is not set
+# CONFIG_MTD_CFI_I8 is not set
+# CONFIG_MTD_RAM is not set
+# CONFIG_MTD_ROM is not set
+# CONFIG_MTD_ABSENT is not set
+
+#
+# Mapping drivers for chip access
+#
+# CONFIG_MTD_COMPLEX_MAPPINGS is not set
+# CONFIG_MTD_PLATRAM is not set
+
+#
+# Self-contained MTD device drivers
+#
+# CONFIG_MTD_DATAFLASH is not set
+# CONFIG_MTD_M25P80 is not set
+# CONFIG_MTD_SST25L is not set
+# CONFIG_MTD_SLRAM is not set
+# CONFIG_MTD_PHRAM is not set
+# CONFIG_MTD_MTDRAM is not set
+# CONFIG_MTD_BLOCK2MTD is not set
+
+#
+# Disk-On-Chip Device Drivers
+#
+# CONFIG_MTD_DOCG3 is not set
+CONFIG_MTD_NAND_ECC=y
+# CONFIG_MTD_NAND_ECC_SMC is not set
+CONFIG_MTD_NAND=y
+# CONFIG_MTD_NAND_ECC_BCH is not set
+# CONFIG_MTD_SM_COMMON is not set
+# CONFIG_MTD_NAND_DENALI_DT is not set
+# CONFIG_MTD_NAND_OMAP_BCH_BUILD is not set
+CONFIG_MTD_NAND_IDS=y
+# CONFIG_MTD_NAND_DISKONCHIP is not set
+# CONFIG_MTD_NAND_DOCG4 is not set
+# CONFIG_MTD_NAND_NANDSIM is not set
+# CONFIG_MTD_NAND_BRCMNAND is not set
+# CONFIG_MTD_NAND_PLATFORM is not set
+# CONFIG_MTD_NAND_HISI504 is not set
+# CONFIG_MTD_NAND_MTK is not set
+CONFIG_MTD_SPI_NAND_HISI_BVT=y
+CONFIG_MTD_NAND_HISNFC100=y
+CONFIG_HISNFC100_MAX_CHIP=1
+CONFIG_HISNFC100_HARDWARE_PAGESIZE_ECC=y
+# CONFIG_HISNFC100_AUTO_PAGESIZE_ECC is not set
+# CONFIG_HISNFC100_PAGESIZE_AUTO_ECC_NONE is not set
+# CONFIG_MTD_ONENAND is not set
+
+#
+# LPDDR & LPDDR2 PCM memory drivers
+#
+# CONFIG_MTD_LPDDR is not set
+# CONFIG_MTD_LPDDR2_NVM is not set
+CONFIG_MTD_SPI_NOR=y
+# CONFIG_MTD_MT81xx_NOR is not set
+# CONFIG_MTD_SPI_NOR_USE_4K_SECTORS is not set
+# CONFIG_SPI_CADENCE_QUADSPI is not set
+# CONFIG_SPI_HISI_SFC is not set
+CONFIG_MTD_SPI_IDS=y
+CONFIG_CLOSE_SPI_8PIN_4IO=y
+CONFIG_MTD_HISFC350=y
+CONFIG_HISFC350_SYSCTRL_ADDRESS=0x20030000
+CONFIG_HISFC350_CHIP_NUM=2
+# CONFIG_HISFC350_SHOW_CYCLE_TIMING is not set
+# CONFIG_HISFC350_ENABLE_CHIPSELECT_0 is not set
+CONFIG_HISFC350_ENABLE_CHIPSELECT_1=y
+# CONFIG_HISFC350_ENABLE_INTR_DMA is not set
+CONFIG_CMD_SPI_BLOCK_PROTECTION=y
+# CONFIG_MTD_UBI is not set
+CONFIG_DTC=y
+CONFIG_OF=y
+# CONFIG_OF_UNITTEST is not set
+CONFIG_OF_FLATTREE=y
+CONFIG_OF_EARLY_FLATTREE=y
+CONFIG_OF_ADDRESS=y
+CONFIG_OF_IRQ=y
+CONFIG_OF_NET=y
+CONFIG_OF_MDIO=y
+CONFIG_OF_RESERVED_MEM=y
+# CONFIG_OF_OVERLAY is not set
+CONFIG_ARCH_MIGHT_HAVE_PC_PARPORT=y
+# CONFIG_PARPORT is not set
+CONFIG_BLK_DEV=y
+# CONFIG_BLK_DEV_NULL_BLK is not set
+# CONFIG_BLK_DEV_COW_COMMON is not set
+# CONFIG_BLK_DEV_LOOP is not set
+# CONFIG_BLK_DEV_DRBD is not set
+# CONFIG_BLK_DEV_NBD is not set
+CONFIG_BLK_DEV_RAM=y
+CONFIG_BLK_DEV_RAM_COUNT=16
+CONFIG_BLK_DEV_RAM_SIZE=65536
+# CONFIG_CDROM_PKTCDVD is not set
+# CONFIG_ATA_OVER_ETH is not set
+# CONFIG_BLK_DEV_RBD is not set
+# CONFIG_NVME_TARGET is not set
+
+#
+# Misc devices
+#
+# CONFIG_SENSORS_LIS3LV02D is not set
+# CONFIG_AD525X_DPOT is not set
+# CONFIG_DUMMY_IRQ is not set
+# CONFIG_ICS932S401 is not set
+# CONFIG_ENCLOSURE_SERVICES is not set
+# CONFIG_APDS9802ALS is not set
+# CONFIG_ISL29003 is not set
+# CONFIG_ISL29020 is not set
+# CONFIG_SENSORS_TSL2550 is not set
+# CONFIG_SENSORS_BH1770 is not set
+# CONFIG_SENSORS_APDS990X is not set
+# CONFIG_HMC6352 is not set
+# CONFIG_DS1682 is not set
+# CONFIG_TI_DAC7512 is not set
+# CONFIG_USB_SWITCH_FSA9480 is not set
+# CONFIG_LATTICE_ECP3_CONFIG is not set
+# CONFIG_SRAM is not set
+# CONFIG_C2PORT is not set
+
+#
+# EEPROM support
+#
+# CONFIG_EEPROM_AT24 is not set
+# CONFIG_EEPROM_AT25 is not set
+# CONFIG_EEPROM_LEGACY is not set
+# CONFIG_EEPROM_MAX6875 is not set
+# CONFIG_EEPROM_93CX6 is not set
+# CONFIG_EEPROM_93XX46 is not set
+
+#
+# Texas Instruments shared transport line discipline
+#
+# CONFIG_SENSORS_LIS3_SPI is not set
+# CONFIG_SENSORS_LIS3_I2C is not set
+
+#
+# Altera FPGA firmware download module
+#
+# CONFIG_ALTERA_STAPL is not set
+
+#
+# Intel MIC Bus Driver
+#
+
+#
+# SCIF Bus Driver
+#
+
+#
+# VOP Bus Driver
+#
+
+#
+# Intel MIC Host Driver
+#
+
+#
+# Intel MIC Card Driver
+#
+
+#
+# SCIF Driver
+#
+
+#
+# Intel MIC Coprocessor State Management (COSM) Drivers
+#
+
+#
+# VOP Driver
+#
+# CONFIG_ECHO is not set
+# CONFIG_CXL_BASE is not set
+# CONFIG_CXL_AFU_DRIVER_OPS is not set
+
+#
+# SCSI device support
+#
+CONFIG_SCSI_MOD=y
+# CONFIG_RAID_ATTRS is not set
+# CONFIG_SCSI is not set
+# CONFIG_SCSI_DMA is not set
+# CONFIG_SCSI_NETLINK is not set
+# CONFIG_ATA is not set
+# CONFIG_MD is not set
+CONFIG_NETDEVICES=y
+CONFIG_NET_CORE=y
+# CONFIG_BONDING is not set
+# CONFIG_DUMMY is not set
+# CONFIG_EQUALIZER is not set
+# CONFIG_NET_TEAM is not set
+# CONFIG_MACVLAN is not set
+# CONFIG_VXLAN is not set
+# CONFIG_MACSEC is not set
+# CONFIG_NETCONSOLE is not set
+# CONFIG_NETPOLL is not set
+# CONFIG_NET_POLL_CONTROLLER is not set
+# CONFIG_TUN is not set
+# CONFIG_TUN_VNET_CROSS_LE is not set
+# CONFIG_VETH is not set
+# CONFIG_NLMON is not set
+
+#
+# CAIF transport drivers
+#
+
+#
+# Distributed Switch Architecture drivers
+#
+CONFIG_ETHERNET=y
+# CONFIG_ALTERA_TSE is not set
+# CONFIG_NET_VENDOR_AMAZON is not set
+# CONFIG_NET_VENDOR_ARC is not set
+# CONFIG_NET_VENDOR_AURORA is not set
+# CONFIG_NET_CADENCE is not set
+# CONFIG_NET_VENDOR_BROADCOM is not set
+# CONFIG_NET_VENDOR_CIRRUS is not set
+# CONFIG_DM9000 is not set
+# CONFIG_DNET is not set
+# CONFIG_NET_VENDOR_EZCHIP is not set
+# CONFIG_NET_VENDOR_FARADAY is not set
+CONFIG_NET_VENDOR_HISILICON=y
+# CONFIG_HIX5HD2_GMAC is not set
+# CONFIG_HISI_FEMAC is not set
+# CONFIG_HIP04_ETH is not set
+# CONFIG_HNS is not set
+# CONFIG_HNS_DSAF is not set
+# CONFIG_HNS_ENET is not set
+CONFIG_HIETH_GMAC=y
+# CONFIG_HIGMAC_DESC_4WORD is not set
+# CONFIG_HIGMAC_RXCSUM is not set
+CONFIG_RX_FLOW_CTRL_SUPPORT=y
+CONFIG_TX_FLOW_CTRL_SUPPORT=y
+CONFIG_TX_FLOW_CTRL_PAUSE_TIME=0xFFFF
+CONFIG_TX_FLOW_CTRL_PAUSE_INTERVAL=0xFFFF
+CONFIG_TX_FLOW_CTRL_ACTIVE_THRESHOLD=16
+CONFIG_TX_FLOW_CTRL_DEACTIVE_THRESHOLD=32
+# CONFIG_NET_VENDOR_INTEL is not set
+# CONFIG_NET_VENDOR_MARVELL is not set
+# CONFIG_NET_VENDOR_MICREL is not set
+# CONFIG_NET_VENDOR_MICROCHIP is not set
+# CONFIG_NET_VENDOR_NATSEMI is not set
+# CONFIG_NET_VENDOR_NETRONOME is not set
+# CONFIG_ETHOC is not set
+# CONFIG_NET_VENDOR_QUALCOMM is not set
+# CONFIG_NET_VENDOR_RENESAS is not set
+# CONFIG_NET_VENDOR_ROCKER is not set
+# CONFIG_NET_VENDOR_SAMSUNG is not set
+# CONFIG_NET_VENDOR_SEEQ is not set
+# CONFIG_NET_VENDOR_SMSC is not set
+# CONFIG_NET_VENDOR_STMICRO is not set
+# CONFIG_NET_VENDOR_SYNOPSYS is not set
+# CONFIG_NET_VENDOR_VIA is not set
+# CONFIG_NET_VENDOR_WIZNET is not set
+CONFIG_PHYLIB=y
+CONFIG_SWPHY=y
+
+#
+# MDIO bus device drivers
+#
+# CONFIG_MDIO_BCM_UNIMAC is not set
+# CONFIG_MDIO_BITBANG is not set
+# CONFIG_MDIO_BUS_MUX_MMIOREG is not set
+# CONFIG_MDIO_HISI_FEMAC is not set
+CONFIG_MDIO_HISI_GEMAC=y
+
+#
+# MII PHY device drivers
+#
+# CONFIG_AMD_PHY is not set
+# CONFIG_AQUANTIA_PHY is not set
+# CONFIG_AT803X_PHY is not set
+# CONFIG_BCM7XXX_PHY is not set
+# CONFIG_BCM87XX_PHY is not set
+# CONFIG_BROADCOM_PHY is not set
+# CONFIG_CICADA_PHY is not set
+# CONFIG_DAVICOM_PHY is not set
+# CONFIG_DP83848_PHY is not set
+# CONFIG_DP83867_PHY is not set
+CONFIG_FIXED_PHY=y
+# CONFIG_ICPLUS_PHY is not set
+# CONFIG_INTEL_XWAY_PHY is not set
+# CONFIG_LSI_ET1011C_PHY is not set
+# CONFIG_LXT_PHY is not set
+# CONFIG_MARVELL_PHY is not set
+# CONFIG_MICREL_PHY is not set
+# CONFIG_MICROCHIP_PHY is not set
+# CONFIG_MICROSEMI_PHY is not set
+# CONFIG_NATIONAL_PHY is not set
+# CONFIG_QSEMI_PHY is not set
+# CONFIG_REALTEK_PHY is not set
+# CONFIG_SMSC_PHY is not set
+# CONFIG_STE10XP is not set
+# CONFIG_TERANETICS_PHY is not set
+# CONFIG_VITESSE_PHY is not set
+# CONFIG_XILINX_GMII2RGMII is not set
+# CONFIG_MICREL_KS8995MA is not set
+# CONFIG_PPP is not set
+# CONFIG_SLIP is not set
+
+#
+# Host-side USB support is needed for USB Network Adapter support
+#
+# CONFIG_WLAN is not set
+
+#
+# Enable WiMAX (Networking options) to see the WiMAX drivers
+#
+# CONFIG_WAN is not set
+# CONFIG_ISDN is not set
+# CONFIG_NVM is not set
+
+#
+# Input device support
+#
+CONFIG_INPUT=y
+# CONFIG_INPUT_FF_MEMLESS is not set
+# CONFIG_INPUT_POLLDEV is not set
+# CONFIG_INPUT_SPARSEKMAP is not set
+# CONFIG_INPUT_MATRIXKMAP is not set
+
+#
+# Userland interfaces
+#
+CONFIG_INPUT_MOUSEDEV=y
+CONFIG_INPUT_MOUSEDEV_PSAUX=y
+CONFIG_INPUT_MOUSEDEV_SCREEN_X=1024
+CONFIG_INPUT_MOUSEDEV_SCREEN_Y=768
+# CONFIG_INPUT_JOYDEV is not set
+CONFIG_INPUT_EVDEV=y
+# CONFIG_INPUT_EVBUG is not set
+
+#
+# Input Device Drivers
+#
+CONFIG_INPUT_KEYBOARD=y
+# CONFIG_KEYBOARD_ADP5588 is not set
+# CONFIG_KEYBOARD_ADP5589 is not set
+CONFIG_KEYBOARD_ATKBD=y
+# CONFIG_KEYBOARD_QT1070 is not set
+# CONFIG_KEYBOARD_QT2160 is not set
+# CONFIG_KEYBOARD_LKKBD is not set
+# CONFIG_KEYBOARD_TCA6416 is not set
+# CONFIG_KEYBOARD_TCA8418 is not set
+# CONFIG_KEYBOARD_LM8333 is not set
+# CONFIG_KEYBOARD_MAX7359 is not set
+# CONFIG_KEYBOARD_MCS is not set
+# CONFIG_KEYBOARD_MPR121 is not set
+# CONFIG_KEYBOARD_NEWTON is not set
+# CONFIG_KEYBOARD_OPENCORES is not set
+# CONFIG_KEYBOARD_SAMSUNG is not set
+# CONFIG_KEYBOARD_STOWAWAY is not set
+# CONFIG_KEYBOARD_SUNKBD is not set
+# CONFIG_KEYBOARD_OMAP4 is not set
+# CONFIG_KEYBOARD_XTKBD is not set
+# CONFIG_KEYBOARD_CAP11XX is not set
+# CONFIG_KEYBOARD_BCM is not set
+CONFIG_INPUT_MOUSE=y
+CONFIG_MOUSE_PS2=y
+CONFIG_MOUSE_PS2_ALPS=y
+CONFIG_MOUSE_PS2_BYD=y
+CONFIG_MOUSE_PS2_LOGIPS2PP=y
+CONFIG_MOUSE_PS2_SYNAPTICS=y
+CONFIG_MOUSE_PS2_CYPRESS=y
+CONFIG_MOUSE_PS2_TRACKPOINT=y
+# CONFIG_MOUSE_PS2_ELANTECH is not set
+# CONFIG_MOUSE_PS2_SENTELIC is not set
+# CONFIG_MOUSE_PS2_TOUCHKIT is not set
+CONFIG_MOUSE_PS2_FOCALTECH=y
+# CONFIG_MOUSE_SERIAL is not set
+# CONFIG_MOUSE_CYAPA is not set
+# CONFIG_MOUSE_ELAN_I2C is not set
+# CONFIG_MOUSE_VSXXXAA is not set
+# CONFIG_MOUSE_SYNAPTICS_I2C is not set
+# CONFIG_INPUT_JOYSTICK is not set
+# CONFIG_INPUT_TABLET is not set
+# CONFIG_INPUT_TOUCHSCREEN is not set
+CONFIG_INPUT_MISC=y
+# CONFIG_INPUT_AD714X is not set
+# CONFIG_INPUT_ATMEL_CAPTOUCH is not set
+# CONFIG_INPUT_BMA150 is not set
+# CONFIG_INPUT_E3X0_BUTTON is not set
+# CONFIG_INPUT_MMA8450 is not set
+# CONFIG_INPUT_MPU3050 is not set
+# CONFIG_INPUT_KXTJ9 is not set
+# CONFIG_INPUT_REGULATOR_HAPTIC is not set
+CONFIG_INPUT_UINPUT=y
+# CONFIG_INPUT_PCF8574 is not set
+# CONFIG_INPUT_ADXL34X is not set
+# CONFIG_INPUT_CMA3000 is not set
+# CONFIG_INPUT_DRV2665_HAPTICS is not set
+# CONFIG_INPUT_DRV2667_HAPTICS is not set
+# CONFIG_RMI4_CORE is not set
+
+#
+# Hardware I/O ports
+#
+CONFIG_SERIO=y
+CONFIG_SERIO_SERPORT=y
+# CONFIG_SERIO_AMBAKMI is not set
+CONFIG_SERIO_LIBPS2=y
+# CONFIG_SERIO_RAW is not set
+# CONFIG_SERIO_ALTERA_PS2 is not set
+# CONFIG_SERIO_PS2MULT is not set
+# CONFIG_SERIO_ARC_PS2 is not set
+# CONFIG_SERIO_APBPS2 is not set
+# CONFIG_USERIO is not set
+# CONFIG_GAMEPORT is not set
+
+#
+# Character devices
+#
+CONFIG_TTY=y
+CONFIG_VT=y
+CONFIG_CONSOLE_TRANSLATIONS=y
+CONFIG_VT_CONSOLE=y
+CONFIG_VT_CONSOLE_SLEEP=y
+CONFIG_HW_CONSOLE=y
+# CONFIG_VT_HW_CONSOLE_BINDING is not set
+CONFIG_UNIX98_PTYS=y
+# CONFIG_LEGACY_PTYS is not set
+# CONFIG_SERIAL_NONSTANDARD is not set
+# CONFIG_N_GSM is not set
+# CONFIG_TRACE_SINK is not set
+CONFIG_DEVMEM=y
+# CONFIG_DEVKMEM is not set
+
+#
+# Serial drivers
+#
+CONFIG_SERIAL_EARLYCON=y
+# CONFIG_SERIAL_8250 is not set
+
+#
+# Non-8250 serial port support
+#
+# CONFIG_SERIAL_AMBA_PL010 is not set
+CONFIG_SERIAL_AMBA_PL011=y
+CONFIG_SERIAL_AMBA_PL011_CONSOLE=y
+# CONFIG_SERIAL_EARLYCON_ARM_SEMIHOST is not set
+# CONFIG_SERIAL_MAX3100 is not set
+# CONFIG_SERIAL_MAX310X is not set
+# CONFIG_SERIAL_UARTLITE is not set
+CONFIG_SERIAL_CORE=y
+CONFIG_SERIAL_CORE_CONSOLE=y
+# CONFIG_SERIAL_SCCNXP is not set
+# CONFIG_SERIAL_SC16IS7XX is not set
+# CONFIG_SERIAL_BCM63XX is not set
+# CONFIG_SERIAL_ALTERA_JTAGUART is not set
+# CONFIG_SERIAL_ALTERA_UART is not set
+# CONFIG_SERIAL_XILINX_PS_UART is not set
+# CONFIG_SERIAL_ARC is not set
+# CONFIG_SERIAL_FSL_LPUART is not set
+# CONFIG_SERIAL_CONEXANT_DIGICOLOR is not set
+# CONFIG_SERIAL_ST_ASC is not set
+# CONFIG_SERIAL_STM32 is not set
+# CONFIG_HVC_DCC is not set
+# CONFIG_IPMI_HANDLER is not set
+# CONFIG_HW_RANDOM is not set
+# CONFIG_R3964 is not set
+# CONFIG_RAW_DRIVER is not set
+# CONFIG_TCG_TPM is not set
+# CONFIG_XILLYBUS is not set
+
+#
+# I2C support
+#
+CONFIG_I2C=y
+CONFIG_I2C_BOARDINFO=y
+CONFIG_I2C_COMPAT=y
+CONFIG_I2C_CHARDEV=y
+# CONFIG_I2C_MUX is not set
+CONFIG_I2C_HELPER_AUTO=y
+
+#
+# I2C Hardware Bus support
+#
+
+#
+# I2C system bus drivers (mostly embedded / system-on-chip)
+#
+# CONFIG_I2C_DESIGNWARE_PLATFORM is not set
+# CONFIG_I2C_EMEV2 is not set
+# CONFIG_I2C_HIBVT is not set
+# CONFIG_I2C_NOMADIK is not set
+# CONFIG_I2C_OCORES is not set
+# CONFIG_I2C_PCA_PLATFORM is not set
+# CONFIG_I2C_PXA_PCI is not set
+# CONFIG_I2C_RK3X is not set
+# CONFIG_I2C_SIMTEC is not set
+# CONFIG_I2C_XILINX is not set
+
+#
+# External I2C/SMBus adapter drivers
+#
+# CONFIG_I2C_PARPORT_LIGHT is not set
+# CONFIG_I2C_TAOS_EVM is not set
+
+#
+# Other I2C/SMBus bus drivers
+#
+CONFIG_I2C_HISI=y
+# CONFIG_I2C_STUB is not set
+# CONFIG_I2C_SLAVE is not set
+# CONFIG_I2C_DEBUG_CORE is not set
+# CONFIG_I2C_DEBUG_ALGO is not set
+# CONFIG_I2C_DEBUG_BUS is not set
+CONFIG_SPI=y
+# CONFIG_SPI_DEBUG is not set
+CONFIG_SPI_MASTER=y
+
+#
+# SPI Master Controller Drivers
+#
+# CONFIG_SPI_ALTERA is not set
+# CONFIG_SPI_AXI_SPI_ENGINE is not set
+# CONFIG_SPI_BITBANG is not set
+# CONFIG_SPI_CADENCE is not set
+# CONFIG_SPI_DESIGNWARE is not set
+# CONFIG_SPI_FSL_SPI is not set
+CONFIG_SPI_PL022=y
+# CONFIG_SPI_PXA2XX_PCI is not set
+# CONFIG_SPI_ROCKCHIP is not set
+# CONFIG_SPI_SC18IS602 is not set
+# CONFIG_SPI_XCOMM is not set
+# CONFIG_SPI_XILINX is not set
+# CONFIG_SPI_ZYNQMP_GQSPI is not set
+
+#
+# SPI Protocol Masters
+#
+CONFIG_SPI_SPIDEV=y
+# CONFIG_SPI_LOOPBACK_TEST is not set
+# CONFIG_SPI_TLE62X0 is not set
+# CONFIG_SPMI is not set
+# CONFIG_HSI is not set
+
+#
+# PPS support
+#
+# CONFIG_PPS is not set
+
+#
+# PPS generators support
+#
+
+#
+# PTP clock support
+#
+# CONFIG_PTP_1588_CLOCK is not set
+
+#
+# Enable PHYLIB and NETWORK_PHY_TIMESTAMPING to see the additional clocks.
+#
+CONFIG_ARCH_HAVE_CUSTOM_GPIO_H=y
+# CONFIG_GPIOLIB is not set
+# CONFIG_W1 is not set
+# CONFIG_POWER_AVS is not set
+CONFIG_POWER_RESET=y
+# CONFIG_POWER_RESET_BRCMKONA is not set
+CONFIG_POWER_RESET_HISI=y
+# CONFIG_POWER_RESET_RESTART is not set
+# CONFIG_POWER_RESET_SYSCON is not set
+# CONFIG_POWER_RESET_SYSCON_POWEROFF is not set
+CONFIG_POWER_SUPPLY=y
+# CONFIG_POWER_SUPPLY_DEBUG is not set
+# CONFIG_PDA_POWER is not set
+# CONFIG_TEST_POWER is not set
+# CONFIG_BATTERY_DS2780 is not set
+# CONFIG_BATTERY_DS2781 is not set
+# CONFIG_BATTERY_DS2782 is not set
+# CONFIG_BATTERY_SBS is not set
+# CONFIG_BATTERY_BQ27XXX is not set
+# CONFIG_BATTERY_MAX17040 is not set
+# CONFIG_BATTERY_MAX17042 is not set
+# CONFIG_CHARGER_MAX8903 is not set
+# CONFIG_CHARGER_LP8727 is not set
+# CONFIG_CHARGER_MANAGER is not set
+# CONFIG_CHARGER_BQ2415X is not set
+# CONFIG_CHARGER_SMB347 is not set
+# CONFIG_BATTERY_GAUGE_LTC2941 is not set
+# CONFIG_HWMON is not set
+# CONFIG_THERMAL is not set
+# CONFIG_WATCHDOG is not set
+CONFIG_SSB_POSSIBLE=y
+
+#
+# Sonics Silicon Backplane
+#
+# CONFIG_SSB is not set
+CONFIG_BCMA_POSSIBLE=y
+
+#
+# Broadcom specific AMBA
+#
+# CONFIG_BCMA is not set
+
+#
+# Multifunction device drivers
+#
+# CONFIG_MFD_CORE is not set
+# CONFIG_MFD_ACT8945A is not set
+# CONFIG_MFD_AS3711 is not set
+# CONFIG_MFD_AS3722 is not set
+# CONFIG_PMIC_ADP5520 is not set
+# CONFIG_MFD_ATMEL_FLEXCOM is not set
+# CONFIG_MFD_ATMEL_HLCDC is not set
+# CONFIG_MFD_BCM590XX is not set
+# CONFIG_MFD_AXP20X_I2C is not set
+# CONFIG_MFD_CROS_EC is not set
+# CONFIG_PMIC_DA903X is not set
+# CONFIG_MFD_DA9052_SPI is not set
+# CONFIG_MFD_DA9052_I2C is not set
+# CONFIG_MFD_DA9055 is not set
+# CONFIG_MFD_DA9062 is not set
+# CONFIG_MFD_DA9063 is not set
+# CONFIG_MFD_DA9150 is not set
+# CONFIG_MFD_EXYNOS_LPASS is not set
+# CONFIG_MFD_MC13XXX_SPI is not set
+# CONFIG_MFD_MC13XXX_I2C is not set
+# CONFIG_MFD_HI6421_PMIC is not set
+# CONFIG_MFD_HISI_FMC is not set
+# CONFIG_HTC_PASIC3 is not set
+# CONFIG_MFD_KEMPLD is not set
+# CONFIG_MFD_88PM800 is not set
+# CONFIG_MFD_88PM805 is not set
+# CONFIG_MFD_88PM860X is not set
+# CONFIG_MFD_MAX14577 is not set
+# CONFIG_MFD_MAX77620 is not set
+# CONFIG_MFD_MAX77686 is not set
+# CONFIG_MFD_MAX77693 is not set
+# CONFIG_MFD_MAX77843 is not set
+# CONFIG_MFD_MAX8907 is not set
+# CONFIG_MFD_MAX8925 is not set
+# CONFIG_MFD_MAX8997 is not set
+# CONFIG_MFD_MAX8998 is not set
+# CONFIG_MFD_MT6397 is not set
+# CONFIG_MFD_MENF21BMC is not set
+# CONFIG_EZX_PCAP is not set
+# CONFIG_MFD_RETU is not set
+# CONFIG_MFD_PCF50633 is not set
+# CONFIG_MFD_PM8921_CORE is not set
+# CONFIG_MFD_RT5033 is not set
+# CONFIG_MFD_RC5T583 is not set
+# CONFIG_MFD_RK808 is not set
+# CONFIG_MFD_RN5T618 is not set
+# CONFIG_MFD_SEC_CORE is not set
+# CONFIG_MFD_SI476X_CORE is not set
+# CONFIG_MFD_SM501 is not set
+# CONFIG_MFD_SKY81452 is not set
+# CONFIG_MFD_SMSC is not set
+# CONFIG_ABX500_CORE is not set
+# CONFIG_MFD_STMPE is not set
+# CONFIG_MFD_SYSCON is not set
+# CONFIG_MFD_TI_AM335X_TSCADC is not set
+# CONFIG_MFD_LP3943 is not set
+# CONFIG_MFD_LP8788 is not set
+# CONFIG_MFD_PALMAS is not set
+# CONFIG_TPS6105X is not set
+# CONFIG_TPS6507X is not set
+# CONFIG_MFD_TPS65086 is not set
+# CONFIG_MFD_TPS65090 is not set
+# CONFIG_MFD_TPS65217 is not set
+# CONFIG_MFD_TI_LP873X is not set
+# CONFIG_MFD_TPS65218 is not set
+# CONFIG_MFD_TPS6586X is not set
+# CONFIG_MFD_TPS65912_I2C is not set
+# CONFIG_MFD_TPS65912_SPI is not set
+# CONFIG_MFD_TPS80031 is not set
+# CONFIG_TWL4030_CORE is not set
+# CONFIG_TWL6040_CORE is not set
+# CONFIG_MFD_WL1273_CORE is not set
+# CONFIG_MFD_LM3533 is not set
+# CONFIG_MFD_TC3589X is not set
+# CONFIG_MFD_TMIO is not set
+# CONFIG_MFD_T7L66XB is not set
+# CONFIG_MFD_TC6387XB is not set
+# CONFIG_MFD_TC6393XB is not set
+# CONFIG_MFD_ARIZONA_I2C is not set
+# CONFIG_MFD_ARIZONA_SPI is not set
+# CONFIG_MFD_WM8400 is not set
+# CONFIG_MFD_WM831X_I2C is not set
+# CONFIG_MFD_WM831X_SPI is not set
+# CONFIG_MFD_WM8350_I2C is not set
+# CONFIG_MFD_WM8994 is not set
+CONFIG_REGULATOR=y
+# CONFIG_REGULATOR_DEBUG is not set
+# CONFIG_REGULATOR_FIXED_VOLTAGE is not set
+# CONFIG_REGULATOR_VIRTUAL_CONSUMER is not set
+# CONFIG_REGULATOR_USERSPACE_CONSUMER is not set
+# CONFIG_REGULATOR_ACT8865 is not set
+# CONFIG_REGULATOR_AD5398 is not set
+# CONFIG_REGULATOR_DA9210 is not set
+# CONFIG_REGULATOR_DA9211 is not set
+# CONFIG_REGULATOR_FAN53555 is not set
+# CONFIG_REGULATOR_ISL9305 is not set
+# CONFIG_REGULATOR_ISL6271A is not set
+# CONFIG_REGULATOR_LP3971 is not set
+# CONFIG_REGULATOR_LP3972 is not set
+# CONFIG_REGULATOR_LP872X is not set
+# CONFIG_REGULATOR_LP8755 is not set
+# CONFIG_REGULATOR_LTC3589 is not set
+# CONFIG_REGULATOR_LTC3676 is not set
+# CONFIG_REGULATOR_MAX1586 is not set
+# CONFIG_REGULATOR_MAX8649 is not set
+# CONFIG_REGULATOR_MAX8660 is not set
+# CONFIG_REGULATOR_MAX8952 is not set
+# CONFIG_REGULATOR_MT6311 is not set
+# CONFIG_REGULATOR_PFUZE100 is not set
+# CONFIG_REGULATOR_PV88060 is not set
+# CONFIG_REGULATOR_PV88080 is not set
+# CONFIG_REGULATOR_PV88090 is not set
+# CONFIG_REGULATOR_TPS51632 is not set
+# CONFIG_REGULATOR_TPS62360 is not set
+# CONFIG_REGULATOR_TPS65023 is not set
+# CONFIG_REGULATOR_TPS6507X is not set
+# CONFIG_REGULATOR_TPS6524X is not set
+# CONFIG_MEDIA_SUPPORT is not set
+
+#
+# Graphics support
+#
+# CONFIG_IMX_IPUV3_CORE is not set
+# CONFIG_DRM is not set
+
+#
+# ACP (Audio CoProcessor) Configuration
+#
+
+#
+# Frame buffer Devices
+#
+CONFIG_FB=y
+# CONFIG_FIRMWARE_EDID is not set
+CONFIG_FB_CMDLINE=y
+CONFIG_FB_NOTIFY=y
+# CONFIG_FB_DDC is not set
+# CONFIG_FB_BOOT_VESA_SUPPORT is not set
+# CONFIG_FB_CFB_FILLRECT is not set
+# CONFIG_FB_CFB_COPYAREA is not set
+# CONFIG_FB_CFB_IMAGEBLIT is not set
+# CONFIG_FB_CFB_REV_PIXELS_IN_BYTE is not set
+# CONFIG_FB_SYS_FILLRECT is not set
+# CONFIG_FB_SYS_COPYAREA is not set
+# CONFIG_FB_SYS_IMAGEBLIT is not set
+# CONFIG_FB_FOREIGN_ENDIAN is not set
+# CONFIG_FB_SYS_FOPS is not set
+# CONFIG_FB_SVGALIB is not set
+# CONFIG_FB_MACMODES is not set
+# CONFIG_FB_BACKLIGHT is not set
+# CONFIG_FB_MODE_HELPERS is not set
+# CONFIG_FB_TILEBLITTING is not set
+
+#
+# Frame buffer hardware drivers
+#
+# CONFIG_FB_ARMCLCD is not set
+# CONFIG_FB_OPENCORES is not set
+# CONFIG_FB_S1D13XXX is not set
+# CONFIG_FB_IBM_GXT4500 is not set
+# CONFIG_FB_VIRTUAL is not set
+# CONFIG_FB_METRONOME is not set
+# CONFIG_FB_BROADSHEET is not set
+# CONFIG_FB_AUO_K190X is not set
+# CONFIG_FB_SIMPLE is not set
+# CONFIG_BACKLIGHT_LCD_SUPPORT is not set
+# CONFIG_VGASTATE is not set
+
+#
+# Console display driver support
+#
+CONFIG_DUMMY_CONSOLE=y
+# CONFIG_FRAMEBUFFER_CONSOLE is not set
+# CONFIG_LOGO is not set
+# CONFIG_SOUND is not set
+
+#
+# HID support
+#
+# CONFIG_HID is not set
+
+#
+# I2C HID support
+#
+# CONFIG_I2C_HID is not set
+CONFIG_USB_OHCI_LITTLE_ENDIAN=y
+# CONFIG_USB_SUPPORT is not set
+# CONFIG_UWB is not set
+# CONFIG_MMC is not set
+# CONFIG_MEMSTICK is not set
+# CONFIG_NEW_LEDS is not set
+# CONFIG_ACCESSIBILITY is not set
+CONFIG_EDAC_ATOMIC_SCRUB=y
+CONFIG_EDAC_SUPPORT=y
+# CONFIG_EDAC is not set
+CONFIG_RTC_LIB=y
+# CONFIG_RTC_CLASS is not set
+# CONFIG_DMADEVICES is not set
+
+#
+# DMABUF options
+#
+# CONFIG_SYNC_FILE is not set
+# CONFIG_AUXDISPLAY is not set
+# CONFIG_UIO is not set
+# CONFIG_VIRT_DRIVERS is not set
+
+#
+# Virtio drivers
+#
+# CONFIG_VIRTIO_MMIO is not set
+
+#
+# Microsoft Hyper-V guest support
+#
+# CONFIG_STAGING is not set
+# CONFIG_GOLDFISH is not set
+# CONFIG_CHROME_PLATFORMS is not set
+CONFIG_CLKDEV_LOOKUP=y
+CONFIG_HAVE_CLK_PREPARE=y
+CONFIG_COMMON_CLK=y
+
+#
+# Common Clock Framework
+#
+# CONFIG_COMMON_CLK_SI5351 is not set
+# CONFIG_COMMON_CLK_SI514 is not set
+# CONFIG_COMMON_CLK_SI570 is not set
+# CONFIG_COMMON_CLK_CDCE706 is not set
+# CONFIG_COMMON_CLK_CDCE925 is not set
+# CONFIG_COMMON_CLK_CS2000_CP is not set
+# CONFIG_CLK_QORIQ is not set
+# CONFIG_COMMON_CLK_NXP is not set
+# CONFIG_COMMON_CLK_PXA is not set
+# CONFIG_COMMON_CLK_PIC32 is not set
+CONFIG_COMMON_CLK_HI3516A=y
+CONFIG_RESET_HISI=y
+
+#
+# Hardware Spinlock drivers
+#
+
+#
+# Clock Source drivers
+#
+CONFIG_CLKSRC_OF=y
+CONFIG_CLKSRC_PROBE=y
+CONFIG_CLKSRC_MMIO=y
+CONFIG_ARM_ARCH_TIMER=y
+CONFIG_ARM_ARCH_TIMER_EVTSTREAM=y
+CONFIG_ARM_TIMER_SP804=y
+# CONFIG_ATMEL_PIT is not set
+# CONFIG_SH_TIMER_CMT is not set
+# CONFIG_SH_TIMER_MTU2 is not set
+# CONFIG_SH_TIMER_TMU is not set
+# CONFIG_EM_TIMER_STI is not set
+# CONFIG_MAILBOX is not set
+# CONFIG_IOMMU_SUPPORT is not set
+
+#
+# Remoteproc drivers
+#
+# CONFIG_STE_MODEM_RPROC is not set
+
+#
+# Rpmsg drivers
+#
+
+#
+# SOC (System On Chip) specific Drivers
+#
+
+#
+# Broadcom SoC drivers
+#
+# CONFIG_SOC_BRCMSTB is not set
+# CONFIG_SUNXI_SRAM is not set
+# CONFIG_SOC_TI is not set
+# CONFIG_PM_DEVFREQ is not set
+# CONFIG_EXTCON is not set
+# CONFIG_MEMORY is not set
+# CONFIG_IIO is not set
+# CONFIG_PWM is not set
+CONFIG_IRQCHIP=y
+CONFIG_ARM_GIC=y
+CONFIG_ARM_GIC_MAX_NR=1
+# CONFIG_IPACK_BUS is not set
+CONFIG_ARCH_HAS_RESET_CONTROLLER=y
+CONFIG_RESET_CONTROLLER=y
+# CONFIG_RESET_ATH79 is not set
+# CONFIG_RESET_BERLIN is not set
+# CONFIG_RESET_LPC18XX is not set
+# CONFIG_RESET_MESON is not set
+# CONFIG_RESET_PISTACHIO is not set
+# CONFIG_RESET_SOCFPGA is not set
+# CONFIG_RESET_STM32 is not set
+# CONFIG_RESET_SUNXI is not set
+# CONFIG_TI_SYSCON_RESET is not set
+# CONFIG_RESET_ZYNQ is not set
+# CONFIG_FMC is not set
+
+#
+# PHY Subsystem
+#
+CONFIG_GENERIC_PHY=y
+# CONFIG_PHY_PXA_28NM_HSIC is not set
+# CONFIG_PHY_PXA_28NM_USB2 is not set
+# CONFIG_BCM_KONA_USB2_PHY is not set
+CONFIG_PHY_HISI_USB2=y
+# CONFIG_POWERCAP is not set
+# CONFIG_MCB is not set
+
+#
+# Performance monitor support
+#
+# CONFIG_RAS is not set
+
+#
+# Android
+#
+# CONFIG_ANDROID is not set
+# CONFIG_NVMEM is not set
+# CONFIG_STM is not set
+# CONFIG_INTEL_TH is not set
+
+#
+# FPGA Configuration Support
+#
+# CONFIG_FPGA is not set
+CONFIG_HI_DMAC=y
+CONFIG_HI_DMAC_CHANNEL_NUM=4
+
+#
+# Firmware Drivers
+#
+# CONFIG_FIRMWARE_MEMMAP is not set
+# CONFIG_FW_CFG_SYSFS is not set
+CONFIG_HAVE_ARM_SMCCC=y
+
+#
+# File systems
+#
+CONFIG_DCACHE_WORD_ACCESS=y
+# CONFIG_EXT2_FS is not set
+# CONFIG_EXT3_FS is not set
+CONFIG_EXT4_FS=y
+CONFIG_EXT4_USE_FOR_EXT2=y
+# CONFIG_EXT4_FS_POSIX_ACL is not set
+# CONFIG_EXT4_FS_SECURITY is not set
+# CONFIG_EXT4_ENCRYPTION is not set
+# CONFIG_EXT4_DEBUG is not set
+CONFIG_JBD2=y
+# CONFIG_JBD2_DEBUG is not set
+CONFIG_FS_MBCACHE=y
+# CONFIG_REISERFS_FS is not set
+# CONFIG_JFS_FS is not set
+# CONFIG_XFS_FS is not set
+# CONFIG_GFS2_FS is not set
+# CONFIG_OCFS2_FS is not set
+# CONFIG_BTRFS_FS is not set
+# CONFIG_NILFS2_FS is not set
+# CONFIG_F2FS_FS is not set
+CONFIG_FS_POSIX_ACL=y
+CONFIG_EXPORTFS=y
+# CONFIG_EXPORTFS_BLOCK_OPS is not set
+CONFIG_FILE_LOCKING=y
+CONFIG_MANDATORY_FILE_LOCKING=y
+# CONFIG_FS_ENCRYPTION is not set
+CONFIG_FSNOTIFY=y
+CONFIG_DNOTIFY=y
+CONFIG_INOTIFY_USER=y
+# CONFIG_FANOTIFY is not set
+# CONFIG_QUOTA is not set
+# CONFIG_QUOTACTL is not set
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_FUSE_FS is not set
+# CONFIG_OVERLAY_FS is not set
+
+#
+# Caches
+#
+# CONFIG_FSCACHE is not set
+
+#
+# CD-ROM/DVD Filesystems
+#
+# CONFIG_ISO9660_FS is not set
+# CONFIG_UDF_FS is not set
+
+#
+# DOS/FAT/NT Filesystems
+#
+CONFIG_FAT_FS=y
+CONFIG_MSDOS_FS=y
+CONFIG_VFAT_FS=y
+CONFIG_FAT_DEFAULT_CODEPAGE=437
+CONFIG_FAT_DEFAULT_IOCHARSET="iso8859-1"
+# CONFIG_FAT_DEFAULT_UTF8 is not set
+# CONFIG_NTFS_FS is not set
+
+#
+# Pseudo filesystems
+#
+CONFIG_PROC_FS=y
+CONFIG_PROC_SYSCTL=y
+CONFIG_PROC_PAGE_MONITOR=y
+# CONFIG_PROC_CHILDREN is not set
+CONFIG_KERNFS=y
+CONFIG_SYSFS=y
+CONFIG_TMPFS=y
+# CONFIG_TMPFS_POSIX_ACL is not set
+# CONFIG_TMPFS_XATTR is not set
+# CONFIG_HUGETLB_PAGE is not set
+CONFIG_CONFIGFS_FS=m
+CONFIG_MISC_FILESYSTEMS=y
+# CONFIG_ORANGEFS_FS is not set
+# CONFIG_ADFS_FS is not set
+# CONFIG_AFFS_FS is not set
+# CONFIG_ECRYPT_FS is not set
+# CONFIG_HFS_FS is not set
+# CONFIG_HFSPLUS_FS is not set
+# CONFIG_BEFS_FS is not set
+# CONFIG_BFS_FS is not set
+# CONFIG_EFS_FS is not set
+CONFIG_YAFFS_FS=y
+CONFIG_YAFFS_YAFFS1=y
+# CONFIG_YAFFS_9BYTE_TAGS is not set
+# CONFIG_YAFFS_DOES_ECC is not set
+CONFIG_YAFFS_YAFFS2=y
+CONFIG_YAFFS_AUTO_YAFFS2=y
+# CONFIG_YAFFS_DISABLE_TAGS_ECC is not set
+# CONFIG_YAFFS_ALWAYS_CHECK_CHUNK_ERASED is not set
+# CONFIG_YAFFS_EMPTY_LOST_AND_FOUND is not set
+# CONFIG_YAFFS_DISABLE_BLOCK_REFRESHING is not set
+# CONFIG_YAFFS_DISABLE_BACKGROUND is not set
+# CONFIG_YAFFS_DISABLE_BAD_BLOCK_MARKING is not set
+CONFIG_YAFFS_XATTR=y
+CONFIG_JFFS2_FS=y
+CONFIG_JFFS2_FS_DEBUG=0
+CONFIG_JFFS2_FS_WRITEBUFFER=y
+# CONFIG_JFFS2_FS_WBUF_VERIFY is not set
+# CONFIG_JFFS2_SUMMARY is not set
+# CONFIG_JFFS2_FS_XATTR is not set
+# CONFIG_JFFS2_COMPRESSION_OPTIONS is not set
+CONFIG_JFFS2_ZLIB=y
+# CONFIG_JFFS2_LZO is not set
+CONFIG_JFFS2_RTIME=y
+# CONFIG_JFFS2_RUBIN is not set
+# CONFIG_LOGFS is not set
+CONFIG_CRAMFS=y
+# CONFIG_SQUASHFS is not set
+# CONFIG_VXFS_FS is not set
+# CONFIG_MINIX_FS is not set
+# CONFIG_OMFS_FS is not set
+# CONFIG_HPFS_FS is not set
+# CONFIG_QNX4FS_FS is not set
+# CONFIG_QNX6FS_FS is not set
+# CONFIG_ROMFS_FS is not set
+# CONFIG_PSTORE is not set
+# CONFIG_SYSV_FS is not set
+# CONFIG_UFS_FS is not set
+CONFIG_NETWORK_FILESYSTEMS=y
+CONFIG_NFS_FS=y
+CONFIG_NFS_V2=y
+CONFIG_NFS_V3=y
+CONFIG_NFS_V3_ACL=y
+CONFIG_NFS_V4=y
+# CONFIG_NFS_SWAP is not set
+# CONFIG_NFS_V4_1 is not set
+CONFIG_ROOT_NFS=y
+# CONFIG_NFS_USE_LEGACY_DNS is not set
+CONFIG_NFS_USE_KERNEL_DNS=y
+# CONFIG_NFSD is not set
+CONFIG_GRACE_PERIOD=y
+CONFIG_LOCKD=y
+CONFIG_LOCKD_V4=y
+CONFIG_NFS_ACL_SUPPORT=y
+CONFIG_NFS_COMMON=y
+CONFIG_SUNRPC=y
+CONFIG_SUNRPC_GSS=y
+# CONFIG_SUNRPC_DEBUG is not set
+# CONFIG_CEPH_FS is not set
+# CONFIG_CIFS is not set
+# CONFIG_NCP_FS is not set
+# CONFIG_CODA_FS is not set
+# CONFIG_AFS_FS is not set
+CONFIG_NLS=y
+CONFIG_NLS_DEFAULT="iso8859-1"
+CONFIG_NLS_CODEPAGE_437=y
+# CONFIG_NLS_CODEPAGE_737 is not set
+# CONFIG_NLS_CODEPAGE_775 is not set
+# CONFIG_NLS_CODEPAGE_850 is not set
+# CONFIG_NLS_CODEPAGE_852 is not set
+# CONFIG_NLS_CODEPAGE_855 is not set
+# CONFIG_NLS_CODEPAGE_857 is not set
+# CONFIG_NLS_CODEPAGE_860 is not set
+# CONFIG_NLS_CODEPAGE_861 is not set
+# CONFIG_NLS_CODEPAGE_862 is not set
+# CONFIG_NLS_CODEPAGE_863 is not set
+# CONFIG_NLS_CODEPAGE_864 is not set
+# CONFIG_NLS_CODEPAGE_865 is not set
+# CONFIG_NLS_CODEPAGE_866 is not set
+# CONFIG_NLS_CODEPAGE_869 is not set
+# CONFIG_NLS_CODEPAGE_936 is not set
+# CONFIG_NLS_CODEPAGE_950 is not set
+# CONFIG_NLS_CODEPAGE_932 is not set
+# CONFIG_NLS_CODEPAGE_949 is not set
+# CONFIG_NLS_CODEPAGE_874 is not set
+# CONFIG_NLS_ISO8859_8 is not set
+# CONFIG_NLS_CODEPAGE_1250 is not set
+# CONFIG_NLS_CODEPAGE_1251 is not set
+# CONFIG_NLS_ASCII is not set
+CONFIG_NLS_ISO8859_1=y
+# CONFIG_NLS_ISO8859_2 is not set
+# CONFIG_NLS_ISO8859_3 is not set
+# CONFIG_NLS_ISO8859_4 is not set
+# CONFIG_NLS_ISO8859_5 is not set
+# CONFIG_NLS_ISO8859_6 is not set
+# CONFIG_NLS_ISO8859_7 is not set
+# CONFIG_NLS_ISO8859_9 is not set
+# CONFIG_NLS_ISO8859_13 is not set
+# CONFIG_NLS_ISO8859_14 is not set
+# CONFIG_NLS_ISO8859_15 is not set
+# CONFIG_NLS_KOI8_R is not set
+# CONFIG_NLS_KOI8_U is not set
+# CONFIG_NLS_MAC_ROMAN is not set
+# CONFIG_NLS_MAC_CELTIC is not set
+# CONFIG_NLS_MAC_CENTEURO is not set
+# CONFIG_NLS_MAC_CROATIAN is not set
+# CONFIG_NLS_MAC_CYRILLIC is not set
+# CONFIG_NLS_MAC_GAELIC is not set
+# CONFIG_NLS_MAC_GREEK is not set
+# CONFIG_NLS_MAC_ICELAND is not set
+# CONFIG_NLS_MAC_INUIT is not set
+# CONFIG_NLS_MAC_ROMANIAN is not set
+# CONFIG_NLS_MAC_TURKISH is not set
+CONFIG_NLS_UTF8=y
+# CONFIG_DLM is not set
+
+#
+# Kernel hacking
+#
+
+#
+# printk and dmesg options
+#
+# CONFIG_PRINTK_TIME is not set
+CONFIG_MESSAGE_LOGLEVEL_DEFAULT=4
+# CONFIG_BOOT_PRINTK_DELAY is not set
+
+#
+# Compile-time checks and compiler options
+#
+# CONFIG_DEBUG_INFO is not set
+# CONFIG_ENABLE_WARN_DEPRECATED is not set
+# CONFIG_ENABLE_MUST_CHECK is not set
+CONFIG_FRAME_WARN=1024
+# CONFIG_STRIP_ASM_SYMS is not set
+# CONFIG_READABLE_ASM is not set
+# CONFIG_UNUSED_SYMBOLS is not set
+# CONFIG_PAGE_OWNER is not set
+# CONFIG_DEBUG_FS is not set
+# CONFIG_HEADERS_CHECK is not set
+# CONFIG_DEBUG_SECTION_MISMATCH is not set
+CONFIG_SECTION_MISMATCH_WARN_ONLY=y
+CONFIG_FRAME_POINTER=y
+# CONFIG_DEBUG_FORCE_WEAK_PER_CPU is not set
+# CONFIG_MAGIC_SYSRQ is not set
+CONFIG_DEBUG_KERNEL=y
+
+#
+# Memory Debugging
+#
+# CONFIG_PAGE_EXTENSION is not set
+# CONFIG_PAGE_POISONING is not set
+# CONFIG_DEBUG_OBJECTS is not set
+# CONFIG_SLUB_DEBUG_ON is not set
+# CONFIG_SLUB_STATS is not set
+CONFIG_HAVE_DEBUG_KMEMLEAK=y
+# CONFIG_DEBUG_KMEMLEAK is not set
+# CONFIG_DEBUG_STACK_USAGE is not set
+# CONFIG_DEBUG_VM is not set
+CONFIG_DEBUG_MEMORY_INIT=y
+# CONFIG_DEBUG_SHIRQ is not set
+
+#
+# Debug Lockups and Hangs
+#
+# CONFIG_LOCKUP_DETECTOR is not set
+# CONFIG_DETECT_HUNG_TASK is not set
+# CONFIG_WQ_WATCHDOG is not set
+# CONFIG_PANIC_ON_OOPS is not set
+CONFIG_PANIC_ON_OOPS_VALUE=0
+CONFIG_PANIC_TIMEOUT=0
+# CONFIG_SCHED_DEBUG is not set
+# CONFIG_SCHED_INFO is not set
+# CONFIG_SCHEDSTATS is not set
+# CONFIG_SCHED_STACK_END_CHECK is not set
+# CONFIG_DEBUG_TIMEKEEPING is not set
+# CONFIG_TIMER_STATS is not set
+
+#
+# Lock Debugging (spinlocks, mutexes, etc...)
+#
+# CONFIG_DEBUG_RT_MUTEXES is not set
+# CONFIG_DEBUG_SPINLOCK is not set
+CONFIG_DEBUG_MUTEXES=y
+# CONFIG_DEBUG_WW_MUTEX_SLOWPATH is not set
+# CONFIG_DEBUG_LOCK_ALLOC is not set
+# CONFIG_PROVE_LOCKING is not set
+# CONFIG_LOCK_STAT is not set
+# CONFIG_DEBUG_ATOMIC_SLEEP is not set
+# CONFIG_DEBUG_LOCKING_API_SELFTESTS is not set
+# CONFIG_LOCK_TORTURE_TEST is not set
+CONFIG_STACKTRACE=y
+# CONFIG_DEBUG_KOBJECT is not set
+CONFIG_DEBUG_BUGVERBOSE=y
+# CONFIG_DEBUG_LIST is not set
+# CONFIG_DEBUG_PI_LIST is not set
+# CONFIG_DEBUG_SG is not set
+# CONFIG_DEBUG_NOTIFIERS is not set
+# CONFIG_DEBUG_CREDENTIALS is not set
+
+#
+# RCU Debugging
+#
+# CONFIG_PROVE_RCU is not set
+# CONFIG_SPARSE_RCU_POINTER is not set
+# CONFIG_TORTURE_TEST is not set
+# CONFIG_RCU_PERF_TEST is not set
+# CONFIG_RCU_TORTURE_TEST is not set
+# CONFIG_RCU_TRACE is not set
+# CONFIG_RCU_EQS_DEBUG is not set
+# CONFIG_DEBUG_WQ_FORCE_RR_CPU is not set
+# CONFIG_DEBUG_BLOCK_EXT_DEVT is not set
+# CONFIG_NOTIFIER_ERROR_INJECTION is not set
+# CONFIG_FAULT_INJECTION is not set
+# CONFIG_LATENCYTOP is not set
+CONFIG_HAVE_FUNCTION_TRACER=y
+CONFIG_HAVE_FUNCTION_GRAPH_TRACER=y
+CONFIG_HAVE_DYNAMIC_FTRACE=y
+CONFIG_HAVE_FTRACE_MCOUNT_RECORD=y
+CONFIG_HAVE_SYSCALL_TRACEPOINTS=y
+CONFIG_HAVE_C_RECORDMCOUNT=y
+CONFIG_TRACING_SUPPORT=y
+# CONFIG_FTRACE is not set
+
+#
+# Runtime Testing
+#
+# CONFIG_TEST_LIST_SORT is not set
+# CONFIG_BACKTRACE_SELF_TEST is not set
+# CONFIG_RBTREE_TEST is not set
+# CONFIG_INTERVAL_TREE_TEST is not set
+# CONFIG_PERCPU_TEST is not set
+# CONFIG_ATOMIC64_SELFTEST is not set
+# CONFIG_TEST_HEXDUMP is not set
+# CONFIG_TEST_STRING_HELPERS is not set
+# CONFIG_TEST_KSTRTOX is not set
+# CONFIG_TEST_PRINTF is not set
+# CONFIG_TEST_BITMAP is not set
+# CONFIG_TEST_UUID is not set
+# CONFIG_TEST_RHASHTABLE is not set
+# CONFIG_TEST_HASH is not set
+# CONFIG_DMA_API_DEBUG is not set
+# CONFIG_TEST_LKM is not set
+# CONFIG_TEST_USER_COPY is not set
+# CONFIG_TEST_BPF is not set
+# CONFIG_TEST_FIRMWARE is not set
+# CONFIG_TEST_UDELAY is not set
+# CONFIG_MEMTEST is not set
+# CONFIG_TEST_STATIC_KEYS is not set
+# CONFIG_SAMPLES is not set
+CONFIG_HAVE_ARCH_KGDB=y
+# CONFIG_KGDB is not set
+# CONFIG_ARCH_WANTS_UBSAN_NO_NULL is not set
+# CONFIG_UBSAN is not set
+CONFIG_ARCH_HAS_DEVMEM_IS_ALLOWED=y
+CONFIG_STRICT_DEVMEM=y
+# CONFIG_IO_STRICT_DEVMEM is not set
+# CONFIG_ARM_PTDUMP is not set
+# CONFIG_ARM_UNWIND is not set
+# CONFIG_DEBUG_USER is not set
+# CONFIG_DEBUG_LL is not set
+CONFIG_DEBUG_LL_INCLUDE="mach/debug-macro.S"
+# CONFIG_DEBUG_UART_8250 is not set
+CONFIG_UNCOMPRESS_INCLUDE="debug/uncompress.h"
+# CONFIG_PID_IN_CONTEXTIDR is not set
+# CONFIG_DEBUG_SET_MODULE_RONX is not set
+# CONFIG_CORESIGHT is not set
+
+#
+# Security options
+#
+CONFIG_KEYS=y
+# CONFIG_PERSISTENT_KEYRINGS is not set
+# CONFIG_ENCRYPTED_KEYS is not set
+# CONFIG_KEY_DH_OPERATIONS is not set
+# CONFIG_SECURITY_DMESG_RESTRICT is not set
+# CONFIG_SECURITY is not set
+# CONFIG_SECURITYFS is not set
+CONFIG_HAVE_HARDENED_USERCOPY_ALLOCATOR=y
+CONFIG_HAVE_ARCH_HARDENED_USERCOPY=y
+# CONFIG_HARDENED_USERCOPY is not set
+CONFIG_DEFAULT_SECURITY_DAC=y
+CONFIG_DEFAULT_SECURITY=""
+CONFIG_CRYPTO=y
+
+#
+# Crypto core or helper
+#
+CONFIG_CRYPTO_ALGAPI=y
+CONFIG_CRYPTO_ALGAPI2=y
+CONFIG_CRYPTO_AEAD=m
+CONFIG_CRYPTO_AEAD2=y
+CONFIG_CRYPTO_BLKCIPHER=y
+CONFIG_CRYPTO_BLKCIPHER2=y
+CONFIG_CRYPTO_HASH=y
+CONFIG_CRYPTO_HASH2=y
+CONFIG_CRYPTO_RNG=m
+CONFIG_CRYPTO_RNG2=y
+CONFIG_CRYPTO_RNG_DEFAULT=m
+CONFIG_CRYPTO_AKCIPHER2=y
+CONFIG_CRYPTO_KPP2=y
+# CONFIG_CRYPTO_RSA is not set
+# CONFIG_CRYPTO_DH is not set
+# CONFIG_CRYPTO_ECDH is not set
+CONFIG_CRYPTO_MANAGER=m
+CONFIG_CRYPTO_MANAGER2=y
+# CONFIG_CRYPTO_USER is not set
+CONFIG_CRYPTO_MANAGER_DISABLE_TESTS=y
+CONFIG_CRYPTO_GF128MUL=m
+CONFIG_CRYPTO_NULL=m
+CONFIG_CRYPTO_NULL2=y
+CONFIG_CRYPTO_WORKQUEUE=y
+# CONFIG_CRYPTO_CRYPTD is not set
+# CONFIG_CRYPTO_MCRYPTD is not set
+# CONFIG_CRYPTO_AUTHENC is not set
+# CONFIG_CRYPTO_TEST is not set
+
+#
+# Authenticated Encryption with Associated Data
+#
+CONFIG_CRYPTO_CCM=m
+CONFIG_CRYPTO_GCM=m
+# CONFIG_CRYPTO_CHACHA20POLY1305 is not set
+CONFIG_CRYPTO_SEQIV=m
+CONFIG_CRYPTO_ECHAINIV=m
+
+#
+# Block modes
+#
+# CONFIG_CRYPTO_CBC is not set
+CONFIG_CRYPTO_CTR=m
+# CONFIG_CRYPTO_CTS is not set
+# CONFIG_CRYPTO_ECB is not set
+# CONFIG_CRYPTO_LRW is not set
+# CONFIG_CRYPTO_PCBC is not set
+# CONFIG_CRYPTO_XTS is not set
+# CONFIG_CRYPTO_KEYWRAP is not set
+
+#
+# Hash modes
+#
+# CONFIG_CRYPTO_CMAC is not set
+CONFIG_CRYPTO_HMAC=m
+# CONFIG_CRYPTO_XCBC is not set
+# CONFIG_CRYPTO_VMAC is not set
+
+#
+# Digest
+#
+CONFIG_CRYPTO_CRC32C=y
+# CONFIG_CRYPTO_CRC32 is not set
+CONFIG_CRYPTO_CRCT10DIF=y
+CONFIG_CRYPTO_GHASH=m
+# CONFIG_CRYPTO_POLY1305 is not set
+# CONFIG_CRYPTO_MD4 is not set
+CONFIG_CRYPTO_MD5=y
+# CONFIG_CRYPTO_MICHAEL_MIC is not set
+# CONFIG_CRYPTO_RMD128 is not set
+# CONFIG_CRYPTO_RMD160 is not set
+# CONFIG_CRYPTO_RMD256 is not set
+# CONFIG_CRYPTO_RMD320 is not set
+CONFIG_CRYPTO_SHA1=y
+CONFIG_CRYPTO_SHA256=y
+# CONFIG_CRYPTO_SHA512 is not set
+# CONFIG_CRYPTO_SHA3 is not set
+# CONFIG_CRYPTO_TGR192 is not set
+# CONFIG_CRYPTO_WP512 is not set
+
+#
+# Ciphers
+#
+CONFIG_CRYPTO_AES=y
+# CONFIG_CRYPTO_ANUBIS is not set
+CONFIG_CRYPTO_ARC4=y
+# CONFIG_CRYPTO_BLOWFISH is not set
+# CONFIG_CRYPTO_CAMELLIA is not set
+# CONFIG_CRYPTO_CAST5 is not set
+# CONFIG_CRYPTO_CAST6 is not set
+# CONFIG_CRYPTO_DES is not set
+# CONFIG_CRYPTO_FCRYPT is not set
+# CONFIG_CRYPTO_KHAZAD is not set
+# CONFIG_CRYPTO_SALSA20 is not set
+# CONFIG_CRYPTO_CHACHA20 is not set
+# CONFIG_CRYPTO_SEED is not set
+# CONFIG_CRYPTO_SERPENT is not set
+# CONFIG_CRYPTO_TEA is not set
+# CONFIG_CRYPTO_TWOFISH is not set
+
+#
+# Compression
+#
+CONFIG_CRYPTO_DEFLATE=y
+CONFIG_CRYPTO_LZO=y
+# CONFIG_CRYPTO_842 is not set
+# CONFIG_CRYPTO_LZ4 is not set
+# CONFIG_CRYPTO_LZ4HC is not set
+
+#
+# Random Number Generation
+#
+# CONFIG_CRYPTO_ANSI_CPRNG is not set
+CONFIG_CRYPTO_DRBG_MENU=m
+CONFIG_CRYPTO_DRBG_HMAC=y
+# CONFIG_CRYPTO_DRBG_HASH is not set
+# CONFIG_CRYPTO_DRBG_CTR is not set
+CONFIG_CRYPTO_DRBG=m
+CONFIG_CRYPTO_JITTERENTROPY=m
+# CONFIG_CRYPTO_USER_API_HASH is not set
+# CONFIG_CRYPTO_USER_API_SKCIPHER is not set
+# CONFIG_CRYPTO_USER_API_RNG is not set
+# CONFIG_CRYPTO_USER_API_AEAD is not set
+# CONFIG_CRYPTO_HW is not set
+# CONFIG_ASYMMETRIC_KEY_TYPE is not set
+
+#
+# Certificates for signature checking
+#
+# CONFIG_ARM_CRYPTO is not set
+# CONFIG_BINARY_PRINTF is not set
+
+#
+# Library routines
+#
+CONFIG_BITREVERSE=y
+CONFIG_HAVE_ARCH_BITREVERSE=y
+CONFIG_RATIONAL=y
+CONFIG_GENERIC_STRNCPY_FROM_USER=y
+CONFIG_GENERIC_STRNLEN_USER=y
+CONFIG_GENERIC_NET_UTILS=y
+CONFIG_GENERIC_PCI_IOMAP=y
+CONFIG_GENERIC_IO=y
+CONFIG_ARCH_USE_CMPXCHG_LOCKREF=y
+CONFIG_CRC_CCITT=y
+CONFIG_CRC16=y
+CONFIG_CRC_T10DIF=y
+CONFIG_CRC_ITU_T=y
+CONFIG_CRC32=y
+# CONFIG_CRC32_SELFTEST is not set
+CONFIG_CRC32_SLICEBY8=y
+# CONFIG_CRC32_SLICEBY4 is not set
+# CONFIG_CRC32_SARWATE is not set
+# CONFIG_CRC32_BIT is not set
+# CONFIG_CRC7 is not set
+CONFIG_LIBCRC32C=y
+# CONFIG_CRC8 is not set
+# CONFIG_AUDIT_ARCH_COMPAT_GENERIC is not set
+# CONFIG_RANDOM32_SELFTEST is not set
+CONFIG_ZLIB_INFLATE=y
+CONFIG_ZLIB_DEFLATE=y
+CONFIG_LZO_COMPRESS=y
+CONFIG_LZO_DECOMPRESS=y
+CONFIG_LZ4_DECOMPRESS=y
+CONFIG_XZ_DEC=y
+CONFIG_XZ_DEC_X86=y
+CONFIG_XZ_DEC_POWERPC=y
+CONFIG_XZ_DEC_IA64=y
+CONFIG_XZ_DEC_ARM=y
+CONFIG_XZ_DEC_ARMTHUMB=y
+CONFIG_XZ_DEC_SPARC=y
+CONFIG_XZ_DEC_BCJ=y
+# CONFIG_XZ_DEC_TEST is not set
+CONFIG_DECOMPRESS_GZIP=y
+CONFIG_DECOMPRESS_LZ4=y
+CONFIG_GENERIC_ALLOCATOR=y
+CONFIG_ASSOCIATIVE_ARRAY=y
+CONFIG_HAS_IOMEM=y
+CONFIG_HAS_IOPORT_MAP=y
+CONFIG_HAS_DMA=y
+CONFIG_DQL=y
+CONFIG_NLATTR=y
+# CONFIG_CORDIC is not set
+# CONFIG_DDR is not set
+# CONFIG_IRQ_POLL is not set
+CONFIG_LIBFDT=y
+CONFIG_OID_REGISTRY=y
+# CONFIG_SG_SPLIT is not set
+# CONFIG_SG_POOL is not set
+CONFIG_ARCH_HAS_SG_CHAIN=y
+CONFIG_SBITMAP=y
+# CONFIG_VIRTUALIZATION is not set
diff --git a/arch/arm/configs/hi3536dv100_full_defconfig b/arch/arm/configs/hi3536dv100_full_defconfig
new file mode 100644
index 0000000..2bbed4f5
--- /dev/null
+++ b/arch/arm/configs/hi3536dv100_full_defconfig
@@ -0,0 +1,2718 @@
+#
+# Automatically generated file; DO NOT EDIT.
+# Linux/arm 4.9.37 Kernel Configuration
+#
+CONFIG_ARM=y
+CONFIG_ARM_HAS_SG_CHAIN=y
+CONFIG_MIGHT_HAVE_PCI=y
+CONFIG_SYS_SUPPORTS_APM_EMULATION=y
+CONFIG_HAVE_PROC_CPU=y
+CONFIG_STACKTRACE_SUPPORT=y
+CONFIG_LOCKDEP_SUPPORT=y
+CONFIG_TRACE_IRQFLAGS_SUPPORT=y
+CONFIG_RWSEM_XCHGADD_ALGORITHM=y
+CONFIG_FIX_EARLYCON_MEM=y
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_NEED_DMA_MAP_STATE=y
+CONFIG_ARCH_SUPPORTS_UPROBES=y
+CONFIG_VECTORS_BASE=0xffff0000
+CONFIG_ARM_PATCH_PHYS_VIRT=y
+CONFIG_GENERIC_BUG=y
+CONFIG_PGTABLE_LEVELS=2
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+CONFIG_IRQ_WORK=y
+CONFIG_BUILDTIME_EXTABLE_SORT=y
+
+#
+# General setup
+#
+CONFIG_BROKEN_ON_SMP=y
+CONFIG_INIT_ENV_ARG_LIMIT=32
+CONFIG_CROSS_COMPILE=""
+# CONFIG_COMPILE_TEST is not set
+CONFIG_LOCALVERSION=""
+# CONFIG_LOCALVERSION_AUTO is not set
+CONFIG_HAVE_KERNEL_GZIP=y
+CONFIG_HAVE_KERNEL_LZMA=y
+CONFIG_HAVE_KERNEL_XZ=y
+CONFIG_HAVE_KERNEL_LZO=y
+CONFIG_HAVE_KERNEL_LZ4=y
+CONFIG_KERNEL_GZIP=y
+# CONFIG_KERNEL_LZMA is not set
+# CONFIG_KERNEL_XZ is not set
+# CONFIG_KERNEL_LZO is not set
+# CONFIG_KERNEL_LZ4 is not set
+CONFIG_DEFAULT_HOSTNAME="(none)"
+CONFIG_SWAP=y
+CONFIG_SYSVIPC=y
+CONFIG_SYSVIPC_SYSCTL=y
+# CONFIG_POSIX_MQUEUE is not set
+CONFIG_CROSS_MEMORY_ATTACH=y
+CONFIG_FHANDLE=y
+CONFIG_USELIB=y
+# CONFIG_AUDIT is not set
+CONFIG_HAVE_ARCH_AUDITSYSCALL=y
+
+#
+# IRQ subsystem
+#
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_GENERIC_IRQ_SHOW=y
+CONFIG_GENERIC_IRQ_SHOW_LEVEL=y
+CONFIG_HARDIRQS_SW_RESEND=y
+CONFIG_IRQ_DOMAIN=y
+CONFIG_IRQ_DOMAIN_HIERARCHY=y
+CONFIG_HANDLE_DOMAIN_IRQ=y
+CONFIG_IRQ_FORCED_THREADING=y
+CONFIG_SPARSE_IRQ=y
+CONFIG_ARCH_CLOCKSOURCE_DATA=y
+CONFIG_GENERIC_TIME_VSYSCALL=y
+CONFIG_GENERIC_CLOCKEVENTS=y
+
+#
+# Timers subsystem
+#
+CONFIG_HZ_PERIODIC=y
+# CONFIG_NO_HZ_IDLE is not set
+# CONFIG_NO_HZ is not set
+# CONFIG_HIGH_RES_TIMERS is not set
+
+#
+# CPU/Task time and stats accounting
+#
+CONFIG_TICK_CPU_ACCOUNTING=y
+# CONFIG_VIRT_CPU_ACCOUNTING_GEN is not set
+CONFIG_IRQ_TIME_ACCOUNTING=y
+# CONFIG_BSD_PROCESS_ACCT is not set
+# CONFIG_TASKSTATS is not set
+
+#
+# RCU Subsystem
+#
+CONFIG_TINY_RCU=y
+# CONFIG_RCU_EXPERT is not set
+CONFIG_SRCU=y
+# CONFIG_TASKS_RCU is not set
+# CONFIG_RCU_STALL_COMMON is not set
+# CONFIG_TREE_RCU_TRACE is not set
+# CONFIG_RCU_EXPEDITE_BOOT is not set
+# CONFIG_BUILD_BIN2C is not set
+# CONFIG_IKCONFIG is not set
+CONFIG_LOG_BUF_SHIFT=17
+CONFIG_NMI_LOG_BUF_SHIFT=13
+CONFIG_GENERIC_SCHED_CLOCK=y
+CONFIG_CGROUPS=y
+# CONFIG_MEMCG is not set
+# CONFIG_BLK_CGROUP is not set
+# CONFIG_CGROUP_SCHED is not set
+# CONFIG_CGROUP_PIDS is not set
+CONFIG_CGROUP_FREEZER=y
+# CONFIG_CPUSETS is not set
+# CONFIG_CGROUP_DEVICE is not set
+# CONFIG_CGROUP_CPUACCT is not set
+# CONFIG_CGROUP_DEBUG is not set
+# CONFIG_CHECKPOINT_RESTORE is not set
+CONFIG_NAMESPACES=y
+CONFIG_UTS_NS=y
+CONFIG_IPC_NS=y
+# CONFIG_USER_NS is not set
+CONFIG_PID_NS=y
+CONFIG_NET_NS=y
+# CONFIG_SCHED_AUTOGROUP is not set
+# CONFIG_SYSFS_DEPRECATED is not set
+# CONFIG_RELAY is not set
+CONFIG_BLK_DEV_INITRD=y
+CONFIG_INITRAMFS_SOURCE=""
+CONFIG_RD_GZIP=y
+# CONFIG_RD_BZIP2 is not set
+# CONFIG_RD_LZMA is not set
+# CONFIG_RD_XZ is not set
+# CONFIG_RD_LZO is not set
+CONFIG_RD_LZ4=y
+CONFIG_CC_OPTIMIZE_FOR_PERFORMANCE=y
+# CONFIG_CC_OPTIMIZE_FOR_SIZE is not set
+CONFIG_SYSCTL=y
+CONFIG_ANON_INODES=y
+CONFIG_HAVE_UID16=y
+CONFIG_BPF=y
+# CONFIG_EXPERT is not set
+CONFIG_UID16=y
+CONFIG_MULTIUSER=y
+# CONFIG_SGETMASK_SYSCALL is not set
+CONFIG_SYSFS_SYSCALL=y
+# CONFIG_SYSCTL_SYSCALL is not set
+CONFIG_KALLSYMS=y
+# CONFIG_KALLSYMS_ALL is not set
+# CONFIG_KALLSYMS_ABSOLUTE_PERCPU is not set
+CONFIG_KALLSYMS_BASE_RELATIVE=y
+CONFIG_PRINTK=y
+CONFIG_PRINTK_NMI=y
+CONFIG_BUG=y
+CONFIG_ELF_CORE=y
+CONFIG_BASE_FULL=y
+CONFIG_FUTEX=y
+CONFIG_EPOLL=y
+CONFIG_SIGNALFD=y
+CONFIG_TIMERFD=y
+CONFIG_EVENTFD=y
+# CONFIG_BPF_SYSCALL is not set
+CONFIG_SHMEM=y
+CONFIG_AIO=y
+CONFIG_ADVISE_SYSCALLS=y
+# CONFIG_USERFAULTFD is not set
+CONFIG_MEMBARRIER=y
+# CONFIG_EMBEDDED is not set
+CONFIG_HAVE_PERF_EVENTS=y
+CONFIG_PERF_USE_VMALLOC=y
+
+#
+# Kernel Performance Events And Counters
+#
+# CONFIG_PERF_EVENTS is not set
+CONFIG_VM_EVENT_COUNTERS=y
+CONFIG_SLUB_DEBUG=y
+CONFIG_COMPAT_BRK=y
+# CONFIG_SLAB is not set
+CONFIG_SLUB=y
+# CONFIG_SLAB_FREELIST_RANDOM is not set
+# CONFIG_SYSTEM_DATA_VERIFICATION is not set
+# CONFIG_PROFILING is not set
+CONFIG_HAVE_OPROFILE=y
+# CONFIG_KPROBES is not set
+# CONFIG_JUMP_LABEL is not set
+# CONFIG_UPROBES is not set
+# CONFIG_HAVE_64BIT_ALIGNED_ACCESS is not set
+CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS=y
+CONFIG_ARCH_USE_BUILTIN_BSWAP=y
+CONFIG_HAVE_KPROBES=y
+CONFIG_HAVE_KRETPROBES=y
+CONFIG_HAVE_OPTPROBES=y
+CONFIG_HAVE_NMI=y
+CONFIG_HAVE_ARCH_TRACEHOOK=y
+CONFIG_HAVE_DMA_CONTIGUOUS=y
+CONFIG_GENERIC_SMP_IDLE_THREAD=y
+CONFIG_GENERIC_IDLE_POLL_SETUP=y
+CONFIG_HAVE_REGS_AND_STACK_ACCESS_API=y
+CONFIG_HAVE_CLK=y
+CONFIG_HAVE_DMA_API_DEBUG=y
+CONFIG_HAVE_PERF_REGS=y
+CONFIG_HAVE_PERF_USER_STACK_DUMP=y
+CONFIG_HAVE_ARCH_JUMP_LABEL=y
+CONFIG_ARCH_WANT_IPC_PARSE_VERSION=y
+CONFIG_HAVE_ARCH_SECCOMP_FILTER=y
+CONFIG_HAVE_GCC_PLUGINS=y
+# CONFIG_GCC_PLUGINS is not set
+CONFIG_HAVE_CC_STACKPROTECTOR=y
+# CONFIG_CC_STACKPROTECTOR is not set
+CONFIG_CC_STACKPROTECTOR_NONE=y
+# CONFIG_CC_STACKPROTECTOR_REGULAR is not set
+# CONFIG_CC_STACKPROTECTOR_STRONG is not set
+CONFIG_HAVE_CONTEXT_TRACKING=y
+CONFIG_HAVE_VIRT_CPU_ACCOUNTING_GEN=y
+CONFIG_HAVE_IRQ_TIME_ACCOUNTING=y
+CONFIG_HAVE_MOD_ARCH_SPECIFIC=y
+CONFIG_MODULES_USE_ELF_REL=y
+CONFIG_ARCH_HAS_ELF_RANDOMIZE=y
+CONFIG_HAVE_ARCH_MMAP_RND_BITS=y
+CONFIG_HAVE_EXIT_THREAD=y
+CONFIG_ARCH_MMAP_RND_BITS_MIN=8
+CONFIG_ARCH_MMAP_RND_BITS_MAX=16
+CONFIG_ARCH_MMAP_RND_BITS=8
+# CONFIG_HAVE_ARCH_HASH is not set
+# CONFIG_ISA_BUS_API is not set
+CONFIG_CLONE_BACKWARDS=y
+CONFIG_OLD_SIGSUSPEND3=y
+CONFIG_OLD_SIGACTION=y
+# CONFIG_CPU_NO_EFFICIENT_FFS is not set
+# CONFIG_HAVE_ARCH_VMAP_STACK is not set
+
+#
+# GCOV-based kernel profiling
+#
+CONFIG_ARCH_HAS_GCOV_PROFILE_ALL=y
+CONFIG_HAVE_GENERIC_DMA_COHERENT=y
+CONFIG_SLABINFO=y
+CONFIG_RT_MUTEXES=y
+CONFIG_BASE_SMALL=0
+CONFIG_MODULES=y
+# CONFIG_MODULE_FORCE_LOAD is not set
+CONFIG_MODULE_UNLOAD=y
+# CONFIG_MODULE_FORCE_UNLOAD is not set
+# CONFIG_MODVERSIONS is not set
+# CONFIG_MODULE_SRCVERSION_ALL is not set
+# CONFIG_MODULE_SIG is not set
+# CONFIG_MODULE_COMPRESS is not set
+# CONFIG_TRIM_UNUSED_KSYMS is not set
+CONFIG_BLOCK=y
+CONFIG_LBDAF=y
+CONFIG_BLK_DEV_BSG=y
+# CONFIG_BLK_DEV_BSGLIB is not set
+# CONFIG_BLK_DEV_INTEGRITY is not set
+CONFIG_BLK_CMDLINE_PARSER=y
+
+#
+# Partition Types
+#
+CONFIG_PARTITION_ADVANCED=y
+# CONFIG_ACORN_PARTITION is not set
+# CONFIG_AIX_PARTITION is not set
+# CONFIG_OSF_PARTITION is not set
+# CONFIG_AMIGA_PARTITION is not set
+# CONFIG_ATARI_PARTITION is not set
+# CONFIG_MAC_PARTITION is not set
+CONFIG_MSDOS_PARTITION=y
+# CONFIG_BSD_DISKLABEL is not set
+# CONFIG_MINIX_SUBPARTITION is not set
+# CONFIG_SOLARIS_X86_PARTITION is not set
+# CONFIG_UNIXWARE_DISKLABEL is not set
+# CONFIG_LDM_PARTITION is not set
+# CONFIG_SGI_PARTITION is not set
+# CONFIG_ULTRIX_PARTITION is not set
+# CONFIG_SUN_PARTITION is not set
+# CONFIG_KARMA_PARTITION is not set
+CONFIG_EFI_PARTITION=y
+# CONFIG_SYSV68_PARTITION is not set
+CONFIG_CMDLINE_PARTITION=y
+
+#
+# IO Schedulers
+#
+CONFIG_IOSCHED_NOOP=y
+CONFIG_IOSCHED_DEADLINE=y
+CONFIG_IOSCHED_CFQ=y
+CONFIG_DEFAULT_DEADLINE=y
+# CONFIG_DEFAULT_CFQ is not set
+# CONFIG_DEFAULT_NOOP is not set
+CONFIG_DEFAULT_IOSCHED="deadline"
+CONFIG_INLINE_SPIN_UNLOCK_IRQ=y
+CONFIG_INLINE_READ_UNLOCK=y
+CONFIG_INLINE_READ_UNLOCK_IRQ=y
+CONFIG_INLINE_WRITE_UNLOCK=y
+CONFIG_INLINE_WRITE_UNLOCK_IRQ=y
+CONFIG_ARCH_SUPPORTS_ATOMIC_RMW=y
+CONFIG_FREEZER=y
+
+#
+# System Type
+#
+CONFIG_MMU=y
+CONFIG_ARCH_MULTIPLATFORM=y
+# CONFIG_ARCH_GEMINI is not set
+# CONFIG_ARCH_EBSA110 is not set
+# CONFIG_ARCH_EP93XX is not set
+# CONFIG_ARCH_FOOTBRIDGE is not set
+# CONFIG_ARCH_NETX is not set
+# CONFIG_ARCH_IOP13XX is not set
+# CONFIG_ARCH_IOP32X is not set
+# CONFIG_ARCH_IOP33X is not set
+# CONFIG_ARCH_IXP4XX is not set
+# CONFIG_ARCH_DOVE is not set
+# CONFIG_ARCH_KS8695 is not set
+# CONFIG_ARCH_W90X900 is not set
+# CONFIG_ARCH_LPC32XX is not set
+# CONFIG_ARCH_PXA is not set
+# CONFIG_ARCH_RPC is not set
+# CONFIG_ARCH_SA1100 is not set
+# CONFIG_ARCH_S3C24XX is not set
+# CONFIG_ARCH_DAVINCI is not set
+# CONFIG_ARCH_OMAP1 is not set
+
+#
+# Multiple platform selection
+#
+
+#
+# CPU Core family selection
+#
+# CONFIG_ARCH_MULTI_V6 is not set
+CONFIG_ARCH_MULTI_V7=y
+CONFIG_ARCH_MULTI_V6_V7=y
+# CONFIG_ARCH_MULTI_CPU_AUTO is not set
+# CONFIG_ARCH_VIRT is not set
+# CONFIG_ARCH_MVEBU is not set
+# CONFIG_ARCH_ALPINE is not set
+# CONFIG_ARCH_ARTPEC is not set
+# CONFIG_ARCH_AT91 is not set
+# CONFIG_ARCH_BCM is not set
+# CONFIG_ARCH_BERLIN is not set
+# CONFIG_ARCH_DIGICOLOR is not set
+# CONFIG_ARCH_HIGHBANK is not set
+# CONFIG_ARCH_HISI is not set
+CONFIG_ARCH_HISI_BVT=y
+
+#
+# Hisilicon BVT platform type
+#
+CONFIG_HI_ZRELADDR=0x80008000
+CONFIG_HI_PARAMS_PHYS=0x00000100
+CONFIG_HI_INITRD_PHYS=0x00800000
+# CONFIG_ARCH_HI3516A is not set
+CONFIG_ARCH_HI3536DV100=y
+# CONFIG_ARCH_KEYSTONE is not set
+# CONFIG_ARCH_MESON is not set
+# CONFIG_ARCH_MXC is not set
+# CONFIG_ARCH_MEDIATEK is not set
+
+#
+# TI OMAP/AM/DM/DRA Family
+#
+# CONFIG_ARCH_OMAP3 is not set
+# CONFIG_ARCH_OMAP4 is not set
+# CONFIG_SOC_OMAP5 is not set
+# CONFIG_SOC_AM33XX is not set
+# CONFIG_SOC_AM43XX is not set
+# CONFIG_SOC_DRA7XX is not set
+# CONFIG_ARCH_MMP is not set
+# CONFIG_ARCH_QCOM is not set
+# CONFIG_ARCH_REALVIEW is not set
+# CONFIG_ARCH_ROCKCHIP is not set
+# CONFIG_ARCH_SOCFPGA is not set
+# CONFIG_PLAT_SPEAR is not set
+# CONFIG_ARCH_STI is not set
+# CONFIG_ARCH_S5PV210 is not set
+# CONFIG_ARCH_EXYNOS is not set
+# CONFIG_ARCH_RENESAS is not set
+# CONFIG_ARCH_SUNXI is not set
+# CONFIG_ARCH_SIRF is not set
+# CONFIG_ARCH_TANGO is not set
+# CONFIG_ARCH_TEGRA is not set
+# CONFIG_ARCH_UNIPHIER is not set
+# CONFIG_ARCH_U8500 is not set
+# CONFIG_ARCH_VEXPRESS is not set
+# CONFIG_ARCH_WM8850 is not set
+# CONFIG_ARCH_ZX is not set
+# CONFIG_ARCH_ZYNQ is not set
+
+#
+# Processor Type
+#
+CONFIG_CPU_V7=y
+CONFIG_CPU_32v6K=y
+CONFIG_CPU_32v7=y
+CONFIG_CPU_ABRT_EV7=y
+CONFIG_CPU_PABRT_V7=y
+CONFIG_CPU_CACHE_V7=y
+CONFIG_CPU_CACHE_VIPT=y
+CONFIG_CPU_COPY_V6=y
+CONFIG_CPU_TLB_V7=y
+CONFIG_CPU_HAS_ASID=y
+CONFIG_CPU_CP15=y
+CONFIG_CPU_CP15_MMU=y
+
+#
+# Processor Features
+#
+# CONFIG_ARM_LPAE is not set
+# CONFIG_ARCH_PHYS_ADDR_T_64BIT is not set
+CONFIG_ARM_THUMB=y
+# CONFIG_ARM_THUMBEE is not set
+CONFIG_ARM_VIRT_EXT=y
+# CONFIG_SWP_EMULATE is not set
+# CONFIG_CPU_ICACHE_DISABLE is not set
+# CONFIG_CPU_DCACHE_DISABLE is not set
+# CONFIG_CPU_BPREDICT_DISABLE is not set
+CONFIG_KUSER_HELPERS=y
+CONFIG_VDSO=y
+CONFIG_MIGHT_HAVE_CACHE_L2X0=y
+# CONFIG_CACHE_L2X0 is not set
+CONFIG_ARM_L1_CACHE_SHIFT_6=y
+CONFIG_ARM_L1_CACHE_SHIFT=6
+CONFIG_ARM_DMA_MEM_BUFFERABLE=y
+# CONFIG_DEBUG_RODATA is not set
+CONFIG_MULTI_IRQ_HANDLER=y
+# CONFIG_ARM_ERRATA_430973 is not set
+# CONFIG_ARM_ERRATA_720789 is not set
+# CONFIG_ARM_ERRATA_754322 is not set
+# CONFIG_ARM_ERRATA_775420 is not set
+# CONFIG_ARM_ERRATA_773022 is not set
+# CONFIG_ARM_ERRATA_818325_852422 is not set
+# CONFIG_ARM_ERRATA_821420 is not set
+# CONFIG_ARM_ERRATA_825619 is not set
+# CONFIG_ARM_ERRATA_852421 is not set
+# CONFIG_ARM_ERRATA_852423 is not set
+
+#
+# Bus support
+#
+# CONFIG_PCI is not set
+# CONFIG_PCI_DOMAINS_GENERIC is not set
+# CONFIG_PCI_SYSCALL is not set
+# CONFIG_PCCARD is not set
+
+#
+# Kernel Features
+#
+CONFIG_HAVE_SMP=y
+# CONFIG_SMP is not set
+CONFIG_HAVE_ARM_ARCH_TIMER=y
+CONFIG_VMSPLIT_3G=y
+# CONFIG_VMSPLIT_3G_OPT is not set
+# CONFIG_VMSPLIT_2G is not set
+# CONFIG_VMSPLIT_1G is not set
+CONFIG_PAGE_OFFSET=0xC0000000
+# CONFIG_ARM_PSCI is not set
+CONFIG_ARCH_NR_GPIO=0
+CONFIG_PREEMPT_NONE=y
+# CONFIG_PREEMPT_VOLUNTARY is not set
+# CONFIG_PREEMPT is not set
+CONFIG_HZ_FIXED=0
+CONFIG_HZ_100=y
+# CONFIG_HZ_200 is not set
+# CONFIG_HZ_250 is not set
+# CONFIG_HZ_300 is not set
+# CONFIG_HZ_500 is not set
+# CONFIG_HZ_1000 is not set
+CONFIG_HZ=100
+# CONFIG_SCHED_HRTICK is not set
+# CONFIG_THUMB2_KERNEL is not set
+CONFIG_ARM_PATCH_IDIV=y
+CONFIG_AEABI=y
+# CONFIG_OABI_COMPAT is not set
+# CONFIG_ARCH_SPARSEMEM_DEFAULT is not set
+# CONFIG_ARCH_SELECT_MEMORY_MODEL is not set
+CONFIG_HAVE_ARCH_PFN_VALID=y
+# CONFIG_HIGHMEM is not set
+# CONFIG_CPU_SW_DOMAIN_PAN is not set
+CONFIG_ARCH_WANT_GENERAL_HUGETLB=y
+# CONFIG_ARM_MODULE_PLTS is not set
+CONFIG_FLATMEM=y
+CONFIG_FLAT_NODE_MEM_MAP=y
+CONFIG_HAVE_MEMBLOCK=y
+CONFIG_NO_BOOTMEM=y
+# CONFIG_HAVE_BOOTMEM_INFO_NODE is not set
+CONFIG_SPLIT_PTLOCK_CPUS=4
+CONFIG_COMPACTION=y
+CONFIG_MIGRATION=y
+# CONFIG_PHYS_ADDR_T_64BIT is not set
+# CONFIG_KSM is not set
+CONFIG_DEFAULT_MMAP_MIN_ADDR=4096
+CONFIG_NEED_PER_CPU_KM=y
+# CONFIG_CLEANCACHE is not set
+# CONFIG_FRONTSWAP is not set
+# CONFIG_CMA is not set
+# CONFIG_ZPOOL is not set
+# CONFIG_ZBUD is not set
+# CONFIG_ZSMALLOC is not set
+CONFIG_GENERIC_EARLY_IOREMAP=y
+# CONFIG_IDLE_PAGE_TRACKING is not set
+CONFIG_FORCE_MAX_ZONEORDER=11
+CONFIG_ALIGNMENT_TRAP=y
+# CONFIG_UACCESS_WITH_MEMCPY is not set
+# CONFIG_SECCOMP is not set
+CONFIG_SWIOTLB=y
+CONFIG_IOMMU_HELPER=y
+# CONFIG_PARAVIRT is not set
+# CONFIG_PARAVIRT_TIME_ACCOUNTING is not set
+# CONFIG_XEN is not set
+
+#
+# Boot options
+#
+CONFIG_USE_OF=y
+CONFIG_ATAGS=y
+# CONFIG_DEPRECATED_PARAM_STRUCT is not set
+CONFIG_ZBOOT_ROM_TEXT=0
+CONFIG_ZBOOT_ROM_BSS=0
+CONFIG_ARM_APPENDED_DTB=y
+CONFIG_ARM_ATAG_DTB_COMPAT=y
+CONFIG_ARM_ATAG_DTB_COMPAT_CMDLINE_FROM_BOOTLOADER=y
+# CONFIG_ARM_ATAG_DTB_COMPAT_CMDLINE_EXTEND is not set
+CONFIG_CMDLINE=""
+# CONFIG_KEXEC is not set
+# CONFIG_CRASH_DUMP is not set
+CONFIG_AUTO_ZRELADDR=y
+# CONFIG_EFI is not set
+
+#
+# CPU Power Management
+#
+
+#
+# CPU Frequency scaling
+#
+# CONFIG_CPU_FREQ is not set
+
+#
+# CPU Idle
+#
+# CONFIG_CPU_IDLE is not set
+# CONFIG_ARCH_NEEDS_CPU_IDLE_COUPLED is not set
+
+#
+# Floating point emulation
+#
+
+#
+# At least one emulation must be selected
+#
+CONFIG_VFP=y
+CONFIG_VFPv3=y
+CONFIG_NEON=y
+# CONFIG_KERNEL_MODE_NEON is not set
+
+#
+# Userspace binary formats
+#
+CONFIG_BINFMT_ELF=y
+CONFIG_ELFCORE=y
+CONFIG_CORE_DUMP_DEFAULT_ELF_HEADERS=y
+CONFIG_BINFMT_SCRIPT=y
+# CONFIG_BINFMT_FLAT is not set
+# CONFIG_HAVE_AOUT is not set
+# CONFIG_BINFMT_MISC is not set
+CONFIG_COREDUMP=y
+
+#
+# Power management options
+#
+CONFIG_SUSPEND=y
+CONFIG_SUSPEND_FREEZER=y
+CONFIG_HIBERNATE_CALLBACKS=y
+CONFIG_HIBERNATION=y
+CONFIG_PM_STD_PARTITION=""
+CONFIG_PM_SLEEP=y
+# CONFIG_PM_AUTOSLEEP is not set
+# CONFIG_PM_WAKELOCKS is not set
+CONFIG_PM=y
+CONFIG_PM_DEBUG=y
+# CONFIG_PM_ADVANCED_DEBUG is not set
+# CONFIG_PM_TEST_SUSPEND is not set
+CONFIG_PM_SLEEP_DEBUG=y
+# CONFIG_APM_EMULATION is not set
+CONFIG_PM_CLK=y
+# CONFIG_WQ_POWER_EFFICIENT_DEFAULT is not set
+CONFIG_CPU_PM=y
+CONFIG_ARCH_SUSPEND_POSSIBLE=y
+CONFIG_ARM_CPU_SUSPEND=y
+CONFIG_ARCH_HIBERNATION_POSSIBLE=y
+CONFIG_NET=y
+
+#
+# Networking options
+#
+CONFIG_PACKET=y
+# CONFIG_PACKET_DIAG is not set
+CONFIG_UNIX=y
+# CONFIG_UNIX_DIAG is not set
+CONFIG_XFRM=y
+CONFIG_XFRM_ALGO=y
+CONFIG_XFRM_USER=y
+# CONFIG_XFRM_SUB_POLICY is not set
+# CONFIG_XFRM_MIGRATE is not set
+# CONFIG_XFRM_STATISTICS is not set
+CONFIG_NET_KEY=y
+# CONFIG_NET_KEY_MIGRATE is not set
+CONFIG_INET=y
+CONFIG_IP_MULTICAST=y
+CONFIG_IP_ADVANCED_ROUTER=y
+# CONFIG_IP_FIB_TRIE_STATS is not set
+CONFIG_IP_MULTIPLE_TABLES=y
+CONFIG_IP_ROUTE_MULTIPATH=y
+CONFIG_IP_ROUTE_VERBOSE=y
+CONFIG_IP_PNP=y
+# CONFIG_IP_PNP_DHCP is not set
+# CONFIG_IP_PNP_BOOTP is not set
+# CONFIG_IP_PNP_RARP is not set
+# CONFIG_NET_IPIP is not set
+# CONFIG_NET_IPGRE_DEMUX is not set
+# CONFIG_NET_IP_TUNNEL is not set
+CONFIG_IP_MROUTE=y
+# CONFIG_IP_MROUTE_MULTIPLE_TABLES is not set
+CONFIG_IP_PIMSM_V1=y
+CONFIG_IP_PIMSM_V2=y
+CONFIG_SYN_COOKIES=y
+# CONFIG_NET_UDP_TUNNEL is not set
+# CONFIG_NET_FOU is not set
+# CONFIG_INET_AH is not set
+# CONFIG_INET_ESP is not set
+# CONFIG_INET_IPCOMP is not set
+# CONFIG_INET_XFRM_TUNNEL is not set
+# CONFIG_INET_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_TRANSPORT is not set
+# CONFIG_INET_XFRM_MODE_TUNNEL is not set
+# CONFIG_INET_XFRM_MODE_BEET is not set
+CONFIG_INET_DIAG=y
+CONFIG_INET_TCP_DIAG=y
+# CONFIG_INET_UDP_DIAG is not set
+# CONFIG_INET_DIAG_DESTROY is not set
+CONFIG_TCP_CONG_ADVANCED=y
+CONFIG_TCP_CONG_BIC=m
+CONFIG_TCP_CONG_CUBIC=y
+CONFIG_TCP_CONG_WESTWOOD=m
+CONFIG_TCP_CONG_HTCP=m
+# CONFIG_TCP_CONG_HSTCP is not set
+# CONFIG_TCP_CONG_HYBLA is not set
+# CONFIG_TCP_CONG_VEGAS is not set
+# CONFIG_TCP_CONG_NV is not set
+# CONFIG_TCP_CONG_SCALABLE is not set
+# CONFIG_TCP_CONG_LP is not set
+# CONFIG_TCP_CONG_VENO is not set
+# CONFIG_TCP_CONG_YEAH is not set
+# CONFIG_TCP_CONG_ILLINOIS is not set
+# CONFIG_TCP_CONG_DCTCP is not set
+# CONFIG_TCP_CONG_CDG is not set
+# CONFIG_TCP_CONG_BBR is not set
+CONFIG_DEFAULT_CUBIC=y
+# CONFIG_DEFAULT_RENO is not set
+CONFIG_DEFAULT_TCP_CONG="cubic"
+CONFIG_TCP_MD5SIG=y
+# CONFIG_IPV6 is not set
+# CONFIG_NETWORK_SECMARK is not set
+# CONFIG_NET_PTP_CLASSIFY is not set
+# CONFIG_NETWORK_PHY_TIMESTAMPING is not set
+# CONFIG_NETFILTER is not set
+# CONFIG_IP_DCCP is not set
+# CONFIG_IP_SCTP is not set
+# CONFIG_RDS is not set
+# CONFIG_TIPC is not set
+# CONFIG_ATM is not set
+# CONFIG_L2TP is not set
+# CONFIG_BRIDGE is not set
+CONFIG_HAVE_NET_DSA=y
+# CONFIG_VLAN_8021Q is not set
+# CONFIG_DECNET is not set
+# CONFIG_LLC2 is not set
+# CONFIG_IPX is not set
+# CONFIG_ATALK is not set
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_PHONET is not set
+# CONFIG_IEEE802154 is not set
+# CONFIG_NET_SCHED is not set
+# CONFIG_DCB is not set
+CONFIG_DNS_RESOLVER=y
+# CONFIG_BATMAN_ADV is not set
+# CONFIG_OPENVSWITCH is not set
+# CONFIG_VSOCKETS is not set
+# CONFIG_NETLINK_DIAG is not set
+# CONFIG_MPLS is not set
+# CONFIG_HSR is not set
+# CONFIG_NET_SWITCHDEV is not set
+# CONFIG_NET_L3_MASTER_DEV is not set
+# CONFIG_NET_NCSI is not set
+# CONFIG_SOCK_CGROUP_DATA is not set
+# CONFIG_CGROUP_NET_PRIO is not set
+# CONFIG_CGROUP_NET_CLASSID is not set
+CONFIG_NET_RX_BUSY_POLL=y
+CONFIG_BQL=y
+# CONFIG_BPF_JIT is not set
+
+#
+# Network testing
+#
+# CONFIG_NET_PKTGEN is not set
+# CONFIG_HAMRADIO is not set
+# CONFIG_CAN is not set
+# CONFIG_IRDA is not set
+# CONFIG_BT is not set
+# CONFIG_AF_RXRPC is not set
+# CONFIG_AF_KCM is not set
+# CONFIG_STREAM_PARSER is not set
+CONFIG_FIB_RULES=y
+CONFIG_WIRELESS=y
+CONFIG_WEXT_CORE=y
+CONFIG_WEXT_PROC=y
+CONFIG_CFG80211=m
+# CONFIG_NL80211_TESTMODE is not set
+# CONFIG_CFG80211_DEVELOPER_WARNINGS is not set
+CONFIG_CFG80211_DEFAULT_PS=y
+# CONFIG_CFG80211_INTERNAL_REGDB is not set
+CONFIG_CFG80211_CRDA_SUPPORT=y
+CONFIG_CFG80211_WEXT=y
+# CONFIG_LIB80211 is not set
+CONFIG_MAC80211=m
+CONFIG_MAC80211_HAS_RC=y
+CONFIG_MAC80211_RC_MINSTREL=y
+CONFIG_MAC80211_RC_MINSTREL_HT=y
+# CONFIG_MAC80211_RC_MINSTREL_VHT is not set
+CONFIG_MAC80211_RC_DEFAULT_MINSTREL=y
+CONFIG_MAC80211_RC_DEFAULT="minstrel_ht"
+CONFIG_MAC80211_MESH=y
+# CONFIG_MAC80211_MESSAGE_TRACING is not set
+# CONFIG_MAC80211_DEBUG_MENU is not set
+CONFIG_MAC80211_STA_HASH_MAX_SIZE=0
+# CONFIG_WIMAX is not set
+# CONFIG_RFKILL is not set
+# CONFIG_NET_9P is not set
+# CONFIG_CAIF is not set
+# CONFIG_CEPH_LIB is not set
+# CONFIG_NFC is not set
+# CONFIG_LWTUNNEL is not set
+# CONFIG_DST_CACHE is not set
+# CONFIG_NET_DEVLINK is not set
+CONFIG_MAY_USE_DEVLINK=y
+CONFIG_HAVE_CBPF_JIT=y
+
+#
+# Device Drivers
+#
+CONFIG_ARM_AMBA=y
+
+#
+# Generic Driver Options
+#
+CONFIG_UEVENT_HELPER=y
+CONFIG_UEVENT_HELPER_PATH="/sbin/hotplug"
+# CONFIG_DEVTMPFS is not set
+CONFIG_STANDALONE=y
+# CONFIG_PREVENT_FIRMWARE_BUILD is not set
+CONFIG_FW_LOADER=y
+CONFIG_FIRMWARE_IN_KERNEL=y
+CONFIG_EXTRA_FIRMWARE=""
+# CONFIG_FW_LOADER_USER_HELPER_FALLBACK is not set
+CONFIG_ALLOW_DEV_COREDUMP=y
+# CONFIG_DEBUG_DRIVER is not set
+# CONFIG_DEBUG_DEVRES is not set
+# CONFIG_DEBUG_TEST_DRIVER_REMOVE is not set
+# CONFIG_SYS_HYPERVISOR is not set
+# CONFIG_GENERIC_CPU_DEVICES is not set
+CONFIG_REGMAP=y
+CONFIG_REGMAP_I2C=y
+CONFIG_REGMAP_MMIO=y
+# CONFIG_DMA_SHARED_BUFFER is not set
+
+#
+# Bus devices
+#
+# CONFIG_BRCMSTB_GISB_ARB is not set
+# CONFIG_VEXPRESS_CONFIG is not set
+# CONFIG_CONNECTOR is not set
+CONFIG_MTD=y
+# CONFIG_MTD_TESTS is not set
+# CONFIG_MTD_REDBOOT_PARTS is not set
+CONFIG_MTD_CMDLINE_PARTS=y
+# CONFIG_MTD_AFS_PARTS is not set
+CONFIG_MTD_OF_PARTS=y
+# CONFIG_MTD_AR7_PARTS is not set
+
+#
+# User Modules And Translation Layers
+#
+CONFIG_MTD_BLKDEVS=y
+CONFIG_MTD_BLOCK=y
+# CONFIG_FTL is not set
+# CONFIG_NFTL is not set
+# CONFIG_INFTL is not set
+# CONFIG_RFD_FTL is not set
+# CONFIG_SSFDC is not set
+# CONFIG_SM_FTL is not set
+# CONFIG_MTD_OOPS is not set
+# CONFIG_MTD_SWAP is not set
+# CONFIG_MTD_PARTITIONED_MASTER is not set
+
+#
+# RAM/ROM/Flash chip drivers
+#
+# CONFIG_MTD_CFI is not set
+# CONFIG_MTD_JEDECPROBE is not set
+CONFIG_MTD_MAP_BANK_WIDTH_1=y
+CONFIG_MTD_MAP_BANK_WIDTH_2=y
+CONFIG_MTD_MAP_BANK_WIDTH_4=y
+# CONFIG_MTD_MAP_BANK_WIDTH_8 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_16 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_32 is not set
+CONFIG_MTD_CFI_I1=y
+CONFIG_MTD_CFI_I2=y
+# CONFIG_MTD_CFI_I4 is not set
+# CONFIG_MTD_CFI_I8 is not set
+# CONFIG_MTD_RAM is not set
+# CONFIG_MTD_ROM is not set
+# CONFIG_MTD_ABSENT is not set
+
+#
+# Mapping drivers for chip access
+#
+# CONFIG_MTD_COMPLEX_MAPPINGS is not set
+# CONFIG_MTD_PLATRAM is not set
+
+#
+# Self-contained MTD device drivers
+#
+# CONFIG_MTD_SLRAM is not set
+# CONFIG_MTD_PHRAM is not set
+# CONFIG_MTD_MTDRAM is not set
+# CONFIG_MTD_BLOCK2MTD is not set
+
+#
+# Disk-On-Chip Device Drivers
+#
+# CONFIG_MTD_DOCG3 is not set
+CONFIG_MTD_NAND_ECC=y
+# CONFIG_MTD_NAND_ECC_SMC is not set
+CONFIG_MTD_NAND=y
+# CONFIG_MTD_NAND_ECC_BCH is not set
+# CONFIG_MTD_SM_COMMON is not set
+# CONFIG_MTD_NAND_DENALI_DT is not set
+# CONFIG_MTD_NAND_GPIO is not set
+# CONFIG_MTD_NAND_OMAP_BCH_BUILD is not set
+CONFIG_MTD_NAND_IDS=y
+# CONFIG_MTD_NAND_DISKONCHIP is not set
+# CONFIG_MTD_NAND_DOCG4 is not set
+# CONFIG_MTD_NAND_NANDSIM is not set
+# CONFIG_MTD_NAND_BRCMNAND is not set
+# CONFIG_MTD_NAND_PLATFORM is not set
+# CONFIG_MTD_NAND_HISI504 is not set
+# CONFIG_MTD_NAND_MTK is not set
+CONFIG_MTD_SPI_NAND_HISI_BVT=y
+# CONFIG_HISI_NAND_ECC_STATUS_REPORT is not set
+# CONFIG_HISI_NAND_FS_MAY_NO_YAFFS2 is not set
+CONFIG_MTD_SPI_NAND_HIFMC100=y
+# CONFIG_MTD_ONENAND is not set
+
+#
+# LPDDR & LPDDR2 PCM memory drivers
+#
+# CONFIG_MTD_LPDDR is not set
+# CONFIG_MTD_LPDDR2_NVM is not set
+CONFIG_MTD_SPI_NOR=y
+# CONFIG_MTD_MT81xx_NOR is not set
+# CONFIG_MTD_SPI_NOR_USE_4K_SECTORS is not set
+# CONFIG_SPI_CADENCE_QUADSPI is not set
+CONFIG_SPI_HISI_SFC=y
+# CONFIG_MTD_SPI_IDS is not set
+CONFIG_CLOSE_SPI_8PIN_4IO=y
+CONFIG_HISI_SPI_BLOCK_PROTECT=y
+CONFIG_MTD_UBI=y
+CONFIG_MTD_UBI_WL_THRESHOLD=4096
+CONFIG_MTD_UBI_BEB_LIMIT=20
+# CONFIG_MTD_UBI_FASTMAP is not set
+# CONFIG_MTD_UBI_GLUEBI is not set
+# CONFIG_MTD_UBI_BLOCK is not set
+CONFIG_DTC=y
+CONFIG_OF=y
+# CONFIG_OF_UNITTEST is not set
+CONFIG_OF_FLATTREE=y
+CONFIG_OF_EARLY_FLATTREE=y
+CONFIG_OF_ADDRESS=y
+CONFIG_OF_IRQ=y
+CONFIG_OF_NET=y
+CONFIG_OF_MDIO=y
+CONFIG_OF_RESERVED_MEM=y
+# CONFIG_OF_OVERLAY is not set
+CONFIG_ARCH_MIGHT_HAVE_PC_PARPORT=y
+# CONFIG_PARPORT is not set
+CONFIG_BLK_DEV=y
+# CONFIG_BLK_DEV_NULL_BLK is not set
+# CONFIG_BLK_DEV_COW_COMMON is not set
+# CONFIG_BLK_DEV_LOOP is not set
+# CONFIG_BLK_DEV_DRBD is not set
+# CONFIG_BLK_DEV_NBD is not set
+CONFIG_BLK_DEV_RAM=y
+CONFIG_BLK_DEV_RAM_COUNT=16
+CONFIG_BLK_DEV_RAM_SIZE=65536
+# CONFIG_CDROM_PKTCDVD is not set
+# CONFIG_ATA_OVER_ETH is not set
+# CONFIG_MG_DISK is not set
+# CONFIG_BLK_DEV_RBD is not set
+# CONFIG_NVME_TARGET is not set
+
+#
+# Misc devices
+#
+# CONFIG_SENSORS_LIS3LV02D is not set
+# CONFIG_AD525X_DPOT is not set
+# CONFIG_DUMMY_IRQ is not set
+# CONFIG_ICS932S401 is not set
+# CONFIG_ENCLOSURE_SERVICES is not set
+# CONFIG_APDS9802ALS is not set
+# CONFIG_ISL29003 is not set
+# CONFIG_ISL29020 is not set
+# CONFIG_SENSORS_TSL2550 is not set
+# CONFIG_SENSORS_BH1770 is not set
+# CONFIG_SENSORS_APDS990X is not set
+# CONFIG_HMC6352 is not set
+# CONFIG_DS1682 is not set
+# CONFIG_USB_SWITCH_FSA9480 is not set
+# CONFIG_SRAM is not set
+# CONFIG_C2PORT is not set
+
+#
+# EEPROM support
+#
+# CONFIG_EEPROM_AT24 is not set
+# CONFIG_EEPROM_LEGACY is not set
+# CONFIG_EEPROM_MAX6875 is not set
+# CONFIG_EEPROM_93CX6 is not set
+
+#
+# Texas Instruments shared transport line discipline
+#
+# CONFIG_TI_ST is not set
+# CONFIG_SENSORS_LIS3_I2C is not set
+
+#
+# Altera FPGA firmware download module
+#
+# CONFIG_ALTERA_STAPL is not set
+
+#
+# Intel MIC Bus Driver
+#
+
+#
+# SCIF Bus Driver
+#
+
+#
+# VOP Bus Driver
+#
+
+#
+# Intel MIC Host Driver
+#
+
+#
+# Intel MIC Card Driver
+#
+
+#
+# SCIF Driver
+#
+
+#
+# Intel MIC Coprocessor State Management (COSM) Drivers
+#
+
+#
+# VOP Driver
+#
+# CONFIG_ECHO is not set
+# CONFIG_CXL_BASE is not set
+# CONFIG_CXL_AFU_DRIVER_OPS is not set
+
+#
+# SCSI device support
+#
+CONFIG_SCSI_MOD=y
+# CONFIG_RAID_ATTRS is not set
+CONFIG_SCSI=y
+CONFIG_SCSI_DMA=y
+CONFIG_SCSI_NETLINK=y
+# CONFIG_SCSI_MQ_DEFAULT is not set
+CONFIG_SCSI_PROC_FS=y
+
+#
+# SCSI support type (disk, tape, CD-ROM)
+#
+CONFIG_BLK_DEV_SD=y
+# CONFIG_CHR_DEV_ST is not set
+# CONFIG_CHR_DEV_OSST is not set
+CONFIG_BLK_DEV_SR=y
+# CONFIG_BLK_DEV_SR_VENDOR is not set
+# CONFIG_CHR_DEV_SG is not set
+# CONFIG_CHR_DEV_SCH is not set
+# CONFIG_SCSI_CONSTANTS is not set
+# CONFIG_SCSI_LOGGING is not set
+# CONFIG_SCSI_SCAN_ASYNC is not set
+
+#
+# SCSI Transports
+#
+# CONFIG_SCSI_SPI_ATTRS is not set
+CONFIG_SCSI_FC_ATTRS=y
+# CONFIG_SCSI_ISCSI_ATTRS is not set
+# CONFIG_SCSI_SAS_ATTRS is not set
+# CONFIG_SCSI_SAS_LIBSAS is not set
+# CONFIG_SCSI_SRP_ATTRS is not set
+CONFIG_SCSI_LOWLEVEL=y
+# CONFIG_ISCSI_TCP is not set
+# CONFIG_ISCSI_BOOT_SYSFS is not set
+# CONFIG_SCSI_UFSHCD is not set
+# CONFIG_LIBFC is not set
+# CONFIG_SCSI_DEBUG is not set
+# CONFIG_SCSI_DH is not set
+# CONFIG_SCSI_OSD_INITIATOR is not set
+CONFIG_HISI_SATA=y
+CONFIG_HISI_SATA_IOBASE=0x10030000
+CONFIG_HISI_SATA_FBS=1
+CONFIG_HISI_SATA_NCQ=1
+# CONFIG_HISI_ESATA is not set
+CONFIG_ATA=y
+# CONFIG_ATA_NONSTANDARD is not set
+CONFIG_ATA_VERBOSE_ERROR=y
+CONFIG_SATA_PMP=y
+
+#
+# Controllers with non-SFF native interface
+#
+CONFIG_SATA_AHCI_PLATFORM=y
+# CONFIG_AHCI_CEVA is not set
+# CONFIG_AHCI_QORIQ is not set
+CONFIG_ATA_SFF=y
+
+#
+# SFF controllers with custom DMA interface
+#
+CONFIG_ATA_BMDMA=y
+
+#
+# SATA SFF controllers with BMDMA
+#
+
+#
+# PATA SFF controllers with BMDMA
+#
+
+#
+# PIO-only SFF controllers
+#
+
+#
+# Generic fallback / legacy drivers
+#
+# CONFIG_MD is not set
+# CONFIG_TARGET_CORE is not set
+CONFIG_NETDEVICES=y
+CONFIG_NET_CORE=y
+# CONFIG_BONDING is not set
+# CONFIG_DUMMY is not set
+# CONFIG_EQUALIZER is not set
+# CONFIG_NET_TEAM is not set
+# CONFIG_MACVLAN is not set
+# CONFIG_VXLAN is not set
+# CONFIG_MACSEC is not set
+# CONFIG_NETCONSOLE is not set
+# CONFIG_NETPOLL is not set
+# CONFIG_NET_POLL_CONTROLLER is not set
+# CONFIG_TUN is not set
+# CONFIG_TUN_VNET_CROSS_LE is not set
+# CONFIG_VETH is not set
+# CONFIG_NLMON is not set
+
+#
+# CAIF transport drivers
+#
+
+#
+# Distributed Switch Architecture drivers
+#
+CONFIG_ETHERNET=y
+# CONFIG_ALTERA_TSE is not set
+# CONFIG_NET_VENDOR_AMAZON is not set
+# CONFIG_NET_VENDOR_ARC is not set
+# CONFIG_NET_VENDOR_AURORA is not set
+# CONFIG_NET_CADENCE is not set
+# CONFIG_NET_VENDOR_BROADCOM is not set
+# CONFIG_NET_VENDOR_CIRRUS is not set
+# CONFIG_DM9000 is not set
+# CONFIG_DNET is not set
+# CONFIG_NET_VENDOR_EZCHIP is not set
+# CONFIG_NET_VENDOR_FARADAY is not set
+CONFIG_NET_VENDOR_HISILICON=y
+# CONFIG_HIX5HD2_GMAC is not set
+CONFIG_HISI_FEMAC=y
+# CONFIG_HIP04_ETH is not set
+# CONFIG_HNS is not set
+# CONFIG_HNS_DSAF is not set
+# CONFIG_HNS_ENET is not set
+# CONFIG_HIETH_GMAC is not set
+# CONFIG_NET_VENDOR_INTEL is not set
+# CONFIG_NET_VENDOR_MARVELL is not set
+# CONFIG_NET_VENDOR_MICREL is not set
+# CONFIG_NET_VENDOR_NATSEMI is not set
+# CONFIG_NET_VENDOR_NETRONOME is not set
+# CONFIG_ETHOC is not set
+# CONFIG_NET_VENDOR_QUALCOMM is not set
+# CONFIG_NET_VENDOR_RENESAS is not set
+# CONFIG_NET_VENDOR_ROCKER is not set
+# CONFIG_NET_VENDOR_SAMSUNG is not set
+# CONFIG_NET_VENDOR_SEEQ is not set
+# CONFIG_NET_VENDOR_SMSC is not set
+# CONFIG_NET_VENDOR_STMICRO is not set
+# CONFIG_NET_VENDOR_SYNOPSYS is not set
+# CONFIG_NET_VENDOR_VIA is not set
+# CONFIG_NET_VENDOR_WIZNET is not set
+CONFIG_PHYLIB=y
+CONFIG_SWPHY=y
+
+#
+# MDIO bus device drivers
+#
+# CONFIG_MDIO_BCM_UNIMAC is not set
+# CONFIG_MDIO_BITBANG is not set
+# CONFIG_MDIO_BUS_MUX_GPIO is not set
+# CONFIG_MDIO_BUS_MUX_MMIOREG is not set
+CONFIG_MDIO_HISI_FEMAC=y
+# CONFIG_MDIO_HISI_GEMAC is not set
+
+#
+# MII PHY device drivers
+#
+# CONFIG_AMD_PHY is not set
+# CONFIG_AQUANTIA_PHY is not set
+# CONFIG_AT803X_PHY is not set
+# CONFIG_BCM7XXX_PHY is not set
+# CONFIG_BCM87XX_PHY is not set
+# CONFIG_BROADCOM_PHY is not set
+# CONFIG_CICADA_PHY is not set
+# CONFIG_DAVICOM_PHY is not set
+# CONFIG_DP83848_PHY is not set
+# CONFIG_DP83867_PHY is not set
+CONFIG_FIXED_PHY=y
+# CONFIG_ICPLUS_PHY is not set
+# CONFIG_INTEL_XWAY_PHY is not set
+# CONFIG_LSI_ET1011C_PHY is not set
+# CONFIG_LXT_PHY is not set
+# CONFIG_MARVELL_PHY is not set
+# CONFIG_MICREL_PHY is not set
+# CONFIG_MICROCHIP_PHY is not set
+# CONFIG_MICROSEMI_PHY is not set
+# CONFIG_NATIONAL_PHY is not set
+# CONFIG_QSEMI_PHY is not set
+# CONFIG_REALTEK_PHY is not set
+# CONFIG_SMSC_PHY is not set
+# CONFIG_STE10XP is not set
+# CONFIG_TERANETICS_PHY is not set
+# CONFIG_VITESSE_PHY is not set
+# CONFIG_XILINX_GMII2RGMII is not set
+# CONFIG_PPP is not set
+# CONFIG_SLIP is not set
+CONFIG_USB_NET_DRIVERS=y
+# CONFIG_USB_CATC is not set
+# CONFIG_USB_KAWETH is not set
+# CONFIG_USB_PEGASUS is not set
+# CONFIG_USB_RTL8150 is not set
+# CONFIG_USB_RTL8152 is not set
+# CONFIG_USB_LAN78XX is not set
+# CONFIG_USB_USBNET is not set
+# CONFIG_USB_IPHETH is not set
+# CONFIG_WLAN is not set
+
+#
+# Enable WiMAX (Networking options) to see the WiMAX drivers
+#
+# CONFIG_WAN is not set
+# CONFIG_ISDN is not set
+# CONFIG_NVM is not set
+
+#
+# Input device support
+#
+CONFIG_INPUT=y
+# CONFIG_INPUT_FF_MEMLESS is not set
+# CONFIG_INPUT_POLLDEV is not set
+# CONFIG_INPUT_SPARSEKMAP is not set
+# CONFIG_INPUT_MATRIXKMAP is not set
+
+#
+# Userland interfaces
+#
+CONFIG_INPUT_MOUSEDEV=y
+CONFIG_INPUT_MOUSEDEV_PSAUX=y
+CONFIG_INPUT_MOUSEDEV_SCREEN_X=1024
+CONFIG_INPUT_MOUSEDEV_SCREEN_Y=768
+# CONFIG_INPUT_JOYDEV is not set
+CONFIG_INPUT_EVDEV=y
+# CONFIG_INPUT_EVBUG is not set
+
+#
+# Input Device Drivers
+#
+CONFIG_INPUT_KEYBOARD=y
+# CONFIG_KEYBOARD_ADP5588 is not set
+# CONFIG_KEYBOARD_ADP5589 is not set
+CONFIG_KEYBOARD_ATKBD=y
+# CONFIG_KEYBOARD_QT1070 is not set
+# CONFIG_KEYBOARD_QT2160 is not set
+# CONFIG_KEYBOARD_LKKBD is not set
+# CONFIG_KEYBOARD_GPIO is not set
+# CONFIG_KEYBOARD_GPIO_POLLED is not set
+# CONFIG_KEYBOARD_TCA6416 is not set
+# CONFIG_KEYBOARD_TCA8418 is not set
+# CONFIG_KEYBOARD_MATRIX is not set
+# CONFIG_KEYBOARD_LM8333 is not set
+# CONFIG_KEYBOARD_MAX7359 is not set
+# CONFIG_KEYBOARD_MCS is not set
+# CONFIG_KEYBOARD_MPR121 is not set
+# CONFIG_KEYBOARD_NEWTON is not set
+# CONFIG_KEYBOARD_OPENCORES is not set
+# CONFIG_KEYBOARD_SAMSUNG is not set
+# CONFIG_KEYBOARD_STOWAWAY is not set
+# CONFIG_KEYBOARD_SUNKBD is not set
+# CONFIG_KEYBOARD_OMAP4 is not set
+# CONFIG_KEYBOARD_XTKBD is not set
+# CONFIG_KEYBOARD_CAP11XX is not set
+# CONFIG_KEYBOARD_BCM is not set
+CONFIG_INPUT_MOUSE=y
+CONFIG_MOUSE_PS2=y
+CONFIG_MOUSE_PS2_ALPS=y
+CONFIG_MOUSE_PS2_BYD=y
+CONFIG_MOUSE_PS2_LOGIPS2PP=y
+CONFIG_MOUSE_PS2_SYNAPTICS=y
+CONFIG_MOUSE_PS2_CYPRESS=y
+CONFIG_MOUSE_PS2_TRACKPOINT=y
+# CONFIG_MOUSE_PS2_ELANTECH is not set
+# CONFIG_MOUSE_PS2_SENTELIC is not set
+# CONFIG_MOUSE_PS2_TOUCHKIT is not set
+CONFIG_MOUSE_PS2_FOCALTECH=y
+# CONFIG_MOUSE_SERIAL is not set
+# CONFIG_MOUSE_APPLETOUCH is not set
+# CONFIG_MOUSE_BCM5974 is not set
+# CONFIG_MOUSE_CYAPA is not set
+# CONFIG_MOUSE_ELAN_I2C is not set
+# CONFIG_MOUSE_VSXXXAA is not set
+# CONFIG_MOUSE_GPIO is not set
+# CONFIG_MOUSE_SYNAPTICS_I2C is not set
+# CONFIG_MOUSE_SYNAPTICS_USB is not set
+# CONFIG_INPUT_JOYSTICK is not set
+# CONFIG_INPUT_TABLET is not set
+# CONFIG_INPUT_TOUCHSCREEN is not set
+CONFIG_INPUT_MISC=y
+# CONFIG_INPUT_AD714X is not set
+# CONFIG_INPUT_ATMEL_CAPTOUCH is not set
+# CONFIG_INPUT_BMA150 is not set
+# CONFIG_INPUT_E3X0_BUTTON is not set
+# CONFIG_INPUT_MMA8450 is not set
+# CONFIG_INPUT_MPU3050 is not set
+# CONFIG_INPUT_GP2A is not set
+# CONFIG_INPUT_GPIO_BEEPER is not set
+# CONFIG_INPUT_GPIO_TILT_POLLED is not set
+# CONFIG_INPUT_GPIO_DECODER is not set
+# CONFIG_INPUT_ATI_REMOTE2 is not set
+# CONFIG_INPUT_KEYSPAN_REMOTE is not set
+# CONFIG_INPUT_KXTJ9 is not set
+# CONFIG_INPUT_POWERMATE is not set
+# CONFIG_INPUT_YEALINK is not set
+# CONFIG_INPUT_CM109 is not set
+CONFIG_INPUT_UINPUT=y
+# CONFIG_INPUT_PCF8574 is not set
+# CONFIG_INPUT_GPIO_ROTARY_ENCODER is not set
+# CONFIG_INPUT_ADXL34X is not set
+# CONFIG_INPUT_CMA3000 is not set
+# CONFIG_INPUT_DRV260X_HAPTICS is not set
+# CONFIG_INPUT_DRV2665_HAPTICS is not set
+# CONFIG_INPUT_DRV2667_HAPTICS is not set
+# CONFIG_RMI4_CORE is not set
+
+#
+# Hardware I/O ports
+#
+CONFIG_SERIO=y
+CONFIG_SERIO_SERPORT=y
+# CONFIG_SERIO_AMBAKMI is not set
+CONFIG_SERIO_LIBPS2=y
+# CONFIG_SERIO_RAW is not set
+# CONFIG_SERIO_ALTERA_PS2 is not set
+# CONFIG_SERIO_PS2MULT is not set
+# CONFIG_SERIO_ARC_PS2 is not set
+# CONFIG_SERIO_APBPS2 is not set
+# CONFIG_USERIO is not set
+# CONFIG_GAMEPORT is not set
+
+#
+# Character devices
+#
+CONFIG_TTY=y
+CONFIG_VT=y
+CONFIG_CONSOLE_TRANSLATIONS=y
+CONFIG_VT_CONSOLE=y
+CONFIG_VT_CONSOLE_SLEEP=y
+CONFIG_HW_CONSOLE=y
+# CONFIG_VT_HW_CONSOLE_BINDING is not set
+CONFIG_UNIX98_PTYS=y
+# CONFIG_LEGACY_PTYS is not set
+# CONFIG_SERIAL_NONSTANDARD is not set
+# CONFIG_N_GSM is not set
+# CONFIG_TRACE_SINK is not set
+CONFIG_DEVMEM=y
+# CONFIG_DEVKMEM is not set
+
+#
+# Serial drivers
+#
+CONFIG_SERIAL_EARLYCON=y
+# CONFIG_SERIAL_8250 is not set
+
+#
+# Non-8250 serial port support
+#
+# CONFIG_SERIAL_AMBA_PL010 is not set
+CONFIG_SERIAL_AMBA_PL011=y
+CONFIG_SERIAL_AMBA_PL011_CONSOLE=y
+# CONFIG_SERIAL_EARLYCON_ARM_SEMIHOST is not set
+# CONFIG_SERIAL_UARTLITE is not set
+CONFIG_SERIAL_CORE=y
+CONFIG_SERIAL_CORE_CONSOLE=y
+# CONFIG_SERIAL_SCCNXP is not set
+# CONFIG_SERIAL_SC16IS7XX is not set
+# CONFIG_SERIAL_BCM63XX is not set
+# CONFIG_SERIAL_ALTERA_JTAGUART is not set
+# CONFIG_SERIAL_ALTERA_UART is not set
+# CONFIG_SERIAL_XILINX_PS_UART is not set
+# CONFIG_SERIAL_ARC is not set
+# CONFIG_SERIAL_FSL_LPUART is not set
+# CONFIG_SERIAL_CONEXANT_DIGICOLOR is not set
+# CONFIG_SERIAL_ST_ASC is not set
+# CONFIG_SERIAL_STM32 is not set
+# CONFIG_HVC_DCC is not set
+# CONFIG_IPMI_HANDLER is not set
+# CONFIG_HW_RANDOM is not set
+# CONFIG_R3964 is not set
+# CONFIG_RAW_DRIVER is not set
+# CONFIG_TCG_TPM is not set
+# CONFIG_XILLYBUS is not set
+
+#
+# I2C support
+#
+CONFIG_I2C=y
+CONFIG_I2C_BOARDINFO=y
+# CONFIG_I2C_COMPAT is not set
+CONFIG_I2C_CHARDEV=y
+# CONFIG_I2C_MUX is not set
+# CONFIG_I2C_HELPER_AUTO is not set
+# CONFIG_I2C_SMBUS is not set
+
+#
+# I2C Algorithms
+#
+# CONFIG_I2C_ALGOBIT is not set
+# CONFIG_I2C_ALGOPCF is not set
+# CONFIG_I2C_ALGOPCA is not set
+
+#
+# I2C Hardware Bus support
+#
+
+#
+# I2C system bus drivers (mostly embedded / system-on-chip)
+#
+# CONFIG_I2C_CBUS_GPIO is not set
+# CONFIG_I2C_DESIGNWARE_PLATFORM is not set
+# CONFIG_I2C_EMEV2 is not set
+# CONFIG_I2C_GPIO is not set
+CONFIG_I2C_HIBVT=y
+# CONFIG_I2C_NOMADIK is not set
+# CONFIG_I2C_OCORES is not set
+# CONFIG_I2C_PCA_PLATFORM is not set
+# CONFIG_I2C_PXA_PCI is not set
+# CONFIG_I2C_RK3X is not set
+# CONFIG_I2C_SIMTEC is not set
+# CONFIG_I2C_XILINX is not set
+
+#
+# External I2C/SMBus adapter drivers
+#
+# CONFIG_I2C_DIOLAN_U2C is not set
+# CONFIG_I2C_PARPORT_LIGHT is not set
+# CONFIG_I2C_ROBOTFUZZ_OSIF is not set
+# CONFIG_I2C_TAOS_EVM is not set
+# CONFIG_I2C_TINY_USB is not set
+
+#
+# Other I2C/SMBus bus drivers
+#
+CONFIG_DMA_MSG_LEN=5
+# CONFIG_I2C_STUB is not set
+# CONFIG_I2C_SLAVE is not set
+# CONFIG_I2C_DEBUG_CORE is not set
+# CONFIG_I2C_DEBUG_ALGO is not set
+# CONFIG_I2C_DEBUG_BUS is not set
+# CONFIG_SPI is not set
+# CONFIG_SPMI is not set
+# CONFIG_HSI is not set
+
+#
+# PPS support
+#
+# CONFIG_PPS is not set
+
+#
+# PPS generators support
+#
+
+#
+# PTP clock support
+#
+# CONFIG_PTP_1588_CLOCK is not set
+
+#
+# Enable PHYLIB and NETWORK_PHY_TIMESTAMPING to see the additional clocks.
+#
+CONFIG_PINCTRL=y
+
+#
+# Pin controllers
+#
+CONFIG_PINMUX=y
+CONFIG_PINCONF=y
+CONFIG_GENERIC_PINCONF=y
+# CONFIG_DEBUG_PINCTRL is not set
+# CONFIG_PINCTRL_AMD is not set
+CONFIG_PINCTRL_SINGLE=y
+CONFIG_ARCH_HAVE_CUSTOM_GPIO_H=y
+CONFIG_GPIOLIB=y
+CONFIG_OF_GPIO=y
+CONFIG_GPIOLIB_IRQCHIP=y
+# CONFIG_DEBUG_GPIO is not set
+CONFIG_GPIO_SYSFS=y
+
+#
+# Memory mapped GPIO drivers
+#
+# CONFIG_GPIO_74XX_MMIO is not set
+# CONFIG_GPIO_ALTERA is not set
+# CONFIG_GPIO_DWAPB is not set
+# CONFIG_GPIO_EM is not set
+# CONFIG_GPIO_GENERIC_PLATFORM is not set
+# CONFIG_GPIO_GRGPIO is not set
+# CONFIG_GPIO_MOCKUP is not set
+# CONFIG_GPIO_MPC8XXX is not set
+CONFIG_GPIO_PL061=y
+# CONFIG_GPIO_XILINX is not set
+# CONFIG_GPIO_ZEVIO is not set
+# CONFIG_GPIO_ZX is not set
+
+#
+# I2C GPIO expanders
+#
+# CONFIG_GPIO_ADP5588 is not set
+# CONFIG_GPIO_ADNP is not set
+# CONFIG_GPIO_MAX7300 is not set
+# CONFIG_GPIO_MAX732X is not set
+# CONFIG_GPIO_PCA953X is not set
+# CONFIG_GPIO_PCF857X is not set
+# CONFIG_GPIO_SX150X is not set
+# CONFIG_GPIO_TPIC2810 is not set
+# CONFIG_GPIO_TS4900 is not set
+
+#
+# MFD GPIO expanders
+#
+# CONFIG_HTC_EGPIO is not set
+
+#
+# SPI or I2C GPIO expanders
+#
+# CONFIG_GPIO_MCP23S08 is not set
+
+#
+# USB GPIO expanders
+#
+# CONFIG_W1 is not set
+# CONFIG_POWER_AVS is not set
+CONFIG_POWER_RESET=y
+# CONFIG_POWER_RESET_BRCMKONA is not set
+# CONFIG_POWER_RESET_GPIO is not set
+# CONFIG_POWER_RESET_GPIO_RESTART is not set
+CONFIG_POWER_RESET_HISI=y
+# CONFIG_POWER_RESET_LTC2952 is not set
+# CONFIG_POWER_RESET_RESTART is not set
+# CONFIG_POWER_RESET_SYSCON is not set
+# CONFIG_POWER_RESET_SYSCON_POWEROFF is not set
+CONFIG_POWER_SUPPLY=y
+# CONFIG_POWER_SUPPLY_DEBUG is not set
+# CONFIG_PDA_POWER is not set
+# CONFIG_TEST_POWER is not set
+# CONFIG_BATTERY_DS2780 is not set
+# CONFIG_BATTERY_DS2781 is not set
+# CONFIG_BATTERY_DS2782 is not set
+# CONFIG_BATTERY_SBS is not set
+# CONFIG_BATTERY_BQ27XXX is not set
+# CONFIG_BATTERY_MAX17040 is not set
+# CONFIG_BATTERY_MAX17042 is not set
+# CONFIG_CHARGER_MAX8903 is not set
+# CONFIG_CHARGER_LP8727 is not set
+# CONFIG_CHARGER_GPIO is not set
+# CONFIG_CHARGER_BQ2415X is not set
+# CONFIG_CHARGER_BQ24190 is not set
+# CONFIG_CHARGER_BQ24257 is not set
+# CONFIG_CHARGER_BQ24735 is not set
+# CONFIG_CHARGER_BQ25890 is not set
+# CONFIG_CHARGER_SMB347 is not set
+# CONFIG_BATTERY_GAUGE_LTC2941 is not set
+# CONFIG_CHARGER_RT9455 is not set
+# CONFIG_HWMON is not set
+# CONFIG_THERMAL is not set
+# CONFIG_WATCHDOG is not set
+CONFIG_SSB_POSSIBLE=y
+
+#
+# Sonics Silicon Backplane
+#
+# CONFIG_SSB is not set
+CONFIG_BCMA_POSSIBLE=y
+
+#
+# Broadcom specific AMBA
+#
+# CONFIG_BCMA is not set
+
+#
+# Multifunction device drivers
+#
+CONFIG_MFD_CORE=y
+# CONFIG_MFD_ACT8945A is not set
+# CONFIG_MFD_AS3711 is not set
+# CONFIG_MFD_AS3722 is not set
+# CONFIG_PMIC_ADP5520 is not set
+# CONFIG_MFD_AAT2870_CORE is not set
+# CONFIG_MFD_ATMEL_FLEXCOM is not set
+# CONFIG_MFD_ATMEL_HLCDC is not set
+# CONFIG_MFD_BCM590XX is not set
+# CONFIG_MFD_AXP20X_I2C is not set
+# CONFIG_MFD_CROS_EC is not set
+# CONFIG_MFD_ASIC3 is not set
+# CONFIG_PMIC_DA903X is not set
+# CONFIG_MFD_DA9052_I2C is not set
+# CONFIG_MFD_DA9055 is not set
+# CONFIG_MFD_DA9062 is not set
+# CONFIG_MFD_DA9063 is not set
+# CONFIG_MFD_DA9150 is not set
+# CONFIG_MFD_DLN2 is not set
+# CONFIG_MFD_EXYNOS_LPASS is not set
+# CONFIG_MFD_MC13XXX_I2C is not set
+# CONFIG_MFD_HI6421_PMIC is not set
+CONFIG_MFD_HISI_FMC=y
+# CONFIG_HTC_PASIC3 is not set
+# CONFIG_HTC_I2CPLD is not set
+# CONFIG_INTEL_SOC_PMIC is not set
+# CONFIG_MFD_KEMPLD is not set
+# CONFIG_MFD_88PM800 is not set
+# CONFIG_MFD_88PM805 is not set
+# CONFIG_MFD_88PM860X is not set
+# CONFIG_MFD_MAX14577 is not set
+# CONFIG_MFD_MAX77620 is not set
+# CONFIG_MFD_MAX77686 is not set
+# CONFIG_MFD_MAX77693 is not set
+# CONFIG_MFD_MAX77843 is not set
+# CONFIG_MFD_MAX8907 is not set
+# CONFIG_MFD_MAX8925 is not set
+# CONFIG_MFD_MAX8997 is not set
+# CONFIG_MFD_MAX8998 is not set
+# CONFIG_MFD_MT6397 is not set
+# CONFIG_MFD_MENF21BMC is not set
+# CONFIG_MFD_VIPERBOARD is not set
+# CONFIG_MFD_RETU is not set
+# CONFIG_MFD_PCF50633 is not set
+# CONFIG_MFD_PM8921_CORE is not set
+# CONFIG_MFD_RT5033 is not set
+# CONFIG_MFD_RTSX_USB is not set
+# CONFIG_MFD_RC5T583 is not set
+# CONFIG_MFD_RK808 is not set
+# CONFIG_MFD_RN5T618 is not set
+# CONFIG_MFD_SEC_CORE is not set
+# CONFIG_MFD_SI476X_CORE is not set
+# CONFIG_MFD_SM501 is not set
+# CONFIG_MFD_SKY81452 is not set
+# CONFIG_MFD_SMSC is not set
+# CONFIG_ABX500_CORE is not set
+# CONFIG_MFD_STMPE is not set
+# CONFIG_MFD_SYSCON is not set
+# CONFIG_MFD_TI_AM335X_TSCADC is not set
+# CONFIG_MFD_LP3943 is not set
+# CONFIG_MFD_LP8788 is not set
+# CONFIG_MFD_PALMAS is not set
+# CONFIG_TPS6105X is not set
+# CONFIG_TPS65010 is not set
+# CONFIG_TPS6507X is not set
+# CONFIG_MFD_TPS65086 is not set
+# CONFIG_MFD_TPS65090 is not set
+# CONFIG_MFD_TPS65217 is not set
+# CONFIG_MFD_TI_LP873X is not set
+# CONFIG_MFD_TPS65218 is not set
+# CONFIG_MFD_TPS6586X is not set
+# CONFIG_MFD_TPS65910 is not set
+# CONFIG_MFD_TPS65912_I2C is not set
+# CONFIG_MFD_TPS80031 is not set
+# CONFIG_TWL4030_CORE is not set
+# CONFIG_TWL6040_CORE is not set
+# CONFIG_MFD_WL1273_CORE is not set
+# CONFIG_MFD_LM3533 is not set
+# CONFIG_MFD_TC3589X is not set
+# CONFIG_MFD_TMIO is not set
+# CONFIG_MFD_T7L66XB is not set
+# CONFIG_MFD_TC6387XB is not set
+# CONFIG_MFD_TC6393XB is not set
+# CONFIG_MFD_ARIZONA_I2C is not set
+# CONFIG_MFD_WM8400 is not set
+# CONFIG_MFD_WM831X_I2C is not set
+# CONFIG_MFD_WM8350_I2C is not set
+# CONFIG_MFD_WM8994 is not set
+# CONFIG_REGULATOR is not set
+# CONFIG_MEDIA_SUPPORT is not set
+
+#
+# Graphics support
+#
+# CONFIG_IMX_IPUV3_CORE is not set
+# CONFIG_DRM is not set
+
+#
+# ACP (Audio CoProcessor) Configuration
+#
+
+#
+# Frame buffer Devices
+#
+CONFIG_FB=y
+# CONFIG_FIRMWARE_EDID is not set
+CONFIG_FB_CMDLINE=y
+CONFIG_FB_NOTIFY=y
+# CONFIG_FB_DDC is not set
+# CONFIG_FB_BOOT_VESA_SUPPORT is not set
+# CONFIG_FB_CFB_FILLRECT is not set
+# CONFIG_FB_CFB_COPYAREA is not set
+# CONFIG_FB_CFB_IMAGEBLIT is not set
+# CONFIG_FB_CFB_REV_PIXELS_IN_BYTE is not set
+# CONFIG_FB_SYS_FILLRECT is not set
+# CONFIG_FB_SYS_COPYAREA is not set
+# CONFIG_FB_SYS_IMAGEBLIT is not set
+# CONFIG_FB_FOREIGN_ENDIAN is not set
+# CONFIG_FB_SYS_FOPS is not set
+# CONFIG_FB_SVGALIB is not set
+# CONFIG_FB_MACMODES is not set
+# CONFIG_FB_BACKLIGHT is not set
+# CONFIG_FB_MODE_HELPERS is not set
+# CONFIG_FB_TILEBLITTING is not set
+
+#
+# Frame buffer hardware drivers
+#
+# CONFIG_FB_ARMCLCD is not set
+# CONFIG_FB_OPENCORES is not set
+# CONFIG_FB_S1D13XXX is not set
+# CONFIG_FB_SMSCUFX is not set
+# CONFIG_FB_UDL is not set
+# CONFIG_FB_IBM_GXT4500 is not set
+# CONFIG_FB_VIRTUAL is not set
+# CONFIG_FB_METRONOME is not set
+# CONFIG_FB_BROADSHEET is not set
+# CONFIG_FB_AUO_K190X is not set
+# CONFIG_FB_SIMPLE is not set
+# CONFIG_FB_SSD1307 is not set
+# CONFIG_BACKLIGHT_LCD_SUPPORT is not set
+# CONFIG_VGASTATE is not set
+
+#
+# Console display driver support
+#
+CONFIG_DUMMY_CONSOLE=y
+# CONFIG_FRAMEBUFFER_CONSOLE is not set
+# CONFIG_LOGO is not set
+# CONFIG_SOUND is not set
+
+#
+# HID support
+#
+CONFIG_HID=y
+# CONFIG_HID_BATTERY_STRENGTH is not set
+# CONFIG_HIDRAW is not set
+# CONFIG_UHID is not set
+CONFIG_HID_GENERIC=y
+
+#
+# Special HID drivers
+#
+# CONFIG_HID_A4TECH is not set
+# CONFIG_HID_ACRUX is not set
+# CONFIG_HID_APPLE is not set
+# CONFIG_HID_APPLEIR is not set
+# CONFIG_HID_AUREAL is not set
+# CONFIG_HID_BELKIN is not set
+# CONFIG_HID_BETOP_FF is not set
+# CONFIG_HID_CHERRY is not set
+# CONFIG_HID_CHICONY is not set
+# CONFIG_HID_CMEDIA is not set
+# CONFIG_HID_CP2112 is not set
+# CONFIG_HID_CYPRESS is not set
+# CONFIG_HID_DRAGONRISE is not set
+# CONFIG_HID_EMS_FF is not set
+# CONFIG_HID_ELECOM is not set
+# CONFIG_HID_ELO is not set
+# CONFIG_HID_EZKEY is not set
+# CONFIG_HID_GEMBIRD is not set
+# CONFIG_HID_GFRM is not set
+# CONFIG_HID_HOLTEK is not set
+# CONFIG_HID_KEYTOUCH is not set
+# CONFIG_HID_KYE is not set
+# CONFIG_HID_UCLOGIC is not set
+# CONFIG_HID_WALTOP is not set
+# CONFIG_HID_GYRATION is not set
+# CONFIG_HID_ICADE is not set
+# CONFIG_HID_TWINHAN is not set
+# CONFIG_HID_KENSINGTON is not set
+# CONFIG_HID_LCPOWER is not set
+# CONFIG_HID_LENOVO is not set
+# CONFIG_HID_LOGITECH is not set
+# CONFIG_HID_MAGICMOUSE is not set
+CONFIG_HID_MICROSOFT=y
+# CONFIG_HID_MONTEREY is not set
+# CONFIG_HID_MULTITOUCH is not set
+# CONFIG_HID_NTRIG is not set
+# CONFIG_HID_ORTEK is not set
+# CONFIG_HID_PANTHERLORD is not set
+# CONFIG_HID_PENMOUNT is not set
+# CONFIG_HID_PETALYNX is not set
+# CONFIG_HID_PICOLCD is not set
+# CONFIG_HID_PLANTRONICS is not set
+# CONFIG_HID_PRIMAX is not set
+# CONFIG_HID_ROCCAT is not set
+# CONFIG_HID_SAITEK is not set
+# CONFIG_HID_SAMSUNG is not set
+# CONFIG_HID_SPEEDLINK is not set
+# CONFIG_HID_STEELSERIES is not set
+# CONFIG_HID_SUNPLUS is not set
+# CONFIG_HID_RMI is not set
+# CONFIG_HID_GREENASIA is not set
+# CONFIG_HID_SMARTJOYPLUS is not set
+# CONFIG_HID_TIVO is not set
+# CONFIG_HID_TOPSEED is not set
+# CONFIG_HID_THRUSTMASTER is not set
+# CONFIG_HID_WACOM is not set
+# CONFIG_HID_XINMO is not set
+# CONFIG_HID_ZEROPLUS is not set
+# CONFIG_HID_ZYDACRON is not set
+# CONFIG_HID_SENSOR_HUB is not set
+# CONFIG_HID_ALPS is not set
+
+#
+# USB HID support
+#
+CONFIG_USB_HID=y
+# CONFIG_HID_PID is not set
+# CONFIG_USB_HIDDEV is not set
+
+#
+# I2C HID support
+#
+# CONFIG_I2C_HID is not set
+CONFIG_USB_OHCI_LITTLE_ENDIAN=y
+CONFIG_USB_SUPPORT=y
+CONFIG_USB_COMMON=y
+CONFIG_USB_ARCH_HAS_HCD=y
+CONFIG_USB=y
+# CONFIG_USB_ANNOUNCE_NEW_DEVICES is not set
+
+#
+# Miscellaneous USB options
+#
+CONFIG_USB_DEFAULT_PERSIST=y
+# CONFIG_USB_DYNAMIC_MINORS is not set
+# CONFIG_USB_OTG is not set
+# CONFIG_USB_OTG_WHITELIST is not set
+# CONFIG_USB_MON is not set
+# CONFIG_USB_WUSB_CBAF is not set
+
+#
+# USB Host Controller Drivers
+#
+# CONFIG_USB_C67X00_HCD is not set
+# CONFIG_USB_XHCI_HCD is not set
+CONFIG_USB_EHCI_HCD=y
+# CONFIG_USB_EHCI_ROOT_HUB_TT is not set
+CONFIG_USB_EHCI_TT_NEWSCHED=y
+CONFIG_USB_EHCI_HCD_PLATFORM=y
+# CONFIG_USB_OXU210HP_HCD is not set
+# CONFIG_USB_ISP116X_HCD is not set
+# CONFIG_USB_ISP1362_HCD is not set
+# CONFIG_USB_FOTG210_HCD is not set
+CONFIG_USB_OHCI_HCD=y
+CONFIG_USB_OHCI_HCD_PLATFORM=y
+# CONFIG_USB_SL811_HCD is not set
+# CONFIG_USB_R8A66597_HCD is not set
+# CONFIG_USB_HCD_TEST_MODE is not set
+
+#
+# USB Device Class drivers
+#
+# CONFIG_USB_ACM is not set
+# CONFIG_USB_PRINTER is not set
+# CONFIG_USB_WDM is not set
+# CONFIG_USB_TMC is not set
+
+#
+# NOTE: USB_STORAGE depends on SCSI but BLK_DEV_SD may
+#
+
+#
+# also be needed; see USB_STORAGE Help for more info
+#
+CONFIG_USB_STORAGE=y
+# CONFIG_USB_STORAGE_DEBUG is not set
+# CONFIG_USB_STORAGE_REALTEK is not set
+# CONFIG_USB_STORAGE_DATAFAB is not set
+# CONFIG_USB_STORAGE_FREECOM is not set
+# CONFIG_USB_STORAGE_ISD200 is not set
+# CONFIG_USB_STORAGE_USBAT is not set
+# CONFIG_USB_STORAGE_SDDR09 is not set
+# CONFIG_USB_STORAGE_SDDR55 is not set
+# CONFIG_USB_STORAGE_JUMPSHOT is not set
+# CONFIG_USB_STORAGE_ALAUDA is not set
+# CONFIG_USB_STORAGE_ONETOUCH is not set
+# CONFIG_USB_STORAGE_KARMA is not set
+# CONFIG_USB_STORAGE_CYPRESS_ATACB is not set
+# CONFIG_USB_STORAGE_ENE_UB6250 is not set
+# CONFIG_USB_UAS is not set
+
+#
+# USB Imaging devices
+#
+# CONFIG_USB_MDC800 is not set
+# CONFIG_USB_MICROTEK is not set
+# CONFIG_USBIP_CORE is not set
+# CONFIG_USB_MUSB_HDRC is not set
+# CONFIG_USB_DWC3 is not set
+# CONFIG_USB_DWC2 is not set
+# CONFIG_USB_CHIPIDEA is not set
+# CONFIG_USB_ISP1760 is not set
+
+#
+# USB port drivers
+#
+# CONFIG_USB_SERIAL is not set
+
+#
+# USB Miscellaneous drivers
+#
+# CONFIG_USB_EMI62 is not set
+# CONFIG_USB_EMI26 is not set
+# CONFIG_USB_ADUTUX is not set
+# CONFIG_USB_SEVSEG is not set
+# CONFIG_USB_RIO500 is not set
+# CONFIG_USB_LEGOTOWER is not set
+# CONFIG_USB_LCD is not set
+# CONFIG_USB_CYPRESS_CY7C63 is not set
+# CONFIG_USB_CYTHERM is not set
+# CONFIG_USB_IDMOUSE is not set
+# CONFIG_USB_FTDI_ELAN is not set
+# CONFIG_USB_APPLEDISPLAY is not set
+# CONFIG_USB_SISUSBVGA is not set
+# CONFIG_USB_LD is not set
+# CONFIG_USB_TRANCEVIBRATOR is not set
+# CONFIG_USB_IOWARRIOR is not set
+# CONFIG_USB_TEST is not set
+# CONFIG_USB_EHSET_TEST_FIXTURE is not set
+# CONFIG_USB_ISIGHTFW is not set
+# CONFIG_USB_YUREX is not set
+# CONFIG_USB_EZUSB_FX2 is not set
+# CONFIG_USB_HSIC_USB3503 is not set
+# CONFIG_USB_HSIC_USB4604 is not set
+# CONFIG_USB_LINK_LAYER_TEST is not set
+
+#
+# USB Physical Layer drivers
+#
+# CONFIG_USB_PHY is not set
+# CONFIG_NOP_USB_XCEIV is not set
+# CONFIG_USB_GPIO_VBUS is not set
+# CONFIG_USB_ISP1301 is not set
+# CONFIG_USB_ULPI is not set
+# CONFIG_USB_GADGET is not set
+# CONFIG_USB_ULPI_BUS is not set
+# CONFIG_UWB is not set
+# CONFIG_MMC is not set
+# CONFIG_MEMSTICK is not set
+# CONFIG_NEW_LEDS is not set
+# CONFIG_ACCESSIBILITY is not set
+CONFIG_EDAC_ATOMIC_SCRUB=y
+CONFIG_EDAC_SUPPORT=y
+# CONFIG_EDAC is not set
+CONFIG_RTC_LIB=y
+CONFIG_RTC_CLASS=y
+CONFIG_RTC_HCTOSYS=y
+CONFIG_RTC_HCTOSYS_DEVICE="rtc0"
+CONFIG_RTC_SYSTOHC=y
+CONFIG_RTC_SYSTOHC_DEVICE="rtc0"
+# CONFIG_RTC_DEBUG is not set
+
+#
+# RTC interfaces
+#
+CONFIG_RTC_INTF_SYSFS=y
+CONFIG_RTC_INTF_PROC=y
+CONFIG_RTC_INTF_DEV=y
+# CONFIG_RTC_INTF_DEV_UIE_EMUL is not set
+# CONFIG_RTC_DRV_TEST is not set
+
+#
+# I2C RTC drivers
+#
+# CONFIG_RTC_DRV_ABB5ZES3 is not set
+# CONFIG_RTC_DRV_ABX80X is not set
+# CONFIG_RTC_DRV_DS1307 is not set
+# CONFIG_RTC_DRV_DS1374 is not set
+# CONFIG_RTC_DRV_DS1672 is not set
+# CONFIG_RTC_DRV_HYM8563 is not set
+# CONFIG_RTC_DRV_MAX6900 is not set
+# CONFIG_RTC_DRV_RS5C372 is not set
+# CONFIG_RTC_DRV_ISL1208 is not set
+# CONFIG_RTC_DRV_ISL12022 is not set
+# CONFIG_RTC_DRV_X1205 is not set
+# CONFIG_RTC_DRV_PCF8523 is not set
+# CONFIG_RTC_DRV_PCF85063 is not set
+# CONFIG_RTC_DRV_PCF8563 is not set
+# CONFIG_RTC_DRV_PCF8583 is not set
+# CONFIG_RTC_DRV_M41T80 is not set
+# CONFIG_RTC_DRV_BQ32K is not set
+# CONFIG_RTC_DRV_S35390A is not set
+# CONFIG_RTC_DRV_FM3130 is not set
+# CONFIG_RTC_DRV_RX8010 is not set
+# CONFIG_RTC_DRV_RX8581 is not set
+# CONFIG_RTC_DRV_RX8025 is not set
+# CONFIG_RTC_DRV_EM3027 is not set
+# CONFIG_RTC_DRV_RV8803 is not set
+
+#
+# SPI RTC drivers
+#
+CONFIG_RTC_I2C_AND_SPI=y
+
+#
+# SPI and I2C RTC drivers
+#
+# CONFIG_RTC_DRV_DS3232 is not set
+# CONFIG_RTC_DRV_PCF2127 is not set
+# CONFIG_RTC_DRV_RV3029C2 is not set
+
+#
+# Platform RTC drivers
+#
+CONFIG_RTC_DRV_HIBVT=y
+# CONFIG_RTC_DRV_CMOS is not set
+# CONFIG_RTC_DRV_DS1286 is not set
+# CONFIG_RTC_DRV_DS1511 is not set
+# CONFIG_RTC_DRV_DS1553 is not set
+# CONFIG_RTC_DRV_DS1685_FAMILY is not set
+# CONFIG_RTC_DRV_DS1742 is not set
+# CONFIG_RTC_DRV_DS2404 is not set
+# CONFIG_RTC_DRV_STK17TA8 is not set
+# CONFIG_RTC_DRV_M48T86 is not set
+# CONFIG_RTC_DRV_M48T35 is not set
+# CONFIG_RTC_DRV_M48T59 is not set
+# CONFIG_RTC_DRV_MSM6242 is not set
+# CONFIG_RTC_DRV_BQ4802 is not set
+# CONFIG_RTC_DRV_RP5C01 is not set
+# CONFIG_RTC_DRV_V3020 is not set
+# CONFIG_RTC_DRV_ZYNQMP is not set
+
+#
+# on-CPU RTC drivers
+#
+# CONFIG_RTC_DRV_PL030 is not set
+# CONFIG_RTC_DRV_PL031 is not set
+# CONFIG_RTC_DRV_SNVS is not set
+
+#
+# HID Sensor RTC drivers
+#
+# CONFIG_RTC_DRV_HID_SENSOR_TIME is not set
+# CONFIG_DMADEVICES is not set
+
+#
+# DMABUF options
+#
+# CONFIG_SYNC_FILE is not set
+# CONFIG_AUXDISPLAY is not set
+# CONFIG_UIO is not set
+# CONFIG_VIRT_DRIVERS is not set
+
+#
+# Virtio drivers
+#
+# CONFIG_VIRTIO_MMIO is not set
+
+#
+# Microsoft Hyper-V guest support
+#
+# CONFIG_STAGING is not set
+# CONFIG_GOLDFISH is not set
+# CONFIG_CHROME_PLATFORMS is not set
+CONFIG_CLKDEV_LOOKUP=y
+CONFIG_HAVE_CLK_PREPARE=y
+CONFIG_COMMON_CLK=y
+
+#
+# Common Clock Framework
+#
+# CONFIG_COMMON_CLK_SI5351 is not set
+# CONFIG_COMMON_CLK_SI514 is not set
+# CONFIG_COMMON_CLK_SI570 is not set
+# CONFIG_COMMON_CLK_CDCE706 is not set
+# CONFIG_COMMON_CLK_CDCE925 is not set
+# CONFIG_COMMON_CLK_CS2000_CP is not set
+# CONFIG_CLK_QORIQ is not set
+# CONFIG_COMMON_CLK_NXP is not set
+# CONFIG_COMMON_CLK_PXA is not set
+# CONFIG_COMMON_CLK_PIC32 is not set
+CONFIG_COMMON_CLK_HI3536DV100=y
+CONFIG_RESET_HISI=y
+
+#
+# Hardware Spinlock drivers
+#
+
+#
+# Clock Source drivers
+#
+CONFIG_CLKSRC_OF=y
+CONFIG_CLKSRC_PROBE=y
+CONFIG_CLKSRC_MMIO=y
+CONFIG_ARM_ARCH_TIMER=y
+CONFIG_ARM_ARCH_TIMER_EVTSTREAM=y
+CONFIG_ARM_TIMER_SP804=y
+# CONFIG_ATMEL_PIT is not set
+# CONFIG_SH_TIMER_CMT is not set
+# CONFIG_SH_TIMER_MTU2 is not set
+# CONFIG_SH_TIMER_TMU is not set
+# CONFIG_EM_TIMER_STI is not set
+# CONFIG_MAILBOX is not set
+# CONFIG_IOMMU_SUPPORT is not set
+
+#
+# Remoteproc drivers
+#
+# CONFIG_STE_MODEM_RPROC is not set
+
+#
+# Rpmsg drivers
+#
+
+#
+# SOC (System On Chip) specific Drivers
+#
+
+#
+# Broadcom SoC drivers
+#
+# CONFIG_SOC_BRCMSTB is not set
+# CONFIG_SUNXI_SRAM is not set
+# CONFIG_SOC_TI is not set
+# CONFIG_PM_DEVFREQ is not set
+# CONFIG_EXTCON is not set
+# CONFIG_MEMORY is not set
+# CONFIG_IIO is not set
+# CONFIG_PWM is not set
+CONFIG_IRQCHIP=y
+CONFIG_ARM_GIC=y
+CONFIG_ARM_GIC_MAX_NR=1
+# CONFIG_IPACK_BUS is not set
+CONFIG_RESET_CONTROLLER=y
+# CONFIG_RESET_ATH79 is not set
+# CONFIG_RESET_BERLIN is not set
+# CONFIG_RESET_LPC18XX is not set
+# CONFIG_RESET_MESON is not set
+# CONFIG_RESET_PISTACHIO is not set
+# CONFIG_RESET_SOCFPGA is not set
+# CONFIG_RESET_STM32 is not set
+# CONFIG_RESET_SUNXI is not set
+# CONFIG_TI_SYSCON_RESET is not set
+# CONFIG_RESET_ZYNQ is not set
+# CONFIG_FMC is not set
+
+#
+# PHY Subsystem
+#
+CONFIG_GENERIC_PHY=y
+# CONFIG_PHY_PXA_28NM_HSIC is not set
+# CONFIG_PHY_PXA_28NM_USB2 is not set
+# CONFIG_BCM_KONA_USB2_PHY is not set
+CONFIG_PHY_HISI_SATA=y
+CONFIG_HISI_SATA_MODE=1
+CONFIG_PHY_HISI_USB2=y
+# CONFIG_POWERCAP is not set
+# CONFIG_MCB is not set
+
+#
+# Performance monitor support
+#
+# CONFIG_RAS is not set
+
+#
+# Android
+#
+# CONFIG_ANDROID is not set
+# CONFIG_NVMEM is not set
+# CONFIG_STM is not set
+# CONFIG_INTEL_TH is not set
+
+#
+# FPGA Configuration Support
+#
+# CONFIG_FPGA is not set
+CONFIG_HI_DMAC=y
+CONFIG_HI_DMAC_CHANNEL_NUM=4
+
+#
+# Firmware Drivers
+#
+# CONFIG_FIRMWARE_MEMMAP is not set
+# CONFIG_FW_CFG_SYSFS is not set
+CONFIG_HAVE_ARM_SMCCC=y
+
+#
+# File systems
+#
+CONFIG_DCACHE_WORD_ACCESS=y
+CONFIG_EXT2_FS=y
+# CONFIG_EXT2_FS_XATTR is not set
+CONFIG_EXT3_FS=y
+# CONFIG_EXT3_FS_POSIX_ACL is not set
+# CONFIG_EXT3_FS_SECURITY is not set
+CONFIG_EXT4_FS=y
+# CONFIG_EXT4_FS_POSIX_ACL is not set
+# CONFIG_EXT4_FS_SECURITY is not set
+# CONFIG_EXT4_ENCRYPTION is not set
+# CONFIG_EXT4_DEBUG is not set
+CONFIG_JBD2=y
+# CONFIG_JBD2_DEBUG is not set
+CONFIG_FS_MBCACHE=y
+# CONFIG_REISERFS_FS is not set
+# CONFIG_JFS_FS is not set
+# CONFIG_XFS_FS is not set
+# CONFIG_GFS2_FS is not set
+# CONFIG_OCFS2_FS is not set
+# CONFIG_BTRFS_FS is not set
+# CONFIG_NILFS2_FS is not set
+# CONFIG_F2FS_FS is not set
+CONFIG_FS_POSIX_ACL=y
+CONFIG_EXPORTFS=y
+# CONFIG_EXPORTFS_BLOCK_OPS is not set
+CONFIG_FILE_LOCKING=y
+CONFIG_MANDATORY_FILE_LOCKING=y
+# CONFIG_FS_ENCRYPTION is not set
+CONFIG_FSNOTIFY=y
+CONFIG_DNOTIFY=y
+CONFIG_INOTIFY_USER=y
+# CONFIG_FANOTIFY is not set
+# CONFIG_QUOTA is not set
+# CONFIG_QUOTACTL is not set
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_FUSE_FS is not set
+# CONFIG_OVERLAY_FS is not set
+
+#
+# Caches
+#
+# CONFIG_FSCACHE is not set
+
+#
+# CD-ROM/DVD Filesystems
+#
+CONFIG_ISO9660_FS=y
+# CONFIG_JOLIET is not set
+# CONFIG_ZISOFS is not set
+# CONFIG_UDF_FS is not set
+
+#
+# DOS/FAT/NT Filesystems
+#
+CONFIG_FAT_FS=y
+CONFIG_MSDOS_FS=y
+CONFIG_VFAT_FS=y
+CONFIG_FAT_DEFAULT_CODEPAGE=437
+CONFIG_FAT_DEFAULT_IOCHARSET="iso8859-1"
+# CONFIG_FAT_DEFAULT_UTF8 is not set
+# CONFIG_NTFS_FS is not set
+
+#
+# Pseudo filesystems
+#
+CONFIG_PROC_FS=y
+CONFIG_PROC_SYSCTL=y
+CONFIG_PROC_PAGE_MONITOR=y
+# CONFIG_PROC_CHILDREN is not set
+CONFIG_KERNFS=y
+CONFIG_SYSFS=y
+CONFIG_TMPFS=y
+CONFIG_TMPFS_POSIX_ACL=y
+CONFIG_TMPFS_XATTR=y
+# CONFIG_HUGETLB_PAGE is not set
+CONFIG_CONFIGFS_FS=m
+CONFIG_MISC_FILESYSTEMS=y
+# CONFIG_ORANGEFS_FS is not set
+# CONFIG_ADFS_FS is not set
+# CONFIG_AFFS_FS is not set
+# CONFIG_ECRYPT_FS is not set
+# CONFIG_HFS_FS is not set
+# CONFIG_HFSPLUS_FS is not set
+# CONFIG_BEFS_FS is not set
+# CONFIG_BFS_FS is not set
+# CONFIG_EFS_FS is not set
+CONFIG_YAFFS_FS=y
+CONFIG_YAFFS_YAFFS1=y
+# CONFIG_YAFFS_9BYTE_TAGS is not set
+# CONFIG_YAFFS_DOES_ECC is not set
+CONFIG_YAFFS_YAFFS2=y
+CONFIG_YAFFS_AUTO_YAFFS2=y
+# CONFIG_YAFFS_DISABLE_TAGS_ECC is not set
+# CONFIG_YAFFS_ALWAYS_CHECK_CHUNK_ERASED is not set
+# CONFIG_YAFFS_EMPTY_LOST_AND_FOUND is not set
+# CONFIG_YAFFS_DISABLE_BLOCK_REFRESHING is not set
+# CONFIG_YAFFS_DISABLE_BACKGROUND is not set
+# CONFIG_YAFFS_DISABLE_BAD_BLOCK_MARKING is not set
+CONFIG_YAFFS_XATTR=y
+CONFIG_JFFS2_FS=y
+CONFIG_JFFS2_FS_DEBUG=0
+CONFIG_JFFS2_FS_WRITEBUFFER=y
+# CONFIG_JFFS2_FS_WBUF_VERIFY is not set
+# CONFIG_JFFS2_SUMMARY is not set
+# CONFIG_JFFS2_FS_XATTR is not set
+# CONFIG_JFFS2_COMPRESSION_OPTIONS is not set
+CONFIG_JFFS2_ZLIB=y
+# CONFIG_JFFS2_LZO is not set
+CONFIG_JFFS2_RTIME=y
+# CONFIG_JFFS2_RUBIN is not set
+CONFIG_UBIFS_FS=y
+# CONFIG_UBIFS_FS_ADVANCED_COMPR is not set
+CONFIG_UBIFS_FS_LZO=y
+CONFIG_UBIFS_FS_ZLIB=y
+# CONFIG_UBIFS_ATIME_SUPPORT is not set
+# CONFIG_LOGFS is not set
+CONFIG_CRAMFS=y
+# CONFIG_SQUASHFS is not set
+# CONFIG_VXFS_FS is not set
+# CONFIG_MINIX_FS is not set
+# CONFIG_OMFS_FS is not set
+# CONFIG_HPFS_FS is not set
+# CONFIG_QNX4FS_FS is not set
+# CONFIG_QNX6FS_FS is not set
+# CONFIG_ROMFS_FS is not set
+# CONFIG_PSTORE is not set
+# CONFIG_SYSV_FS is not set
+# CONFIG_UFS_FS is not set
+CONFIG_NETWORK_FILESYSTEMS=y
+CONFIG_NFS_FS=y
+CONFIG_NFS_V2=y
+CONFIG_NFS_V3=y
+CONFIG_NFS_V3_ACL=y
+CONFIG_NFS_V4=y
+# CONFIG_NFS_SWAP is not set
+# CONFIG_NFS_V4_1 is not set
+CONFIG_ROOT_NFS=y
+# CONFIG_NFS_USE_LEGACY_DNS is not set
+CONFIG_NFS_USE_KERNEL_DNS=y
+# CONFIG_NFSD is not set
+CONFIG_GRACE_PERIOD=y
+CONFIG_LOCKD=y
+CONFIG_LOCKD_V4=y
+CONFIG_NFS_ACL_SUPPORT=y
+CONFIG_NFS_COMMON=y
+CONFIG_SUNRPC=y
+CONFIG_SUNRPC_GSS=y
+# CONFIG_SUNRPC_DEBUG is not set
+# CONFIG_CEPH_FS is not set
+# CONFIG_CIFS is not set
+# CONFIG_NCP_FS is not set
+# CONFIG_CODA_FS is not set
+# CONFIG_AFS_FS is not set
+CONFIG_NLS=y
+CONFIG_NLS_DEFAULT="iso8859-1"
+CONFIG_NLS_CODEPAGE_437=y
+CONFIG_NLS_CODEPAGE_737=m
+CONFIG_NLS_CODEPAGE_775=m
+CONFIG_NLS_CODEPAGE_850=m
+CONFIG_NLS_CODEPAGE_852=m
+CONFIG_NLS_CODEPAGE_855=m
+CONFIG_NLS_CODEPAGE_857=m
+CONFIG_NLS_CODEPAGE_860=m
+CONFIG_NLS_CODEPAGE_861=m
+CONFIG_NLS_CODEPAGE_862=m
+CONFIG_NLS_CODEPAGE_863=m
+CONFIG_NLS_CODEPAGE_864=m
+CONFIG_NLS_CODEPAGE_865=m
+CONFIG_NLS_CODEPAGE_866=m
+CONFIG_NLS_CODEPAGE_869=m
+CONFIG_NLS_CODEPAGE_936=y
+CONFIG_NLS_CODEPAGE_950=m
+CONFIG_NLS_CODEPAGE_932=m
+CONFIG_NLS_CODEPAGE_949=m
+CONFIG_NLS_CODEPAGE_874=m
+CONFIG_NLS_ISO8859_8=m
+CONFIG_NLS_CODEPAGE_1250=m
+CONFIG_NLS_CODEPAGE_1251=m
+CONFIG_NLS_ASCII=y
+CONFIG_NLS_ISO8859_1=y
+CONFIG_NLS_ISO8859_2=m
+CONFIG_NLS_ISO8859_3=m
+CONFIG_NLS_ISO8859_4=m
+CONFIG_NLS_ISO8859_5=m
+CONFIG_NLS_ISO8859_6=m
+CONFIG_NLS_ISO8859_7=m
+CONFIG_NLS_ISO8859_9=m
+CONFIG_NLS_ISO8859_13=m
+CONFIG_NLS_ISO8859_14=m
+CONFIG_NLS_ISO8859_15=m
+CONFIG_NLS_KOI8_R=m
+CONFIG_NLS_KOI8_U=m
+# CONFIG_NLS_MAC_ROMAN is not set
+# CONFIG_NLS_MAC_CELTIC is not set
+# CONFIG_NLS_MAC_CENTEURO is not set
+# CONFIG_NLS_MAC_CROATIAN is not set
+# CONFIG_NLS_MAC_CYRILLIC is not set
+# CONFIG_NLS_MAC_GAELIC is not set
+# CONFIG_NLS_MAC_GREEK is not set
+# CONFIG_NLS_MAC_ICELAND is not set
+# CONFIG_NLS_MAC_INUIT is not set
+# CONFIG_NLS_MAC_ROMANIAN is not set
+# CONFIG_NLS_MAC_TURKISH is not set
+CONFIG_NLS_UTF8=y
+# CONFIG_DLM is not set
+
+#
+# Kernel hacking
+#
+
+#
+# printk and dmesg options
+#
+# CONFIG_PRINTK_TIME is not set
+CONFIG_MESSAGE_LOGLEVEL_DEFAULT=4
+# CONFIG_BOOT_PRINTK_DELAY is not set
+
+#
+# Compile-time checks and compiler options
+#
+# CONFIG_DEBUG_INFO is not set
+# CONFIG_ENABLE_WARN_DEPRECATED is not set
+# CONFIG_ENABLE_MUST_CHECK is not set
+CONFIG_FRAME_WARN=1024
+# CONFIG_STRIP_ASM_SYMS is not set
+# CONFIG_READABLE_ASM is not set
+# CONFIG_UNUSED_SYMBOLS is not set
+# CONFIG_PAGE_OWNER is not set
+# CONFIG_DEBUG_FS is not set
+# CONFIG_HEADERS_CHECK is not set
+# CONFIG_DEBUG_SECTION_MISMATCH is not set
+CONFIG_SECTION_MISMATCH_WARN_ONLY=y
+CONFIG_FRAME_POINTER=y
+# CONFIG_DEBUG_FORCE_WEAK_PER_CPU is not set
+# CONFIG_MAGIC_SYSRQ is not set
+CONFIG_DEBUG_KERNEL=y
+
+#
+# Memory Debugging
+#
+# CONFIG_PAGE_EXTENSION is not set
+# CONFIG_PAGE_POISONING is not set
+# CONFIG_DEBUG_OBJECTS is not set
+# CONFIG_SLUB_DEBUG_ON is not set
+# CONFIG_SLUB_STATS is not set
+CONFIG_HAVE_DEBUG_KMEMLEAK=y
+# CONFIG_DEBUG_KMEMLEAK is not set
+# CONFIG_DEBUG_STACK_USAGE is not set
+# CONFIG_DEBUG_VM is not set
+CONFIG_DEBUG_MEMORY_INIT=y
+# CONFIG_DEBUG_SHIRQ is not set
+
+#
+# Debug Lockups and Hangs
+#
+# CONFIG_LOCKUP_DETECTOR is not set
+# CONFIG_DETECT_HUNG_TASK is not set
+# CONFIG_WQ_WATCHDOG is not set
+# CONFIG_PANIC_ON_OOPS is not set
+CONFIG_PANIC_ON_OOPS_VALUE=0
+CONFIG_PANIC_TIMEOUT=0
+# CONFIG_SCHED_DEBUG is not set
+# CONFIG_SCHED_INFO is not set
+# CONFIG_SCHEDSTATS is not set
+# CONFIG_SCHED_STACK_END_CHECK is not set
+# CONFIG_DEBUG_TIMEKEEPING is not set
+# CONFIG_TIMER_STATS is not set
+
+#
+# Lock Debugging (spinlocks, mutexes, etc...)
+#
+# CONFIG_DEBUG_RT_MUTEXES is not set
+# CONFIG_DEBUG_SPINLOCK is not set
+CONFIG_DEBUG_MUTEXES=y
+# CONFIG_DEBUG_WW_MUTEX_SLOWPATH is not set
+# CONFIG_DEBUG_LOCK_ALLOC is not set
+# CONFIG_PROVE_LOCKING is not set
+# CONFIG_LOCK_STAT is not set
+# CONFIG_DEBUG_ATOMIC_SLEEP is not set
+# CONFIG_DEBUG_LOCKING_API_SELFTESTS is not set
+# CONFIG_LOCK_TORTURE_TEST is not set
+CONFIG_STACKTRACE=y
+# CONFIG_DEBUG_KOBJECT is not set
+CONFIG_DEBUG_BUGVERBOSE=y
+# CONFIG_DEBUG_LIST is not set
+# CONFIG_DEBUG_PI_LIST is not set
+# CONFIG_DEBUG_SG is not set
+# CONFIG_DEBUG_NOTIFIERS is not set
+# CONFIG_DEBUG_CREDENTIALS is not set
+
+#
+# RCU Debugging
+#
+# CONFIG_PROVE_RCU is not set
+# CONFIG_SPARSE_RCU_POINTER is not set
+# CONFIG_TORTURE_TEST is not set
+# CONFIG_RCU_PERF_TEST is not set
+# CONFIG_RCU_TORTURE_TEST is not set
+# CONFIG_RCU_TRACE is not set
+# CONFIG_RCU_EQS_DEBUG is not set
+# CONFIG_DEBUG_WQ_FORCE_RR_CPU is not set
+# CONFIG_DEBUG_BLOCK_EXT_DEVT is not set
+# CONFIG_NOTIFIER_ERROR_INJECTION is not set
+# CONFIG_FAULT_INJECTION is not set
+# CONFIG_LATENCYTOP is not set
+CONFIG_HAVE_FUNCTION_TRACER=y
+CONFIG_HAVE_FUNCTION_GRAPH_TRACER=y
+CONFIG_HAVE_DYNAMIC_FTRACE=y
+CONFIG_HAVE_FTRACE_MCOUNT_RECORD=y
+CONFIG_HAVE_SYSCALL_TRACEPOINTS=y
+CONFIG_HAVE_C_RECORDMCOUNT=y
+CONFIG_TRACING_SUPPORT=y
+# CONFIG_FTRACE is not set
+
+#
+# Runtime Testing
+#
+# CONFIG_TEST_LIST_SORT is not set
+# CONFIG_BACKTRACE_SELF_TEST is not set
+# CONFIG_RBTREE_TEST is not set
+# CONFIG_INTERVAL_TREE_TEST is not set
+# CONFIG_PERCPU_TEST is not set
+# CONFIG_ATOMIC64_SELFTEST is not set
+# CONFIG_TEST_HEXDUMP is not set
+# CONFIG_TEST_STRING_HELPERS is not set
+# CONFIG_TEST_KSTRTOX is not set
+# CONFIG_TEST_PRINTF is not set
+# CONFIG_TEST_BITMAP is not set
+# CONFIG_TEST_UUID is not set
+# CONFIG_TEST_RHASHTABLE is not set
+# CONFIG_TEST_HASH is not set
+# CONFIG_DMA_API_DEBUG is not set
+# CONFIG_TEST_LKM is not set
+# CONFIG_TEST_USER_COPY is not set
+# CONFIG_TEST_BPF is not set
+# CONFIG_TEST_FIRMWARE is not set
+# CONFIG_TEST_UDELAY is not set
+# CONFIG_MEMTEST is not set
+# CONFIG_TEST_STATIC_KEYS is not set
+# CONFIG_SAMPLES is not set
+CONFIG_HAVE_ARCH_KGDB=y
+# CONFIG_KGDB is not set
+# CONFIG_ARCH_WANTS_UBSAN_NO_NULL is not set
+# CONFIG_UBSAN is not set
+CONFIG_ARCH_HAS_DEVMEM_IS_ALLOWED=y
+CONFIG_STRICT_DEVMEM=y
+# CONFIG_IO_STRICT_DEVMEM is not set
+# CONFIG_ARM_PTDUMP is not set
+# CONFIG_ARM_UNWIND is not set
+# CONFIG_DEBUG_USER is not set
+# CONFIG_DEBUG_LL is not set
+CONFIG_DEBUG_LL_INCLUDE="mach/debug-macro.S"
+# CONFIG_DEBUG_UART_8250 is not set
+CONFIG_UNCOMPRESS_INCLUDE="debug/uncompress.h"
+# CONFIG_PID_IN_CONTEXTIDR is not set
+# CONFIG_DEBUG_SET_MODULE_RONX is not set
+# CONFIG_CORESIGHT is not set
+
+#
+# Security options
+#
+CONFIG_KEYS=y
+# CONFIG_PERSISTENT_KEYRINGS is not set
+# CONFIG_ENCRYPTED_KEYS is not set
+# CONFIG_KEY_DH_OPERATIONS is not set
+# CONFIG_SECURITY_DMESG_RESTRICT is not set
+# CONFIG_SECURITY is not set
+# CONFIG_SECURITYFS is not set
+CONFIG_HAVE_HARDENED_USERCOPY_ALLOCATOR=y
+CONFIG_HAVE_ARCH_HARDENED_USERCOPY=y
+# CONFIG_HARDENED_USERCOPY is not set
+CONFIG_DEFAULT_SECURITY_DAC=y
+CONFIG_DEFAULT_SECURITY=""
+CONFIG_CRYPTO=y
+
+#
+# Crypto core or helper
+#
+CONFIG_CRYPTO_ALGAPI=y
+CONFIG_CRYPTO_ALGAPI2=y
+CONFIG_CRYPTO_AEAD=m
+CONFIG_CRYPTO_AEAD2=y
+CONFIG_CRYPTO_BLKCIPHER=y
+CONFIG_CRYPTO_BLKCIPHER2=y
+CONFIG_CRYPTO_HASH=y
+CONFIG_CRYPTO_HASH2=y
+CONFIG_CRYPTO_RNG=m
+CONFIG_CRYPTO_RNG2=y
+CONFIG_CRYPTO_RNG_DEFAULT=m
+CONFIG_CRYPTO_AKCIPHER2=y
+CONFIG_CRYPTO_KPP2=y
+# CONFIG_CRYPTO_RSA is not set
+# CONFIG_CRYPTO_DH is not set
+# CONFIG_CRYPTO_ECDH is not set
+CONFIG_CRYPTO_MANAGER=m
+CONFIG_CRYPTO_MANAGER2=y
+# CONFIG_CRYPTO_USER is not set
+CONFIG_CRYPTO_MANAGER_DISABLE_TESTS=y
+CONFIG_CRYPTO_GF128MUL=m
+CONFIG_CRYPTO_NULL=m
+CONFIG_CRYPTO_NULL2=y
+CONFIG_CRYPTO_WORKQUEUE=y
+# CONFIG_CRYPTO_CRYPTD is not set
+# CONFIG_CRYPTO_MCRYPTD is not set
+# CONFIG_CRYPTO_AUTHENC is not set
+# CONFIG_CRYPTO_TEST is not set
+
+#
+# Authenticated Encryption with Associated Data
+#
+CONFIG_CRYPTO_CCM=m
+CONFIG_CRYPTO_GCM=m
+# CONFIG_CRYPTO_CHACHA20POLY1305 is not set
+CONFIG_CRYPTO_SEQIV=m
+CONFIG_CRYPTO_ECHAINIV=m
+
+#
+# Block modes
+#
+# CONFIG_CRYPTO_CBC is not set
+CONFIG_CRYPTO_CTR=m
+# CONFIG_CRYPTO_CTS is not set
+# CONFIG_CRYPTO_ECB is not set
+# CONFIG_CRYPTO_LRW is not set
+# CONFIG_CRYPTO_PCBC is not set
+# CONFIG_CRYPTO_XTS is not set
+# CONFIG_CRYPTO_KEYWRAP is not set
+
+#
+# Hash modes
+#
+# CONFIG_CRYPTO_CMAC is not set
+CONFIG_CRYPTO_HMAC=m
+# CONFIG_CRYPTO_XCBC is not set
+# CONFIG_CRYPTO_VMAC is not set
+
+#
+# Digest
+#
+CONFIG_CRYPTO_CRC32C=y
+# CONFIG_CRYPTO_CRC32 is not set
+CONFIG_CRYPTO_CRCT10DIF=y
+CONFIG_CRYPTO_GHASH=m
+# CONFIG_CRYPTO_POLY1305 is not set
+# CONFIG_CRYPTO_MD4 is not set
+CONFIG_CRYPTO_MD5=y
+# CONFIG_CRYPTO_MICHAEL_MIC is not set
+# CONFIG_CRYPTO_RMD128 is not set
+# CONFIG_CRYPTO_RMD160 is not set
+# CONFIG_CRYPTO_RMD256 is not set
+# CONFIG_CRYPTO_RMD320 is not set
+CONFIG_CRYPTO_SHA1=y
+CONFIG_CRYPTO_SHA256=y
+# CONFIG_CRYPTO_SHA512 is not set
+# CONFIG_CRYPTO_SHA3 is not set
+# CONFIG_CRYPTO_TGR192 is not set
+# CONFIG_CRYPTO_WP512 is not set
+
+#
+# Ciphers
+#
+CONFIG_CRYPTO_AES=y
+# CONFIG_CRYPTO_ANUBIS is not set
+CONFIG_CRYPTO_ARC4=y
+# CONFIG_CRYPTO_BLOWFISH is not set
+# CONFIG_CRYPTO_CAMELLIA is not set
+# CONFIG_CRYPTO_CAST5 is not set
+# CONFIG_CRYPTO_CAST6 is not set
+# CONFIG_CRYPTO_DES is not set
+# CONFIG_CRYPTO_FCRYPT is not set
+# CONFIG_CRYPTO_KHAZAD is not set
+# CONFIG_CRYPTO_SALSA20 is not set
+# CONFIG_CRYPTO_CHACHA20 is not set
+# CONFIG_CRYPTO_SEED is not set
+# CONFIG_CRYPTO_SERPENT is not set
+# CONFIG_CRYPTO_TEA is not set
+# CONFIG_CRYPTO_TWOFISH is not set
+
+#
+# Compression
+#
+CONFIG_CRYPTO_DEFLATE=y
+CONFIG_CRYPTO_LZO=y
+# CONFIG_CRYPTO_842 is not set
+# CONFIG_CRYPTO_LZ4 is not set
+# CONFIG_CRYPTO_LZ4HC is not set
+
+#
+# Random Number Generation
+#
+# CONFIG_CRYPTO_ANSI_CPRNG is not set
+CONFIG_CRYPTO_DRBG_MENU=m
+CONFIG_CRYPTO_DRBG_HMAC=y
+# CONFIG_CRYPTO_DRBG_HASH is not set
+# CONFIG_CRYPTO_DRBG_CTR is not set
+CONFIG_CRYPTO_DRBG=m
+CONFIG_CRYPTO_JITTERENTROPY=m
+# CONFIG_CRYPTO_USER_API_HASH is not set
+# CONFIG_CRYPTO_USER_API_SKCIPHER is not set
+# CONFIG_CRYPTO_USER_API_RNG is not set
+# CONFIG_CRYPTO_USER_API_AEAD is not set
+# CONFIG_CRYPTO_HW is not set
+# CONFIG_ASYMMETRIC_KEY_TYPE is not set
+
+#
+# Certificates for signature checking
+#
+# CONFIG_ARM_CRYPTO is not set
+# CONFIG_BINARY_PRINTF is not set
+
+#
+# Library routines
+#
+CONFIG_BITREVERSE=y
+CONFIG_HAVE_ARCH_BITREVERSE=y
+CONFIG_RATIONAL=y
+CONFIG_GENERIC_STRNCPY_FROM_USER=y
+CONFIG_GENERIC_STRNLEN_USER=y
+CONFIG_GENERIC_NET_UTILS=y
+CONFIG_GENERIC_PCI_IOMAP=y
+CONFIG_GENERIC_IO=y
+CONFIG_ARCH_USE_CMPXCHG_LOCKREF=y
+CONFIG_CRC_CCITT=y
+CONFIG_CRC16=y
+CONFIG_CRC_T10DIF=y
+CONFIG_CRC_ITU_T=y
+CONFIG_CRC32=y
+# CONFIG_CRC32_SELFTEST is not set
+CONFIG_CRC32_SLICEBY8=y
+# CONFIG_CRC32_SLICEBY4 is not set
+# CONFIG_CRC32_SARWATE is not set
+# CONFIG_CRC32_BIT is not set
+# CONFIG_CRC7 is not set
+CONFIG_LIBCRC32C=y
+# CONFIG_CRC8 is not set
+# CONFIG_AUDIT_ARCH_COMPAT_GENERIC is not set
+# CONFIG_RANDOM32_SELFTEST is not set
+CONFIG_ZLIB_INFLATE=y
+CONFIG_ZLIB_DEFLATE=y
+CONFIG_LZO_COMPRESS=y
+CONFIG_LZO_DECOMPRESS=y
+CONFIG_LZ4_DECOMPRESS=y
+CONFIG_XZ_DEC=y
+CONFIG_XZ_DEC_X86=y
+CONFIG_XZ_DEC_POWERPC=y
+CONFIG_XZ_DEC_IA64=y
+CONFIG_XZ_DEC_ARM=y
+CONFIG_XZ_DEC_ARMTHUMB=y
+CONFIG_XZ_DEC_SPARC=y
+CONFIG_XZ_DEC_BCJ=y
+# CONFIG_XZ_DEC_TEST is not set
+CONFIG_DECOMPRESS_GZIP=y
+CONFIG_DECOMPRESS_LZ4=y
+CONFIG_GENERIC_ALLOCATOR=y
+CONFIG_ASSOCIATIVE_ARRAY=y
+CONFIG_HAS_IOMEM=y
+CONFIG_HAS_IOPORT_MAP=y
+CONFIG_HAS_DMA=y
+CONFIG_DQL=y
+CONFIG_GLOB=y
+# CONFIG_GLOB_SELFTEST is not set
+CONFIG_NLATTR=y
+# CONFIG_CORDIC is not set
+# CONFIG_DDR is not set
+# CONFIG_IRQ_POLL is not set
+CONFIG_LIBFDT=y
+CONFIG_OID_REGISTRY=y
+# CONFIG_SG_SPLIT is not set
+CONFIG_SG_POOL=y
+CONFIG_ARCH_HAS_SG_CHAIN=y
+CONFIG_SBITMAP=y
+# CONFIG_VIRTUALIZATION is not set
diff --git a/arch/arm/mach-hibvt/Kconfig b/arch/arm/mach-hibvt/Kconfig
new file mode 100644
index 0000000..ac0db1c
--- /dev/null
+++ b/arch/arm/mach-hibvt/Kconfig
@@ -0,0 +1,46 @@
+config ARCH_HISI_BVT
+	bool "Hisilicon BVT SoC Support"
+	select ARM_AMBA
+	select ARM_GIC
+	select ARM_TIMER_SP804
+	select POWER_RESET
+	select POWER_RESET_HISI
+	select POWER_SUPPLY
+
+if ARCH_HISI_BVT
+
+menu "Hisilicon BVT platform type"
+
+config HI_ZRELADDR
+       hex 'zreladdr'
+       default "0x80008000"
+
+config HI_PARAMS_PHYS
+       hex 'params_phys'
+       default "0x00000100"
+
+config HI_INITRD_PHYS
+       hex 'initrd_phys'
+       default "0x00800000"
+
+config ARCH_HI3516A
+	bool "Hisilicon Hi3516A Cortex-A7(Single) family"
+	select HAVE_ARM_ARCH_TIMER
+	select ARM_GIC
+	select ARCH_HAS_RESET_CONTROLLER
+	select RESET_CONTROLLER
+	select ARCH_MULTI_V7
+	help
+		Support for Hisilicon Hi3516A Soc family.
+
+config ARCH_HI3536DV100
+	bool "Hisilicon Hi3536DV100 Cortex-A7(Single) family"
+	depends on ARCH_MULTI_V7
+	select HAVE_ARM_ARCH_TIMER
+	select PINCTRL
+	help
+		Support for Hisilicon Hi3536DV100 Soc family.
+
+endmenu
+
+endif
diff --git a/arch/arm/mach-hibvt/Makefile b/arch/arm/mach-hibvt/Makefile
new file mode 100644
index 0000000..680a8a8
--- /dev/null
+++ b/arch/arm/mach-hibvt/Makefile
@@ -0,0 +1,6 @@
+#
+# Makefile for Hisilicon processors family
+#
+
+obj-$(CONFIG_ARCH_HI3516A) += mach-hi3516a.o
+obj-$(CONFIG_ARCH_HI3536DV100) += mach-hi3536dv100.o
diff --git a/arch/arm/mach-hibvt/Makefile.boot b/arch/arm/mach-hibvt/Makefile.boot
new file mode 100644
index 0000000..be34718
--- /dev/null
+++ b/arch/arm/mach-hibvt/Makefile.boot
@@ -0,0 +1,3 @@
+zreladdr-$(CONFIG_ARCH_HISI_BVT)      := $(CONFIG_HI_ZRELADDR)
+params_phys-$(CONFIG_ARCH_HISI_BVT)   := $(CONFIG_HI_PARAMS_PHYS)
+initrd_phys-$(CONFIG_ARCH_HISI_BVT)   := $(CONFIG_HI_INITRD_PHYS)
diff --git a/arch/arm/mach-hibvt/include/mach/hi3516a_io.h b/arch/arm/mach-hibvt/include/mach/hi3516a_io.h
new file mode 100644
index 0000000..7654fb7
--- /dev/null
+++ b/arch/arm/mach-hibvt/include/mach/hi3516a_io.h
@@ -0,0 +1,25 @@
+#ifndef __HI3516A_IO_H
+#define __HI3516A_IO_H
+
+/*
+ * phy: 0x20000000 ~ 0x20700000
+ * vir: 0xFE100000 ~ 0xFE800000
+ */
+#define HI3516A_IOCH2_PHYS  0x20000000
+#define IO_OFFSET_HIGH      0xDE100000
+#define HI3516A_IOCH2_VIRT (HI3516A_IOCH2_PHYS + IO_OFFSET_HIGH)
+#define HI3516A_IOCH2_SIZE 0x700000
+
+/* phy: 0x10000000 ~ 0x100D0000
+ * vir: 0xFE000000 ~ 0xFE0D0000
+ */
+#define HI3516A_IOCH1_PHYS  0x10000000
+#define IO_OFFSET_LOW       0xEE000000
+#define HI3516A_IOCH1_VIRT (HI3516A_IOCH1_PHYS + IO_OFFSET_LOW)
+#define HI3516A_IOCH1_SIZE 0xD0000
+
+#define IO_ADDRESS(x) ((x) >= HI3516A_IOCH2_PHYS ? (x) + IO_OFFSET_HIGH \
+		                        : (x) + IO_OFFSET_LOW)
+#endif
+
+
diff --git a/arch/arm/mach-hibvt/include/mach/hi3536dv100_io.h b/arch/arm/mach-hibvt/include/mach/hi3536dv100_io.h
new file mode 100644
index 0000000..6135e75
--- /dev/null
+++ b/arch/arm/mach-hibvt/include/mach/hi3536dv100_io.h
@@ -0,0 +1,44 @@
+#ifndef __HI3536DV100_IO_H
+#define __HI3536DV100_IO_H
+
+/*  phys_addr		virt_addr
+ *  0x1100_0000 <-----> 0xFE00_0000
+ *  0x1104_0000 <-----> 0xFE04_0000
+ */
+#define HI3536DV100_IOCH1_VIRT (0xFE000000)
+#define HI3536DV100_IOCH1_PHYS (0x11000000)
+#define HI3536DV100_IOCH1_SIZE (0x00040000)
+
+/* phys_addr        virt_addr
+ * 0x1200_0000 <-----> 0xFE10_0000
+ * 0x121B_0000 <-----> 0xFE2B_0000
+ */
+#define HI3536DV100_IOCH2_VIRT (0xFE100000)
+#define HI3536DV100_IOCH2_PHYS (0x12000000)
+#define HI3536DV100_IOCH2_SIZE (0x001B0000)
+
+/* phys_addr        virt_addr
+ * 0x1300_0000 <-----> 0xFE30_0000
+ * 0x1321_0000 <-----> 0xFE51_0000
+ */
+#define HI3536DV100_IOCH3_VIRT (0xFE300000)
+#define HI3536DV100_IOCH3_PHYS (0x13000000)
+#define HI3536DV100_IOCH3_SIZE (0x00210000)
+
+#define IO_OFFSET_LOW		(0xEB300000)
+#define IO_OFFSET_MID		(0xEC100000)
+#define IO_OFFSET_HIGH		(0xED000000)
+
+#define IO_ADDRESS_LOW(x)	((x) + IO_OFFSET_LOW)
+#define IO_ADDRESS_MID(x)	((x) + IO_OFFSET_MID)
+#define IO_ADDRESS_HIGH(x)	((x) + IO_OFFSET_HIGH)
+
+#define __IO_ADDRESS_HIGH(x) ((x >= HI3536DV100_IOCH2_PHYS) ? IO_ADDRESS_MID(x) \
+				: IO_ADDRESS_HIGH(x))
+#define IO_ADDRESS(x)   ((x) >= HI3536DV100_IOCH3_PHYS ? IO_ADDRESS_LOW(x) \
+				: __IO_ADDRESS_HIGH(x))
+
+#define __io_address(x) (IOMEM(IO_ADDRESS(x)))
+
+#endif
+
diff --git a/arch/arm/mach-hibvt/include/mach/hi3536dv100_platform.h b/arch/arm/mach-hibvt/include/mach/hi3536dv100_platform.h
new file mode 100644
index 0000000..bf21bc5
--- /dev/null
+++ b/arch/arm/mach-hibvt/include/mach/hi3536dv100_platform.h
@@ -0,0 +1,14 @@
+#ifndef __HISI_CHIP_REGS_H__
+#define __HISI_CHIP_REGS_H__
+
+/* -------------------------------------------------------------------- */
+/* Clock and Reset Generator REG */
+/* -------------------------------------------------------------------- */
+#define REG_CRG_BASE		0x12040000
+
+/* -------------------------------------------------------------------- */
+/* Misc control REG */
+/* -------------------------------------------------------------------- */
+#define REG_MISC_CTRL_BASE  0x12120000
+
+#endif /* End of __HISI_CHIP_REGS_H__ */
diff --git a/arch/arm/mach-hibvt/include/mach/io.h b/arch/arm/mach-hibvt/include/mach/io.h
new file mode 100644
index 0000000..07abf1c
--- /dev/null
+++ b/arch/arm/mach-hibvt/include/mach/io.h
@@ -0,0 +1,12 @@
+#ifndef __ASM_ARM_ARCH_IO_H
+#define __ASM_ARM_ARCH_IO_H
+
+#ifdef CONFIG_ARCH_HI3516A
+#include <mach/hi3516a_io.h>
+#endif
+
+#ifdef CONFIG_ARCH_HI3536DV100
+#include <mach/hi3536dv100_io.h>
+#endif
+
+#endif
diff --git a/arch/arm/mach-hibvt/include/mach/platform.h b/arch/arm/mach-hibvt/include/mach/platform.h
new file mode 100644
index 0000000..00ac02f
--- /dev/null
+++ b/arch/arm/mach-hibvt/include/mach/platform.h
@@ -0,0 +1,8 @@
+#ifndef __HISI_PLATFORM_H__
+#define __HISI_PLATFORM_H__
+
+#ifdef CONFIG_ARCH_HI3536DV100
+#include <mach/hi3536dv100_platform.h>
+#endif
+
+#endif /* End of __HISI_PLATFORM_H__ */
diff --git a/arch/arm/mach-hibvt/mach-hi3516a.c b/arch/arm/mach-hibvt/mach-hi3516a.c
new file mode 100644
index 0000000..ed49f25
--- /dev/null
+++ b/arch/arm/mach-hibvt/mach-hi3516a.c
@@ -0,0 +1,65 @@
+/*
+ * Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program. If not, see <http://www.gnu.org/licenses/>.
+ *
+*/
+
+#include <linux/clocksource.h>
+#include <linux/irqchip.h>
+
+#include <asm/mach/arch.h>
+#include <asm/mach/map.h>
+#include <mach/io.h>
+
+/*
+ * This table is only for optimization. Since ioremap() could always share
+ * the same mapping if it's defined as static IO mapping.
+ *
+ * Without this table, system could also work. The cost is some virtual address
+ * spaces wasted since ioremap() may be called multi times for the same
+ * IO space.
+ */
+static struct map_desc hi3516a_io_desc[] __initdata = {
+	{
+		/* hi3516a_IOCH1 */
+		.pfn		= __phys_to_pfn(HI3516A_IOCH1_PHYS),
+		.virtual	= HI3516A_IOCH1_VIRT,
+		.length		= HI3516A_IOCH1_SIZE,
+		.type		= MT_DEVICE,
+	},
+	{
+		/* hi3516a_IOCH2 */
+		.pfn		= __phys_to_pfn(HI3516A_IOCH2_PHYS),
+		.virtual	= HI3516A_IOCH2_VIRT,
+		.length		= HI3516A_IOCH2_SIZE,
+		.type		= MT_DEVICE,
+	},
+};
+
+static void __init hi3516a_map_io(void)
+{
+	/* debug_ll_io_init(); */
+	iotable_init(hi3516a_io_desc, ARRAY_SIZE(hi3516a_io_desc));
+}
+
+static const char *const hi3516a_compat[] __initconst = {
+	"hisilicon,hi3516a",
+	NULL,
+};
+
+DT_MACHINE_START(HI3516A_DT, "Hisilicon Hi3516A (Flattened Device Tree)")
+	.map_io		= hi3516a_map_io,
+	.dt_compat	= hi3516a_compat,
+MACHINE_END
diff --git a/arch/arm/mach-hibvt/mach-hi3536dv100.c b/arch/arm/mach-hibvt/mach-hi3536dv100.c
new file mode 100644
index 0000000..7b27dfa
--- /dev/null
+++ b/arch/arm/mach-hibvt/mach-hi3536dv100.c
@@ -0,0 +1,70 @@
+/*
+ * Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program. If not, see <http://www.gnu.org/licenses/>.
+ *
+*/
+
+#include <linux/clocksource.h>
+#include <linux/irqchip.h>
+
+#include <asm/mach/arch.h>
+#include <asm/mach/map.h>
+#include <mach/io.h>
+
+/*
+ * This table is only for optimization. Since ioremap() could always share
+ * the same mapping if it's defined as static IO mapping.
+ *
+ * Without this table, system could also work. The cost is some virtual address
+ * spaces wasted since ioremap() may be called multi times for the same
+ * IO space.
+ */
+static struct map_desc hi3536dv100_io_desc[] __initdata = {
+	/* hi3536dv100_IOCH1 */
+	{
+		.virtual    = HI3536DV100_IOCH1_VIRT,
+		.pfn        = __phys_to_pfn(HI3536DV100_IOCH1_PHYS),
+		.length     = HI3536DV100_IOCH1_SIZE,
+		.type       = MT_DEVICE
+	},
+	/* hi3536dv100_IOCH2 */
+	{
+		.virtual        = HI3536DV100_IOCH2_VIRT,
+		.pfn            = __phys_to_pfn(HI3536DV100_IOCH2_PHYS),
+		.length         = HI3536DV100_IOCH2_SIZE,
+		.type           = MT_DEVICE
+	},
+	/* hi3536dv100_IOCH3 */
+	{
+		.virtual        = HI3536DV100_IOCH3_VIRT,
+		.pfn            = __phys_to_pfn(HI3536DV100_IOCH3_PHYS),
+		.length         = HI3536DV100_IOCH3_SIZE,
+		.type           = MT_DEVICE
+	},
+};
+
+static void __init hi3536dv100_map_io(void)
+{
+	iotable_init(hi3536dv100_io_desc, ARRAY_SIZE(hi3536dv100_io_desc));
+}
+static const char *const hi3536dv100_compat[] __initconst = {
+	"hisilicon,hi3536dv100",
+	NULL,
+};
+
+DT_MACHINE_START(HI3536DV100_DT, "Hisilicon Hi3536DV100 (Flattened Device Tree)")
+	.map_io		= hi3536dv100_map_io,
+	.dt_compat	= hi3536dv100_compat,
+MACHINE_END
diff --git a/arch/arm/mm/dma-mapping.c b/arch/arm/mm/dma-mapping.c
index ab77100..6143695 100644
--- a/arch/arm/mm/dma-mapping.c
+++ b/arch/arm/mm/dma-mapping.c
@@ -2397,3 +2397,10 @@ void arch_teardown_dma_ops(struct device *dev)
 {
 	arm_teardown_iommu_dma_ops(dev);
 }
+
+void hi_dmac_map_area(const void *kaddr, size_t size,
+			enum dma_data_direction dir)
+{
+	dmac_map_area(kaddr, size, dir);
+}
+EXPORT_SYMBOL(hi_dmac_map_area);
diff --git a/drivers/Kconfig b/drivers/Kconfig
index e1e2066..ee519f7 100644
--- a/drivers/Kconfig
+++ b/drivers/Kconfig
@@ -202,4 +202,6 @@ source "drivers/hwtracing/intel_th/Kconfig"
 
 source "drivers/fpga/Kconfig"
 
+source "drivers/hidmac/Kconfig"
+
 endmenu
diff --git a/drivers/Makefile b/drivers/Makefile
index 733bf0b..36a7a91 100644
--- a/drivers/Makefile
+++ b/drivers/Makefile
@@ -174,3 +174,4 @@ obj-$(CONFIG_STM)		+= hwtracing/stm/
 obj-$(CONFIG_ANDROID)		+= android/
 obj-$(CONFIG_NVMEM)		+= nvmem/
 obj-$(CONFIG_FPGA)		+= fpga/
+obj-$(CONFIG_HI_DMAC)		+= hidmac/
diff --git a/drivers/ata/Kconfig b/drivers/ata/Kconfig
index 2c8be74..9154bc8 100644
--- a/drivers/ata/Kconfig
+++ b/drivers/ata/Kconfig
@@ -2,6 +2,8 @@
 # SATA/PATA driver configuration
 #
 
+source "drivers/ata/Kconfig.hiahci"
+
 config HAVE_PATA_PLATFORM
 	bool
 	help
diff --git a/drivers/ata/Kconfig.hiahci b/drivers/ata/Kconfig.hiahci
new file mode 100644
index 0000000..3bc0424
--- /dev/null
+++ b/drivers/ata/Kconfig.hiahci
@@ -0,0 +1,43 @@
+menuconfig HISI_SATA
+	bool "Hisilicon sata device support"
+	depends on ARCH_HI3536DV100
+	default y if ARCH_HI3536DV100
+	select ATA
+	select ATA_VERBOSE_ERROR
+	select SATA_PMP
+	select SATA_AHCI_PLATFORM
+
+if HISI_SATA
+config HISI_SATA_IOBASE
+	hex "Hisi sata IO address"
+	default "0x10030000" if ARCH_HI3536DV100
+	help
+	  hisilicon sata io base address.
+
+config HISI_SATA_FBS
+	int "Hisi sata FIS-Based switching"
+	default 1
+	range 0 1
+	help
+	  Hisatav200 supports FBS.
+	  FBS is FIS-Based switching.
+	  Choose y if you want to use it.
+
+config HISI_SATA_NCQ
+	int "Hisi sata Native Command Queuing"
+	default 1
+	range 0 1
+	help
+	  Hisatav200 supports NCQ.
+	  NCQ is Native Command Queuing.
+	  Choose y if you want to use it.
+
+config HISI_ESATA
+	bool "Support Hisi eSATA"
+	default n
+	help
+	  Hisatav200 supports eSATA.
+	  Choose y if you want to use it.
+
+endif
+
diff --git a/drivers/ata/Makefile b/drivers/ata/Makefile
index a46e6b7..40ee545 100644
--- a/drivers/ata/Makefile
+++ b/drivers/ata/Makefile
@@ -1,5 +1,6 @@
 
 obj-$(CONFIG_ATA)		+= libata.o
+obj-$(CONFIG_HISI_SATA)       += hisi_sata_dbg.o
 
 # non-SFF interface
 obj-$(CONFIG_SATA_AHCI)		+= ahci.o libahci.o
diff --git a/drivers/ata/ahci.h b/drivers/ata/ahci.h
index 0cc08f8..4fe8dc3 100644
--- a/drivers/ata/ahci.h
+++ b/drivers/ata/ahci.h
@@ -240,6 +240,9 @@ enum {
 						        error-handling stage) */
 	AHCI_HFLAG_NO_DEVSLP		= (1 << 17), /* no device sleep */
 	AHCI_HFLAG_NO_FBS		= (1 << 18), /* no FBS */
+#ifdef CONFIG_HISI_SATA
+	AHCI_HFLAG_NO_SXS		= (1 << 19), /* do not support External SATA */
+#endif
 
 #ifdef CONFIG_PCI_MSI
 	AHCI_HFLAG_MULTI_MSI		= (1 << 20), /* per-port MSI(-X) */
@@ -344,6 +347,13 @@ struct ahci_host_priv {
 	bool			got_runtime_pm; /* Did we do pm_runtime_get? */
 	struct clk		*clks[AHCI_MAX_CLKS]; /* Optional */
 	struct regulator	**target_pwrs;	/* Optional */
+
+#ifdef CONFIG_HISI_SATA
+#define         PCI_AHCI 0
+#define         ORI_AHCI 1
+	u32         type;
+#endif
+
 	/*
 	 * If platform uses PHYs. There is a 1:1 relation between the port number and
 	 * the PHY position in this array.
diff --git a/drivers/ata/ahci_platform.c b/drivers/ata/ahci_platform.c
index 62a04c8..e08e678 100644
--- a/drivers/ata/ahci_platform.c
+++ b/drivers/ata/ahci_platform.c
@@ -26,6 +26,12 @@
 
 #define DRV_NAME "ahci"
 
+#ifdef CONFIG_HISI_SATA_NCQ
+static unsigned int ncq_en = CONFIG_HISI_SATA_NCQ;
+module_param(ncq_en, uint, 0600);
+MODULE_PARM_DESC(ncq_en, "ahci ncq flag (default:1)");
+#endif
+
 static const struct ata_port_info ahci_port_info = {
 	.flags		= AHCI_FLAG_COMMON,
 	.pio_mask	= ATA_PIO4,
@@ -54,8 +60,20 @@ static int ahci_probe(struct platform_device *pdev)
 	of_property_read_u32(dev->of_node,
 			     "ports-implemented", &hpriv->force_port_map);
 
+#ifdef CONFIG_HISI_SATA
+	hpriv->type = ORI_AHCI;
+#ifndef CONFIG_HISI_ESATA
+	hpriv->flags |= AHCI_HFLAG_NO_SXS;
+#endif
+
+#ifdef CONFIG_HISI_SATA_NCQ
+	if (!ncq_en)
+		 hpriv->flags |= AHCI_HFLAG_NO_NCQ;
+#endif
+#else
 	if (of_device_is_compatible(dev->of_node, "hisilicon,hisi-ahci"))
 		hpriv->flags |= AHCI_HFLAG_NO_FBS | AHCI_HFLAG_NO_NCQ;
+#endif
 
 	rc = ahci_platform_init_host(pdev, hpriv, &ahci_port_info,
 				     &ahci_platform_sht);
diff --git a/drivers/ata/hisi_sata_dbg.c b/drivers/ata/hisi_sata_dbg.c
new file mode 100644
index 0000000..45efc6b
--- /dev/null
+++ b/drivers/ata/hisi_sata_dbg.c
@@ -0,0 +1,158 @@
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/module.h>
+#include <linux/libata.h>
+#include <mach/io.h>
+#include "ahci.h"
+#include "hisi_sata_dbg.h"
+
+void hisi_sata_mem_dump(unsigned int *addr, unsigned int size)
+{
+	int ix;
+
+	for (ix = 0; ix < size; ix += 0x04, addr++) {
+		if (!(ix & 0x0F))
+			pr_debug("\n0x%08X: ",
+				(unsigned int)virt_to_phys(addr));
+		pr_debug("%08X ", *addr);
+	}
+}
+EXPORT_SYMBOL(hisi_sata_mem_dump);
+
+void hisi_sata_phys_mem_dump(unsigned int addr, unsigned int size)
+{
+	hisi_sata_mem_dump(phys_to_virt(addr), size);
+}
+EXPORT_SYMBOL(hisi_sata_phys_mem_dump);
+
+void hisi_ahci_reg_dump(void)
+{
+	int ix;
+	unsigned int regbase;
+
+	regbase = CONFIG_HISI_SATA_IOBASE;
+	pr_debug("AHCI GHC Register dump:");
+	for (ix = 0; ix <= 0x28; ix += 0x04) {
+		if (!(ix & 0x0F))
+			pr_debug("\n0x%08X: ", (regbase + ix));
+		pr_debug("%08X ", readl(__io_address(regbase + ix)));
+	}
+	pr_debug("\n");
+
+	regbase = CONFIG_HISI_SATA_IOBASE + 0x0100;
+	pr_debug("AHCI PORT 0 Register dump:");
+	for (ix = 0; ix <= 0x7F; ix += 0x04) {
+		if (!(ix & 0x0F))
+			pr_debug("\n0x%08X: ", (regbase + ix));
+		pr_debug("%08X ", readl(__io_address(regbase + ix)));
+	}
+	pr_debug("\n");
+}
+EXPORT_SYMBOL(hisi_ahci_reg_dump);
+
+void hisi_ahci_rx_fis_dump(struct ata_link *link, int pmp_port_num)
+{
+	struct ahci_port_priv *pp = NULL;
+
+	pp = link->ap->private_data;
+	if (NULL == pp) {
+		pr_debug("Error: pp=NULL\n");
+		return;
+	}
+	pr_debug("ACHI Received FIS:");
+	hisi_sata_phys_mem_dump((unsigned int)(pp->rx_fis_dma),
+				AHCI_RX_FIS_SZ * pmp_port_num);
+	pr_debug("\n");
+}
+EXPORT_SYMBOL_GPL(hisi_ahci_rx_fis_dump);
+
+void hisi_ata_taskfile_dump(struct ata_taskfile *tf)
+{
+	if (NULL == tf) {
+		pr_debug("Error: tf=NULL\n");
+		return;
+	}
+
+	pr_debug("Taskfile dump:\n");
+	pr_debug("flags:0x%08lX, protocol:0x%02X, command:0x%02X, device:0x%02X, ctl:0x%02X\n",
+		tf->flags, tf->protocol, tf->command, tf->device, tf->ctl);
+	pr_debug("feature:0x%08X, nsect:0x%02X, lbal:0x%02X, lbam:0x%02X, lbah:0x%02X\n",
+		tf->feature, tf->nsect, tf->lbal, tf->lbam, tf->lbah);
+	pr_debug("hob_feature:0x%08X, hob_nsect:0x%02X, hob_lbal:0x%02X, hob_lbam:0x%02X, hob_lbah:0x%02X\n",
+		tf->hob_feature, tf->hob_nsect, tf->hob_lbal,
+		tf->hob_lbam, tf->hob_lbah);
+}
+EXPORT_SYMBOL_GPL(hisi_ata_taskfile_dump);
+
+static void __hisi_ahci_st_md(void __iomem *addr)
+{
+	unsigned int *addr_v;
+	unsigned int *tmp;
+	unsigned int i;
+
+	addr_v = (unsigned int *)addr;
+
+	pr_debug("\n\n");
+	for (i = 0; i < 16; i++) {
+		tmp = addr_v + i * 4;
+		pr_debug("%8x: %8x %8x %8x %8x\n",
+			(unsigned int)(addr + i * 16),
+			*tmp, *(tmp + 1), *(tmp + 2), *(tmp + 3));
+	}
+
+	pr_debug("\n");
+}
+
+void hisi_ahci_st_dump(void __iomem *port_base)
+{
+	unsigned int tmp;
+
+	pr_debug("\n**********Dmac status**********\n");
+	tmp = readl(port_base + 0x58);
+	pr_debug("txdmac_curr_st:0x%2x\n", (tmp>>24) & 0xf);
+	tmp = readl(port_base + 0x64);
+	pr_debug("rxdmac_curr_st:0x%2x\n", (tmp>>24) & 0xf);
+	tmp = readl(port_base + 0x70);
+	pr_debug("dmac tx fifo:count-0x%x-empty-%x-ful-%x\n",
+			(tmp>>0) & 0xff,
+			(tmp>>16) & 0x1, (tmp>>17) & 0x1);
+	pr_debug("dmac rx fifo:count-0x%x-empty-%x-ful-%x\n",
+			(tmp>>8) & 0xff,
+			(tmp>>18) & 0x1, (tmp>>19) & 0x1);
+
+	pr_debug("\n");
+	pr_debug("**********HBA status**********\n");
+	tmp = readl(port_base + 0x50);
+	pr_debug("pxxx_curr_st:0x%2x      ndrx_curr_st:0x%2x\n",
+			(tmp>>24) & 0xf,
+			(tmp>>16) & 0xff);
+	pr_debug("cfis_curr_st:0x%2x      piox_curr_st:0x%2x\n",
+			(tmp>>12) & 0xf,
+			(tmp>>8) & 0xf);
+	pr_debug("pmxx_curr_st:0x%2x      errx_curr_st:0x%2x\n",
+			(tmp>>4) & 0xf,
+			(tmp>>0) & 0xf);
+
+	pr_debug("\n");
+	pr_debug("**********Link status**********\n");
+	tmp = readl(port_base + 0x54);
+	pr_debug("link_curr_st:0x%2x\n", (tmp>>24) & 0x1f);
+	pr_debug("link tx fifo:count-0x%x-empty-%x-ful-%x\n",
+			(tmp>>0) & 0x1f,
+			(tmp>>5) & 0x1, (tmp>>6) & 0x1);
+	pr_debug("link rx fifo:count-0x%x-empty-%x-ful-%x\n",
+			(tmp>>8) & 0x1f,
+			(tmp>>13) & 0x1, (tmp>>14) & 0x1);
+	pr_debug("link df fifo:count-0x%x-empty-%x-ful-%x\n\n",
+			(tmp>>16) & 0x1f,
+			(tmp>>21) & 0x1, (tmp>>22) & 0x1);
+
+	pr_debug("**********CMD header**********\n");
+	tmp = readl(port_base + 0x0);
+	__hisi_ahci_st_md(phys_to_virt(tmp));
+	__hisi_ahci_st_md(phys_to_virt(tmp+0x100));
+	__hisi_ahci_st_md(phys_to_virt(tmp+0x200));
+	__hisi_ahci_st_md(phys_to_virt(tmp+0x300));
+}
+EXPORT_SYMBOL_GPL(hisi_ahci_st_dump);
+
diff --git a/drivers/ata/hisi_sata_dbg.h b/drivers/ata/hisi_sata_dbg.h
new file mode 100644
index 0000000..27b14fe
--- /dev/null
+++ b/drivers/ata/hisi_sata_dbg.h
@@ -0,0 +1,47 @@
+
+#ifndef _HISI_SATA_DBG_H
+#define _HISI_SATA_DBG_H
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/libata.h>
+#include "ahci.h"
+
+
+void hisi_sata_mem_dump(unsigned int *addr, unsigned int size);
+void hisi_sata_phys_mem_dump(unsigned int addr, unsigned int size);
+void hisi_ahci_rx_fis_dump(struct ata_link *link, int pmp_port_num);
+void hisi_ata_taskfile_dump(struct ata_taskfile *tf);
+void hisi_ahci_st_dump(void __iomem *port_base);
+void hisi_ahci_reg_dump(void);
+
+#define HISI_AHCI_REG_DUMP(X) \
+do {\
+	pr_debug("------------------[ Start ]--------------------\n"); \
+	pr_debug("Dump AHCI registers at %s %d\n", __func__, __LINE__); \
+	hisi_ahci_reg_dump(); \
+	pr_debug("------------------[  End  ]--------------------\n");\
+} while (0)
+
+#define hisi_sata_readl(addr) do {\
+		unsigned int reg = readl((unsigned int)addr); \
+		pr_debug("HI_AHCI(REG) %s:%d: readl(0x%08X) = 0x%08X\n",\
+		__func__, __LINE__, (unsigned int)addr, reg); \
+		reg;\
+	} while (0)
+
+#define hisi_sata_writel(v, addr) do { writel(v, (unsigned int)addr); \
+	pr_debug("HI_AHCI(REG) %s:%d: writel(0x%08X) = 0x%08X\n",\
+		__func__, __LINE__, (unsigned int)addr, \
+		(unsigned int)(v)); \
+	} while (0)
+
+#undef HISI_DUMP_AHCI_REG_OPS
+#ifdef HISI_DUMP_AHCI_REG_OPS
+#define readl(addr) hisi_sata_readl(addr)
+#define write(v, addr) hisi_sata_writel(v, addr)
+#endif
+
+#endif /* _HISI_SATA_DBG_H */
+
+
+
diff --git a/drivers/ata/libahci.c b/drivers/ata/libahci.c
index 0d028ea..4d1e0f8 100644
--- a/drivers/ata/libahci.c
+++ b/drivers/ata/libahci.c
@@ -57,6 +57,30 @@ MODULE_PARM_DESC(skip_host_reset, "skip global host reset (0=don't skip, 1=skip)
 module_param_named(ignore_sss, ahci_ignore_sss, int, 0444);
 MODULE_PARM_DESC(ignore_sss, "Ignore staggered spinup flag (0=don't ignore, 1=ignore)");
 
+#ifdef CONFIG_HISI_SATA_FBS
+static int fbs_en = CONFIG_HISI_SATA_FBS;
+module_param(fbs_en, uint, 0600);
+MODULE_PARM_DESC(fbs_en, "ahci fbs flags (default:1)");
+
+#define AHCI_TIMEOUT_COUNT	10
+#define AHCI_POLL_TIMER		(20 * HZ)
+
+struct ata_fbs_ctrl {
+	unsigned int fbs_enable_ctrl; /* fbs enable or disable control switch */
+	unsigned int fbs_mode_ctrl;   /* 1.5G: fbs disable, 3G/6G: fbs enable */
+	unsigned int fbs_enable_flag;
+	unsigned int fbs_disable_flag;
+	unsigned int fbs_cmd_issue_flag;
+	struct timer_list poll_timer;
+};
+static struct ata_fbs_ctrl fbs_ctrl[4];
+extern void hisi_sata_set_fifoth(void *mmio);
+#endif
+#ifdef CONFIG_ARCH_HI3536DV100
+extern void hisi_sata_reset_rxtx_assert(void);
+extern void hisi_sata_reset_rxtx_deassert(void);
+#endif
+
 static int ahci_set_lpm(struct ata_link *link, enum ata_lpm_policy policy,
 			unsigned hints);
 static ssize_t ahci_led_show(struct ata_port *ap, char *buf);
@@ -503,6 +527,13 @@ void ahci_save_initial_config(struct device *dev, struct ahci_host_priv *hpriv)
 		cap &= ~HOST_CAP_FBS;
 	}
 
+#ifdef CONFIG_HISI_SATA
+	if ((cap & HOST_CAP_SXS) && (hpriv->flags & AHCI_HFLAG_NO_SXS)) {
+		dev_info(dev, "controller can't support eSATA, turning off CAP_SXS\n");
+		cap &= ~HOST_CAP_SXS;
+	}
+#endif
+
 	if (hpriv->force_port_map && port_map != hpriv->force_port_map) {
 		dev_info(dev, "forcing port_map 0x%x -> 0x%x\n",
 			 port_map, hpriv->force_port_map);
@@ -1380,8 +1411,28 @@ int ahci_do_softreset(struct ata_link *link, unsigned int *class,
 	bool fbs_disabled = false;
 	int rc;
 
+#ifdef CONFIG_HISI_SATA_FBS
+	unsigned int port_num = ap->port_no;
+#endif
+
 	DPRINTK("ENTER\n");
 
+#ifdef CONFIG_HISI_SATA_FBS
+	if (fbs_ctrl[port_num].fbs_enable_ctrl &&
+			(link->pmp == SATA_PMP_CTRL_PORT) &&
+			(hpriv->type == ORI_AHCI)) {
+		struct ahci_port_priv *pp = ap->private_data;
+
+		if (pp->fbs_enabled == false)
+			ahci_enable_fbs(ap);
+
+		fbs_ctrl[port_num].fbs_enable_flag = 0;
+		fbs_ctrl[port_num].fbs_disable_flag = 0;
+		fbs_ctrl[port_num].fbs_cmd_issue_flag = 0;
+
+	}
+#endif
+
 	/* prepare for SRST (AHCI-1.1 10.4.1) */
 	rc = ahci_kick_engine(ap);
 	if (rc && rc != -EOPNOTSUPP)
@@ -1410,6 +1461,10 @@ int ahci_do_softreset(struct ata_link *link, unsigned int *class,
 				 AHCI_CMD_RESET | AHCI_CMD_CLR_BUSY, msecs)) {
 		rc = -EIO;
 		reason = "1st FIS failed";
+#ifdef CONFIG_ARCH_HI3536DV100
+		hisi_sata_reset_rxtx_assert();
+		hisi_sata_reset_rxtx_deassert();
+#endif
 		goto fail;
 	}
 
@@ -1599,6 +1654,68 @@ static int ahci_pmp_qc_defer(struct ata_queued_cmd *qc)
 	struct ata_port *ap = qc->ap;
 	struct ahci_port_priv *pp = ap->private_data;
 
+#ifdef CONFIG_HISI_SATA_FBS
+	struct ahci_host_priv *hpriv = ap->host->private_data;
+	int is_atapi = ata_is_atapi(qc->tf.protocol);
+	void __iomem *port_mmio = ahci_port_base(ap);
+	unsigned int port_num = ap->port_no;
+	unsigned int cmd_timeout_count;
+
+	if (fbs_ctrl[port_num].fbs_enable_ctrl &&
+			(ap->link.pmp == SATA_PMP_CTRL_PORT) &&
+			(hpriv->type == ORI_AHCI)) {
+		if (is_atapi || fbs_ctrl[ap->port_no].fbs_cmd_issue_flag) {
+			mod_timer(&fbs_ctrl[port_num].poll_timer,
+					jiffies + AHCI_POLL_TIMER);
+
+			if (!fbs_ctrl[port_num].fbs_disable_flag) {
+				cmd_timeout_count = 0;
+				while (readl(port_mmio + PORT_SCR_ACT)
+						|| readl(port_mmio
+							+ PORT_CMD_ISSUE)
+						|| readl(port_mmio
+							+ PORT_IRQ_STAT)) {
+					cmd_timeout_count++;
+					if (cmd_timeout_count >=
+							AHCI_TIMEOUT_COUNT) {
+						fbs_ctrl[ap->port_no].
+							fbs_cmd_issue_flag = 1;
+						return ATA_DEFER_LINK;
+					}
+				}
+
+				if (pp->fbs_enabled == true)
+					ahci_disable_fbs(ap);
+
+				ap->excl_link = NULL;
+				ap->nr_active_links = 0;
+				fbs_ctrl[port_num].fbs_disable_flag = 1;
+				fbs_ctrl[port_num].fbs_enable_flag = 0;
+				fbs_ctrl[ap->port_no].fbs_cmd_issue_flag = 0;
+			}
+		} else {
+			if (fbs_ctrl[port_num].fbs_enable_flag) {
+				cmd_timeout_count = 0;
+				while (readl(port_mmio + PORT_SCR_ACT)
+						|| readl(port_mmio
+							+ PORT_CMD_ISSUE)
+						|| readl(port_mmio
+							+ PORT_IRQ_STAT)) {
+					cmd_timeout_count++;
+					if (cmd_timeout_count >=
+							AHCI_TIMEOUT_COUNT) {
+						return ATA_DEFER_LINK;
+					}
+				}
+
+				if (pp->fbs_enabled == false)
+					ahci_enable_fbs(ap);
+				fbs_ctrl[port_num].fbs_enable_flag = 0;
+				fbs_ctrl[port_num].fbs_disable_flag = 0;
+			}
+		}
+	}
+#endif
 	if (!sata_pmp_attached(ap) || pp->fbs_enabled)
 		return ata_std_qc_defer(qc);
 	else
@@ -1643,6 +1760,7 @@ static void ahci_qc_prep(struct ata_queued_cmd *qc)
 	ahci_fill_cmd_slot(pp, qc->tag, opts);
 }
 
+#ifndef CONFIG_HISI_SATA_FBS
 static void ahci_fbs_dec_intr(struct ata_port *ap)
 {
 	struct ahci_port_priv *pp = ap->private_data;
@@ -1666,6 +1784,7 @@ static void ahci_fbs_dec_intr(struct ata_port *ap)
 	if (fbs & PORT_FBS_DEC)
 		dev_err(ap->host->dev, "failed to clear device error\n");
 }
+#endif
 
 static void ahci_error_intr(struct ata_port *ap, u32 irq_stat)
 {
@@ -1773,7 +1892,9 @@ static void ahci_error_intr(struct ata_port *ap, u32 irq_stat)
 		ata_port_freeze(ap);
 	else if (fbs_need_dec) {
 		ata_link_abort(link);
+#ifndef CONFIG_HISI_SATA_FBS
 		ahci_fbs_dec_intr(ap);
+#endif
 	} else
 		ata_port_abort(ap);
 }
@@ -2170,7 +2291,9 @@ static void ahci_enable_fbs(struct ata_port *ap)
 	writel(fbs | PORT_FBS_EN, port_mmio + PORT_FBS);
 	fbs = readl(port_mmio + PORT_FBS);
 	if (fbs & PORT_FBS_EN) {
+#ifndef CONFIG_HISI_SATA_FBS
 		dev_info(ap->host->dev, "FBS is enabled\n");
+#endif
 		pp->fbs_enabled = true;
 		pp->fbs_last_dev = -1; /* initialization */
 	} else
@@ -2210,6 +2333,9 @@ static void ahci_disable_fbs(struct ata_port *ap)
 	}
 
 	hpriv->start_engine(ap);
+#ifdef CONFIG_HISI_SATA_FBS
+	hisi_sata_set_fifoth(port_mmio);
+#endif
 }
 
 static void ahci_pmp_attach(struct ata_port *ap)
@@ -2218,12 +2344,24 @@ static void ahci_pmp_attach(struct ata_port *ap)
 	struct ahci_port_priv *pp = ap->private_data;
 	u32 cmd;
 
+#ifdef CONFIG_HISI_SATA_FBS
+	struct ahci_host_priv *hpriv = ap->host->private_data;
+	unsigned int port_num = ap->port_no;
+#endif
+
 	cmd = readl(port_mmio + PORT_CMD);
 	cmd |= PORT_CMD_PMP;
 	writel(cmd, port_mmio + PORT_CMD);
 
 	ahci_enable_fbs(ap);
 
+#ifdef CONFIG_HISI_SATA_FBS
+	if (hpriv->type == ORI_AHCI) {
+		if (!fbs_ctrl[port_num].fbs_enable_ctrl)
+			ahci_disable_fbs(ap);
+	}
+#endif
+
 	pp->intr_mask |= PORT_IRQ_BAD_PMP;
 
 	/*
@@ -2292,6 +2430,19 @@ static int ahci_port_suspend(struct ata_port *ap, pm_message_t mesg)
 }
 #endif
 
+#ifdef CONFIG_HISI_SATA_FBS
+static void ahci_poll_func(unsigned long arg)
+{
+	struct ata_port *ap = (struct ata_port *)arg;
+	unsigned int port_num = ap->port_no;
+
+	if (ap->link.pmp == SATA_PMP_CTRL_PORT) {
+		fbs_ctrl[port_num].fbs_enable_flag = 1;
+		fbs_ctrl[port_num].fbs_disable_flag = 0;
+	}
+}
+#endif
+
 static int ahci_port_start(struct ata_port *ap)
 {
 	struct ahci_host_priv *hpriv = ap->host->private_data;
@@ -2385,6 +2536,20 @@ static int ahci_port_start(struct ata_port *ap)
 
 	ap->private_data = pp;
 
+#ifdef CONFIG_HISI_SATA_FBS
+	if (hpriv->type == ORI_AHCI) {
+		fbs_ctrl[ap->port_no].fbs_enable_ctrl = fbs_en;
+		fbs_ctrl[ap->port_no].fbs_enable_flag = 0;
+		fbs_ctrl[ap->port_no].fbs_disable_flag = 0;
+		fbs_ctrl[ap->port_no].fbs_cmd_issue_flag = 0;
+
+		init_timer(&fbs_ctrl[ap->port_no].poll_timer);
+		fbs_ctrl[ap->port_no].poll_timer.function = ahci_poll_func;
+		fbs_ctrl[ap->port_no].poll_timer.data = (unsigned long)ap;
+		fbs_ctrl[ap->port_no].poll_timer.expires = jiffies + AHCI_POLL_TIMER;
+	}
+#endif
+
 	/* engage engines, captain */
 	return ahci_port_resume(ap);
 }
diff --git a/drivers/char/random.c b/drivers/char/random.c
index 08d1dd5..c378812 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -1744,7 +1744,7 @@ urandom_read(struct file *file, char __user *buf, size_t nbytes, loff_t *ppos)
 
 	if (!crng_ready() && maxwarn > 0) {
 		maxwarn--;
-		printk(KERN_NOTICE "random: %s: uninitialized urandom read "
+		printk_once(KERN_NOTICE "random: %s: uninitialized urandom read "
 		       "(%zd bytes read)\n",
 		       current->comm, nbytes);
 		spin_lock_irqsave(&primary_crng.lock, flags);
diff --git a/drivers/clk/Makefile b/drivers/clk/Makefile
index 42042c0..0a0c6d9 100644
--- a/drivers/clk/Makefile
+++ b/drivers/clk/Makefile
@@ -57,6 +57,7 @@ obj-y					+= bcm/
 obj-$(CONFIG_ARCH_BERLIN)		+= berlin/
 obj-$(CONFIG_H8300)			+= h8300/
 obj-$(CONFIG_ARCH_HISI)			+= hisilicon/
+obj-$(CONFIG_ARCH_HISI_BVT)     += hisilicon/
 obj-$(CONFIG_ARCH_MXC)			+= imx/
 obj-$(CONFIG_MACH_INGENIC)		+= ingenic/
 obj-$(CONFIG_COMMON_CLK_KEYSTONE)	+= keystone/
diff --git a/drivers/clk/hisilicon/Kconfig b/drivers/clk/hisilicon/Kconfig
index 3f537a0..f331da5 100644
--- a/drivers/clk/hisilicon/Kconfig
+++ b/drivers/clk/hisilicon/Kconfig
@@ -6,6 +6,22 @@ config COMMON_CLK_HI3519
 	help
 	  Build the clock driver for hi3519.
 
+config COMMON_CLK_HI3516A
+	tristate "Hi3516A Clock Driver"
+	depends on ARCH_HI3516A || COMPILE_TEST
+	select RESET_HISI
+	default ARCH_HISI
+	help
+	  Build the clock driver for hi3516A.
+
+config COMMON_CLK_HI3536DV100
+	tristate "Hi3536DV100 Clock Driver"
+	depends on ARCH_HI3536DV100 || COMPILE_TEST
+	select RESET_HISI
+	default ARCH_HISI
+	help
+	  Build the clock driver for hi3536DV100.
+
 config COMMON_CLK_HI6220
 	bool "Hi6220 Clock Driver"
 	depends on ARCH_HISI || COMPILE_TEST
@@ -15,7 +31,7 @@ config COMMON_CLK_HI6220
 
 config RESET_HISI
 	bool "HiSilicon Reset Controller Driver"
-	depends on ARCH_HISI || COMPILE_TEST
+	depends on ARCH_HISI || COMPILE_TEST || ARCH_HISI_BVT
 	select RESET_CONTROLLER
 	help
 	  Build reset controller driver for HiSilicon device chipsets.
diff --git a/drivers/clk/hisilicon/Makefile b/drivers/clk/hisilicon/Makefile
index e169ec7..6eefb3d 100644
--- a/drivers/clk/hisilicon/Makefile
+++ b/drivers/clk/hisilicon/Makefile
@@ -8,6 +8,8 @@ obj-$(CONFIG_ARCH_HI3xxx)	+= clk-hi3620.o
 obj-$(CONFIG_ARCH_HIP04)	+= clk-hip04.o
 obj-$(CONFIG_ARCH_HIX5HD2)	+= clk-hix5hd2.o
 obj-$(CONFIG_COMMON_CLK_HI3519)	+= clk-hi3519.o
+obj-$(CONFIG_COMMON_CLK_HI3516A)  += clk-hi3516a.o
+obj-$(CONFIG_COMMON_CLK_HI3536DV100)  += clk-hi3536dv100.o
 obj-$(CONFIG_COMMON_CLK_HI6220)	+= clk-hi6220.o
 obj-$(CONFIG_RESET_HISI)	+= reset.o
 obj-$(CONFIG_STUB_CLK_HI6220)	+= clk-hi6220-stub.o
diff --git a/drivers/clk/hisilicon/clk-hi3516a.c b/drivers/clk/hisilicon/clk-hi3516a.c
new file mode 100644
index 0000000..07fb754
--- /dev/null
+++ b/drivers/clk/hisilicon/clk-hi3516a.c
@@ -0,0 +1,493 @@
+/*
+ * Hi3516A Clock Driver
+ *
+ * Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <dt-bindings/clock/hi3516a-clock.h>
+#include <linux/clk-provider.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+
+#include "clk.h"
+#include "crg.h"
+#include "reset.h"
+
+struct hi3516a_pll_clock {
+	u32     id;
+	const char  *name;
+	const char  *parent_name;
+	u32     ctrl_reg1;
+	u8      frac_shift;
+	u8      frac_width;
+	u8      postdiv1_shift;
+	u8      postdiv1_width;
+	u8      postdiv2_shift;
+	u8      postdiv2_width;
+	u32     ctrl_reg2;
+	u8      fbdiv_shift;
+	u8      fbdiv_width;
+	u8      refdiv_shift;
+	u8      refdiv_width;
+};
+
+struct hi3516a_clk_pll {
+	struct clk_hw   hw;
+	u32     id;
+	void __iomem    *ctrl_reg1;
+	u8      frac_shift;
+	u8      frac_width;
+	u8      postdiv1_shift;
+	u8      postdiv1_width;
+	u8      postdiv2_shift;
+	u8      postdiv2_width;
+	void __iomem    *ctrl_reg2;
+	u8      fbdiv_shift;
+	u8      fbdiv_width;
+	u8      refdiv_shift;
+	u8      refdiv_width;
+};
+
+static const struct
+hisi_fixed_rate_clock hi3516a_fixed_rate_clks_crg[] = {
+	{ HI3516A_FIXED_3M, "3m", NULL, 0, 3000000, },
+	{ HI3516A_FIXED_6M, "6m", NULL, 0, 6000000, },
+	{ HI3516A_FIXED_13P5M, "13.5m", NULL, 0, 13500000, },
+	{ HI3516A_FIXED_24M, "24m", NULL, 0, 24000000, },
+	{ HI3516A_FIXED_25M, "25m", NULL, 0, 25000000, },
+	{ HI3516A_FIXED_27M, "27m", NULL, 0, 27000000, },
+	{ HI3516A_FIXED_37P125M, "37.125m", NULL, 0, 37125000, },
+	{ HI3516A_FIXED_50M, "50m", NULL, 0, 50000000, },
+	{ HI3516A_FIXED_74P25M, "74.25m", NULL, 0, 74250000, },
+	{ HI3516A_FIXED_75M, "75m", NULL, 0, 75000000, },
+	{ HI3516A_FIXED_99M, "99m", NULL, 0, 99000000, },
+	{ HI3516A_FIXED_100M, "100m", NULL, 0, 100000000, },
+	{ HI3516A_FIXED_125M, "125m", NULL, 0, 125000000, },
+	{ HI3516A_FIXED_145M, "145m", NULL, 0, 145000000, },
+	{ HI3516A_FIXED_148P5M, "148.5m", NULL, 0, 148500000, },
+	{ HI3516A_FIXED_150M, "150m", NULL, 0, 150000000, },
+	{ HI3516A_FIXED_194M, "194m", NULL, 0, 194000000, },
+	{ HI3516A_FIXED_198M, "198m", NULL, 0, 198000000, },
+	{ HI3516A_FIXED_200M, "200m", NULL, 0, 200000000, },
+	{ HI3516A_FIXED_229M, "229m", NULL, 0, 229000000, },
+	{ HI3516A_FIXED_237M, "237m", NULL, 0, 237000000, },
+	{ HI3516A_FIXED_242M, "242m", NULL, 0, 242000000, },
+	{ HI3516A_FIXED_250M, "250m", NULL, 0, 250000000, },
+	{ HI3516A_FIXED_297M, "297m", NULL, 0, 297000000, },
+	{ HI3516A_FIXED_300M, "300m", NULL, 0, 300000000, },
+	{ HI3516A_FIXED_333M, "333m", NULL, 0, 333000000, },
+	{ HI3516A_FIXED_400M, "400m", NULL, 0, 400000000, },
+	{ HI3516A_FIXED_500M, "500m", NULL, 0, 500000000, },
+	{ HI3516A_FIXED_594M, "594m", NULL, 0, 594000000, },
+	{ HI3516A_FIXED_600M, "600m", NULL, 0, 600000000, },
+	{ HI3516A_FIXED_726P25M, "725.25m", NULL, 0, 726250000, },
+	{ HI3516A_FIXED_750M, "750m", NULL, 0, 750000000, },
+	{ HI3516A_FIXED_900M, "900m", NULL, 0, 900000000, },
+	{ HI3516A_FIXED_1000M, "1000m", NULL, 0, 1000000000UL, },
+	{ HI3516A_FIXED_1188M, "1188m", NULL, 0, 1188000000UL, },
+};
+
+static const char *const sysaxi_mux_p[] = {"198m", "148.5m"};
+static const char *const uart_mux_p[] = {"clk_sysapb", "6m"};
+static const char *const snor_mux_p[] = {"24m", "75m", "125m"};
+static const char *const snand_mux_p[] = {"24m", "75m", "125m"};
+static const char *const nand_mux_p[] = {"24m", "198m"};
+static const char *const eth_phy_mux_p[] = {"50m", "25m"};
+static const char *const a7_mux_p[] = {"400m", "500m", "apll"};
+static const char *const mmc_mux_p[] = {"50m", "100m", "25m", "75m"};
+
+static u32 sysaxi_mux_table[] = {0, 1};
+static u32 uart_mux_table[] = {0, 1};
+static u32 snor_mux_table[] = {0, 1, 2};
+static u32 snand_mux_table[] = {0, 1, 2};
+static u32 nand_mux_table[] = {0, 1};
+static u32 eth_phy_mux_table[] = {0, 1};
+static u32 a7_mux_table[] = {2, 1, 0};
+static u32 mmc_mux_table[] = {0, 1, 2, 3};
+
+static const struct hisi_mux_clock hi3516a_mux_clks_crg[] = {
+	{ HI3516A_SYSAXI_CLK, "sysaxi_mux", sysaxi_mux_p,
+		ARRAY_SIZE(sysaxi_mux_p),
+		CLK_SET_RATE_PARENT, 0x30, 3, 1, 0, sysaxi_mux_table, },
+	{ HI3516A_SNOR_MUX, "snor_mux", snor_mux_p, ARRAY_SIZE(snor_mux_p),
+		CLK_SET_RATE_PARENT, 0xc0, 2, 2, 0, snor_mux_table, },
+	{ HI3516A_SNAND_MUX, "snand_mux", snand_mux_p, ARRAY_SIZE(snand_mux_p),
+		CLK_SET_RATE_PARENT, 0xc0, 6, 2, 0, snand_mux_table, },
+	{ HI3516A_NAND_MUX, "nand_mux", nand_mux_p, ARRAY_SIZE(nand_mux_p),
+		CLK_SET_RATE_PARENT, 0xd0, 2, 1, 0, nand_mux_table, },
+	{ HI3516A_MMC0_MUX, "mmc0_mux", mmc_mux_p, ARRAY_SIZE(mmc_mux_p),
+		CLK_SET_RATE_PARENT, 0xc4, 2, 2, 0, mmc_mux_table, },
+	{ HI3516A_MMC1_MUX, "mmc1_mux", mmc_mux_p, ARRAY_SIZE(mmc_mux_p),
+		CLK_SET_RATE_PARENT, 0xc4, 10, 2, 0, mmc_mux_table, },
+	{ HI3516A_UART_MUX, "uart_mux", uart_mux_p,
+		ARRAY_SIZE(uart_mux_p),
+		CLK_SET_RATE_PARENT, 0xe4, 19, 1, 0, uart_mux_table, },
+	{ HI3516A_ETH_PHY_MUX, "eth_phy_mux", eth_phy_mux_p,
+		ARRAY_SIZE(eth_phy_mux_p), CLK_SET_RATE_PARENT,
+		0xcc, 6, 1, 0, eth_phy_mux_table, },
+	{ HI3516A_A7_MUX, "a7_mux", a7_mux_p, ARRAY_SIZE(a7_mux_p),
+		CLK_SET_RATE_PARENT, 0x30, 8, 2, 0, a7_mux_table, },
+};
+
+/* fixed factor clocks */
+static struct hisi_fixed_factor_clock
+				hi3516a_fixed_factor_clks[] = {
+	{ HI3516A_SYSAXI_CLK, "clk_sysapb", "sysaxi_mux", 1, 4,
+		CLK_SET_RATE_PARENT, },
+};
+
+static const struct hisi_gate_clock hi3516a_gate_clks[] = {
+	/* spi nor */
+	{ HI3516A_SNOR_CLK, "clk_snor", "snor_mux",
+		CLK_SET_RATE_PARENT, 0xc0, 1, 0, },
+	/* spi nand */
+	{ HI3516A_SNAND_CLK, "clk_snand", "snand_mux",
+		CLK_SET_RATE_PARENT, 0xc0, 5, 0, },
+	/* nand */
+	{ HI3516A_NAND_CLK, "clk_nand", "nand_mux",
+		CLK_SET_RATE_PARENT, 0xd8, 1, 0, },
+	/* mmc */
+	{ HI3516A_MMC0_CLK, "clk_mmc0", "mmc0_mux",
+		CLK_SET_RATE_PARENT, 0xc4, 1, 0, },
+	{ HI3516A_MMC1_CLK, "clk_mmc1", "mmc1_mux",
+		CLK_SET_RATE_PARENT, 0xc4, 9, 0, },
+
+	/* usb ctrl */
+	{ HI3516A_USB2_CTRL_UTMI0_REQ, "usb2_cttl_utmi0_req", NULL,
+                CLK_SET_RATE_PARENT, 0xb4, 5, 1, },
+        { HI3516A_USB2_HRST_REQ, "usb2_hrst_req", NULL,
+                CLK_SET_RATE_PARENT, 0xb4, 0, 1, },
+
+	/* uart */
+	{ HI3516A_UART0_CLK, "clk_uart0", "50m",
+		CLK_SET_RATE_PARENT, 0xe4, 15, 0, },
+	{ HI3516A_UART1_CLK, "clk_uart1", "50m",
+		CLK_SET_RATE_PARENT, 0xe4, 16, 0, },
+	{ HI3516A_UART2_CLK, "clk_uart2", "50m",
+		CLK_SET_RATE_PARENT, 0xe4, 17, 0, },
+	{ HI3516A_UART3_CLK, "clk_uart3", "50m",
+		CLK_SET_RATE_PARENT, 0xe4, 18, 0, },
+	/* ethernet mac */
+	{ HI3516A_ETH_CLK, "clk_eth", NULL,
+		CLK_SET_RATE_PARENT, 0xcc, 1, 0, },
+	{ HI3516A_ETH_MACIF_CLK, "clk_eth_macif", NULL,
+		CLK_SET_RATE_PARENT, 0xcc, 3, 0, },
+	/* spi */
+	{ HI3516A_SPI0_CLK, "clk_spi0", "clk_sysapb",
+		CLK_SET_RATE_PARENT, 0xe4, 13, 0, },
+	{ HI3516A_SPI1_CLK, "clk_spi1", "clk_sysapb",
+		CLK_SET_RATE_PARENT, 0xe4, 14, 0, },
+	{ HI3516A_DMAC_CLK, "clk_dmac", "50m",
+		CLK_SET_RATE_PARENT, 0xd8, 5, 0, },
+};
+
+static struct hi3516a_pll_clock hi3516a_pll_clks[] __initdata = {
+	{ HI3516A_APLL_CLK, "apll", NULL, 0x0, 0, 24, 24, 3, 28, 3,
+		0x4, 0, 12, 12, 6},
+};
+
+#define to_pll_clk(_hw) container_of(_hw, struct hi3516a_clk_pll, hw)
+
+static void hi3516a_calc_pll(u32 *frac_val, u32 *postdiv1_val, u32 *postdiv2_val,
+		u32 *fbdiv_val, u32 *refdiv_val, u64 rate)
+{
+	u64 rem;
+	*frac_val = 0;
+	rem = do_div(rate, 1000000);
+	*fbdiv_val = rate;
+	*refdiv_val = 24;
+	rem = rem * (1 << 24);
+	do_div(rem, 1000000);
+	*frac_val = rem;
+}
+
+static int clk_pll_set_rate(struct clk_hw *hw,
+		unsigned long rate,
+		unsigned long parent_rate)
+{
+	struct hi3516a_clk_pll *clk = to_pll_clk(hw);
+	u32 frac_val, postdiv1_val, postdiv2_val, fbdiv_val, refdiv_val;
+	u32 val;
+
+	/*Fixme  ignore postdives now because apll don't use them*/
+	postdiv1_val = postdiv2_val = 0;
+
+	hi3516a_calc_pll(&frac_val, &postdiv1_val, &postdiv2_val,
+			&fbdiv_val, &refdiv_val, (u64)rate);
+
+	val = readl_relaxed(clk->ctrl_reg1);
+	val &= ~(((1 << clk->frac_width) - 1) << clk->frac_shift);
+	val &= ~(((1 << clk->postdiv1_width) - 1) << clk->postdiv1_shift);
+	val &= ~(((1 << clk->postdiv2_width) - 1) << clk->postdiv2_shift);
+
+	val |= frac_val << clk->frac_shift;
+	val |= postdiv1_val << clk->postdiv1_shift;
+	val |= postdiv2_val << clk->postdiv2_shift;
+	writel_relaxed(val, clk->ctrl_reg1);
+
+	val = readl_relaxed(clk->ctrl_reg2);
+	val &= ~(((1 << clk->fbdiv_width) - 1) << clk->fbdiv_shift);
+	val &= ~(((1 << clk->refdiv_width) - 1) << clk->refdiv_shift);
+
+	val |= fbdiv_val << clk->fbdiv_shift;
+	val |= refdiv_val << clk->refdiv_shift;
+	writel_relaxed(val, clk->ctrl_reg2);
+
+	return 0;
+}
+
+static unsigned long clk_pll_recalc_rate(struct clk_hw *hw,
+		unsigned long parent_rate)
+{
+	struct hi3516a_clk_pll *clk = to_pll_clk(hw);
+	u64 frac_val, fbdiv_val, refdiv_val;
+	u32 val;
+	u64 tmp, rate;
+
+	val = readl_relaxed(clk->ctrl_reg1);
+	val = val >> clk->frac_shift;
+	val &= ((1 << clk->frac_width) - 1);
+	frac_val = val;
+
+	val = readl_relaxed(clk->ctrl_reg2);
+	val = val >> clk->fbdiv_shift;
+	val &= ((1 << clk->fbdiv_width) - 1);
+	fbdiv_val = val;
+
+	val = readl_relaxed(clk->ctrl_reg2);
+	val = val >> clk->refdiv_shift;
+	val &= ((1 << clk->refdiv_width) - 1) ;
+	refdiv_val = val;
+
+	/* rate = 24000000 * (fbdiv + frac / (1<<24) ) / refdiv  */
+	rate = 0;
+	tmp = 24000000 * fbdiv_val;
+	rate += tmp;
+	do_div(rate, refdiv_val);
+
+	return rate;
+}
+
+static int clk_pll_determine_rate(struct clk_hw *hw,
+		struct clk_rate_request *req)
+{
+	return req->rate;
+}
+
+static struct clk_ops clk_pll_ops = {
+	.set_rate = clk_pll_set_rate,
+	.determine_rate = clk_pll_determine_rate,
+	.recalc_rate = clk_pll_recalc_rate,
+};
+
+void __init hi3516a_clk_register_pll(struct hi3516a_pll_clock *clks,
+		int nums, struct hisi_clock_data *data)
+{
+	void __iomem *base = data->base;
+	int i;
+
+	for (i = 0; i < nums; i++) {
+		struct hi3516a_clk_pll *p_clk;
+		struct clk *clk;
+		struct clk_init_data init;
+
+		p_clk = kzalloc(sizeof(*p_clk), GFP_KERNEL);
+		if (!p_clk)
+			return;
+
+		init.name = clks[i].name;
+		init.flags = CLK_IS_BASIC;
+		init.parent_names =
+			(clks[i].parent_name ? &clks[i].parent_name : NULL);
+		init.num_parents = (clks[i].parent_name ? 1 : 0);
+		init.ops = &clk_pll_ops;
+
+		p_clk->ctrl_reg1 = base + clks[i].ctrl_reg1;
+		p_clk->frac_shift = clks[i].frac_shift;
+		p_clk->frac_width = clks[i].frac_width;
+		p_clk->postdiv1_shift = clks[i].postdiv1_shift;
+		p_clk->postdiv1_width = clks[i].postdiv1_width;
+		p_clk->postdiv2_shift = clks[i].postdiv2_shift;
+		p_clk->postdiv2_width = clks[i].postdiv2_width;
+
+		p_clk->ctrl_reg2 = base + clks[i].ctrl_reg2;
+		p_clk->fbdiv_shift = clks[i].fbdiv_shift;
+		p_clk->fbdiv_width = clks[i].fbdiv_width;
+		p_clk->refdiv_shift = clks[i].refdiv_shift;
+		p_clk->refdiv_width = clks[i].refdiv_width;
+		p_clk->hw.init = &init;
+
+		clk = clk_register(NULL, &p_clk->hw);
+		if (IS_ERR(clk)) {
+			kfree(p_clk);
+			pr_err("%s: failed to register clock %s\n",
+					__func__, clks[i].name);
+			continue;
+		}
+
+		data->clk_data.clks[clks[i].id] = clk;
+	}
+
+
+}
+
+static struct hisi_clock_data *hi3516a_clk_register(
+		struct platform_device *pdev)
+{
+	struct hisi_clock_data *clk_data;
+	int ret;
+
+	clk_data = hisi_clk_alloc(pdev, HI3516A_CRG_NR_CLKS);
+	if (!clk_data)
+		return ERR_PTR(-ENOMEM);
+
+	ret = hisi_clk_register_fixed_rate(hi3516a_fixed_rate_clks_crg,
+			ARRAY_SIZE(hi3516a_fixed_rate_clks_crg), clk_data);
+	if (ret)
+		return ERR_PTR(ret);
+
+	hi3516a_clk_register_pll(hi3516a_pll_clks,
+			ARRAY_SIZE(hi3516a_pll_clks), clk_data);
+
+	ret = hisi_clk_register_mux(hi3516a_mux_clks_crg,
+			ARRAY_SIZE(hi3516a_mux_clks_crg), clk_data);
+	if (ret)
+		goto unregister_fixed_rate;
+
+	ret = hisi_clk_register_fixed_factor(hi3516a_fixed_factor_clks,
+			ARRAY_SIZE(hi3516a_fixed_factor_clks), clk_data);
+	if (ret)
+		goto unregister_mux;
+
+	ret = hisi_clk_register_gate(hi3516a_gate_clks,
+			ARRAY_SIZE(hi3516a_gate_clks), clk_data);
+	if (ret)
+		goto unregister_factor;
+
+	ret = of_clk_add_provider(pdev->dev.of_node,
+			of_clk_src_onecell_get, &clk_data->clk_data);
+	if (ret)
+		goto unregister_gate;
+
+	return clk_data;
+
+unregister_gate:
+	hisi_clk_unregister_gate(hi3516a_gate_clks,
+			ARRAY_SIZE(hi3516a_gate_clks), clk_data);
+unregister_factor:
+	hisi_clk_unregister_fixed_factor(hi3516a_fixed_factor_clks,
+			ARRAY_SIZE(hi3516a_fixed_factor_clks), clk_data);
+unregister_mux:
+	hisi_clk_unregister_mux(hi3516a_mux_clks_crg,
+			ARRAY_SIZE(hi3516a_mux_clks_crg), clk_data);
+unregister_fixed_rate:
+	hisi_clk_unregister_fixed_rate(hi3516a_fixed_rate_clks_crg,
+			ARRAY_SIZE(hi3516a_fixed_rate_clks_crg), clk_data);
+	return ERR_PTR(ret);
+}
+
+static void hi3516a_clk_unregister(struct platform_device *pdev)
+{
+	struct hisi_crg_dev *crg = platform_get_drvdata(pdev);
+
+	of_clk_del_provider(pdev->dev.of_node);
+
+	hisi_clk_unregister_gate(hi3516a_gate_clks,
+			ARRAY_SIZE(hi3516a_gate_clks), crg->clk_data);
+	hisi_clk_unregister_mux(hi3516a_mux_clks_crg,
+			ARRAY_SIZE(hi3516a_mux_clks_crg), crg->clk_data);
+	hisi_clk_unregister_fixed_factor(hi3516a_fixed_factor_clks,
+			ARRAY_SIZE(hi3516a_fixed_factor_clks), crg->clk_data);
+	hisi_clk_unregister_fixed_rate(hi3516a_fixed_rate_clks_crg,
+			ARRAY_SIZE(hi3516a_fixed_rate_clks_crg), crg->clk_data);
+}
+
+static const struct hisi_crg_funcs hi3516a_crg_funcs = {
+	.register_clks = hi3516a_clk_register,
+	.unregister_clks = hi3516a_clk_unregister,
+};
+
+
+static const struct of_device_id hi3516a_crg_match_table[] = {
+	{
+		.compatible = "hisilicon,hi3516a-clock",
+		.data = &hi3516a_crg_funcs
+	},
+	{ }
+};
+MODULE_DEVICE_TABLE(of, hi3516a_crg_match_table);
+
+static int hi3516a_crg_probe(struct platform_device *pdev)
+{
+	struct hisi_crg_dev *crg;
+
+	crg = devm_kmalloc(&pdev->dev, sizeof(*crg), GFP_KERNEL);
+	if (!crg)
+		return -ENOMEM;
+
+	crg->funcs = of_device_get_match_data(&pdev->dev);
+	if (!crg->funcs)
+		return -ENOENT;
+
+	crg->rstc = hisi_reset_init(pdev);
+	if (!crg->rstc)
+		return -ENOMEM;
+
+	crg->clk_data = crg->funcs->register_clks(pdev);
+	if (IS_ERR(crg->clk_data)) {
+		hisi_reset_exit(crg->rstc);
+		return PTR_ERR(crg->clk_data);
+	}
+
+	platform_set_drvdata(pdev, crg);
+	return 0;
+}
+
+static int hi3516a_crg_remove(struct platform_device *pdev)
+{
+	struct hisi_crg_dev *crg = platform_get_drvdata(pdev);
+
+	hisi_reset_exit(crg->rstc);
+	crg->funcs->unregister_clks(pdev);
+	return 0;
+}
+
+static struct platform_driver hi3516a_crg_driver = {
+	.probe          = hi3516a_crg_probe,
+	.remove     = hi3516a_crg_remove,
+	.driver         = {
+		.name   = "hi3516a-clock",
+		.of_match_table = hi3516a_crg_match_table,
+	},
+};
+
+static int __init hi3516a_crg_init(void)
+{
+	return platform_driver_register(&hi3516a_crg_driver);
+}
+core_initcall(hi3516a_crg_init);
+
+static void __exit hi3516a_crg_exit(void)
+{
+	platform_driver_unregister(&hi3516a_crg_driver);
+}
+module_exit(hi3516a_crg_exit);
+
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("HiSilicon Hi3516A CRG Driver");
diff --git a/drivers/clk/hisilicon/clk-hi3536dv100.c b/drivers/clk/hisilicon/clk-hi3536dv100.c
new file mode 100644
index 0000000..19f35633
--- /dev/null
+++ b/drivers/clk/hisilicon/clk-hi3536dv100.c
@@ -0,0 +1,247 @@
+/*
+ * Hi3536DV100 Clock Driver
+ *
+ * Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <dt-bindings/clock/hi3536dv100-clock.h>
+#include <linux/clk-provider.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include "clk.h"
+#include "crg.h"
+#include "reset.h"
+
+static const struct
+hisi_fixed_rate_clock hi3536dv100_fixed_rate_clks_crg[] = {
+	{ HI3536DV100_FIXED_3M,		"3m",	NULL, 0, 3000000, },
+	{ HI3536DV100_FIXED_6M,		"6m",	NULL, 0, 6000000, },
+	{ HI3536DV100_FIXED_12M,	"12m",	NULL, 0, 12000000, },
+	{ HI3536DV100_FIXED_24M,	"24m",	NULL, 0, 24000000, },
+	{ HI3536DV100_FIXED_50M,	"50m",	NULL, 0, 50000000, },
+	{ HI3536DV100_FIXED_83P3M,	"83.3m",NULL, 0, 83300000, },
+	{ HI3536DV100_FIXED_100M,	"100m", NULL, 0, 100000000, },
+	{ HI3536DV100_FIXED_125M,	"125m", NULL, 0, 125000000, },
+	{ HI3536DV100_FIXED_150M,	"150m", NULL, 0, 150000000, },
+	{ HI3536DV100_FIXED_200M,	"200m", NULL, 0, 200000000, },
+	{ HI3536DV100_FIXED_250M,	"250m", NULL, 0, 250000000, },
+	{ HI3536DV100_FIXED_300M,	"300m", NULL, 0, 300000000, },
+	{ HI3536DV100_FIXED_324M,	"324m", NULL, 0, 324000000, },
+	{ HI3536DV100_FIXED_342M,	"342m", NULL, 0, 342000000, },
+	{ HI3536DV100_FIXED_342M,	"375m", NULL, 0, 375000000, },
+	{ HI3536DV100_FIXED_400M,	"400m", NULL, 0, 400000000, },
+	{ HI3536DV100_FIXED_448M,	"448m", NULL, 0, 448000000, },
+	{ HI3536DV100_FIXED_500M,	"500m", NULL, 0, 500000000, },
+	{ HI3536DV100_FIXED_540M,	"540m", NULL, 0, 540000000, },
+	{ HI3536DV100_FIXED_600M,	"600m", NULL, 0, 600000000, },
+	{ HI3536DV100_FIXED_750M,	"750m",	NULL, 0, 750000000, },
+	{ HI3536DV100_FIXED_1500M,	"1500m",NULL, 0, 1500000000UL, },
+};
+
+static const char *sysaxi_mux_p[] __initconst = {
+	"24m", "250m", "200m", "300m"};
+static const char *sysapb_mux_p[] __initconst = {"24m", "50m"};
+static const char *uart_mux_p[] __initconst = {"sysapb_mux", "24m", "2m"};
+static const char *fmc_mux_p[] __initconst = {"24m", "83.3m", "150m"};
+
+static u32 sysaxi_mux_table[] = {0, 1, 2, 3};
+static u32 sysapb_mux_table[] = {0, 1};
+static u32 uart_mux_table[] = {0, 1, 2};
+static u32 fmc_mux_table[] = {0, 1, 2};
+
+static struct hisi_mux_clock hi3536dv100_mux_clks_crg[] __initdata = {
+	{ HI3536DV100_SYSAXI_CLK, "sysaxi_mux", sysaxi_mux_p,
+		ARRAY_SIZE(sysaxi_mux_p),
+		CLK_SET_RATE_PARENT, 0x50, 2, 2, 0, sysaxi_mux_table, },
+	{ HI3536DV100_SYSAPB_CLK, "sysapb_mux", sysapb_mux_p,
+		ARRAY_SIZE(sysapb_mux_p),
+		CLK_SET_RATE_PARENT, 0x50, 0, 1, 0, sysapb_mux_table, },
+	{ HI3536DV100_FMC_MUX, "fmc_mux", fmc_mux_p, ARRAY_SIZE(fmc_mux_p),
+		CLK_SET_RATE_PARENT, 0xc0, 2, 2, 0, fmc_mux_table, },
+	{ HI3536DV100_UART_MUX, "uart_mux", uart_mux_p,
+		ARRAY_SIZE(uart_mux_p),
+		CLK_SET_RATE_PARENT, 0xcc, 18, 2, 0, uart_mux_table, },
+};
+
+static struct hisi_fixed_factor_clock
+				hi3536dv100_fixed_factor_clks[] __initdata = {
+	{ HI3536DV100_SYSAXI_CLK, "clk_sysaxi", "sysaxi_mux", 1, 4,
+		CLK_SET_RATE_PARENT},
+};
+
+static struct hisi_gate_clock hi3536dv100_gate_clks[] __initdata = {
+	/* fmc */
+	{ HI3536DV100_FMC_CLK, "clk_fmc", "fmc_mux",
+		CLK_SET_RATE_PARENT, 0xc0, 1, 0, },
+	/* uart */
+	{ HI3536DV100_UART0_CLK, "clk_uart0", "24m",
+		CLK_SET_RATE_PARENT, 0xcc, 15, 0, },
+	{ HI3536DV100_UART1_CLK, "clk_uart1", "24m",
+		CLK_SET_RATE_PARENT, 0xcc, 16, 0, },
+	{ HI3536DV100_UART2_CLK, "clk_uart2", "24m",
+		CLK_SET_RATE_PARENT, 0xcc, 17, 0, },
+	/* ethernet mac */
+	{ HI3536DV100_ETH0_CLK, "clk_eth0", NULL,
+		CLK_SET_RATE_PARENT, 0xc4, 1, 0, },
+	{ HI3536DV100_ETH0_PHY_CLK, "clk_eth0_phy", NULL,
+		CLK_SET_RATE_PARENT, 0xc4, 10, 0, },
+	{ HI3536DV100_DMAC_CLK, "clk_dmac", "50m",
+		CLK_SET_RATE_PARENT, 0xc8, 5, 0, },
+};
+
+static struct hisi_clock_data *hi3536dv100_clk_register(
+		struct platform_device *pdev)
+{
+	struct hisi_clock_data *clk_data;
+	int ret;
+
+	clk_data = hisi_clk_alloc(pdev, HI3536DV100_CRG_NR_CLKS);
+	if (!clk_data)
+		return ERR_PTR(-ENOMEM);
+
+	ret = hisi_clk_register_fixed_rate(hi3536dv100_fixed_rate_clks_crg,
+			ARRAY_SIZE(hi3536dv100_fixed_rate_clks_crg), clk_data);
+	if (ret)
+		return ERR_PTR(ret);
+
+	ret = hisi_clk_register_mux(hi3536dv100_mux_clks_crg,
+			ARRAY_SIZE(hi3536dv100_mux_clks_crg), clk_data);
+	if (ret)
+		goto unregister_fixed_rate;
+
+	ret = hisi_clk_register_fixed_factor(hi3536dv100_fixed_factor_clks,
+			ARRAY_SIZE(hi3536dv100_fixed_factor_clks), clk_data);
+	if (ret)
+		goto unregister_mux;
+
+	ret = hisi_clk_register_gate(hi3536dv100_gate_clks,
+			ARRAY_SIZE(hi3536dv100_gate_clks), clk_data);
+	if (ret)
+		goto unregister_factor;
+
+	ret = of_clk_add_provider(pdev->dev.of_node,
+			of_clk_src_onecell_get, &clk_data->clk_data);
+	if (ret)
+		goto unregister_gate;
+
+	return clk_data;
+
+unregister_gate:
+	hisi_clk_unregister_gate(hi3536dv100_gate_clks,
+			ARRAY_SIZE(hi3536dv100_gate_clks), clk_data);
+unregister_factor:
+	hisi_clk_unregister_fixed_factor(hi3536dv100_fixed_factor_clks,
+			ARRAY_SIZE(hi3536dv100_fixed_factor_clks), clk_data);
+unregister_mux:
+	hisi_clk_unregister_mux(hi3536dv100_mux_clks_crg,
+			ARRAY_SIZE(hi3536dv100_mux_clks_crg), clk_data);
+unregister_fixed_rate:
+	hisi_clk_unregister_fixed_rate(hi3536dv100_fixed_rate_clks_crg,
+			ARRAY_SIZE(hi3536dv100_fixed_rate_clks_crg), clk_data);
+	return ERR_PTR(ret);
+}
+
+static void hi3536dv100_clk_unregister(struct platform_device *pdev)
+{
+	struct hisi_crg_dev *crg = platform_get_drvdata(pdev);
+
+	of_clk_del_provider(pdev->dev.of_node);
+
+	hisi_clk_unregister_gate(hi3536dv100_gate_clks,
+			ARRAY_SIZE(hi3536dv100_gate_clks), crg->clk_data);
+	hisi_clk_unregister_mux(hi3536dv100_mux_clks_crg,
+			ARRAY_SIZE(hi3536dv100_mux_clks_crg), crg->clk_data);
+	hisi_clk_unregister_fixed_factor(hi3536dv100_fixed_factor_clks,
+			ARRAY_SIZE(hi3536dv100_fixed_factor_clks), crg->clk_data);
+	hisi_clk_unregister_fixed_rate(hi3536dv100_fixed_rate_clks_crg,
+			ARRAY_SIZE(hi3536dv100_fixed_rate_clks_crg), crg->clk_data);
+}
+
+static const struct hisi_crg_funcs hi3536dv100_crg_funcs = {
+	.register_clks = hi3536dv100_clk_register,
+	.unregister_clks = hi3536dv100_clk_unregister,
+};
+
+
+static const struct of_device_id hi3536dv100_crg_match_table[] = {
+	{
+		.compatible = "hisilicon,hi3536dv100-clock",
+		.data = &hi3536dv100_crg_funcs
+	},
+	{ }
+};
+MODULE_DEVICE_TABLE(of, hi3536dv100_crg_match_table);
+
+static int hi3536dv100_crg_probe(struct platform_device *pdev)
+{
+	struct hisi_crg_dev *crg;
+
+	crg = devm_kmalloc(&pdev->dev, sizeof(*crg), GFP_KERNEL);
+	if (!crg)
+		return -ENOMEM;
+
+	crg->funcs = of_device_get_match_data(&pdev->dev);
+	if (!crg->funcs)
+		return -ENOENT;
+
+	crg->rstc = hisi_reset_init(pdev);
+	if (!crg->rstc)
+		return -ENOMEM;
+
+	crg->clk_data = crg->funcs->register_clks(pdev);
+	if (IS_ERR(crg->clk_data)) {
+		hisi_reset_exit(crg->rstc);
+		return PTR_ERR(crg->clk_data);
+	}
+
+	platform_set_drvdata(pdev, crg);
+	return 0;
+}
+
+static int hi3536dv100_crg_remove(struct platform_device *pdev)
+{
+	struct hisi_crg_dev *crg = platform_get_drvdata(pdev);
+
+	hisi_reset_exit(crg->rstc);
+	crg->funcs->unregister_clks(pdev);
+	return 0;
+}
+
+static struct platform_driver hi3536dv100_crg_driver = {
+	.probe          = hi3536dv100_crg_probe,
+	.remove     = hi3536dv100_crg_remove,
+	.driver         = {
+		.name   = "hi3536dv100-clock",
+		.of_match_table = hi3536dv100_crg_match_table,
+	},
+};
+
+static int __init hi3536dv100_crg_init(void)
+{
+	return platform_driver_register(&hi3536dv100_crg_driver);
+}
+core_initcall(hi3536dv100_crg_init);
+
+static void __exit hi3536dv100_crg_exit(void)
+{
+	platform_driver_unregister(&hi3536dv100_crg_driver);
+}
+module_exit(hi3536dv100_crg_exit);
+
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("HiSilicon Hi3536DV100 CRG Driver");
diff --git a/drivers/clk/hisilicon/crg.h b/drivers/clk/hisilicon/crg.h
new file mode 100644
index 0000000..e073971
--- /dev/null
+++ b/drivers/clk/hisilicon/crg.h
@@ -0,0 +1,34 @@
+/*
+ * HiSilicon Clock and Reset Driver Header
+ *
+ * Copyright (c) 2016 HiSilicon Limited.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __HISI_CRG_H
+#define __HISI_CRG_H
+
+struct hisi_clock_data;
+struct hisi_reset_controller;
+
+struct hisi_crg_funcs {
+	struct hisi_clock_data*	(*register_clks)(struct platform_device *pdev);
+	void (*unregister_clks)(struct platform_device *pdev);
+};
+
+struct hisi_crg_dev {
+	struct hisi_clock_data *clk_data;
+	struct hisi_reset_controller *rstc;
+	const struct hisi_crg_funcs *funcs;
+};
+
+#endif	/* __HISI_CRG_H */
diff --git a/drivers/clocksource/timer-sp804.c b/drivers/clocksource/timer-sp804.c
index d078633..46e9055 100644
--- a/drivers/clocksource/timer-sp804.c
+++ b/drivers/clocksource/timer-sp804.c
@@ -235,6 +235,10 @@ static int __init sp804_of_init(struct device_node *np)
 	writel(0, base + TIMER_CTRL);
 	writel(0, base + TIMER_2_BASE + TIMER_CTRL);
 
+	/* Ensure timer interrupts are clear */
+	writel(1, base + TIMER_INTCLR);
+	writel(1, base + TIMER_2_BASE + TIMER_INTCLR);
+
 	if (initialized || !of_device_is_available(np)) {
 		ret = -EINVAL;
 		goto err;
diff --git a/drivers/gpio/gpio-pl061.c b/drivers/gpio/gpio-pl061.c
index 6e3c143..1489e46 100644
--- a/drivers/gpio/gpio-pl061.c
+++ b/drivers/gpio/gpio-pl061.c
@@ -208,6 +208,25 @@ static int pl061_irq_type(struct irq_data *d, unsigned trigger)
 	return 0;
 }
 
+#ifdef CONFIG_ARCH_HISI_BVT
+static irqreturn_t pl061_irq_handler(int irq, void *data)
+{
+	unsigned long pending;
+	int offset;
+	struct gpio_chip *gc = data;
+	struct pl061_gpio *chip = container_of(gc, struct pl061_gpio, gc);
+
+	pending = readb(chip->base + GPIOMIS);
+	writeb(pending, chip->base + GPIOIC);
+	if (pending) {
+		for_each_set_bit(offset, &pending, PL061_GPIO_NR)
+			generic_handle_irq(irq_find_mapping(gc->irqdomain,
+							    offset));
+	}
+
+	return IRQ_HANDLED;
+}
+#else
 static void pl061_irq_handler(struct irq_desc *desc)
 {
 	unsigned long pending;
@@ -227,6 +246,7 @@ static void pl061_irq_handler(struct irq_desc *desc)
 
 	chained_irq_exit(irqchip, desc);
 }
+#endif
 
 static void pl061_irq_mask(struct irq_data *d)
 {
@@ -308,7 +328,17 @@ static int pl061_probe(struct amba_device *adev, const struct amba_id *id)
 			return -ENODEV;
 		}
 	} else {
+#ifdef CONFIG_ARCH_HISI_BVT
+		if (dev->of_node) {
+			i = of_alias_get_id(dev->of_node, "gpio");
+			chip->gc.base = i * PL061_GPIO_NR;
+		}
+
+		if (chip->gc.base < 0)
+			chip->gc.base = -1;
+#else
 		chip->gc.base = -1;
+#endif
 		irq_base = 0;
 	}
 
@@ -353,8 +383,21 @@ static int pl061_probe(struct amba_device *adev, const struct amba_id *id)
 		dev_info(&adev->dev, "could not add irqchip\n");
 		return ret;
 	}
+#ifdef CONFIG_ARCH_HISI_BVT
+	ret = devm_request_irq(dev, irq, pl061_irq_handler, IRQF_SHARED,
+			dev_name(dev), &chip->gc);
+	if (ret) {
+		dev_info(dev, "request irq failed: %d\n", ret);
+		return ret;
+	}
+
+	/* Set the parent IRQ for all affected IRQs */
+	for (i = 0; i < chip->gc.ngpio; i++)
+		irq_set_parent(irq_find_mapping(chip->gc.irqdomain, i), irq);
+#else
 	gpiochip_set_chained_irqchip(&chip->gc, &pl061_irqchip,
 				     irq, pl061_irq_handler);
+#endif
 
 	for (i = 0; i < PL061_GPIO_NR; i++) {
 		if (pdata) {
diff --git a/drivers/hidmac/Kconfig b/drivers/hidmac/Kconfig
new file mode 100644
index 0000000..dcb3e08b
--- /dev/null
+++ b/drivers/hidmac/Kconfig
@@ -0,0 +1,21 @@
+#
+# Sensor device configuration
+#
+
+config HI_DMAC
+	tristate "Hisilicon DMAC Controller support"
+	depends on (ARCH_HISI_BVT)
+	help
+	  The Direction Memory Access(DMA) is a high-speed data transfer
+	  operation. It supports data read/write between peripherals and
+	  memories without using the CPU.
+	  Hisilicon DMA Controller(DMAC) directly transfers data between
+	  a memory and a peripheral, between peripherals, or between memories.
+	  This avoids the CPU intervention and reduces the interrupt handling
+	  overhead of the CPU.
+
+if HI_DMAC
+config HI_DMAC_CHANNEL_NUM
+	int "hi dmac channel num"
+	default "4"
+endif
diff --git a/drivers/hidmac/Makefile b/drivers/hidmac/Makefile
new file mode 100644
index 0000000..7e41f4c
--- /dev/null
+++ b/drivers/hidmac/Makefile
@@ -0,0 +1,6 @@
+#
+# Makefile for the hi dmac drivers.
+#
+
+obj-$(CONFIG_HI_DMAC)	+= hi_pl08x.o
+
diff --git a/drivers/hidmac/hi_pl08x.c b/drivers/hidmac/hi_pl08x.c
new file mode 100644
index 0000000..daaebdc
--- /dev/null
+++ b/drivers/hidmac/hi_pl08x.c
@@ -0,0 +1,1274 @@
+/*
+ *
+ * Copyright (c) 2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program. If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/gfp.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/i2c.h>
+#include <linux/init.h>
+#include <linux/time.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/platform_device.h>
+#include <linux/dma-mapping.h>
+#include <linux/pm_runtime.h>
+#include <linux/slab.h>
+#include <linux/of.h>
+#include <linux/clk.h>
+#include <linux/reset.h>
+#include <asm/io.h>
+#include <linux/hidmac.h>
+
+#include "hi_pl08x.h"
+
+#ifdef CONFIG_ARCH_HI3536DV100
+#include "hidmac_hi3536dv100.h"
+#endif
+
+#ifdef CONFIG_ARCH_HI3516A
+#include "hidmac_hi3516a.h"
+#endif
+
+#define RX	0
+#define TX	1
+
+static int dmac_channel[CHANNEL_NUM] = {0, 1, 2, 3};
+
+int g_channel_status[CHANNEL_NUM];
+
+/* #define DEBUG */
+
+#define DEBUG
+#ifdef DEBUG
+#define dma_err printk
+#else
+#define dma_err(fmt, ...) do {} while (0)
+#endif
+
+/*
+ *Define Memory range
+ */
+mem_addr mem_num[MEM_MAX_NUM] = {
+	{DDRAM_ADRS, DDRAM_SIZE},
+	{FLASH_BASE, FLASH_SIZE}
+};
+
+typedef void REG_ISR(int *p_dma_chn, int *p_dma_status);
+REG_ISR *function[CHANNEL_NUM];
+
+struct hidmac_host {
+	struct clk *clk;
+	struct reset_control *rstc;
+	void __iomem *regbase;
+
+	int irq;
+};
+
+void __iomem *dma_regbase;
+unsigned int pllihead[2];
+
+#define CLR_INT(i)	((*(unsigned int *)(dma_regbase+0x008)) = (1 << i))
+
+/*
+ *	memory address validity check
+ *
+static int mem_check_valid(unsigned int addr)
+{
+	unsigned int cnt;
+
+	for (cnt = 0; cnt < MEM_MAX_NUM; cnt++) {
+		if ((addr >= mem_num[cnt].addr_base) &&
+			(addr <= (mem_num[cnt].addr_base + mem_num[cnt].size)))
+			return 0;
+	}
+
+	return -1;
+} */
+
+/*
+ * dmac interrupt handle function
+ */
+irqreturn_t dmac_isr(int irq, void *dev_id)
+{
+	struct hidmac_host *dma = dev_id;
+	unsigned int channel_status;
+	unsigned int channel_tc_status, channel_err_status;
+	unsigned int i;
+
+	/*read the status of current interrupt */
+	dmac_readw(dma->regbase + DMAC_INTSTATUS, channel_status);
+
+	/*decide which channel has trigger the interrupt*/
+	for (i = 0; i < DMAC_MAX_CHANNELS; i++) {
+		if ((((channel_status >> i) & 0x1) == 0x01)) {
+			/* [HSCP201306240006],l00181524,20130625 */
+			/* The INT status should be read first then clear it */
+			/* CLR_INT(i); */
+			dmac_readw(dma->regbase + DMAC_INTTCSTATUS, channel_tc_status);
+			dmac_readw(dma->regbase + DMAC_INTERRORSTATUS, channel_err_status);
+			CLR_INT(i);
+			/*??HSCP201403110002?? l00183122 20140723*/
+			if (g_channel_status[i] == DMAC_CHN_VACANCY
+						&& (function[i]) == NULL) {
+				if ((0x01 == ((channel_tc_status >> i) & 0x01)))
+					dmac_writew(dma->regbase + DMAC_INTTCCLEAR,
+								(0x01 << i));
+				else if ((0x01 == ((channel_err_status
+								>> i)&0x01)))
+					dmac_writew(dma->regbase + DMAC_INTERRCLR,
+								(0x01 << i));
+				continue;
+			}
+
+			/* save the current channel transfer */
+			/* status to g_channel_status[i] */
+			if ((0x01 == ((channel_tc_status >> i) & 0x01))) {
+				g_channel_status[i] = DMAC_CHN_SUCCESS;
+				dmac_writew(dma->regbase + DMAC_INTTCCLEAR, (0x01 << i));
+			} else if ((0x01 == ((channel_err_status >> i)&0x01))) {
+				g_channel_status[i] = -DMAC_CHN_ERROR;
+				dmac_writew(dma->regbase + DMAC_INTERRCLR, (0x01 << i));
+			} else {
+				pr_err("Isr Error in DMAC_IntHandeler");
+				pr_err("%d! channel\n", i);
+			}
+
+			if ((function[i]) != NULL)
+				function[i](&i, &g_channel_status[i]);
+		}
+	}
+
+	return IRQ_RETVAL(1);
+}
+
+/*
+ *	update the state of channels
+ */
+#define HI_DMA_UPDATE_TIMEOUT  5000000
+static int dma_update_status(unsigned int channel)
+{
+
+	unsigned int channel_status;
+	unsigned int channel_tc_status[3];
+	unsigned int channel_err_status[3];
+	unsigned int i = channel, j, time = 0;
+
+
+	while (1) {
+		for (j = 0; j < 3; j++) {
+			dmac_readw(dma_regbase + DMAC_INTTCSTATUS, channel_status);
+			channel_tc_status[j] = (channel_status >> i) & 0x01;
+			dmac_readw(dma_regbase + DMAC_INTERRORSTATUS, channel_status);
+			channel_err_status[j] = (channel_status >> i) & 0x01;
+		}
+
+		if ((channel_tc_status[0] == 0x1) &&
+			(channel_tc_status[1] == 0x1) &&
+				(channel_tc_status[2] == 0x1)) {
+			g_channel_status[i] = DMAC_CHN_SUCCESS;
+			dmac_writew(dma_regbase + DMAC_INTTCCLEAR, (0x01 << i));
+			break;
+		} else if ((channel_err_status[0] == 0x1) &&
+			(channel_err_status[1] == 0x1) &&
+				(channel_err_status[2] == 0x1)) {
+			g_channel_status[i] = -DMAC_CHN_ERROR;
+			dma_err("Error in DMAC %d finish!\n", i);
+			dmac_writew(dma_regbase + DMAC_INTERRCLR, (0x01 << i));
+			break;
+		}
+
+		if (++time == HI_DMA_UPDATE_TIMEOUT) {
+			dma_err("Timeout in DMAC %d!\n", i);
+			g_channel_status[i] = -DMAC_CHN_TIMEOUT;
+			break;
+		}
+	}
+
+	return g_channel_status[i];
+}
+
+
+/*
+ *	check the state of channels
+ */
+static int dmac_check_over(unsigned int channel)
+{
+	int status = 0;
+
+	if (-DMAC_CHN_ERROR == g_channel_status[channel]) {
+		dma_err("Error transfer %d finished\n", channel);
+		dmac_writew(dma_regbase + DMAC_CxCONFIG(channel), DMAC_CxDISABLE);
+		g_channel_status[channel] = DMAC_CHN_VACANCY;
+		status = -DMAC_CHN_ERROR;
+	} else if (DMAC_NOT_FINISHED == g_channel_status[channel])
+		status = DMAC_NOT_FINISHED;
+	else if (DMAC_CHN_ALLOCAT == g_channel_status[channel])
+		status = DMAC_CHN_ALLOCAT;
+	else if (DMAC_CHN_VACANCY == g_channel_status[channel])
+		status = DMAC_CHN_VACANCY;
+	else if (-DMAC_CHN_TIMEOUT == g_channel_status[channel]) {
+		dma_err("transfer %d timeout!\n", channel);
+		status = -DMAC_CHN_TIMEOUT;
+	} else if (DMAC_CHN_SUCCESS == g_channel_status[channel])
+		/*The transfer of Channel %d has finished successfully!*/
+		status = DMAC_CHN_SUCCESS;
+	else {
+		dmac_writew(dma_regbase + DMAC_CxCONFIG(channel), DMAC_CxDISABLE);
+		g_channel_status[channel] = DMAC_CHN_VACANCY;
+		status = -DMAC_CHN_ERROR;
+	}
+	return status;
+}
+
+spinlock_t my_lcok = __SPIN_LOCK_UNLOCKED(old_style_spin_init);
+unsigned long flags;
+
+/*
+ *	allocate channel.
+ */
+int dmac_channel_allocate(void *pisr)
+{
+	unsigned int i, channelinfo, g_channelinfo;
+
+	for (i = 0; i < CHANNEL_NUM; i++)
+		dmac_check_over(dmac_channel[i]);
+
+	dmac_readw(dma_regbase + DMAC_ENBLDCHNS, g_channelinfo);
+	g_channelinfo = g_channelinfo & 0x00ff;
+
+	for (i = 0; i < CHANNEL_NUM; i++) {
+		if (g_channel_status[dmac_channel[i]] == DMAC_CHN_VACANCY) {
+			channelinfo = g_channelinfo >> dmac_channel[i];
+			if (0x00 == (channelinfo & 0x01)) {
+				/*clear the interrupt in this channel */
+				dmac_writew(dma_regbase + DMAC_INTERRCLR,
+						(0x01 << dmac_channel[i]));
+				dmac_writew(dma_regbase + DMAC_INTTCCLEAR,
+						(0x01 << dmac_channel[i]));
+
+				g_channel_status[dmac_channel[i]]
+						= DMAC_CHN_ALLOCAT;
+				return dmac_channel[i];
+			}
+		}
+	}
+
+	dma_err("no to alloc\n");
+	return -EINVAL;
+}
+EXPORT_SYMBOL(dmac_channel_allocate);
+
+int dmac_register_isr(unsigned int channel, void *pisr)
+{
+	if (channel > CHANNEL_NUM - 1) {
+		dma_err("channel which choosed %d is error !\n", channel);
+		return -1;
+	}
+
+	if (g_channel_status[channel] != DMAC_CHN_VACANCY) {
+		dma_err("dma chn %d is in used!\n", channel);
+		return -1;
+	}
+
+	/*clear the interrupt in this channel */
+	dmac_writew(dma_regbase + DMAC_INTERRCLR, (0x01 << channel));
+	dmac_writew(dma_regbase + DMAC_INTTCCLEAR, (0x01 << channel));
+
+	function[channel] = (void *)pisr;
+	g_channel_status[channel] = DMAC_CHN_ALLOCAT;
+
+	return 0;
+}
+EXPORT_SYMBOL(dmac_register_isr);
+
+/*
+ *	free channel
+ */
+int dmac_channel_free(unsigned int channel)
+{
+	if (channel >= DMAC_MAX_CHANNELS) {
+		dma_err("channel larger than total.\n");
+		return -EINVAL;
+	}
+
+	g_channel_status[channel] = DMAC_CHN_VACANCY;
+	return 0;
+}
+EXPORT_SYMBOL(dmac_channel_free);
+
+static unsigned int dmac_check_request(unsigned int peripheral_addr,
+					int direction)
+{
+	int i;
+	/* check request pipe with peripheral_addr */
+	for (i = direction; i < DMAC_MAX_PERIPHERALS; i = i + 2) {
+		if (g_peripheral[i].peri_addr == peripheral_addr)
+			return i;
+	}
+
+	dma_err("Invalid devaddr\n");
+
+	return -1;
+}
+
+/*
+ *	init dmac register
+ *	clear interrupt flags
+ *	called by dma_driver_init
+ */
+int dmac_init(struct hidmac_host *dma)
+{
+	unsigned int i, tempvalue;
+	int ret;
+
+	clk_prepare_enable(dma->clk);
+	reset_control_deassert(dma->rstc);
+
+	dmac_readw(dma->regbase + DMAC_CONFIG, tempvalue);
+	if (tempvalue == 0) {
+		dmac_writew(dma->regbase + DMAC_CONFIG,
+				DMAC_CONFIG_VAL);
+		dmac_writew(dma->regbase + DMAC_INTTCCLEAR, 0xFF);
+		dmac_writew(dma->regbase + DMAC_INTERRCLR, 0xFF);
+		for (i = 0; i < DMAC_MAX_CHANNELS; i++) {
+			dmac_writew(dma->regbase + DMAC_CxCONFIG(i),
+				DMAC_CxDISABLE);
+			function[i] = NULL;
+		}
+	}
+
+	/* creat LLI */
+	/* alloc space for dma lli, as the source is uncontinuous, so... */
+	ret = allocate_dmalli_space(pllihead, 1);
+	if (ret < 0)
+		return -1;
+
+	if (request_irq(dma->irq, dmac_isr, 0, "hi_dma", dma)) {
+		dma_err("DMA Irq %d request failed\n", dma->irq);
+		free_dmalli_space(pllihead, 1);
+		return -1;
+	}
+
+	return 0;
+}
+
+
+/*
+ *	alloc_dma_lli_space
+ *	output:
+ *             ppheadlli[0]: memory physics address
+ *             ppheadlli[1]: virtual address
+ *
+ */
+int allocate_dmalli_space(unsigned int *ppheadlli, unsigned int page_num)
+{
+	dma_addr_t dma_phys;
+	void *dma_virt;
+
+	dma_virt = dma_alloc_coherent(NULL, page_num*PAGE_SIZE,
+					&dma_phys, GFP_DMA | GFP_KERNEL);
+	if (NULL == dma_virt) {
+		dma_err("can't get dma mem from system\n");
+		return -1;
+	}
+
+	ppheadlli[0] = (unsigned int)(dma_phys);
+	ppheadlli[1] = (unsigned int)(dma_virt);
+
+	return 0;
+}
+EXPORT_SYMBOL(allocate_dmalli_space);
+
+/*
+ *	free_dma_lli_space
+ */
+int free_dmalli_space(unsigned int *ppheadlli, unsigned int page_num)
+{
+	dma_addr_t dma_phys;
+	unsigned int dma_virt;
+
+	dma_phys = (dma_addr_t)(ppheadlli[0]);
+	dma_virt = ppheadlli[1];
+
+	dma_free_coherent(NULL, page_num*PAGE_SIZE,
+				(void *)dma_virt, dma_phys);
+
+	ppheadlli[0] = 0;
+	ppheadlli[1] = 0;
+	return 0;
+}
+EXPORT_SYMBOL(free_dmalli_space);
+
+/*
+ * config register for memory to memory DMA transfer without LLI
+ * note:
+ * it is necessary to call dmac_channelstart for channel enable
+ */
+int dmac_start_m2m(unsigned int  channel, unsigned int psource,
+			unsigned int pdest, unsigned int uwnumtransfers)
+{
+	unsigned int uwchannel_num, tmp_trasnsfer;
+
+	if (uwnumtransfers > (MAXTRANSFERSIZE << 2)) {
+		dma_err("Invalidate transfer size,size=%x\n", uwnumtransfers);
+		return -EINVAL;
+	}
+
+	uwchannel_num = channel;
+
+	if ((uwchannel_num == DMAC_CHANNEL_INVALID)
+			|| (uwchannel_num > CHANNEL_NUM)) {
+		pr_err("failure of DMAC channel allocation in M2M function!\n");
+		return -EFAULT;
+	}
+
+	/* dmac_writew (DMAC_CxCONFIG(uwchannel_num), DMAC_CxDISABLE); */
+	dmac_writew(dma_regbase + DMAC_CxSRCADDR(uwchannel_num), psource);
+	dmac_writew(dma_regbase + DMAC_CxDESTADDR(uwchannel_num), pdest);
+	dmac_writew(dma_regbase + DMAC_CxLLI(uwchannel_num), 0);
+	tmp_trasnsfer = (uwnumtransfers >> 2) & 0xfff;
+	tmp_trasnsfer = tmp_trasnsfer | (DMAC_CxCONTROL_M2M & (~0xfff));
+	dmac_writew(dma_regbase + DMAC_CxCONTROL(uwchannel_num), tmp_trasnsfer);
+	dmac_writew(dma_regbase + DMAC_CxCONFIG(uwchannel_num), DMAC_CxCONFIG_M2M);
+
+	return 0;
+}
+EXPORT_SYMBOL(dmac_start_m2m);
+
+/*
+ *	channel enable
+ *	start a dma transfer immediately
+ */
+int dmac_channelstart(unsigned int u32channel)
+{
+
+	unsigned int reg_value;
+
+	if (u32channel >= DMAC_MAX_CHANNELS) {
+		dma_err("channel larger %d\n", DMAC_MAX_CHANNELS);
+		return -EINVAL;
+	}
+
+	g_channel_status[u32channel] = DMAC_NOT_FINISHED;
+	dmac_readw(dma_regbase + DMAC_CxCONFIG(u32channel), reg_value);
+	dmac_writew(dma_regbase + DMAC_CxCONFIG(u32channel),
+			(reg_value | DMAC_CHANNEL_ENABLE));
+
+	return 0;
+}
+EXPORT_SYMBOL(dmac_channelstart);
+
+/*
+ *	wait for transfer end
+ */
+int dmac_wait(int channel)
+{
+	int ret_result, ret = 0;
+
+	if (channel < 0)
+		return -1;
+
+	while (1) {
+		ret_result = dma_update_status(channel);
+		if (ret_result == -DMAC_CHN_ERROR) {
+			dma_err("Transfer Error.\n");
+			ret = -1;
+			goto end;
+		} else  if (ret_result == DMAC_NOT_FINISHED)
+			udelay(10);
+		else if (ret_result == DMAC_CHN_SUCCESS) {
+			ret = DMAC_CHN_SUCCESS;
+			goto end;
+		}
+		else if (ret_result == DMAC_CHN_VACANCY) {
+			ret = DMAC_CHN_SUCCESS;
+			goto end;
+		} else if (ret_result == -DMAC_CHN_TIMEOUT) {
+			dma_err("Timeout.\n");
+			dmac_writew(dma_regbase + DMAC_CxCONFIG(channel), DMAC_CxDISABLE);
+			g_channel_status[channel] = DMAC_CHN_VACANCY;
+			ret = -1;
+			goto end;
+		}
+	}
+end:
+	dmac_channelclose(channel);
+	return ret;
+}
+EXPORT_SYMBOL(dmac_wait);
+
+/*
+ *	buile LLI for memory to memory DMA transfer
+ */
+int dmac_buildllim2m_isp(unsigned int *ppheadlli, unsigned int *psource,
+			unsigned int *pdest, unsigned int *length,
+			unsigned int lli_num)
+{
+	unsigned int address, phy_address;
+	unsigned int j;
+
+	if (ppheadlli != NULL) {
+		phy_address = (unsigned int)(ppheadlli[0]);
+		dma_debug("phy_address: 0x%X\n",phy_address);
+		address = (unsigned int)(ppheadlli[1]);
+		dma_debug("address: 0x%X\n",address);
+		for (j = 0; j < lli_num; j++) {
+			dma_debug("psource[%d]: 0x%X\n", j, psource[j]);
+			dmac_writew(address, psource[j]);
+			address += 4;
+			phy_address += 4;
+			dma_debug("pdest[%d]: 0x%X\n", j, pdest[j]);
+			dmac_writew(address, pdest[j]);
+			address += 4;
+			phy_address += 4;
+
+			/* if the last node, next_lli_addr = 0*/
+			if (j == (lli_num - 1))
+				dmac_writew(address, 0);
+			else
+				dmac_writew(address,
+					(((phy_address + 8) & (~0x03))
+					 | DMAC_CxLLI_LM));
+
+			address += 4;
+			phy_address += 4;
+
+			if (j == (lli_num - 1)) {
+				dmac_writew(address, ((DMAC_CxCONTROL_LLIM2M_ISP
+					&(~0xfff)) | (length[j])
+					| 0x80000000));
+			} else {
+				dmac_writew(address,
+					(((DMAC_CxCONTROL_LLIM2M_ISP&(~0xfff)) |
+					 (length[j])) & 0x7fffffff));
+			}
+
+			address += 4;
+			phy_address += 4;
+		}
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(dmac_buildllim2m_isp);
+
+/*
+ *	buile LLI for memory to memory DMA transfer
+ */
+int dmac_buildllim2m(unsigned int *ppheadlli, unsigned int pdest,
+			unsigned int psource, unsigned int totaltransfersize,
+				unsigned int uwnumtransfers)
+{
+	unsigned int lli_num = 0;
+	unsigned int last_lli = 0;
+	unsigned int address , phy_address, srcaddr, denstaddr;
+	unsigned int j;
+
+	lli_num = (totaltransfersize / uwnumtransfers);
+
+	if ((totaltransfersize % uwnumtransfers) != 0)
+		last_lli = 1, ++lli_num;
+
+	if (ppheadlli != NULL) {
+		phy_address = (unsigned int)(ppheadlli[0]);
+		address = (unsigned int)(ppheadlli[1]);
+		for (j = 0; j < lli_num; j++) {
+			srcaddr = (psource + (j*uwnumtransfers));
+			dmac_writew(address, srcaddr);
+			address += 4;
+			phy_address += 4;
+			denstaddr = (pdest + (j*uwnumtransfers));
+			dmac_writew(address, denstaddr);
+			address += 4;
+			phy_address += 4;
+			if (j == (lli_num - 1))
+				dmac_writew(address, 0);
+			else
+				dmac_writew(address,
+					(((phy_address + 8) & (~0x03))
+					 | DMAC_CxLLI_LM));
+
+			address += 4;
+			phy_address += 4;
+
+			if ((j == (lli_num - 1)) && (last_lli == 0))
+				dmac_writew(address, ((DMAC_CxCONTROL_LLIM2M
+					&(~0xfff)) | (uwnumtransfers >> 2)
+					| 0x80000000));
+			else if ((j == (lli_num - 1)) && (last_lli == 1))
+				dmac_writew(address, ((DMAC_CxCONTROL_LLIM2M
+					& (~0xfff)) | ((totaltransfersize
+					% uwnumtransfers) >> 2) | 0x80000000));
+			else
+				dmac_writew(address,
+					(((DMAC_CxCONTROL_LLIM2M&(~0xfff)) |
+					 (uwnumtransfers >> 2)) & 0x7fffffff));
+
+			address += 4;
+			phy_address += 4;
+		}
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(dmac_buildllim2m);
+
+/*
+ *	disable channel
+ *	used before the operation of register configuration
+ */
+int dmac_channelclose(unsigned int channel)
+{
+	unsigned int reg_value, count;
+
+	if (channel >= DMAC_MAX_CHANNELS) {
+		dma_err("channel larger than total.\n");
+		return -EINVAL;
+	}
+
+	dmac_readw(dma_regbase + DMAC_CxCONFIG(channel), reg_value);
+
+#define CHANNEL_CLOSE_IMMEDIATE
+#ifdef CHANNEL_CLOSE_IMMEDIATE
+	reg_value &= 0xFFFFFFFE;
+	dmac_writew(dma_regbase + DMAC_CxCONFIG(channel) , reg_value);
+#else
+	reg_value |= DMAC_CONFIGURATIONx_HALT_DMA_ENABLE;
+	/*ignore incoming dma request*/
+	dmac_writew(dma_regbase + DMAC_CxCONFIG(channel), reg_value);
+	dmac_readw(dma_regbase + DMAC_CxCONFIG(channel), reg_value);
+	/*if FIFO is empty*/
+	while ((reg_value & DMAC_CONFIGURATIONx_ACTIVE)
+			== DMAC_CONFIGURATIONx_ACTIVE)
+		dmac_readw(dma_regbase + DMAC_CxCONFIG(channel), reg_value);
+	reg_value &= 0xFFFFFFFE;
+	dmac_writew(dma_regbase + DMAC_CxCONFIG(channel), reg_value);
+#endif
+
+	dmac_readw(dma_regbase + DMAC_ENBLDCHNS, reg_value);
+	reg_value = reg_value & 0x00ff;
+	count = 0;
+	while (((reg_value >> channel) & 0x1) == 1) {
+		dmac_readw(dma_regbase + DMAC_ENBLDCHNS, reg_value);
+		reg_value = reg_value & 0x00ff;
+		if (count++ > 10000) {
+			dma_err("close failure.\n");
+			return -1;
+		}
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(dmac_channelclose);
+
+/*
+ *	load configuration from LLI for memory to memory
+ */
+int dmac_start_llim2m(unsigned int channel, unsigned int *pfirst_lli)
+{
+	unsigned int uwchannel_num;
+	dmac_lli  plli;
+	unsigned int first_lli;
+
+	if (NULL == pfirst_lli) {
+		dma_err("Invalidate LLI head!\n");
+		return -EFAULT;
+	}
+
+	uwchannel_num = channel;
+	if ((uwchannel_num == DMAC_CHANNEL_INVALID) ||
+				(uwchannel_num > 7)) {
+		dma_err("failure of DMAC channel allocation in");
+		dma_err("LLIM2M function,channel=%x!\n ", uwchannel_num);
+		return -EINVAL;
+	}
+
+	memset(&plli, 0, sizeof(plli));
+	first_lli = (unsigned int)pfirst_lli[1];
+	dmac_readw(first_lli, plli.src_addr);
+	dmac_readw(first_lli+4, plli.dst_addr);
+	dmac_readw(first_lli+8, plli.next_lli);
+	dmac_readw(first_lli+12, plli.lli_transfer_ctrl);
+
+	dmac_channelclose(uwchannel_num);
+	dmac_writew(dma_regbase + DMAC_INTTCCLEAR, (0x1 << uwchannel_num));
+	dmac_writew(dma_regbase + DMAC_INTERRCLR, (0x1 << uwchannel_num));
+	dmac_writew(dma_regbase + DMAC_SYNC, 0x0);
+
+	dmac_writew(dma_regbase + DMAC_CxCONFIG(uwchannel_num),
+			DMAC_CxDISABLE);
+	dmac_writew(dma_regbase + DMAC_CxSRCADDR(uwchannel_num),
+			(unsigned int)(plli.src_addr));
+	dmac_writew(dma_regbase + DMAC_CxDESTADDR(uwchannel_num),
+			(unsigned int)(plli.dst_addr));
+	dmac_writew(dma_regbase + DMAC_CxLLI(uwchannel_num),
+			(unsigned int)(plli.next_lli));
+	dmac_writew(dma_regbase + DMAC_CxCONTROL(uwchannel_num),
+			(unsigned int)(plli.lli_transfer_ctrl));
+	dmac_writew(dma_regbase + DMAC_CxCONFIG(uwchannel_num),
+			DMAC_CxCONFIG_LLIM2M);
+
+	return 0;
+}
+EXPORT_SYMBOL(dmac_start_llim2m);
+
+/*
+ *	load configuration from LLI for memory and peripheral
+ */
+int dmac_start_llim2p(unsigned int channel, unsigned int *pfirst_lli,
+				unsigned int uwperipheralid)
+{
+	unsigned int uwchannel_num;
+	dmac_lli plli;
+	unsigned int first_lli;
+	unsigned int temp = 0;
+
+	if (NULL == pfirst_lli) {
+		dma_err("Invalidate LLI head!\n");
+		return -EINVAL;
+	}
+	uwchannel_num = channel;
+	if ((uwchannel_num == DMAC_CHANNEL_INVALID) ||
+			(uwchannel_num > CHANNEL_NUM)) {
+		dma_err("failure of DMAC channel allocation in");
+		dma_err("LLIM2P function, channel=%x!\n ", uwchannel_num);
+		return -EINVAL;
+	}
+
+	memset(&plli, 0, sizeof(plli));
+	first_lli = (unsigned int)pfirst_lli[1];
+	dmac_readw(first_lli, plli.src_addr);
+	dmac_readw(first_lli+4, plli.dst_addr);
+	dmac_readw(first_lli+8, plli.next_lli);
+	dmac_readw(first_lli+12, plli.lli_transfer_ctrl);
+
+	dmac_channelclose(uwchannel_num);
+	dmac_writew(dma_regbase + DMAC_INTTCCLEAR, (0x1<<uwchannel_num));
+	dmac_writew(dma_regbase + DMAC_INTERRCLR, (0x1<<uwchannel_num));
+	dmac_writew(dma_regbase + DMAC_SYNC, 0x0);
+
+	dmac_readw(dma_regbase + DMAC_CxCONFIG(uwchannel_num), temp);
+	dmac_writew(dma_regbase + DMAC_CxCONFIG(uwchannel_num),
+			temp|DMAC_CxDISABLE);
+	dmac_writew(dma_regbase + DMAC_CxSRCADDR(uwchannel_num),
+			plli.src_addr);
+	dmac_writew(dma_regbase + DMAC_CxDESTADDR(uwchannel_num),
+			plli.dst_addr);
+	dmac_writew(dma_regbase + DMAC_CxLLI(uwchannel_num),
+			plli.next_lli);
+	dmac_writew(dma_regbase + DMAC_CxCONTROL(uwchannel_num),
+			plli.lli_transfer_ctrl);
+
+	return 0;
+}
+EXPORT_SYMBOL(dmac_start_llim2p);
+
+/*
+ *	enable memory and peripheral dma transfer
+ *	note:
+ *	it is necessary to call dmac_channelstart to enable channel
+ */
+int dmac_start_m2p(unsigned int channel, unsigned int memaddr,
+		unsigned int uwperipheralid, unsigned int uwnumtransfers,
+		unsigned int next_lli_addr)
+{
+
+	unsigned int uwtrans_control = 0;
+	unsigned int addtmp, tmp;
+	unsigned int uwdst_addr = 0, uwsrc_addr = 0;
+	unsigned int uwwidth;
+	int uwchannel_num;
+
+	addtmp = memaddr;
+
+	if ((uwperipheralid > 15)) {
+		dma_err("Invalid peripheral id%x\n", uwperipheralid);
+		return -EINVAL;
+	}
+
+	uwchannel_num = (int)channel;
+	if ((uwchannel_num == DMAC_CHANNEL_INVALID)
+		|| (uwchannel_num > CHANNEL_NUM) || (uwchannel_num < 0)) {
+		dma_err("failure alloc\n");
+		return -EFAULT;
+	}
+
+	/* must modified with different peripheral */
+	uwwidth = g_peripheral[uwperipheralid].transfer_width;
+
+	/* check transfer direction *
+	 * even number-->TX, odd number-->RX*/
+	uwsrc_addr = memaddr;
+	uwdst_addr = (unsigned int)(g_peripheral[uwperipheralid].peri_addr);
+
+	tmp = uwnumtransfers >> uwwidth;
+	if (tmp & (~0x0fff)) {
+		dma_err("Invalidate size%x\n", uwnumtransfers);
+		return -EINVAL;
+	}
+
+	tmp = tmp & 0xfff;
+	uwtrans_control = tmp |
+		(g_peripheral[uwperipheralid].transfer_ctrl & (~0xfff));
+	dmac_writew(dma_regbase + DMAC_INTTCCLEAR, (0x1<<(unsigned int)uwchannel_num));
+	dmac_writew(dma_regbase + DMAC_INTERRCLR, (0x1<<(unsigned int)uwchannel_num));
+	dmac_writew(dma_regbase + DMAC_CxSRCADDR(uwchannel_num), (unsigned int)uwsrc_addr);
+	dmac_writew(dma_regbase + DMAC_CxDESTADDR(uwchannel_num), (unsigned int)uwdst_addr);
+	dmac_writew(dma_regbase + DMAC_CxCONTROL(uwchannel_num),
+			(unsigned int)uwtrans_control);
+	dmac_writew(dma_regbase + DMAC_CxCONFIG(uwchannel_num),
+			(g_peripheral[uwperipheralid].transfer_cfg));
+
+	return 0;
+}
+
+/*
+ *	enable memory and peripheral dma transfer
+ *	note:
+ *	it is necessary to call dmac_channelstart to enable channel
+ */
+int dmac_start_p2m(unsigned int channel, unsigned int memaddr,
+		unsigned int uwperipheralid, unsigned int uwnumtransfers,
+		unsigned int next_lli_addr)
+{
+	unsigned int uwtrans_control = 0;
+	unsigned int addtmp, tmp;
+	unsigned int uwdst_addr = 0, uwsrc_addr = 0;
+	unsigned int uwwidth;
+	int uwchannel_num;
+
+	addtmp = memaddr;
+
+	if ((uwperipheralid > 15)) {
+		dma_err("Invalid peripheral id%x\n", uwperipheralid);
+		return -EINVAL;
+	}
+
+	uwchannel_num = (int)channel;
+	if ((uwchannel_num == DMAC_CHANNEL_INVALID)
+		|| (uwchannel_num > 3) || (uwchannel_num < 0)) {
+		dma_err("failure alloc\n");
+		return -EFAULT;
+	}
+
+	/* must modified with different peripheral */
+	uwwidth = g_peripheral[uwperipheralid].transfer_width;
+
+	/* check transfer direction *
+	 * even number-->TX, odd number-->RX*/
+	uwsrc_addr = (unsigned int)(g_peripheral[uwperipheralid].peri_addr);
+	uwdst_addr = memaddr;
+
+	tmp = uwnumtransfers >> uwwidth;
+	if (tmp & (~0x0fff)) {
+		dma_err("Invalidate size%x\n", uwnumtransfers);
+		return -EINVAL;
+	}
+
+	tmp = tmp & 0xfff;
+	uwtrans_control = tmp |
+		(g_peripheral[uwperipheralid].transfer_ctrl & (~0xfff));
+	dmac_writew(dma_regbase + DMAC_INTTCCLEAR, (0x1<<(unsigned int)uwchannel_num));
+	dmac_writew(dma_regbase + DMAC_INTERRCLR, (0x1<<(unsigned int)uwchannel_num));
+	dmac_writew(dma_regbase + DMAC_CxSRCADDR(uwchannel_num),
+			(unsigned int)uwsrc_addr);
+	dmac_writew(dma_regbase + DMAC_CxDESTADDR(uwchannel_num),
+			(unsigned int)uwdst_addr);
+	dmac_writew(dma_regbase + DMAC_CxCONTROL(uwchannel_num),
+			(unsigned int)uwtrans_control);
+	dmac_writew(dma_regbase + DMAC_CxCONFIG(uwchannel_num),
+			(g_peripheral[uwperipheralid].transfer_cfg));
+
+	return 0;
+}
+
+/*
+ *	execute memory to memory dma transfer without LLI
+ */
+int dmac_m2m_transfer(unsigned int source, unsigned int dest,
+						unsigned int length)
+{
+	unsigned int ulchnn, dma_size = 0;
+	unsigned int dma_count, left_size;
+
+	left_size = length;
+	dma_count = 0;
+	ulchnn = dmac_channel_allocate(NULL);
+
+	ulchnn = 2;
+
+	dma_err("use channel %d\n", ulchnn);
+
+	while ((left_size >> 2) >= 0xffc) {
+		dma_size   = 0xffc;
+		left_size -= (dma_size << 2);
+		dma_err("left_size is %x.", left_size);
+		dmac_start_m2m(ulchnn, (unsigned int)(source
+			+ dma_count * (dma_size << 2)),
+			(unsigned int)(dest + dma_count * (dma_size << 2)),
+					(dma_size << 2));
+		if (dmac_channelstart(ulchnn) != 0) {
+			dma_err("start channel error...\n");
+			return -1;
+		}
+
+		if (dmac_wait(ulchnn) != DMAC_CHN_SUCCESS) {
+			dma_err("dma transfer error...\n");
+			return -1;
+		}
+
+		dma_count++;
+	}
+
+	dmac_start_m2m(ulchnn, (source + dma_count * (dma_size << 2)),
+			(dest + dma_count * (dma_size << 2)), (left_size << 2));
+
+	if (dmac_channelstart(ulchnn) != 0)
+		return -1;
+
+	if (dmac_wait(ulchnn) != DMAC_CHN_SUCCESS)
+		return -1;
+
+	return 0;
+}
+EXPORT_SYMBOL(dmac_m2m_transfer);
+
+/*
+ *	execute memory to peripheral dma transfer without LLI
+ */
+int dmac_m2p_transfer(unsigned int memaddr, unsigned int uwperipheralid,
+			unsigned int length)
+{
+	unsigned int ulchnn, dma_size = 0;
+	unsigned int dma_count, left_size;
+	unsigned int uwwidth;
+
+	left_size = length;
+	dma_count = 0;
+
+	ulchnn = dmac_channel_allocate(NULL);
+	if (DMAC_CHANNEL_INVALID == ulchnn)
+		return -1;
+
+	uwwidth = g_peripheral[uwperipheralid].transfer_width;
+
+	while ((left_size >> uwwidth) >= 0xffc) {
+		dma_size = 0xffc;
+		left_size -= (dma_size << uwwidth);
+
+		if (dmac_start_m2p(ulchnn,
+			(unsigned int)(memaddr + dma_count * dma_size),
+			uwperipheralid, (dma_size << uwwidth), 0) < 0)
+			return -1;
+
+		if (dmac_channelstart(ulchnn) != 0)
+			return -1;
+
+		if (dmac_wait(ulchnn) != DMAC_CHN_SUCCESS) {
+			dmac_channel_free(ulchnn);
+			return -1;
+		}
+
+		dma_count++;
+	}
+
+	pr_debug("memaddr=0x%x\n", (unsigned int)(memaddr
+					+ dma_count * dma_size));
+
+	if (dmac_start_m2p(ulchnn,
+		(unsigned int)(memaddr + dma_count * dma_size),
+			uwperipheralid, left_size, 0) < 0)
+		return -1;
+
+	if (dmac_channelstart(ulchnn) != 0)
+		return -1;
+
+	return ulchnn;
+}
+
+/*
+ *	execute memory to peripheral dma transfer without LLI
+ */
+int dmac_p2m_transfer(unsigned int memaddr, unsigned int uwperipheralid,
+			unsigned int length)
+{
+	unsigned int ulchnn, dma_size = 0;
+	unsigned int dma_count, left_size;
+	unsigned int uwwidth;
+
+	left_size = length;
+	dma_count = 0;
+
+	ulchnn = dmac_channel_allocate(NULL);
+	if (DMAC_CHANNEL_INVALID == ulchnn)
+		return -1;
+
+	uwwidth = g_peripheral[uwperipheralid].transfer_width;
+
+	while ((left_size >> uwwidth) >= 0xffc) {
+		dma_size = 0xffc;
+		left_size -= (dma_size << uwwidth);
+
+		if (dmac_start_p2m(ulchnn,
+			(unsigned int)(memaddr + dma_count * dma_size),
+			uwperipheralid, (dma_size << uwwidth), 0) < 0)
+			return -1;
+
+		if (dmac_channelstart(ulchnn) != 0)
+			return -1;
+
+		if (dmac_wait(ulchnn) != DMAC_CHN_SUCCESS) {
+			dmac_channel_free(ulchnn);
+			return -1;
+		}
+
+		dma_count++;
+	}
+
+	pr_debug("memaddr=0x%x\n", (unsigned int)(memaddr
+					+ dma_count * dma_size));
+
+	if (dmac_start_p2m(ulchnn,
+		(unsigned int)(memaddr + dma_count * dma_size),
+			uwperipheralid, left_size, 0) < 0)
+		return -1;
+
+	if (dmac_channelstart(ulchnn) != 0)
+		return -1;
+
+	return ulchnn;
+}
+
+/*
+ * memory to memory dma transfer with LLI
+ *
+ * @source
+ * @dest
+ * @length
+ * @num
+ * */
+int do_dma_llim2m_isp(unsigned int *source,
+		unsigned int *dest,
+		unsigned int *length,
+		unsigned int num)
+{
+	unsigned int chnn;
+	int ret = 0;
+
+	/* the dma channel is default using 2 */
+	chnn = 2;
+
+	ret = dmac_buildllim2m_isp(pllihead, source, dest, length, num);
+
+	if (ret) {
+		dma_err("build lli error...\n");
+		return -1;
+	}
+
+	/* dmac_register_isr(chnn, dmac_channel_close); */
+	ret = dmac_start_llim2m(chnn, pllihead);
+	if (ret)
+		return -1;
+
+	if (dmac_channelstart(chnn) != 0) {
+		dma_err("start channel error...\n");
+		return -1;
+	}
+
+	return ret;
+}
+EXPORT_SYMBOL(do_dma_llim2m_isp);
+
+int do_dma_m2p(unsigned int memaddr, unsigned int peripheral_addr,
+		unsigned int length)
+{
+	int ret = 0;
+	int uwperipheralid;
+
+	uwperipheralid = dmac_check_request(peripheral_addr, TX);
+	if (uwperipheralid < 0) {
+		dma_err("m2p:Invalid devaddr\n");
+		return -1;
+	}
+
+	ret = dmac_m2p_transfer(memaddr, uwperipheralid, length);
+	if (ret == -1) {
+		dma_err("m2p:trans err\n");
+		return -1;
+	}
+
+	return ret;
+}
+
+int do_dma_p2m(unsigned int memaddr, unsigned int peripheral_addr,
+		unsigned int length)
+{
+	int ret = -1;
+	int uwperipheralid;
+
+	uwperipheralid = dmac_check_request(peripheral_addr, RX);
+	if (uwperipheralid < 0) {
+		dma_err("p2m:Invalid devaddr.\n");
+		return -1;
+	}
+
+	ret = dmac_p2m_transfer(memaddr, uwperipheralid, length);
+	if (ret == -1) {
+		dma_err("p2m:trans err\n");
+		return -1;
+	}
+
+	return ret;
+}
+
+/*
+ *	Apply DMA interrupt resource
+ *	init channel state
+ */
+static int hi_dmac_probe(struct platform_device *platdev)
+{
+	unsigned int i;
+	struct hidmac_host *dma;
+	struct resource *res;
+	int ret;
+
+	dma = devm_kzalloc(&platdev->dev, sizeof(*dma), GFP_KERNEL);
+	if (!dma)
+		return -ENOMEM;
+
+	res = platform_get_resource(platdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(&platdev->dev, "no mmio resource\n");
+		return -ENODEV;
+	}
+
+	dma->regbase = devm_ioremap_resource(&platdev->dev, res);
+	if (IS_ERR(dma->regbase))
+		return PTR_ERR(dma->regbase);
+
+	dma->clk = devm_clk_get(&platdev->dev, NULL);
+	if (IS_ERR(dma->clk))
+		return PTR_ERR(dma->clk);
+
+	dma->rstc = devm_reset_control_get(&platdev->dev, "dma-reset");
+	if (IS_ERR(dma->rstc))
+		return PTR_ERR(dma->rstc);
+
+	dma->irq = platform_get_irq(platdev, 0);
+	if (unlikely(dma->irq < 0))
+		return -ENODEV;
+
+	dma_regbase = dma->regbase;
+
+	ret = dmac_init(dma);
+	if (ret)
+		return -ENODEV;
+
+	platform_set_drvdata(platdev, dma);
+
+	for (i = 0; i < DMAC_MAX_CHANNELS; i++)
+		g_channel_status[i] = DMAC_CHN_VACANCY;
+
+	dev_info(&platdev->dev, "hidmac probe!\n");
+	return ret;
+}
+
+static int hi_dmac_remove(struct platform_device *platdev)
+{
+	int i;
+	struct hidmac_host *dma = platform_get_drvdata(platdev);
+
+	clk_disable_unprepare(dma->clk);
+
+	for (i = 0; i < DMAC_MAX_CHANNELS; i++)
+		g_channel_status[i] = DMAC_CHN_VACANCY;
+
+	free_dmalli_space(pllihead, 1);
+
+	return 0;
+}
+
+static int hi_dmac_suspend(struct platform_device *platdev,
+		pm_message_t state)
+{
+	int i;
+	struct hidmac_host *dma = platform_get_drvdata(platdev);
+
+	clk_prepare_enable(dma->clk);
+
+	for (i = 0; i < DMAC_MAX_CHANNELS; i++)
+		g_channel_status[i] = DMAC_CHN_VACANCY;
+
+	clk_disable_unprepare(dma->clk);
+
+	return 0;
+}
+
+static int hi_dmac_resume(struct platform_device *platdev)
+{
+	int i;
+	struct hidmac_host *dma = platform_get_drvdata(platdev);
+	unsigned int tempvalue;
+
+	clk_prepare_enable(dma->clk);
+	reset_control_deassert(dma->rstc);
+
+	dmac_readw(dma->regbase + DMAC_CONFIG, tempvalue);
+	if (tempvalue == 0) {
+		dmac_writew(dma->regbase + DMAC_CONFIG,
+				DMAC_CONFIG_VAL);
+		dmac_writew(dma->regbase + DMAC_INTTCCLEAR, 0xFF);
+		dmac_writew(dma->regbase + DMAC_INTERRCLR, 0xFF);
+		for (i = 0; i < DMAC_MAX_CHANNELS; i++) {
+			dmac_writew(dma->regbase + DMAC_CxCONFIG(i),
+				DMAC_CxDISABLE);
+			function[i] = NULL;
+		}
+	}
+
+	for (i = 0; i < DMAC_MAX_CHANNELS; i++)
+		g_channel_status[i] = DMAC_CHN_VACANCY;
+
+	return 0;
+}
+
+static const struct of_device_id hisi_dmac_dt_ids[] = {
+	{ .compatible = "hisilicon,hisi-dmac"},
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, hisi_dmac_dt_ids);
+
+static struct platform_driver hisi_dmac_driver = {
+	.driver = {
+		.name   = "hisi-dmac",
+		.of_match_table = hisi_dmac_dt_ids,
+	},
+	.probe      = hi_dmac_probe,
+	.remove     = hi_dmac_remove,
+	.suspend    = hi_dmac_suspend,
+	.resume     = hi_dmac_resume,
+};
+
+module_platform_driver(hisi_dmac_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Hisilicon");
+MODULE_DESCRIPTION("HiSilicon DMA Controller driver");
diff --git a/drivers/hidmac/hi_pl08x.h b/drivers/hidmac/hi_pl08x.h
new file mode 100644
index 0000000..2213e3a
--- /dev/null
+++ b/drivers/hidmac/hi_pl08x.h
@@ -0,0 +1,79 @@
+/* ./drivers/hidmac/hi_dmac.h
+ *
+ *
+ * History:
+ *      17-August-2006 create this file
+ */
+#ifndef __HI_DMAC_H__
+#define __HI_DMAC_H__
+
+#define  dmac_writew(addr, value)\
+	writel(value, (void *)(addr))
+#define  dmac_readw(addr, v)\
+	v = readl((void *)(addr))
+
+/*#define DMA_DEBUG*/
+#ifdef DMA_DEBUG
+#define dma_debug printk
+#else
+#define dma_debug(fmt, ...) do {} while (0);
+#endif
+
+#define DMAC_CONFIGURATIONx_HALT_DMA_ENABLE	(0x01L<<18)
+#define DMAC_CONFIGURATIONx_ACTIVE		(0x01L<<17)
+#define DMAC_CONFIGURATIONx_CHANNEL_ENABLE	1
+#define DMAC_CONFIGURATIONx_CHANNEL_DISABLE	0
+
+/*definition for the return value*/
+#define DMAC_ERROR_BASE				100
+#define DMAC_CHANNEL_INVALID			(DMAC_ERROR_BASE+1)
+
+#define DMAC_TRXFERSIZE_INVALID			(DMAC_ERROR_BASE+2)
+#define DMAC_SOURCE_ADDRESS_INVALID		(DMAC_ERROR_BASE+3)
+#define DMAC_DESTINATION_ADDRESS_INVALID	(DMAC_ERROR_BASE+4)
+#define DMAC_MEMORY_ADDRESS_INVALID		(DMAC_ERROR_BASE+5)
+#define DMAC_PERIPHERAL_ID_INVALID		(DMAC_ERROR_BASE+6)
+#define DMAC_DIRECTION_ERROR			(DMAC_ERROR_BASE+7)
+#define DMAC_TRXFER_ERROR			(DMAC_ERROR_BASE+8)
+#define DMAC_LLIHEAD_ERROR			(DMAC_ERROR_BASE+9)
+#define DMAC_SWIDTH_ERROR			(DMAC_ERROR_BASE+0xa)
+#define DMAC_LLI_ADDRESS_INVALID		(DMAC_ERROR_BASE+0xb)
+#define DMAC_TRANS_CONTROL_INVALID		(DMAC_ERROR_BASE+0xc)
+#define DMAC_MEMORY_ALLOCATE_ERROR		(DMAC_ERROR_BASE+0xd)
+#define DMAC_NOT_FINISHED			(DMAC_ERROR_BASE+0xe)
+
+#define DMAC_TIMEOUT				(DMAC_ERROR_BASE+0xf)
+#define DMAC_CHN_SUCCESS			(DMAC_ERROR_BASE+0x10)
+#define DMAC_CHN_ERROR				(DMAC_ERROR_BASE+0x11)
+#define DMAC_CHN_TIMEOUT			(DMAC_ERROR_BASE+0x12)
+#define DMAC_CHN_ALLOCAT			(DMAC_ERROR_BASE+0x13)
+#define DMAC_CHN_VACANCY			(DMAC_ERROR_BASE+0x14)
+
+#define DMAC_CONFIGURATIONx_ACTIVE_NOT		0
+
+/*the means the bit in the channel control register*/
+#define DMAC_TRANS_SIZE         0xff0
+
+/*DMAC peripheral structure*/
+typedef struct dmac_peripheral {
+	/* peripherial ID*/
+	unsigned int peri_id;
+	/*peripheral data register address*/
+	unsigned int peri_addr;
+	/*default channel control word*/
+	unsigned int transfer_ctrl;
+	/*default channel configuration word*/
+	unsigned int transfer_cfg;
+	/*default channel configuration word*/
+	unsigned int transfer_width;
+} dmac_peripheral;
+
+typedef struct mem_addr {
+	unsigned int addr_base;
+	unsigned int size;
+} mem_addr;
+
+typedef unsigned int dma_addr_t;
+/* #define PAGE_SIZE 0x1000 */
+
+#endif /* End of #ifndef __HI_INC_ECSDMACC_H__ */
diff --git a/drivers/hidmac/hidmac_hi3516a.h b/drivers/hidmac/hidmac_hi3516a.h
new file mode 100644
index 0000000..433c41c
--- /dev/null
+++ b/drivers/hidmac/hidmac_hi3516a.h
@@ -0,0 +1,159 @@
+#ifndef __HI_DMAC_HI3516A_H__
+#define __HI_DMAC_HI3516A_H__
+
+#define DDRAM_ADRS	0x80000000      /* fixed */
+#define DDRAM_SIZE	0x1FFFFFFF      /* 512M DDR. */
+
+#define FLASH_BASE	0x10000000
+#define FLASH_SIZE	0x04000000      /* (32MB) */
+
+#define DMAC_INTSTATUS		0X00
+#define DMAC_INTTCSTATUS	0X04
+#define DMAC_INTTCCLEAR		0X08
+#define DMAC_INTERRORSTATUS	0X0C
+
+#define DMAC_INTERRCLR		0X10
+#define DMAC_RAWINTTCSTATUS	0X14
+#define DMAC_RAWINTERRORSTATUS	0X18
+#define DMAC_ENBLDCHNS		0X1C
+#define DMAC_CONFIG			0X30
+#define DMAC_SYNC			0X34
+
+#define DMAC_MAXTRANSFERSIZE	0x0fff /*the max length is denoted by 0-11bit*/
+#define MAXTRANSFERSIZE		DMAC_MAXTRANSFERSIZE
+#define DMAC_CxDISABLE		0x00
+#define DMAC_CxENABLE		0x01
+
+/*the definition for DMAC channel register*/
+#define DMAC_CxBASE(i)		(0x100+i*0x20)
+#define DMAC_CxSRCADDR(i)	DMAC_CxBASE(i)
+#define DMAC_CxDESTADDR(i)	(DMAC_CxBASE(i)+0x04)
+#define DMAC_CxLLI(i)		(DMAC_CxBASE(i)+0x08)
+#define DMAC_CxCONTROL(i)	(DMAC_CxBASE(i)+0x0C)
+#define DMAC_CxCONFIG(i)	(DMAC_CxBASE(i)+0x10)
+
+/*the means the bit in the channel control register*/
+#define DMAC_CxCONTROL_M2M	0x9d480000  /* Dwidth=32,burst size=4 */
+#define DMAC_CxCONTROL_LLIM2M		0x0f480000  /* Dwidth=32,burst size=1 */
+#define DMAC_CxCONTROL_LLIM2M_ISP	0x0b489000  /* Dwidth=32,burst size=1 */
+#define DMAC_CxCONTROL_LLIP2M    0x0a000000
+#define DMAC_CxCONTROL_LLIM2P    0x86089000
+#define DMAC_CxLLI_LM		0x01
+
+#define NUM_HAL_INTERRUPT_DMAC         (14 + 16)
+
+#define DMAC_CxCONFIG_M2M	0xc000
+#define DMAC_CxCONFIG_LLIM2M	0xc000
+
+/*#define DMAC_CxCONFIG_M2M  0x4001*/
+#define DMAC_CHANNEL_ENABLE	1
+#define DMAC_CHANNEL_DISABLE	0xfffffffe
+
+#define DMAC_CxCONTROL_P2M	0x89409000
+#define DMAC_CxCONFIG_P2M	0xd000
+
+#define DMAC_CxCONTROL_M2P	0x86089000
+#define DMAC_CxCONFIG_M2P	0xc800
+
+#define DMAC_CxCONFIG_SIO_P2M	0x0000d000
+#define DMAC_CxCONFIG_SIO_M2P	0x0000c800
+
+/*default the config and sync regsiter for DMAC controller*/
+/*M1,M2 little endian, enable DMAC*/
+#define DMAC_CONFIG_VAL		0x01
+/*enable the sync logic for the 16 peripheral*/
+#define DMAC_SYNC_VAL		0x0
+
+#define DMAC_MAX_PERIPHERALS	16
+#define MEM_MAX_NUM		2
+#define CHANNEL_NUM		CONFIG_HI_DMAC_CHANNEL_NUM
+#define DMAC_MAX_CHANNELS	CHANNEL_NUM
+
+#define MMC_REG_BASE		0x10030000
+#define MMC_RX_REG		(MMC_REG_BASE+0x100)
+#define MMC_TX_REG		(MMC_REG_BASE+0x100)
+
+#define UART0_REG_BASE		0x20080000
+#define UART0_DATA_REG		(UART0_REG_BASE + 0x0)
+
+#define UART1_REG_BASE		0x20090000
+#define UART1_DATA_REG		(UART1_REG_BASE + 0x0)
+
+#define UART2_REG_BASE		0x200A0000
+#define UART2_DATA_REG		(UART2_REG_BASE + 0x0)
+
+#define UART3_REG_BASE		0x200B0000
+#define UART3_DATA_REG		(UART3_REG_BASE + 0x0)
+
+#define SPI0_REG_BASE       0x200c0000
+#define SPI0_DATA_REG       (SPI0_REG_BASE + 0x08)
+
+#define SPI1_REG_BASE       0x200e0000
+#define SPI1_DATA_REG       (SPI1_REG_BASE + 0x08)
+
+#define I2C0_REG_BASE       0x200d0000
+#define I2C0_DATA_REG       (I2C0_REG_BASE + 0x10)
+
+#define I2C1_REG_BASE       0x20240000
+#define I2C1_DATA_REG       (I2C1_REG_BASE + 0x10)
+
+#define PERI_8BIT_MODE            0
+#define PERI_16BIT_MODE           1
+#define PERI_32BIT_MODE           2
+/*the transfer control and configuration value for different peripheral*/
+
+extern int g_channel_status[CHANNEL_NUM];
+
+/*
+ *	DMA config array!
+ *	DREQ, FIFO, CONTROL, CONFIG, BITWIDTH
+ */
+dmac_peripheral  g_peripheral[DMAC_MAX_PERIPHERALS] = {
+	/* DREQ,  FIFO,   CONTROL,   CONFIG, WIDTH */
+	/*periphal 0: I2C0/I2C1 RX*/
+	{ 0, I2C0_DATA_REG, 0x99000000, 0xd000, PERI_8BIT_MODE},
+	/*periphal 1: I2C0/I2C1 TX*/
+	{ 1, I2C0_DATA_REG, 0x96000000, 0xc840, PERI_8BIT_MODE},
+	/*periphal 2: I2C1/I2C2 RX*/
+	{ 2, I2C1_DATA_REG, 0x99000000, 0xd004, PERI_8BIT_MODE},    /*  8bit width */
+	/*periphal 3: I2C1/I2C2 TX*/
+	{ 3, I2C1_DATA_REG, 0x96000000, 0xc8c0, PERI_8BIT_MODE},    /*  8bit width */
+
+	/*periphal 4: UART0 RX*/
+	{ 4, UART0_DATA_REG, DMAC_CxCONTROL_LLIP2M, DMAC_CxCONFIG_P2M | (4 << 1), PERI_8BIT_MODE},
+
+	/*periphal 5: UART0 TX*/
+	{ 5, UART0_DATA_REG, DMAC_CxCONTROL_LLIM2P, DMAC_CxCONFIG_M2P | (5 << 1), PERI_8BIT_MODE},
+
+	/*periphal 6: UART1 RX*/
+	{ 6, UART1_DATA_REG, DMAC_CxCONTROL_LLIP2M, DMAC_CxCONFIG_P2M | (6 << 1), PERI_8BIT_MODE},
+
+	/*periphal 7: UART1 TX*/
+	{ 7, UART1_DATA_REG, DMAC_CxCONTROL_LLIM2P, DMAC_CxCONFIG_M2P | (7 << 1), PERI_8BIT_MODE},
+
+	/*periphal 8: UART2 RX*/
+	{ 8, UART2_DATA_REG, DMAC_CxCONTROL_LLIP2M, DMAC_CxCONFIG_P2M | (8 << 1), PERI_8BIT_MODE},
+
+	/*periphal 9: UART2 TX*/
+	{ 9, UART2_DATA_REG, DMAC_CxCONTROL_LLIM2P, DMAC_CxCONFIG_M2P | (9 << 1), PERI_8BIT_MODE},
+
+	/*periphal 10: UART3 RX*/
+	{ 10, UART3_DATA_REG, DMAC_CxCONTROL_LLIP2M, DMAC_CxCONFIG_P2M | (10 << 1), PERI_8BIT_MODE},
+
+	/*periphal 11: UART0 TX*/
+	{ 11, UART3_DATA_REG, DMAC_CxCONTROL_LLIM2P, DMAC_CxCONFIG_M2P | (11 << 1), PERI_8BIT_MODE},
+
+	/*periphal 12: SSP1 RX*/
+	{ 12, 0, 0, 0, 0},
+
+	/*periphal 13: SSP1 TX*/
+	{ 13, 0, 0, 0, 0},
+
+	/*periphal 14: SSP0 RX*/
+	{ 14, 0, 0, 0, 0},
+
+	/*periphal 15: SSP0 TX*/
+	{ 15, 0, 0, 0, 0},
+};
+
+#endif
diff --git a/drivers/hidmac/hidmac_hi3536dv100.h b/drivers/hidmac/hidmac_hi3536dv100.h
new file mode 100644
index 0000000..f6efcf5
--- /dev/null
+++ b/drivers/hidmac/hidmac_hi3536dv100.h
@@ -0,0 +1,114 @@
+#ifndef __HI_DMAC_HI3516CV300_H__
+#define __HI_DMAC_HI3516CV300_H__
+
+#define DDRAM_ADRS	0x80000000      /* fixed */
+#define DDRAM_SIZE	0x1FFFFFFF      /* 512M DDR. */
+
+#define FLASH_BASE	0x10000000
+#define FLASH_SIZE	0x04000000      /* (32MB) */
+
+#define DMAC_INTSTATUS		0X00
+#define DMAC_INTTCSTATUS	0X04
+#define DMAC_INTTCCLEAR		0X08
+#define DMAC_INTERRORSTATUS	0X0C
+
+#define DMAC_INTERRCLR		0X10
+#define DMAC_RAWINTTCSTATUS	0X14
+#define DMAC_RAWINTERRORSTATUS	0X18
+#define DMAC_ENBLDCHNS		0X1C
+#define DMAC_CONFIG			0X30
+#define DMAC_SYNC			0X34
+
+#define DMAC_MAXTRANSFERSIZE	0x0fff /*the max length is denoted by 0-11bit*/
+#define MAXTRANSFERSIZE		DMAC_MAXTRANSFERSIZE
+#define DMAC_CxDISABLE		0x00
+#define DMAC_CxENABLE		0x01
+
+/*the definition for DMAC channel register*/
+#define DMAC_CxBASE(i)		(0x100+i*0x20)
+#define DMAC_CxSRCADDR(i)	DMAC_CxBASE(i)
+#define DMAC_CxDESTADDR(i)	(DMAC_CxBASE(i)+0x04)
+#define DMAC_CxLLI(i)		(DMAC_CxBASE(i)+0x08)
+#define DMAC_CxCONTROL(i)	(DMAC_CxBASE(i)+0x0C)
+#define DMAC_CxCONFIG(i)	(DMAC_CxBASE(i)+0x10)
+
+/*the means the bit in the channel control register*/
+#define DMAC_CxCONTROL_M2M	0x9d480000  /* Dwidth=32,burst size=4 */
+#define DMAC_CxCONTROL_LLIM2M		0x0f480000  /* Dwidth=32,burst size=1 */
+#define DMAC_CxCONTROL_LLIM2M_ISP	0x0b489000  /* Dwidth=32,burst size=1 */
+#define DMAC_CxLLI_LM		0x01
+
+#define NUM_HAL_INTERRUPT_DMAC         (14 + 16)
+
+#define DMAC_CxCONFIG_M2M	0xc000
+#define DMAC_CxCONFIG_LLIM2M	0xc000
+
+/*#define DMAC_CxCONFIG_M2M  0x4001*/
+#define DMAC_CHANNEL_ENABLE	1
+#define DMAC_CHANNEL_DISABLE	0xfffffffe
+
+#define DMAC_CxCONTROL_P2M	0x89409000
+#define DMAC_CxCONFIG_P2M	0xd000
+
+#define DMAC_CxCONTROL_M2P	0x86089000
+#define DMAC_CxCONFIG_M2P	0xc800
+
+#define DMAC_CxCONFIG_SIO_P2M	0x0000d000
+#define DMAC_CxCONFIG_SIO_M2P	0x0000c800
+
+/*default the config and sync regsiter for DMAC controller*/
+/*M1,M2 little endian, enable DMAC*/
+#define DMAC_CONFIG_VAL		0x01
+/*enable the sync logic for the 16 peripheral*/
+#define DMAC_SYNC_VAL		0x0
+
+#define DMAC_MAX_PERIPHERALS	16
+#define MEM_MAX_NUM		2
+#define CHANNEL_NUM		CONFIG_HI_DMAC_CHANNEL_NUM
+#define DMAC_MAX_CHANNELS	CHANNEL_NUM
+
+#define REG_BASE_I2C0		0x120c0000
+#define I2C0_DATA_RXF		(REG_BASE_I2C0 + 0x24)
+#define I2C0_DATA_TXF		(REG_BASE_I2C0 + 0x20)
+
+
+#define REG_BASE_UART0		0x12080000
+#define UART0_DATA_REG		(REG_BASE_UART0 + 0x0)
+
+#define REG_BASE_UART1		0x12090000
+#define UART1_DATA_REG		(REG_BASE_UART1 + 0x0)
+
+#define REG_BASE_UART2		0x120a0000
+#define UART2_DATA_REG		(REG_BASE_UART2 + 0x0)
+
+/*the transfer control and configuration value for different peripheral*/
+
+extern int g_channel_status[CHANNEL_NUM];
+
+dmac_peripheral  g_peripheral[DMAC_MAX_PERIPHERALS] = {
+	/*periphal 0: UART0 RX, 8bit width */
+	{0, UART0_DATA_REG, 0x99000000, 0xd000, 0},
+
+	/*periphal 1: UART0 TX, 8bit width */
+	{1, UART0_DATA_REG, 0x96000000, 0xc840, 0},
+
+	/*periphal 2: UART1 RX, 8bit width */
+	{2, UART1_DATA_REG, 0x99000000, 0xd004, 0},
+
+	/*periphal 3: UART1 TX, 8bit width */
+	{3, UART1_DATA_REG, 0x96000000, 0xc8c0, 0},
+
+	/*periphal 4: UART2 RX, 8bit width */
+	{4, UART2_DATA_REG, 0x99000000, 0xd008, 0},
+
+	/*periphal 5: UART2 TX, 8bit width */
+	{5, UART2_DATA_REG, 0x96000000, 0xc940, 0},
+
+	/*periphal 6: I2C0 RX, 8bit width */
+	{6, I2C0_DATA_RXF, 0x99000000, 0xd00c, 0},
+
+	/*periphal 7: I2C0 TX, 8bit width */
+	{7, I2C0_DATA_TXF, 0x96000000, 0xc9c0, 0},
+};
+
+#endif
diff --git a/drivers/i2c/busses/Kconfig b/drivers/i2c/busses/Kconfig
index d252276..fe3f48c 100644
--- a/drivers/i2c/busses/Kconfig
+++ b/drivers/i2c/busses/Kconfig
@@ -555,6 +555,16 @@ config I2C_GPIO
 	  This is a very simple bitbanging I2C driver utilizing the
 	  arch-neutral GPIO API to control the SCL and SDA lines.
 
+config I2C_HIBVT
+	tristate "Hisilicon BVT I2C Controller"
+	depends on ARCH_HISI_BVT
+	help
+	  Say Y here to include support for Hisilicon BVT I2C controller in the
+	  Hisilicon BVT SoCs.
+
+	  This driver can also be built as a module.  If so, the module
+	  will be called i2c-hibvt.
+
 config I2C_HIGHLANDER
 	tristate "Highlander FPGA SMBus interface"
 	depends on SH_HIGHLANDER
@@ -1214,4 +1224,20 @@ config I2C_OPAL
 	  This driver can also be built as a module. If so, the module will be
 	  called as i2c-opal.
 
+config I2C_HISI
+	tristate "Hisilicon I2C Controller support"
+	depends on ARCH_HI3516A
+	help
+	  Hisilicon I2C controller has 3 buses.
+	  We can access some sensors though it.
+	  This IP is only used in HI3516A chip.
+
+config DMA_MSG_LEN
+	int "Hisilicon I2C support DMA minimum LEN"
+	depends on I2C_HIBVT
+	range 1 1024
+	default 5
+	help
+		The i2c_msg minimum LEN of i2c support DMA,range from 1 to 1024
+
 endmenu
diff --git a/drivers/i2c/busses/Makefile b/drivers/i2c/busses/Makefile
index 29764cc..f96cde3 100644
--- a/drivers/i2c/busses/Makefile
+++ b/drivers/i2c/busses/Makefile
@@ -51,6 +51,7 @@ obj-$(CONFIG_I2C_EG20T)		+= i2c-eg20t.o
 obj-$(CONFIG_I2C_EMEV2)		+= i2c-emev2.o
 obj-$(CONFIG_I2C_EXYNOS5)	+= i2c-exynos5.o
 obj-$(CONFIG_I2C_GPIO)		+= i2c-gpio.o
+obj-$(CONFIG_I2C_HIBVT)		+= i2c-hibvt.o
 obj-$(CONFIG_I2C_HIGHLANDER)	+= i2c-highlander.o
 obj-$(CONFIG_I2C_HIX5HD2)	+= i2c-hix5hd2.o
 obj-$(CONFIG_I2C_IBM_IIC)	+= i2c-ibm_iic.o
@@ -122,4 +123,6 @@ obj-$(CONFIG_I2C_SIBYTE)	+= i2c-sibyte.o
 obj-$(CONFIG_I2C_XGENE_SLIMPRO) += i2c-xgene-slimpro.o
 obj-$(CONFIG_SCx200_ACB)	+= scx200_acb.o
 
+obj-$(CONFIG_I2C_HISI)		+= i2c-hisilicon.o
+
 ccflags-$(CONFIG_I2C_DEBUG_BUS) := -DDEBUG
diff --git a/drivers/i2c/busses/i2c-hibvt.c b/drivers/i2c/busses/i2c-hibvt.c
new file mode 100644
index 0000000..83ec012
--- /dev/null
+++ b/drivers/i2c/busses/i2c-hibvt.c
@@ -0,0 +1,890 @@
+/*
+ * Hisilicon BVT I2C Controller Driver
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * Authors: wenpan@hisilicon.com
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+#include <linux/slab.h>
+#include <linux/clk.h>
+#include <linux/delay.h>
+#include <linux/i2c.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/dma-mapping.h>
+
+#ifdef CONFIG_HI_DMAC
+#include <linux/hidmac.h>
+#endif
+/*
+ * I2C Registers offsets
+ */
+#define HIBVT_I2C_GLB		0x0
+#define HIBVT_I2C_SCL_H		0x4
+#define HIBVT_I2C_SCL_L		0x8
+#define HIBVT_I2C_DEV_ADDR	0x10
+#define HIBVT_I2C_DATA1		0x14
+#define HIBVT_I2C_TXF		0x20
+#define HIBVT_I2C_RXF		0x24
+#define HIBVT_I2C_CMD_BASE	0x30
+#define HIBVT_I2C_LOOP1		0xb0
+#define HIBVT_I2C_DST1		0xb4
+#define HIBVT_I2C_TX_WATER	0xc8
+#define HIBVT_I2C_RX_WATER	0xcc
+#define HIBVT_I2C_CTRL1		0xd0
+#define HIBVT_I2C_STAT		0xd8
+#define HIBVT_I2C_INTR_RAW	0xe0
+#define HIBVT_I2C_INTR_EN	0xe4
+#define HIBVT_I2C_INTR_STAT	0xe8
+
+/*
+ * I2C Global Config Register -- HIBVT_I2C_GLB
+ */
+#define GLB_EN_MASK		BIT(0)
+#define GLB_SDA_HOLD_MASK	GENMASK(23, 8)
+#define GLB_SDA_HOLD_SHIFT	(8)
+
+/*
+ * I2C Timing CMD Register -- HIBVT_I2C_CMD_BASE + n * 4 (n = 0, 1, 2, ... 31)
+ */
+#define CMD_EXIT	0x0
+#define CMD_TX_S	0x1
+#define CMD_TX_D1_2	0x4
+#define CMD_TX_D1_1	0x5
+#define CMD_TX_FIFO	0x9
+#define CMD_RX_FIFO	0x12
+#define CMD_RX_ACK	0x13
+#define CMD_IGN_ACK	0x15
+#define CMD_TX_ACK	0x16
+#define CMD_TX_NACK	0x17
+#define CMD_JMP1	0x18
+#define CMD_UP_TXF	0x1d
+#define CMD_TX_RS	0x1e
+#define CMD_TX_P	0x1f
+
+/*
+ * I2C Control Register 1 -- HIBVT_I2C_CTRL1
+ */
+#define CTRL1_CMD_START_MASK	BIT(0)
+#define CTRL1_DMA_OP_MASK	(0x3 << 8)
+#define CTRL1_DMA_R		(0x3 << 8)
+#define CTRL1_DMA_W		(0x2 << 8)
+
+/*
+ * I2C Status Register -- HIBVT_I2C_STAT
+ */
+#define STAT_RXF_NOE_MASK	BIT(16) /* RX FIFO not empty flag */
+#define STAT_TXF_NOF_MASK	BIT(19) /* TX FIFO not full flag */
+
+
+/*
+ * I2C Interrupt status and mask Register --
+ * HIBVT_I2C_INTR_RAW, HIBVT_I2C_STAT, HIBVT_I2C_INTR_STAT
+ */
+#define INTR_ABORT_MASK		(BIT(0) | BIT(11))
+#define INTR_RX_MASK		BIT(2)
+#define INTR_TX_MASK		BIT(4)
+#define INTR_CMD_DONE_MASK	BIT(12)
+#define INTR_USE_MASK		(INTR_ABORT_MASK \
+				|INTR_RX_MASK \
+				| INTR_TX_MASK \
+				| INTR_CMD_DONE_MASK)
+#define INTR_ALL_MASK		GENMASK(31, 0)
+
+#define I2C_DEFAULT_FREQUENCY	100000
+#define I2C_TXF_DEPTH		64
+#define I2C_RXF_DEPTH		64
+#define I2C_TXF_WATER		32
+#define I2C_RXF_WATER		32
+#define I2C_WAIT_TIMEOUT	0x10000
+#define I2C_IRQ_TIMEOUT		(msecs_to_jiffies(1000))
+
+
+struct hibvt_i2c_dev {
+	struct device		*dev;
+	struct i2c_adapter	adap;
+	resource_size_t		phybase;
+	void __iomem		*base;
+	struct clk		*clk;
+	int			irq;
+
+	unsigned int		freq;
+	struct i2c_msg		*msg;
+	unsigned int		msg_num;
+	unsigned int		msg_idx;
+	unsigned int		msg_buf_ptr;
+	struct completion	msg_complete;
+
+	spinlock_t		lock;
+	int			status;
+};
+
+static inline void hibvt_i2c_disable(struct hibvt_i2c_dev *i2c)
+{
+	unsigned int val;
+
+	val = readl(i2c->base + HIBVT_I2C_GLB);
+	val &= ~GLB_EN_MASK;
+	writel(val, i2c->base + HIBVT_I2C_GLB);
+}
+
+static inline void hibvt_i2c_enable(struct hibvt_i2c_dev *i2c)
+{
+	unsigned int val;
+
+	val = readl(i2c->base + HIBVT_I2C_GLB);
+	val |= GLB_EN_MASK;
+	writel(val, i2c->base + HIBVT_I2C_GLB);
+}
+
+static inline void hibvt_i2c_cfg_irq(struct hibvt_i2c_dev *i2c,
+		unsigned int flag)
+{
+	writel(flag, i2c->base + HIBVT_I2C_INTR_EN);
+}
+
+static inline void hibvt_i2c_disable_irq(struct hibvt_i2c_dev *i2c,
+		unsigned int flag)
+{
+	unsigned int val;
+
+	val = readl(i2c->base + HIBVT_I2C_INTR_EN);
+	val &= ~flag;
+	writel(val, i2c->base + HIBVT_I2C_INTR_EN);
+}
+
+static inline unsigned int hibvt_i2c_clr_irq(struct hibvt_i2c_dev *i2c)
+{
+	unsigned int val;
+
+	val = readl(i2c->base + HIBVT_I2C_INTR_STAT);
+	writel(INTR_ALL_MASK, i2c->base + HIBVT_I2C_INTR_RAW);
+
+	return val;
+}
+
+static inline void hibvt_i2c_cmdreg_set(struct hibvt_i2c_dev *i2c,
+		unsigned int cmd, unsigned int *offset)
+{
+	dev_dbg(i2c->dev, "hii2c reg: offset=0x%x, cmd=0x%x...\n",
+			*offset * 4, cmd);
+	writel(cmd, i2c->base + HIBVT_I2C_CMD_BASE + *offset * 4);
+	(*offset)++;
+}
+
+/*
+ * config i2c slave addr
+ */
+static inline void hibvt_i2c_set_addr(struct hibvt_i2c_dev *i2c)
+{
+	struct i2c_msg *msg = i2c->msg;
+	u16 addr;
+
+	if (msg->flags & I2C_M_TEN) {
+		/* First byte is 11110XX0 where XX is upper 2 bits */
+		addr = ((msg->addr & 0x300) << 1) | 0xf000;
+		if (msg->flags & I2C_M_RD)
+			addr |= 1 << 8;
+
+		/* Second byte is the remaining 8 bits */
+		addr |= msg->addr & 0xff;
+	} else {
+		addr = (msg->addr & 0x7f) << 1;
+		if (msg->flags & I2C_M_RD)
+			addr |= 1;
+	}
+
+	writel(addr, i2c->base + HIBVT_I2C_DEV_ADDR);
+}
+
+/*
+ * Start command sequence
+ */
+static inline void hibvt_i2c_start_cmd(struct hibvt_i2c_dev *i2c)
+{
+	unsigned int val;
+
+	val = readl(i2c->base + HIBVT_I2C_CTRL1);
+	val |= CTRL1_CMD_START_MASK;
+	writel(val, i2c->base + HIBVT_I2C_CTRL1);
+}
+
+static int hibvt_i2c_wait_rx_noempty(struct hibvt_i2c_dev *i2c)
+{
+	unsigned int time_cnt = 0;
+	unsigned int val;
+
+	do {
+		val = readl(i2c->base + HIBVT_I2C_STAT);
+		if (val & STAT_RXF_NOE_MASK)
+			return 0;
+
+		udelay(50);
+	} while (time_cnt++ < I2C_WAIT_TIMEOUT);
+
+	dev_err(i2c->dev, "wait rx no empty timeout, RIS: 0x%x, SR: 0x%x\n",
+			readl(i2c->base + HIBVT_I2C_INTR_RAW), val);
+	return -EIO;
+}
+
+static int hibvt_i2c_wait_tx_nofull(struct hibvt_i2c_dev *i2c)
+{
+	unsigned int time_cnt = 0;
+	unsigned int val;
+
+	do {
+		val = readl(i2c->base + HIBVT_I2C_STAT);
+		if (val & STAT_TXF_NOF_MASK)
+			return 0;
+
+		udelay(50);
+	} while (time_cnt++ < I2C_WAIT_TIMEOUT);
+
+	dev_err(i2c->dev, "wait rx no empty timeout, RIS: 0x%x, SR: 0x%x\n",
+			readl(i2c->base + HIBVT_I2C_INTR_RAW), val);
+	return -EIO;
+}
+
+static int hibvt_i2c_wait_idle(struct hibvt_i2c_dev *i2c)
+{
+	unsigned int time_cnt = 0;
+	unsigned int val;
+
+	do {
+		val = readl(i2c->base + HIBVT_I2C_INTR_RAW);
+		if (val & (INTR_ABORT_MASK)) {
+			dev_err(i2c->dev, "wait idle abort!, RIS: 0x%x\n",
+					val);
+			return -EIO;
+		}
+
+		if (val & INTR_CMD_DONE_MASK)
+			return 0;
+
+		udelay(50);
+	} while (time_cnt++ < I2C_WAIT_TIMEOUT);
+
+	dev_err(i2c->dev, "wait idle timeout, RIS: 0x%x, SR: 0x%x\n",
+			val, readl(i2c->base + HIBVT_I2C_STAT));
+
+	return -EIO;
+}
+
+static void hibvt_i2c_set_freq(struct hibvt_i2c_dev *i2c)
+{
+	unsigned int max_freq, freq;
+	unsigned int clk_rate;
+	unsigned int val, sda_hold;
+
+	freq = i2c->freq;
+	clk_rate = clk_get_rate(i2c->clk);
+	max_freq = clk_rate >> 1;
+
+	if (freq > max_freq) {
+		i2c->freq = max_freq;
+		freq = i2c->freq;
+	}
+
+	if (freq <= 100000) {
+		val = clk_rate / (freq * 2) - 1;
+		writel(val, i2c->base + HIBVT_I2C_SCL_H);
+		writel(val, i2c->base + HIBVT_I2C_SCL_L);
+	} else {
+		val = (clk_rate * 36) / (freq * 100);
+		writel(val, i2c->base + HIBVT_I2C_SCL_H);
+		val = (clk_rate * 64) / (freq * 100);
+		writel(val, i2c->base + HIBVT_I2C_SCL_L);
+	}
+
+	sda_hold = (0xa << GLB_SDA_HOLD_SHIFT) & GLB_SDA_HOLD_MASK;
+	val = readl(i2c->base + HIBVT_I2C_GLB);
+	val &= ~GLB_SDA_HOLD_MASK;
+	val |= sda_hold;
+	writel(val, i2c->base + HIBVT_I2C_GLB);
+}
+
+/*
+ * set i2c controller TX and RX FIFO water
+ */
+static inline void hibvt_i2c_set_water(struct hibvt_i2c_dev *i2c)
+{
+	writel(I2C_TXF_WATER, i2c->base + HIBVT_I2C_TX_WATER);
+	writel(I2C_RXF_WATER, i2c->base + HIBVT_I2C_RX_WATER);
+}
+
+/*
+ * initialise the controller, set i2c bus interface freq
+ */
+static void hibvt_i2c_hw_init(struct hibvt_i2c_dev *i2c)
+{
+	hibvt_i2c_disable(i2c);
+	hibvt_i2c_disable_irq(i2c, INTR_ALL_MASK);
+	hibvt_i2c_set_freq(i2c);
+	hibvt_i2c_set_water(i2c);
+}
+
+/*
+ * hibvt_i2c_cfg_cmd - config i2c controller command sequence
+ *
+ * After all the timing command is configured,
+ * and then start the command, you can i2c communication,
+ * and then only need to read and write i2c fifo.
+ */
+static void hibvt_i2c_cfg_cmd(struct hibvt_i2c_dev *i2c)
+{
+	struct i2c_msg *msg = i2c->msg;
+	int offset = 0;
+
+	if (i2c->msg_idx == 0)
+		hibvt_i2c_cmdreg_set(i2c, CMD_TX_S, &offset);
+	else
+		hibvt_i2c_cmdreg_set(i2c, CMD_TX_RS, &offset);
+
+	if (msg->flags & I2C_M_TEN) {
+		if (i2c->msg_idx == 0) {
+			hibvt_i2c_cmdreg_set(i2c, CMD_TX_D1_2, &offset);
+			hibvt_i2c_cmdreg_set(i2c, CMD_TX_D1_1, &offset);
+		} else {
+			hibvt_i2c_cmdreg_set(i2c, CMD_TX_D1_2, &offset);
+		}
+	} else {
+		hibvt_i2c_cmdreg_set(i2c, CMD_TX_D1_1, &offset);
+	}
+
+	if (msg->flags & I2C_M_IGNORE_NAK)
+		hibvt_i2c_cmdreg_set(i2c, CMD_IGN_ACK, &offset);
+	else
+		hibvt_i2c_cmdreg_set(i2c, CMD_RX_ACK, &offset);
+
+	if (msg->flags & I2C_M_RD) {
+		if (msg->len >= 2) {
+			writel(offset, i2c->base + HIBVT_I2C_DST1);
+			writel(msg->len - 2, i2c->base + HIBVT_I2C_LOOP1);
+			hibvt_i2c_cmdreg_set(i2c, CMD_RX_FIFO, &offset);
+			hibvt_i2c_cmdreg_set(i2c, CMD_TX_ACK, &offset);
+			hibvt_i2c_cmdreg_set(i2c, CMD_JMP1, &offset);
+		}
+		hibvt_i2c_cmdreg_set(i2c, CMD_RX_FIFO, &offset);
+		hibvt_i2c_cmdreg_set(i2c, CMD_TX_NACK, &offset);
+	} else {
+		writel(offset, i2c->base + HIBVT_I2C_DST1);
+		writel(msg->len - 1, i2c->base + HIBVT_I2C_LOOP1);
+		hibvt_i2c_cmdreg_set(i2c, CMD_UP_TXF, &offset);
+		hibvt_i2c_cmdreg_set(i2c, CMD_TX_FIFO, &offset);
+
+		if (msg->flags & I2C_M_IGNORE_NAK)
+			hibvt_i2c_cmdreg_set(i2c, CMD_IGN_ACK, &offset);
+		else
+			hibvt_i2c_cmdreg_set(i2c, CMD_RX_ACK, &offset);
+
+		hibvt_i2c_cmdreg_set(i2c, CMD_JMP1, &offset);
+	}
+
+	if ((i2c->msg_idx == (i2c->msg_num - 1)) || (msg->flags & I2C_M_STOP)) {
+		dev_dbg(i2c->dev, "run to %s %d...TX STOP\n",
+				__func__, __LINE__);
+		hibvt_i2c_cmdreg_set(i2c, CMD_TX_P, &offset);
+	}
+
+	hibvt_i2c_cmdreg_set(i2c, CMD_EXIT, &offset);
+}
+
+#ifdef CONFIG_HI_DMAC
+int dma_to_i2c(unsigned long src, unsigned int dst, unsigned int length)
+{
+	int chan;
+
+	chan = do_dma_m2p(src, dst, length);
+	if (chan == -1)
+		pr_err("dma_to_i2c error\n");
+
+	return chan;
+}
+
+int i2c_to_dma(unsigned int src, unsigned long dst,
+		unsigned int length)
+{
+	int chan;
+
+	chan = do_dma_p2m(dst, src, length);
+	if (chan == -1)
+		pr_err("dma_p2m error...\n");
+
+	return chan;
+}
+
+static int hibvt_i2c_do_dma_write(struct hibvt_i2c_dev *i2c,
+		unsigned long dma_dst_addr)
+{
+	int chan, val, status = 0;
+	struct i2c_msg *msg = i2c->msg;
+
+	hibvt_i2c_set_freq(i2c);
+	writel(0x1, i2c->base + HIBVT_I2C_TX_WATER);
+	hibvt_i2c_enable(i2c);
+	hibvt_i2c_clr_irq(i2c);
+	hibvt_i2c_set_addr(i2c);
+	hibvt_i2c_cfg_cmd(i2c);
+
+	val = readl(i2c->base + HIBVT_I2C_CTRL1);
+	val &= ~CTRL1_DMA_OP_MASK;
+	val |= CTRL1_DMA_W | CTRL1_CMD_START_MASK;
+	writel(val, i2c->base + HIBVT_I2C_CTRL1);
+
+	/*  transmit DATA from DMAC to I2C in DMA mode */
+	chan = dma_to_i2c(dma_dst_addr, (i2c->phybase + HIBVT_I2C_TXF),
+			msg->len);
+	if (chan == -1) {
+		status = -1;
+		goto end;
+	}
+	status = hibvt_i2c_wait_idle(i2c);
+end:
+	dmac_channelclose(chan);
+	dmac_channel_free(chan);
+	hibvt_i2c_disable(i2c);
+
+	return status;
+}
+
+static int hibvt_i2c_do_dma_read(struct hibvt_i2c_dev *i2c,
+		unsigned long dma_dst_addr)
+{
+	unsigned int val, chan, status = 0;
+	struct i2c_msg *msg = i2c->msg;
+
+	hibvt_i2c_set_freq(i2c);
+	writel(0x0, i2c->base + HIBVT_I2C_RX_WATER);
+	hibvt_i2c_enable(i2c);
+	hibvt_i2c_clr_irq(i2c);
+	hibvt_i2c_set_addr(i2c);
+	hibvt_i2c_cfg_cmd(i2c);
+
+	val = readl(i2c->base + HIBVT_I2C_CTRL1);
+	val &= ~CTRL1_DMA_OP_MASK;
+	val |= CTRL1_CMD_START_MASK | CTRL1_DMA_R;
+	writel(val, i2c->base + HIBVT_I2C_CTRL1);
+	/* transmit DATA from I2C to DMAC in DMA mode */
+	chan = i2c_to_dma((i2c->phybase + HIBVT_I2C_RXF),
+			dma_dst_addr, msg->len);
+	if (chan == -1) {
+		status = -1;
+		goto end;
+	}
+	status = hibvt_i2c_wait_idle(i2c);
+end:
+	dmac_channelclose(chan);
+	dmac_channel_free(chan);
+	hibvt_i2c_disable(i2c);
+
+	return status;
+}
+#else
+static int hibvt_i2c_do_dma_write(struct hibvt_i2c_dev *i2c,
+		unsigned int dma_dst_addr)
+{
+	dev_err(i2c->dev, "DMA is not enabled!");
+	return -1;
+}
+
+static int hibvt_i2c_do_dma_read(struct hibvt_i2c_dev *i2c,
+		unsigned int dma_dst_addr)
+{
+	dev_err(i2c->dev, "DMA is not enabled!");
+	return -1;
+}
+#endif
+static int hibvt_i2c_dma_xfer_one_msg(struct hibvt_i2c_dev *i2c)
+{
+	unsigned int status;
+	struct i2c_msg *msg = i2c->msg;
+	dma_addr_t dma_dst_addr;
+
+
+	dev_dbg(i2c->dev, "[%s,%d]msg->flags=0x%x, len=0x%x\n",
+			__func__, __LINE__, msg->flags, msg->len);
+
+	if (msg->flags & I2C_M_RD){
+		dma_dst_addr = dma_map_single(i2c->dev, msg->buf,
+								msg->len, DMA_FROM_DEVICE);
+		if (dma_mapping_error(i2c->dev, dma_dst_addr)) {
+			dev_err(i2c->dev, "DMA mapping failed\n");
+			return -EINVAL;
+		}
+
+		status = hibvt_i2c_do_dma_read(i2c, dma_dst_addr);
+
+		dma_unmap_single(i2c->dev, dma_dst_addr, msg->len, DMA_FROM_DEVICE);
+
+	} else {
+		dma_dst_addr = dma_map_single(i2c->dev, msg->buf,
+				msg->len, DMA_TO_DEVICE);
+
+		if (dma_mapping_error(i2c->dev, dma_dst_addr)){
+			dev_err(i2c->dev, "DMA mapping failed\n");
+			return -EINVAL;
+		}
+
+		status = hibvt_i2c_do_dma_write(i2c, dma_dst_addr);
+		dma_unmap_single(i2c->dev, dma_dst_addr, msg->len, DMA_TO_DEVICE);
+	}
+	status = hibvt_i2c_wait_idle(i2c);
+	hibvt_i2c_disable(i2c);
+
+	return status;
+}
+static int hibvt_i2c_polling_xfer_one_msg(struct hibvt_i2c_dev *i2c)
+{
+	int status;
+	unsigned int val;
+	struct i2c_msg *msg = i2c->msg;
+
+	dev_dbg(i2c->dev, "[%s,%d]msg->flags=0x%x, len=0x%x\n",
+			__func__, __LINE__, msg->flags, msg->len);
+
+	hibvt_i2c_enable(i2c);
+	hibvt_i2c_clr_irq(i2c);
+	hibvt_i2c_set_addr(i2c);
+	hibvt_i2c_cfg_cmd(i2c);
+	hibvt_i2c_start_cmd(i2c);
+
+	i2c->msg_buf_ptr = 0;
+
+	if (msg->flags & I2C_M_RD) {
+		while (i2c->msg_buf_ptr < msg->len) {
+			status = hibvt_i2c_wait_rx_noempty(i2c);
+			if (status)
+				goto end;
+
+			val = readl(i2c->base + HIBVT_I2C_RXF);
+			msg->buf[i2c->msg_buf_ptr] = val;
+			i2c->msg_buf_ptr++;
+
+		}
+	} else {
+		while (i2c->msg_buf_ptr < msg->len) {
+			status = hibvt_i2c_wait_tx_nofull(i2c);
+			if (status)
+				goto end;
+
+			val = msg->buf[i2c->msg_buf_ptr];
+			writel(val, i2c->base + HIBVT_I2C_TXF);
+			i2c->msg_buf_ptr++;
+		}
+	}
+
+	status = hibvt_i2c_wait_idle(i2c);
+end:
+	hibvt_i2c_disable(i2c);
+
+	return status;
+}
+
+static irqreturn_t hibvt_i2c_isr(int irq, void *dev_id)
+{
+	struct hibvt_i2c_dev *i2c = dev_id;
+	unsigned int irq_status;
+	struct i2c_msg *msg = i2c->msg;
+
+	spin_lock(&i2c->lock);
+
+	irq_status = hibvt_i2c_clr_irq(i2c);
+	dev_dbg(i2c->dev, "%s RIS:  0x%x\n", __func__, irq_status);
+
+	if (!irq_status) {
+		dev_dbg(i2c->dev, "no irq\n");
+		goto end;
+	}
+
+	if (irq_status & INTR_ABORT_MASK) {
+		dev_err(i2c->dev, "irq handle abort, RIS: 0x%x\n",
+				irq_status);
+		i2c->status = -EIO;
+		hibvt_i2c_disable_irq(i2c, INTR_ALL_MASK);
+
+		complete(&i2c->msg_complete);
+		goto end;
+	}
+
+	if (msg->flags & I2C_M_RD) {
+		while ((readl(i2c->base + HIBVT_I2C_STAT) & STAT_RXF_NOE_MASK)
+				&& (i2c->msg_buf_ptr < msg->len)) {
+			msg->buf[i2c->msg_buf_ptr] =
+				readl(i2c->base + HIBVT_I2C_RXF);
+			i2c->msg_buf_ptr++;
+		}
+	} else {
+		while ((readl(i2c->base + HIBVT_I2C_STAT) & STAT_TXF_NOF_MASK)
+				&& (i2c->msg_buf_ptr < msg->len)) {
+			writel(msg->buf[i2c->msg_buf_ptr],
+					i2c->base + HIBVT_I2C_TXF);
+			i2c->msg_buf_ptr++;
+		}
+	}
+
+	if (i2c->msg_buf_ptr >= msg->len)
+		hibvt_i2c_disable_irq(i2c, INTR_TX_MASK | INTR_RX_MASK);
+
+	if (irq_status & INTR_CMD_DONE_MASK) {
+		dev_dbg(i2c->dev, "cmd done\n");
+		i2c->status =  0;
+		hibvt_i2c_disable_irq(i2c, INTR_ALL_MASK);
+
+		complete(&i2c->msg_complete);
+	}
+
+end:
+	spin_unlock(&i2c->lock);
+
+	return IRQ_HANDLED;
+}
+
+static int hibvt_i2c_interrupt_xfer_one_msg(struct hibvt_i2c_dev *i2c)
+{
+	int status;
+	struct i2c_msg *msg = i2c->msg;
+	unsigned long timeout;
+	unsigned long flags;
+
+	dev_dbg(i2c->dev, "[%s,%d]msg->flags=0x%x, len=0x%x\n",
+			__func__, __LINE__, msg->flags, msg->len);
+
+	reinit_completion(&i2c->msg_complete);
+	i2c->msg_buf_ptr = 0;
+	i2c->status = -EIO;
+
+	spin_lock_irqsave(&i2c->lock, flags);
+	hibvt_i2c_enable(i2c);
+	hibvt_i2c_clr_irq(i2c);
+	if (msg->flags & I2C_M_RD)
+		hibvt_i2c_cfg_irq(i2c, INTR_USE_MASK & ~INTR_TX_MASK);
+	else
+		hibvt_i2c_cfg_irq(i2c, INTR_USE_MASK & ~INTR_RX_MASK);
+
+	hibvt_i2c_set_addr(i2c);
+	hibvt_i2c_cfg_cmd(i2c);
+	hibvt_i2c_start_cmd(i2c);
+	spin_unlock_irqrestore(&i2c->lock, flags);
+
+	timeout = wait_for_completion_timeout(&i2c->msg_complete,
+			I2C_IRQ_TIMEOUT);
+
+	if (timeout == 0) {
+		hibvt_i2c_disable_irq(i2c, INTR_ALL_MASK);
+		status = -EIO;
+		dev_err(i2c->dev, "%s timeout\n",
+			 msg->flags & I2C_M_RD ? "rx" : "tx");
+	} else {
+		status = i2c->status;
+	}
+
+	hibvt_i2c_disable(i2c);
+
+	return status;
+}
+
+/*
+ * Master transfer function
+ */
+static int hibvt_i2c_xfer(struct i2c_adapter *adap,
+			struct i2c_msg *msgs, int num)
+{
+	struct hibvt_i2c_dev *i2c = i2c_get_adapdata(adap);
+	int status;
+
+	if (!msgs) {
+		dev_err(i2c->dev, "msgs == NULL\n");
+		return -EIO;
+	}
+
+	i2c->msg = msgs;
+	i2c->msg_num = num;
+	i2c->msg_idx = 0;
+
+	while (i2c->msg_idx < i2c->msg_num) {
+		if (i2c->msg->len > CONFIG_DMA_MSG_LEN ) {
+			status = hibvt_i2c_dma_xfer_one_msg(i2c);
+			if (status)
+				break;
+		}else if (i2c->irq >= 0) {
+			status = hibvt_i2c_interrupt_xfer_one_msg(i2c);
+
+			if (status)
+				break;
+		}else {
+			status = hibvt_i2c_polling_xfer_one_msg(i2c);
+			if (status)
+				break;
+		}
+		i2c->msg++;
+		i2c->msg_idx++;
+	}
+
+	if (!status || i2c->msg_idx > 0)
+		status = i2c->msg_idx;
+
+	return status;
+}
+
+static u32 hibvt_i2c_func(struct i2c_adapter *adap)
+{
+	return I2C_FUNC_I2C | I2C_FUNC_10BIT_ADDR
+		| I2C_FUNC_PROTOCOL_MANGLING;
+}
+
+static const struct i2c_algorithm hibvt_i2c_algo = {
+	.master_xfer		= hibvt_i2c_xfer,
+	.functionality		= hibvt_i2c_func,
+};
+
+static int hibvt_i2c_probe(struct platform_device *pdev)
+{
+	int status;
+	struct hibvt_i2c_dev *i2c;
+	struct i2c_adapter *adap;
+	struct resource *res;
+
+	i2c = devm_kzalloc(&pdev->dev, sizeof(*i2c), GFP_KERNEL);
+	if (!i2c)
+		return -ENOMEM;
+
+	platform_set_drvdata(pdev, i2c);
+	i2c->dev = &pdev->dev;
+	spin_lock_init(&i2c->lock);
+	init_completion(&i2c->msg_complete);
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	i2c->phybase = res->start;
+	i2c->base = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(i2c->base)) {
+		dev_err(i2c->dev, "cannot ioremap resource\n");
+		return -ENOMEM;
+	}
+
+	i2c->clk = devm_clk_get(&pdev->dev, NULL);
+	if (IS_ERR(i2c->clk)) {
+		dev_err(i2c->dev, "cannot get clock\n");
+		return -ENOENT;
+	}
+	clk_prepare_enable(i2c->clk);
+
+	if (of_property_read_u32(pdev->dev.of_node, "clock-frequency",
+				&i2c->freq)) {
+		dev_warn(i2c->dev, "setting default clock-frequency@%dHz\n",
+				I2C_DEFAULT_FREQUENCY);
+		i2c->freq = I2C_DEFAULT_FREQUENCY;
+	}
+
+	/* i2c controller initialization, disable interrupt */
+	hibvt_i2c_hw_init(i2c);
+
+	i2c->irq = platform_get_irq(pdev, 0);
+	status = devm_request_irq(&pdev->dev, i2c->irq, hibvt_i2c_isr,
+			IRQF_SHARED, dev_name(&pdev->dev), i2c);
+	if (status) {
+		dev_dbg(i2c->dev, "falling back to polling mode");
+		i2c->irq = -1;
+	}
+
+	adap = &i2c->adap;
+	i2c_set_adapdata(adap, i2c);
+	adap->owner = THIS_MODULE;
+	strlcpy(adap->name, "hibvt-i2c", sizeof(adap->name));
+	adap->dev.parent = &pdev->dev;
+	adap->dev.of_node = pdev->dev.of_node;
+	adap->algo = &hibvt_i2c_algo;
+
+	/* Add the i2c adapter */
+	status = i2c_add_adapter(adap);
+	if (status) {
+		dev_err(i2c->dev, "failed to add bus to i2c core\n");
+		goto err_add_adapter;
+	}
+
+	dev_info(i2c->dev, "%s%d@%dhz registered\n",
+			adap->name, adap->nr, i2c->freq);
+
+	return 0;
+
+err_add_adapter:
+	clk_disable_unprepare(i2c->clk);
+	return status;
+}
+
+static int hibvt_i2c_remove(struct platform_device *pdev)
+{
+	struct hibvt_i2c_dev *i2c = platform_get_drvdata(pdev);
+
+	clk_disable_unprepare(i2c->clk);
+	i2c_del_adapter(&i2c->adap);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM_SLEEP
+static int hibvt_i2c_suspend(struct device *dev)
+{
+	struct hibvt_i2c_dev *i2c = dev_get_drvdata(dev);
+
+	i2c_lock_adapter(&i2c->adap);
+	clk_disable_unprepare(i2c->clk);
+	i2c_unlock_adapter(&i2c->adap);
+
+	return 0;
+}
+
+static int hibvt_i2c_resume(struct device *dev)
+{
+	struct hibvt_i2c_dev *i2c = dev_get_drvdata(dev);
+
+	i2c_lock_adapter(&i2c->adap);
+	clk_prepare_enable(i2c->clk);
+	hibvt_i2c_hw_init(i2c);
+	i2c_unlock_adapter(&i2c->adap);
+
+	return 0;
+}
+#endif
+
+static SIMPLE_DEV_PM_OPS(hibvt_i2c_dev_pm, hibvt_i2c_suspend,
+		hibvt_i2c_resume);
+
+static const struct of_device_id hibvt_i2c_match[] = {
+	{ .compatible = "hisilicon,hibvt-i2c"},
+	{ .compatible = "hisilicon,hi3516cv300-i2c"},
+	{ .compatible = "hisilicon,hi3536dv100-i2c"},
+	{},
+};
+MODULE_DEVICE_TABLE(of, hibvt_i2c_match);
+
+static struct platform_driver hibvt_i2c_driver = {
+	.driver		= {
+		.name	= "hibvt-i2c",
+		.of_match_table = hibvt_i2c_match,
+		.pm	= &hibvt_i2c_dev_pm,
+	},
+	.probe		= hibvt_i2c_probe,
+	.remove		= hibvt_i2c_remove,
+};
+
+module_platform_driver(hibvt_i2c_driver);
+
+MODULE_AUTHOR("Pan Wen, <wenpan@hisilicon.com>");
+MODULE_DESCRIPTION("HISILICON BVT I2C Bus driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/i2c/busses/i2c-hisilicon.c b/drivers/i2c/busses/i2c-hisilicon.c
new file mode 100644
index 0000000..71424e8
--- /dev/null
+++ b/drivers/i2c/busses/i2c-hisilicon.c
@@ -0,0 +1,1001 @@
+/*
+ * HiSilicon I2C-HISI-V100 Controller Driver
+ *
+ * Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program. If not, see <http://www.gnu.org/licenses/>.
+ */
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/i2c.h>
+#include <linux/init.h>
+#include <linux/time.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/errno.h>
+#include <linux/err.h>
+#include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
+#include <linux/slab.h>
+#include <linux/io.h>
+#include "i2c-hisilicon.h"
+#include <linux/dma-mapping.h>
+#include <linux/clk.h>
+
+#ifdef CONFIG_HI_DMAC
+#include <linux/hidmac.h>
+#endif
+
+#define I2C_HISI	"hisi_i2c"
+
+#ifdef CONFIG_ARCH_HI3516A
+#include <mach/hi3516a_io.h>
+#endif
+
+#define hi_err(x...) \
+	do { \
+		pr_alert("%s->%d: ", __func__, __LINE__); \
+		pr_alert(x); \
+		pr_alert("\n"); \
+	} while (0)
+
+/* #define HI_I2C_DEBUG */
+
+#ifdef HI_I2C_DEBUG
+
+#define hi_msg(x...) \
+	do { \
+		pr_alert("%s (line:%d) ", __func__, __LINE__); \
+		pr_alert(x); \
+	} while (0)
+#else
+#define hi_msg(args...) do { } while (0)
+#endif
+
+#define I2C_WAIT_TIME_OUT	20000
+
+#define I2C_DFT_RATE	(100000)
+
+struct hi_i2c {
+	unsigned char __iomem *regbase;
+	struct device *dev;
+	struct resource *mem;
+	struct clk *clk;
+	unsigned int irq;
+	struct i2c_adapter adap;
+	struct i2c_msg *msg;
+	struct hi_platform_i2c *pdata;
+	unsigned int g_last_dev_addr;
+	unsigned int g_last_mode;
+};
+
+static int hi_i2c_abortprocess(struct hi_i2c *pinfo)
+{
+	unsigned int auto_status;
+	unsigned int tx_src;
+
+	tx_src = readl(pinfo->regbase + I2C_TX_ABRT_SRC);
+	hi_err("tx_abrt_src is %x.\n", tx_src);
+
+	auto_status = readl(pinfo->regbase + I2C_AUTO_REG);
+
+	/* clear 0xB0 err status */
+	/* auto_mst_tx_abrt_clr
+	   auto_tx_cmd_fifo_over_clr
+	   auto_rx_cmd_fifo_under_clr
+	   auto_rx_cmd_fifo_over_clr
+	 */
+	auto_status |= 0x0f000000;
+	writel(auto_status, pinfo->regbase + I2C_AUTO_REG);
+	writel(0x1, pinfo->regbase + I2C_CLR_INTR_REG);
+
+	/* disable i2c */
+	writel(0, pinfo->regbase + I2C_ENABLE_REG);
+
+	/* enable i2c */
+	writel(0x1, pinfo->regbase + I2C_ENABLE_REG);
+
+	return 0;
+}
+
+void hi_i2c_set_rate(struct hi_i2c *pinfo)
+{
+	unsigned int apb_clk, scl_h, scl_l, hold;
+
+	/* get apb bus clk for diff plat */
+	apb_clk = clk_get_rate(pinfo->clk);
+
+	/* set SCLH and SCLL depend on apb_clk and def_rate */
+	if (pinfo->pdata->clk_limit <= I2C_DFT_RATE) {
+		/* in normal mode		F_scl: def_rate
+		   i2c_scl_hcnt = (F_i2c / F_scl) * 0.5
+		   i2c_scl_hcnt = (F_i2c / F_scl) * 0.5
+		*/
+		scl_h = (apb_clk / I2C_DFT_RATE) / 2;
+		scl_l = scl_h;
+	} else {
+		/* in fast mode		F_scl: def_rate
+		   i2c_scl_hcnt = (F_i2c / F_scl) * 0.36
+		   i2c_scl_hcnt = (F_i2c / F_scl) * 0.64
+		*/
+		scl_h = ((apb_clk / 100) * 36) / pinfo->pdata->clk_limit;
+		scl_l = ((apb_clk / 100) * 64) / pinfo->pdata->clk_limit;
+	}
+
+	writel(scl_h, pinfo->regbase + I2C_SCL_H_REG);
+	writel(scl_l, pinfo->regbase + I2C_SCL_L_REG);
+
+	/* set hi_i2c hold time */
+	hold = scl_h / 2;
+	writel(hold, pinfo->regbase + I2C_SDA_HOLD_REG);
+}
+
+void hi_i2c_hw_init(struct hi_i2c *pinfo)
+{
+	unsigned int temp, rx_fifo, tx_fifo;
+
+	/* unlock hi_i2c controller to access */
+	writel(HI_I2C_UNLOCK_VALUE, pinfo->regbase + I2C_LOCK_REG);
+
+	/* disable hi_i2c controller */
+	temp = readl(pinfo->regbase + I2C_ENABLE_REG);
+	writel((temp & ~HI_I2C_ENABLE), pinfo->regbase + I2C_ENABLE_REG);
+
+	/* disable hi_i2c auto_mode */
+	writel(HI_I2C_AUTO_MODE_OFF, pinfo->regbase + I2C_AUTO_REG);
+
+	/* set hi_i2c in fast mode */
+	writel(HI_I2C_FAST_MODE, pinfo->regbase + I2C_CON_REG);
+
+	/* set hi_i2c rate */
+	hi_i2c_set_rate(pinfo);
+
+	rx_fifo = HI_I2C_RX_FIFO;
+	tx_fifo = HI_I2C_TX_FIFO;
+
+	/* set hi_i2c fifo */
+	writel(rx_fifo, pinfo->regbase + I2C_RX_TL_REG);
+	writel(tx_fifo, pinfo->regbase + I2C_TX_TL_REG);
+
+	/* enable interrupt mask */
+	writel(DISABLE_ALL_INTERRUPTS, pinfo->regbase + I2C_INTR_MASK_REG);
+
+	/* enable hi_i2c controller */
+	temp = readl(pinfo->regbase + I2C_ENABLE_REG);
+	writel((temp | HI_I2C_ENABLE), pinfo->regbase + I2C_ENABLE_REG);
+
+	pinfo->g_last_dev_addr = 0;
+	pinfo->g_last_mode = I2C_MODE_NONE;
+
+	pinfo->msg = NULL;
+}
+
+int hi_i2c_wait_idle(struct hi_i2c *pinfo)
+{
+	unsigned int val;
+	unsigned int time_cnt;
+
+	time_cnt = 0;
+	do {
+		val = readl(pinfo->regbase + I2C_INTR_RAW_REG);
+		if (val & I2C_RAW_TX_ABORT) {
+			hi_err("wait last i2c fifo is empty abort! "\
+					"int_raw_status: %#x!\n", val);
+			return hi_i2c_abortprocess(pinfo);
+		}
+
+		val = readl(pinfo->regbase + I2C_AUTO_REG);
+		if (!IS_RX_FIFO_EMPTY(val))
+			readl(pinfo->regbase + I2C_TX_RX_REG);
+
+		if (IS_FIFO_EMPTY(val))
+			break;
+
+		if (time_cnt > I2C_WAIT_TIME_OUT) {
+			hi_err("wait last i2c fifo is empty timeout! "\
+					"auto_status: %#x\n", val);
+			return -EBUSY;
+		}
+		time_cnt++;
+		udelay(50);
+	} while (1);
+
+	udelay(10);
+
+	time_cnt = 0;
+	do {
+		val = readl(pinfo->regbase + I2C_INTR_RAW_REG);
+		if (val & I2C_RAW_TX_ABORT) {
+			hi_err("wait last i2c is idle abort! "\
+					"int_raw_status: %#x!\n", val);
+			return hi_i2c_abortprocess(pinfo);
+		}
+
+		val = readl(pinfo->regbase + I2C_STATUS_REG);
+		if (IS_I2C_IDLE(val))
+			break;
+
+		if (time_cnt > I2C_WAIT_TIME_OUT) {
+			hi_err("wait last i2c is idle timeout! "\
+					"auto_status: %#x\n", val);
+			return -EBUSY;
+		}
+		time_cnt++;
+		udelay(50);
+	} while (1);
+
+	return 0;
+}
+
+/* wait until tx fifo is not full */
+int hi_i2c_wait_txfifo_notfull(struct hi_i2c *pinfo)
+{
+	unsigned int val;
+	unsigned int time_cnt;
+
+	time_cnt = 0;
+	do {
+		val = readl(pinfo->regbase + I2C_INTR_RAW_REG);
+		if (val & I2C_RAW_TX_ABORT) {
+			hi_err("abort! last int_raw_status: %#x!\n", val);
+			return hi_i2c_abortprocess(pinfo);
+		}
+
+		val = readl(pinfo->regbase + I2C_AUTO_REG);
+		if (!IS_RX_FIFO_EMPTY(val))
+			readl(pinfo->regbase + I2C_TX_RX_REG);
+
+		if (val & I2c_AUTO_TX_FIFO_NOT_FULL)
+			break;
+
+		if (time_cnt > I2C_WAIT_TIME_OUT) {
+			hi_err("timeout! last auto_status: %#x\n", val);
+			return -EBUSY;
+		}
+		time_cnt++;
+		udelay(50);
+	} while (1);
+
+	return 0;
+}
+
+/* wait until tx fifo is not empty */
+int hi_i2c_wait_rxfifo_notempty(struct hi_i2c *pinfo)
+{
+	unsigned int val;
+	unsigned int time_cnt;
+
+	time_cnt = 0;
+	do {
+		val = readl(pinfo->regbase + I2C_INTR_RAW_REG);
+		if ((val & I2C_RAW_TX_ABORT) == I2C_RAW_TX_ABORT) {
+			hi_err("abort! int_raw_status: %#x!\n", val);
+			hi_i2c_abortprocess(pinfo);
+			return -EIO;
+		}
+
+		val = readl(pinfo->regbase + I2C_AUTO_REG);
+		if (!IS_RX_FIFO_EMPTY(val))
+			break;
+
+		if (time_cnt > I2C_WAIT_TIME_OUT) {
+			hi_err("timeout! auto_status: %#x\n", val);
+			hi_i2c_abortprocess(pinfo);
+			return -EBUSY;
+		}
+		time_cnt++;
+		udelay(50);
+	} while (1);
+
+	return 0;
+}
+
+static inline int hi_i2c_set_dev_addr_and_mode(struct hi_i2c *pinfo,
+		unsigned int work_mode)
+{
+	unsigned int dev_addr = pinfo->msg->addr;
+
+	if ((pinfo->g_last_dev_addr == dev_addr)
+			&& (pinfo->g_last_mode == work_mode))
+		return 0;
+
+	/* wait until all cmd in fifo is finished and i2c is idle */
+	if (hi_i2c_wait_idle(pinfo) < 0)
+		return -1;
+
+	/* disable i2c */
+	writel(0x0, pinfo->regbase + I2C_ENABLE_REG);
+	/* clear interrupt */
+	writel(0x1, pinfo->regbase + I2C_CLR_INTR_REG);
+	/* enable interrupt mask */
+	writel(DISABLE_ALL_INTERRUPTS, pinfo->regbase + I2C_INTR_MASK_REG);
+	/* clear err status */
+	writel(0x0f000000, pinfo->regbase + I2C_AUTO_REG);
+
+	/* different device, need to reinit i2c ctrl */
+	if ((pinfo->g_last_dev_addr) != dev_addr) {
+		/* set slave dev addr */
+		writel((dev_addr & 0xff)>>1, pinfo->regbase + I2C_TAR_REG);
+		pinfo->g_last_dev_addr = dev_addr;
+	}
+
+	if (pinfo->g_last_mode != work_mode) {
+
+		/* set auto mode */
+		if (work_mode == I2C_MODE_AUTO) {
+			writel(0x0, pinfo->regbase + I2C_DMA_CMD0);
+			writel(0x80000000, pinfo->regbase + I2C_AUTO_REG);
+			pinfo->g_last_mode = work_mode;
+		} else if (work_mode == I2C_MODE_DMA) {
+			writel(0x0, pinfo->regbase + I2C_AUTO_REG);
+			pinfo->g_last_mode = work_mode;
+		} else {
+			hi_err("invalid i2c mode\n");
+			return -1;
+		}
+	}
+
+	/*  enable i2c */
+	writel(0x1, pinfo->regbase + I2C_ENABLE_REG);
+
+	hi_msg("\n@@@@@@@@@@\n");
+
+	return 0;
+}
+
+int hi_i2c_write(struct hi_i2c *pinfo)
+{
+	unsigned int reg_val;
+	unsigned int temp_reg;
+	unsigned int temp_data;
+	unsigned int temp_auto_reg;
+	unsigned int min_msgs_len = 0;
+	struct i2c_msg *msg = pinfo->msg;
+	unsigned int msg_buf_ptr = 0;
+
+	min_msgs_len = (msg->flags & I2C_M_16BIT_REG) ? 2 : 1;
+	min_msgs_len += (msg->flags & I2C_M_16BIT_DATA) ? 2 : 1;
+	if (msg->len < min_msgs_len){
+		hi_err("Unsupported this length: %d!\n", msg->len);
+		return -1;
+	}
+
+	if (hi_i2c_set_dev_addr_and_mode(pinfo, I2C_MODE_AUTO) < 0)
+		return -1;
+
+	temp_auto_reg = HI_I2C_WRITE;
+
+	if (msg->flags & I2C_M_16BIT_REG) {
+		/* 16bit reg addr */
+		temp_auto_reg |= I2C_AUTO_ADDR;
+
+		/* switch high byte and low byte */
+		temp_reg = msg->buf[msg_buf_ptr] << 8;
+
+		msg_buf_ptr++;
+
+		temp_reg |= msg->buf[msg_buf_ptr];
+
+		msg_buf_ptr++;
+	} else {
+		temp_reg = msg->buf[msg_buf_ptr];
+		msg_buf_ptr++;
+	}
+
+	if (msg->flags & I2C_M_16BIT_DATA) {
+		/* 16bit data */
+		temp_auto_reg |= I2C_AUTO_DATA;
+
+		/* switch high byte and low byte */
+		temp_data =  msg->buf[msg_buf_ptr] << 8;
+
+		msg_buf_ptr++;
+
+		temp_data |= msg->buf[msg_buf_ptr];
+
+		msg_buf_ptr++;
+	} else {
+		temp_data = msg->buf[msg_buf_ptr];
+		msg_buf_ptr++;
+	}
+
+	writel(temp_auto_reg, pinfo->regbase + I2C_AUTO_REG);
+	hi_msg("temp_auto_reg: 0x%x\n", temp_auto_reg);
+
+	/* set write reg&data */
+	reg_val = (temp_reg << REG_SHIFT) | temp_data;
+
+	/* wait until tx fifo not full */
+	if (hi_i2c_wait_txfifo_notfull(pinfo) < 0)
+		return -1;
+
+	hi_msg("reg_val = %x\n", reg_val);
+
+	writel(reg_val, pinfo->regbase + I2C_TX_RX_REG);
+
+	hi_msg("dev_addr =%x, reg_addr = %x, Data = %x\n",
+		pinfo->msg->addr, pinfo->msg->buf[0], pinfo->msg->buf[1]);
+
+	return 0;
+}
+
+unsigned int hi_i2c_read(struct hi_i2c *pinfo)
+{
+	unsigned int reg_val;
+	unsigned int temp_reg;
+	unsigned int ret_data = 0xffff;
+	unsigned int temp_auto_reg;
+	unsigned int min_msgs_len = 0;
+	struct i2c_msg *msg = pinfo->msg;
+
+	min_msgs_len = (msg->flags & I2C_M_16BIT_REG) ? 2 : 1;
+	if (msg->len < min_msgs_len){
+		hi_err("Unsupported this length: %d!\n", msg->len);
+		return -1;
+	}
+
+	if (hi_i2c_set_dev_addr_and_mode(pinfo, I2C_MODE_AUTO) < 0)
+		return -1;
+
+	temp_auto_reg = HI_I2C_READ;
+
+	if (msg->flags & I2C_M_16BIT_REG) {
+		/* 16bit reg addr */
+		temp_auto_reg |= I2C_AUTO_ADDR;
+
+		/* switch high byte and low byte */
+		temp_reg = msg->buf[0] << 8;
+		temp_reg |= msg->buf[1];
+	} else {
+		temp_reg = msg->buf[0];
+	}
+
+	if (msg->flags & I2C_M_16BIT_DATA)
+		/* 16bit data */
+		temp_auto_reg |= I2C_AUTO_DATA;
+
+	writel(temp_auto_reg, pinfo->regbase + I2C_AUTO_REG);
+	hi_msg("temp_auto_reg: 0x%x\n", temp_auto_reg);
+
+	/* 1. write addr */
+	reg_val = temp_reg << REG_SHIFT;
+	hi_msg("reg_val %x\n", reg_val);
+
+	/* wait until tx fifo not full  */
+	if (hi_i2c_wait_txfifo_notfull(pinfo) < 0)
+		return -1;
+
+	/* regaddr */
+	writel(reg_val, pinfo->regbase + I2C_TX_RX_REG);
+
+	/* 2. read return data */
+	/* wait until rx fifo not empty  */
+	if (hi_i2c_wait_rxfifo_notempty(pinfo) < 0)
+		return -1;
+
+	ret_data = readl(pinfo->regbase + I2C_TX_RX_REG) & DATA_16BIT_MASK;
+	hi_msg("ret_data = %x\n", ret_data);
+
+	if (msg->flags & I2C_M_16BIT_DATA) {
+		pinfo->msg->buf[0] = ret_data & DATA_8BIT_MASK;
+		pinfo->msg->buf[1] = (ret_data >> 8) & DATA_8BIT_MASK;
+	} else {
+		pinfo->msg->buf[0] = ret_data & DATA_8BIT_MASK;
+	}
+
+	writel(0x1, pinfo->regbase + I2C_CLR_INTR_REG);
+
+	return 0;
+}
+
+/************************************
+	* dma functions *
+************************************/
+#ifdef CONFIG_HI_DMAC
+void hi_i2c_dma_start(struct hi_i2c *pinfo, unsigned int dir)
+{
+	writel((1 << dir), pinfo->regbase + I2C_DMA_CTRL_REG);
+}
+
+void hi_i2c_dmac_config(struct hi_i2c *pinfo, unsigned int dir)
+{
+	/* 1. enable RX(0) or TX(1) in DMA mode */
+	hi_i2c_dma_start(pinfo, dir);
+
+	/* 2. set dma fifo */
+	writel(4, pinfo->regbase + I2C_DMA_TDLR);
+	writel(4, pinfo->regbase + I2C_DMA_RDLR);
+}
+
+void hi_i2c_start_rx(struct hi_i2c *pinfo, unsigned int reg_addr,
+			unsigned int length)
+{
+	unsigned int reg;
+
+	writel(reg_addr, pinfo->regbase + I2C_DMA_CMD1);
+	writel(length, pinfo->regbase + I2C_DMA_CMD2);
+
+	reg = readl(pinfo->regbase + I2C_DMA_CMD0);
+
+	/*start tx*/
+	reg &= ~0x40000000;
+	writel((0x80000000 | reg), pinfo->regbase + I2C_DMA_CMD0);
+}
+
+void hi_i2c_start_tx(struct hi_i2c *pinfo, unsigned int reg_addr,
+			unsigned int length)
+{
+	unsigned int reg;
+
+	writel(reg_addr, pinfo->regbase + I2C_DMA_CMD1);
+	writel(length, pinfo->regbase + I2C_DMA_CMD2);
+
+	reg = readl(pinfo->regbase + I2C_DMA_CMD0);
+
+	/*start rx*/
+	writel((0xc0000000 | reg), pinfo->regbase + I2C_DMA_CMD0);
+}
+
+int dma_to_i2c(unsigned int src, unsigned int dst, unsigned int length)
+{
+	int chan;
+
+	chan = do_dma_m2p(src, dst, length);
+	if (chan == -1)
+		hi_err("dma_to_i2c error\n");
+
+	return chan;
+}
+
+
+int i2c_to_dma(unsigned int src, unsigned int dst, unsigned int length)
+{
+	int chan;
+
+	chan = do_dma_p2m(dst, src, length);
+	if (chan == -1)
+		hi_err("dma_p2m error...\n");
+
+	return chan;
+}
+
+static int hi_i2c_do_dma_write(struct hi_i2c *pinfo,
+		unsigned int reg_addr, unsigned int reg_addr_num,
+		unsigned int dma_buf, unsigned int length)
+{
+	unsigned int temp_reg = reg_addr;
+	int chan;
+
+	/* 1. switch i2c devaddr and dma mode*/
+	if (hi_i2c_set_dev_addr_and_mode(pinfo, I2C_MODE_DMA) < 0)
+		return -1;
+
+	if (2 == reg_addr_num) {
+		/* switch high byte and low byte */
+		temp_reg = REVERT_HL_BYTE(reg_addr);
+		writel(0x10000000, pinfo->regbase + I2C_DMA_CMD0);
+	} else {
+		writel(0x0, pinfo->regbase + I2C_DMA_CMD0);
+	}
+
+	/* 2. config i2c into DMA mode */
+	hi_i2c_dmac_config(pinfo, 0x1);
+
+	/* 3. start i2c logic to write */
+	hi_i2c_start_tx(pinfo, temp_reg, length - 1);
+
+	/* 4. transmit DATA from DMAC to I2C in DMA mode */
+	chan = dma_to_i2c(dma_buf, (pinfo->mem->start + I2C_DATA_CMD_REG),
+				length);
+
+	if (dmac_wait(chan) != DMAC_CHN_SUCCESS) {
+		hi_err("dma wait failed\n");
+		dmac_channel_free(chan);
+		return -1;
+	}
+
+	dmac_channel_free(chan);
+
+	return 0;
+}
+
+static int hi_i2c_do_dma_read(struct hi_i2c *pinfo,
+		unsigned int reg_addr, unsigned int reg_addr_num,
+		unsigned int dma_buf, unsigned int length)
+{
+	unsigned int temp_reg = reg_addr;
+	int chan;
+
+	/* 1. switch i2c devaddr and dma mode*/
+	if (hi_i2c_set_dev_addr_and_mode(pinfo, I2C_MODE_DMA) < 0)
+		return -1;
+
+	if (2 == reg_addr_num) {
+		/* switch high byte and low byte */
+		temp_reg = REVERT_HL_BYTE(reg_addr);
+		writel(0x10000000, pinfo->regbase + I2C_DMA_CMD0);
+	} else {
+		writel(0x0, pinfo->regbase + I2C_DMA_CMD0);
+	}
+
+	/* 2. config i2c into DMA mode */
+	hi_i2c_dmac_config(pinfo, 0x0);
+
+	/* 3. transmit DATA from I2C to DMAC in DMA mode */
+	chan = i2c_to_dma((pinfo->mem->start + I2C_DATA_CMD_REG),
+				dma_buf, length);
+
+	/* 4. start i2c logic to read */
+	hi_i2c_start_rx(pinfo, temp_reg, length - 1);
+
+	if (dmac_wait(chan) != DMAC_CHN_SUCCESS) {
+		hi_err("dma wait failed\n");
+		dmac_channel_free(chan);
+		return -1;
+	}
+
+	dmac_channel_free(chan);
+
+	return 0;
+}
+
+#else
+static int hi_i2c_do_dma_write(struct hi_i2c *pinfo,
+		unsigned int reg_addr, unsigned int reg_addr_num,
+		unsigned int dma_buf, unsigned int length)
+{
+	hi_err("DMA is not enabled!");
+	return -1;
+}
+
+static int hi_i2c_do_dma_read(struct hi_i2c *pinfo,
+		unsigned int reg_addr, unsigned int reg_addr_num,
+		unsigned int dma_buf, unsigned int length)
+{
+	hi_err("DMA is not enabled!");
+	return -1;
+}
+#endif
+
+int hi_i2c_dma_write(const struct i2c_client *client, unsigned int dma_buf,
+		unsigned int reg_addr, unsigned int reg_addr_num,
+		unsigned int length)
+{
+	struct i2c_adapter *adap = client->adapter;
+	struct hi_i2c *pinfo = (struct hi_i2c *)i2c_get_adapdata(adap);
+	struct i2c_msg msg;
+	int ret;
+	unsigned long flags;
+
+	spin_lock_irqsave(&adap->spinlock, flags);
+
+	memset(&msg, 0x0, sizeof(struct i2c_msg));
+	msg.addr = client->addr;
+	msg.flags = client->flags;
+	msg.len = length;
+
+	pinfo->msg = &msg;
+
+	ret = hi_i2c_do_dma_write(pinfo, reg_addr, reg_addr_num, dma_buf,
+			length);
+
+	spin_unlock_irqrestore(&adap->spinlock, flags);
+
+	return ret;
+}
+EXPORT_SYMBOL(hi_i2c_dma_write);
+
+int hi_i2c_dma_read(const struct i2c_client *client, unsigned int dma_buf,
+		unsigned int reg_addr, unsigned int reg_addr_num,
+		unsigned int length)
+{
+	struct i2c_adapter *adap = client->adapter;
+	struct hi_i2c *pinfo = (struct hi_i2c *)i2c_get_adapdata(adap);
+	struct i2c_msg msg;
+	int ret;
+	unsigned long flags;
+
+	spin_lock_irqsave(&adap->spinlock, flags);
+
+	memset(&msg, 0x0, sizeof(struct i2c_msg));
+	msg.addr = client->addr;
+	msg.flags = client->flags;
+	msg.flags |= I2C_M_RD;
+	msg.len = length;
+
+	pinfo->msg = &msg;
+
+	ret = hi_i2c_do_dma_read(pinfo, reg_addr, reg_addr_num, dma_buf,
+			length);
+
+	spin_unlock_irqrestore(&adap->spinlock, flags);
+
+	return ret;
+}
+EXPORT_SYMBOL(hi_i2c_dma_read);
+
+static int hi_i2c_xfer(struct i2c_adapter *adap, struct i2c_msg *msgs,
+		int num)
+{
+	struct hi_i2c *pinfo;
+	unsigned int msg_idx;
+	dma_addr_t dma_buf;
+	__u16 len;
+	unsigned int reg_addr;
+	unsigned int reg_width;
+	int ret;
+
+	if (!msgs || (num <= 0)) {
+		hi_err("msgs == NULL || num <= 0, Invalid argument!\n");
+		return -EINVAL;
+	}
+
+	pinfo = (struct hi_i2c *)i2c_get_adapdata(adap);
+	pinfo->msg = msgs;
+
+	for (msg_idx = 0; msg_idx < num; msg_idx++) {
+		len =  pinfo->msg->len;
+		if (pinfo->msg->flags & I2C_M_16BIT_REG) {
+			reg_addr = pinfo->msg->buf[0];
+			reg_addr |= pinfo->msg->buf[1] << 8;
+			reg_width = 2;
+		} else {
+			reg_addr = pinfo->msg->buf[0];
+			reg_width = 1;
+		}
+
+		if (pinfo->msg->flags & I2C_M_DMA) {
+			if (pinfo->msg->flags & I2C_M_16BIT_DATA) {
+				hi_err("I2C DMA no support I2C_M_16BIT_DATA\n");
+				return -EINVAL;
+			}
+
+			if (((pinfo->msg->flags & I2C_M_RD) && (len <= 0)) ||
+					(!(pinfo->msg->flags & I2C_M_RD) &&
+					 (len <= reg_width))) {
+				hi_err("msg->len == %d, Invalid argument!\n",
+						len);
+				return -EINVAL;
+			}
+
+			dma_buf = dma_map_single(pinfo->dev,
+					pinfo->msg->buf, len,
+					DMA_BIDIRECTIONAL);
+			if (dma_mapping_error(pinfo->dev, dma_buf)) {
+				hi_err("DMA mapping failed\n");
+				return -EINVAL;
+			}
+
+			if (pinfo->msg->flags & I2C_M_RD)
+				ret = hi_i2c_do_dma_read(pinfo, reg_addr,
+						reg_width, dma_buf, len);
+			else
+				ret = hi_i2c_do_dma_write(pinfo, reg_addr,
+						reg_width, dma_buf + reg_width,
+						len - reg_width);
+
+			dma_unmap_single(pinfo->dev, dma_buf, len,
+						DMA_BIDIRECTIONAL);
+
+			if (ret)
+				break;
+		} else {
+			if (pinfo->msg->flags & I2C_M_RD)
+				ret = hi_i2c_read(pinfo);
+			else
+				ret = hi_i2c_write(pinfo);
+
+			if (ret)
+				break;
+		}
+		pinfo->msg++;
+	}
+
+	if (!ret || msg_idx > 0)
+		ret = msg_idx;
+	else
+		ret = -EIO;
+
+	return ret;
+}
+
+/**************************************************************/
+
+static u32 hi_i2c_func(struct i2c_adapter *adap)
+{
+	return I2C_FUNC_I2C;
+}
+
+static const struct i2c_algorithm hi_i2c_algo = {
+	.master_xfer    = hi_i2c_xfer,
+	.functionality  = hi_i2c_func,
+};
+
+static int hi_i2c_probe(struct platform_device *pdev)
+{
+	int errorcode;
+	struct hi_i2c *pinfo;
+	struct i2c_adapter *adap;
+	struct resource *mem;
+	struct hi_platform_i2c *platform_info;
+	int tmp = 0;
+	struct device   *dev = &pdev->dev;
+	struct device_node *np = pdev->dev.of_node;
+
+	pdev->name = I2C_HISI;
+	tmp = of_property_read_u32(np, "id", &pdev->id);
+	if (tmp) {
+		dev_err(&pdev->dev, "Get id failed!\n");
+		errorcode = -EBADF;
+		goto i2c_errorcode_na;
+	}
+
+	platform_info = devm_kzalloc(dev, sizeof(*platform_info), GFP_KERNEL);
+	if (!platform_info)
+		return -ENOMEM;
+
+	mem = devm_kzalloc(dev, sizeof(*mem), GFP_KERNEL);
+	if (!mem)
+		return -ENOMEM;
+
+	tmp = of_property_read_u32(np, "clock-frequency", &platform_info->clk_limit);
+	if (tmp) {
+		dev_err(&pdev->dev, "Get clock-frequency failed!\n");
+		errorcode = -EBADF;
+		goto i2c_errorcode_na;
+	}
+	platform_info->i2c_class = I2C_CLASS_DDC;
+
+	dev->platform_data = platform_info;
+
+	pinfo = kzalloc(sizeof(struct hi_i2c), GFP_KERNEL);
+	if (pinfo == NULL) {
+		dev_err(&pdev->dev, "Out of memory!\n");
+		errorcode = -ENOMEM;
+		goto i2c_errorcode_na;
+	}
+
+	tmp = of_property_read_u32(np, "reg", &mem->start);
+	if (tmp) {
+		dev_err(&pdev->dev, "Get reg failed!\n");
+		errorcode = -ENXIO;
+		goto i2c_errorcode_na;
+	}
+
+	tmp = of_property_read_u32(np, "io-size", &mem->end);
+	if (tmp) {
+		dev_err(&pdev->dev, "Get io-size failed!\n");
+		errorcode = -EBADF;
+		goto i2c_errorcode_na;
+	}
+	mem->end = mem->start + mem->end -1;
+	mem->flags = IORESOURCE_MEM;
+	pdev->resource = mem;
+	pinfo->regbase = (unsigned char __iomem *)IO_ADDRESS(mem->start);
+	pinfo->mem = mem;
+	/* find the clock and enable it */
+	pinfo->clk = devm_clk_get(&pdev->dev, NULL);
+	pinfo->dev = &pdev->dev;
+	pinfo->pdata = platform_info;
+	pinfo->g_last_dev_addr = 0;
+
+	hi_i2c_hw_init(pinfo);
+
+	platform_set_drvdata(pdev, pinfo);
+
+	adap = &pinfo->adap;
+	i2c_set_adapdata(adap, pinfo);
+	adap->owner = THIS_MODULE;
+	adap->class = platform_info->i2c_class;
+	strlcpy(adap->name, pdev->name, sizeof(adap->name));
+	adap->algo = &hi_i2c_algo;
+	adap->dev.parent = &pdev->dev;
+	adap->nr = pdev->id;
+	adap->retries = HI_I2C_RETRIES;
+	errorcode = i2c_add_numbered_adapter(adap);
+	if (errorcode) {
+		dev_err(&pdev->dev,
+				"%s: Adding I2C adapter failed!\n", __func__);
+		goto i2c_errorcode_free_irq;
+	}
+	dev_notice(&pdev->dev,
+			"Hisilicon [%s] probed!\n",
+			dev_name(&pinfo->adap.dev));
+
+	goto i2c_errorcode_na;
+
+i2c_errorcode_free_irq:
+	free_irq(pinfo->irq, pinfo);
+	kfree(pinfo);
+
+i2c_errorcode_na:
+	return errorcode;
+}
+
+static int hi_i2c_remove(struct platform_device *pdev)
+{
+	struct hi_i2c *pinfo = NULL;
+	int errorcode = 0;
+
+	pinfo = platform_get_drvdata(pdev);
+
+	if (pinfo) {
+		i2c_del_adapter(&pinfo->adap);
+
+		free_irq(pinfo->irq, pinfo);
+
+		kfree(pinfo);
+	}
+
+	dev_notice(&pdev->dev,
+			"Remove Hisilicon Media Processor"
+			"I2C adapter [%d].\n", errorcode);
+
+	return errorcode;
+}
+
+#ifdef CONFIG_PM
+static int hi_i2c_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	struct hi_i2c *pinfo;
+
+	pinfo = platform_get_drvdata(pdev);
+
+	hi_i2c_abortprocess(pinfo);
+
+	return 0;
+}
+
+static int hi_i2c_resume(struct platform_device *pdev)
+{
+	struct hi_i2c *pinfo;
+
+	pinfo = platform_get_drvdata(pdev);
+
+	hi_i2c_hw_init(pinfo);
+
+	return 0;
+}
+#else
+#define hi_i2c_suspend		NULL
+#define hi_i2c_resume		NULL
+#endif
+
+/******************************************************************************/
+static const struct of_device_id hi_i2c_match[] = {
+	{ .compatible = "hisilicon,hisi-i2c-hisilicon"},
+	{}
+};
+MODULE_DEVICE_TABLE(of, hi_i2c_match);
+/******************************************************************************/
+
+static struct platform_driver hi_i2c_driver = {
+	.driver = {
+		.owner  = THIS_MODULE,
+		.name   = "hisi-i2c-hisilicon",
+		.of_match_table = of_match_ptr(hi_i2c_match),
+	},
+	.probe		= hi_i2c_probe,
+	.remove		= hi_i2c_remove,
+#ifdef CONFIG_PM
+	.suspend	= hi_i2c_suspend,
+	.resume		= hi_i2c_resume,
+#endif
+};
+
+module_platform_driver(hi_i2c_driver);
+
+MODULE_DESCRIPTION("HISILICON I2C Bus driver");
+MODULE_AUTHOR("BVT OSDRV");
+MODULE_LICENSE("GPL");
diff --git a/drivers/i2c/busses/i2c-hisilicon.h b/drivers/i2c/busses/i2c-hisilicon.h
new file mode 100644
index 0000000..bb49513
--- /dev/null
+++ b/drivers/i2c/busses/i2c-hisilicon.h
@@ -0,0 +1,112 @@
+#ifndef __HI_I2C_H__
+#define __HI_I2C_H__
+
+#define HI_I2C_RX_FIFO 0x8
+#define HI_I2C_TX_FIFO 0x8
+#define HI_I2C_RETRIES 0x1
+
+#define I2C_CON_REG		0x000
+#define I2C_TAR_REG		0x004
+#define I2C_DATA_CMD_REG	0x010
+#define I2C_SCL_H_REG		0x01C
+#define I2C_SCL_L_REG		0x020
+#define I2C_INTR_STAT_REG	0x02C
+#define I2C_INTR_MASK_REG	0x030
+#define I2C_INTR_RAW_REG	0x034
+#define I2C_RX_TL_REG		0x038
+#define I2C_TX_TL_REG		0x03C
+#define I2C_CLR_INTR_REG	0x040
+#define I2C_CLR_RX_OVER_REG	0x048
+#define I2C_CLR_TX_OVER_REG	0x04C
+#define I2C_ENABLE_REG		0x06C
+#define I2C_STATUS_REG		0x070
+#define I2C_TXFLR_REG		0x074
+#define I2C_RXFLR_REG		0x078
+#define I2C_SDA_HOLD_REG	0x07C
+#define I2C_TX_ABRT_SRC		0x080
+#define I2C_DMA_CTRL_REG	0x088
+#define I2C_DMA_TDLR		0x08C
+#define I2C_DMA_RDLR		0x090
+#define I2C_LPIF_STATE		0x0A8
+#define I2C_LOCK_REG		0x0AC
+#define I2C_AUTO_REG		0x0B0
+#define I2C_TX_RX_REG		0x0B4
+#define I2C_DMA_CMD0		0x0B8
+#define I2C_DMA_CMD1		0x0BC
+#define I2C_DMA_CMD2		0x0C0
+#define I2C_ENABLE_STATUS_REG	0x09C
+
+#define HI_I2C_FAST_MODE	0x65
+
+#define HI_I2C_UNLOCK_VALUE	0x1ACCE551
+
+#define HI_I2C_ENABLE		(1 << 0)
+
+#define HI_I2C_AUTO_MODE_OFF	0x0f000000
+
+#define HI_I2C_WRITE		0x80000000
+#define HI_I2C_READ		0xc0000000
+
+#define READ_OPERATION     (1)
+#define WRITE_OPERATION    0xfe
+
+#define CMD_I2C_WRITE      0x01
+#define CMD_I2C_READ       0x03
+
+/* I2C_COM_REG */
+#define I2C_SEND_ACK (~(1 << 4))
+#define I2C_START        (1 << 3)
+#define I2C_READ         (1 << 2)
+#define I2C_WRITE        (1 << 1)
+#define I2C_STOP (1 << 0)
+
+/* I2C_ENABLE_REG */
+#define I2C_ENABLE                  (1 << 0)
+
+#define I2C_RAW_TX_ABORT            (1 << 6)
+
+/*I2C_INTR_STAT_REG */
+#define I2C_AUTO_RX_FIFO_NOT_EMPTY  (1 << 8)
+#define I2C_AUTO_TX_FIFO_EMPTRY     (1 << 20)
+#define I2c_AUTO_TX_FIFO_NOT_FULL   (1 << 21)
+#define I2C_TX_ABRT                 (1 << 23)
+#define I2C_AUTO_DATA               (1 << 28)
+#define I2C_AUTO_ADDR               (1 << 29)
+
+/* I2C_STATUS */
+#define I2C_STATUS_WORKING          (1 << 0)
+
+#define IS_TX_FIFO_EMPTY(status)        (((status) &\
+			I2C_AUTO_TX_FIFO_EMPTRY) == I2C_AUTO_TX_FIFO_EMPTRY)
+#define IS_RX_FIFO_EMPTY(status)        (((status) &\
+			I2C_AUTO_RX_FIFO_NOT_EMPTY) == 0)
+#define IS_FIFO_EMPTY(status)           (IS_RX_FIFO_EMPTY(status) &&\
+			IS_TX_FIFO_EMPTY(status))
+#define IS_I2C_IDLE(status)             (((status) & I2C_STATUS_WORKING) == 0)
+
+#define REG_SHIFT		16
+#define DATA_16BIT_MASK		0xFFFF
+#define DATA_8BIT_MASK		0xFFFF
+
+#define REVERT_HL_BYTE(value)   ((value >> 8) | ((value & 0xFF) << 8))
+
+/*
+ * I2C Interrupt related Macros
+ */
+#define DEFAULT_I2C_REG_IMSC		0x0UL
+#define DISABLE_ALL_INTERRUPTS		((~DEFAULT_I2C_REG_IMSC) & 0xfff)
+#define ENABLE_ALL_INTERRUPTS		DEFAULT_I2C_REG_IMSC
+
+typedef enum i2c_mode_e {
+	I2C_MODE_AUTO,
+	I2C_MODE_DMA,
+	I2C_MODE_NONE,
+} i2c_mode_e;
+
+struct hi_platform_i2c {
+	int	clk_limit;
+	unsigned int i2c_class;
+	unsigned int clk_rate;
+};
+
+#endif
diff --git a/drivers/i2c/i2c-core.c b/drivers/i2c/i2c-core.c
index 7484aac..5951ac1 100644
--- a/drivers/i2c/i2c-core.c
+++ b/drivers/i2c/i2c-core.c
@@ -1098,8 +1098,13 @@ static int i2c_check_addr_validity(unsigned addr, unsigned short flags)
 		if (addr > 0x3ff)
 			return -EINVAL;
 	} else {
+		/* we always use dev+RD bit */
 		/* 7-bit address, reject the general call address */
+#ifdef	CONFIG_I2C_HISI
+		if (addr == 0x00 || addr > 0xfe)
+#else
 		if (addr == 0x00 || addr > 0x7f)
+#endif
 			return -EINVAL;
 	}
 	return 0;
@@ -1824,6 +1829,9 @@ static int i2c_register_adapter(struct i2c_adapter *adap)
 
 	rt_mutex_init(&adap->bus_lock);
 	rt_mutex_init(&adap->mux_lock);
+#ifdef CONFIG_ARCH_HISI_BVT
+		spin_lock_init(&adap->spinlock);
+#endif
 	mutex_init(&adap->userspace_clients_lock);
 	INIT_LIST_HEAD(&adap->userspace_clients);
 
@@ -2537,6 +2545,9 @@ EXPORT_SYMBOL(__i2c_transfer);
 int i2c_transfer(struct i2c_adapter *adap, struct i2c_msg *msgs, int num)
 {
 	int ret;
+#ifdef CONFIG_ARCH_HISI_BVT
+	unsigned long flags;
+#endif
 
 	/* REVISIT the fault reporting model here is weak:
 	 *
@@ -2566,6 +2577,9 @@ int i2c_transfer(struct i2c_adapter *adap, struct i2c_msg *msgs, int num)
 		}
 #endif
 
+#ifdef CONFIG_ARCH_HISI_BVT
+		spin_lock_irqsave(&adap->spinlock, flags);
+#else
 		if (in_atomic() || irqs_disabled()) {
 			ret = i2c_trylock_bus(adap, I2C_LOCK_SEGMENT);
 			if (!ret)
@@ -2574,10 +2588,13 @@ int i2c_transfer(struct i2c_adapter *adap, struct i2c_msg *msgs, int num)
 		} else {
 			i2c_lock_bus(adap, I2C_LOCK_SEGMENT);
 		}
-
+#endif
 		ret = __i2c_transfer(adap, msgs, num);
+#ifdef CONFIG_ARCH_HISI_BVT
+		spin_unlock_irqrestore(&adap->spinlock, flags);
+#else
 		i2c_unlock_bus(adap, I2C_LOCK_SEGMENT);
-
+#endif
 		return ret;
 	} else {
 		dev_dbg(&adap->dev, "I2C level transfers not supported\n");
@@ -2601,7 +2618,11 @@ int i2c_master_send(const struct i2c_client *client, const char *buf, int count)
 	struct i2c_msg msg;
 
 	msg.addr = client->addr;
+#ifdef CONFIG_I2C_HISI
+	msg.flags = client->flags;
+#else
 	msg.flags = client->flags & I2C_M_TEN;
+#endif
 	msg.len = count;
 	msg.buf = (char *)buf;
 
@@ -2630,7 +2651,11 @@ int i2c_master_recv(const struct i2c_client *client, char *buf, int count)
 	int ret;
 
 	msg.addr = client->addr;
+#ifdef CONFIG_I2C_HISI
+	msg.flags = client->flags;
+#else
 	msg.flags = client->flags & I2C_M_TEN;
+#endif
 	msg.flags |= I2C_M_RD;
 	msg.len = count;
 	msg.buf = buf;
diff --git a/drivers/i2c/i2c-dev.c b/drivers/i2c/i2c-dev.c
index 6f638bb..c1bb3fc 100644
--- a/drivers/i2c/i2c-dev.c
+++ b/drivers/i2c/i2c-dev.c
@@ -146,16 +146,59 @@ static ssize_t i2cdev_read(struct file *file, char __user *buf, size_t count,
 	if (count > 8192)
 		count = 8192;
 
+#ifdef CONFIG_I2C_HISI
+	{
+		unsigned reg_width;
+		unsigned data_width;
+
+		if (client->flags & I2C_M_16BIT_REG)
+			reg_width = 2;
+		else
+			reg_width = 1;
+
+		if (client->flags & I2C_M_16BIT_DATA)
+			data_width = 2;
+		else
+			data_width = 1;
+
+		if (client->flags & I2C_M_DMA)
+			tmp = kmalloc(max_t(size_t, reg_width, count),
+					GFP_KERNEL);
+		else
+			tmp = kmalloc(max_t(size_t, reg_width, data_width),
+					GFP_KERNEL);
+
+		if (tmp == NULL)
+			return -ENOMEM;
+
+		if (copy_from_user(tmp, buf, reg_width))
+			return -EFAULT;
+	}
+#else
 	tmp = kmalloc(count, GFP_KERNEL);
 	if (tmp == NULL)
 		return -ENOMEM;
+#endif
 
 	pr_debug("i2c-dev: i2c-%d reading %zu bytes.\n",
 		iminor(file_inode(file)), count);
 
 	ret = i2c_master_recv(client, tmp, count);
+#ifdef CONFIG_I2C_HISI
+	if (ret >= 0) {
+		if (client->flags & I2C_M_DMA) {
+			ret = copy_to_user(buf, tmp, count) ? -EFAULT : ret;
+		} else {
+			if (client->flags & I2C_M_16BIT_DATA)
+				ret = copy_to_user(buf, tmp, 2) ? -EFAULT : ret;
+			else
+				ret = copy_to_user(buf, tmp, 1) ? -EFAULT : ret;
+		}
+	}
+#else
 	if (ret >= 0)
 		ret = copy_to_user(buf, tmp, count) ? -EFAULT : ret;
+#endif
 	kfree(tmp);
 	return ret;
 }
@@ -424,7 +467,11 @@ static long i2cdev_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 	case I2C_SLAVE:
 	case I2C_SLAVE_FORCE:
 		if ((arg > 0x3ff) ||
+#ifdef CONFIG_I2C_HISI
+		    (((client->flags & I2C_M_TEN) == 0) && arg > 0xfe))
+#else
 		    (((client->flags & I2C_M_TEN) == 0) && arg > 0x7f))
+#endif
 			return -EINVAL;
 		if (cmd == I2C_SLAVE && i2cdev_check_addr(client->adapter, arg))
 			return -EBUSY;
@@ -450,6 +497,26 @@ static long i2cdev_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 		else
 			client->flags &= ~I2C_CLIENT_PEC;
 		return 0;
+#ifdef CONFIG_I2C_HISI
+	case I2C_16BIT_REG:
+		if (arg)
+			client->flags |= I2C_M_16BIT_REG;
+		else
+			client->flags &= ~I2C_M_16BIT_REG;
+		return 0;
+	case I2C_16BIT_DATA:
+		if (arg)
+			client->flags |= I2C_M_16BIT_DATA;
+		else
+			client->flags &= ~I2C_M_16BIT_DATA;
+		return 0;
+	case I2C_DMA:
+		if (arg)
+			client->flags |= I2C_M_DMA;
+		else
+			client->flags &= ~I2C_M_DMA;
+		return 0;
+#endif
 	case I2C_FUNCS:
 		funcs = i2c_get_functionality(client->adapter);
 		return put_user(funcs, (unsigned long __user *)arg);
diff --git a/drivers/mfd/Kconfig b/drivers/mfd/Kconfig
index c6df644..327bb5b 100644
--- a/drivers/mfd/Kconfig
+++ b/drivers/mfd/Kconfig
@@ -358,6 +358,17 @@ config MFD_HI655X_PMIC
 	help
 	  Select this option to enable Hisilicon hi655x series pmic driver.
 
+config MFD_HISI_FMC
+	tristate "HiSilicon Flash Memory Controller"
+	depends on OF
+	depends on ARCH_HISI_BVT
+	select MFD_CORE
+	select REGMAP_MMIO
+	help
+	  Select this option to enable the HiSilicon Flash Memory
+	  Controller(FMC) driver.
+
+
 config HTC_PASIC3
 	tristate "HTC PASIC3 LED/DS1WM chip support"
 	select MFD_CORE
diff --git a/drivers/mfd/Makefile b/drivers/mfd/Makefile
index 9834e66..9c6d6ea 100644
--- a/drivers/mfd/Makefile
+++ b/drivers/mfd/Makefile
@@ -180,6 +180,7 @@ obj-$(CONFIG_MFD_TPS65090)	+= tps65090.o
 obj-$(CONFIG_MFD_AAT2870_CORE)	+= aat2870-core.o
 obj-$(CONFIG_MFD_ATMEL_FLEXCOM)	+= atmel-flexcom.o
 obj-$(CONFIG_MFD_ATMEL_HLCDC)	+= atmel-hlcdc.o
+obj-$(CONFIG_MFD_HISI_FMC)	+= hisi_fmc.o
 obj-$(CONFIG_MFD_INTEL_LPSS)	+= intel-lpss.o
 obj-$(CONFIG_MFD_INTEL_LPSS_PCI)	+= intel-lpss-pci.o
 obj-$(CONFIG_MFD_INTEL_LPSS_ACPI)	+= intel-lpss-acpi.o
diff --git a/drivers/mfd/hisi_fmc.c b/drivers/mfd/hisi_fmc.c
new file mode 100644
index 0000000..ef5eab3
--- /dev/null
+++ b/drivers/mfd/hisi_fmc.c
@@ -0,0 +1,110 @@
+/* HiSilicon Flash Memory Controller Driver
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program. If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/err.h>
+#include <linux/mfd/core.h>
+#include <linux/mfd/hisi_fmc.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/platform_device.h>
+
+unsigned char hifmc_cs_user[HIFMC_MAX_CHIP_NUM];
+/* ------------------------------------------------------------------------ */
+static const struct mfd_cell hisi_fmc_devs[] = {
+	{
+		.name = "hisi_spi_nor",
+		.of_compatible = "hisilicon,fmc-spi-nor",
+	},
+	{
+		.name = "hisi_spi_nand",
+		.of_compatible = "hisilicon,fmc-spi-nand",
+	},
+	{
+		.name = "hisi_nand",
+		.of_compatible = "hisilicon,fmc-nand",
+	},
+};
+
+static int hisi_fmc_probe(struct platform_device *pdev)
+{
+	struct hisi_fmc *fmc;
+	struct resource *res;
+	int ret;
+
+	fmc = devm_kzalloc(&pdev->dev, sizeof(*fmc), GFP_KERNEL);
+	if (!fmc)
+		return -ENOMEM;
+
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "control");
+	fmc->regbase = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(fmc->regbase))
+		return PTR_ERR(fmc->regbase);
+
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "memory");
+	fmc->iobase = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(fmc->iobase))
+		return PTR_ERR(fmc->iobase);
+
+	fmc->clk = devm_clk_get(&pdev->dev, NULL);
+	if (IS_ERR(fmc->clk))
+		return PTR_ERR(fmc->clk);
+
+	mutex_init(&fmc->lock);
+
+	platform_set_drvdata(pdev, fmc);
+
+	ret = mfd_add_devices(&pdev->dev, 0, hisi_fmc_devs,
+			ARRAY_SIZE(hisi_fmc_devs), NULL, 0, NULL);
+	if (ret) {
+		dev_err(&pdev->dev, "add mfd devices failed: %d\n", ret);
+		return ret;
+	}
+
+	return 0;
+}
+
+static int hisi_fmc_remove(struct platform_device *pdev)
+{
+	struct hisi_fmc *fmc = platform_get_drvdata(pdev);
+
+	mfd_remove_devices(&pdev->dev);
+	mutex_destroy(&fmc->lock);
+
+	return 0;
+}
+
+static const struct of_device_id hisi_fmc_of_match_tbl[] = {
+	{ .compatible = "hisilicon,hisi-fmc"},
+	{ }
+};
+MODULE_DEVICE_TABLE(of, hisi_fmc_of_match_tbl);
+
+static struct platform_driver hisi_fmc_driver = {
+	.driver = {
+		.name = "hifmc",
+		.of_match_table = hisi_fmc_of_match_tbl,
+	},
+	.probe = hisi_fmc_probe,
+	.remove = hisi_fmc_remove,
+};
+module_platform_driver(hisi_fmc_driver);
+
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("HiSilicon Flash Memory Controller Driver");
diff --git a/drivers/mmc/core/sdio.c b/drivers/mmc/core/sdio.c
index bd44ba8..61ef3ea 100644
--- a/drivers/mmc/core/sdio.c
+++ b/drivers/mmc/core/sdio.c
@@ -28,6 +28,10 @@
 #include "sdio_ops.h"
 #include "sdio_cis.h"
 
+#ifdef CONFIG_ARCH_HISI_BVT
+#include "host.h"
+#endif
+
 static int sdio_read_fbr(struct sdio_func *func)
 {
 	int ret;
@@ -1173,3 +1177,40 @@ int mmc_attach_sdio(struct mmc_host *host)
 	return err;
 }
 
+#ifdef CONFIG_ARCH_HISI_BVT
+/* sdio_reset_comm has been fixed in latest kernel/msm.git for Linux
+ * 2.6.27. The implementation prior to that buggy, and needs broadcom's
+ * patch for it*/
+int sdio_reset_comm(struct mmc_card *card)
+{
+	struct mmc_host *host = card->host;
+	u32 ocr;
+	u32 rocr;
+	int err;
+
+	mmc_claim_host(host);
+	mmc_retune_disable(host);
+	mmc_go_idle(host);
+	mmc_set_clock(host, host->f_min);
+	err = mmc_send_io_op_cond(host, 0, &ocr);
+	if (err)
+		goto err;
+	rocr = mmc_select_voltage(host, ocr);
+	if (!rocr) {
+		err = -EINVAL;
+		goto err;
+	}
+	err = mmc_sdio_init_card(host, rocr, card, 0);
+	if (err)
+		goto err;
+	mmc_release_host(host);
+	return 0;
+err:
+	printk("%s: Error resetting SDIO communications (%d)\n",
+			mmc_hostname(host), err);
+	mmc_release_host(host);
+	return err;
+}
+EXPORT_SYMBOL(sdio_reset_comm);
+#endif
+
diff --git a/drivers/mmc/host/Kconfig b/drivers/mmc/host/Kconfig
index 5274f50..a230288 100644
--- a/drivers/mmc/host/Kconfig
+++ b/drivers/mmc/host/Kconfig
@@ -798,3 +798,5 @@ config MMC_SDHCI_BRCMSTB
 	  Broadcom STB SoCs.
 
 	  If unsure, say Y.
+
+source "drivers/mmc/host/himci/Kconfig"
diff --git a/drivers/mmc/host/Makefile b/drivers/mmc/host/Makefile
index e2bdaaf..246f354 100644
--- a/drivers/mmc/host/Makefile
+++ b/drivers/mmc/host/Makefile
@@ -80,3 +80,5 @@ obj-$(CONFIG_MMC_SDHCI_BRCMSTB)		+= sdhci-brcmstb.o
 ifeq ($(CONFIG_CB710_DEBUG),y)
 	CFLAGS-cb710-mmc	+= -DDEBUG
 endif
+
+obj-$(CONFIG_HIMCI)	+= himci/
diff --git a/drivers/mmc/host/himci/Kconfig b/drivers/mmc/host/himci/Kconfig
new file mode 100644
index 0000000..b14241a
--- /dev/null
+++ b/drivers/mmc/host/himci/Kconfig
@@ -0,0 +1,23 @@
+#
+#  himci family SD/MMC device configuration
+#
+menuconfig HIMCI
+	tristate "himciv100 driver support"
+	depends on ARCH_HI3516A
+	default y if ARCH_HI3516A
+	select MMC_UNSAFE_RESUME
+	select MMC_EMBEDDED_SDIO
+	select MMC_BLOCK
+	select MMC_BLOCK_BOUNCE
+	help
+	  This selects the Hisilicon Synopsys MultiMedia Card Driver
+	  support. If you want use SD/MMC/SDIO driver,
+	  Say Y or M here.
+
+	  default is Y.
+
+config SEND_AUTO_STOP
+	bool "Send Auto Stop to terminate data transfer between host and SD card"
+	depends on ARCH_HI3516A && HIMCI
+	default y
+
diff --git a/drivers/mmc/host/himci/Makefile b/drivers/mmc/host/himci/Makefile
new file mode 100644
index 0000000..6858bfce
--- /dev/null
+++ b/drivers/mmc/host/himci/Makefile
@@ -0,0 +1,2 @@
+obj-$(CONFIG_HIMCI) += hisi_mci.o
+hisi_mci-y	:= himci.o himci_proc.o
diff --git a/drivers/mmc/host/himci/himci.c b/drivers/mmc/host/himci/himci.c
new file mode 100644
index 0000000..cbf72ae
--- /dev/null
+++ b/drivers/mmc/host/himci/himci.c
@@ -0,0 +1,1653 @@
+/*
+ * himci.c - hisilicon MMC Host driver
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#define pr_fmt(fmt) "himci: " fmt
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/platform_device.h>
+#include <linux/mm.h>
+#include <linux/interrupt.h>
+#include <linux/dma-mapping.h>
+#include <linux/scatterlist.h>
+
+#include <linux/mmc/host.h>
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/sd.h>
+#include <linux/slab.h>
+
+#include <linux/ioport.h>
+#include <linux/device.h>
+#include <linux/spinlock.h>
+
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/kthread.h>
+#include <linux/workqueue.h>
+#include <linux/freezer.h>
+#include <asm/dma.h>
+#include <asm/irq.h>
+#include <linux/sizes.h>
+#include <mach/io.h>
+
+#include <linux/io.h>
+#include <linux/of.h>
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/reset.h>
+
+#include "himci_reg.h"
+#include "himci.h"
+#include "himci_proc.h"
+
+#ifdef CONFIG_ARCH_HI3516A
+#include "himci_hi3516a.c"
+#endif
+
+#define DRIVER_NAME "himci"
+#define CMD_DES_PAGE_SIZE	(2 * PAGE_SIZE)
+
+static unsigned int detect_time = HI_MCI_DETECT_TIMEOUT;
+static unsigned int retry_count = MAX_RETRY_COUNT;
+static unsigned int request_timeout = HI_MCI_REQUEST_TIMEOUT;
+int trace_level = HIMCI_TRACE_LEVEL;
+unsigned int slot_index = 0;
+struct himci_host *mci_host[HIMCI_SLOT_NUM] = {NULL};
+
+#ifdef MODULE
+
+module_param(detect_time, uint, 0600);
+MODULE_PARM_DESC(detect_timer, "card detect time (default:500ms))");
+
+module_param(retry_count, uint, 0600);
+MODULE_PARM_DESC(retry_count, "retry count times (default:100))");
+
+module_param(request_timeout, uint, 0600);
+MODULE_PARM_DESC(request_timeout, "Request timeout time (default:3s))");
+
+module_param(trace_level, int, 0600);
+MODULE_PARM_DESC(trace_level, "HIMCI_TRACE_LEVEL");
+
+#endif
+
+/* reset MMC host controller */
+static void himci_sys_reset(struct himci_host *host)
+{
+	unsigned int reg_value;
+	unsigned long flags;
+
+	himci_trace(2, "reset");
+
+	local_irq_save(flags);
+
+	reg_value = himci_readl(host->base + MCI_BMOD);
+	reg_value |= BMOD_SWR;
+	himci_writel(reg_value, host->base + MCI_BMOD);
+	mdelay(10);
+
+	reg_value = himci_readl(host->base + MCI_BMOD);
+	reg_value |= BURST_16 | BURST_INCR;
+	himci_writel(reg_value, host->base + MCI_BMOD);
+
+	reg_value = himci_readl(host->base + MCI_CTRL);
+	reg_value |=  CTRL_RESET | FIFO_RESET | DMA_RESET;
+	himci_writel(reg_value, host->base + MCI_CTRL);
+
+	local_irq_restore(flags);
+}
+
+static void himci_ctrl_power(struct himci_host *host, unsigned int flag)
+{
+	himci_trace(2, "begin");
+
+	himci_writel(flag, host->base + MCI_PWREN);
+}
+
+/**********************************************
+ *1: card off
+ *0: card on
+ ***********************************************/
+static unsigned int himci_sys_card_detect(struct himci_host *host)
+{
+	unsigned int card_status;
+
+	card_status = readl(host->base + MCI_CDETECT);
+
+	return card_status & HIMCI_CARD0;
+}
+
+/**********************************************
+ *1: card readonly
+ *0: card read/write
+ ***********************************************/
+static unsigned int himci_ctrl_card_readonly(struct himci_host *host)
+{
+	unsigned int card_value = himci_readl(host->base + MCI_WRTPRT);
+	return card_value & HIMCI_CARD0;
+}
+
+static int himci_wait_cmd(struct himci_host *host)
+{
+	int wait_retry_count = 0;
+	unsigned int reg_data = 0;
+	unsigned long flags;
+
+	himci_trace(2, "begin");
+	himci_assert(host);
+
+	while (1) {
+		/*
+		 * Check if CMD::start_cmd bit is clear.
+		 * start_cmd = 0 means MMC Host controller has loaded registers
+		 * and next command can be loaded in.
+		 */
+		reg_data = himci_readl(host->base + MCI_CMD);
+		if ((reg_data & START_CMD) == 0)
+			return 0;
+
+		/* Check if Raw_Intr_Status::HLE bit is set. */
+		spin_lock_irqsave(&host->lock, flags);
+		reg_data = himci_readl(host->base + MCI_RINTSTS);
+		if (reg_data & HLE_INT_STATUS) {
+			reg_data |= HLE_INT_STATUS;
+			himci_writel(reg_data, host->base + MCI_RINTSTS);
+			spin_unlock_irqrestore(&host->lock, flags);
+
+			himci_trace(5, "Other CMD is running,"
+				"please operate cmd again!");
+			return 1;
+		}
+
+		spin_unlock_irqrestore(&host->lock, flags);
+		udelay(100);
+
+		/* Check if number of retries for this are over. */
+		wait_retry_count++;
+		if (wait_retry_count >= retry_count) {
+			himci_trace(5, "send cmd is timeout!");
+			return -1;
+		}
+	}
+}
+
+static void himci_control_cclk(struct himci_host *host, unsigned int flag)
+{
+	unsigned int reg;
+	union cmd_arg_u cmd_reg;
+
+	himci_trace(2, "begin");
+	himci_assert(host);
+
+	reg = himci_readl(host->base + MCI_CLKENA);
+	if (flag == ENABLE)
+		reg |= CCLK_ENABLE;
+	else
+		reg &= 0xffff0000;
+	himci_writel(reg, host->base + MCI_CLKENA);
+
+	cmd_reg.cmd_arg = himci_readl(host->base + MCI_CMD);
+	cmd_reg.bits.start_cmd = 1;
+	cmd_reg.bits.card_number = 0;
+	cmd_reg.bits.cmd_index = 0;
+	cmd_reg.bits.data_transfer_expected = 0;
+	cmd_reg.bits.update_clk_reg_only = 1;
+	cmd_reg.bits.response_expect = 0;
+	cmd_reg.bits.send_auto_stop = 0;
+	cmd_reg.bits.wait_prvdata_complete = 0;
+	cmd_reg.bits.check_response_crc = 0;
+	himci_writel(cmd_reg.cmd_arg, host->base + MCI_CMD);
+	if (himci_wait_cmd(host) != 0)
+		himci_trace(5, "disable or enable clk is timeout!");
+}
+
+static void himci_set_cclk(struct himci_host *host, unsigned int cclk)
+{
+	unsigned int reg_value;
+	union cmd_arg_u clk_cmd;
+	unsigned int hclk;
+
+	himci_trace(2, "begin");
+	himci_assert(host);
+	himci_assert(cclk);
+
+	hclk = cclk > MMC_CRG_MIN ? cclk : MMC_CRG_MIN;
+	clk_set_rate(host->clk, hclk);
+
+	hclk = clk_get_rate(host->clk);
+
+	/*
+	 * set card clk divider value,
+	 * clk_divider = Fmmcclk/(Fmmc_cclk * 2)
+	 */
+	reg_value = hclk / (cclk * 2);
+	if ((hclk % (cclk * 2)) && (hclk > cclk))
+		reg_value++;
+	if (reg_value > 0xFF)
+		reg_value = 0xFF;
+
+	host->hclk = hclk;
+	host->cclk = reg_value ? (hclk / (reg_value * 2)) : hclk;
+	himci_writel(reg_value, host->base + MCI_CLKDIV);
+
+	clk_cmd.cmd_arg = himci_readl(host->base + MCI_CMD);
+	clk_cmd.bits.start_cmd = 1;
+	clk_cmd.bits.update_clk_reg_only = 1;
+	clk_cmd.bits.cmd_index = 0;
+	clk_cmd.bits.data_transfer_expected = 0;
+	clk_cmd.bits.response_expect = 0;
+	himci_writel(clk_cmd.cmd_arg, host->base + MCI_CMD);
+	if (himci_wait_cmd(host) != 0)
+		himci_trace(5, "set card clk divider is failed!");
+}
+
+static void himci_init_host(struct himci_host *host)
+{
+	unsigned int tmp_reg = 0;
+	unsigned long flags;
+
+	himci_trace(2, "begin");
+	himci_assert(host);
+
+	himci_sys_reset(host);
+
+	/* set drv/smpl phase shift */
+	tmp_reg |= SMPL_PHASE_DFLT | DRV_PHASE_DFLT;
+	himci_writel(tmp_reg, host->base + MCI_UHS_REG_EXT);
+
+	/* set card read threshold */
+	himci_writel(RW_THRESHOLD_SIZE, host->base + MCI_CARDTHRCTL);
+
+	/* clear MMC host intr */
+	himci_writel(ALL_INT_CLR, host->base + MCI_RINTSTS);
+
+	spin_lock_irqsave(&host->lock, flags);
+	host->pending_events = 0;
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	/* MASK MMC all host intr */
+	tmp_reg = himci_readl(host->base + MCI_INTMASK);
+	tmp_reg &= ~ALL_INT_MASK;
+	tmp_reg |= DATA_INT_MASK;
+	himci_writel(tmp_reg, host->base + MCI_INTMASK);
+
+	/* enable inner DMA mode and close intr of MMC host controler */
+	tmp_reg = himci_readl(host->base + MCI_CTRL);
+	tmp_reg &= ~INTR_EN;
+	tmp_reg |= USE_INTERNAL_DMA | INTR_EN;
+	himci_writel(tmp_reg, host->base + MCI_CTRL);
+
+	/* set timeout param */
+	himci_writel(DATA_TIMEOUT | RESPONSE_TIMEOUT, host->base + MCI_TIMEOUT);
+
+	/* set FIFO param */
+	tmp_reg = 0;
+	tmp_reg |= BURST_SIZE | RX_WMARK | TX_WMARK;
+	himci_writel(tmp_reg, host->base + MCI_FIFOTH);
+}
+
+static void himci_detect_card(unsigned long arg)
+{
+	struct himci_host *host = (struct himci_host *)arg;
+	unsigned int i, curr_status, status[5], detect_retry_count = 0;
+
+	himci_assert(host);
+
+	while (1) {
+		for (i = 0; i < 5; i++) {
+			status[i] = himci_sys_card_detect(host);
+			udelay(10);
+		}
+		if ((status[0] == status[1])
+				&& (status[0] == status[2])
+				&& (status[0] == status[3])
+				&& (status[0] == status[4]))
+			break;
+
+		detect_retry_count++;
+		if (detect_retry_count >= retry_count) {
+			himci_error("this is a dithering, card detect error!");
+			goto err;
+		}
+	}
+	curr_status = status[0];
+	if (curr_status != host->card_status) {
+		himci_trace(2, "begin card_status = %d\n", host->card_status);
+		host->card_status = curr_status;
+		if (curr_status != CARD_UNPLUGED) {
+			himci_init_host(host);
+			pr_info("card connected!\n");
+		} else {
+			pr_info("card disconnected!\n");
+		}
+
+		mmc_detect_change(host->mmc, 0);
+	}
+err:
+	mod_timer(&host->timer, jiffies + detect_time);
+}
+
+static void himci_idma_start(struct himci_host *host)
+{
+	unsigned int tmp;
+
+	himci_trace(2, "begin");
+	himci_writel(host->dma_paddr, host->base + MCI_DBADDR);
+	tmp = himci_readl(host->base + MCI_BMOD);
+	tmp |= BMOD_DMA_EN;
+	himci_writel(tmp, host->base + MCI_BMOD);
+}
+
+static void himci_idma_stop(struct himci_host *host)
+{
+	unsigned int tmp_reg;
+
+	himci_trace(2, "begin");
+	tmp_reg = himci_readl(host->base + MCI_BMOD);
+	tmp_reg &= ~BMOD_DMA_EN;
+	himci_writel(tmp_reg, host->base + MCI_BMOD);
+}
+
+static int himci_setup_data(struct himci_host *host, struct mmc_data *data)
+{
+	unsigned int sg_phyaddr, sg_length;
+	unsigned int i, ret = 0;
+	unsigned int data_size;
+	unsigned int max_des, des_cnt;
+	struct himci_des *des;
+
+	himci_trace(2, "begin");
+	himci_assert(host);
+	himci_assert(data);
+
+	host->data = data;
+
+	if (data->flags & MMC_DATA_READ)
+		host->dma_dir = DMA_FROM_DEVICE;
+	else
+		host->dma_dir = DMA_TO_DEVICE;
+
+	host->dma_sg = data->sg;
+	host->dma_sg_num = dma_map_sg(mmc_dev(host->mmc),
+			data->sg, data->sg_len, host->dma_dir);
+	himci_assert(host->dma_sg_num);
+	himci_trace(2, "host->dma_sg_num is %d\n", host->dma_sg_num);
+	data_size = data->blksz * data->blocks;
+
+	if (data_size > (DMA_BUFFER * MAX_DMA_DES)) {
+		himci_error("mci request data_size is too big!\n");
+		ret = -1;
+		goto out;
+	}
+
+	himci_trace(2, "host->dma_paddr is 0x%08X,host->dma_vaddr is 0x%08X\n",
+			(unsigned int)host->dma_paddr,
+			(unsigned int)host->dma_vaddr);
+
+	max_des = (CMD_DES_PAGE_SIZE/sizeof(struct himci_des));
+	des = (struct himci_des *)host->dma_vaddr;
+	des_cnt = 0;
+
+	for (i = 0; i < host->dma_sg_num; i++) {
+		sg_length = sg_dma_len(&data->sg[i]);
+		sg_phyaddr = sg_dma_address(&data->sg[i]);
+		himci_trace(2, "sg[%d] sg_length is 0x%08X, " \
+				"sg_phyaddr is 0x%08X\n", \
+				i, (unsigned int)sg_length, \
+				(unsigned int)sg_phyaddr);
+		while (sg_length) {
+			des[des_cnt].idmac_des_ctrl = DMA_DES_OWN
+				| DMA_DES_NEXT_DES;
+			des[des_cnt].idmac_des_buf_addr = sg_phyaddr;
+			/* idmac_des_next_addr is paddr for dma */
+			des[des_cnt].idmac_des_next_addr = host->dma_paddr
+				+ (des_cnt + 1) * sizeof(struct himci_des);
+
+			if (sg_length >= 0x1F00) {
+				des[des_cnt].idmac_des_buf_size = 0x1F00;
+				sg_length -= 0x1F00;
+				sg_phyaddr += 0x1F00;
+			} else {
+				/* FIXME:data alignment */
+				des[des_cnt].idmac_des_buf_size = sg_length;
+				sg_length = 0;
+			}
+
+			himci_trace(2, "des[%d] vaddr  is 0x%08X", i,
+					(unsigned int)&des[i]);
+			himci_trace(2, "des[%d].idmac_des_ctrl is 0x%08X",
+			       i, (unsigned int)des[i].idmac_des_ctrl);
+			himci_trace(2, "des[%d].idmac_des_buf_size is 0x%08X",
+				i, (unsigned int)des[i].idmac_des_buf_size);
+			himci_trace(2, "des[%d].idmac_des_buf_addr 0x%08X",
+				i, (unsigned int)des[i].idmac_des_buf_addr);
+			himci_trace(2, "des[%d].idmac_des_next_addr is 0x%08X",
+				i, (unsigned int)des[i].idmac_des_next_addr);
+			des_cnt++;
+		}
+
+		himci_assert(des_cnt < max_des);
+	}
+	des[0].idmac_des_ctrl |= DMA_DES_FIRST_DES;
+	des[des_cnt - 1].idmac_des_ctrl |= DMA_DES_LAST_DES;
+	des[des_cnt - 1].idmac_des_next_addr = 0;
+out:
+	return ret;
+}
+
+static int himci_exec_cmd(struct himci_host *host,
+			   struct mmc_command *cmd, struct mmc_data *data)
+{
+	volatile union cmd_arg_u  cmd_regs;
+
+	himci_trace(2, "begin");
+	himci_assert(host);
+	himci_assert(cmd);
+
+	host->cmd = cmd;
+
+	himci_writel(cmd->arg, host->base + MCI_CMDARG);
+	himci_trace(4, "arg_reg 0x%x, val 0x%x", MCI_CMDARG, cmd->arg);
+	cmd_regs.cmd_arg = himci_readl(host->base + MCI_CMD);
+	if (data) {
+		cmd_regs.bits.data_transfer_expected = 1;
+		if (data->flags & (MMC_DATA_WRITE | MMC_DATA_READ))
+			cmd_regs.bits.transfer_mode = 0;
+
+		if (data->flags & MMC_DATA_WRITE)
+			cmd_regs.bits.read_write = 1;
+		else if (data->flags & MMC_DATA_READ)
+			cmd_regs.bits.read_write = 0;
+	} else {
+		cmd_regs.bits.data_transfer_expected = 0;
+		cmd_regs.bits.transfer_mode = 0;
+		cmd_regs.bits.read_write = 0;
+	}
+
+	cmd_regs.bits.send_auto_stop = 0;
+#ifdef CONFIG_SEND_AUTO_STOP
+	if ((host->mrq->stop) && (!(host->is_tuning)))
+		cmd_regs.bits.send_auto_stop = 1;
+#endif
+
+	if (cmd == host->mrq->stop ||
+			cmd->opcode == MMC_STOP_TRANSMISSION) {
+		cmd_regs.bits.stop_abort_cmd = 1;
+		cmd_regs.bits.wait_prvdata_complete = 0;
+	} else {
+		cmd_regs.bits.stop_abort_cmd = 0;
+		cmd_regs.bits.wait_prvdata_complete = 1;
+	}
+
+	switch (mmc_resp_type(cmd)) {
+	case MMC_RSP_NONE:
+		cmd_regs.bits.response_expect = 0;
+		cmd_regs.bits.response_length = 0;
+		cmd_regs.bits.check_response_crc = 0;
+		break;
+	case MMC_RSP_R1:
+	case MMC_RSP_R1B:
+		cmd_regs.bits.response_expect = 1;
+		cmd_regs.bits.response_length = 0;
+		cmd_regs.bits.check_response_crc = 1;
+		break;
+	case MMC_RSP_R2:
+		cmd_regs.bits.response_expect = 1;
+		cmd_regs.bits.response_length = 1;
+		cmd_regs.bits.check_response_crc = 1;
+		break;
+	case MMC_RSP_R3:
+	case MMC_RSP_R1 & (~MMC_RSP_CRC):
+		cmd_regs.bits.response_expect = 1;
+		cmd_regs.bits.response_length = 0;
+		cmd_regs.bits.check_response_crc = 0;
+		break;
+	default:
+		host->cmd->error = -EINVAL;
+		himci_error("himci: unhandled response type %02x\n",
+				mmc_resp_type(cmd));
+		return -EINVAL;
+	}
+
+	himci_trace(3, "cmd->opcode = %d cmd->arg = 0x%X\n",
+			cmd->opcode, cmd->arg);
+	if (cmd->opcode == MMC_GO_IDLE_STATE)
+		cmd_regs.bits.send_initialization = 1;
+	else
+		cmd_regs.bits.send_initialization = 0;
+	/* CMD 11 check switch voltage */
+	if (cmd->opcode == SD_SWITCH_VOLTAGE)
+		cmd_regs.bits.volt_switch = 1;
+	else
+		cmd_regs.bits.volt_switch = 0;
+
+	cmd_regs.bits.card_number = 0;
+	cmd_regs.bits.cmd_index = cmd->opcode;
+	cmd_regs.bits.start_cmd = 1;
+	cmd_regs.bits.update_clk_reg_only = 0;
+
+	himci_writel(DATA_INT_MASK, host->base + MCI_RINTSTS);
+	himci_writel(cmd_regs.cmd_arg, host->base + MCI_CMD);
+	himci_trace(4, "cmd_reg 0x%x, val 0x%x\n", MCI_CMD, cmd_regs.cmd_arg);
+
+	if (himci_wait_cmd(host) != 0) {
+		himci_trace(3, "send card cmd is failed!");
+		return -EINVAL;
+	}
+	return 0;
+}
+
+static void himci_finish_request(struct himci_host *host,
+				  struct mmc_request *mrq)
+{
+	himci_trace(2, "begin");
+	himci_assert(host);
+	himci_assert(mrq);
+
+	host->mrq = NULL;
+	host->cmd = NULL;
+	host->data = NULL;
+	mmc_request_done(host->mmc, mrq);
+}
+
+static void himci_cmd_done(struct himci_host *host, unsigned int stat)
+{
+	unsigned int i;
+	struct mmc_command *cmd = host->cmd;
+
+	himci_trace(2, "begin");
+	himci_assert(host);
+	himci_assert(cmd);
+
+	for (i = 0; i < 4; i++) {
+		if (mmc_resp_type(cmd) == MMC_RSP_R2) {
+			cmd->resp[i] = himci_readl(host->base +
+					MCI_RESP3 - i * 0x4);
+			/* R2 must delay some time here ,when use UHI card,
+			   need check why */
+			udelay(1000);
+		} else
+			cmd->resp[i] = himci_readl(host->base +
+					MCI_RESP0 + i * 0x4);
+	}
+
+	if (stat & RTO_INT_STATUS) {
+		cmd->error = -ETIMEDOUT;
+		himci_trace(3, "irq cmd status stat = 0x%x is timeout error!",
+				stat);
+	} else if (stat & (RCRC_INT_STATUS | RE_INT_STATUS)) {
+		cmd->error = -EILSEQ;
+		himci_trace(3, "irq cmd status stat = 0x%x is response error!",
+				stat);
+	}
+
+	host->cmd = NULL;
+}
+
+static void himci_data_done(struct himci_host *host, unsigned int stat)
+{
+	struct mmc_data *data = host->data;
+
+	himci_trace(2, "begin");
+	himci_assert(host);
+	himci_assert(data);
+
+	dma_unmap_sg(mmc_dev(host->mmc), data->sg, data->sg_len, host->dma_dir);
+
+	if (stat & (HTO_INT_STATUS | DRTO_INT_STATUS)) {
+		data->error = -ETIMEDOUT;
+		himci_trace(3, "irq data status stat = 0x%x is timeout error!",
+			    stat);
+	} else if (stat & (EBE_INT_STATUS | SBE_INT_STATUS |
+			   FRUN_INT_STATUS | DCRC_INT_STATUS)) {
+		data->error = -EILSEQ;
+		himci_trace(3, "irq data status stat = 0x%x is data error!",
+				stat);
+	}
+
+	if (!data->error)
+		data->bytes_xfered = data->blocks * data->blksz;
+	else
+		data->bytes_xfered = 0;
+
+	host->data = NULL;
+}
+
+static int himci_wait_cmd_complete(struct himci_host *host)
+{
+	unsigned int cmd_retry_count = 0;
+	unsigned long cmd_jiffies_timeout;
+	unsigned int cmd_irq_reg = 0;
+	struct mmc_command *cmd = host->cmd;
+	unsigned long flags;
+
+	himci_trace(2, "begin");
+	himci_assert(host);
+	himci_assert(cmd);
+
+	cmd_jiffies_timeout = jiffies + request_timeout;
+	while (1) {
+
+		do {
+			spin_lock_irqsave(&host->lock, flags);
+			cmd_irq_reg = readl(host->base + MCI_RINTSTS);
+
+			if (cmd_irq_reg & CD_INT_STATUS) {
+				himci_writel((CD_INT_STATUS | RTO_INT_STATUS
+					| RCRC_INT_STATUS | RE_INT_STATUS),
+					host->base + MCI_RINTSTS);
+				spin_unlock_irqrestore(&host->lock, flags);
+				himci_cmd_done(host, cmd_irq_reg);
+				return 0;
+			} else if (cmd_irq_reg & VOLT_SWITCH_INT_STATUS) {
+				himci_writel(VOLT_SWITCH_INT_STATUS,
+						host->base + MCI_RINTSTS);
+				spin_unlock_irqrestore(&host->lock, flags);
+				himci_cmd_done(host, cmd_irq_reg);
+				return 0;
+			}
+			spin_unlock_irqrestore(&host->lock, flags);
+			cmd_retry_count++;
+		} while (cmd_retry_count < retry_count);
+
+		cmd_retry_count = 0;
+
+		if (host->card_status == CARD_UNPLUGED) {
+			cmd->error = -ETIMEDOUT;
+			return -1;
+		}
+
+		if (!time_before(jiffies, cmd_jiffies_timeout)) {
+			unsigned int i = 0;
+			for (i = 0; i < 4; i++) {
+				cmd->resp[i] = himci_readl(host->base
+						+ MCI_RESP0 + i * 0x4);
+				pr_err("voltage switch read MCI_RESP");
+				pr_err("%d : 0x%x\n", i, cmd->resp[i]);
+			}
+			cmd->error = -ETIMEDOUT;
+			himci_trace(3, "wait cmd request complete is timeout!");
+			return -1;
+		}
+
+		schedule();
+	}
+}
+/*
+ * designware support send stop command automatically when
+ * read or wirte multi blocks
+ */
+#ifdef CONFIG_SEND_AUTO_STOP
+static int himci_wait_auto_stop_complete(struct himci_host *host)
+{
+	unsigned int cmd_retry_count = 0;
+	unsigned long cmd_jiffies_timeout;
+	unsigned int cmd_irq_reg = 0;
+	unsigned long flags;
+
+	himci_trace(2, "begin");
+	himci_assert(host);
+
+	cmd_jiffies_timeout = jiffies + request_timeout;
+	while (1) {
+
+		do {
+			spin_lock_irqsave(&host->lock, flags);
+			cmd_irq_reg = readl(host->base + MCI_RINTSTS);
+			if (cmd_irq_reg & ACD_INT_STATUS) {
+				himci_writel((ACD_INT_STATUS | RTO_INT_STATUS
+					| RCRC_INT_STATUS | RE_INT_STATUS),
+					host->base + MCI_RINTSTS);
+				spin_unlock_irqrestore(&host->lock, flags);
+				return 0;
+			}
+			spin_unlock_irqrestore(&host->lock, flags);
+			cmd_retry_count++;
+		} while (cmd_retry_count < retry_count);
+
+		cmd_retry_count = 0;
+		if (host->card_status == CARD_UNPLUGED)
+			return -1;
+		if (!time_before(jiffies, cmd_jiffies_timeout)) {
+			himci_trace(3, "wait auto stop complete is timeout!");
+			return -1;
+		}
+
+		schedule();
+	}
+
+}
+#endif
+
+static int himci_wait_data_complete(struct himci_host *host)
+{
+	unsigned int tmp_reg;
+	struct mmc_data *data = host->data;
+	long time = request_timeout;
+	unsigned long flags;
+
+	himci_trace(2, "begin");
+	himci_assert(host);
+	himci_assert(data);
+
+	time = wait_event_timeout(host->intr_wait,
+				  test_bit(HIMCI_PEND_DTO_B,
+					   &host->pending_events), time);
+
+	/* Mask MMC host data intr */
+	spin_lock_irqsave(&host->lock, flags);
+	tmp_reg = himci_readl(host->base + MCI_INTMASK);
+	tmp_reg &= ~DATA_INT_MASK;
+	himci_writel(tmp_reg, host->base + MCI_INTMASK);
+	host->pending_events &= ~HIMCI_PEND_DTO_M;
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	if (((time <= 0)
+		&& (!test_bit(HIMCI_PEND_DTO_B, &host->pending_events)))
+		|| (host->card_status == CARD_UNPLUGED)) {
+
+		data->error = -ETIMEDOUT;
+		himci_trace(5, "wait data request complete is timeout! 0x%08X",
+				host->irq_status);
+		himci_idma_stop(host);
+		himci_data_done(host, host->irq_status);
+		return -1;
+	}
+
+	himci_idma_stop(host);
+	himci_data_done(host, host->irq_status);
+	return 0;
+}
+
+static int himci_wait_card_complete(struct himci_host *host,
+		struct mmc_data *data)
+{
+	unsigned int card_retry_count = 0;
+	unsigned long card_jiffies_timeout;
+	unsigned int card_status_reg = 0;
+
+	himci_trace(2, "begin");
+	himci_assert(host);
+
+	card_jiffies_timeout = jiffies + request_timeout;
+	while (1) {
+		do {
+			card_status_reg = readl(host->base + MCI_STATUS);
+			if (!(card_status_reg & DATA_BUSY)) {
+				himci_trace(2, "end");
+				return 0;
+			}
+			card_retry_count++;
+		} while (card_retry_count < retry_count);
+
+		card_retry_count = 0;
+
+		if (host->card_status == CARD_UNPLUGED) {
+			host->mrq->cmd->error = -ETIMEDOUT;
+			himci_trace(3, "card is unpluged!");
+			return -1;
+		}
+
+		if (!time_before(jiffies, card_jiffies_timeout)) {
+			host->mrq->cmd->error = -ETIMEDOUT;
+			himci_trace(3, "wait card ready complete is timeout!");
+			return -1;
+		}
+
+		schedule();
+	}
+}
+
+static void himci_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct himci_host *host = mmc_priv(mmc);
+	int byte_cnt = 0, trans_cnt;
+	int fifo_count = 0, tmp_reg;
+	int ret = 0;
+	unsigned long flags;
+
+	himci_trace(2, "begin");
+	himci_assert(mmc);
+	himci_assert(mrq);
+	himci_assert(host);
+
+	host->mrq = mrq;
+	host->irq_status = 0;
+
+	if (host->card_status == CARD_UNPLUGED) {
+		mrq->cmd->error = -ENODEV;
+		goto request_end;
+	}
+
+	ret = himci_wait_card_complete(host, mrq->data);
+	if (ret) {
+		mrq->cmd->error = ret;
+		goto request_end;
+	}
+
+	/* prepare data */
+	if (mrq->data) {
+		ret = himci_setup_data(host, mrq->data);
+		if (ret) {
+			mrq->data->error = ret;
+			himci_trace(3, "data setup is error!");
+			goto request_end;
+		}
+
+		byte_cnt = mrq->data->blksz * mrq->data->blocks;
+		himci_writel(byte_cnt, host->base + MCI_BYTCNT);
+		himci_writel(mrq->data->blksz, host->base + MCI_BLKSIZ);
+
+		/* reset fifo */
+		tmp_reg = himci_readl(host->base + MCI_CTRL);
+		tmp_reg |= FIFO_RESET;
+		himci_writel(tmp_reg, host->base + MCI_CTRL);
+
+		do {
+			tmp_reg = himci_readl(host->base + MCI_CTRL);
+			fifo_count++;
+			if (fifo_count >= retry_count) {
+				pr_info("fifo reset is timeout!");
+				return;
+			}
+		} while (tmp_reg & FIFO_RESET);
+
+		/* start DMA */
+		himci_idma_start(host);
+	} else {
+		himci_writel(0, host->base + MCI_BYTCNT);
+		himci_writel(0, host->base + MCI_BLKSIZ);
+	}
+
+	/* send command */
+	ret = himci_exec_cmd(host, mrq->cmd, mrq->data);
+	if (ret) {
+		mrq->cmd->error = ret;
+		himci_idma_stop(host);
+		himci_trace(3, "can't send card cmd! ret = %d", ret);
+		goto request_end;
+	}
+
+	/* wait command send complete */
+	himci_wait_cmd_complete(host);
+
+	/* start data transfer */
+	if (mrq->data) {
+		if (!(mrq->cmd->error)) {
+			/* Open MMC host data intr */
+			spin_lock_irqsave(&host->lock, flags);
+			tmp_reg = himci_readl(host->base + MCI_INTMASK);
+			tmp_reg |= DATA_INT_MASK;
+			himci_writel(tmp_reg, host->base + MCI_INTMASK);
+			spin_unlock_irqrestore(&host->lock, flags);
+
+			/* wait data transfer complete */
+			himci_wait_data_complete(host);
+		} else {
+			/* CMD error in data command */
+			himci_idma_stop(host);
+		}
+
+		if (mrq->stop) {
+#ifdef CONFIG_SEND_AUTO_STOP
+			trans_cnt = himci_readl(host->base + MCI_TCBCNT);
+			/* send auto stop */
+			if ((trans_cnt == byte_cnt) && (!(host->is_tuning))) {
+				himci_trace(3, "byte_cnt = %d, trans_cnt = %d",
+						byte_cnt, trans_cnt);
+				ret = himci_wait_auto_stop_complete(host);
+				if (ret) {
+					mrq->stop->error = -ETIMEDOUT;
+					goto request_end;
+				}
+			} else {
+#endif
+				/* send soft stop command */
+				himci_trace(3, "this time, send soft stop");
+				ret = himci_exec_cmd(host, host->mrq->stop,
+						host->data);
+				if (ret) {
+					mrq->stop->error = ret;
+					goto request_end;
+				}
+				ret = himci_wait_cmd_complete(host);
+				if (ret)
+					goto request_end;
+#ifdef CONFIG_SEND_AUTO_STOP
+			}
+#endif
+		}
+	}
+
+request_end:
+	/* clear MMC host intr */
+	spin_lock_irqsave(&host->lock, flags);
+	himci_writel(ALL_SD_INT_CLR, host->base + MCI_RINTSTS);
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	himci_finish_request(host, mrq);
+}
+
+static int himci_do_voltage_switch(struct himci_host *host,
+						 struct mmc_ios *ios)
+{
+	u32 ctrl;
+
+	/*
+	 * We first check whether the request is to set signalling voltage
+	 * to 3.3V. If so, we change the voltage to 3.3V and return quickly.
+	 */
+	ctrl = himci_readl(host->base + MCI_UHS_REG);
+	if (ios->signal_voltage == MMC_SIGNAL_VOLTAGE_330) {
+		/* Set 1.8V Signal Enable in the MCI_UHS_REG to 1 */
+		himci_trace(3, "switch voltage 330");
+		ctrl &= ~HI_SDXC_CTRL_VDD_180;
+		himci_writel(ctrl, host->base + MCI_UHS_REG);
+
+		/* Wait for 5ms */
+		usleep_range(5000, 5500);
+
+		/* 3.3V regulator output should be stable within 5 ms */
+		ctrl = himci_readl(host->base + MCI_UHS_REG);
+		if (!(ctrl & HI_SDXC_CTRL_VDD_180)) {
+			/* config Pin drive capability */
+			himci_set_drv_cap(host, 0);
+			return 0;
+		} else {
+			himci_error(": Switching to 3.3V ");
+			himci_error("signalling voltage failed\n");
+			return -EIO;
+		}
+	} else if (!(ctrl & HI_SDXC_CTRL_VDD_180) &&
+		  (ios->signal_voltage == MMC_SIGNAL_VOLTAGE_180)) {
+		/* Stop SDCLK */
+		himci_trace(3, "switch voltage 180");
+		himci_control_cclk(host, DISABLE);
+
+
+		/*
+		 * Enable 1.8V Signal Enable in the MCI_UHS_REG
+		 */
+		ctrl |= HI_SDXC_CTRL_VDD_180;
+		himci_writel(ctrl, host->base + MCI_UHS_REG);
+
+		/* Wait for 5ms */
+		usleep_range(8000, 8500);
+
+		ctrl = himci_readl(host->base + MCI_UHS_REG);
+		if (ctrl & HI_SDXC_CTRL_VDD_180) {
+			/* Provide SDCLK again and wait for 1ms */
+			himci_control_cclk(host, ENABLE);
+			usleep_range(1000, 1500);
+
+			/*
+			 * If CMD11 return CMD down, then the card
+			 * was successfully switched to 1.8V signaling.
+			 */
+			ctrl = himci_readl(host->base + MCI_RINTSTS);
+			if ((ctrl & VOLT_SWITCH_INT_STATUS)
+					&& (ctrl & CD_INT_STATUS)) {
+				/* config Pin drive capability */
+				himci_set_drv_cap(host, 1);
+				return 0;
+			}
+		}
+
+		/*
+		 * If we are here, that means the switch to 1.8V signaling
+		 * failed. We power cycle the card, and retry initialization
+		 * sequence by setting S18R to 0.
+		 */
+		himci_control_cclk(host, DISABLE);
+
+		/* Wait for 1ms as per the spec */
+		usleep_range(1000, 1500);
+		himci_control_cclk(host, ENABLE);
+
+		himci_error(": Switching to 1.8V signalling ");
+		himci_error("voltage failed, retrying with S18R set to 0\n");
+		return -EAGAIN;
+	} else
+		/* No signal voltage switch required */
+		return 0;
+}
+
+static int himci_start_signal_voltage_switch(struct mmc_host *mmc,
+					      struct mmc_ios *ios)
+{
+	struct himci_host *host = mmc_priv(mmc);
+	int err;
+
+	err = himci_do_voltage_switch(host, ios);
+	return err;
+}
+
+static int himci_send_stop(struct mmc_host *host)
+{
+	struct mmc_command cmd = {0};
+	int err;
+
+	cmd.opcode = MMC_STOP_TRANSMISSION;
+	cmd.flags = MMC_RSP_SPI_R1B | MMC_RSP_R1B | MMC_CMD_AC;
+	err = mmc_wait_for_cmd(host, &cmd, 0);
+	return err;
+}
+
+static void himci_set_sap_phase(struct himci_host *host, u32 phase)
+{
+	unsigned int reg_value;
+	unsigned long flags;
+
+	spin_lock_irqsave(&host->lock, flags);
+
+	reg_value = himci_readl(host->base + MCI_UHS_REG_EXT);
+	reg_value &= ~CLK_SMPL_PHS_MASK;
+	reg_value |= (phase << CLK_SMPL_PHS_SHIFT);
+	himci_writel(reg_value, host->base + MCI_UHS_REG_EXT);
+
+	spin_unlock_irqrestore(&host->lock, flags);
+}
+
+/*
+ * The procedure of tuning the phase shift of sampling clock
+ *
+ * 1.Set a phase shift of 0° on cclk_in_sample
+ * 2.Send the Tuning command to the card
+ * 3.increase the phase shift value of cclk_in_sample until the
+ *   correct sampling point is received such that the host does not
+ *   see any of the errors.
+ * 4.Mark this phase shift value as the starting point of the sampling
+ *   window.
+ * 5.increase the phase shift value of cclk_in_sample until the host
+ *   sees the errors starting to come again or the phase shift value
+ *   reaches 360°.
+ * 6.Mark the last successful phase shift value as the ending
+ *   point of the sampling window.
+ *
+ *     A window is established where the tuning block is matched.
+ * For example, for a scenario where the tuning block is received
+ * correctly for a phase shift window of 90°and 180°, then an appropriate
+ * sampling point is established as 135°. Once a sampling point is
+ * established, no errors should be visible in the tuning block.
+ *
+ */
+static int himci_execute_tuning(struct mmc_host *mmc, u32 opcode)
+{
+	struct himci_host *host;
+	unsigned int index, count;
+	unsigned int err = 0;
+	unsigned int found = 0; /* identify if we have found a valid phase */
+	unsigned int start_point;
+	unsigned int end_point;
+	unsigned int prev_err = NOT_FOUND;
+	unsigned int raise_point = NOT_FOUND;
+	unsigned int fall_point = NOT_FOUND;
+	int phase, ret;
+
+
+	start_point = TUNING_START_PHASE;
+	end_point = TUNING_END_PHASE;
+
+	host = mmc_priv(mmc);
+
+	himci_writel(0x1, host->base + MCI_CARDTHRCTL);
+
+	himci_trace(3, "start sd3.0 phase tuning...");
+	host->is_tuning = 1;
+	for (index = start_point; index <= end_point; index++) {
+		/* set sample clk phase shift */
+		himci_set_sap_phase(host, index);
+
+		count = 0;
+		do {
+			ret = mmc_send_tuning(mmc, opcode, NULL);
+			himci_send_stop(mmc); /* send soft_stop tail */
+
+			if (ret) {
+				himci_trace(3, "send tuning CMD%u fail! phase:%d err:%d\n",
+						opcode, index, ret);
+				err = 1;
+				break;
+			}
+			count++;
+		} while (count < 1);
+
+		if (!err)
+			found = 1;	/* found a valid phase */
+
+		if (index > start_point) {
+			if (err && !prev_err)
+				fall_point = index - 1;
+
+			if (!err && prev_err)
+				raise_point = index;
+		}
+
+		if ((raise_point != NOT_FOUND) && (fall_point != NOT_FOUND))
+			goto tuning_out;
+
+		prev_err = err;
+		err = 0;
+	}
+
+tuning_out:
+	host->is_tuning = 0;
+	if (!found) {
+		himci_trace(5, "%s: no valid phase shift! use default",
+				mmc_hostname(mmc));
+		himci_writel(DEFAULT_PHASE, host->base + MCI_UHS_REG_EXT);
+	} else {
+		himci_trace(3, "Tuning finished!!");
+
+		if (NOT_FOUND == raise_point)
+			raise_point = start_point;
+		if (NOT_FOUND == fall_point)
+			fall_point = end_point;
+
+		if (fall_point < raise_point) {
+			phase = (raise_point + fall_point) / 2;
+			phase = phase - (HIMCI_PHASE_SCALE / 2);
+			phase = (phase < 0) ? (HIMCI_PHASE_SCALE + phase) : phase;
+		} else
+			phase = (raise_point + fall_point) / 2;
+
+		himci_set_sap_phase(host, phase);
+
+		pr_info("tuning %s: valid phase shift [%d, %d] Final Phase %d\n",
+			mmc_hostname(mmc), raise_point, fall_point, phase);
+	}
+
+	himci_writel(RW_THRESHOLD_SIZE, host->base + MCI_CARDTHRCTL);
+
+	return 0;
+}
+
+static void himci_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct himci_host *host = mmc_priv(mmc);
+	unsigned int tmp_reg;
+	u32 ctrl;
+
+	himci_trace(2, "begin");
+	himci_assert(mmc);
+	himci_assert(ios);
+	himci_assert(host);
+
+	himci_trace(3, "ios->power_mode = %d ", ios->power_mode);
+	switch (ios->power_mode) {
+	case MMC_POWER_OFF:
+		/*
+		 * Set controller working voltage as 3.3V before power off.
+		 */
+		ctrl = himci_readl(host->base + MCI_UHS_REG);
+		ctrl &= ~HI_SDXC_CTRL_VDD_180;
+		himci_writel(ctrl, host->base + MCI_UHS_REG);
+
+		himci_ctrl_power(host, POWER_OFF);
+		break;
+	case MMC_POWER_UP:
+	case MMC_POWER_ON:
+		himci_ctrl_power(host, POWER_ON);
+		break;
+	}
+	himci_trace(3, "ios->clock = %d ", ios->clock);
+	if (ios->clock) {
+		himci_control_cclk(host, DISABLE);
+		himci_set_cclk(host, ios->clock);
+		himci_control_cclk(host, ENABLE);
+
+		/* speed mode check, if it is DDR50 set DDR mode */
+		if (ios->timing == MMC_TIMING_UHS_DDR50) {
+			ctrl = himci_readl(host->base + MCI_UHS_REG);
+			if (!(HI_SDXC_CTRL_DDR_REG & ctrl)) {
+				ctrl |= HI_SDXC_CTRL_DDR_REG;
+				himci_writel(ctrl, host->base + MCI_UHS_REG);
+			}
+		}
+	} else {
+		himci_control_cclk(host, DISABLE);
+		if (ios->timing != MMC_TIMING_UHS_DDR50) {
+			ctrl = himci_readl(host->base + MCI_UHS_REG);
+			if (HI_SDXC_CTRL_DDR_REG & ctrl) {
+				ctrl &= ~HI_SDXC_CTRL_DDR_REG;
+				himci_writel(ctrl, host->base + MCI_UHS_REG);
+			}
+		}
+	}
+
+	/* set bus_width */
+	himci_trace(3, "ios->bus_width = %d ", ios->bus_width);
+	if (ios->bus_width == MMC_BUS_WIDTH_4) {
+		tmp_reg = himci_readl(host->base + MCI_CTYPE);
+		tmp_reg |= CARD_WIDTH;
+		himci_writel(tmp_reg, host->base + MCI_CTYPE);
+	} else {
+		tmp_reg = himci_readl(host->base + MCI_CTYPE);
+		tmp_reg &= ~CARD_WIDTH;
+		himci_writel(tmp_reg, host->base + MCI_CTYPE);
+	}
+}
+
+static void himci_enable_sdio_irq(struct mmc_host *mmc, int enable)
+{
+	struct himci_host *host = mmc_priv(mmc);
+	unsigned int reg_value;
+
+	reg_value = himci_readl(host->base + MCI_INTMASK);
+	if (enable)
+		reg_value |= SDIO_INT_MASK;
+	else
+		reg_value &= ~SDIO_INT_MASK;
+	himci_writel(reg_value, host->base + MCI_INTMASK);
+}
+
+static int himci_get_card_detect(struct mmc_host *mmc)
+{
+	unsigned ret;
+	struct himci_host *host = mmc_priv(mmc);
+
+	himci_trace(2, "begin");
+	ret = himci_sys_card_detect(host);
+
+	if (ret)
+		return 0;
+	else
+		return 1;
+}
+
+static int himci_get_ro(struct mmc_host *mmc)
+{
+	unsigned ret;
+	struct himci_host *host = mmc_priv(mmc);
+
+	himci_trace(2, "begin");
+	himci_assert(mmc);
+
+	ret = himci_ctrl_card_readonly(host);
+
+	return ret;
+}
+
+static const struct mmc_host_ops himci_ops = {
+	.request = himci_request,
+	.set_ios = himci_set_ios,
+	.get_ro = himci_get_ro,
+	.start_signal_voltage_switch = himci_start_signal_voltage_switch,
+	.execute_tuning	= himci_execute_tuning,
+	.enable_sdio_irq = himci_enable_sdio_irq,
+	.get_cd = himci_get_card_detect,
+};
+
+static irqreturn_t hisd_irq(int irq, void *dev_id)
+{
+	struct himci_host *host = dev_id;
+	u32 state = 0;
+	int handle = 0;
+	u32 mstate = 0;
+
+	spin_lock(&host->lock);
+	state = himci_readl(host->base + MCI_RINTSTS);
+	spin_unlock(&host->lock);
+
+	/* bugfix: when send soft stop to SD Card, Host will report
+	   sdio interrupt, This situation needs to be avoided */
+	if (host->mmc->caps & MMC_CAP_SDIO_IRQ) {
+		if ((host->mmc->card != NULL)
+				&& (host->mmc->card->type == MMC_TYPE_SDIO)) {
+			mstate = himci_readl(host->base + MCI_INTMASK);
+			if ((state & SDIO_INT_STATUS) &&
+					(mstate & SDIO_INT_MASK)) {
+				spin_lock(&host->lock);
+				himci_writel(SDIO_INT_STATUS,
+						host->base + MCI_RINTSTS);
+				spin_unlock(&host->lock);
+				handle = 1;
+				mmc_signal_sdio_irq(host->mmc);
+			}
+		}
+	}
+
+	if (state & DATA_INT_MASK) {
+		handle = 1;
+		host->pending_events |= HIMCI_PEND_DTO_M;
+
+		spin_lock(&host->lock);
+		host->irq_status = himci_readl(host->base + MCI_RINTSTS);
+		himci_writel(DATA_INT_MASK , host->base + MCI_RINTSTS);
+		spin_unlock(&host->lock);
+
+		wake_up(&host->intr_wait);
+	}
+
+	if (handle)
+		return IRQ_HANDLED;
+
+	return IRQ_NONE;
+}
+
+static int himci_of_parse(struct device_node *np, struct mmc_host *mmc)
+{
+	struct himci_host *host = mmc_priv(mmc);
+	int ret = mmc_of_parse(mmc);
+	int len;
+
+	if (ret)
+		return ret;
+
+	if (of_property_read_u32(np, "min-frequency", &mmc->caps))
+		mmc->f_min = MMC_CCLK_MIN;
+
+	of_property_read_u32(np, "devid", &host->devid);
+
+	if (of_find_property(np, "cap-mmc-hw-reset", &len))
+		mmc->caps |= MMC_CAP_HW_RESET;
+
+	return 0;
+}
+
+static int __init himci_probe(struct platform_device *pdev)
+{
+	struct mmc_host *mmc;
+	struct himci_host *host = NULL;
+	struct resource *host_ioaddr_res = NULL;
+	int ret = 0, irq;
+	struct device_node *np = pdev->dev.of_node;
+
+	himci_trace(2, "begin");
+	pr_info("mmc host probe\n");
+	himci_assert(pdev);
+
+	mmc = mmc_alloc_host(sizeof(struct himci_host), &pdev->dev);
+	if (!mmc) {
+		himci_error("no mem for hi mci host controller!\n");
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	platform_set_drvdata(pdev, mmc);
+
+	mmc->ops = &himci_ops;
+
+	host_ioaddr_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (NULL == host_ioaddr_res) {
+		himci_error("no ioaddr rescources config!\n");
+		ret = -ENODEV;
+		goto out;
+	}
+
+	if (himci_of_parse(np, mmc)) {
+		himci_error("failed to parse mmc dts!\n");
+		ret = -EINVAL;
+		goto out;
+	}
+
+	/* reload by this controller */
+	mmc->max_blk_count = 2048;
+	mmc->max_segs = 1024;
+	mmc->max_seg_size = mmc->max_blk_size * mmc->max_blk_count;
+	mmc->max_req_size = mmc->max_blk_size * mmc->max_blk_count;
+	mmc->ocr_avail = MMC_VDD_32_33 | MMC_VDD_33_34;
+
+	host = mmc_priv(mmc);
+	mci_host[slot_index++] = host;
+	pdev->id = host->devid;
+	host->pdev = pdev;
+	host->mmc = mmc;
+	host->dma_vaddr = dma_alloc_coherent(&pdev->dev, CMD_DES_PAGE_SIZE,
+			&host->dma_paddr, GFP_KERNEL);
+	if (!host->dma_vaddr) {
+		himci_error("no mem for himci dma!\n");
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	host->base = devm_ioremap_resource(&pdev->dev, host_ioaddr_res);
+	if (IS_ERR_OR_NULL(host->base)) {
+		himci_error("no mem for himci base!\n");
+		ret = -ENOMEM;
+		goto out;
+	}
+
+	spin_lock_init(&host->lock);
+
+	host->crg_rst = devm_reset_control_get(&pdev->dev, "mmc_reset");
+	if (IS_ERR_OR_NULL(host->crg_rst)) {
+		himci_error("get rst fail.\n");
+		ret = PTR_ERR(host->crg_rst);
+		goto out;
+	}
+
+	reset_control_assert(host->crg_rst);
+	usleep_range(50, 60);
+	reset_control_deassert(host->crg_rst);
+
+	host->clk = devm_clk_get(&pdev->dev, "mmc_clk");
+	if (IS_ERR_OR_NULL(host->clk)) {
+		himci_error("get clock fail.\n");
+		ret = PTR_ERR(host->clk);
+		goto out;
+	}
+
+	clk_prepare_enable(host->clk);
+
+	host->power_status = POWER_OFF;
+
+	/* enable card */
+	himci_init_host(host);
+	host->card_status = himci_sys_card_detect(host);
+
+	init_timer(&host->timer);
+	host->timer.function = himci_detect_card;
+	host->timer.data = (unsigned long)host;
+	host->timer.expires = jiffies + detect_time;
+	add_timer(&host->timer);
+
+	init_waitqueue_head(&host->intr_wait);
+	irq = platform_get_irq(pdev, 0);
+	if (irq < 0) {
+		pr_err("no IRQ defined!\n");
+		goto out;
+	}
+
+	host->irq = irq;
+	ret = request_irq(irq, hisd_irq, 0, DRIVER_NAME, host);
+	if (ret) {
+		pr_err("request_irq error!\n");
+		goto out;
+	}
+
+	mmc_add_host(mmc);
+	return 0;
+out:
+	if (host) {
+		del_timer(&host->timer);
+
+		if (host->base)
+			devm_iounmap(&pdev->dev, host->base);
+
+		if (host->dma_vaddr)
+			dma_free_coherent(&pdev->dev, CMD_DES_PAGE_SIZE,
+					host->dma_vaddr, host->dma_paddr);
+	}
+	if (mmc)
+		mmc_free_host(mmc);
+
+	return ret;
+}
+
+static int __exit himci_remove(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+
+	himci_trace(2, "begin");
+	himci_assert(pdev);
+
+	platform_set_drvdata(pdev, NULL);
+
+	if (mmc) {
+		struct himci_host *host = mmc_priv(mmc);
+
+		mmc_remove_host(mmc);
+		free_irq(host->irq, host);
+		del_timer_sync(&host->timer);
+		himci_ctrl_power(host, POWER_OFF);
+		himci_control_cclk(host, DISABLE);
+		devm_iounmap(&pdev->dev, host->base);
+		dma_free_coherent(&pdev->dev, CMD_DES_PAGE_SIZE, host->dma_vaddr,
+				  host->dma_paddr);
+		mmc_free_host(mmc);
+	}
+	return 0;
+}
+
+static void himci_shutdown(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+
+	himci_trace(3, "shutdown");
+	if (mmc) {
+		unsigned int val;
+		struct himci_host *host = mmc_priv(mmc);
+
+		/* bugfix: host reset can trigger error intr */
+		himci_writel(0, host->base + MCI_IDINTEN);
+		himci_writel(0, host->base + MCI_INTMASK);
+
+		val = himci_readl(host->base + MCI_CTRL);
+		val |= CTRL_RESET | FIFO_RESET | DMA_RESET;
+		himci_writel(val, host->base + MCI_CTRL);
+	}
+}
+
+#ifdef CONFIG_PM
+static int himci_pltm_suspend(struct platform_device *pdev,
+		pm_message_t state)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct himci_host *host;
+	int ret = 0;
+
+	if (mmc) {
+		host = mmc_priv(mmc);
+		del_timer_sync(&host->timer);
+
+		if (__clk_is_enabled(host->clk))
+			clk_disable_unprepare(host->clk);
+	}
+
+	return ret;
+}
+
+static int himci_pltm_resume(struct platform_device *pdev)
+{
+	struct mmc_host *mmc = platform_get_drvdata(pdev);
+	struct himci_host *host;
+	int ret = 0;
+
+	if (mmc) {
+		host = mmc_priv(mmc);
+
+		if (!__clk_is_enabled(host->clk))
+			clk_prepare_enable(host->clk);
+
+		himci_init_host(host);
+
+		add_timer(&host->timer);
+	}
+
+	return ret;
+}
+#else
+#define himci_pltm_suspend    NULL
+#define himci_pltm_resume     NULL
+#endif
+
+void himci_mmc_rescan(int slot)
+{
+	struct mmc_host *mmc;
+	struct himci_host *host;
+
+	host = mci_host[slot];
+	if (!host || !host->mmc) {
+		himci_trace(5, "mmc%d: invalid slot!\n", slot);
+		return;
+	}
+
+	mmc = host->mmc;
+	del_timer_sync(&host->timer);
+
+	mmc_remove_host(mmc);
+
+	mmc_add_host(mmc);
+
+	add_timer(&host->timer);
+}
+EXPORT_SYMBOL(himci_mmc_rescan);
+
+static const struct of_device_id
+himci_match[] __maybe_unused = {
+	{.compatible = "hisilicon,hi3516a-himci"},
+	{},
+};
+
+static struct platform_driver himci_driver = {
+	.probe = himci_probe,
+	.remove = himci_remove,
+	.shutdown = himci_shutdown,
+	.suspend = himci_pltm_suspend,
+	.resume = himci_pltm_resume,
+	.driver = {
+		   .name = DRIVER_NAME,
+		   .owner = THIS_MODULE,
+		   .of_match_table = of_match_ptr(himci_match),
+		   },
+};
+
+static int __init himci_init(void)
+{
+	int ret;
+
+	himci_trace(2, "begin");
+
+	/*
+	 * We should register SDIO1 first to make sure that
+	 * the eMMC device,which connected to SDIO1 is mmcblk0.
+	 */
+
+	ret = platform_driver_register(&himci_driver);
+	if (ret) {
+		platform_driver_unregister(&himci_driver);
+		himci_error("Himci driver register failed!");
+		return ret;
+	}
+
+	/* device proc entry */
+	ret = mci_proc_init(HIMCI_SLOT_NUM);
+	if (ret)
+		himci_error("device proc init is failed!");
+
+	return ret;
+}
+
+static void __exit himci_exit(void)
+{
+	himci_trace(2, "begin");
+
+	mci_proc_shutdown();
+
+	platform_driver_unregister(&himci_driver);
+}
+
+module_init(himci_init);
+module_exit(himci_exit);
+
+#ifdef MODULE
+MODULE_AUTHOR("Hisilicon Drive Group");
+MODULE_DESCRIPTION("MMC/SD driver for the Hisilicon MMC/SD Host Controller");
+MODULE_LICENSE("GPL");
+#endif
diff --git a/drivers/mmc/host/himci/himci.h b/drivers/mmc/host/himci/himci.h
new file mode 100644
index 0000000..5c00ada
--- /dev/null
+++ b/drivers/mmc/host/himci/himci.h
@@ -0,0 +1,138 @@
+#ifndef _HI_MCI_H_
+#define _HI_MCI_H_
+
+#include <linux/mmc/mmc.h>
+
+extern int trace_level;
+#define HIMCI_TRACE_LEVEL 5
+/*
+   0 - all message
+   1 - dump all register read/write
+   2 - flow trace
+   3 - timeout err and protocol err
+   */
+
+#define HIMCI_TRACE_FMT KERN_INFO
+
+#define NOT_FOUND       -1
+#define POWER_ON	1
+#define POWER_OFF	0
+
+#define CARD_UNPLUGED	1
+#define CARD_PLUGED	0
+
+#define ENABLE		1
+#define DISABLE		0
+
+#define HI_MCI_DETECT_TIMEOUT	(HZ/2)
+
+#define HI_MCI_REQUEST_TIMEOUT	(5 * HZ)
+
+#define MAX_RETRY_COUNT   100
+
+#define MMC_CCLK_MIN      100000
+
+/* Base address of SD card register */
+#define HI_MCI_INTR               (48+32)
+
+#define himci_trace(level, msg...) do { \
+	if ((level) >= trace_level) { \
+		printk(HIMCI_TRACE_FMT "%s:%d: ", __func__, __LINE__); \
+		printk(msg); \
+		printk("\n"); \
+	} \
+} while (0)
+
+#define himci_assert(cond) do { \
+	if (!(cond)) {\
+		printk(KERN_ERR "Assert:himci:%s:%d\n", \
+				__func__, \
+				__LINE__); \
+		BUG(); \
+	} \
+} while (0)
+
+#define himci_error(s...) do { \
+	printk(KERN_ERR "himci:%s:%d: ", __func__, __LINE__); \
+	printk(s); \
+	printk("\n"); \
+} while (0)
+
+#define himci_readl(addr) ({unsigned int reg = readl(IOMEM(addr)); \
+	himci_trace(1, "readl(0x%04X) = 0x%08X", (unsigned int)addr, reg); \
+	reg; })
+
+#define himci_writel(v, addr) do { writel(v, IOMEM(addr)); \
+	himci_trace(1, "writel(0x%04X) = 0x%08X", (unsigned int)addr, \
+			(unsigned int)(v)); \
+} while (0)
+
+struct himci_des {
+	unsigned long idmac_des_ctrl;
+	unsigned long idmac_des_buf_size;
+	unsigned long idmac_des_buf_addr;
+	unsigned long idmac_des_next_addr;
+};
+
+struct himci_host {
+	struct mmc_host    *mmc;
+	struct platform_device *pdev;
+	spinlock_t		lock;
+	struct mmc_request	*mrq;
+	struct mmc_command	*cmd;
+	struct mmc_data		*data;
+	void __iomem		*base;
+	struct scatterlist	*dma_sg;
+	unsigned int		dma_sg_num;
+	unsigned int		dma_dir;
+	dma_addr_t		dma_paddr;
+	unsigned int		*dma_vaddr;
+	struct timer_list	timer;
+	unsigned int		irq;
+	unsigned int		irq_status;
+	unsigned int		is_tuning;
+	wait_queue_head_t  intr_wait;
+#define HIMCI_PEND_DTO_B  (0)
+#define HIMCI_PEND_DTO_M  (1 << HIMCI_PEND_DTO_B)
+	unsigned long      pending_events;
+	unsigned int       power_status;
+	unsigned int	card_status;
+	unsigned int	devid;
+	unsigned int	   hclk;
+	unsigned int	   cclk;
+	struct clk	*clk;
+	struct reset_control *crg_rst;
+};
+
+union cmd_arg_u {
+	unsigned int cmd_arg;
+	struct cmd_bits_arg {
+		unsigned int cmd_index:6;
+		unsigned int response_expect:1;
+		unsigned int response_length:1;
+		unsigned int check_response_crc:1;
+		unsigned int data_transfer_expected:1;
+		unsigned int read_write:1;
+		unsigned int transfer_mode:1;
+		unsigned int send_auto_stop:1;
+		unsigned int wait_prvdata_complete:1;
+		unsigned int stop_abort_cmd:1;
+		unsigned int send_initialization:1;
+		unsigned int card_number:5;
+		unsigned int update_clk_reg_only:1; /* bit 21 */
+		unsigned int read_ceata_device:1;
+		unsigned int ccs_expected:1;
+		unsigned int enable_boot:1;
+		unsigned int expect_boot_ack:1;
+		unsigned int disable_boot:1;
+		unsigned int boot_mode:1;
+		unsigned int volt_switch:1;
+		unsigned int use_hold_reg:1;
+		unsigned int reserved:1;
+		unsigned int start_cmd:1; /* HSB */
+	} bits;
+};
+
+struct mmc_host *get_mmchost(int hostid);
+#endif
+
diff --git a/drivers/mmc/host/himci/himci_hi3516a.c b/drivers/mmc/host/himci/himci_hi3516a.c
new file mode 100644
index 0000000..b452094
--- /dev/null
+++ b/drivers/mmc/host/himci/himci_hi3516a.c
@@ -0,0 +1,95 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#define MMC_CRG_MIN			25000000
+
+#define TUNING_START_PHASE	0
+#define TUNING_END_PHASE	7
+#define HIMCI_PHASE_SCALE	8
+#define DRV_PHASE_DFLT		(0x2<<23)
+#define SMPL_PHASE_DFLT		(0x3<<16)
+
+#define REG_PAD_CTRL			0x200f0800
+
+#define REG_CTRL_SDIO0_CLK		0xcc
+#define REG_CTRL_SDIO0_CMD		0xdc
+#define REG_CTRL_SDIO0_DATA0	0xe0
+#define REG_CTRL_SDIO0_DATA1	0xe4
+#define REG_CTRL_SDIO0_DATA2	0xe8
+#define REG_CTRL_SDIO0_DATA3	0xec
+
+#define REG_CTRL_SDIO1_CLK		0x104
+#define REG_CTRL_SDIO1_CMD		0x114
+#define REG_CTRL_SDIO1_DATA0	0x118
+#define REG_CTRL_SDIO1_DATA1	0x11c
+#define REG_CTRL_SDIO1_DATA2	0x120
+#define REG_CTRL_SDIO1_DATA3	0x124
+
+#define SDIO_CLK_DS_3V3			0x60
+#define SDIO_CMD_DS_3V3			0xe0
+#define SDIO_DATA0_DS_3V3		0xe0
+#define SDIO_DATA1_DS_3V3		0xe0
+#define SDIO_DATA2_DS_3V3		0xe0
+#define SDIO_DATA3_DS_3V3		0xe0
+
+#define SDIO_CLK_DS_1V8			0x40
+#define SDIO_CMD_DS_1V8			0xd0
+#define SDIO_DATA0_DS_1V8		0xd0
+#define SDIO_DATA1_DS_1V8		0xd0
+#define SDIO_DATA2_DS_1V8		0xd0
+#define SDIO_DATA3_DS_1V8		0xd0
+
+struct sdio_drv_cap {
+	unsigned int reg_addr;
+	unsigned int ds_3v3;
+	unsigned int ds_1v8;
+};
+
+#define SDIO_DRV_CAP(ofst, v1, v2) { \
+	.reg_addr = ofst, \
+	.ds_3v3 = v1, \
+	.ds_1v8 = v2}
+static  struct sdio_drv_cap sdio_ds[] = {
+	SDIO_DRV_CAP(REG_CTRL_SDIO0_CLK, SDIO_CLK_DS_3V3, SDIO_CLK_DS_1V8),
+	SDIO_DRV_CAP(REG_CTRL_SDIO0_CMD, SDIO_CMD_DS_3V3, SDIO_CMD_DS_1V8),
+	SDIO_DRV_CAP(REG_CTRL_SDIO0_DATA0, SDIO_DATA0_DS_3V3, SDIO_DATA0_DS_1V8),
+	SDIO_DRV_CAP(REG_CTRL_SDIO0_DATA1, SDIO_DATA1_DS_3V3, SDIO_DATA1_DS_1V8),
+	SDIO_DRV_CAP(REG_CTRL_SDIO0_DATA2, SDIO_DATA2_DS_3V3, SDIO_DATA2_DS_1V8),
+	SDIO_DRV_CAP(REG_CTRL_SDIO0_DATA3, SDIO_DATA3_DS_3V3, SDIO_DATA3_DS_1V8),
+	SDIO_DRV_CAP(REG_CTRL_SDIO1_CLK, SDIO_CLK_DS_3V3, SDIO_CLK_DS_1V8),
+	SDIO_DRV_CAP(REG_CTRL_SDIO1_CMD, SDIO_CMD_DS_3V3, SDIO_CMD_DS_1V8),
+	SDIO_DRV_CAP(REG_CTRL_SDIO1_DATA0, SDIO_DATA0_DS_3V3, SDIO_DATA0_DS_1V8),
+	SDIO_DRV_CAP(REG_CTRL_SDIO1_DATA1, SDIO_DATA1_DS_3V3, SDIO_DATA1_DS_1V8),
+	SDIO_DRV_CAP(REG_CTRL_SDIO1_DATA2, SDIO_DATA2_DS_3V3, SDIO_DATA2_DS_1V8),
+	SDIO_DRV_CAP(REG_CTRL_SDIO1_DATA3, SDIO_DATA3_DS_3V3, SDIO_DATA3_DS_1V8),
+};
+
+static void himci_set_drv_cap(struct himci_host *host, unsigned int vdd_180)
+{
+	unsigned int i, offset;
+
+	offset = host->devid * 6;
+	for (i = 0; i < 6; i++) {
+		if (vdd_180)
+			himci_writel(sdio_ds[i + offset].ds_1v8, 
+				IO_ADDRESS(REG_PAD_CTRL + sdio_ds[i + offset].reg_addr));
+		else
+			himci_writel(sdio_ds[i + offset].ds_3v3, 
+				IO_ADDRESS(REG_PAD_CTRL + sdio_ds[i + offset].reg_addr));
+	}
+}
diff --git a/drivers/mmc/host/himci/himci_proc.c b/drivers/mmc/host/himci/himci_proc.c
new file mode 100644
index 0000000..c60dd5b
--- /dev/null
+++ b/drivers/mmc/host/himci/himci_proc.c
@@ -0,0 +1,221 @@
+/*****************************************************************************
+ *  This is the driver for the host mci SOC.
+ *
+ *  Copyright (C) Hisilicon. All rights reserved.
+ *
+ ******************************************************************************/
+
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/device.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+
+#include <linux/mmc/card.h>
+
+#include <linux/export.h>
+#include <linux/mmc/host.h>
+#include "himci.h"
+#include "himci_reg.h"
+#include "himci_proc.h"
+
+#define MCI_PARENT       "mci"
+#define MCI_STATS_PROC   "mci_info"
+#define MAX_CLOCK_SCALE	(4)
+
+static struct proc_dir_entry *proc_mci_dir;
+static unsigned int mci_max_connections;
+static char *card_type[MAX_CARD_TYPE + 1] = {
+	"MMC card",
+	"SD card",
+	"SDIO card",
+	"SD combo (IO+mem) card",
+	"unknown"
+};
+static char *clock_unit[MAX_CLOCK_SCALE] = {
+	"Hz",
+	"KHz",
+	"MHz",
+	"GHz"
+};
+
+static char *mci_get_card_type(unsigned int sd_type)
+{
+	if (MAX_CARD_TYPE <= sd_type)
+		return card_type[MAX_CARD_TYPE];
+	else
+		return card_type[sd_type];
+}
+
+static unsigned int analyze_clock_scale(unsigned int clock,
+		unsigned int *clock_val)
+{
+	unsigned int scale = 0;
+	unsigned int tmp = clock;
+
+	while (1) {
+		tmp = tmp / 1000;
+		if (0 < tmp) {
+			*clock_val = tmp;
+			scale++;
+		} else {
+			break;
+		}
+	}
+	return scale;
+}
+
+static void mci_stats_seq_printout(struct seq_file *s)
+{
+	unsigned int index_mci;
+	unsigned int clock;
+	unsigned int clock_scale;
+	unsigned int clock_value = 0;
+	const char *type;
+	struct mmc_host *mmc;
+	struct himci_host *host;
+	struct mmc_card	*card;
+
+	for (index_mci = 0; index_mci < HIMCI_SLOT_NUM; index_mci++) {
+		host = mci_host[index_mci];
+		if (!host || !host->mmc) {
+			seq_printf(s, "MCI%d invalid\n", index_mci);
+			continue;
+		} else {
+			seq_printf(s, "MCI%d", index_mci);
+		}
+
+		mmc = host->mmc;
+		card = mmc->card;
+		if (NULL == card) {
+			seq_puts(s, " disconnected\n");
+		} else {
+			seq_puts(s, " connected\n");
+
+			seq_printf(s,
+					"\tType: %s",
+					mci_get_card_type(card->type)
+				  );
+
+			if (mmc_card_blockaddr(card)) {
+				if (mmc_card_ext_capacity(card))
+					type = "SDXC";
+				else
+					type = "SDHC";
+				seq_printf(s, "(%s)\n", type);
+			}
+
+			clock = host->hclk;
+			clock_scale = analyze_clock_scale(clock, &clock_value);
+			seq_printf(s, "\tHost work clock %d%s\n",
+					clock_value, clock_unit[clock_scale]);
+
+			clock = mmc->ios.clock;
+			clock_scale = analyze_clock_scale(clock, &clock_value);
+			seq_printf(s, "\tCard support clock %d%s\n",
+					clock_value, clock_unit[clock_scale]);
+
+			clock = host->cclk;
+			clock_scale = analyze_clock_scale(clock, &clock_value);
+			seq_printf(s, "\tCard work clock %d%s\n",
+					clock_value, clock_unit[clock_scale]);
+		}
+	}
+}
+
+/* proc interface setup */
+static void *mci_seq_start(struct seq_file *s, loff_t *pos)
+{
+	/*   counter is used to tracking multi proc interfaces
+	 *  We have only one interface so return zero
+	 *  pointer to start the sequence.
+	 */
+	static unsigned long counter;
+
+	if (*pos == 0)
+		return &counter;
+
+	*pos = 0;
+	return NULL;
+}
+
+/* proc interface next */
+static void *mci_seq_next(struct seq_file *s, void *v, loff_t *pos)
+{
+	(*pos)++;
+	if (*pos >= HIMCI_SLOT_NUM)
+		return NULL;
+
+	return NULL;
+}
+
+/* define parameters where showed in proc file */
+static int mci_stats_seq_show(struct seq_file *s, void *v)
+{
+	mci_stats_seq_printout(s);
+	return 0;
+}
+
+/* proc interface stop */
+static void mci_seq_stop(struct seq_file *s, void *v)
+{
+}
+
+/* proc interface operation */
+static const struct seq_operations mci_stats_seq_ops = {
+	.start = mci_seq_start,
+	.next = mci_seq_next,
+	.stop = mci_seq_stop,
+	.show = mci_stats_seq_show
+};
+
+/* proc file open*/
+static int mci_stats_proc_open(struct inode *inode, struct file *file)
+{
+	return seq_open(file, &mci_stats_seq_ops);
+};
+
+/* proc file operation */
+static const struct file_operations mci_stats_proc_ops = {
+	.owner = THIS_MODULE,
+	.open = mci_stats_proc_open,
+	.read = seq_read,
+	.release = seq_release
+};
+
+int mci_proc_init(unsigned int max_connections)
+{
+	struct proc_dir_entry *proc_stats_entry;
+
+	mci_max_connections = max_connections;
+
+	proc_mci_dir = proc_mkdir(MCI_PARENT, NULL);
+	if (!proc_mci_dir) {
+		pr_err("%s: failed to create proc file %s\n",
+				__func__, MCI_PARENT);
+		return 1;
+	}
+
+	proc_stats_entry = proc_create(MCI_STATS_PROC,
+			0, proc_mci_dir, &mci_stats_proc_ops);
+	if (!proc_stats_entry) {
+		pr_err("%s: failed to create proc file %s\n",
+				__func__, MCI_STATS_PROC);
+		return 1;
+	}
+
+	return 0;
+}
+
+int mci_proc_shutdown(void)
+{
+	if (proc_mci_dir) {
+		if (mci_max_connections > 0)
+			remove_proc_entry(MCI_STATS_PROC, proc_mci_dir);
+
+		remove_proc_entry(MCI_PARENT, NULL);
+		proc_mci_dir = NULL;
+	}
+
+	return 0;
+}
diff --git a/drivers/mmc/host/himci/himci_proc.h b/drivers/mmc/host/himci/himci_proc.h
new file mode 100644
index 0000000..23b4a22
--- /dev/null
+++ b/drivers/mmc/host/himci/himci_proc.h
@@ -0,0 +1,18 @@
+/*
+ *  MCI connection table manager
+ */
+#ifndef __MCI_PROC_H__
+#define __MCI_PROC_H__
+
+#include <linux/proc_fs.h>
+
+#define MAX_CARD_TYPE	4
+#define MAX_SPEED_MODE	5
+
+#define HIMCI_SLOT_NUM 2
+
+extern struct himci_host *mci_host[HIMCI_SLOT_NUM];
+int mci_proc_init(unsigned int max_connections);
+int mci_proc_shutdown(void);
+
+#endif /*  __MCI_PROC_H__ */
diff --git a/drivers/mmc/host/himci/himci_reg.h b/drivers/mmc/host/himci/himci_reg.h
new file mode 100644
index 0000000..3f156f48
--- /dev/null
+++ b/drivers/mmc/host/himci/himci_reg.h
@@ -0,0 +1,188 @@
+#ifndef _HI_MCI_REG_H_
+#define _HI_MCI_REG_H_
+
+#define HI_MCI_IO_SIZE		0x1000
+
+#define MCI_CTRL		0x00
+#define MCI_PWREN		0x04
+#define MCI_CLKDIV		0x08
+#define MCI_CLKSRC		0x0C
+#define MCI_CLKENA		0x10
+#define MCI_TIMEOUT		0x14
+#define MCI_CTYPE		0x18
+#define MCI_BLKSIZ		0x1c
+#define MCI_BYTCNT		0x20
+#define MCI_INTMASK		0x24
+#define MCI_CMDARG		0x28
+#define MCI_CMD			0x2C
+#define MCI_RESP0		0x30
+#define MCI_RESP1		0x34
+#define MCI_RESP2		0x38
+#define MCI_RESP3		0x3C
+#define MCI_MINTSTS		0x40
+#define MCI_RINTSTS		0x44
+#define MCI_STATUS		0x48
+#define MCI_FIFOTH		0x4C
+#define MCI_CDETECT		0x50
+#define MCI_WRTPRT		0x54
+#define MCI_GPIO		0x58
+#define MCI_TCBCNT		0x5C
+#define MCI_TBBCNT		0x60
+#define MCI_DEBNCE		0x64
+#define MCI_USRID		0x68
+#define MCI_VERID		0x6C
+#define MCI_HCON		0x70
+#define MCI_UHS_REG		0x74
+#define MCI_BMOD		0x80
+#define MCI_DBADDR		0x88
+#define MCI_IDSTS		0x8C
+#define MCI_IDINTEN		0x90
+#define MCI_DSCADDR		0x94
+#define MCI_BUFADDR		0x98
+#define MCI_CARDTHRCTL		0x100
+#define MCI_UHS_REG_EXT     0x108
+/* MCI_UHS_REG(0x74) details */
+#define HI_SDXC_CTRL_VDD_180	(0x1<<0)
+#define HI_SDXC_CTRL_DDR_REG	(0x1<<16)
+
+/* MCI_BMOD(0x80) details */
+#define BMOD_SWR		(0x1<<0)
+#define BURST_INCR		(0x1<<1)
+#define BMOD_DMA_EN		(0x1<<7)
+#define BURST_8			(0x2<<8)
+#define BURST_16		(0x3<<8)
+
+/* MCI_CTRL(0x00) details */
+#define CTRL_RESET             (1<<0)
+#define FIFO_RESET             (1<<1)
+#define DMA_RESET              (1<<2)
+#define INTR_EN                (1<<4)
+#define USE_INTERNAL_DMA       (1<<25)
+
+/* IDMAC DEST1 details */
+#define DMA_BUFFER		(0x2000)
+#define MAX_DMA_DES		(20480)
+
+/* IDMAC DEST0 details */
+#define DMA_DES_OWN		(1<<31)
+#define DMA_DES_NEXT_DES	(1<<4)
+#define DMA_DES_FIRST_DES	(1<<3)
+#define DMA_DES_LAST_DES	(1<<2)
+
+/* MCI_CDETECT(0x50) details */
+#define HIMCI_CARD0		(0x1<<0)
+
+/* MCI_TIMEOUT(0x14) details: */
+/*bit 31-8: data read timeout param*/
+#define DATA_TIMEOUT		(0xffffff<<8)
+
+/* bit 7-0: response timeout param */
+#define RESPONSE_TIMEOUT	0xff
+
+/* MCI_CLKENA(0x10) details */
+#define CCLK_ENABLE		(0x1<<0)	/* bit 0: enable of card clk*/
+
+
+
+/* MCI_CTYPE(0x18) details */
+#define CARD_WIDTH		(0x1<<0)
+
+/* MCI_CARDTHRCTL(0x100) details */
+#define RW_THRESHOLD_SIZE	(0x2000001)
+
+/* MCI_INTMASK(0x24) details:
+   bit 16-1: mask MMC host controller each interrupt
+*/
+#define ALL_INT_MASK		0x1ffff
+#define DTO_INT_MASK		(0x1<<3)
+#define SDIO_INT_MASK		(0x1<<16)
+
+/* MCI_UHS_REG_EXT(0x108) details */
+/* bit[19:16] sampling phase */
+#define CLK_SMPL_PHS_SHIFT	(16)
+#define CLK_SMPL_PHS_MASK	(0x7<<16)
+
+/* bit[26:23] drv phase */
+#define CLK_DRV_PHS_SHIFT	(23)
+#define CLK_DRV_PHS_MASK	(0x7<<23)
+#define DEFAULT_PHASE		0x1050000
+
+/* MCI_CMD(0x2c) details:
+   bit 31: cmd execute or load start param of interface clk bit
+*/
+#define START_CMD         (0x1<<31)
+
+/* MCI_INTSTS(0x44) details */
+/***************************************************************/
+/* bit 16: sdio interrupt status */
+#define SDIO_INT_STATUS    (0x1<<16)
+
+/* bit 15: end-bit error (read)/write no CRC interrupt status */
+#define EBE_INT_STATUS    (0x1<<15)
+
+/* bit 14: auto command done interrupt status */
+#define ACD_INT_STATUS    (0x1<<14)
+
+/* bit 13: start bit error interrupt status */
+#define SBE_INT_STATUS    (0x1<<13)
+
+/* bit 12: hardware locked write error interrupt status */
+#define HLE_INT_STATUS    (0x1<<12)
+
+/* bit 11: FIFO underrun/overrun error interrupt status */
+#define FRUN_INT_STATUS    (0x1<<11)
+
+/* bit 10: data starvation-by-host timeout interrupt status */
+#define HTO_INT_STATUS    (0x1<<10)
+
+/* bit 10: volt_switch to 1.8v for sdxc */
+#define VOLT_SWITCH_INT_STATUS    (0x1<<10)
+
+/* bit 9: data read timeout interrupt status */
+#define DRTO_INT_STATUS    (0x1<<9)
+
+/* bit 8: response timeout interrupt status */
+#define RTO_INT_STATUS    (0x1<<8)
+
+/* bit 7: data CRC error interrupt status */
+#define DCRC_INT_STATUS    (0x1<<7)
+
+/* bit 6: response CRC error interrupt status */
+#define RCRC_INT_STATUS    (0x1<<6)
+
+/* bit 5: receive FIFO data request interrupt status */
+#define RXDR_INT_STATUS    (0x1<<5)
+
+/* bit 4: transmit FIFO data request interrupt status */
+#define TXDR_INT_STATUS    (0x1<<4)
+
+/* bit 3: data transfer Over interrupt status */
+#define DTO_INT_STATUS    (0x1<<3)
+
+/* bit 2: command done interrupt status */
+#define CD_INT_STATUS    (0x1<<2)
+
+/* bit 1: response error interrupt status */
+#define RE_INT_STATUS    (0x1<<1)
+
+#define CMD_INT_MASK	(RTO_INT_STATUS | RCRC_INT_STATUS | RE_INT_STATUS)
+#define DATA_INT_MASK	(DTO_INT_STATUS | DCRC_INT_STATUS \
+		| SBE_INT_STATUS | EBE_INT_STATUS)
+/***************************************************************/
+
+/* MCI_RINTSTS(0x44) details:bit 16-1: clear
+   MMC host controller each interrupt but
+   hardware locked write error interrupt
+*/
+#define ALL_INT_CLR       0x1efff
+#define ALL_SD_INT_CLR    0xefff
+
+/* MCI_STATUS(0x48) details */
+#define DATA_BUSY		(0x1<<9)
+
+/* MCI_FIFOTH(0x4c) details */
+#define BURST_SIZE		(0x6<<28)
+#define RX_WMARK		(0x7f<<16)
+#define TX_WMARK          (0x80)
+
+#endif
diff --git a/drivers/mtd/Makefile b/drivers/mtd/Makefile
index 99bb9a1..f46b1cc 100644
--- a/drivers/mtd/Makefile
+++ b/drivers/mtd/Makefile
@@ -30,7 +30,7 @@ obj-$(CONFIG_MTD_SWAP)		+= mtdswap.o
 nftl-objs		:= nftlcore.o nftlmount.o
 inftl-objs		:= inftlcore.o inftlmount.o
 
+obj-$(CONFIG_MTD_SPI_NOR)	+= spi-nor/
 obj-y		+= chips/ lpddr/ maps/ devices/ nand/ onenand/ tests/
 
-obj-$(CONFIG_MTD_SPI_NOR)	+= spi-nor/
 obj-$(CONFIG_MTD_UBI)		+= ubi/
diff --git a/drivers/mtd/devices/Makefile b/drivers/mtd/devices/Makefile
index 7912d3a..9e7da47 100644
--- a/drivers/mtd/devices/Makefile
+++ b/drivers/mtd/devices/Makefile
@@ -18,5 +18,4 @@ obj-$(CONFIG_MTD_BCM47XXSFLASH)	+= bcm47xxsflash.o
 obj-$(CONFIG_MTD_ST_SPI_FSM)    += st_spi_fsm.o
 obj-$(CONFIG_MTD_POWERNV_FLASH)	+= powernv_flash.o
 
-
 CFLAGS_docg3.o			+= -I$(src)
diff --git a/drivers/mtd/nand/Kconfig b/drivers/mtd/nand/Kconfig
index b254090..5f4768c 100644
--- a/drivers/mtd/nand/Kconfig
+++ b/drivers/mtd/nand/Kconfig
@@ -569,4 +569,31 @@ config MTD_NAND_MTK
 	  Enables support for NAND controller on MTK SoCs.
 	  This controller is found on mt27xx, mt81xx, mt65xx SoCs.
 
+config MTD_SPI_NAND_HISI_BVT
+    tristate "Support for SPI NAND controller on Hisilicon SoCs"
+    depends on MTD_NAND
+    help
+      Enables support for the SPI NAND device drivers.
+
+config HISI_NAND_ECC_STATUS_REPORT
+	tristate "Report the ecc status to MTD for HiSilicon Nand Driver"
+	depends on MFD_HISI_FMC
+	default n
+	help
+	  Flash Memory Controller V100 reports the ecc status include ECC error
+	  and ECC corrected to MTD to monitor the aging of devices.
+
+config HISI_NAND_FS_MAY_NO_YAFFS2
+    bool "Remove the restraintion of 16bit ecc type on yaffs2 to HiSilicon"
+	depends on MFD_HISI_FMC
+    default n
+    help
+      The ecc type: 16bit is limited by the HiSilicon flash memory controller,
+      as the yaffs2 tag of hisi rootfs limits the min size of CTRL len is 28.
+
+source "drivers/mtd/nand/hifmc100/Kconfig"
+source "drivers/mtd/nand/hisnfc100/Kconfig"
+source "drivers/mtd/nand/hinfc610/Kconfig"
+source "drivers/mtd/nand/hifmc100_nand/Kconfig"
+
 endif # MTD_NAND
diff --git a/drivers/mtd/nand/Makefile b/drivers/mtd/nand/Makefile
index cafde6f..84f9a3f 100644
--- a/drivers/mtd/nand/Makefile
+++ b/drivers/mtd/nand/Makefile
@@ -8,6 +8,10 @@ obj-$(CONFIG_MTD_NAND_BCH)		+= nand_bch.o
 obj-$(CONFIG_MTD_NAND_IDS)		+= nand_ids.o
 obj-$(CONFIG_MTD_SM_COMMON) 		+= sm_common.o
 
+obj-$(CONFIG_MTD_NAND_HIFMC100)		+= hifmc100_nand/
+obj-$(CONFIG_MTD_SPI_NAND_HIFMC100)	+= hifmc100/
+obj-$(CONFIG_MTD_NAND_HISNFC100)	+= hisnfc100/
+obj-$(CONFIG_MTD_NAND_HINFC610)		+= hinfc610/
 obj-$(CONFIG_MTD_NAND_CAFE)		+= cafe_nand.o
 obj-$(CONFIG_MTD_NAND_AMS_DELTA)	+= ams-delta.o
 obj-$(CONFIG_MTD_NAND_DENALI)		+= denali.o
@@ -59,4 +63,4 @@ obj-$(CONFIG_MTD_NAND_BRCMNAND)		+= brcmnand/
 obj-$(CONFIG_MTD_NAND_QCOM)		+= qcom_nandc.o
 obj-$(CONFIG_MTD_NAND_MTK)		+= mtk_nand.o mtk_ecc.o
 
-nand-objs := nand_base.o nand_bbt.o nand_timings.o
+nand-objs := nand_base.o nand_bbt.o nand_timings.o hinfc_gen.o hinfc_spl_ids.o match_table.o
diff --git a/drivers/mtd/nand/hifmc100/Kconfig b/drivers/mtd/nand/hifmc100/Kconfig
new file mode 100644
index 0000000..5b15bc8
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100/Kconfig
@@ -0,0 +1,17 @@
+#
+# hisilicon flash memory controller SPI nand device driver version 100
+# drivers/mtd/nand/hifmc100/Kconfig
+# add by hisilicon 2017.8.7
+#
+
+config MTD_SPI_NAND_HIFMC100
+	bool "Hisilicon Flash Memory Controller v100 SPI Nand devices support"
+	depends on MFD_HISI_FMC && MTD_SPI_NAND_HISI_BVT
+	select MISC_FILESYSTEMS
+	select MTD_BLOCK
+	select YAFFS_FS
+	select YAFFS_YAFFS2
+	help
+	  Hisilicon Flash Memory Controller version 100 is called hifmc100 for
+	  short. The controller driver support registers and DMA transfers
+	  while reading or writing the SPI nand flash.
diff --git a/drivers/mtd/nand/hifmc100/Makefile b/drivers/mtd/nand/hifmc100/Makefile
new file mode 100644
index 0000000..b1fda5d
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100/Makefile
@@ -0,0 +1,26 @@
+#
+# The Flash Memory Controller v100 Device Driver for hisilicon
+#
+# Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.
+#
+# This program is free software; you can redistribute  it and/or modify it
+# under  the terms of  the GNU General  Public License as published by the
+# Free Software Foundation;  either version 2 of the  License, or (at your
+# option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+# GNU General Public License for more details.
+#
+# You should have received a copy of the GNU General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+#
+#
+
+#
+# drivers/mtd/nand/hifmc100/Makefile
+#
+
+obj-y	+= hifmc_spi_nand_ids.o
+obj-y	+= hifmc100.o hifmc100_os.o
diff --git a/drivers/mtd/nand/hifmc100/hifmc100.c b/drivers/mtd/nand/hifmc100/hifmc100.c
new file mode 100644
index 0000000..748088f
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100/hifmc100.c
@@ -0,0 +1,1167 @@
+/*
+ * The Flash Memory Controller v100 Device Driver for hisilicon
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/clk.h>
+#include <linux/io.h>
+#include <linux/errno.h>
+#include <linux/slab.h>
+#include <linux/mtd/nand.h>
+#include <linux/delay.h>
+#include <linux/sched.h>
+#include <asm/setup.h>
+
+#include "../hinfc_gen.h"
+#include "hifmc100_os.h"
+#include "hifmc100.h"
+#include <linux/mfd/hisi_fmc.h>
+
+/*****************************************************************************/
+static void hifmc100_switch_to_spi_nand(struct hifmc_host *host)
+{
+	int reg;
+
+	reg = hifmc_readl(host, FMC_CFG);
+	reg &= ~FLASH_TYPE_SEL_MASK;
+	reg |= FMC_CFG_FLASH_SEL(FLASH_TYPE_SPI_NAND);
+	hifmc_writel(host, FMC_CFG, reg);
+}
+
+/*****************************************************************************/
+static void hifmc100_operation_config(struct hifmc_host *host, int op)
+{
+	int ret, clkrate = 0;
+	struct hifmc_spi *spi = host->spi;
+
+	hifmc100_switch_to_spi_nand(host);
+	clk_prepare_enable(host->clk);
+	switch (op) {
+	case OP_STYPE_WRITE:
+		clkrate = min((u_long)host->clkrate,
+				 (u_long)CLK_FMC_TO_CRG_MHZ(spi->write->clock));
+		break;
+	case OP_STYPE_READ:
+		clkrate = min((u_long)host->clkrate,
+				 (u_long)CLK_FMC_TO_CRG_MHZ(spi->read->clock));
+		break;
+	case OP_STYPE_ERASE:
+		clkrate = min((u_long)host->clkrate,
+				 (u_long)CLK_FMC_TO_CRG_MHZ(spi->erase->clock));
+		break;
+	default:
+		break;
+	}
+
+	ret = clk_set_rate(host->clk, clkrate);
+	if (WARN_ON(ret))
+		pr_err("clk_set_rate failed: %d\n", ret);
+}
+
+/*****************************************************************************/
+static void hifmc100_send_cmd_write(struct hifmc_host *host)
+{
+	unsigned char pages_per_block_shift;
+	unsigned int reg, block_num, block_num_h, page_num;
+	struct hifmc_spi *spi = host->spi;
+	struct nand_chip *chip = host->chip;
+#ifdef HIFMC100_SPI_NAND_SUPPORT_REG_WRITE
+	const char *op = "Reg";
+#else
+	const char *op = "Dma";
+#endif
+
+	if (WR_DBG)
+		pr_info("\n");
+	FMC_PR(WR_DBG, "*-Start send %s page write command\n", op);
+
+	mutex_lock(host->lock);
+	hifmc100_operation_config(host, OP_STYPE_WRITE);
+
+	reg = spi->driver->wait_ready(spi);
+	if (reg) {
+		DB_MSG("Error: %s program wait ready failed! status: %#x\n",
+				op, reg);
+		goto end;
+	}
+
+	reg = spi->driver->write_enable(spi);
+	if (reg) {
+		DB_MSG("Error: %s program write enable failed! reg: %#x\n",
+				op, reg);
+		goto end;
+	}
+
+	reg = FMC_INT_CLR_ALL;
+	hifmc_writel(host, FMC_INT_CLR, reg);
+	FMC_PR(WR_DBG, "|-Set INT_CLR[%#x]%#x\n", FMC_INT_CLR, reg);
+
+	reg = OP_CFG_FM_CS(host->cmd_op.cs)
+		| OP_CFG_MEM_IF_TYPE(spi->write->iftype);
+	hifmc_writel(host, FMC_OP_CFG, reg);
+	FMC_PR(WR_DBG, "|-Set OP_CFG[%#x]%#x\n", FMC_OP_CFG, reg);
+
+	pages_per_block_shift = chip->phys_erase_shift - chip->page_shift;
+	block_num = host->addr_value[1] >> pages_per_block_shift;
+	block_num_h = block_num >> REG_CNT_HIGH_BLOCK_NUM_SHIFT;
+	reg = FMC_ADDRH_SET(block_num_h);
+	hifmc_writel(host, FMC_ADDRH, reg);
+	FMC_PR(WR_DBG, "|-Set ADDRH[%#x]%#x\n", FMC_ADDRH, reg);
+
+	page_num = host->addr_value[1] - (block_num << pages_per_block_shift);
+	reg = ((block_num & REG_CNT_BLOCK_NUM_MASK) << REG_CNT_BLOCK_NUM_SHIFT)
+	     | ((page_num & REG_CNT_PAGE_NUM_MASK) << REG_CNT_PAGE_NUM_SHIFT);
+	hifmc_writel(host, FMC_ADDRL, reg);
+	FMC_PR(WR_DBG, "|-Set ADDRL[%#x]%#x\n", FMC_ADDRL, reg);
+
+	*host->epm = 0x0000;
+
+#ifndef HIFMC100_SPI_NAND_SUPPORT_REG_WRITE
+	reg = host->dma_buffer;
+	hifmc_writel(host, FMC_DMA_SADDR_D0, reg);
+	FMC_PR(WR_DBG, "|-Set DMA_SADDR_D[0x40]%#x\n", reg);
+
+#ifdef CONFIG_64BIT
+	reg = (host->dma_buffer & FMC_DMA_SADDRH_MASK) >> 32;
+	hifmc_writel(host, FMC_DMA_SADDRH_D0, reg);
+	FMC_PR(WR_DBG, "\t|-Set DMA_SADDRH_D0[%#x]%#x\n", FMC_DMA_SADDRH_D0, reg);
+#endif
+
+	reg = host->dma_oob;
+	hifmc_writel(host, FMC_DMA_SADDR_OOB, reg);
+	FMC_PR(WR_DBG, "|-Set DMA_SADDR_OOB[%#x]%#x\n", FMC_DMA_SADDR_OOB, reg);
+#ifdef CONFIG_64BIT
+	reg = (host->dma_oob & FMC_DMA_SADDRH_MASK) >> 32;
+	hifmc_writel(host, FMC_DMA_SADDRH_OOB, reg);
+	FMC_PR(WR_DBG, "\t|-Set DMA_SADDRH_OOB[%#x]%#x\n", FMC_DMA_SADDRH_OOB,
+			reg);
+#endif
+#endif
+
+	reg = OP_CTRL_WR_OPCODE(spi->write->cmd)
+#ifdef HIFMC100_SPI_NAND_SUPPORT_REG_WRITE
+		| OP_CTRL_DMA_OP(OP_TYPE_REG)
+#else
+		| OP_CTRL_DMA_OP(OP_TYPE_DMA)
+#endif
+		| OP_CTRL_RW_OP(RW_OP_WRITE)
+		| OP_CTRL_DMA_OP_READY;
+	hifmc_writel(host, FMC_OP_CTRL, reg);
+	FMC_PR(WR_DBG, "|-Set OP_CTRL[%#x]%#x\n", FMC_OP_CTRL, reg);
+
+	FMC_DMA_WAIT_INT_FINISH(host);
+
+end:
+	mutex_unlock(host->lock);
+	FMC_PR(WR_DBG, "*-End %s page program!\n", op);
+}
+
+/*****************************************************************************/
+static void hifmc100_send_cmd_status(struct hifmc_host *host)
+{
+	unsigned char status, addr = STATUS_ADDR;
+	struct hifmc_spi *spi = host->spi;
+
+	if (host->cmd_op.l_cmd == NAND_CMD_GET_FEATURES)
+		addr = PROTECT_ADDR;
+
+	status = spi_nand_feature_op(spi, GET_OP, addr, 0);
+	FMC_PR((ER_DBG || WR_DBG), "\t*-Get status[%#x]: %#x\n", addr, status);
+}
+
+/*****************************************************************************/
+static void hifmc100_send_cmd_read(struct hifmc_host *host)
+{
+	unsigned char pages_per_block_shift, only_oob = 0;
+	unsigned short wrap = 0;
+	unsigned int reg, block_num, block_num_h, page_num, addr_of = 0;
+	struct hifmc_spi *spi = host->spi;
+	struct nand_chip *chip = host->chip;
+#ifdef HIFMC100_SPI_NAND_SUPPORT_REG_READ
+	char *op = "Reg";
+#else
+	char *op = "Dma";
+#endif
+
+	if (RD_DBG)
+		pr_info("\n");
+	FMC_PR(RD_DBG, "\t*-Start %s page read\n", op);
+
+	if ((host->addr_value[0] == host->cache_addr_value[0])
+		&& (host->addr_value[1] == host->cache_addr_value[1])) {
+		FMC_PR(RD_DBG, "\t*-%s read cache hit, addr[%#x %#x]\n",
+			op, host->addr_value[1], host->addr_value[0]);
+		return;
+	}
+
+	mutex_lock(host->lock);
+	hifmc100_operation_config(host, OP_STYPE_READ);
+
+	FMC_PR(RD_DBG, "\t|-Wait ready before %s page read\n", op);
+	reg = spi->driver->wait_ready(spi);
+	if (reg) {
+		DB_MSG("Error: %s read wait ready fail! reg: %#x\n", op, reg);
+		goto end;
+	}
+
+	reg = FMC_INT_CLR_ALL;
+	hifmc_writel(host, FMC_INT_CLR, reg);
+	FMC_PR(RD_DBG, "\t|-Set INT_CLR[%#x]%#x\n", FMC_INT_CLR, reg);
+
+	if (host->cmd_op.l_cmd == NAND_CMD_READOOB) {
+		only_oob = 1;
+		host->cmd_op.op_cfg = OP_CTRL_RD_OP_SEL(RD_OP_READ_OOB);
+	} else
+		host->cmd_op.op_cfg = OP_CTRL_RD_OP_SEL(RD_OP_READ_ALL_PAGE);
+
+	reg = OP_CFG_FM_CS(host->cmd_op.cs)
+		| OP_CFG_MEM_IF_TYPE(spi->read->iftype)
+		| OP_CFG_DUMMY_NUM(spi->read->dummy);
+	hifmc_writel(host, FMC_OP_CFG, reg);
+	FMC_PR(RD_DBG, "\t|-Set OP_CFG[%#x]%#x\n", FMC_OP_CFG, reg);
+
+	pages_per_block_shift = chip->phys_erase_shift - chip->page_shift;
+	block_num = host->addr_value[1] >> pages_per_block_shift;
+	block_num_h = block_num >> REG_CNT_HIGH_BLOCK_NUM_SHIFT;
+
+	reg = FMC_ADDRH_SET(block_num_h);
+	hifmc_writel(host, FMC_ADDRH, reg);
+	FMC_PR(RD_DBG, "\t|-Set ADDRH[%#x]%#x\n", FMC_ADDRH, reg);
+
+	page_num = host->addr_value[1] - (block_num << pages_per_block_shift);
+	if (only_oob)
+		switch (host->ecctype) {
+		case NAND_ECC_8BIT:
+			addr_of = REG_CNT_ECC_8BIT_OFFSET;
+			break;
+		case NAND_ECC_16BIT:
+			addr_of = REG_CNT_ECC_16BIT_OFFSET;
+			break;
+		case NAND_ECC_24BIT:
+			addr_of = REG_CNT_ECC_24BIT_OFFSET;
+			break;
+		case NAND_ECC_0BIT:
+		default:
+			break;
+		}
+
+	reg = ((block_num & REG_CNT_BLOCK_NUM_MASK) << REG_CNT_BLOCK_NUM_SHIFT)
+		| ((page_num & REG_CNT_PAGE_NUM_MASK) << REG_CNT_PAGE_NUM_SHIFT)
+		| ((wrap & REG_CNT_WRAP_MASK) << REG_CNT_WRAP_SHIFT)
+		| (addr_of & REG_CNT_ECC_OFFSET_MASK);
+	hifmc_writel(host, FMC_ADDRL, reg);
+	FMC_PR(RD_DBG, "\t|-Set ADDRL[%#x]%#x\n", FMC_ADDRL, reg);
+
+#ifndef HIFMC100_SPI_NAND_SUPPORT_REG_READ
+	reg = host->dma_buffer;
+	hifmc_writel(host, FMC_DMA_SADDR_D0, reg);
+	FMC_PR(RD_DBG, "\t|-Set DMA_SADDR_D0[%#x]%#x\n", FMC_DMA_SADDR_D0, reg);
+
+#ifdef CONFIG_64BIT
+	reg = (host->dma_buffer & FMC_DMA_SADDRH_MASK) >> 32;
+	hifmc_writel(host, FMC_DMA_SADDRH_D0, reg);
+	FMC_PR(RD_DBG, "\t|-Set DMA_SADDRH_D0[%#x]%#x\n", FMC_DMA_SADDRH_D0, reg);
+#endif
+
+	reg = host->dma_oob;
+	hifmc_writel(host, FMC_DMA_SADDR_OOB, reg);
+	FMC_PR(RD_DBG, "\t|-Set DMA_SADDR_OOB[%#x]%#x\n", FMC_DMA_SADDR_OOB,
+			reg);
+
+#ifdef CONFIG_64BIT
+	reg = (host->dma_oob & FMC_DMA_SADDRH_MASK) >> 32;
+	hifmc_writel(host, FMC_DMA_SADDRH_OOB, reg);
+	FMC_PR(RD_DBG, "\t|-Set DMA_SADDRH_OOB[%#x]%#x\n", FMC_DMA_SADDRH_OOB,
+			reg);
+#endif
+#endif
+
+	reg = OP_CTRL_RD_OPCODE(spi->read->cmd) | host->cmd_op.op_cfg
+#ifdef HIFMC100_SPI_NAND_SUPPORT_REG_READ
+		| OP_CTRL_DMA_OP(OP_TYPE_REG)
+#else
+		| OP_CTRL_DMA_OP(OP_TYPE_DMA)
+#endif
+		| OP_CTRL_RW_OP(RW_OP_READ) | OP_CTRL_DMA_OP_READY;
+	hifmc_writel(host, FMC_OP_CTRL, reg);
+	FMC_PR(RD_DBG, "\t|-Set OP_CTRL[%#x]%#x\n", FMC_OP_CTRL, reg);
+
+	FMC_DMA_WAIT_INT_FINISH(host);
+
+	host->cache_addr_value[0] = host->addr_value[0];
+	host->cache_addr_value[1] = host->addr_value[1];
+
+end:
+	mutex_unlock(host->lock);
+	FMC_PR(RD_DBG, "\t*-End %s page read\n", op);
+}
+
+/*****************************************************************************/
+static void hifmc100_send_cmd_erase(struct hifmc_host *host)
+{
+	unsigned int reg;
+	struct hifmc_spi *spi = host->spi;
+
+	if (ER_DBG)
+		pr_info("\n");
+	FMC_PR(ER_DBG, "\t*-Start send cmd erase!\n");
+
+	mutex_lock(host->lock);
+	hifmc100_operation_config(host, OP_STYPE_ERASE);
+
+	reg = spi->driver->wait_ready(spi);
+	FMC_PR(ER_DBG, "\t|-Erase wait ready, reg: %#x\n", reg);
+	if (reg) {
+		DB_MSG("Error: Erase wait ready fail! status: %#x\n", reg);
+		goto end;
+	}
+
+	reg = spi->driver->write_enable(spi);
+	if (reg) {
+		DB_MSG("Error: Erase write enable failed! reg: %#x\n", reg);
+		goto end;
+	}
+
+	reg = FMC_INT_CLR_ALL;
+	hifmc_writel(host, FMC_INT_CLR, reg);
+	FMC_PR(ER_DBG, "\t|-Set INT_CLR[%#x]%#x\n", FMC_INT_CLR, reg);
+
+	reg = spi->erase->cmd;
+	hifmc_writel(host, FMC_CMD, FMC_CMD_CMD1(reg));
+	FMC_PR(ER_DBG, "\t|-Set CMD[%#x]%#x\n", FMC_CMD, reg);
+
+	reg = FMC_ADDRL_BLOCK_H_MASK(host->addr_value[1])
+		| FMC_ADDRL_BLOCK_L_MASK(host->addr_value[0]);
+	hifmc_writel(host, FMC_ADDRL, reg);
+	FMC_PR(ER_DBG, "\t|-Set ADDRL[%#x]%#x\n", FMC_ADDRL, reg);
+
+	reg = OP_CFG_FM_CS(host->cmd_op.cs)
+		| OP_CFG_MEM_IF_TYPE(spi->erase->iftype)
+		| OP_CFG_ADDR_NUM(STD_OP_ADDR_NUM)
+		| OP_CFG_DUMMY_NUM(spi->erase->dummy);
+	hifmc_writel(host, FMC_OP_CFG, reg);
+	FMC_PR(ER_DBG, "\t|-Set OP_CFG[%#x]%#x\n", FMC_OP_CFG, reg);
+
+	reg = FMC_OP_CMD1_EN
+		| FMC_OP_ADDR_EN
+		| FMC_OP_REG_OP_START;
+	hifmc_writel(host, FMC_OP, reg);
+	FMC_PR(ER_DBG, "\t|-Set OP[%#x]%#x\n", FMC_OP, reg);
+
+	FMC_CMD_WAIT_CPU_FINISH(host);
+
+end:
+	mutex_unlock(host->lock);
+	FMC_PR(ER_DBG, "\t*-End send cmd erase!\n");
+}
+
+/*****************************************************************************/
+void hifmc100_ecc0_switch(struct hifmc_host *host, unsigned char op)
+{
+	unsigned int config;
+#if EC_DBG
+	unsigned int cmp_cfg;
+
+	config = hifmc_readl(host, FMC_CFG);
+	FMC_PR(EC_DBG, "\t *-Get CFG[%#x]%#x\n", FMC_CFG, config);
+
+	if (op)
+		cmp_cfg = host->fmc_cfg;
+	else
+		cmp_cfg = host->fmc_cfg_ecc0;
+
+	if (cmp_cfg != config)
+		DB_MSG("Warning: FMC config[%#x] is different.\n",
+				cmp_cfg);
+#endif
+
+	if (op == ENABLE)
+		config = host->fmc_cfg_ecc0;
+	else if (op == DISABLE)
+		config = host->fmc_cfg;
+	else {
+		DB_MSG("Error: Invalid opcode: %d\n", op);
+		return;
+	}
+
+	hifmc_writel(host, FMC_CFG, config);
+	FMC_PR(EC_DBG, "\t *-Set CFG[%#x]%#x\n", FMC_CFG, config);
+}
+
+/*****************************************************************************/
+static void hifmc100_send_cmd_readid(struct hifmc_host *host)
+{
+	unsigned int reg;
+
+	FMC_PR(BT_DBG, "\t|*-Start send cmd read ID\n");
+
+	hifmc100_ecc0_switch(host, ENABLE);
+
+	reg = FMC_CMD_CMD1(SPI_CMD_RDID);
+	hifmc_writel(host, FMC_CMD, reg);
+	FMC_PR(BT_DBG, "\t||-Set CMD[%#x]%#x\n", FMC_CMD, reg);
+
+	reg = READ_ID_ADDR;
+	hifmc_writel(host, FMC_ADDRL, reg);
+	FMC_PR(BT_DBG, "\t||-Set ADDRL[%#x]%#x\n", FMC_ADDRL, reg);
+
+	reg = OP_CFG_FM_CS(host->cmd_op.cs)
+		| OP_CFG_ADDR_NUM(READ_ID_ADDR_NUM);
+	hifmc_writel(host, FMC_OP_CFG, reg);
+	FMC_PR(BT_DBG, "\t||-Set OP_CFG[%#x]%#x\n", FMC_OP_CFG, reg);
+
+	reg = FMC_DATA_NUM_CNT(MAX_SPI_NAND_ID_LEN);
+	hifmc_writel(host, FMC_DATA_NUM, reg);
+	FMC_PR(BT_DBG, "\t||-Set DATA_NUM[%#x]%#x\n", FMC_DATA_NUM, reg);
+
+	reg = FMC_OP_CMD1_EN
+		| FMC_OP_ADDR_EN
+		| FMC_OP_READ_DATA_EN
+		| FMC_OP_REG_OP_START;
+	hifmc_writel(host, FMC_OP, reg);
+	FMC_PR(BT_DBG, "\t||-Set OP[%#x]%#x\n", FMC_OP, reg);
+
+	host->addr_cycle = 0x0;
+
+	FMC_CMD_WAIT_CPU_FINISH(host);
+
+	hifmc100_ecc0_switch(host, DISABLE);
+
+	FMC_PR(BT_DBG, "\t|*-End read flash ID\n");
+}
+
+/*****************************************************************************/
+static void hifmc100_send_cmd_reset(struct hifmc_host *host)
+{
+	unsigned int reg;
+
+	FMC_PR(BT_DBG, "\t|*-Start send cmd reset\n");
+
+	reg = FMC_CMD_CMD1(SPI_CMD_RESET);
+	hifmc_writel(host, FMC_CMD, reg);
+	FMC_PR(BT_DBG, "\t||-Set CMD[%#x]%#x\n", FMC_CMD, reg);
+
+	reg = OP_CFG_FM_CS(host->cmd_op.cs);
+	hifmc_writel(host, FMC_OP_CFG, reg);
+	FMC_PR(BT_DBG, "\t||-Set OP_CFG[%#x]%#x\n", FMC_OP_CFG, reg);
+
+	reg = FMC_OP_CMD1_EN | FMC_OP_REG_OP_START;
+	hifmc_writel(host, FMC_OP, reg);
+	FMC_PR(BT_DBG, "\t||-Set OP[%#x]%#x\n", FMC_OP, reg);
+
+	FMC_CMD_WAIT_CPU_FINISH(host);
+
+	FMC_PR(BT_DBG, "\t|*-End send cmd reset\n");
+}
+
+/*****************************************************************************/
+static void hifmc100_host_init(struct hifmc_host *host)
+{
+	unsigned int reg;
+
+	FMC_PR(BT_DBG, "\t||*-Start SPI Nand host init\n");
+
+	reg = hifmc_readl(host, FMC_CFG);
+	if ((reg & FMC_CFG_OP_MODE_MASK) == FMC_CFG_OP_MODE_BOOT) {
+		reg |= FMC_CFG_OP_MODE(FMC_CFG_OP_MODE_NORMAL);
+		hifmc_writel(host, FMC_CFG, reg);
+		FMC_PR(BT_DBG, "\t|||-Set CFG[%#x]%#x\n", FMC_CFG, reg);
+	}
+
+	host->fmc_cfg = reg;
+	host->fmc_cfg_ecc0 = (reg & ~ECC_TYPE_MASK) | ECC_TYPE_0BIT;
+
+	reg = hifmc_readl(host, FMC_GLOBAL_CFG);
+	if (reg & FMC_GLOBAL_CFG_WP_ENABLE) {
+		reg &= ~FMC_GLOBAL_CFG_WP_ENABLE;
+		hifmc_writel(host, FMC_GLOBAL_CFG, reg);
+	}
+
+	host->addr_cycle = 0;
+	host->addr_value[0] = 0;
+	host->addr_value[1] = 0;
+	host->cache_addr_value[0] = ~0;
+	host->cache_addr_value[1] = ~0;
+
+	host->send_cmd_write = hifmc100_send_cmd_write;
+	host->send_cmd_status = hifmc100_send_cmd_status;
+	host->send_cmd_read = hifmc100_send_cmd_read;
+	host->send_cmd_erase = hifmc100_send_cmd_erase;
+	host->send_cmd_readid = hifmc100_send_cmd_readid;
+	host->send_cmd_reset = hifmc100_send_cmd_reset;
+#ifdef CONFIG_PM
+	host->suspend = hifmc100_suspend;
+	host->resume  = hifmc100_resume;
+#endif
+
+	reg = TIMING_CFG_TCSH(CS_HOLD_TIME)
+		| TIMING_CFG_TCSS(CS_SETUP_TIME)
+		| TIMING_CFG_TSHSL(CS_DESELECT_TIME);
+	hifmc_writel(host, FMC_SPI_TIMING_CFG, reg);
+
+	reg = ALL_BURST_ENABLE;
+	hifmc_writel(host, FMC_DMA_AHB_CTRL, reg);
+
+	FMC_PR(BT_DBG, "\t||*-End SPI Nand host init\n");
+}
+
+/*****************************************************************************/
+static unsigned char hifmc100_read_byte(struct mtd_info *mtd)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+	unsigned char value, ret_val = 0;
+
+	if (host->cmd_op.l_cmd == NAND_CMD_READID) {
+		value = hifmc_readb(host->iobase + host->offset);
+		host->offset++;
+		if (host->cmd_op.data_no == host->offset)
+			host->cmd_op.l_cmd = 0;
+		return value;
+	}
+
+	if (host->cmd_op.cmd == NAND_CMD_STATUS) {
+		value = hifmc_readl(host, FMC_STATUS);
+		if (host->cmd_op.l_cmd == NAND_CMD_GET_FEATURES) {
+			FMC_PR((ER_DBG || WR_DBG), "\t\tRead BP status:%#x\n",
+					value);
+			if (ANY_BP_ENABLE(value))
+				ret_val |= NAND_STATUS_WP;
+
+			host->cmd_op.l_cmd = NAND_CMD_STATUS;
+		}
+
+		if (!(value & STATUS_OIP_MASK))
+			ret_val |= NAND_STATUS_READY;
+
+		if (value & STATUS_E_FAIL_MASK) {
+			FMC_PR(ER_DBG, "\t\tGet erase status: %#x\n", value);
+			ret_val |= NAND_STATUS_FAIL;
+		}
+
+		if (value & STATUS_P_FAIL_MASK) {
+			FMC_PR(WR_DBG, "\t\tGet write status: %#x\n", value);
+			ret_val |= NAND_STATUS_FAIL;
+		}
+
+		return ret_val;
+	}
+
+	if (host->cmd_op.l_cmd == NAND_CMD_READOOB) {
+		value  = hifmc_readb(host->buffer + host->pagesize + host->offset);
+		host->offset++;
+		return value;
+	}
+
+	host->offset++;
+
+	return hifmc_readb(host->buffer + host->column + host->offset - 1);
+}
+
+/*****************************************************************************/
+static unsigned short hifmc100_read_word(struct mtd_info *mtd)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+	host->offset += 2;
+	return hifmc_readw(host->buffer + host->column + host->offset - 2);
+}
+
+/*****************************************************************************/
+static void hifmc100_write_buf(struct mtd_info *mtd,
+	const u_char *buf, int len)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+#ifdef HIFMC100_SPI_NAND_SUPPORT_REG_WRITE
+	if (buf == chip->oob_poi)
+		memcpy((char *)host->iobase + host->pagesize, buf, len);
+	else
+		memcpy((char *)host->iobase, buf, len);
+#else
+	if (buf == chip->oob_poi)
+		memcpy((char *)(host->buffer + host->pagesize), buf, len);
+	else
+		memcpy((char *)host->buffer, buf, len);
+#endif
+	return;
+}
+
+/*****************************************************************************/
+static void hifmc100_read_buf(struct mtd_info *mtd, u_char *buf, int len)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+#ifdef HIFMC100_SPI_NAND_SUPPORT_REG_READ
+	if (buf == chip->oob_poi)
+		memcpy(buf, (char *)host->iobase + host->pagesize, len);
+	else
+		memcpy(buf, (char *)host->iobase, len);
+#else
+	if (buf == chip->oob_poi)
+		memcpy(buf, (char *)host->buffer + host->pagesize, len);
+	else
+		memcpy(buf, (char *)host->buffer, len);
+#endif
+
+#ifdef CONFIG_HISI_NAND_ECC_STATUS_REPORT
+	if (buf != chip->oob_poi) {
+		u_int reg, ecc_step = host->pagesize >> 10;
+
+		reg = hifmc_readl(host, HIFMC100_ECC_ERR_NUM0_BUF0);
+		while (ecc_step) {
+			u_char err_num;
+
+			err_num = GET_ECC_ERR_NUM(--ecc_step, reg);
+			if (err_num == 0xff)
+				mtd->ecc_stats.failed++;
+			else
+				mtd->ecc_stats.corrected += err_num;
+		}
+	}
+#endif
+
+	return;
+}
+
+/*****************************************************************************/
+static void hifmc100_select_chip(struct mtd_info *mtd, int chipselect)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+	if (chipselect < 0)
+		return;
+
+	if (chipselect > CONFIG_SPI_NAND_MAX_CHIP_NUM)
+		DB_BUG("Error: Invalid chipselect: %d\n", chipselect);
+
+	if (host->mtd != mtd) {
+		host->mtd = mtd;
+		host->cmd_op.cs = chipselect;
+	}
+
+	if (!(chip->options & NAND_BROKEN_XD)) {
+		if ((chip->state == FL_ERASING) || (chip->state == FL_WRITING))
+			host->cmd_op.l_cmd = NAND_CMD_GET_FEATURES;
+	}
+}
+
+/*****************************************************************************/
+static void hifmc100_cmd_ctrl(struct mtd_info *mtd, int dat, unsigned ctrl)
+{
+	unsigned char cmd;
+	int is_cache_invalid = 1;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+	if (ctrl & NAND_ALE) {
+		unsigned int addr_value = 0;
+		unsigned int addr_offset = 0;
+
+		if (ctrl & NAND_CTRL_CHANGE) {
+			host->addr_cycle = 0x0;
+			host->addr_value[0] = 0x0;
+			host->addr_value[1] = 0x0;
+		}
+		addr_offset = host->addr_cycle << 3;
+
+		if (host->addr_cycle >= HIFMC100_ADDR_CYCLE_MASK) {
+			addr_offset = (host->addr_cycle -
+					HIFMC100_ADDR_CYCLE_MASK) << 3;
+			addr_value = 1;
+		}
+
+		host->addr_value[addr_value] |=
+			((dat & 0xff) << addr_offset);
+
+		host->addr_cycle++;
+	}
+
+	if ((ctrl & NAND_CLE) && (ctrl & NAND_CTRL_CHANGE)) {
+		cmd = dat & 0xff;
+		host->cmd_op.cmd = cmd;
+		switch (cmd) {
+		case NAND_CMD_PAGEPROG:
+			host->offset = 0;
+			host->send_cmd_write(host);
+			break;
+
+		case NAND_CMD_READSTART:
+			is_cache_invalid = 0;
+			if (host->addr_value[0] == host->pagesize)
+				host->cmd_op.l_cmd = NAND_CMD_READOOB;
+			host->send_cmd_read(host);
+			break;
+
+		case NAND_CMD_ERASE2:
+			host->send_cmd_erase(host);
+			break;
+
+		case NAND_CMD_READID:
+			memset((u_char *)(host->iobase), 0,
+					MAX_SPI_NAND_ID_LEN);
+			host->cmd_op.l_cmd = cmd;
+			host->cmd_op.data_no = MAX_SPI_NAND_ID_LEN;
+			host->send_cmd_readid(host);
+			break;
+
+		case NAND_CMD_STATUS:
+			host->send_cmd_status(host);
+			break;
+
+		case NAND_CMD_READ0:
+			host->cmd_op.l_cmd = cmd;
+			break;
+
+		case NAND_CMD_RESET:
+			host->send_cmd_reset(host);
+			break;
+
+		case NAND_CMD_SEQIN:
+		case NAND_CMD_ERASE1:
+		default:
+			break;
+		}
+	}
+
+	if ((dat == NAND_CMD_NONE) && host->addr_cycle) {
+		if (host->cmd_op.cmd == NAND_CMD_SEQIN
+			|| host->cmd_op.cmd == NAND_CMD_READ0
+			|| host->cmd_op.cmd == NAND_CMD_READID) {
+			host->offset = 0x0;
+			host->column = (host->addr_value[0] & 0xffff);
+		}
+	}
+
+	if (is_cache_invalid) {
+		host->cache_addr_value[0] = ~0;
+		host->cache_addr_value[1] = ~0;
+	}
+}
+
+/*****************************************************************************/
+static int hifmc100_dev_ready(struct mtd_info *mtd)
+{
+	unsigned int reg;
+	unsigned long deadline = jiffies + FMC_MAX_READY_WAIT_JIFFIES;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+	do {
+		reg = OP_CFG_FM_CS(host->cmd_op.cs);
+		hifmc_writel(host, FMC_OP_CFG, reg);
+
+		reg = FMC_OP_READ_STATUS_EN | FMC_OP_REG_OP_START;
+		hifmc_writel(host, FMC_OP, reg);
+
+		FMC_CMD_WAIT_CPU_FINISH(host);
+
+		reg = hifmc_readl(host, FMC_STATUS);
+
+		if (!(reg & STATUS_OIP_MASK))
+			return NAND_STATUS_READY;
+
+		cond_resched();
+
+	} while (!time_after_eq(jiffies, deadline));
+
+	if (!(chip->options & NAND_SCAN_SILENT_NODEV))
+		pr_warn("Wait SPI nand ready timeout, status: %#x\n", reg);
+
+	return 0;
+}
+
+/*****************************************************************************/
+/*
+ * 'host->epm' only use the first oobfree[0] field, it looks very simple, But...
+ */
+/* Default OOB area layout */
+static int hifmc_ooblayout_ecc_default(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 32;
+	oobregion->offset = 32;
+
+	return 0;
+}
+
+static int hifmc_ooblayout_free_default(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 30;
+	oobregion->offset = 2;
+
+	return 0;
+}
+
+static struct mtd_ooblayout_ops hifmc_ooblayout_default_ops = {
+	.ecc = hifmc_ooblayout_ecc_default,
+	.free = hifmc_ooblayout_free_default,
+};
+
+#ifdef CONFIG_HISI_NAND_FS_MAY_NO_YAFFS2
+static int hifmc_ooblayout_ecc_4k16bit(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 14;
+	oobregion->offset = 14;
+
+	return 0;
+}
+
+static int hifmc_ooblayout_free_4k16bit(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 14;
+	oobregion->offset = 2;
+
+	return 0;
+}
+
+static struct mtd_ooblayout_ops hifmc_ooblayout_4k16bit_ops = {
+	.ecc = hifmc_ooblayout_ecc_4k16bit,
+	.free = hifmc_ooblayout_free_4k16bit,
+};
+
+static int hifmc_ooblayout_ecc_2k16bit(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 6;
+	oobregion->offset = 6;
+
+	return 0;
+}
+
+static int hifmc_ooblayout_free_2k16bit(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 6;
+	oobregion->offset = 2;
+
+	return 0;
+}
+
+static struct mtd_ooblayout_ops hifmc_ooblayout_2k16bit_ops = {
+	.ecc = hifmc_ooblayout_ecc_2k16bit,
+	.free = hifmc_ooblayout_free_2k16bit,
+};
+#endif
+
+/*****************************************************************************/
+static struct nand_config_info hifmc_spi_nand_config_table[] = {
+	{NAND_PAGE_4K,	NAND_ECC_24BIT,	24, 200,	&hifmc_ooblayout_default_ops},
+#ifdef CONFIG_HISI_NAND_FS_MAY_NO_YAFFS2
+	{NAND_PAGE_4K,	NAND_ECC_16BIT,	16, 128,	&hifmc_ooblayout_4k16bit_ops},
+#endif
+	{NAND_PAGE_4K,	NAND_ECC_8BIT,	8, 88,		&hifmc_ooblayout_default_ops},
+	{NAND_PAGE_4K,	NAND_ECC_0BIT,	0, 32,		&hifmc_ooblayout_default_ops},
+
+	{NAND_PAGE_2K,	NAND_ECC_24BIT,	24, 128,	&hifmc_ooblayout_default_ops},
+#ifdef CONFIG_HISI_NAND_FS_MAY_NO_YAFFS2
+	{NAND_PAGE_2K,	NAND_ECC_16BIT,	16, 64,		&hifmc_ooblayout_2k16bit_ops},
+#endif
+	{NAND_PAGE_2K,	NAND_ECC_8BIT,	8, 64,		&hifmc_ooblayout_default_ops},
+	{NAND_PAGE_2K,	NAND_ECC_0BIT,	0, 32,		&hifmc_ooblayout_default_ops},
+
+	{0, 0, 0, 0, NULL},
+};
+
+/*
+ * Auto-sensed the page size and ecc type value. driver will try each of page
+ * size and ecc type one by one till flash can be read and wrote accurately.
+ * so the page size and ecc type is match adaptively without switch on the board
+ */
+static struct nand_config_info *hifmc100_get_config_type_info(
+		struct mtd_info *mtd, struct nand_dev_t *nand_dev)
+{
+	struct nand_config_info *best = NULL;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct nand_config_info *info = hifmc_spi_nand_config_table;
+
+	nand_dev->start_type = "Auto";
+
+	for (; info->ooblayout_ops; info++) {
+		if (match_page_type_to_size(info->pagetype) != mtd->writesize)
+			continue;
+
+		if (mtd->oobsize < info->oobsize)
+			continue;
+
+		if (!best || (best->ecctype < info->ecctype))
+			best = info;
+	}
+
+	/* All SPI NAND are small-page, SLC */
+	chip->bits_per_cell = 1;
+
+	return best;
+}
+
+/*****************************************************************************/
+static void hifmc100_chip_init(struct nand_chip *chip)
+{
+	chip->read_byte = hifmc100_read_byte;
+	chip->read_word = hifmc100_read_word;
+	chip->write_buf = hifmc100_write_buf;
+	chip->read_buf = hifmc100_read_buf;
+
+	chip->select_chip = hifmc100_select_chip;
+
+	chip->cmd_ctrl = hifmc100_cmd_ctrl;
+	chip->dev_ready = hifmc100_dev_ready;
+
+	chip->chip_delay = FMC_CHIP_DELAY;
+
+	chip->options = NAND_SKIP_BBTSCAN | NAND_BROKEN_XD
+		| NAND_SCAN_SILENT_NODEV;
+
+	chip->ecc.mode = NAND_ECC_NONE;
+}
+
+/*****************************************************************************/
+static void hifmc100_set_oob_info(struct mtd_info *mtd,
+		struct nand_config_info *info, struct nand_dev_t *nand_dev)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+	struct mtd_oob_region hifmc_oobregion = {0, 0};
+
+	if (info->ecctype != NAND_ECC_0BIT)
+		mtd->oobsize = info->oobsize;
+
+	host->oobsize = mtd->oobsize;
+	nand_dev->oobsize = host->oobsize;
+
+	host->dma_oob = host->dma_buffer + host->pagesize;
+	host->bbm = (u_char *)(host->buffer + host->pagesize
+			+ HIFMC_BAD_BLOCK_POS);
+
+	info->ooblayout_ops->free(mtd, 0, &hifmc_oobregion);
+
+	mtd_set_ooblayout(mtd, info->ooblayout_ops);
+
+	/* EB bits locate in the bottom two of CTRL(30) */
+	host->epm = (u_short *)(host->buffer + host->pagesize
+			+ hifmc_oobregion.offset + 28);
+
+#ifdef CONFIG_HISI_NAND_FS_MAY_NO_YAFFS2
+	if (best->ecctype == NAND_ECC_16BIT) {
+		if (host->pagesize == _2K) {
+			/* EB bits locate in the bottom two of CTRL(4) */
+			host->epm = (u_short *)(host->buffer + host->pagesize
+					+ hifmc_oobregion.offset + 4);
+		} else if (host->pagesize == _4K) {
+			/* EB bit locate in the bottom two of CTRL(14) */
+			host->epm = (u_short *)(host->buffer + host->pagesize
+					+ hifmc_oobregion.offset + 12);
+		}
+	}
+#endif
+}
+
+/*****************************************************************************/
+static unsigned int hifmc100_get_ecc_reg(struct hifmc_host *host,
+		struct nand_config_info *info, struct nand_dev_t *nand_dev)
+{
+	host->ecctype = info->ecctype;
+	nand_dev->ecctype = host->ecctype;
+
+	return FMC_CFG_ECC_TYPE(match_ecc_type_to_reg(info->ecctype));
+}
+
+/*****************************************************************************/
+static unsigned int hifmc100_get_page_reg(struct hifmc_host *host,
+		struct nand_config_info *info)
+{
+	host->pagesize = match_page_type_to_size(info->pagetype);
+
+	return FMC_CFG_PAGE_SIZE(match_page_type_to_reg(info->pagetype));
+}
+
+/*****************************************************************************/
+static unsigned int hifmc100_get_block_reg(struct hifmc_host *host,
+		struct nand_config_info *info)
+{
+	unsigned int block_reg = 0, page_per_block;
+	struct mtd_info *mtd = host->mtd;
+
+	host->block_page_mask = ((mtd->erasesize / mtd->writesize) - 1);
+	page_per_block = mtd->erasesize / match_page_type_to_size(info->pagetype);
+	switch (page_per_block) {
+		case 64:
+			block_reg = BLOCK_SIZE_64_PAGE;
+			break;
+		case 128:
+			block_reg = BLOCK_SIZE_128_PAGE;
+			break;
+		case 256:
+			block_reg = BLOCK_SIZE_256_PAGE;
+			break;
+		case 512:
+			block_reg = BLOCK_SIZE_512_PAGE;
+			break;
+		default:
+			DB_MSG("Can't support block %#x and page %#x size\n",
+					mtd->erasesize, mtd->writesize);
+	}
+
+	return FMC_CFG_BLOCK_SIZE(block_reg);
+}
+
+/*****************************************************************************/
+static void hifmc100_set_fmc_cfg_reg(struct hifmc_host *host,
+		struct nand_config_info *type_info, struct nand_dev_t *nand_dev)
+{
+	unsigned int page_reg, ecc_reg, block_reg, reg_fmc_cfg;
+
+	ecc_reg = hifmc100_get_ecc_reg(host, type_info, nand_dev);
+	page_reg = hifmc100_get_page_reg(host, type_info);
+	block_reg = hifmc100_get_block_reg(host, type_info);
+
+	reg_fmc_cfg = hifmc_readl(host, FMC_CFG);
+	reg_fmc_cfg &= ~(PAGE_SIZE_MASK | ECC_TYPE_MASK | BLOCK_SIZE_MASK);
+	reg_fmc_cfg |= ecc_reg | page_reg | block_reg;
+	hifmc_writel(host, FMC_CFG, reg_fmc_cfg);
+
+	/* Save value of FMC_CFG and FMC_CFG_ECC0 to turn on/off ECC */
+	host->fmc_cfg = reg_fmc_cfg;
+	host->fmc_cfg_ecc0 = (host->fmc_cfg & ~ECC_TYPE_MASK) | ECC_TYPE_0BIT;
+	FMC_PR(BT_DBG, "\t|-Save FMC_CFG[%#x]: %#x and FMC_CFG_ECC0: %#x\n",
+			FMC_CFG, host->fmc_cfg, host->fmc_cfg_ecc0);
+}
+
+/*****************************************************************************/
+static int hifmc100_set_config_info(struct mtd_info *mtd,
+		struct nand_chip *chip, struct nand_dev_t *nand_dev)
+{
+	struct hifmc_host *host = chip->priv;
+	struct nand_config_info *type_info = NULL;
+
+	FMC_PR(BT_DBG, "\t*-Start config Block Page OOB and Ecc\n");
+
+	type_info = hifmc100_get_config_type_info(mtd, nand_dev);
+	BUG_ON(!type_info);
+
+	FMC_PR(BT_DBG, "\t|-%s Config, PageSize %s EccType %s OOBSize %d\n",
+			nand_dev->start_type, nand_page_name(type_info->pagetype),
+			nand_ecc_name(type_info->ecctype), type_info->oobsize);
+
+	/* Set the page_size, ecc_type, block_size of FMC_CFG[0x0] register */
+	hifmc100_set_fmc_cfg_reg(host, type_info, nand_dev);
+
+	hifmc100_set_oob_info(mtd, type_info, nand_dev);
+
+	FMC_PR(BT_DBG, "\t*-End config Block Page Oob and Ecc\n");
+
+	return 0;
+}
+
+/*****************************************************************************/
+int hifmc100_spi_nand_init(struct nand_chip *chip)
+{
+	struct hifmc_host *host = chip->priv;
+
+	FMC_PR(BT_DBG, "\t|*-Start hifmc100 SPI Nand init\n");
+
+	/* Set system clock and enable controller */
+	clk_prepare_enable(host->clk);
+
+	/* Switch SPI type to SPI nand */
+	hifmc100_switch_to_spi_nand(host);
+
+	/* Hifmc host init */
+	hifmc100_host_init(host);
+	host->chip = chip;
+
+	/* Hifmc nand_chip struct init */
+	hifmc100_chip_init(chip);
+
+	hifmc_spi_nand_ids_register();
+	hinfc_param_adjust = hifmc100_set_config_info;
+
+	FMC_PR(BT_DBG, "\t|*-End hifmc100 SPI Nand init\n");
+
+	return 0;
+}
+#ifdef CONFIG_PM
+/*****************************************************************************/
+int hifmc100_suspend(struct platform_device *pltdev, pm_message_t state)
+{
+	unsigned int ret;
+	struct hifmc_host *host = platform_get_drvdata(pltdev);
+	struct hifmc_spi *spi = host->spi;
+
+	mutex_lock(host->lock);
+	hifmc100_switch_to_spi_nand(host);
+
+	ret = spi->driver->wait_ready(spi);
+	if (ret) {
+		DB_MSG("Error: wait ready failed!");
+		return 0;
+	}
+
+	clk_disable_unprepare(host->clk);
+	mutex_unlock(host->lock);
+
+	return 0;
+}
+/*****************************************************************************/
+int hifmc100_resume(struct platform_device *pltdev)
+{
+	int cs;
+	struct hifmc_host *host = platform_get_drvdata(pltdev);
+	struct nand_chip *chip = host->chip;
+
+	mutex_lock(host->lock);
+	hifmc100_switch_to_spi_nand(host);
+	clk_prepare_enable(host->clk);
+
+	for (cs = 0; cs < chip->numchips; cs++)
+		host->send_cmd_reset(host);
+
+	hifmc100_spi_nand_config(host);
+
+	mutex_unlock(host->lock);
+	return 0;
+}
+#endif
+
diff --git a/drivers/mtd/nand/hifmc100/hifmc100.h b/drivers/mtd/nand/hifmc100/hifmc100.h
new file mode 100644
index 0000000..2f7f5a8
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100/hifmc100.h
@@ -0,0 +1,391 @@
+/*
+ * The Flash Memory Controller v100 Device Driver for hisilicon
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+ 
+#ifndef __HIFMC100_H__
+#define __HIFMC100_H__
+
+/*****************************************************************************/
+#include <linux/platform_device.h>
+#include <linux/mfd/hisi_fmc.h>
+
+/*****************************************************************************/
+#define INFINITE			(0xFFFFFFFF)
+
+/*****************************************************************************/
+#define SPI_IF_READ_STD			(0x01)
+#define SPI_IF_READ_FAST		(0x02)
+#define SPI_IF_READ_DUAL		(0x04)
+#define SPI_IF_READ_DUAL_ADDR		(0x08)
+#define SPI_IF_READ_QUAD		(0x10)
+#define SPI_IF_READ_QUAD_ADDR		(0x20)
+
+#define SPI_IF_WRITE_STD		(0x01)
+#define SPI_IF_WRITE_DUAL		(0x02)
+#define SPI_IF_WRITE_DUAL_ADDR		(0x04)
+#define SPI_IF_WRITE_QUAD		(0x08)
+#define SPI_IF_WRITE_QUAD_ADDR		(0x10)
+
+#define SPI_IF_ERASE_SECTOR_4K		(0x01)
+#define SPI_IF_ERASE_SECTOR_32K		(0x02)
+#define SPI_IF_ERASE_SECTOR_64K		(0x04)
+#define SPI_IF_ERASE_SECTOR_128K	(0x08)
+#define SPI_IF_ERASE_SECTOR_256K	(0x10)
+
+/******************************************************************************/
+#define HIFMC_SPI_NAND_SUPPORT_READ	(SPI_IF_READ_STD \
+					| SPI_IF_READ_FAST \
+					| SPI_IF_READ_DUAL \
+					| SPI_IF_READ_DUAL_ADDR \
+					| SPI_IF_READ_QUAD \
+					| SPI_IF_READ_QUAD_ADDR)
+
+#define HIFMC_SPI_NAND_SUPPORT_WRITE	(SPI_IF_WRITE_STD | SPI_IF_WRITE_QUAD)
+
+#define HIFMC_SPI_NAND_SUPPORT_MAX_DUMMY	8
+
+/*****************************************************************************/
+#define SPI_CMD_READ_STD		0x03	/* Standard read cache */
+#define SPI_CMD_READ_FAST		0x0B	/* Higher speed read cache */
+#define SPI_CMD_READ_DUAL		0x3B	/* 2 IO read cache only date */
+#define SPI_CMD_READ_DUAL_ADDR		0xBB	/* 2 IO read cache date&addr */
+#define SPI_CMD_READ_QUAD		0x6B	/* 4 IO read cache only date */
+#define SPI_CMD_READ_QUAD_ADDR		0xEB	/* 4 IO read cache date&addr */
+
+#define SPI_CMD_WRITE_STD		0x02	/* Standard page program */
+#define SPI_CMD_WRITE_DUAL		0xA2	/* 2 IO program only date */
+#define SPI_CMD_WRITE_DUAL_ADDR		0xD2	/* 2 IO program date&addr */
+#define SPI_CMD_WRITE_QUAD		0x32	/* 4 IO program only date */
+#define SPI_CMD_WRITE_QUAD_ADDR		0x12	/* 4 IO program date&addr */
+
+#define SPI_CMD_SE_4K			0x20	/* 4KB sector Erase */
+#define SPI_CMD_SE_32K			0x52	/* 32KB sector Erase */
+#define SPI_CMD_SE_64K			0xD8	/* 64KB sector Erase */
+#define SPI_CMD_SE_128K			0xD8	/* 128KB sector Erase */
+#define SPI_CMD_SE_256K			0xD8	/* 256KB sector Erase */
+
+/*****************************************************************************/
+#define SET_READ_STD(_dummy_, _size_, _clk_) \
+	static struct spi_op read_std_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_STD, SPI_CMD_READ_STD, _dummy_, _size_, _clk_ }
+
+#define SET_READ_FAST(_dummy_, _size_, _clk_) \
+	static struct spi_op read_fast_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_FAST, SPI_CMD_READ_FAST, _dummy_, _size_, _clk_ }
+
+#define SET_READ_DUAL(_dummy_, _size_, _clk_) \
+	static struct spi_op read_dual_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_DUAL, SPI_CMD_READ_DUAL, _dummy_, _size_, _clk_ }
+
+#define SET_READ_DUAL_ADDR(_dummy_, _size_, _clk_) \
+	static struct spi_op read_dual_addr_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_DUAL_ADDR, SPI_CMD_READ_DUAL_ADDR, _dummy_, _size_, _clk_ }
+
+#define SET_READ_QUAD(_dummy_, _size_, _clk_) \
+	static struct spi_op read_quad_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_QUAD, SPI_CMD_READ_QUAD, _dummy_, _size_, _clk_ }
+
+#define SET_READ_QUAD_ADDR(_dummy_, _size_, _clk_) \
+	static struct spi_op read_quad_addr_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_QUAD_ADDR, SPI_CMD_READ_QUAD_ADDR, _dummy_, _size_, _clk_ }
+
+/*****************************************************************************/
+#define SET_WRITE_STD(_dummy_, _size_, _clk_) \
+	static struct spi_op write_std_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_WRITE_STD, SPI_CMD_WRITE_STD, _dummy_, _size_, _clk_ }
+
+#define SET_WRITE_DUAL(_dummy_, _size_, _clk_) \
+	static struct spi_op write_dual_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_WRITE_DUAL, SPI_CMD_WRITE_DUAL, _dummy_, _size_, _clk_ }
+
+#define SET_WRITE_DUAL_ADDR(_dummy_, _size_, _clk_) \
+	static struct spi_op write_dual_addr_##_dummy_##_size_##_clk_ = { \
+SPI_IF_WRITE_DUAL_ADDR, SPI_CMD_WRITE_DUAL_ADDR, _dummy_, _size_, _clk_ }
+
+#define SET_WRITE_QUAD(_dummy_, _size_, _clk_) \
+	static struct spi_op write_quad_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_WRITE_QUAD, SPI_CMD_WRITE_QUAD, _dummy_, _size_, _clk_ }
+
+#define SET_WRITE_QUAD_ADDR(_dummy_, _size_, _clk_) \
+	static struct spi_op write_quad_addr_##_dummy_##_size_##_clk_ = { \
+SPI_IF_WRITE_QUAD_ADDR, SPI_CMD_WRITE_QUAD_ADDR, _dummy_, _size_, _clk_ }
+
+/*****************************************************************************/
+#define SET_ERASE_SECTOR_4K(_dummy_, _size_, _clk_) \
+	static struct spi_op erase_sector_4k_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_ERASE_SECTOR_4K, SPI_CMD_SE_4K, _dummy_, _size_, _clk_ }
+
+#define SET_ERASE_SECTOR_32K(_dummy_, _size_, _clk_) \
+	static struct spi_op erase_sector_32k_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_ERASE_SECTOR_32K, SPI_CMD_SE_32K, _dummy_, _size_, _clk_ }
+
+#define SET_ERASE_SECTOR_64K(_dummy_, _size_, _clk_) \
+	static struct spi_op erase_sector_64k_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_ERASE_SECTOR_64K, SPI_CMD_SE_64K, _dummy_, _size_, _clk_ }
+
+#define SET_ERASE_SECTOR_128K(_dummy_, _size_, _clk_) \
+	static struct spi_op erase_sector_128k_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_ERASE_SECTOR_128K, SPI_CMD_SE_128K, _dummy_, _size_, _clk_ }
+
+#define SET_ERASE_SECTOR_256K(_dummy_, _size_, _clk_) \
+	static struct spi_op erase_sector_256k_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_ERASE_SECTOR_256K, SPI_CMD_SE_256K, _dummy_, _size_, _clk_ }
+
+/*****************************************************************************/
+#define READ_STD(_dummy_, _size_, _clk_) read_std_##_dummy_##_size_##_clk_
+#define READ_FAST(_dummy_, _size_, _clk_) read_fast_##_dummy_##_size_##_clk_
+#define READ_DUAL(_dummy_, _size_, _clk_) read_dual_##_dummy_##_size_##_clk_
+#define READ_DUAL_ADDR(_dummy_, _size_, _clk_) \
+		read_dual_addr_##_dummy_##_size_##_clk_
+#define READ_QUAD(_dummy_, _size_, _clk_) read_quad_##_dummy_##_size_##_clk_
+#define READ_QUAD_ADDR(_dummy_, _size_, _clk_) \
+		read_quad_addr_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+#define WRITE_STD(_dummy_, _size_, _clk_) write_std_##_dummy_##_size_##_clk_
+#define WRITE_DUAL(_dummy_, _size_, _clk_) write_dual_##_dummy_##_size_##_clk_
+#define WRITE_DUAL_ADDR(_dummy_, _size_, _clk_) \
+		write_dual_addr_##_dummy_##_size_##_clk_
+#define WRITE_QUAD(_dummy_, _size_, _clk_) write_quad_##_dummy_##_size_##_clk_
+#define WRITE_QUAD_ADDR(_dummy_, _size_, _clk_) \
+		write_quad_addr_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+#define ERASE_SECTOR_4K(_dummy_, _size_, _clk_) \
+		erase_sector_4k_##_dummy_##_size_##_clk_
+#define ERASE_SECTOR_32K(_dummy_, _size_, _clk_) \
+		erase_sector_32k_##_dummy_##_size_##_clk_
+#define ERASE_SECTOR_64K(_dummy_, _size_, _clk_) \
+		erase_sector_64k_##_dummy_##_size_##_clk_
+#define ERASE_SECTOR_128K(_dummy_, _size_, _clk_) \
+		erase_sector_128k_##_dummy_##_size_##_clk_
+#define ERASE_SECTOR_256K(_dummy_, _size_, _clk_) \
+		erase_sector_256k_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+#define SPI_CMD_WREN			0x06	/* Write Enable */
+#define SPI_CMD_WRDI			0x04	/* Write Disable */
+
+#define SPI_CMD_RDID			0x9F	/* Read Identification */
+
+/*****************************************************************************/
+#define SPI_CMD_GET_FEATURES		0x0F	/* Get Features */
+#define SPI_CMD_SET_FEATURE		0x1F	/* Set Feature */
+
+#define SPI_CMD_PAGE_READ		0x13	/* Page Read to Cache */
+
+#define SPI_CMD_RESET			0xff	/* Reset the device */
+
+/*****************************************************************************/
+/* These macroes are for debug only, reg option is slower then dma option */
+#undef HIFMC100_SPI_NAND_SUPPORT_REG_READ
+/* #define HIFMC100_SPI_NAND_SUPPORT_REG_READ */
+
+#undef HIFMC100_SPI_NAND_SUPPORT_REG_WRITE
+/* #define HIFMC100_SPI_NAND_SUPPORT_REG_WRITE */
+
+#ifdef CONFIG_HISI_NAND_ECC_STATUS_REPORT
+/*****************************************************************************/
+#define HIFMC100_ECC_ERR_NUM0_BUF0		0xc0
+
+#define GET_ECC_ERR_NUM(_i, _reg)		(((_reg) >> ((_i) * 8)) & 0xff)
+#endif
+/*****************************************************************************/
+#define REG_CNT_HIGH_BLOCK_NUM_SHIFT		10
+
+#define REG_CNT_BLOCK_NUM_MASK			0x3ff
+#define REG_CNT_BLOCK_NUM_SHIFT			22
+
+#define REG_CNT_PAGE_NUM_MASK			0x3f
+#define REG_CNT_PAGE_NUM_SHIFT			16
+
+#define REG_CNT_WRAP_MASK			0xf
+#define REG_CNT_WRAP_SHIFT			12
+
+#define REG_CNT_ECC_OFFSET_MASK			0xfff
+#define REG_CNT_ECC_8BIT_OFFSET			1054
+#define REG_CNT_ECC_16BIT_OFFSET		1056
+#define REG_CNT_ECC_24BIT_OFFSET		1082
+
+#define ERR_STR_DRIVER "Driver does not support this configure "
+#define ERR_STR_CHECK "Please make sure the hardware configuration is correct"
+
+/*****************************************************************************/
+#define HIFMC100_ADDR_CYCLE_MASK		0x2
+
+/*****************************************************************************/
+#define OP_STYPE_NONE			0x0
+#define OP_STYPE_READ			0x01
+#define OP_STYPE_WRITE			0x02
+#define OP_STYPE_ERASE			0x04
+#define CLK_FMC_TO_CRG_MHZ(_clk)	((_clk) * 2000000)
+
+/*****************************************************************************/
+#define MAX_SPI_OP			8
+
+/*****************************************************************************/
+/* SPI general operation parameter */
+struct spi_op {
+	unsigned char iftype;
+	unsigned char cmd;
+	unsigned char dummy;
+	unsigned int size;
+	unsigned int clock;
+};
+
+struct spi_drv;
+
+/* SPI interface all operation */
+struct hifmc_spi {
+	char *name;
+	int chipselect;
+	unsigned long long chipsize;
+	unsigned int erasesize;
+#define SPI_NOR_3BYTE_ADDR_LEN	3	/* address len 3Bytes */
+#define SPI_NOR_4BYTE_ADDR_LEN	4	/* address len 4Bytes for 32MB */
+	unsigned int addrcycle;
+
+	struct spi_op read[1];
+	struct spi_op write[1];
+	struct spi_op erase[MAX_SPI_OP];
+
+	void *host;
+
+	struct spi_drv *driver;
+};
+
+/* SPI interface special operation function hook */
+struct spi_drv {
+	int (*wait_ready)(struct hifmc_spi *spi);
+	int (*write_enable)(struct hifmc_spi *spi);
+	int (*qe_enable)(struct hifmc_spi *spi);
+	int (*bus_prepare)(struct hifmc_spi *spi, int op);
+	int (*entry_4addr)(struct hifmc_spi *spi, int en);
+};
+
+struct spi_nand_info {
+	char *name;
+	unsigned char id[MAX_SPI_NAND_ID_LEN];
+	unsigned char id_len;
+	unsigned long long chipsize;
+	unsigned int erasesize;
+	unsigned int pagesize;
+	unsigned int oobsize;
+#define BBP_LAST_PAGE		0x01
+#define BBP_FIRST_PAGE		0x02
+	unsigned int badblock_pos;
+	struct spi_op *read[MAX_SPI_OP];
+	struct spi_op *write[MAX_SPI_OP];
+	struct spi_op *erase[MAX_SPI_OP];
+	struct spi_drv *driver;
+};
+
+/*****************************************************************************/
+extern u_char spi_nand_feature_op(struct hifmc_spi *spi, u_char op, u_char addr,
+		u_char val);
+
+/*****************************************************************************/
+struct hifmc_host {
+	struct mtd_info *mtd;
+	struct nand_chip *chip;
+	struct hifmc_spi spi[CONFIG_SPI_NAND_MAX_CHIP_NUM];
+	struct hifmc_cmd_op cmd_op;
+
+	void __iomem *iobase;
+	void __iomem *regbase;
+	struct clk *clk;
+	u32 clkrate;
+
+	unsigned int fmc_cfg;
+	unsigned int fmc_cfg_ecc0;
+
+	unsigned int offset;
+
+	struct device *dev;
+	struct mutex *lock;
+
+	/* This is maybe an un-aligment address, only for malloc or free */
+	char *buforg;
+	char *buffer;
+
+#ifdef CONFIG_64BIT
+	unsigned long long dma_buffer;
+	unsigned long long dma_oob;
+#else
+	unsigned int dma_buffer;
+	unsigned int dma_oob;
+#endif
+
+	unsigned int addr_cycle;
+	unsigned int addr_value[2];
+	unsigned int cache_addr_value[2];
+
+	unsigned int column;
+	unsigned int block_page_mask;
+
+	unsigned int ecctype;
+	unsigned int pagesize;
+	unsigned int oobsize;
+
+	int add_partition;
+
+	int  need_rr_data;
+#define HIFMC100_READ_RETRY_DATA_LEN         128
+	char rr_data[HIFMC100_READ_RETRY_DATA_LEN];
+	struct read_retry_t *read_retry;
+
+	int version;
+
+	/* BOOTROM read two bytes to detect the bad block flag */
+#define HIFMC_BAD_BLOCK_POS		0
+	unsigned char *bbm;	/* nand bad block mark */
+	unsigned short *epm;	/* nand empty page mark */
+
+	unsigned int uc_er;
+
+	void (*send_cmd_write)(struct hifmc_host *host);
+	void (*send_cmd_status)(struct hifmc_host *host);
+	void (*send_cmd_read)(struct hifmc_host *host);
+	void (*send_cmd_erase)(struct hifmc_host *host);
+	void (*send_cmd_readid)(struct hifmc_host *host);
+	void (*send_cmd_reset)(struct hifmc_host *host);
+#ifdef CONFIG_PM
+	int (*suspend)(struct platform_device *pltdev, pm_message_t state);
+	int (*resume)(struct platform_device *pltdev);
+#endif
+};
+
+/*****************************************************************************/
+void hifmc100_ecc0_switch(struct hifmc_host *host, unsigned char op);
+
+int hifmc100_spi_nand_init(struct nand_chip *chip);
+
+/*****************************************************************************/
+extern void hifmc_spi_nand_ids_register(void);
+
+extern void hifmc_set_nand_system_clock(struct spi_op *op, int clk_en);
+
+/*****************************************************************************/
+#ifdef CONFIG_PM
+int hifmc100_suspend(struct platform_device *pltdev, pm_message_t state);
+int hifmc100_resume(struct platform_device *pltdev);
+void hifmc100_spi_nand_config(struct hifmc_host *host);
+#endif
+
+#endif /* End of __HIFMC100_H__ */
diff --git a/drivers/mtd/nand/hifmc100/hifmc100_os.c b/drivers/mtd/nand/hifmc100/hifmc100_os.c
new file mode 100644
index 0000000..c5c90fe
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100/hifmc100_os.c
@@ -0,0 +1,237 @@
+/*
+ * The Flash Memory Controller v100 Device Driver for hisilicon
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/delay.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/dma-mapping.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/partitions.h>
+#include <linux/of_platform.h>
+#include <linux/mfd/hisi_fmc.h>
+
+#include <asm/setup.h>
+
+#include "../../mtdcore.h"
+#include "hifmc100.h"
+#include "hifmc100_os.h"
+
+/*****************************************************************************/
+static int hifmc100_spi_nand_pre_probe(struct nand_chip *chip)
+{
+	uint8_t nand_maf_id;
+	struct hifmc_host *host = chip->priv;
+
+	/* Reset the chip first */
+	host->send_cmd_reset(host);
+	udelay(1000);
+
+	/* Check the ID */
+	host->offset = 0;
+	memset((unsigned char *)(chip->IO_ADDR_R), 0, 0x10);
+	host->send_cmd_readid(host);
+	nand_maf_id = hifmc_readb(chip->IO_ADDR_R);
+
+	if (nand_maf_id == 0x00 || nand_maf_id == 0xff) {
+		printk("Cannot found a valid SPI Nand Device\n");
+		return 1;
+	}
+
+	return 0;
+}
+/*****************************************************************************/
+static int hifmc_nand_scan(struct mtd_info *mtd)
+{
+	int result = 0;
+	unsigned char cs, chip_num = CONFIG_SPI_NAND_MAX_CHIP_NUM;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+	for (cs = 0; chip_num && (cs < HIFMC_MAX_CHIP_NUM); cs++) {
+		if (hifmc_cs_user[cs]) {
+			FMC_PR(BT_DBG, "\t\t*-Current CS(%d) is occupied.\n",
+					cs);
+			continue;
+		}
+
+		host->cmd_op.cs = cs;
+
+		if (hifmc100_spi_nand_pre_probe(chip))
+			return -ENODEV;
+
+		FMC_PR(BT_DBG, "\t\t*-Scan SPI nand flash on CS: %d\n", cs);
+		if (nand_scan(mtd, chip_num))
+			continue;
+		chip_num--;
+	}
+
+	if (chip_num == CONFIG_SPI_NAND_MAX_CHIP_NUM)
+		result = -ENXIO;
+	else
+		result = 0;
+
+	return result;
+}
+
+/*****************************************************************************/
+static int hisi_spi_nand_probe(struct platform_device *pltdev)
+{
+	int len, result = 0;
+	struct hifmc_host *host;
+	struct nand_chip *chip;
+	struct mtd_info *mtd;
+	struct device *dev = &pltdev->dev;
+	struct device_node *np = NULL;
+	struct hisi_fmc *fmc = dev_get_drvdata(dev->parent);
+
+	FMC_PR(BT_DBG, "\t*-Start SPI Nand flash driver probe\n");
+
+	len = sizeof(struct hifmc_host) + sizeof(struct nand_chip)
+		+ sizeof(struct mtd_info);
+	host = devm_kzalloc(dev, len, GFP_KERNEL);
+	if (!host)
+		return -ENOMEM;
+	memset((char *)host, 0, len);
+
+	platform_set_drvdata(pltdev, host);
+	host->dev = &pltdev->dev;
+
+	host->chip = chip = (struct nand_chip *)&host[1];
+	host->mtd  = mtd  = nand_to_mtd(chip);
+
+	host->regbase = fmc->regbase;
+	host->iobase = fmc->iobase;
+	host->clk = fmc->clk;
+	host->lock = &fmc->lock;
+
+	memset((char *)host->iobase, 0xff, SPI_NAND_BUFFER_LEN);
+	chip->IO_ADDR_R = chip->IO_ADDR_W = host->iobase;
+
+	host->buffer = dmam_alloc_coherent(host->dev, SPI_NAND_BUFFER_LEN,
+			&host->dma_buffer, GFP_KERNEL);
+	if (!host->buffer) {
+		DB_MSG("Error: Can't allocate memory for dma buffer.");
+		result = -EIO;
+		goto fail;
+	}
+	memset(host->buffer, 0xff, SPI_NAND_BUFFER_LEN);
+
+	chip->priv = host;
+	result = hifmc100_spi_nand_init(chip);
+	if (result) {
+		FMC_PR(BT_DBG, "\t|-SPI Nand init failed, ret: %d\n", result);
+		result = -ENODEV;
+		goto fail;
+	}
+
+	np = of_get_next_available_child(dev->of_node, NULL);
+	mtd->name = np->name;
+	mtd->type = MTD_NANDFLASH;
+	mtd->priv = chip;
+	mtd->owner = THIS_MODULE;
+
+	result = of_property_read_u32(np, "spi-max-frequency", &host->clkrate);
+	if (result)
+		goto fail;
+
+	result = hifmc_nand_scan(mtd);
+	if (result) {
+		FMC_PR(BT_DBG, "\t|-Scan SPI Nand failed.\n");
+		goto fail;
+	}
+
+	result = mtd_device_register(mtd, NULL, 0);
+	if (!result) {
+		FMC_PR(BT_DBG, "\t*-End driver probe !!\n");
+	    return 0;
+	}
+
+	result = -ENODEV;
+fail:
+	clk_disable_unprepare(host->clk);
+	nand_release(mtd);
+
+	DB_MSG("Error: driver probe, result: %d\n", result);
+	return result;
+}
+
+/*****************************************************************************/
+static int hisi_spi_nand_remove(struct platform_device *pltdev)
+{
+	struct hifmc_host *host = platform_get_drvdata(pltdev);
+
+	dmam_free_coherent(host->dev, SPI_NAND_BUFFER_LEN,
+			host->buffer, host->dma_buffer);
+	clk_disable_unprepare(host->clk);
+	nand_release(host->mtd);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+/*****************************************************************************/
+static int hifmc100_os_suspend(struct platform_device *pltdev,
+		pm_message_t state)
+{
+	struct hifmc_host *host = platform_get_drvdata(pltdev);
+
+	if (host && host->suspend)
+		return (host->suspend)(pltdev, state);
+
+	return 0;
+}
+
+/*****************************************************************************/
+static int hifmc100_os_resume(struct platform_device *pltdev)
+{
+	struct hifmc_host *host = platform_get_drvdata(pltdev);
+
+	if (host && host->resume)
+		return (host->resume)(pltdev);
+
+	return 0;
+}
+#endif /* End of CONFIG_PM */
+/*****************************************************************************/
+static const struct of_device_id hisi_spi_nand_dt_ids[] = {
+	{ .compatible = "hisilicon,hisi-spi-nand"},
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, hisi_spi_nand_dt_ids);
+
+static struct platform_driver hisi_spi_nand_driver = {
+	.driver = {
+		.name	= "hisi_spi_nand",
+		.of_match_table = hisi_spi_nand_dt_ids,
+	},
+	.probe	= hisi_spi_nand_probe,
+	.remove = hisi_spi_nand_remove,
+#ifdef CONFIG_PM
+	.suspend	= hifmc100_os_suspend,
+	.resume		= hifmc100_os_resume,
+#endif
+};
+module_platform_driver(hisi_spi_nand_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("BVT_BSP");
+MODULE_DESCRIPTION("Hisilicon Flash Memory Controller V100 SPI Nand Driver");
diff --git a/drivers/mtd/nand/hifmc100/hifmc100_os.h b/drivers/mtd/nand/hifmc100/hifmc100_os.h
new file mode 100644
index 0000000..22199dc
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100/hifmc100_os.h
@@ -0,0 +1,30 @@
+/*
+ * The Flash Memory Controller v100 Device Driver for hisilicon
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef __HIFMC100_OS_H__
+#define __HIFMC100_OS_H__
+
+/*****************************************************************************/
+#define SPI_NAND_MAX_PAGESIZE			4096
+#define SPI_NAND_MAX_OOBSIZE			256
+
+#define SPI_NAND_BUFFER_LEN	(SPI_NAND_MAX_PAGESIZE + SPI_NAND_MAX_OOBSIZE)
+
+#endif /* End of __HIFMC100_OS_H__ */
diff --git a/drivers/mtd/nand/hifmc100/hifmc100_spi_general.c b/drivers/mtd/nand/hifmc100/hifmc100_spi_general.c
new file mode 100644
index 0000000..4bcd9c1
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100/hifmc100_spi_general.c
@@ -0,0 +1,253 @@
+/*
+ * The Flash Memory Controller v100 Device Driver for hisilicon
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+/*
+	Send set/get features command to SPI Nand flash
+*/
+u_char spi_nand_feature_op(struct hifmc_spi *spi, u_char op, u_char addr,
+		u_char val)
+{
+	unsigned int reg;
+	const char *str[] = {"Get", "Set"};
+	struct hifmc_host *host = (struct hifmc_host *)spi->host;
+
+	if ((GET_OP == op) && (STATUS_ADDR == addr)) {
+		if (SR_DBG)
+			pr_info("\n");
+		FMC_PR(SR_DBG, "\t\t|*-Start Get Status\n");
+
+		reg = OP_CFG_FM_CS(host->cmd_op.cs);
+		hifmc_writel(host, FMC_OP_CFG, reg);
+		FMC_PR(SR_DBG, "\t\t||-Set OP_CFG[%#x]%#x\n", FMC_OP_CFG, reg);
+
+		reg = FMC_OP_READ_STATUS_EN | FMC_OP_REG_OP_START;
+		hifmc_writel(host, FMC_OP, reg);
+		FMC_PR(SR_DBG, "\t\t||-Set OP[%#x]%#x\n", FMC_OP, reg);
+
+		FMC_CMD_WAIT_CPU_FINISH(host);
+
+		val = hifmc_readl(host, FMC_STATUS);
+		FMC_PR(SR_DBG, "\t\t|*-End Get Status, result: %#x\n", val);
+
+		return val;
+	}
+
+	FMC_PR(FT_DBG, "\t|||*-Start %s feature, addr[%#x]\n", str[op], addr);
+
+	hifmc100_ecc0_switch(host, ENABLE);
+
+	reg = FMC_CMD_CMD1(op ? SPI_CMD_SET_FEATURE : SPI_CMD_GET_FEATURES);
+	hifmc_writel(host, FMC_CMD, reg);
+	FMC_PR(FT_DBG, "\t||||-Set CMD[%#x]%#x\n", FMC_CMD, reg);
+
+	hifmc_writel(host, FMC_ADDRL, addr);
+	FMC_PR(FT_DBG, "\t||||-Set ADDRL[%#x]%#x\n", FMC_ADDRL, addr);
+
+	reg = OP_CFG_FM_CS(host->cmd_op.cs)
+		| OP_CFG_ADDR_NUM(FEATURES_OP_ADDR_NUM);
+	hifmc_writel(host, FMC_OP_CFG, reg);
+	FMC_PR(FT_DBG, "\t||||-Set OP_CFG[%#x]%#x\n", FMC_OP_CFG, reg);
+
+	reg = FMC_DATA_NUM_CNT(FEATURES_DATA_LEN);
+	hifmc_writel(host, FMC_DATA_NUM, reg);
+	FMC_PR(FT_DBG, "\t||||-Set DATA_NUM[%#x]%#x\n", FMC_DATA_NUM, reg);
+
+	reg = FMC_OP_CMD1_EN
+		| FMC_OP_ADDR_EN
+		| FMC_OP_REG_OP_START;
+
+	if (SET_OP == op) {
+		reg |= FMC_OP_WRITE_DATA_EN;
+		hifmc_writeb(val, host->iobase);
+		FMC_PR(FT_DBG, "\t||||-Write IO[%#lx]%#x\n", (long)host->iobase,
+				*(u_char *)host->iobase);
+	} else
+		reg |= FMC_OP_READ_DATA_EN;
+
+	hifmc_writel(host, FMC_OP, reg);
+	FMC_PR(FT_DBG, "\t||||-Set OP[%#x]%#x\n", FMC_OP, reg);
+
+	FMC_CMD_WAIT_CPU_FINISH(host);
+
+	if (GET_OP == op) {
+		val = hifmc_readb(host->iobase);
+		FMC_PR(FT_DBG, "\t||||-Read IO[%#lx]%#x\n", (long)host->iobase,
+				*(u_char *)host->iobase);
+	}
+
+	hifmc100_ecc0_switch(host, DISABLE);
+
+	FMC_PR(FT_DBG, "\t|||*-End %s Feature[%#x]:%#x\n", str[op], addr, val);
+
+	return val;
+}
+
+/*****************************************************************************/
+/*
+	Read status[C0H]:[0]bit OIP, judge whether the device is busy or not
+*/
+static int spi_general_wait_ready(struct hifmc_spi *spi)
+{
+	unsigned char status;
+	unsigned long deadline = jiffies + FMC_MAX_READY_WAIT_JIFFIES;
+	struct hifmc_host *host = (struct hifmc_host *)spi->host;
+
+	do {
+		status = spi_nand_feature_op(spi, GET_OP, STATUS_ADDR, 0);
+		if (!(status & STATUS_OIP_MASK)) {
+			if ((host->cmd_op.l_cmd == NAND_CMD_ERASE2)
+			    && (status & STATUS_E_FAIL_MASK))
+				return status;
+			if ((host->cmd_op.l_cmd == NAND_CMD_PAGEPROG)
+			    && (status & STATUS_P_FAIL_MASK))
+				return status;
+			return 0;
+		}
+
+		cond_resched();
+
+	} while (!time_after_eq(jiffies, deadline));
+
+	DB_MSG("Error: SPI Nand wait ready timeout, status: %#x\n", status);
+
+	return 1;
+}
+
+/*****************************************************************************/
+/*
+	Send write enable cmd to SPI Nand, status[C0H]:[2]bit WEL must be set 1
+*/
+static int spi_general_write_enable(struct hifmc_spi *spi)
+{
+	unsigned int reg;
+	struct hifmc_host *host = (struct hifmc_host *)spi->host;
+
+	if (WE_DBG)
+		pr_info("\n");
+	FMC_PR(WE_DBG, "\t|*-Start Write Enable\n");
+
+	reg = spi_nand_feature_op(spi, GET_OP, STATUS_ADDR, 0);
+	if (reg & STATUS_WEL_MASK) {
+		FMC_PR(WE_DBG, "\t||-Write Enable was opened! reg: %#x\n",
+				reg);
+		return 0;
+	}
+
+	reg = hifmc_readl(host, FMC_GLOBAL_CFG);
+	FMC_PR(WE_DBG, "\t||-Get GLOBAL_CFG[%#x]%#x\n", FMC_GLOBAL_CFG, reg);
+	if (reg & FMC_GLOBAL_CFG_WP_ENABLE) {
+		reg &= ~FMC_GLOBAL_CFG_WP_ENABLE;
+		hifmc_writel(host, FMC_GLOBAL_CFG, reg);
+		FMC_PR(WE_DBG, "\t||-Set GLOBAL_CFG[%#x]%#x\n",
+				FMC_GLOBAL_CFG, reg);
+	}
+
+	reg = FMC_CMD_CMD1(SPI_CMD_WREN);
+	hifmc_writel(host, FMC_CMD, reg);
+	FMC_PR(WE_DBG, "\t||-Set CMD[%#x]%#x\n", FMC_CMD, reg);
+
+	reg = OP_CFG_FM_CS(host->cmd_op.cs);
+	hifmc_writel(host, FMC_OP_CFG, reg);
+	FMC_PR(WE_DBG, "\t||-Set OP_CFG[%#x]%#x\n", FMC_OP_CFG, reg);
+
+	reg = FMC_OP_CMD1_EN | FMC_OP_REG_OP_START;
+	hifmc_writel(host, FMC_OP, reg);
+	FMC_PR(WE_DBG, "\t||-Set OP[%#x]%#x\n", FMC_OP, reg);
+
+	FMC_CMD_WAIT_CPU_FINISH(host);
+
+#if WE_DBG
+	spi->driver->wait_ready(spi);
+
+	reg = spi_nand_feature_op(spi, GET_OP, STATUS_ADDR, 0);
+	if (reg & STATUS_WEL_MASK)
+		FMC_PR(WE_DBG, "\t||-Write Enable success. reg: %#x\n", reg);
+	else {
+		DB_MSG("Error: Write Enable failed! reg: %#x\n", reg);
+		return reg;
+	}
+#endif
+
+	FMC_PR(WE_DBG, "\t|*-End Write Enable\n");
+	return 0;
+}
+
+/*****************************************************************************/
+/*
+	judge whether SPI Nand support QUAD read/write or not
+*/
+static int spi_is_quad(struct hifmc_spi *spi)
+{
+	const char *if_str[] = {"STD", "DUAL", "DIO", "QUAD", "QIO"};
+
+	FMC_PR(QE_DBG, "\t\t|||*-SPI read iftype: %s write iftype: %s\n",
+		if_str[spi->read->iftype], if_str[spi->write->iftype]);
+
+	if ((IF_TYPE_QUAD == spi->read->iftype)
+	    || (IF_TYPE_QIO == spi->read->iftype)
+	    || (IF_TYPE_QUAD == spi->write->iftype)
+	    || (IF_TYPE_QIO == spi->write->iftype))
+		return 1;
+
+	return 0;
+}
+
+/*****************************************************************************/
+/*
+	Send set features cmd to SPI Nand, feature[B0H]:[0]bit QE would be set
+*/
+static int spi_general_qe_enable(struct hifmc_spi *spi)
+{
+	unsigned int reg, op;
+	const char *str[] = {"Disable", "Enable"};
+
+	FMC_PR(QE_DBG, "\t||*-Start SPI Nand flash QE\n");
+
+	op = spi_is_quad(spi);
+
+	FMC_PR(QE_DBG, "\t|||*-End Quad check, SPI Nand %s Quad.\n", str[op]);
+
+	reg = spi_nand_feature_op(spi, GET_OP, FEATURE_ADDR, 0);
+	FMC_PR(QE_DBG, "\t|||-Get [%#x]feature: %#x\n", FEATURE_ADDR, reg);
+	if ((reg & FEATURE_QE_ENABLE) == op) {
+		FMC_PR(QE_DBG, "\t||*-SPI Nand quad was %sd!\n", str[op]);
+		return op;
+	}
+
+	if (op == ENABLE)
+		reg |= FEATURE_QE_ENABLE;
+	else
+		reg &= ~FEATURE_QE_ENABLE;
+
+	spi_nand_feature_op(spi, SET_OP, FEATURE_ADDR, reg);
+	FMC_PR(QE_DBG, "\t|||-SPI Nand %s Quad\n", str[op]);
+
+	spi->driver->wait_ready(spi);
+
+	reg = spi_nand_feature_op(spi, GET_OP, FEATURE_ADDR, 0);
+	if ((reg & FEATURE_QE_ENABLE) == op)
+		FMC_PR(QE_DBG, "\t|||-SPI Nand %s Quad succeed!\n", str[op]);
+	else
+		DB_MSG("Error: %s Quad failed! reg: %#x\n", str[op], reg);
+
+	FMC_PR(QE_DBG, "\t||*-End SPI Nand %s Quad.\n", str[op]);
+
+	return op;
+}
diff --git a/drivers/mtd/nand/hifmc100/hifmc_spi_nand_ids.c b/drivers/mtd/nand/hifmc100/hifmc_spi_nand_ids.c
new file mode 100644
index 0000000..fc3ec14
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100/hifmc_spi_nand_ids.c
@@ -0,0 +1,1341 @@
+/*
+ * The Flash Memory Controller v100 Device Driver for hisilicon
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+ 
+#include <asm/setup.h>
+#include <linux/types.h>
+#include <linux/io.h>
+#include <linux/sched.h>
+#include <linux/printk.h>
+#include <linux/platform_device.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/partitions.h>
+#include <mach/platform.h>
+#include <linux/mfd/hisi_fmc.h>
+
+#include "../hinfc_gen.h"
+#include "hifmc100.h"
+
+/*****************************************************************************/
+SET_READ_STD(1, INFINITE, 24);
+
+SET_READ_FAST(1, INFINITE, 75);
+SET_READ_FAST(1, INFINITE, 80);
+SET_READ_FAST(1, INFINITE, 104);
+SET_READ_FAST(1, INFINITE, 108);
+SET_READ_FAST(1, INFINITE, 120);
+
+SET_READ_DUAL(1, INFINITE, 75);
+SET_READ_DUAL(1, INFINITE, 80);
+SET_READ_DUAL(1, INFINITE, 104);
+SET_READ_DUAL(1, INFINITE, 108);
+SET_READ_DUAL(1, INFINITE, 120);
+
+SET_READ_DUAL_ADDR(1, INFINITE, 75);
+SET_READ_DUAL_ADDR(1, INFINITE, 80);
+SET_READ_DUAL_ADDR(1, INFINITE, 104);
+SET_READ_DUAL_ADDR(1, INFINITE, 108);
+SET_READ_DUAL_ADDR(1, INFINITE, 120);
+
+SET_READ_QUAD(1, INFINITE, 75);
+SET_READ_QUAD(1, INFINITE, 80);
+SET_READ_QUAD(1, INFINITE, 104);
+SET_READ_QUAD(1, INFINITE, 108);
+SET_READ_QUAD(1, INFINITE, 120);
+
+SET_READ_QUAD_ADDR(1, INFINITE, 75);
+SET_READ_QUAD_ADDR(2, INFINITE, 75);
+SET_READ_QUAD_ADDR(1, INFINITE, 80);
+SET_READ_QUAD_ADDR(2, INFINITE, 80);
+SET_READ_QUAD_ADDR(2, INFINITE, 104);
+SET_READ_QUAD_ADDR(1, INFINITE, 108);
+SET_READ_QUAD_ADDR(1, INFINITE, 120);
+
+/*****************************************************************************/
+SET_WRITE_STD(0, 256, 24);
+SET_WRITE_STD(0, 256, 75);
+SET_WRITE_STD(0, 256, 80);
+SET_WRITE_STD(0, 256, 104);
+
+SET_WRITE_QUAD(0, 256, 75);
+SET_WRITE_QUAD(0, 256, 80);
+SET_WRITE_QUAD(0, 256, 104);
+SET_WRITE_QUAD(0, 256, 108);
+SET_WRITE_QUAD(0, 256, 120);
+
+/*****************************************************************************/
+SET_ERASE_SECTOR_128K(0, _128K, 24);
+SET_ERASE_SECTOR_128K(0, _128K, 75);
+SET_ERASE_SECTOR_128K(0, _128K, 80);
+SET_ERASE_SECTOR_128K(0, _128K, 104);
+
+SET_ERASE_SECTOR_256K(0, _256K, 24);
+SET_ERASE_SECTOR_256K(0, _256K, 75);
+SET_ERASE_SECTOR_256K(0, _256K, 80);
+SET_ERASE_SECTOR_256K(0, _256K, 104);
+
+/*****************************************************************************/
+#include "hifmc100_spi_general.c"
+static struct spi_drv spi_driver_general = {
+	.wait_ready = spi_general_wait_ready,
+	.write_enable = spi_general_write_enable,
+	.qe_enable = spi_general_qe_enable,
+};
+
+/* some spi nand flash default QUAD enable, needn't to set qe enable */
+static struct spi_drv spi_driver_no_qe = {
+	.wait_ready = spi_general_wait_ready,
+	.write_enable = spi_general_write_enable,
+};
+
+/*****************************************************************************/
+#define SPI_NAND_ID_TAB_VER		"2.4"
+
+/******* SPI Nand ID Table ***************************************************
+* Version	Manufacturer	Chip Name	Size		Operation
+* 1.0		ESMT		F50L512M41A	64MB		Add 5 chip
+*		GD		5F1GQ4UAYIG	128MB
+*		GD		5F2GQ4UAYIG	256MB
+*		GD		5F4GQ4UAYIG	512MB
+*		GD		5F4GQ4UBYIG	512MB
+* 1.1		ESMT		F50L1G41A	128MB		Add 2 chip
+*		Winbond		W25N01GV	128MB
+* 1.2		GD		5F1GQ4UBYIG	128MB		Add 2 chip
+*		GD		5F2GQ4UBYIG	256MB
+* 1.3		ATO		ATO25D1GA	128MB		Add 1 chip
+* 1.4		MXIC		MX35LF1GE4AB	128MB		Add 2 chip
+*		MXIC		MX35LF2GE4AB	256MB		(SOP-16Pin)
+* 1.5		Paragon		PN26G01A	128MB		Add 1 chip
+* 1.6		All-flash	AFS1GQ4UAC	128MB		Add 1 chip
+* 1.7		TOSHIBA		TC58CVG0S3H	128MB		Add 2 chip
+*		TOSHIBA		TC58CVG2S0H	512MB
+* 1.8		ALL-flash	AFS2GQ4UAD	256MB		Add 2 chip
+*		Paragon		PN26G02A	256MB
+* 1.9		TOSHIBA		TC58CVG1S3H	256MB		Add 1 chip
+* 2.0		HeYangTek	HYF1GQ4UAACAE	128MB		Add 3 chip
+*		HeYangTek	HYF2GQ4UAACAE	256MB
+*		HeYangTek	HYF4GQ4UAACBE	512MB
+* 2.1		Micron		MT29F1G01ABA	128MB		Add 5 chip
+		Paragon	1.8V	PN26Q01AWSIUG	128MB
+		TOSHIBA 1.8V	TC58CYG0S3H	128MB
+		TOSHIBA 1.8V	TC58CYG1S3H	256MB
+		TOSHIBA 1.8V	TC58CYG2S0H	512MB
+* 2.2		Micron		MT29F2G01ABA	256MB		Add 1 chip
+* 2.3		MXIC		MX35LF2G14AC	256MB		Add 1 chip
+* 2.4	    GD 1.8V		5F4GQ4RAYIG		512MB		Add 1 chip
+******************************************************************************/
+struct spi_nand_info hifmc_spi_nand_flash_table[] = {
+	/* Micron MT29F1G01ABA 1GBit */
+	{
+		.name      = "MT29F1G01ABA",
+		.id        = {0x2C, 0x14},
+		.id_len    = 2,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(2, INFINITE, 80),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 80),
+			&WRITE_QUAD(0, 256, 80),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 80),
+			0
+		},
+		.driver    = &spi_driver_no_qe,
+	},
+
+	/* Micron MT29F2G01ABA 2GBit */
+	{
+		.name      = "MT29F2G01ABA",
+		.id        = {0x2C, 0x24},
+		.id_len    = 2,
+		.chipsize  = _256M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 108),
+			&READ_DUAL(1, INFINITE, 108),
+			&READ_DUAL_ADDR(1, INFINITE, 108),
+			&READ_QUAD(1, INFINITE, 108),
+			&READ_QUAD_ADDR(2, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 80),
+			&WRITE_QUAD(0, 256, 108),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 80),
+			0
+		},
+		.driver    = &spi_driver_no_qe,
+	},
+
+	/* ESMT F50L512M41A 512Mbit */
+	{
+		.name      = "F50L512M41A",
+		.id        = {0xC8, 0x20},
+		.id_len    = 2,
+		.chipsize  = _64M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 64,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_no_qe,
+	},
+
+	/* ESMT F50L1G41A 1Gbit */
+	{
+		.name      = "F50L1G41A",
+		.id        = {0xC8, 0x21},
+		.id_len    = 2,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 64,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_no_qe,
+	},
+
+	/* GD 5F1GQ4UAYIG 1Gbit */
+	{
+		.name      = "5F1GQ4UAYIG",
+		.id        = {0xc8, 0xf1},
+		.id_len    = 2,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 64,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 120),
+			&READ_DUAL(1, INFINITE, 120),
+			&READ_DUAL_ADDR(1, INFINITE, 120),
+			&READ_QUAD(1, INFINITE, 120),
+			&READ_QUAD_ADDR(1, INFINITE, 120),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 120),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* GD 5F1GQ4UBYIG 1Gbit */
+	{
+		.name      = "5F1GQ4UBYIG",
+		.id        = {0xc8, 0xd1},
+		.id_len    = 2,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 120),
+			&READ_DUAL(1, INFINITE, 120),
+			&READ_DUAL_ADDR(1, INFINITE, 120),
+			&READ_QUAD(1, INFINITE, 120),
+			&READ_QUAD_ADDR(1, INFINITE, 120),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 120),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* GD 5F2GQ4UAYIG 2Gbit */
+	{
+		.name      = "5F2GQ4UAYIG",
+		.id        = {0xc8, 0xf2},
+		.id_len    = 2,
+		.chipsize  = _256M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 64,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 120),
+			&READ_DUAL(1, INFINITE, 120),
+			&READ_DUAL_ADDR(1, INFINITE, 120),
+			&READ_QUAD(1, INFINITE, 120),
+			&READ_QUAD_ADDR(1, INFINITE, 120),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 120),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* GD 5F2GQ4UBYIG 2Gbit */
+	{
+		.name      = "5F2GQ4UBYIG",
+		.id        = {0xc8, 0xd2},
+		.id_len    = 2,
+		.chipsize  = _256M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 120),
+			&READ_DUAL(1, INFINITE, 120),
+			&READ_DUAL_ADDR(1, INFINITE, 120),
+			&READ_QUAD(1, INFINITE, 120),
+			&READ_QUAD_ADDR(1, INFINITE, 120),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 120),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* GD 5F4GQ4UAYIG 4Gbit */
+	{
+		.name      = "5F4GQ4UAYIG",
+		.id        = {0xc8, 0xf4},
+		.id_len    = 2,
+		.chipsize  = _512M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 64,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 120),
+			&READ_DUAL(1, INFINITE, 120),
+			&READ_DUAL_ADDR(1, INFINITE, 120),
+			&READ_QUAD(1, INFINITE, 120),
+			&READ_QUAD_ADDR(1, INFINITE, 120),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 120),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* GD 5F4GQ4UBYIG 4Gbit */
+	{
+		.name      = "5F4GQ4UBYIG",
+		.id        = {0xc8, 0xd4},
+		.id_len    = 2,
+		.chipsize  = _512M,
+		.erasesize = _256K,
+		.pagesize  = _4K,
+		.oobsize   = 256,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 120),
+			&READ_DUAL(1, INFINITE, 120),
+			&READ_DUAL_ADDR(1, INFINITE, 120),
+			&READ_QUAD(1, INFINITE, 120),
+			&READ_QUAD_ADDR(1, INFINITE, 120),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 120),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_256K(0, _256K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* GD 1.8V 5F4GQ4RAYIG 4Gbit */
+	{
+		.name      = "5F4GQ4RAYIG",
+		.id        = {0xc8, 0xe4},
+		.id_len    = 2,
+		.chipsize  = _512M,
+		.erasesize = _256K,
+		.pagesize  = _4K,
+		.oobsize   = 256,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 75),
+			&READ_DUAL(1, INFINITE, 75),
+			&READ_DUAL_ADDR(1, INFINITE, 75),
+			&READ_QUAD(1, INFINITE, 75),
+			&READ_QUAD_ADDR(1, INFINITE, 75),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 75),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_256K(0, _256K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* Winbond W25N01GV 1Gbit */
+	{
+		.name      = "W25N01GV",
+		.id        = {0xef, 0xaa, 0x21},
+		.id_len    = 3,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 64,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_DUAL_ADDR(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			&READ_QUAD_ADDR(2, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_no_qe,
+	},
+
+	/* Winbond W25N01GW 1Gbit 1.8V */
+	{
+		.name      = "W25N01GW",
+		.id        = {0xef, 0xba, 0x21},
+		.id_len    = 3,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 64,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 75),
+			&READ_DUAL(1, INFINITE, 75),
+			&READ_DUAL_ADDR(1, INFINITE, 75),
+			&READ_QUAD(1, INFINITE, 75),
+			&READ_QUAD_ADDR(2, INFINITE, 75),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 75),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_no_qe,
+	},
+
+	/* ATO ATO25D1GA 1Gbit */
+	{
+		.name      = "ATO25D1GA",
+		.id        = {0x9b, 0x12},
+		.id_len    = 2,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 64,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* MXIC MX35LF1GE4AB 1Gbit */
+	{
+		.name      = "MX35LF1GE4AB",
+		.id        = {0xc2, 0x12},
+		.id_len    = 2,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 64,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* MXIC MX35LF2GE4AB 2Gbit SOP-16Pin */
+	{
+		.name      = "MX35LF2GE4AB",
+		.id        = {0xc2, 0x22},
+		.id_len    = 2,
+		.chipsize  = _256M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 64,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* MXIC MX35LF2G14AC 2GBit */
+	{
+		.name      = "MX35LF2G14AC",
+		.id        = {0xc2, 0x20},
+		.id_len    = 2,
+		.chipsize  = _256M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 64,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* Paragon PN26G01AWSIUG 1Gbit 1.8V */
+	{
+		.name      = "PN26G01AW",
+		.id        = {0xa1, 0xc1},
+		.id_len    = 2,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 75),
+			&READ_DUAL(1, INFINITE, 75),
+			&READ_DUAL_ADDR(1, INFINITE, 75),
+			&READ_QUAD(1, INFINITE, 75),
+			&READ_QUAD_ADDR(1, INFINITE, 75),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 75),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 75),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* Paragon PN26G01A 1Gbit */
+	{
+		.name      = "PN26G01A",
+		.id        = {0xa1, 0xe1},
+		.id_len    = 2,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 108),
+			&READ_DUAL(1, INFINITE, 108),
+			&READ_DUAL_ADDR(1, INFINITE, 108),
+			&READ_QUAD(1, INFINITE, 108),
+			&READ_QUAD_ADDR(1, INFINITE, 108),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 108),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* Paragon PN26G02A 2Gbit */
+	{
+		.name      = "PN26G02A",
+		.id        = {0xa1, 0xe2},
+		.id_len    = 2,
+		.chipsize  = _256M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 108),
+			&READ_DUAL(1, INFINITE, 108),
+			&READ_DUAL_ADDR(1, INFINITE, 108),
+			&READ_QUAD(1, INFINITE, 108),
+			&READ_QUAD_ADDR(1, INFINITE, 108),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 108),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* All-flash AFS1GQ4UAC 1Gbit */
+	{
+		.name      = "AFS1GQ4UAC",
+		.id        = {0xc1, 0x51},
+		.id_len    = 2,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(1, INFINITE, 80),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 80),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* All-flash AFS2GQ4UAD 2Gbit */
+	{
+		.name      = "AFS2GQ4UAD",
+		.id        = {0xc1, 0x52},
+		.id_len    = 2,
+		.chipsize  = _256M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(1, INFINITE, 80),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 80),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 24),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* TOSHIBA TC58CVG0S3H 1Gbit */
+	{
+		.name      = "TC58CVG0S3H",
+		.id        = {0x98, 0xc2},
+		.id_len    = 2,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 104),
+			0
+		},
+		.driver    = &spi_driver_no_qe,
+	},
+
+	/* TOSHIBA TC58CYG0S3H 1.8V 1Gbit */
+	{
+		.name      = "TC58CYG0S3H",
+		.id        = {0x98, 0xb2},
+		.id_len    = 2,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 75),
+			&READ_DUAL(1, INFINITE, 75),
+			&READ_QUAD(1, INFINITE, 75),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 75),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 75),
+			0
+		},
+		.driver    = &spi_driver_no_qe,
+	},
+
+	/* TOSHIBA TC58CVG1S3H 2Gbit */
+	{
+		.name      = "TC58CVG1S3H",
+		.id        = {0x98, 0xcb},
+		.id_len    = 2,
+		.chipsize  = _256M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 104),
+			0
+		},
+		.driver    = &spi_driver_no_qe,
+	},
+
+	/* TOSHIBA TC58CYG1S3H 1.8V 2Gbit */
+	{
+		.name      = "TC58CYG1S3H",
+		.id        = {0x98, 0xbb},
+		.id_len    = 2,
+		.chipsize  = _256M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 75),
+			&READ_DUAL(1, INFINITE, 75),
+			&READ_QUAD(1, INFINITE, 75),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 75),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 75),
+			0
+		},
+		.driver    = &spi_driver_no_qe,
+	},
+
+	/* TOSHIBA TC58CVG2S0H 4Gbit */
+	{
+		.name      = "TC58CVG2S0H",
+		.id        = {0x98, 0xcd},
+		.id_len    = 2,
+		.chipsize  = _512M,
+		.erasesize = _256K,
+		.pagesize  = _4K,
+		.oobsize   = 256,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_256K(0, _256K, 104),
+			0
+		},
+		.driver    = &spi_driver_no_qe,
+	},
+
+	/* TOSHIBA TC58CYG2S0H 1.8V 4Gbit */
+	{
+		.name      = "TC58CYG2S0H",
+		.id        = {0x98, 0xbd},
+		.id_len    = 2,
+		.chipsize  = _512M,
+		.erasesize = _256K,
+		.pagesize  = _4K,
+		.oobsize   = 256,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 75),
+			&READ_DUAL(1, INFINITE, 75),
+			&READ_QUAD(1, INFINITE, 75),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 75),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_256K(0, _256K, 75),
+			0
+		},
+		.driver    = &spi_driver_no_qe,
+	},
+
+	/* HeYangTek HYF1GQ4UAACAE 1Gbit */
+	{
+		.name      = "HYF1GQ4UAACAE",
+		.id        = {0xc9, 0x51},
+		.id_len    = 2,
+		.chipsize  = _128M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(1, INFINITE, 80),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 80),
+			&WRITE_QUAD(0, 256, 80),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 80),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* HeYangTek HYF2GQ4UAACAE 2Gbit */
+	{
+		.name      = "HYF2GQ4UAACAE",
+		.id        = {0xc9, 0x52},
+		.id_len    = 2,
+		.chipsize  = _256M,
+		.erasesize = _128K,
+		.pagesize  = _2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(1, INFINITE, 80),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 80),
+			&WRITE_QUAD(0, 256, 80),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, _128K, 80),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	/* HeYangTek HYF4GQ4UAACBE 4Gbit */
+	{
+		.name      = "HYF4GQ4UAACBE",
+		.id        = {0xc9, 0xd4},
+		.id_len    = 2,
+		.chipsize  = _512M,
+		.erasesize = _256K,
+		.pagesize  = _4K,
+		.oobsize   = 256,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(1, INFINITE, 80),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 80),
+			&WRITE_QUAD(0, 256, 80),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_256K(0, _256K, 80),
+			0
+		},
+		.driver    = &spi_driver_general,
+	},
+
+	{	.id_len    = 0,	},
+};
+
+/*****************************************************************************/
+static void hifmc100_spi_nand_search_rw(struct spi_nand_info *spiinfo,
+	struct spi_op *spiop_rw, u_int iftype, u_int max_dummy, int rw_type)
+{
+	int ix = 0;
+	struct spi_op **spiop, **fitspiop;
+
+	for (fitspiop = spiop = (rw_type ? spiinfo->write : spiinfo->read);
+		(*spiop) && ix < MAX_SPI_OP; spiop++, ix++) {
+		if (((*spiop)->iftype & iftype)
+			&& ((*spiop)->dummy <= max_dummy)
+			&& (*fitspiop)->iftype < (*spiop)->iftype)
+			fitspiop = spiop;
+	}
+	memcpy(spiop_rw, (*fitspiop), sizeof(struct spi_op));
+}
+
+/*****************************************************************************/
+static void hifmc100_spi_nand_get_erase(struct spi_nand_info *spiinfo,
+		struct spi_op *spiop_erase)
+{
+	int ix;
+
+	spiop_erase->size = 0;
+	for (ix = 0; ix < MAX_SPI_OP; ix++) {
+		if (spiinfo->erase[ix] == NULL)
+			break;
+		if (spiinfo->erasesize == spiinfo->erase[ix]->size) {
+			memcpy(&spiop_erase[ix], spiinfo->erase[ix],
+					sizeof(struct spi_op));
+			break;
+		}
+	}
+}
+
+/*****************************************************************************/
+static void hifmc100_map_spi_op(struct hifmc_spi *spi)
+{
+	unsigned char ix;
+	const int iftype_read[] = {
+		SPI_IF_READ_STD,	IF_TYPE_STD,
+		SPI_IF_READ_FAST,	IF_TYPE_STD,
+		SPI_IF_READ_DUAL,	IF_TYPE_DUAL,
+		SPI_IF_READ_DUAL_ADDR,	IF_TYPE_DIO,
+		SPI_IF_READ_QUAD,	IF_TYPE_QUAD,
+		SPI_IF_READ_QUAD_ADDR,	IF_TYPE_QIO,
+		0,			0,
+	};
+	const int iftype_write[] = {
+		SPI_IF_WRITE_STD,	IF_TYPE_STD,
+		SPI_IF_WRITE_QUAD,	IF_TYPE_QUAD,
+		0,			0,
+	};
+	const char *if_str[] = {"STD", "DUAL", "DIO", "QUAD", "QIO"};
+
+	FMC_PR(BT_DBG, "\t||*-Start Get SPI operation iftype\n");
+
+	for (ix = 0; iftype_write[ix]; ix += 2) {
+		if (spi->write->iftype == iftype_write[ix]) {
+			spi->write->iftype = iftype_write[ix + 1];
+			break;
+		}
+	}
+	FMC_PR(BT_DBG, "\t|||-Get best write iftype: %s \n",
+		if_str[spi->write->iftype]);
+
+	for (ix = 0; iftype_read[ix]; ix += 2) {
+		if (spi->read->iftype == iftype_read[ix]) {
+			spi->read->iftype = iftype_read[ix + 1];
+			break;
+		}
+	}
+	FMC_PR(BT_DBG, "\t|||-Get best read iftype: %s \n",
+		if_str[spi->read->iftype]);
+
+	spi->erase->iftype = IF_TYPE_STD;
+	FMC_PR(BT_DBG, "\t|||-Get best erase iftype: %s \n",
+		if_str[spi->erase->iftype]);
+
+	FMC_PR(BT_DBG, "\t||*-End Get SPI operation iftype \n");
+}
+
+/*****************************************************************************/
+static void hifmc100_spi_ids_probe(struct mtd_info *mtd,
+				struct spi_nand_info *spi_dev)
+{
+	unsigned int reg;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+	struct hifmc_spi *spi = host->spi;
+
+	FMC_PR(BT_DBG, "\t|*-Start match SPI operation & chip init\n");
+
+	spi->host = host;
+	spi->name = spi_dev->name;
+	spi->driver = spi_dev->driver;
+
+	hifmc100_spi_nand_search_rw(spi_dev, spi->read,
+			HIFMC_SPI_NAND_SUPPORT_READ,
+			HIFMC_SPI_NAND_SUPPORT_MAX_DUMMY, RW_OP_READ);
+	FMC_PR(BT_DBG, "\t||-Save spi->read op cmd:%#x\n", spi->read->cmd);
+
+	hifmc100_spi_nand_search_rw(spi_dev, spi->write,
+			HIFMC_SPI_NAND_SUPPORT_WRITE,
+			HIFMC_SPI_NAND_SUPPORT_MAX_DUMMY, RW_OP_WRITE);
+	FMC_PR(BT_DBG, "\t||-Save spi->write op cmd:%#x\n", spi->write->cmd);
+
+	hifmc100_spi_nand_get_erase(spi_dev, spi->erase);
+	FMC_PR(BT_DBG, "\t||-Save spi->erase op cmd:%#x\n", spi->erase->cmd);
+
+	hifmc100_map_spi_op(spi);
+
+	if (spi->driver->qe_enable)
+		spi->driver->qe_enable(spi);
+
+	/* Disable write protection */
+	reg = spi_nand_feature_op(spi, GET_OP, PROTECT_ADDR, 0);
+	FMC_PR(BT_DBG, "\t||-Get protect status[%#x]: %#x\n", PROTECT_ADDR,
+			reg);
+	if (ANY_BP_ENABLE(reg)) {
+		reg &= ~ALL_BP_MASK;
+		spi_nand_feature_op(spi, SET_OP, PROTECT_ADDR, reg);
+		FMC_PR(BT_DBG, "\t||-Set [%#x]FT %#x\n", PROTECT_ADDR, reg);
+
+		spi->driver->wait_ready(spi);
+
+		reg = spi_nand_feature_op(spi, GET_OP, PROTECT_ADDR, 0);
+		FMC_PR(BT_DBG, "\t||-Check BP disable result: %#x\n", reg);
+		if (ANY_BP_ENABLE(reg))
+			DB_MSG("Error: Write protection disable failed!\n");
+	}
+
+	/* Disable chip internal ECC */
+	reg = spi_nand_feature_op(spi, GET_OP, FEATURE_ADDR, 0);
+	FMC_PR(BT_DBG, "\t||-Get feature status[%#x]: %#x\n", FEATURE_ADDR,
+			reg);
+	if (reg & FEATURE_ECC_ENABLE) {
+		reg &= ~FEATURE_ECC_ENABLE;
+		spi_nand_feature_op(spi, SET_OP, FEATURE_ADDR, reg);
+		FMC_PR(BT_DBG, "\t||-Set [%#x]FT: %#x\n", FEATURE_ADDR, reg);
+
+		spi->driver->wait_ready(spi);
+
+		reg = spi_nand_feature_op(spi, GET_OP, FEATURE_ADDR, 0);
+		FMC_PR(BT_DBG, "\t||-Check internal ECC disable result: %#x\n",
+				reg);
+		if (reg & FEATURE_ECC_ENABLE)
+			DB_MSG("Error: Chip internal ECC disable failed!\n");
+	}
+
+	hifmc_cs_user[host->cmd_op.cs]++;
+
+	FMC_PR(BT_DBG, "\t|*-End match SPI operation & chip init\n");
+}
+
+static struct nand_flash_dev spi_nand_dev;
+/*****************************************************************************/
+static struct nand_flash_dev *spi_nand_get_flash_info(struct mtd_info *mtd,
+		unsigned char *id)
+{
+	unsigned char ix, len = 0;
+	char buffer[100];
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+	struct spi_nand_info *spi_dev = hifmc_spi_nand_flash_table;
+	struct nand_flash_dev *type = &spi_nand_dev;
+
+	FMC_PR(BT_DBG, "\t*-Start find SPI Nand flash\n");
+
+	len = sprintf(buffer, "SPI Nand(cs %d) ID: %#x %#x",
+			host->cmd_op.cs, id[0], id[1]);
+
+	for (; spi_dev->id_len; spi_dev++) {
+		if (memcmp(id, spi_dev->id, spi_dev->id_len))
+			continue;
+
+		for (ix = 2; ix < spi_dev->id_len; ix++)
+			len += sprintf(buffer + len, " %#x", id[ix]);
+		pr_info("%s\n", buffer);
+
+		FMC_PR(BT_DBG, "\t||-CS(%d) found SPI Nand: %s\n",
+				host->cmd_op.cs, spi_dev->name);
+
+		type->name = spi_dev->name;
+		memcpy(type->id, spi_dev->id, spi_dev->id_len);
+		type->pagesize = spi_dev->pagesize;
+		type->chipsize = spi_dev->chipsize >> 20;
+		type->erasesize = spi_dev->erasesize;
+		type->id_len = spi_dev->id_len;
+		type->oobsize = spi_dev->oobsize;
+		FMC_PR(BT_DBG, "\t|-Save struct nand_flash_dev info\n");
+
+		mtd->oobsize = spi_dev->oobsize;
+		mtd->erasesize = spi_dev->erasesize;
+		mtd->writesize = spi_dev->pagesize;
+		chip->chipsize = spi_dev->chipsize;
+
+		hifmc100_spi_ids_probe(mtd, spi_dev);
+
+		FMC_PR(BT_DBG, "\t*-Found SPI nand: %s\n", spi_dev->name);
+
+		return type;
+	}
+
+	FMC_PR(BT_DBG, "\t*-Not found SPI nand flash, %s\n", buffer);
+
+	return NULL;
+}
+
+/*****************************************************************************/
+void hifmc_spi_nand_ids_register(void)
+{
+	pr_info("SPI Nand ID Table Version %s\n", SPI_NAND_ID_TAB_VER);
+	get_spi_nand_flash_type_hook = spi_nand_get_flash_info;
+}
+
+#ifdef CONFIG_PM
+/*****************************************************************************/
+void hifmc100_spi_nand_config(struct hifmc_host *host)
+{
+	unsigned int reg;
+	struct hifmc_spi *spi = host->spi;
+	static const char const *str[] = {"STD", "DUAL", "DIO", "QUAD", "QIO"};
+
+	/* judge whether support QUAD read/write or not, set it if yes */
+	FMC_PR(PM_DBG, "\t|-SPI read iftype: %s write iftype: %s\n",
+		str[spi->read->iftype], str[spi->write->iftype]);
+
+	if (spi->driver->qe_enable)
+		spi->driver->qe_enable(spi);
+
+	/* Disable write protection */
+	reg = spi_nand_feature_op(spi, GET_OP, PROTECT_ADDR, 0);
+	FMC_PR(PM_DBG, "\t|-Get protect status[%#x]: %#x\n", PROTECT_ADDR,
+			reg);
+	if (ANY_BP_ENABLE(reg)) {
+		reg &= ~ALL_BP_MASK;
+		spi_nand_feature_op(spi, SET_OP, PROTECT_ADDR, reg);
+		FMC_PR(PM_DBG, "\t|-Set [%#x]FT %#x\n", PROTECT_ADDR, reg);
+
+		spi->driver->wait_ready(spi);
+
+		reg = spi_nand_feature_op(spi, GET_OP, PROTECT_ADDR, 0);
+		FMC_PR(PM_DBG, "\t|-Check BP disable result: %#x\n", reg);
+		if (ANY_BP_ENABLE(reg))
+			DB_MSG("Error: Write protection disable failed!\n");
+	}
+
+	/* Disable chip internal ECC */
+	reg = spi_nand_feature_op(spi, GET_OP, FEATURE_ADDR, 0);
+	FMC_PR(PM_DBG, "\t|-Get feature status[%#x]: %#x\n", FEATURE_ADDR,
+			reg);
+	if (reg & FEATURE_ECC_ENABLE) {
+		reg &= ~FEATURE_ECC_ENABLE;
+		spi_nand_feature_op(spi, SET_OP, FEATURE_ADDR, reg);
+		FMC_PR(PM_DBG, "\t|-Set [%#x]FT: %#x\n", FEATURE_ADDR, reg);
+
+		spi->driver->wait_ready(spi);
+
+		reg = spi_nand_feature_op(spi, GET_OP, FEATURE_ADDR, 0);
+		FMC_PR(PM_DBG, "\t|-Check internal ECC disable result: %#x\n",
+				reg);
+		if (reg & FEATURE_ECC_ENABLE)
+			DB_MSG("Error: Chip internal ECC disable failed!\n");
+	}
+}
+/*****************************************************************************/
+#endif /* CONFIG_PM */
diff --git a/drivers/mtd/nand/hifmc100_nand/Kconfig b/drivers/mtd/nand/hifmc100_nand/Kconfig
new file mode 100644
index 0000000..7775208
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100_nand/Kconfig
@@ -0,0 +1,50 @@
+#
+# drivers/mtd/nand/hifmc100_nand/Kconfig
+# add by hisilicon 2017.10.26
+#
+
+menuconfig MTD_NAND_HIFMC100
+	bool "Hisilicon Flash Memory Controller v100 Nand devices support"
+	depends on MFD_HISI_FMC && !MTD_SPI_NAND_HISI_BVT
+	select MISC_FILESYSTEMS
+	select MTD_BLOCK
+	select YAFFS_FS
+	select YAFFS_YAFFS2
+	help
+	  Hisilicon Flash Memory Controller version 100 is called hifmc100 for
+	  short. The controller support DMA transfers while reading or writing
+	  the Nand flash.
+
+if MTD_NAND_HIFMC100
+
+config HIFMC100_NAND_EDO_MODE
+	bool "the Extended Data Out(EDO) mode"
+	help
+	  In Extended data out (EDO), a new data cycle is started while the data
+	  output of the previous cycle is still active. This process of cycle
+	  overlapping, called pipelining, increases processing speed by about
+	  10 nanoseconds per cycle,increasing computer performance by about 5
+	  percent compared to performance using FMP.
+
+config RW_H_WIDTH
+	int "the width of Read/Write HIGH Hold Time (0 to 15)"
+	range 0 15
+	default 10 if ARCH_HI3559AV100
+	help
+	  the Read/Write HIGH Hold Time of nand flash
+
+config R_L_WIDTH
+	int "the Read pulse width (0 to 15)"
+	range 0 15
+	default 10 if ARCH_HI3559AV100
+	help
+	  the Read/Write LOW Hold Time of nand flash
+
+config W_L_WIDTH
+	int "the Write pulse width (0 to 15)"
+	range 0 15
+	default 10 if ARCH_HI3559AV100
+	help
+	  the Read/Write LOW Hold Time of nand flash
+
+endif # End of MTD_NAND_HIFMC100
diff --git a/drivers/mtd/nand/hifmc100_nand/Makefile b/drivers/mtd/nand/hifmc100_nand/Makefile
new file mode 100644
index 0000000..623363c
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100_nand/Makefile
@@ -0,0 +1,26 @@
+#
+# The Flash Memory Controller v100 Device Driver for hisilicon
+#
+# Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+#
+# This program is free software; you can redistribute  it and/or modify it
+# under  the terms of  the GNU General  Public License as published by the
+# Free Software Foundation;  either version 2 of the  License, or (at your
+# option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+# GNU General Public License for more details.
+#
+# You should have received a copy of the GNU General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+#
+#
+
+#
+# drivers/mtd/nand/hifmc100_nand/Makefile
+#
+
+obj-y	+= hifmc_nand_spl_ids.o
+obj-y	+= hifmc100_nand.o hifmc100_nand_os.o
diff --git a/drivers/mtd/nand/hifmc100_nand/hifmc100_nand.c b/drivers/mtd/nand/hifmc100_nand/hifmc100_nand.c
new file mode 100644
index 0000000..54dddeb
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100_nand/hifmc100_nand.c
@@ -0,0 +1,1127 @@
+/*
+ * The Flash Memory Controller v100 Device Driver for hisilicon
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+ 
+#include <linux/io.h>
+#include <linux/compiler.h>
+#include <linux/delay.h>
+#include <linux/printk.h>
+#include <linux/clk.h>
+#include <linux/mfd/hisi_fmc.h>
+
+#include "../hinfc_gen.h"
+#include "hifmc100_nand_os.h"
+#include "hifmc100_nand.h"
+
+#include <mach/platform.h>
+/*****************************************************************************/
+static void hifmc100_dma_transfer(struct hifmc_host *host, int todev)
+{
+	unsigned int reg = (unsigned int)host->dma_buffer;
+	char *op = todev ? "write" : "read";
+
+	FMC_PR(DMA_DB, "\t\t *-Start %s page dma transfer\n", op);
+
+	hifmc_writel(host, FMC_DMA_SADDR_D0, reg);
+	FMC_PR(DMA_DB, "\t\t |-Set ADDR0[%#x]%#x\n", FMC_DMA_SADDR_D0, reg);
+
+#ifdef CONFIG_64BIT
+	reg = (host->dma_buffer & FMC_DMA_SADDRH_MASK) >> 32;
+	hifmc_writel(host, FMC_DMA_SADDRH_D0, reg);
+	FMC_PR(DMA_DB, "\t\t |-Set ADDRH0[%#x]%#x\n", FMC_DMA_SADDRH_D0, reg);
+#endif
+	
+	reg += FMC_DMA_ADDR_OFFSET;
+	hifmc_writel(host, FMC_DMA_SADDR_D1, reg);
+	FMC_PR(DMA_DB, "\t\t |-Set ADDR1[%#x]%#x\n", FMC_DMA_SADDR_D1, reg);
+
+	reg += FMC_DMA_ADDR_OFFSET;
+	hifmc_writel(host, FMC_DMA_SADDR_D2, reg);
+	FMC_PR(DMA_DB, "\t\t |-Set ADDR2[%#x]%#x\n", FMC_DMA_SADDR_D2, reg);
+
+	reg += FMC_DMA_ADDR_OFFSET;
+	hifmc_writel(host, FMC_DMA_SADDR_D3, reg);
+	FMC_PR(DMA_DB, "\t\t |-Set ADDR3[%#x]%#x\n", FMC_DMA_SADDR_D3, reg);
+
+	reg = host->dma_oob;
+	hifmc_writel(host, FMC_DMA_SADDR_OOB, reg);
+	FMC_PR(DMA_DB, "\t\t |-Set OOB[%#x]%#x\n", FMC_DMA_SADDR_OOB, reg);
+
+#ifdef CONFIG_64BIT
+	reg = (host->dma_oob & FMC_DMA_SADDRH_MASK) >> 32;
+	hifmc_writel(host, FMC_DMA_SADDRH_OOB, reg);
+	FMC_PR(DMA_DB, "\t\t |-Set ADDRH0[%#x]%#x\n", FMC_DMA_SADDRH_OOB, reg);
+#endif
+	
+	if (host->ecctype == NAND_ECC_0BIT) {
+		hifmc_writel(host, FMC_DMA_LEN, FMC_DMA_LEN_SET(host->oobsize));
+		FMC_PR(DMA_DB, "\t\t |-Set LEN[%#x]%#x\n", FMC_DMA_LEN, reg);
+	}
+	reg = FMC_OP_READ_DATA_EN | FMC_OP_WRITE_DATA_EN;
+	hifmc_writel(host, FMC_OP, reg);
+	FMC_PR(DMA_DB, "\t\t |-Set OP[%#x]%#x\n", FMC_OP, reg);
+
+	reg = FMC_DMA_AHB_CTRL_DMA_PP_EN
+		| FMC_DMA_AHB_CTRL_BURST16_EN
+		| FMC_DMA_AHB_CTRL_BURST8_EN
+		| FMC_DMA_AHB_CTRL_BURST4_EN;
+	hifmc_writel(host, FMC_DMA_AHB_CTRL, reg);
+	FMC_PR(DMA_DB, "\t\t |-Set AHBCTRL[%#x]%#x\n", FMC_DMA_AHB_CTRL, reg);
+
+	reg = OP_CFG_FM_CS(host->cmd_op.cs)
+		| OP_CFG_ADDR_NUM(host->addr_cycle);
+	hifmc_writel(host, FMC_OP_CFG, reg);
+	FMC_PR(DMA_DB, "\t\t |-Set OP_CFG[%#x]%#x\n", FMC_OP_CFG, reg);
+
+	reg = OP_CTRL_DMA_OP_READY;
+	if (todev)
+		reg |= OP_CTRL_RW_OP(todev);
+	hifmc_writel(host, FMC_OP_CTRL, reg);
+	FMC_PR(DMA_DB, "\t\t |-Set OP_CTRL[%#x]%#x\n", FMC_OP_CTRL, reg);
+
+	FMC_DMA_WAIT_CPU_FINISH(host);
+
+	FMC_PR(DMA_DB, "\t\t *-End %s page dma transfer\n", op);
+
+	return;
+}
+
+/*****************************************************************************/
+static void hifmc100_send_cmd_write(struct hifmc_host *host)
+{
+	unsigned int reg;
+
+	FMC_PR(WR_DBG, "\t|*-Start send page programme cmd\n");
+
+	if (*host->bbm != 0xFF && *host->bbm != 0x00)
+		pr_info("WARNING: attempt to write an invalid bbm. " \
+				"page: 0x%08x, mark: 0x%02x,\n",
+				GET_PAGE_INDEX(host), *host->bbm);
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	reg = host->addr_value[1];
+	hifmc_writel(host, FMC_ADDRH, reg);
+	FMC_PR(WR_DBG, "\t||-Set ADDRH[%#x]%#x\n", FMC_ADDRH, reg);
+
+	reg = host->addr_value[0] & 0xffff0000;
+	hifmc_writel(host, FMC_ADDRL, reg);
+	FMC_PR(WR_DBG, "\t||-Set ADDRL[%#x]%#x\n", FMC_ADDRL, reg);
+
+	reg = FMC_CMD_CMD2(NAND_CMD_PAGEPROG) | FMC_CMD_CMD1(NAND_CMD_SEQIN);
+	hifmc_writel(host, FMC_CMD, reg);
+	FMC_PR(WR_DBG, "\t||-Set CMD[%#x]%#x\n", FMC_CMD, reg);
+
+	*host->epm = 0x0000;
+
+	hifmc100_dma_transfer(host, RW_OP_WRITE);
+
+	FMC_PR(WR_DBG, "\t|*-End send page read cmd\n");
+}
+
+/*****************************************************************************/
+static void hifmc100_send_cmd_read(struct hifmc_host *host)
+{
+	unsigned int reg;
+
+	FMC_PR(RD_DBG, "\t*-Start send page read cmd\n");
+
+	if ((host->addr_value[0] == host->cache_addr_value[0])
+		&& (host->addr_value[1] == host->cache_addr_value[1])) {
+		FMC_PR(RD_DBG, "\t*-Cache hit! addr1[%#x], addr0[%#x]\n",
+			host->addr_value[1], host->addr_value[0]);
+		return;
+	}
+
+	host->page_status = 0;
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	reg = FMC_INT_CLR_ALL;
+	hifmc_writel(host, FMC_INT_CLR, reg);
+	FMC_PR(RD_DBG, "\t|-Set INT_CLR[%#x]%#x\n", FMC_INT_CLR, reg);
+
+	reg = host->nand_cfg;
+	hifmc_writel(host, FMC_CFG, reg);
+	FMC_PR(RD_DBG, "\t|-Set CFG[%#x]%#x\n", FMC_CFG, reg);
+
+	reg = host->addr_value[1];
+	hifmc_writel(host, FMC_ADDRH, reg);
+	FMC_PR(RD_DBG, "\t|-Set ADDRH[%#x]%#x\n", FMC_ADDRH, reg);
+
+	reg = host->addr_value[0] & 0xffff0000;
+	hifmc_writel(host, FMC_ADDRL, reg);
+	FMC_PR(RD_DBG, "\t|-Set ADDRL[%#x]%#x\n", FMC_ADDRL, reg);
+
+	reg = FMC_CMD_CMD2(NAND_CMD_READSTART) | FMC_CMD_CMD1(NAND_CMD_READ0);
+	hifmc_writel(host, FMC_CMD, reg);
+	FMC_PR(RD_DBG, "\t|-Set CMD[%#x]%#x\n", FMC_CMD, reg);
+
+	hifmc100_dma_transfer(host, RW_OP_READ);
+
+	if (hifmc_readl(host, FMC_INT) & FMC_INT_ERR_INVALID)
+		host->page_status |= HIFMC100_PS_UC_ECC;
+
+	host->cache_addr_value[0] = host->addr_value[0];
+	host->cache_addr_value[1] = host->addr_value[1];
+
+	FMC_PR(RD_DBG, "\t*-End send page read cmd\n");
+}
+
+/*****************************************************************************/
+static void hifmc100_send_cmd_erase(struct hifmc_host *host)
+{
+	unsigned int reg;
+
+	FMC_PR(ER_DBG, "\t *-Start send cmd erase\n");
+
+	/* Don't case the read retry config */
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	reg = host->addr_value[0];
+	hifmc_writel(host, FMC_ADDRL, reg);
+	FMC_PR(ER_DBG, "\t |-Set ADDRL[%#x]%#x\n", FMC_ADDRL, reg);
+
+	reg = FMC_CMD_CMD2(NAND_CMD_ERASE2) | FMC_CMD_CMD1(NAND_CMD_ERASE1);
+	hifmc_writel(host, FMC_CMD, reg);
+	FMC_PR(ER_DBG, "\t |-Set CMD[%#x]%#x\n", FMC_CMD, reg);
+
+	reg = OP_CFG_FM_CS(host->cmd_op.cs)
+		| OP_CFG_ADDR_NUM(host->addr_cycle);
+	hifmc_writel(host, FMC_OP_CFG, reg);
+	FMC_PR(ER_DBG, "\t |-Set OP_CFG[%#x]%#x\n", FMC_OP_CFG, reg);
+
+	/* need to config WAIT_READY_EN */
+	reg = FMC_OP_WAIT_READY_EN
+		| FMC_OP_CMD1_EN
+		| FMC_OP_CMD2_EN
+		| FMC_OP_ADDR_EN
+		| FMC_OP_REG_OP_START;
+	hifmc_writel(host, FMC_OP, reg);
+	FMC_PR(ER_DBG, "\t |-Set OP[%#x]%#x\n", FMC_OP, reg);
+
+	FMC_CMD_WAIT_CPU_FINISH(host);
+
+	FMC_PR(ER_DBG, "\t |*-End send cmd erase\n");
+}
+
+/*****************************************************************************/
+static void hifmc100_ecc_randomizer(struct hifmc_host *host, int ecc_en,
+		int randomizer_en)
+{
+	unsigned int old_reg, reg, change = 0;
+	char *ecc_op = ecc_en ? "Quit" : "Enter";
+	char *rand_op = randomizer_en ? "Enable" : "Disable";
+
+	if (IS_NAND_RANDOM(host)) {
+		reg = old_reg = hifmc_readl(host, FMC_GLOBAL_CFG);
+		if (randomizer_en)
+			reg |= FMC_GLOBAL_CFG_RANDOMIZER_EN;
+		else
+			reg &= ~FMC_GLOBAL_CFG_RANDOMIZER_EN;
+
+		if (old_reg != reg) {
+			FMC_PR(EC_DBG, "\t |*-Start %s randomizer\n", rand_op);
+			FMC_PR(EC_DBG, "\t ||-Get global CFG[%#x]%#x\n",
+					FMC_GLOBAL_CFG, old_reg);
+			hifmc_writel(host, FMC_GLOBAL_CFG, reg);
+			FMC_PR(EC_DBG, "\t ||-Set global CFG[%#x]%#x\n",
+					FMC_GLOBAL_CFG, reg);
+			change++;
+		}
+	}
+
+	old_reg = hifmc_readl(host, FMC_CFG);
+	reg = (ecc_en ? host->nand_cfg : host->nand_cfg_ecc0);
+
+	if (old_reg != reg) {
+		FMC_PR(EC_DBG, "\t |%s-Start %s ECC0 mode\n", change ? "|":"*",
+				ecc_op);
+		FMC_PR(EC_DBG, "\t ||-Get CFG[%#x]%#x\n", FMC_CFG, old_reg);
+		hifmc_writel(host, FMC_CFG, reg);
+		FMC_PR(EC_DBG, "\t ||-Set CFG[%#x]%#x\n", FMC_CFG, reg);
+		change++;
+	}
+
+	if (EC_DBG && change)
+		FMC_PR(EC_DBG, "\t |*-End randomizer and ECC0 mode config\n");
+}
+
+/*****************************************************************************/
+static void hifmc100_send_cmd_status(struct hifmc_host *host)
+{
+	unsigned int regval;
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	regval = OP_CFG_FM_CS(host->cmd_op.cs);
+	hifmc_writel(host, FMC_OP_CFG, regval);
+
+	regval = FMC_OP_READ_STATUS_EN | FMC_OP_REG_OP_START;
+	hifmc_writel(host, FMC_OP, regval);
+
+	FMC_CMD_WAIT_CPU_FINISH(host);
+}
+
+/*****************************************************************************/
+static void hifmc100_send_cmd_readid(struct hifmc_host *host)
+{
+	unsigned int reg;
+
+	FMC_PR(BT_DBG, "\t *-Start read nand flash ID\n");
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	reg = FMC_DATA_NUM_CNT(host->cmd_op.data_no);
+	hifmc_writel(host, FMC_DATA_NUM, reg);
+	FMC_PR(BT_DBG, "\t |-Set DATA_NUM[%#x]%#x\n", FMC_DATA_NUM, reg);
+
+	reg = FMC_CMD_CMD1(NAND_CMD_READID);
+	hifmc_writel(host, FMC_CMD, reg);
+	FMC_PR(BT_DBG, "\t |-Set CMD[%#x]%#x\n", FMC_CMD, reg);
+
+	reg = 0;
+	hifmc_writel(host, FMC_ADDRL, reg);
+	FMC_PR(BT_DBG, "\t |-Set ADDRL[%#x]%#x\n", FMC_ADDRL, reg);
+
+	reg = OP_CFG_FM_CS(host->cmd_op.cs)
+		| OP_CFG_ADDR_NUM(READ_ID_ADDR_NUM);
+	hifmc_writel(host, FMC_OP_CFG, reg);
+	FMC_PR(BT_DBG, "\t |-Set OP_CFG[%#x]%#x\n", FMC_OP_CFG, reg);
+
+	reg = FMC_OP_CMD1_EN
+		| FMC_OP_ADDR_EN
+		| FMC_OP_READ_DATA_EN
+		| FMC_OP_REG_OP_START;
+	hifmc_writel(host, FMC_OP, reg);
+	FMC_PR(BT_DBG, "\t |-Set OP[%#x]%#x\n", FMC_OP, reg);
+
+	host->addr_cycle = 0x0;
+
+	FMC_CMD_WAIT_CPU_FINISH(host);
+
+	FMC_PR(BT_DBG, "\t *-End read nand flash ID\n");
+}
+
+/*****************************************************************************/
+static void hifmc100_send_cmd_reset(struct hifmc_host *host)
+{
+	unsigned int reg;
+
+	FMC_PR(BT_DBG, "\t *-Start reset nand flash\n");
+
+	reg = FMC_CMD_CMD1(NAND_CMD_RESET);
+	hifmc_writel(host, FMC_CMD, reg);
+	FMC_PR(BT_DBG, "\t |-Set CMD[%#x]%#x\n", FMC_CMD, reg);
+
+	reg = OP_CFG_FM_CS(host->cmd_op.cs);
+	hifmc_writel(host, FMC_OP_CFG, reg);
+	FMC_PR(BT_DBG, "\t |-Set OP_CFG[%#x]%#x\n", FMC_OP_CFG, reg);
+
+	reg = FMC_OP_CMD1_EN
+		| FMC_OP_WAIT_READY_EN
+		| FMC_OP_REG_OP_START;
+	hifmc_writel(host, FMC_OP, reg);
+	FMC_PR(BT_DBG, "\t |-Set OP[%#x]%#x\n", FMC_OP, reg);
+
+	FMC_CMD_WAIT_CPU_FINISH(host);
+
+	FMC_PR(BT_DBG, "\t *-End reset nand flash\n");
+}
+
+/*****************************************************************************/
+static unsigned char hifmc100_read_byte(struct mtd_info *mtd)
+{
+	unsigned char value = 0;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+	if (host->cmd_op.l_cmd == NAND_CMD_READID) {
+		value = hifmc_readb((void __iomem *)(chip->IO_ADDR_R + host->offset));
+		host->offset++;
+		if (host->cmd_op.data_no == host->offset)
+			host->cmd_op.l_cmd = 0;
+		return value;
+	}
+
+	if (host->cmd_op.cmd == NAND_CMD_STATUS) {
+		value = hifmc_readl(host, FMC_STATUS);
+		if (host->cmd_op.l_cmd == NAND_CMD_ERASE1)
+			FMC_PR(ER_DBG, "\t*-Erase WP status: %#x\n", value);
+		if (host->cmd_op.l_cmd == NAND_CMD_PAGEPROG)
+			FMC_PR(WR_DBG, "\t*-Write WP status: %#x\n", value);
+		return value;
+	}
+
+	if (host->cmd_op.l_cmd == NAND_CMD_READOOB) {
+		value = hifmc_readb((void __iomem *)(host->buffer + host->pagesize
+					+ host->offset));
+		host->offset++;
+		return value;
+	}
+
+	host->offset++;
+
+	return hifmc_readb((void __iomem *)(host->buffer + host->column \
+				+ host->offset - 1));
+}
+
+/*****************************************************************************/
+static unsigned short hifmc100_read_word(struct mtd_info *mtd)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+	host->offset += 2;
+	return hifmc_readw(host->buffer + host->column + host->offset - 2);
+}
+
+/*****************************************************************************/
+static void hifmc100_write_buf(struct mtd_info *mtd,
+	const u_char *buf, int len)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+#ifdef HIFMC100_NAND_SUPPORT_REG_WRITE
+	if (buf == chip->oob_poi)
+		memcpy((char *)host->iobase + host->pagesize, buf, len);
+	else
+		memcpy((char *)host->iobase, buf, len);
+#else
+	if (buf == chip->oob_poi)
+		memcpy((char *)host->buffer + host->pagesize, buf, len);
+	else
+		memcpy((char *)host->buffer, buf, len);
+#endif
+	return;
+}
+
+/*****************************************************************************/
+static void hifmc100_ecc_err_num_count(struct mtd_info *mtd,
+			u_int ecc_st, u_int reg)
+{
+	u_char err_num;
+
+	if (ecc_st > 4)
+		ecc_st = 4;
+
+	while (ecc_st) {
+		err_num = GET_ECC_ERR_NUM(--ecc_st, reg);
+		if (err_num == 0xff)
+			mtd->ecc_stats.failed++;
+		else
+			mtd->ecc_stats.corrected += err_num;
+	}
+}
+
+/*****************************************************************************/
+static void hifmc100_read_buf(struct mtd_info *mtd, u_char *buf, int len)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+#ifdef HIFMC100_NAND_SUPPORT_REG_READ
+	if (buf == chip->oob_poi)
+		memcpy(buf, (char *)host->iobase + host->pagesize, len);
+	else
+		memcpy(buf, (char *)host->iobase, len);
+#else
+	if (buf == chip->oob_poi)
+		memcpy(buf, (char *)host->buffer + host->pagesize, len);
+	else
+		memcpy(buf, (char *)host->buffer, len);
+#endif
+	if (buf != chip->oob_poi) {
+		u_int reg, ecc_step = host->pagesize >> 10;
+
+		/* 2K or 4K or 8K(1) or 16K(1-1) pagesize */
+		reg = hifmc_readl(host, HIFMC100_ECC_ERR_NUM0_BUF0);
+		hifmc100_ecc_err_num_count(mtd, ecc_step, reg);
+
+		if (ecc_step > 4) {
+			/* 8K(2) or 16K(1-2) pagesize */
+			reg = hifmc_readl(host, HIFMC100_ECC_ERR_NUM1_BUF0);
+			hifmc100_ecc_err_num_count(mtd, ecc_step, reg);
+			if (ecc_step > 8) {
+				/* 16K(2-1) pagesize */
+				reg = hifmc_readl(host,
+						HIFMC100_ECC_ERR_NUM0_BUF1);
+				hifmc100_ecc_err_num_count(mtd, ecc_step, reg);
+				/* 16K(2-2) pagesize */
+				reg = hifmc_readl(host,
+						HIFMC100_ECC_ERR_NUM1_BUF1);
+				hifmc100_ecc_err_num_count(mtd, ecc_step, reg);
+			}
+		}
+	}
+
+	return;
+}
+
+/*****************************************************************************/
+static void hifmc100_select_chip(struct mtd_info *mtd, int chipselect)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+	if (chipselect < 0)
+		return;
+
+	if (chipselect > CONFIG_HIFMC100_MAX_NAND_CHIP)
+		DB_BUG("Error: Invalid chip select: %d\n", chipselect);
+
+	host->cmd_op.cs = chipselect;
+	if (host->mtd != mtd)
+		host->mtd = mtd;
+
+	switch (chip->state) {
+	case FL_ERASING:
+		host->cmd_op.l_cmd = NAND_CMD_ERASE1;
+		if (ER_DBG)
+			pr_info("\n");
+		FMC_PR(ER_DBG, "\t*-Erase chip: %d\n", chipselect);
+		break;
+	case FL_WRITING:
+		host->cmd_op.l_cmd = NAND_CMD_PAGEPROG;
+		if (WR_DBG)
+			pr_info("\n");
+		FMC_PR(WR_DBG, "\t*-Write chip: %d\n", chipselect);
+		break;
+	case FL_READING:
+		host->cmd_op.l_cmd = NAND_CMD_READ0;
+		if (RD_DBG)
+			pr_info("\n");
+		FMC_PR(RD_DBG, "\t*-Read chip: %d\n", chipselect);
+		break;
+	default:
+		break;
+	}
+}
+
+/*****************************************************************************/
+static void hifmc100_cmd_ctrl(struct mtd_info *mtd, int dat, unsigned ctrl)
+{
+	unsigned char cmd;
+	int is_cache_invalid = 1;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+
+	if (ctrl & NAND_ALE) {
+		unsigned int addr_value = 0;
+		unsigned int addr_offset = 0;
+
+		if (ctrl & NAND_CTRL_CHANGE) {
+			host->addr_cycle = 0x0;
+			host->addr_value[0] = 0x0;
+			host->addr_value[1] = 0x0;
+		}
+		addr_offset = host->addr_cycle << 3;
+
+		if (host->addr_cycle >= HIFMC100_ADDR_CYCLE_MASK) {
+			addr_offset = (host->addr_cycle -
+					HIFMC100_ADDR_CYCLE_MASK) << 3;
+			addr_value = 1;
+		}
+
+		host->addr_value[addr_value] |=
+			((dat & 0xff) << addr_offset);
+
+		host->addr_cycle++;
+	}
+
+	if ((ctrl & NAND_CLE) && (ctrl & NAND_CTRL_CHANGE)) {
+		cmd = dat & 0xff;
+		host->cmd_op.cmd = cmd;
+		switch (cmd) {
+		case NAND_CMD_PAGEPROG:
+			host->offset = 0;
+			host->send_cmd_pageprog(host);
+			break;
+
+		case NAND_CMD_READSTART:
+			is_cache_invalid = 0;
+			if (host->addr_value[0] == host->pagesize)
+				host->cmd_op.l_cmd = NAND_CMD_READOOB;
+			host->send_cmd_readstart(host);
+			break;
+
+		case NAND_CMD_ERASE2:
+			host->cmd_op.l_cmd = cmd;
+			host->send_cmd_erase(host);
+			break;
+
+		case NAND_CMD_READID:
+			memset((u_char *)(chip->IO_ADDR_R), 0, MAX_NAND_ID_LEN);
+			host->cmd_op.l_cmd = cmd;
+			host->cmd_op.data_no = MAX_NAND_ID_LEN;
+			host->send_cmd_readid(host);
+			break;
+
+		case NAND_CMD_STATUS:
+			host->send_cmd_status(host);
+			break;
+
+		case NAND_CMD_READ0:
+			host->cmd_op.l_cmd = cmd;
+			break;
+
+		case NAND_CMD_RESET:
+			host->send_cmd_reset(host);
+			break;
+
+		case NAND_CMD_SEQIN:
+		case NAND_CMD_ERASE1:
+		default:
+			break;
+		}
+	}
+
+	/* pass pagesize and ecctype to kernel when startup. */
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	if ((dat == NAND_CMD_NONE) && host->addr_cycle) {
+		if (host->cmd_op.cmd == NAND_CMD_SEQIN
+			|| host->cmd_op.cmd == NAND_CMD_READ0
+			|| host->cmd_op.cmd == NAND_CMD_READID) {
+			host->offset = 0x0;
+			host->column = (host->addr_value[0] & 0xffff);
+		}
+	}
+
+	if (is_cache_invalid) {
+		host->cache_addr_value[0] = ~0;
+		host->cache_addr_value[1] = ~0;
+	}
+}
+
+/*****************************************************************************/
+static int hifmc100_dev_ready(struct mtd_info *mtd)
+{
+	return 0x1;
+}
+
+/*****************************************************************************/
+/*
+ * 'host->epm' only use the first oobfree[0] field, it looks very simple, But...
+ */
+static int hifmc_ooblayout_ecc_default(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 32;
+	oobregion->offset = 32;
+
+	return 0;
+}
+
+static int hifmc_ooblayout_free_default(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 30;
+	oobregion->offset = 2;
+
+	return 0;
+}
+
+static struct mtd_ooblayout_ops hifmc_ooblayout_default_ops = {
+	.ecc = hifmc_ooblayout_ecc_default,
+	.free = hifmc_ooblayout_free_default,
+};
+
+#ifdef CONFIG_HISI_NAND_FS_MAY_NO_YAFFS2
+static int hifmc_ooblayout_ecc_4k16bit(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 14;
+	oobregion->offset = 14;
+
+	return 0;
+}
+
+static int hifmc_ooblayout_free_4k16bit(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 14;
+	oobregion->offset = 2;
+
+	return 0;
+}
+tatic struct mtd_ooblayout_ops hifmc_ooblayout_4k16bit_ops = {
+	.ecc = hifmc_ooblayout_ecc_4k16bit,
+	.free = hifmc_ooblayout_free_4k16bit,
+};
+
+static int hifmc_ooblayout_ecc_2k16bit(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 6;
+	oobregion->offset = 6;
+
+	return 0;
+}
+
+static int hifmc_ooblayout_free_2k16bit(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 6;
+	oobregion->offset = 2;
+
+	return 0;
+}
+
+static struct mtd_ooblayout_ops hifmc_ooblayout_2k16bit_ops = {
+	.ecc = hifmc_ooblayout_ecc_2k16bit,
+	.free = hifmc_ooblayout_free_2k16bit,
+};
+#endif
+/*****************************************************************************/
+/* ecc/pagesize get from NAND controller */
+static struct nand_config_info hifmc100_nand_hw_auto_config_table[] = {
+	{NAND_PAGE_16K, NAND_ECC_64BIT, 64, 1824/*1824*/, &hifmc_ooblayout_default_ops},
+	{NAND_PAGE_16K, NAND_ECC_40BIT, 40, 1200/*1152*/, &hifmc_ooblayout_default_ops},
+	{NAND_PAGE_16K, NAND_ECC_0BIT,  0, 32 ,          &hifmc_ooblayout_default_ops},
+
+	{NAND_PAGE_8K, NAND_ECC_64BIT, 64, 928 /*928*/,  &hifmc_ooblayout_default_ops},
+	{NAND_PAGE_8K, NAND_ECC_40BIT, 40, 600 /*592*/,  &hifmc_ooblayout_default_ops},
+	{NAND_PAGE_8K, NAND_ECC_24BIT, 24, 368 /*368*/,  &hifmc_ooblayout_default_ops},
+	{NAND_PAGE_8K, NAND_ECC_0BIT,  0, 32,           &hifmc_ooblayout_default_ops},
+
+	{NAND_PAGE_4K, NAND_ECC_24BIT, 24, 200 /*200*/,  &hifmc_ooblayout_default_ops},
+#ifdef CONFIG_HISI_NAND_FS_MAY_NO_YAFFS2
+	{NAND_PAGE_4K, NAND_ECC_16BIT, 16, 128 /*128*/,  &hifmc_ooblayout_4k16bit_ops},
+#endif
+	{NAND_PAGE_4K, NAND_ECC_8BIT, 8, 128 /*88*/,   &hifmc_ooblayout_default_ops},
+	{NAND_PAGE_4K, NAND_ECC_0BIT, 0, 32,           &hifmc_ooblayout_default_ops},
+
+	{NAND_PAGE_2K, NAND_ECC_24BIT, 24, 128 /*116*/, &hifmc_ooblayout_default_ops},
+#ifdef CONFIG_HISI_NAND_FS_MAY_NO_YAFFS2
+	{NAND_PAGE_2K, NAND_ECC_16BIT, 16, 64 /*64*/, &hifmc_ooblayout_2k16bit_ops},
+#endif
+	{NAND_PAGE_2K, NAND_ECC_8BIT,  8, 64  /*60*/,  &hifmc_ooblayout_default_ops},
+	{NAND_PAGE_2K, NAND_ECC_0BIT,  0, 32,          &hifmc_ooblayout_default_ops},
+
+	{0,		0,		0,		0,		NULL},
+};
+
+/*****************************************************************************/
+/*
+ *  0 - This NAND NOT support randomizer
+ *  1 - This NAND support randomizer.
+ */
+static int hifmc100_nand_support_randomizer(u_int pageisze, u_int ecctype)
+{
+	switch (pageisze) {
+	case _8K:
+		return (ecctype >= NAND_ECC_24BIT && ecctype <= NAND_ECC_80BIT);
+	case _16K:
+		return (ecctype >= NAND_ECC_40BIT && ecctype <= NAND_ECC_80BIT);
+	case _32K:
+		return (ecctype >= NAND_ECC_40BIT && ecctype <= NAND_ECC_80BIT);
+	default:
+		return 0;
+	}
+}
+
+/*****************************************************************************/
+/* used the best correct arithmetic. */
+static struct nand_config_info *hifmc100_get_config_type_info(
+		struct mtd_info *mtd, struct nand_dev_t *nand_dev)
+{
+	struct nand_config_info *best = NULL;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+	struct nand_config_info *info = hifmc100_nand_hw_auto_config_table;
+
+	nand_dev->start_type = "Auto";
+	nand_dev->flags |= (IS_NANDC_HW_AUTO(host) | IS_NANDC_CONFIG_DONE(host));
+
+	for (; info->ooblayout_ops; info++) {
+		if (match_page_type_to_size(info->pagetype) != mtd->writesize)
+			continue;
+
+		if (mtd->oobsize < info->oobsize)
+			continue;
+
+		if (!best || (best->ecctype < info->ecctype))
+			best = info;
+	}
+
+	return best;
+}
+
+/*****************************************************************************/
+static unsigned int hifmc100_get_ecc_reg(struct hifmc_host *host,
+		struct nand_config_info *info, struct nand_dev_t *nand_dev)
+{
+	host->ecctype = info->ecctype;
+	FMC_PR(BT_DBG, "\t |-Save best EccType %d(%s)\n", host->ecctype,
+			match_ecc_type_to_str(info->ecctype));
+
+	nand_dev->ecctype = host->ecctype;
+
+	return FMC_CFG_ECC_TYPE(match_ecc_type_to_reg(info->ecctype));
+}
+
+/*****************************************************************************/
+static unsigned int hifmc100_get_page_reg(struct hifmc_host *host,
+		struct nand_config_info *info)
+{
+	host->pagesize = match_page_type_to_size(info->pagetype);
+	FMC_PR(BT_DBG, "\t |-Save best PageSize %d(%s)\n", host->pagesize,
+			match_page_type_to_str(info->pagetype));
+
+	return FMC_CFG_PAGE_SIZE(match_page_type_to_reg(info->pagetype));
+}
+
+/*****************************************************************************/
+static unsigned int hifmc100_get_block_reg(struct hifmc_host *host,
+		struct nand_config_info *info)
+{
+	unsigned int block_reg = 0, page_per_block;
+	struct mtd_info *mtd = host->mtd;
+
+	host->block_page_mask = ((mtd->erasesize / mtd->writesize) - 1);
+	page_per_block = mtd->erasesize / match_page_type_to_size(info->pagetype);
+	switch (page_per_block) {
+		case 64:
+			block_reg = BLOCK_SIZE_64_PAGE;
+			break;
+		case 128:
+			block_reg = BLOCK_SIZE_128_PAGE;
+			break;
+		case 256:
+			block_reg = BLOCK_SIZE_256_PAGE;
+			break;
+		case 512:
+			block_reg = BLOCK_SIZE_512_PAGE;
+			break;
+		default:
+			DB_MSG("Can't support block %#x and page %#x size\n",
+					mtd->erasesize, mtd->writesize);
+	}
+
+	return FMC_CFG_BLOCK_SIZE(block_reg);
+}
+
+/*****************************************************************************/
+static void hifmc100_set_fmc_cfg_reg(struct hifmc_host *host,
+		struct nand_config_info *type_info, struct nand_dev_t *nand_dev)
+{
+	unsigned int page_reg, ecc_reg, block_reg, reg_fmc_cfg;
+
+	ecc_reg = hifmc100_get_ecc_reg(host, type_info, nand_dev);
+	page_reg = hifmc100_get_page_reg(host, type_info);
+	block_reg = hifmc100_get_block_reg(host, type_info);
+
+	if (hifmc100_nand_support_randomizer(host->pagesize, host->ecctype))
+		host->flags |= IS_NAND_RANDOM(nand_dev);
+
+	/*
+	 * Check if hardware enable randomizer PIN, But NAND does not need
+	 * randomizer. We will notice user.
+	 */
+	if (IS_NAND_RANDOM(host) &&
+	    !hifmc100_nand_support_randomizer(host->pagesize, host->ecctype))
+		DB_BUG(ERSTR_HARDWARE
+			"This NAND flash does not support `randomizer`, "
+			"Please don't configure hardware randomizer PIN.");
+
+	/* Save value of FMC_CFG and FMC_CFG_ECC0 to turn on/off ECC */
+	reg_fmc_cfg = hifmc_readl(host, FMC_CFG);
+	reg_fmc_cfg &= ~(PAGE_SIZE_MASK | ECC_TYPE_MASK | BLOCK_SIZE_MASK);
+	reg_fmc_cfg |= ecc_reg | page_reg | block_reg;
+	host->nand_cfg = reg_fmc_cfg;
+	host->nand_cfg_ecc0 = (host->nand_cfg & ~ECC_TYPE_MASK) | ECC_TYPE_0BIT;
+	FMC_PR(BT_DBG, "\t|-Save FMC_CFG[%#x]: %#x and FMC_CFG_ECC0: %#x\n",
+			FMC_CFG, host->nand_cfg, host->nand_cfg_ecc0);
+
+	/* pass pagesize and ecctype to kernel when spiflash startup. */
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	/*
+	 * If it want to support the 'read retry' feature, the 'randomizer'
+	 * feature must be support first.
+	 */
+	host->read_retry = NULL;
+
+	if (host->read_retry && !IS_NAND_RANDOM(host)) {
+		DB_BUG(ERSTR_HARDWARE
+			"This Nand flash need to enable 'randomizer' feature. "
+			"Please configure hardware randomizer PIN.");
+	}
+}
+
+/*****************************************************************************/
+static void hifmc100_set_oob_info(struct mtd_info *mtd,
+		struct nand_config_info *info, struct nand_dev_t *nand_dev)
+{
+	int buffer_len;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hifmc_host *host = chip->priv;
+	struct mtd_oob_region hifmc_oobregion = {0, 0};
+
+	if (info->ecctype != NAND_ECC_0BIT)
+		mtd->oobsize = info->oobsize;
+	mtd->oobavail = HIFMC100_NAND_OOBSIZE_FOR_YAFFS;
+
+	host->oobsize = mtd->oobsize;
+
+	buffer_len = host->pagesize + host->oobsize;
+	host->buffer = dmam_alloc_coherent(host->dev, buffer_len,
+			&host->dma_buffer, GFP_KERNEL);
+	if (WARN_ON(!host->buffer)) {
+		dev_err(host->dev, "failed to allocate host->buffer\n");
+		return;
+	}
+
+	memset(host->buffer, 0xff, buffer_len);
+	host->dma_oob = host->dma_buffer + host->pagesize;
+
+	host->bbm = (unsigned char *)(host->buffer + host->pagesize
+			+ HIFMC100_BAD_BLOCK_POS);
+
+	info->ooblayout_ops->free(mtd, 0, &hifmc_oobregion);
+
+	mtd_set_ooblayout(mtd, info->ooblayout_ops);
+
+	/* EB bits locate in the bottom two of CTRL(30) */
+	host->epm = (u_short *)(host->buffer + host->pagesize
+			+ hifmc_oobregion.offset + 28);
+
+#ifdef CONFIG_HISI_NAND_FS_MAY_NO_YAFFS2
+	if (best->ecctype == NAND_ECC_16BIT) {
+		if (host->pagesize == _2K) {
+			/* EB bits locate in the bottom two of CTRL(4) */
+			host->epm = (u_short *)(host->buffer + host->pagesize
+					+ hifmc_oobregion.offset + 4);
+		} else if (host->pagesize == _4K) {
+			/* EB bit locate in the bottom two of CTRL(14) */
+			host->epm = (u_short *)(host->buffer + host->pagesize
+					+ hifmc_oobregion.offset + 12);
+		}
+	}
+#endif
+}
+/*****************************************************************************/
+static int hifmc100_set_config_info(struct mtd_info *mtd,
+		struct nand_chip *chip, struct nand_dev_t *dev)
+{
+	struct hifmc_host *host = chip->priv;
+	struct nand_dev_t *nand_dev = &g_nand_dev;
+	struct nand_config_info *type_info = NULL;
+
+	FMC_PR(BT_DBG, "\t*-Start config Block Page OOB and Ecc\n");
+
+	type_info = hifmc100_get_config_type_info(mtd, nand_dev);
+	BUG_ON(!type_info);
+
+	FMC_PR(BT_DBG, "\t|-%s Config, PageSize %s EccType %s OobSize %d\n",
+			nand_dev->start_type, nand_page_name(type_info->pagetype),
+			nand_ecc_name(type_info->ecctype), type_info->oobsize);
+
+	/* Set the page_size, ecc_type, block_size of FMC_CFG[0x0] register */
+	hifmc100_set_fmc_cfg_reg(host, type_info, nand_dev);
+
+	hifmc100_set_oob_info(mtd, type_info, nand_dev);
+
+	if (mtd->writesize > NAND_MAX_PAGESIZE
+			|| mtd->oobsize > NAND_MAX_OOBSIZE) {
+		DB_BUG(ERSTR_DRIVER
+			"Driver does not support this Nand Flash. Please " \
+			"increase NAND_MAX_PAGESIZE and NAND_MAX_OOBSIZE.\n");
+	}
+
+	/* Some Nand Flash devices have subpage structure */
+	if (mtd->writesize != host->pagesize) {
+		unsigned int shift = 0;
+		unsigned int writesize = mtd->writesize;
+
+		while (writesize > host->pagesize) {
+			writesize >>= 1;
+			shift++;
+		}
+		chip->chipsize = chip->chipsize >> shift;
+		mtd->erasesize = mtd->erasesize >> shift;
+		mtd->writesize = host->pagesize;
+		pr_info("Nand divide into 1/%u\n", (1 << shift));
+	}
+
+	FMC_PR(BT_DBG, "\t*-End config Block Page Oob and Ecc\n");
+
+	return 0;
+}
+
+/*****************************************************************************/
+static void hifmc100_chip_init(struct nand_chip *chip)
+{
+	memset((char *)chip->IO_ADDR_R, 0xff, NAND_BUFFER_LEN);
+
+	chip->read_byte = hifmc100_read_byte;
+	chip->read_word = hifmc100_read_word;
+	chip->write_buf = hifmc100_write_buf;
+	chip->read_buf = hifmc100_read_buf;
+
+	chip->select_chip = hifmc100_select_chip;
+
+	chip->cmd_ctrl = hifmc100_cmd_ctrl;
+	chip->dev_ready = hifmc100_dev_ready;
+
+	chip->chip_delay = FMC_CHIP_DELAY;
+
+	chip->options = NAND_NEED_READRDY | NAND_BROKEN_XD
+		| NAND_SKIP_BBTSCAN;
+
+	chip->ecc.mode = NAND_ECC_NONE;
+}
+
+/*****************************************************************************/
+static int hifmc100_host_init(struct hifmc_host *host)
+{
+	unsigned int reg, flash_type;
+
+	FMC_PR(BT_DBG, "\t *-Start nand host init\n");
+
+	reg = hifmc_readl(host, FMC_CFG);
+	FMC_PR(BT_DBG, "\t |-Read FMC CFG[%#x]%#x\n", FMC_CFG, reg);
+	flash_type = GET_SPI_FLASH_TYPE(reg);
+	if (flash_type != FLASH_TYPE_NAND) {
+		DB_MSG("Error: Flash type isn't Nand flash. reg[%#x]\n", reg);
+		reg |= FMC_CFG_FLASH_SEL(FLASH_TYPE_NAND);
+		FMC_PR(BT_DBG, "\t |-Change flash type to Nand flash\n");
+	}
+
+	if ((reg & FMC_CFG_OP_MODE_MASK) == FMC_CFG_OP_MODE_BOOT) {
+		reg |= FMC_CFG_OP_MODE(FMC_CFG_OP_MODE_NORMAL);
+		FMC_PR(BT_DBG, "\t |-Controller enter normal mode\n");
+	}
+	hifmc_writel(host, FMC_CFG, reg);
+	FMC_PR(BT_DBG, "\t |-Set CFG[%#x]%#x\n", FMC_CFG, reg);
+
+	host->nand_cfg = reg;
+	host->nand_cfg_ecc0 = (reg & ~ECC_TYPE_MASK) | ECC_TYPE_0BIT;
+
+	reg = hifmc_readl(host, FMC_GLOBAL_CFG);
+	FMC_PR(BT_DBG, "\t |-Read global CFG[%#x]%#x\n", FMC_GLOBAL_CFG, reg);
+	if (reg & FMC_GLOBAL_CFG_RANDOMIZER_EN) {
+		host->flags &= ~NAND_RANDOMIZER;
+		FMC_PR(BT_DBG, "\t |-Default disable randomizer\n");
+		reg &= ~FMC_GLOBAL_CFG_RANDOMIZER_EN;
+		hifmc_writel(host, FMC_GLOBAL_CFG, reg);
+		FMC_PR(BT_DBG, "\t |-Set global CFG[%#x]%#x\n", FMC_GLOBAL_CFG, reg);
+	}
+
+#ifdef CONFIG_HIFMC100_NAND_EDO_MODE
+	/* enable EDO node */
+	reg = hifmc_readl(host, FMC_GLOBAL_CFG);
+	hifmc_writel(host, FMC_GLOBAL_CFG, SET_NAND_EDO_MODE_EN(reg));
+#endif
+
+	host->addr_cycle = 0;
+	host->addr_value[0] = 0;
+	host->addr_value[1] = 0;
+	host->cache_addr_value[0] = ~0;
+	host->cache_addr_value[1] = ~0;
+
+	host->send_cmd_pageprog = hifmc100_send_cmd_write;
+	host->send_cmd_status = hifmc100_send_cmd_status;
+	host->send_cmd_readstart = hifmc100_send_cmd_read;
+	host->send_cmd_erase = hifmc100_send_cmd_erase;
+	host->send_cmd_readid = hifmc100_send_cmd_readid;
+	host->send_cmd_reset = hifmc100_send_cmd_reset;
+
+	/*
+	 * check if start from nand.
+	 * This register REG_SYSSTAT is set in start.S
+	 * When start in NAND (Auto), the ECC/PAGESIZE driver don't detect.
+	 */
+	host->flags |= NANDC_HW_AUTO;
+
+	if (GET_SYS_BOOT_MODE(reg) == BOOT_FROM_NAND) {
+		host->flags |= NANDC_CONFIG_DONE;
+		FMC_PR(BT_DBG, "\t |-Auto config pagesize and ecctype\n");
+	}
+
+	host->enable_ecc_randomizer = hifmc100_ecc_randomizer;
+
+	FMC_PR(BT_DBG, "\t *-End nand host init\n");
+
+	return 0;
+}
+
+/*****************************************************************************/
+int hifmc100_nand_init(struct nand_chip *chip)
+{
+	struct hifmc_host *host = chip->priv;
+
+	/* enable and set system clock */
+	clk_prepare_enable(host->clk);
+
+	/* fmc ip version check */
+	host->version = hifmc_readl(host, FMC_VERSION);
+	if (host->version != HIFMC_VER_100)
+		return -EFAULT;
+	pr_info("Found Flash Memory Controller v100 Nand Driver\n");
+
+	/* hifmc host init */
+	if (hifmc100_host_init(host)) {
+		DB_MSG("Error: Nand host init failed!\n");
+		return -EFAULT;
+	}
+	host->chip = chip;
+
+	hifmc_writel(host, FMC_PND_PWIDTH_CFG, PWIDTH_CFG_RW_HCNT(CONFIG_RW_H_WIDTH)
+			| PWIDTH_CFG_R_LCNT(CONFIG_R_L_WIDTH)
+			| PWIDTH_CFG_W_LCNT(CONFIG_W_L_WIDTH));
+
+	/* hifmc nand_chip struct init */
+	hifmc100_chip_init(chip);
+
+	hifmc_spl_ids_register();
+	hinfc_param_adjust = hifmc100_set_config_info;
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+/*****************************************************************************/
+void hifmc100_nand_config(struct hifmc_host *host)
+{
+	/* enable system clock */
+	clk_prepare_enable(host->clk);
+	FMC_PR(PM_DBG, "\t |-enable system clock\n");
+}
+#endif  /* CONFIG_PM */
diff --git a/drivers/mtd/nand/hifmc100_nand/hifmc100_nand.h b/drivers/mtd/nand/hifmc100_nand/hifmc100_nand.h
new file mode 100644
index 0000000..9f7bbb9
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100_nand/hifmc100_nand.h
@@ -0,0 +1,164 @@
+/*
+ * The Flash Memory Controller v100 Device Driver for hisilicon
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef __HIFMC100_NAND_H__
+#define __HIFMC100_NAND_H__
+
+#include <linux/mfd/hisi_fmc.h>
+
+/******************************************************************************/
+/* These macroes are for debug only, reg option is slower then dma option */
+#undef HIFMC100_NAND_SUPPORT_REG_READ
+/* #define HIFMC100_NAND_SUPPORT_REG_READ */
+
+#undef HIFMC100_NAND_SUPPORT_REG_WRITE
+/* #define HIFMC100_NAND_SUPPORT_REG_WRITE */
+
+/*****************************************************************************/
+#define HIFMC100_ECC_ERR_NUM0_BUF0		0xc0
+#define HIFMC100_ECC_ERR_NUM1_BUF0		0xc4
+#define HIFMC100_ECC_ERR_NUM0_BUF1		0xc8
+#define HIFMC100_ECC_ERR_NUM1_BUF1		0xcc
+
+#define GET_ECC_ERR_NUM(_i, _reg)		(((_reg) >> ((_i) * 8)) & 0xff)
+
+/*****************************************************************************/
+#define NAND_MAX_PAGESIZE			32768
+#define NAND_MAX_OOBSIZE			4800
+
+#define CONFIG_SUPPORT_YAFFS
+#define HIFMC100_NAND_OOBSIZE_FOR_YAFFS		32
+
+/*****************************************************************************/
+#define REG_CNT_HIGH_BLOCK_NUM_SHIFT		10
+
+#define REG_CNT_BLOCK_NUM_MASK			0x3ff
+#define REG_CNT_BLOCK_NUM_SHIFT			22
+
+#define REG_CNT_PAGE_NUM_MASK			0x3f
+#define REG_CNT_PAGE_NUM_SHIFT			16
+
+#define REG_CNT_WRAP_MASK			0xf
+#define REG_CNT_WRAP_SHIFT			12
+
+#define REG_CNT_ECC_OFFSET_MASK			0xfff
+#define REG_CNT_ECC_8BIT_OFFSET			1054
+#define REG_CNT_ECC_16BIT_OFFSET		1056
+#define REG_CNT_ECC_24BIT_OFFSET		1082
+
+/*****************************************************************************/
+#define HIFMC100_ADDR_CYCLE_MASK		0x4
+
+#define NAND_EDO_MODE_SHIFT            9
+#define NAND_EDO_MODE_MASK             (1<<NAND_EDO_MODE_SHIFT)
+#define SET_NAND_EDO_MODE_EN(reg)      ((reg) | NAND_EDO_MODE_MASK)
+/*****************************************************************************/
+struct hifmc_host {
+	struct nand_chip *chip;
+	struct mtd_info  *mtd;
+
+	struct hifmc_cmd_op cmd_op;
+	void __iomem *regbase;
+	void __iomem *iobase;
+
+	/* Controller config option nand flash */
+	unsigned int nand_cfg;
+	unsigned int nand_cfg_ecc0;
+
+	unsigned int offset;
+
+	struct device *dev;
+
+	/* This is maybe an un-aligment address, only for malloc or free */
+	char *buforg;
+	char *buffer;
+
+#ifdef CONFIG_64BIT
+	unsigned long long dma_buffer;
+	unsigned long long dma_oob;
+#else
+	unsigned int dma_buffer;
+	unsigned int dma_oob;
+#endif
+
+	unsigned int addr_cycle;
+	unsigned int addr_value[2];
+	unsigned int cache_addr_value[2];
+
+	unsigned int column;
+	unsigned int block_page_mask;
+
+	unsigned int ecctype;
+	unsigned int pagesize;
+	unsigned int oobsize;
+
+	int  need_rr_data;
+#define HIFMC100_READ_RETRY_DATA_LEN         128
+	char rr_data[HIFMC100_READ_RETRY_DATA_LEN];
+	int  version;
+	int   add_partition;
+
+	/* BOOTROM read two bytes to detect the bad block flag */
+#define HIFMC100_BAD_BLOCK_POS              0
+	unsigned char *bbm;  /* nand bad block mark */
+	unsigned short *epm;  /* nand empty page mark */
+	unsigned int flags;
+
+#define HIFMC100_PS_UC_ECC        0x01 /* page has ecc error */
+#define HIFMC100_PS_BAD_BLOCK     0x02 /* bad block */
+#define HIFMC100_PS_EMPTY_PAGE    0x04 /* page is empty */
+#define HIFMC100_PS_EPM_ERROR     0x0100 /* empty page mark word has error. */
+#define HIFMC100_PS_BBM_ERROR     0x0200 /* bad block mark word has error. */
+	unsigned int page_status;
+
+	struct clk *clk;
+
+	void (*send_cmd_pageprog)(struct hifmc_host *host);
+	void (*send_cmd_status)(struct hifmc_host *host);
+	void (*send_cmd_readstart)(struct hifmc_host *host);
+	void (*send_cmd_erase)(struct hifmc_host *host);
+	void (*send_cmd_readid)(struct hifmc_host *host);
+	void (*send_cmd_reset)(struct hifmc_host *host);
+	void (*enable)(int enable);
+
+	void (*enable_ecc_randomizer)(struct hifmc_host *host,
+				     int ecc_en, int randomizer_en);
+
+	void (*detect_ecc)(struct hifmc_host *host);
+
+	struct read_retry_t *read_retry;
+};
+
+/*****************************************************************************/
+extern struct nand_dev_t g_nand_dev;
+
+/*****************************************************************************/
+int hifmc100_nand_init(struct nand_chip *chip);
+
+/*****************************************************************************/
+extern void hifmc_spl_ids_register(void);
+
+/*****************************************************************************/
+#ifdef CONFIG_PM
+void hifmc100_nand_config(struct hifmc_host *host);
+#endif
+/*****************************************************************************/
+
+#endif /* End of __HIFMC100_NAND_H__ */
diff --git a/drivers/mtd/nand/hifmc100_nand/hifmc100_nand_os.c b/drivers/mtd/nand/hifmc100_nand/hifmc100_nand_os.c
new file mode 100644
index 0000000..4dc7e50
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100_nand/hifmc100_nand_os.c
@@ -0,0 +1,165 @@
+/*
+ * The Flash Memory Controller v100 Device Driver for hisilicon
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/of_platform.h>
+
+#include "hifmc100_nand_os.h"
+#include "hifmc100_nand.h"
+#include <linux/mfd/hisi_fmc.h>
+
+/*****************************************************************************/
+static inline int mtd_has_partitions(void) { return 1; }
+
+/*****************************************************************************/
+static int hisi_nand_os_probe(struct platform_device *pltdev)
+{
+	int len, result = 0;
+	struct hifmc_host *host;
+	struct nand_chip *chip;
+	struct mtd_info *mtd;
+	int nr_parts = 0;
+	struct mtd_partition *parts = NULL;
+	struct device *dev = &pltdev->dev;
+	struct device_node *np = NULL;
+	struct hisi_fmc *fmc = dev_get_drvdata(dev->parent);
+
+	len = sizeof(struct hifmc_host) + sizeof(struct nand_chip)
+		+ sizeof(struct mtd_info);
+	host = devm_kzalloc(dev, len, GFP_KERNEL);
+	if (!host)
+		return -ENOMEM;
+	memset((char *)host, 0, len);
+	platform_set_drvdata(pltdev, host);
+
+	host->dev = &pltdev->dev;
+	host->chip = chip = (struct nand_chip *)&host[1];
+	host->mtd = mtd = nand_to_mtd(chip);
+	host->regbase = fmc->regbase;
+	host->iobase = fmc->iobase;
+	host->clk = fmc->clk;
+	chip->IO_ADDR_R = chip->IO_ADDR_W = host->iobase;
+
+	/* hifmc Nand host init */
+	chip->priv = host;
+	result = hifmc100_nand_init(chip);
+	if (result) {
+		DB_MSG("Error: host init failed! result: %d\n", result);
+		goto fail;
+	}
+
+	np = of_get_next_available_child(dev->of_node, NULL);
+	mtd->name = np->name;
+	mtd->type = MTD_NANDFLASH;
+	mtd->priv = chip;
+	mtd->flags = MTD_CAP_NANDFLASH;
+	mtd->owner = THIS_MODULE;
+
+	if (nand_scan(mtd, CONFIG_HIFMC100_MAX_NAND_CHIP)) {
+		result = -ENXIO;
+		goto fail;
+	}
+
+	result = mtd_device_register(host->mtd, parts, nr_parts);
+	if (result) {
+		kfree(parts);
+		parts = NULL;
+	}
+
+	return (1 == result) ? -ENODEV : 0;
+
+fail:
+	clk_disable_unprepare(host->clk);
+	nand_release(mtd);
+	return result;
+}
+
+/*****************************************************************************/
+static int hisi_nand_os_remove(struct platform_device *pltdev)
+{
+	struct hifmc_host *host = platform_get_drvdata(pltdev);
+
+	clk_disable_unprepare(host->clk);
+	nand_release(host->mtd);
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+/*****************************************************************************/
+static int hifmc100_nand_os_suspend(struct platform_device *pltdev,
+		pm_message_t state)
+{
+	struct hifmc_host *host = platform_get_drvdata(pltdev);
+	if (!host)
+		return 0;
+
+	while ((hifmc_readl(host, FMC_OP) & FMC_OP_REG_OP_START))
+		_cond_resched();
+
+	while ((hifmc_readl(host, FMC_OP_CTRL) & OP_CTRL_DMA_OP_READY))
+		_cond_resched();
+
+	clk_disable_unprepare(host->clk);
+	FMC_PR(PM_DBG, "\t|-disable system clock\n");
+	return 0;
+}
+
+/*****************************************************************************/
+static int hifmc100_nand_os_resume(struct platform_device *pltdev)
+{
+	int cs;
+	struct hifmc_host *host = platform_get_drvdata(pltdev);
+	struct nand_chip *chip = host->chip;
+
+	if (!host)
+		return 0;
+
+	for (cs = 0; cs < chip->numchips; cs++)
+		host->send_cmd_reset(host);
+
+	hifmc100_nand_config(host);
+	return 0;
+}
+#endif /* CONFIG_PM */
+
+/*****************************************************************************/
+static const struct of_device_id hisi_nand_dt_ids[] = {
+	{ .compatible = "hisilicon,hisi_nand" },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, hisi_nand_dt_ids);
+
+static struct platform_driver hisi_nand_driver = {
+	.driver = {
+		.name	= "hisi_nand",
+		.of_match_table = hisi_nand_dt_ids,
+	},
+	.probe	= hisi_nand_os_probe,
+	.remove = hisi_nand_os_remove,
+#ifdef CONFIG_PM
+	.suspend	= hifmc100_nand_os_suspend,
+	.resume		= hifmc100_nand_os_resume,
+#endif
+};
+module_platform_driver(hisi_nand_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("BVT_BSP");
+MODULE_DESCRIPTION("Hisilicon Flash Memory Controller V100 Nand Driver");
diff --git a/drivers/mtd/nand/hifmc100_nand/hifmc100_nand_os.h b/drivers/mtd/nand/hifmc100_nand/hifmc100_nand_os.h
new file mode 100644
index 0000000..b6d9807
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100_nand/hifmc100_nand_os.h
@@ -0,0 +1,74 @@
+/*
+ * The Flash Memory Controller v100 Device Driver for hisilicon
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef __HIFMC100_NAND_OS_H__
+#define __HIFMC100_NAND_OS_H__
+
+/*****************************************************************************/
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/partitions.h>
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/sched.h>
+#include <asm/errno.h>
+#include <asm/setup.h>
+#include <linux/io.h>
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+
+#include <asm/clkdev.h>
+#include <linux/resource.h>
+#include <linux/clk.h>
+#include <linux/clkdev.h>
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 4, 5))
+	#include "../../mtdcore.h"
+#endif
+
+/*****************************************************************************/
+#define DEFAULT_NAND_PAGESIZE	2048
+#define DEFAULT_NAND_OOBSIZE	64
+
+#define NAND_BUFFER_LEN		(DEFAULT_NAND_PAGESIZE + DEFAULT_NAND_OOBSIZE)
+
+/*****************************************************************************/
+#ifndef CONFIG_RW_H_WIDTH
+	#define CONFIG_RW_H_WIDTH	(10)
+	#warning NOT config CONFIG_RW_H_WIDTH, used default value, maybe invalid.
+#endif
+
+#ifndef CONFIG_R_L_WIDTH
+	#define CONFIG_R_L_WIDTH	(10)
+	#warning NOT config CONFIG_R_L_WIDTH, used default value, maybe invalid.
+#endif
+
+#ifndef CONFIG_W_L_WIDTH
+	#define CONFIG_W_L_WIDTH	(10)
+	#warning NOT config CONFIG_W_L_WIDTH, used default value, maybe invalid.
+#endif
+
+extern void hifmc100_nand_controller_enable(int enable);
+
+#endif /* End of __HIFMC100_NAND_OS_H__ */
diff --git a/drivers/mtd/nand/hifmc100_nand/hifmc_nand_spl_ids.c b/drivers/mtd/nand/hifmc100_nand/hifmc_nand_spl_ids.c
new file mode 100644
index 0000000..e0d7a39
--- /dev/null
+++ b/drivers/mtd/nand/hifmc100_nand/hifmc_nand_spl_ids.c
@@ -0,0 +1,942 @@
+/*
+ * The Flash Memory Controller v100 Device Driver for hisilicon
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <asm/setup.h>
+#include <linux/mtd/nand.h>
+#include <linux/mfd/hisi_fmc.h>
+
+#include "../hinfc_gen.h"
+#include "hifmc100_nand.h"
+
+/*****************************************************************************/
+#define _768K           (_256K + _512K)
+
+/*****************************************************************************/
+struct nand_flash_special_dev {
+	unsigned char id[8];
+	int length;             /* length of id. */
+	unsigned long long chipsize;
+	struct nand_flash_dev *(*probe)(unsigned char *id);
+	char *name;
+
+	unsigned long pagesize;
+	unsigned long erasesize;
+	unsigned long oobsize;
+	unsigned long options;
+	unsigned int read_retry_type;
+
+#define BBP_LAST_PAGE                    0x01
+#define BBP_FIRST_PAGE                   0x02
+	unsigned int badblock_pos;
+	int flags;
+};
+
+/*****************************************************************************/
+/*                    this is nand probe function.                           */
+/*****************************************************************************/
+
+static struct nand_flash_dev *hynix_probe_v02(unsigned char *id)
+{
+	struct nand_flash_dev *type = &g_nand_dev.flash_dev;
+
+	int pagesizes[]   = {_2K, _4K, _8K, 0};
+	int oobsizes[]    = {128, 224, 448, 0, 0, 0, 0, 0};
+	int blocksizes[]  = {_128K, _256K, _512K, _768K, _1M, _2M, 0, 0};
+
+	int blocktype = (((id[3] >> 5) & 0x04) | ((id[3] >> 4) & 0x03));
+	int oobtype   = (((id[3] >> 2) & 0x03) | ((id[3] >> 4) & 0x04));
+
+	type->options   = 0;
+	type->pagesize  = pagesizes[(id[3] & 0x03)];
+	type->erasesize = blocksizes[blocktype];
+	type->oobsize = oobsizes[oobtype];
+
+	return type;
+}
+
+/*****************************************************************************/
+static struct nand_flash_dev *samsung_probe_v02(unsigned char *id)
+{
+	struct nand_flash_dev *type = &g_nand_dev.flash_dev;
+
+	int pagesizes[]   = {_2K, _4K, _8K, 0};
+	int oobsizes[]    = {0, 128, 218, 400, 436, 0, 0, 0};
+	int blocksizes[]  = {_128K, _256K, _512K, _1M, 0, 0, 0, 0};
+
+	int blocktype = (((id[3] >> 5) & 0x04) | ((id[3] >> 4) & 0x03));
+	int oobtype   = (((id[3] >> 4) & 0x04) | ((id[3] >> 2) & 0x03));
+
+	type->options   = 0;
+	type->pagesize  = pagesizes[(id[3] & 0x03)];
+	type->erasesize = blocksizes[blocktype];
+	type->oobsize = oobsizes[oobtype];
+
+	return type;
+}
+
+/*****************************************************************************/
+
+#define DRV_VERSION     "1.39"
+
+/*****************************************************************************/
+/*
+ * samsung:  27nm need randomizer, 21nm need read retry;
+ * micron:   25nm need read retry, datasheet will explain read retry.
+ * toshaba   32nm need randomizer, 24nm need read retry.
+ * hynix:    2xnm need read retry.
+ *
+ *		The special nand flash ID table version 1.39
+ *
+ * manufactory  |  type  |       name 	     |   ecc_type  | version_tag
+ * Micron		|  MLC	 |  MT29F64G08CBABA  |   40bit/1k  |  1.36
+ * Micron		|  MLC	 |  MT29F32G08CBADA  |   40bit/1k  |
+ * Micron		|  SLC	 |  MT29F8G08ABxBA   |   4bit/512  |
+ * Micron		|  MLC	 |  MT29F16G08CBABx  |   12bit/512 |
+ * Micron		|  MLC	 |  MT29F16G08CBACA  |   24bit/1k  |
+ * Micron		|  MLC	 |  MT29F32G08CBACA  |   24bit/1k  |
+ * Micron		|  MLC	 |  MT29F64G08CxxAA  |   24bit/1k  |
+ * Micron		|  MLC	 |  MT29F256G08CJAAA |   24bit/1k  |   2CE
+ * Micron		|  MLC	 |  MT29F256G08CMCBB |   24bit/1k  |
+ * Micron		|  SLC	 |  MT29F8G08ABACA   |   8bit/512  |
+ * Micron		|  SLC	 |  MT29F4G08ABAEA   |   8bit/512  |
+ * Micron		|  SLC	 |  MT29F2G08ABAFA   |   8bit/512  |
+ * Micron		|  SLC	 |  MT29F16G08ABACA  |   8bit/512  |
+ * Toshiba		|  MLC   |  TC58NVG4D2FTA00  |   24bit/1k  |
+ * Toshiba		|  MLC   |  TH58NVG6D2FTA20  |   24bit/1k  |   2CE
+ * Toshiba		|  MLC   |  TC58NVG5D2HTA00  |   40bit/1k  |
+ * Toshiba		|  MLC   |  TC58NVG6D2GTA00  |   40bit/1k  |
+ * Toshiba		|  MLC   |  TC58NVG6DCJTA00  |			   |
+ * Toshiba		|  MLC   |  TC58TEG5DCJTA00  |			   |
+ * Toshiba		|  SLC   |  TC58NVG0S3HTA00  |   8bit/512  |
+ * Toshiba		|  SLC   |  TC58NVG1S3HTA00  |   8bit/512  |
+ * Toshiba		|  SLC   |  TC58NVG1S3ETA00  |   4bit/512  |
+ * Toshiba		|  SLC   |  TC58NVG3S0FTA00  |   4bit/512  |
+ * Toshiba		|  SLC   |  TC58NVG2S0FTA00  |   4bit/512  |
+ * Toshiba		|  SLC   |  TH58NVG2S3HTA00  |   4bit/512  |
+ * Toshiba		|  TLC   |  TC58NVG5T2JTA00  |   60bit/1k  |
+ * Toshiba		|  TLC   |  TC58TEG5DCKTAx0  |   60bit/1k  |
+ * Toshiba		|  MLC   |  Tx58TEGxDDKTAx0  |			   |
+ * Samsung		|  MLC   |  K9LB(HC/PD/MD)G08U0(1)D  |   8bit/512B  |
+ * Samsung		|  MLC   |  K9GAG08U0E	     |   24bit/1KB |
+ * Samsung		|  MLC   |  K9LBG08U0E	     |   24bit/1KB |
+ * Samsung		|  MLC   |  K9G8G08U0C	     |   24bit/1KB |
+ * Samsung		|  MLC   |  K9GAG08U0F	     |   24bit/1KB |
+ * Samsung		|  MLC   |  K9LBG08U0M	     |             |
+ * Samsung		|  MLC   |  K9GBG08U0A	     |   24bit/1KB |
+ * Samsung		|  MLC   |  K9GBG08U0B	     |   40bit/1KB |
+ * Hynix		|  MLC   |  H27UAG8T2A	     |			   |
+ * Hynix		|  MLC   |  H27UAG8T2B	     |			   |
+ * Hynix		|  MLC   |  H27UBG8T2A	     |			   |
+ * Hynix		|  MLC   |  H27UBG8T2BTR	 |	 24bit/1KB |
+ * Hynix		|  MLC   |  H27UCG8T2A		 |	 40bit/1KB |
+ * Hynix		|  MLC   |  H27UBG8T2C		 |	 40bit/1KB |
+ * MISC			|  MLC   |  P1UAGA30AT-GCA	 |	 8bit/512  |
+ * MISC			|  MLC   |  PSU8GA30AT-GIA/ASU8GA30IT-G30CA	 |	 4bit/512  |
+ * MISC			|  SLC   |  PSU2GA30AT   	 |	 1bit/512  |   1.36
+ * Toshiba		|  SLC   |  TC58NVG2S0HTA00  |	 24bit/1K  |   1.37
+ * Toshiba		|  SLC   |  TC58NVG3S0HTA00  |   24bit/1K  |   1.37
+ * Micron		|  SLC	 |  MT29F2G08ABAEA   |   4bit/512 |
+ * Spansion		|  SLC	 | S34ML02G200TFI000	 | 24bit/1K |
+ * Spansion		|  SLC	 | S34ML04G200TFI000	 | 24bit/1K |  1.38
+ * MXIC Macronix|  SLC	 | MX30UF2G18AC 1.8V | 4bit/512 |  1.39
+ *
+ */
+static struct nand_flash_special_dev nand_flash_special_table[] = {
+
+	/************************* 1.8V MXIC Macronix **************************/
+	{       /* SLC 4bit/512 1.8V */
+		.name      = "MX30UF2G18AC",
+		.id        = {0xC2, 0xAA, 0x90, 0x15, 0x06},
+		.length    = 5,
+		.chipsize  = _256M,
+		.probe     = NULL,
+		.pagesize  = _2K,
+		.erasesize = _128K,
+		.oobsize   = 64,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+
+	/****************************** Spansion *******************************/
+
+	{		/* SLC S34ML02G200TFI000 */
+		.name      = "S34ML02G200TFI000",
+		.id        = {0x01, 0xDA, 0x90, 0x95, 0x46, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _256M,
+		.probe     = NULL,
+		.pagesize  = _2K,
+		.erasesize = _128K,
+		.oobsize   = 128,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+
+	{		/* SLC S34ML04G200TFI000 */
+		.name      = "S34ML04G200TFI000",
+		.id        = {0x01, 0xDC, 0x90, 0x95, 0x56, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _512M,
+		.probe     = NULL,
+		.pagesize  = _2K,
+		.erasesize = _128K,
+		.oobsize   = 128,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+
+	/****************************** Micron *******************************/
+
+	{        /* MLC 40bit/1k */
+		.name      = "MT29F64G08CBABA",
+		.id        = {0x2C, 0x64, 0x44, 0x4B, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _8G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _2M,
+		.oobsize   = 744,
+		.options   = 0,
+		.read_retry_type = NAND_RR_MICRON,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = NAND_RANDOMIZER | NAND_CHIP_MICRON,
+	},
+	{        /* MLC 40bit/1k */
+		.name      = "MT29F32G08CBADA",
+		.id        = {0x2C, 0x44, 0x44, 0x4B, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _2M,
+		.oobsize   = 744,
+		.options   = 0,
+		.read_retry_type = NAND_RR_MICRON,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{        /* SLC 4bit/512 */
+		.name      = "MT29F8G08ABxBA",
+		.id        = {0x2C, 0x38, 0x00, 0x26, 0x85, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _1G,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _512K,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 12bit/512 */
+		.name      = "MT29F16G08CBABx",
+		.id        = {0x2C, 0x48, 0x04, 0x46, 0x85, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _2G,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _1M,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 24bit/1k */
+		.name      = "MT29F16G08CBACA",
+		.id        = {0x2C, 0x48, 0x04, 0x4A, 0xA5, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _2G,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _1M,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 24bit/1k */
+		.name      = "MT29F32G08CBACA",
+		.id        = {0x2C, 0x68, 0x04, 0x4A, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _1M,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 24bit/1k */
+		.name      = "MT29F64G08CxxAA",
+		.id        = {0x2C, 0x88, 0x04, 0x4B, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _8G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _2M,
+		.oobsize   = 448,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{        /* MLC 24bit/1k 2CE */
+		.name      = "MT29F256G08CJAAA",
+		.id        = {0x2C, 0xA8, 0x05, 0xCB, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _16G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _2M,
+		.oobsize   = 448,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{        /* MLC 40bit/1k */
+		.name      = "MT29F256G08CMCBB",
+		.id        = {0x2C, 0x64, 0x44, 0x4B, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _8G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _2M,
+		.oobsize   = 744,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* SLC 8bit/512 */
+		.name      = "MT29F8G08ABACA",
+		.id        = {0x2C, 0xD3, 0x90, 0xA6, 0x64, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _1G,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _256K,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* SLC 8bit/512 */
+		.name      = "MT29F4G08ABAEA",
+		.id        = {0x2C, 0xDC, 0x90, 0xA6, 0x54, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _512M,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _256K,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* SLC 8bit/512 */
+		.name      = "MT29F2G08ABAFA",
+		.id        = {0x2C, 0xDA, 0x90, 0x95, 0x04, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _256M,
+		.probe     = NULL,
+		.pagesize  = _2K,
+		.erasesize = _128K,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{		/* SLC MT29F2G08ABAEA */
+		.name      = "MT29F2G08ABAEA",
+		.id        = {0x2C, 0xDA, 0x90, 0x95, 0x06, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _256M,
+		.probe     = NULL,
+		.pagesize  = _2K,
+		.erasesize = _128K,
+		.oobsize   = 64,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* SLC 8bit/512 */
+		.name      = "MT29F16G08ABACA",
+		.id        = {0x2C, 0x48, 0x00, 0x26, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _2G,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _512K,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+
+	/****************************** Toshaba *******************************/
+
+	{       /* MLC 24bit/1k 32nm */
+		.name      = "TC58NVG4D2FTA00",
+		.id        = {0x98, 0xD5, 0x94, 0x32, 0x76, 0x55, 0x00, 0x00},
+		.length    = 6,
+		.chipsize  = _2G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _1M,
+		.oobsize   = 448,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 24bit/1k 32nm 2CE*/
+		.name      = "TH58NVG6D2FTA20",
+		.id        = {0x98, 0xD7, 0x94, 0x32, 0x76, 0x55, 0x00, 0x00},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _1M,
+		.oobsize   = 448,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 40bit/1k 24nm */
+		.name      = "TC58NVG5D2HTA00 24nm",
+		.id        = {0x98, 0xD7, 0x94, 0x32, 0x76, 0x56, 0x08, 0x00},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _1M,
+		.oobsize   = 640,
+		.options   = 0,
+		.read_retry_type = NAND_RR_TOSHIBA_24nm,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{       /* MLC 40bit/1k */
+		.name      = "TC58NVG6D2GTA00",
+		.id        = {0x98, 0xDE, 0x94, 0x82, 0x76, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _8G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _2M,
+		.oobsize   = 640,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 19nm */
+		.name      = "TC58NVG6DCJTA00 19nm",
+		.id        = {0x98, 0xDE, 0x84, 0x93, 0x72, 0x57, 0x08, 0x04},
+		.length    = 8,
+		.chipsize  = _8G,
+		.probe     = NULL,
+		.pagesize  = _16K,
+		.erasesize = _4M,
+		.oobsize   = 1280,
+		.options   = 0,
+		.read_retry_type = NAND_RR_TOSHIBA_24nm,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{       /* MLC 19nm */
+		.name      = "TC58TEG5DCJTA00 19nm",
+		.id        = {0x98, 0xD7, 0x84, 0x93, 0x72, 0x57, 0x08, 0x04},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = _16K,
+		.erasesize = _4M,
+		.oobsize   = 1280,
+		.options   = 0,
+		.read_retry_type = NAND_RR_TOSHIBA_24nm,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER | NAND_CHIP_TOSHIBA_TOGGLE_10,
+	},
+	{       /* SLC 8bit/512 */
+		.name      = "TC58NVG0S3HTA00",
+		.id        = {0x98, 0xF1, 0x80, 0x15, 0x72, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _128M,
+		.probe     = NULL,
+		.pagesize  = _2K,
+		.erasesize = _128K,
+		.oobsize   = 128,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		/*
+		 * Datasheet: read one column of any page in each block. If the
+		 * data of the column is 00 (Hex), define the block as a bad
+		 * block.
+		 */
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 8bit/512 */
+		.name      = "TC58NVG1S3HTA00",
+		.id        = {0x98, 0xDA, 0x90, 0x15, 0x76, 0x16, 0x08, 0x00},
+		.length    = 7,
+		.chipsize  = _256M,
+		.probe     = NULL,
+		.pagesize  = _2K,
+		.erasesize = _128K,
+		.oobsize   = 128,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 4bit/512 */
+		.name      = "TC58NVG1S3ETA00",
+		.id        = {0x98, 0xDA, 0x90, 0x15, 0x76, 0x14, 0x03, 0x00},
+		.length    = 7,
+		.chipsize  = _256M,
+		.probe     = NULL,
+		.pagesize  = _2K,
+		.erasesize = _128K,
+		.oobsize   = 64,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 4bit/512 */
+		.name      = "TC58NVG3S0FTA00",
+		.id        = {0x98, 0xD3, 0x90, 0x26, 0x76, 0x15, 0x02, 0x08},
+		.length    = 8,
+		.chipsize  = _1G,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _256K,
+		.oobsize   = 232,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 24bit/1k */
+		.name      = "TC58NVG3S0HTA00",
+		.id        = {0x98, 0xD3, 0x91, 0x26, 0x76, 0x16, 0x08, 0x00},
+		.length    = 8,
+		.chipsize  = _1G,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _256K,
+		.oobsize   = 256,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 24bit/1k */
+		.name      = "TC58NVG2S0HTA00",
+		.id        = {0x98, 0xDC, 0x90, 0x26, 0x76, 0x16, 0x08, 0x00},
+		.length    = 8,
+		.chipsize  = _512M,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _256K,
+		.oobsize   = 256,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 4bit/512 */
+		.name      = "TC58NVG2S0FTA00",
+		.id        = {0x98, 0xDC, 0x90, 0x26, 0x76, 0x15, 0x01, 0x08},
+		.length    = 8,
+		.chipsize  = _512M,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _256K,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 4bit/512 */
+		.name      = "TH58NVG2S3HTA00",
+		.id        = {0x98, 0xDC, 0x91, 0x15, 0x76},
+		.length    = 5,
+		.chipsize  = _512M,
+		.probe     = NULL,
+		.pagesize  = _2K,
+		.erasesize = _128K,
+		.oobsize   = 128,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* TLC 60bit/1k 19nm */
+		.name      = "TC58NVG5T2JTA00 19nm TLC",
+		/* datasheet says 6 ids id data, but really has 8 ids. */
+		.id        = {0x98, 0xD7, 0x98, 0x92, 0x72, 0x57, 0x08, 0x10},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _4M,
+		.oobsize   = 1024,
+		.options   = 0,
+		.read_retry_type = NAND_RR_TOSHIBA_24nm,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{	/* TLC 60bit/1k 19nm */
+		.name	   = "TC58TEG5DCKTAx0 19nm MLC",
+		/* datasheet says 6 ids id data, but really has 8 ids. */
+		.id	   = {0x98, 0xD7, 0x84, 0x93, 0x72, 0x50, 0x08, 0x04},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe	   = NULL,
+		.pagesize  = _16K,
+		.erasesize = _4M,
+		.oobsize   = 1280,
+		.options   = 0,
+		.read_retry_type = NAND_RR_TOSHIBA_19nm,
+		.badblock_pos	 = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{
+		.name	   = "Tx58TEGxDDKTAx0 19nm MLC",
+		.id	   = {0x98, 0xDE, 0x94, 0x93, 0x76, 0x50},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe	   = NULL,
+		.pagesize  = _16K,
+		.erasesize = _4M,
+		.oobsize   = 1280,
+		.options   = 0,
+		.read_retry_type = NAND_RR_TOSHIBA_19nm,
+		.badblock_pos	 = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	/******************************* Samsung ******************************/
+	{       /* MLC 8bit/512B */
+		.name     = "K9LB(HC/PD/MD)G08U0(1)D",
+		.id       = {0xEC, 0xD7, 0xD5, 0x29, 0x38, 0x41, 0x00, 0x00},
+		.length   = 6,
+		.chipsize = _4G,
+		.probe    = samsung_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 24bit/1KB */
+		.name      = "K9GAG08U0E",
+		.id        = {0xEC, 0xD5, 0x84, 0x72, 0x50, 0x42, 0x00, 0x00},
+		.length    = 6,
+		.chipsize  = _2G,
+		.probe     = samsung_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 24bit/1KB */
+		.name     = "K9LBG08U0E",
+		.id       = {0xEC, 0xD7, 0xC5, 0x72, 0x54, 0x42, 0x00, 0x00},
+		.length   = 6,
+		.chipsize = _4G,
+		.probe    = samsung_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 24bit/1KB */
+		.name     = "K9G8G08U0C",
+		.id       = {0xEC, 0xD3, 0x84, 0x72, 0x50, 0x42, 0x00, 0x00},
+		.length   = 6,
+		.chipsize = _1G,
+		.probe    = samsung_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 24bit/1k */
+		.name      = "K9GAG08U0F",
+		.id        = {0xEC, 0xD5, 0x94, 0x76, 0x54, 0x43, 0x00, 0x00},
+		.length    = 6,
+		.chipsize  = _2G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _1M,
+		.oobsize   = 512,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC */
+		.name      = "K9LBG08U0M",
+		.id        = {0xEC, 0xD7, 0x55, 0xB6, 0x78, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _512K,
+		.oobsize   = 128,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 24bit/1k */
+		.name      = "K9GBG08U0A 20nm",
+		.id        = {0xEC, 0xD7, 0x94, 0x7A, 0x54, 0x43, 0x00, 0x00},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _1M,
+		.oobsize   = 640,
+		.options   = 0,
+		.read_retry_type = NAND_RR_SAMSUNG,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{        /* MLC 40bit/1k */
+		.name      = "K9GBG08U0B",
+		.id        = {0xEC, 0xD7, 0x94, 0x7E, 0x64, 0x44, 0x00, 0x00},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _1M,
+		.oobsize   = 1024,
+		.options   = 0,
+		.read_retry_type = NAND_RR_SAMSUNG,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+
+	/*********************************** Hynix ****************************/
+	{       /* MLC */
+		.name     = "H27UAG8T2A",
+		.id       = {0xAD, 0xD5, 0x94, 0x25, 0x44, 0x41, },
+		.length   = 6,
+		.chipsize = _2G,
+		.probe    = hynix_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC */
+		.name     = "H27UAG8T2B",
+		.id       = {0xAD, 0xD5, 0x94, 0x9A, 0x74, 0x42, },
+		.length   = 6,
+		.chipsize = _2G,
+		.probe    = hynix_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC */
+		.name     = "H27UBG8T2A",
+		.id       = {0xAD, 0xD7, 0x94, 0x9A, 0x74, 0x42, },
+		.length   = 6,
+		.chipsize = _4G,
+		.probe    = hynix_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 24bit/1K, 26nm TODO: Need read retry, chip is EOS */
+		.name      = "H27UBG8T2BTR 26nm",
+		.id        = {0xAD, 0xD7, 0x94, 0xDA, 0x74, 0xC3, },
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _2M,
+		.oobsize   = 640,
+		.options   = 0,
+		.read_retry_type = NAND_RR_HYNIX_BG_BDIE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{        /* MLC 40bit/1k */
+		.name      = "H27UCG8T2A",
+		.id        = {0xAD, 0xDE, 0x94, 0xDA, 0x74, 0xC4, },
+		.length    = 6,
+		.chipsize  = _8G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _2M,
+		.oobsize   = 640,
+		.options   = 0,
+		.read_retry_type = NAND_RR_HYNIX_CG_ADIE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{        /* MLC 40bit/1k */
+		.name      = "H27UBG8T2C",
+		.id        = {0xAD, 0xD7, 0x94, 0x91, 0x60, 0x44, },
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = _8K,
+		.erasesize = _2M,
+		.oobsize   = 640,
+		.options   = 0,
+		.read_retry_type = NAND_RR_HYNIX_BG_CDIE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+
+	/********************** MISC ******************************************/
+	{        /* MLC 8bit/512 */
+		.name      = "P1UAGA30AT-GCA",
+		.id        = {0xC8, 0xD5, 0x14, 0x29, 0x34, 0x01, },
+		.length    = 6,
+		.chipsize  = _2G,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _512K,
+		.oobsize   = 218,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 4bit/512 */
+		/*
+		 * PowerFlash ASU8GA30IT-G30CA ID and MIRA PSU8GA30AT-GIA ID are
+		 * the same ID
+		 */
+		.name      = "PSU8GA30AT-GIA/ASU8GA30IT-G30CA",
+		.id        = {0xC8, 0xD3, 0x90, 0x19, 0x34, 0x01, },
+		.length    = 6,
+		.chipsize  = _1G,
+		.probe     = NULL,
+		.pagesize  = _4K,
+		.erasesize = _256K,
+		.oobsize   = 218,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{        /* SLC 1bit/512 */
+		.name      = "PSU2GA30AT",
+		.id        = {0x7F, 0x7F, 0x7F, 0x7F, 0xC8, 0xDA, 0x00, 0x15, },
+		.length    = 8,
+		.chipsize  = _256M,
+		.probe     = NULL,
+		.pagesize  = _2K,
+		.erasesize = _128K,
+		.oobsize   = 64,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{{0}, 0, 0, 0, 0, 0, 0, 0, 0},
+};
+
+struct nand_dev_t g_nand_dev;
+/*****************************************************************************/
+struct nand_flash_dev *hifmc_get_spl_flash_type(struct mtd_info *mtd,
+		unsigned char *id)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct nand_flash_special_dev *spl_dev = nand_flash_special_table;
+	struct nand_flash_dev *type = &g_nand_dev.flash_dev;
+	struct nand_dev_t *nand_dev = &g_nand_dev;
+
+	FMC_PR(BT_DBG, "\t *-Start find special nand flash\n");
+
+	pr_info("Nand ID: %#X %#X %#X %#X %#X %#X %#X %#X\n", id[0], id[1],
+			id[2], id[3], id[4], id[5], id[6], id[7]);
+
+	for (; spl_dev->length; spl_dev++) {
+		if (memcmp(id, spl_dev->id, spl_dev->length))
+			continue;
+
+		FMC_PR(BT_DBG, "\t |-Found special Nand flash: %s\n",
+				spl_dev->name);
+
+		if (spl_dev->probe) {
+			type = spl_dev->probe(id);
+		} else {
+			type->options   = spl_dev->options;
+			type->pagesize  = spl_dev->pagesize;
+			type->erasesize = spl_dev->erasesize;
+			type->oobsize = spl_dev->oobsize;
+		}
+
+		type->name = spl_dev->name;
+		type->id_len = spl_dev->length;
+		memcpy(type->id, id, type->id_len);
+		type->chipsize = (unsigned int)(spl_dev->chipsize >> 20);
+		FMC_PR(BT_DBG, "\t |-Save struct nand_flash_dev info\n");
+
+		memcpy(nand_dev->ids, id, MAX_NAND_ID_LEN);
+		nand_dev->oobsize = type->oobsize;
+		nand_dev->flags = spl_dev->flags;
+		nand_dev->read_retry_type = spl_dev->read_retry_type;
+		FMC_PR(BT_DBG, "\t |-Save struct nand_dev_t information\n");
+
+		mtd->size = spl_dev->chipsize;
+
+		return type;
+	}
+	nand_dev->read_retry_type = NAND_RR_NONE;
+
+	chip->cmdfunc(mtd, NAND_CMD_READID, 0x00, -1);
+	chip->read_byte(mtd);
+	chip->read_byte(mtd);
+
+	FMC_PR(BT_DBG, "\t *-Not found special nand flash\n");
+
+	return NULL;
+}
+
+/*****************************************************************************/
+void hifmc_spl_ids_register(void)
+{
+	pr_info("Special NAND id table Version %s\n", DRV_VERSION);
+	get_spi_nand_flash_type_hook = hifmc_get_spl_flash_type;
+}
diff --git a/drivers/mtd/nand/hinfc610/Kconfig b/drivers/mtd/nand/hinfc610/Kconfig
new file mode 100644
index 0000000..95d9ce2
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/Kconfig
@@ -0,0 +1,94 @@
+menuconfig MTD_NAND_HINFC610
+	tristate "Hisilicon NAND Controller v610 Nand devices Support"
+	depends on !MTD_SPI_NAND_HISI_BVT && (ARCH_HI3516A)
+	select YAFFS_FS
+	select MISC_FILESYSTEMS
+	select MTD_BLOCK
+	select YAFFS_YAFFS2
+	help
+	  When the config is set, the kernel will support Hisilicon
+	  NAND Controller v610 devices. It means that the kernel would
+	  control the nand flash with the nand controller v610 device
+	  in operation.
+
+if MTD_NAND_HINFC610
+
+config HINFC610_MAX_CHIP
+	int "number of nand flash chip (1,4)"
+	range 1 4
+	default 1
+	help
+	  nand controller v610 device only support 1 or 2 nand flash chip,
+	  your should not config other value.
+
+config HINFC610_DBG_NAND_DEBUG
+	bool "Debug: create debug file to control debug type"
+	default y
+	help
+	  When the config is set, the kernel will add the "debug" file
+	  to control debug type. When the config is set, we could choose
+	  the debugging type to display the informations of the nand controller
+	  v610 device in operation.
+
+config HINFC610_DBG_NAND_DUMP
+	bool "Debug: display read/write/erase process nand data"
+	depends on HINFC610_DBG_NAND_DEBUG
+	default y
+	default n if (ARCH_HI3516A)
+	help
+	  When the config is set, the kernel will add "dump" file to
+	  display all nand operation and data.When the "HINFC610_DBG_NAND_DEBUG"
+	  has been set, the nand controller v610 device will display
+	  all the operations and data.
+
+config HINFC610_DBG_NAND_ERASE_COUNT
+	bool "Debug: display last erase count"
+	depends on HINFC610_DBG_NAND_DEBUG
+	default y
+	default n if (ARCH_HI3516A)
+	help
+	  When the config is set, the kernel will add "erase_count" file
+	  to display last erase count. When the "HINFC610_DBG_NAND_DEBUG"
+	  has been set, the nand controller v610 device will display
+	  the last erase count.
+
+config HINFC610_DBG_NAND_ECC_COUNT
+	bool "Debug: display last ecc count."
+	depends on HINFC610_DBG_NAND_DEBUG
+	default y
+	default n if (ARCH_HI3516A)
+	help
+	  When the config is set, the kernel will add "ecc_count"
+	  to display last ecc count. When the "HINFC610_DBG_NAND_DEBUG"
+	  has been set, the nand controller v610 device will display
+	  the last ecc count.
+
+config HINFC610_DBG_NAND_READ_RETRY
+	bool "Debug: display read_retry process"
+	depends on HINFC610_DBG_NAND_DEBUG
+	default y
+	default n if (ARCH_HI3516A)
+	help
+	  When the config is set, the kernel will add read_retry file
+	  to display read_retry process.
+
+choice
+	prompt "Pagesize and Ecc Type Select"
+	default HINFC610_AUTO_PAGESIZE_ECC if ARCH_HI3516A
+
+config HINFC610_AUTO_PAGESIZE_ECC
+	bool "Auto"
+	help
+	  When the config is set, pagesize and ecc type will use
+	  hardware config. When we replace the flash, the
+	  controller will identify the pagesize and ecc type of
+	  the flash.
+
+config HINFC610_PAGESIZE_AUTO_ECC_NONE
+	bool "Pagesize Auto, Ecc None"
+	help
+	  select pagesize 2K, ecc none.
+
+endchoice
+
+endif # MTD_NAND_HINFC610
diff --git a/drivers/mtd/nand/hinfc610/Makefile b/drivers/mtd/nand/hinfc610/Makefile
new file mode 100644
index 0000000..9ef9acd
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/Makefile
@@ -0,0 +1,19 @@
+
+obj-$(CONFIG_MTD_NAND_HINFC610) += hinfc610.o hinfc610_os.o hinfc610_gen.o \
+	hinfc620_gen.o hinfc610_dbg_inf.o \
+	hinfc610_read_retry_hynix_bg_cdie.o \
+	hinfc610_read_retry_hynix_bg_bdie.o \
+	hinfc610_read_retry_hynix_cg_adie.o \
+	hinfc610_read_retry_micron.o  \
+	hinfc610_read_retry_samsung.o \
+	hinfc610_read_retry_toshiba.o \
+	hinfc610_read_retry.o \
+	hinfc610_sync.o \
+	hinfc610_sync_onfi_23.o \
+	hinfc610_sync_toggle.o
+
+obj-$(CONFIG_HINFC610_DBG_NAND_DEBUG) += hinfc610_dbg.o hinfc610_dbg_ecc_dump.o
+obj-$(CONFIG_HINFC610_DBG_NAND_DUMP) += hinfc610_dbg_dump.o
+obj-$(CONFIG_HINFC610_DBG_NAND_ERASE_COUNT) += hinfc610_dbg_erase_count.o
+obj-$(CONFIG_HINFC610_DBG_NAND_ECC_COUNT) += hinfc610_dbg_ecc_count.o
+obj-$(CONFIG_HINFC610_DBG_NAND_READ_RETRY) += hinfc610_dbg_read_retry.o
diff --git a/drivers/mtd/nand/hinfc610/hinfc610.c b/drivers/mtd/nand/hinfc610/hinfc610.c
new file mode 100644
index 0000000..eb8cb7f
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610.c
@@ -0,0 +1,1196 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#define pr_fmt(fmt) "hinfc610: " fmt
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+#include "hinfc610_dbg_inf.h"
+#include "hinfc610_gen.h"
+#include "hinfc620_gen.h"
+#include "hinfc610_sync.h"
+#include "hinfc610_read_retry.h"
+
+/*****************************************************************************/
+static unsigned int get_8bits(unsigned char byte)
+{
+	int ix = 0;
+	int num = 0;
+
+	if (byte == 0xFF)
+		return 8;
+	if (!byte)
+		return 0;
+
+	while (ix++ < 8) {
+		if ((byte & 1))
+			num++;
+		byte = (byte >> 1);
+	}
+	return num;
+}
+/*****************************************************************************/
+
+static unsigned int get_16bits(unsigned short byte)
+{
+	int ix = 0;
+	int num = 0;
+
+	if (byte == 0xFFFF)
+		return 16;
+	if (!byte)
+		return 0;
+
+	while (ix++ < 16) {
+		if ((byte & 1))
+			num++;
+		byte = (byte >> 1);
+	}
+	return num;
+}
+/*****************************************************************************/
+
+static void hinfc610_dma_transfer(struct hinfc_host *host, int todev)
+{
+	unsigned long reg_val;
+	unsigned int dma_addr = (unsigned int)host->dma_buffer;
+
+	hinfc_write(host, dma_addr, HINFC610_DMA_ADDR_DATA);
+
+	dma_addr += HINFC610_DMA_ADDR_OFFSET;
+	hinfc_write(host, dma_addr, HINFC610_DMA_ADDR_DATA1);
+
+	dma_addr += HINFC610_DMA_ADDR_OFFSET;
+	hinfc_write(host, dma_addr, HINFC610_DMA_ADDR_DATA2);
+
+	dma_addr += HINFC610_DMA_ADDR_OFFSET;
+	hinfc_write(host, dma_addr, HINFC610_DMA_ADDR_DATA3);
+
+	/* 32K PAGESIZE need below. */
+	dma_addr += HINFC610_DMA_ADDR_OFFSET;
+	hinfc_write(host, dma_addr, HINFC610_DMA_ADDR_DATA4);
+
+	dma_addr += HINFC610_DMA_ADDR_OFFSET;
+	hinfc_write(host, dma_addr, HINFC610_DMA_ADDR_DATA5);
+
+	dma_addr += HINFC610_DMA_ADDR_OFFSET;
+	hinfc_write(host, dma_addr, HINFC610_DMA_ADDR_DATA6);
+
+	dma_addr += HINFC610_DMA_ADDR_OFFSET;
+	hinfc_write(host, dma_addr, HINFC610_DMA_ADDR_DATA7);
+
+	hinfc_write(host, host->dma_oob, HINFC610_DMA_ADDR_OOB);
+
+	if (host->ecctype == NAND_ECC_NONE) {
+		hinfc_write(host,
+			((host->oobsize & HINFC610_DMA_LEN_OOB_MASK)
+			 << HINFC610_DMA_LEN_OOB_SHIFT),
+			HINFC610_DMA_LEN);
+
+		hinfc_write(host,
+			HINFC610_DMA_PARA_DATA_RW_EN
+			| HINFC610_DMA_PARA_OOB_RW_EN,
+			HINFC610_DMA_PARA);
+	} else
+		hinfc_write(host,
+			HINFC610_DMA_PARA_DATA_RW_EN
+			| HINFC610_DMA_PARA_OOB_RW_EN
+			| HINFC610_DMA_PARA_DATA_EDC_EN
+			| HINFC610_DMA_PARA_OOB_EDC_EN,
+			HINFC610_DMA_PARA);
+
+	reg_val = (HINFC610_DMA_CTRL_DMA_START
+		| HINFC610_DMA_CTRL_BURST4_EN
+		| HINFC610_DMA_CTRL_BURST8_EN
+		| HINFC610_DMA_CTRL_BURST16_EN
+		| ((host->addr_cycle == 4 ? 1 : 0)
+		   << HINFC610_DMA_CTRL_ADDR_NUM_SHIFT)
+		| (((unsigned int)host->chipselect & HINFC610_DMA_CTRL_CS_MASK)
+		   << HINFC610_DMA_CTRL_CS_SHIFT));
+
+	if (todev)
+		reg_val |= HINFC610_DMA_CTRL_WE;
+
+	hinfc_write(host, reg_val, HINFC610_DMA_CTRL);
+
+	do {
+		unsigned int timeout = 0xF0000000;
+
+		while ((hinfc_read(host, HINFC610_DMA_CTRL))
+			& HINFC610_DMA_CTRL_DMA_START && timeout) {
+			_cond_resched();
+			timeout--;
+		}
+		if (!timeout)
+			PR_BUG("Wait DMA finish timeout.\n");
+	} while (0);
+}
+/*****************************************************************************/
+
+static void hinfc610_sync_entry(struct hinfc_host *host)
+{
+	struct nand_sync *sync = host->sync;
+	struct nand_chip *chip = host->chip;
+
+	if (!sync) {
+		PR_BUG("this NAND not support sync feature.\n");
+		return;
+	}
+
+	if (HINFC610_IS_SYNC(host)) {
+		PR_BUG("this NAND not support sync feature.\n");
+		return;
+	}
+
+	if (sync->enable)
+		sync->enable(chip);
+
+	clk_prepare_enable(host->clk);
+
+	switch (sync->type) {
+	case NAND_TYPE_TOGGLE_10:
+		host->NFC_CON |= HINFC610_CON_NF_MODE_TOGGLE;
+		host->NFC_CON_ECC_NONE |= HINFC610_CON_NF_MODE_TOGGLE;
+		break;
+
+	case NAND_TYPE_ONFI_23:
+		host->NFC_CON |= HINFC610_CON_NF_MODE_ONFI_23;
+		host->NFC_CON_ECC_NONE |= HINFC610_CON_NF_MODE_ONFI_23;
+		break;
+
+	case NAND_TYPE_ONFI_30:
+		host->NFC_CON |= HINFC610_CON_NF_MODE_ONFI_30;
+		host->NFC_CON_ECC_NONE |= HINFC610_CON_NF_MODE_ONFI_30;
+		break;
+
+	default:
+		PR_BUG("Unsupport sync type 0x%08X.\n", sync->type);
+		break;
+	}
+}
+/*****************************************************************************/
+
+static void hinfc610_sync_exit(struct hinfc_host *host)
+{
+	struct nand_sync *sync = host->sync;
+	struct nand_chip *chip = host->chip;
+
+	if (!HINFC610_IS_SYNC(host)) {
+		PR_BUG("Current already exit from sync feature.\n");
+		return;
+	}
+
+	if (sync->disable)
+		sync->disable(chip);
+
+	host->NFC_CON &= ~HINFC610_CON_NF_MODE_MASK;
+	host->NFC_CON_ECC_NONE &= ~HINFC610_CON_NF_MODE_MASK;
+
+	clk_disable_unprepare(host->clk);
+}
+/*****************************************************************************/
+
+void hinfc610_cmd_ctrl(struct mtd_info *mtd, int dat, unsigned int ctrl)
+{
+	int is_cache_invalid = 1;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hinfc_host *host = chip->priv;
+
+	if (ctrl & NAND_ALE) {
+		unsigned int addr_value = 0;
+		unsigned int addr_offset = 0;
+
+		if (ctrl & NAND_CTRL_CHANGE) {
+			host->addr_cycle = 0x0;
+			host->addr_value[0] = 0x0;
+			host->addr_value[1] = 0x0;
+		}
+		addr_offset = host->addr_cycle << 3;
+
+		if (host->addr_cycle >= HINFC610_ADDR_CYCLE_MASK) {
+			addr_offset =
+			    (host->addr_cycle - HINFC610_ADDR_CYCLE_MASK) << 3;
+			addr_value = 1;
+		}
+
+		host->addr_value[addr_value] |=
+			((dat & 0xff) << addr_offset);
+
+		host->addr_cycle++;
+	}
+
+	if ((ctrl & NAND_CLE) && (ctrl & NAND_CTRL_CHANGE)) {
+		host->command = dat & 0xff;
+		switch (host->command) {
+		case NAND_CMD_PAGEPROG:
+			host->send_cmd_pageprog(host);
+			hinfc610_dbg_write(host);
+			break;
+
+		case NAND_CMD_READSTART:
+			is_cache_invalid = 0;
+			host->send_cmd_readstart(host);
+			hinfc610_dbg_read(host);
+
+			break;
+
+		case NAND_CMD_ERASE2:
+			host->send_cmd_erase(host);
+			hinfc610_dbg_erase(host);
+
+			break;
+
+		case NAND_CMD_READID:
+			memset((unsigned char *)(chip->IO_ADDR_R), 0, 0x10);
+			host->send_cmd_readid(host);
+			break;
+
+		case NAND_CMD_STATUS:
+			host->send_cmd_status(host);
+			break;
+
+		case NAND_CMD_SEQIN:
+		case NAND_CMD_ERASE1:
+		case NAND_CMD_READ0:
+			break;
+		case NAND_CMD_RESET:
+			host->send_cmd_reset(host, host->chipselect);
+			break;
+
+		default:
+			break;
+		}
+	}
+
+	if ((dat == NAND_CMD_NONE) && host->addr_cycle) {
+		if (host->command == NAND_CMD_SEQIN ||
+		    host->command == NAND_CMD_READ0 ||
+		    host->command == NAND_CMD_READID) {
+			host->offset = 0x0;
+			host->column = (host->addr_value[0] & 0xffff);
+		}
+	}
+
+	if (is_cache_invalid) {
+		host->cache_addr_value[0] = ~0;
+		host->cache_addr_value[1] = ~0;
+	}
+}
+/*****************************************************************************/
+
+static int hinfc610_send_cmd_pageprog(struct hinfc_host *host)
+{
+	if (*host->bbm != 0xFF && *host->bbm != 0x00)
+		pr_warn("Attempt to write an invalid bbm. page: 0x%08x, mark: 0x%02x, current process(pid): %s(%d).\n",
+			GET_PAGE_INDEX(host), *host->bbm,
+			current->comm, current->pid);
+
+	if (IS_NAND_SYNC_ASYNC(host))
+		hinfc610_sync_entry(host);
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	hinfc_write(host, host->addr_value[0] & 0xffff0000, HINFC610_ADDRL);
+	hinfc_write(host, host->addr_value[1], HINFC610_ADDRH);
+	hinfc_write(host,
+		((NAND_CMD_STATUS << 16) | (NAND_CMD_PAGEPROG << 8) |
+		 NAND_CMD_SEQIN),
+		HINFC610_CMD);
+
+	*host->epm = 0x0000;
+
+	hinfc610_dma_transfer(host, 1);
+
+	if (IS_NAND_SYNC_ASYNC(host))
+		hinfc610_sync_exit(host);
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_get_data_status(struct hinfc_host *host)
+{
+	unsigned int page_status = 0;
+
+	if (IS_PS_UN_ECC(host))
+		page_status = HINFC610_PS_UC_ECC;
+
+	/* this is block start address */
+	if (!((host->addr_value[0] >> 16) & host->block_page_mask)) {
+
+		/* it is a bad block */
+		if (*host->bbm == 0x00) {
+			page_status |= HINFC610_PS_BAD_BLOCK;
+			goto out;
+		}
+
+		if (*host->bbm != 0xFF) {
+			page_status |= HINFC610_PS_BBM_ERROR;
+
+			/*
+			 * if there are more than 2 bits flipping, it is
+			 * maybe a bad block
+			 */
+			if (!IS_PS_UN_ECC(host) || get_8bits(*host->bbm) < 6) {
+				page_status |= HINFC610_PS_BAD_BLOCK;
+				goto out;
+			}
+		}
+	}
+
+	if (*host->epm == 0x0000)
+		goto out;
+
+	if (*host->epm == 0xFFFF) {
+		page_status |= HINFC610_PS_EMPTY_PAGE;
+		goto out;
+	}
+
+	page_status |= HINFC610_PS_EPM_ERROR;
+
+	if (IS_PS_UN_ECC(host) && get_16bits(*host->epm) > 12) {
+		page_status |= HINFC610_PS_EMPTY_PAGE;
+		goto out;
+	}
+
+out:
+	return page_status;
+}
+/*****************************************************************************/
+
+static int hinfc610_do_read_retry(struct hinfc_host *host)
+{
+	int ix;
+
+	for (ix = 1; IS_PS_UN_ECC(host) && ix < host->read_retry->count; ix++) {
+
+		hinfc_write(host, HINFC610_INTCLR_UE | HINFC610_INTCLR_CE,
+			    HINFC610_INTCLR);
+
+		host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+		host->read_retry->set_rr_param(host, ix);
+
+		/* enable ecc and randomizer */
+		host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+		hinfc_write(host, HINFC610_INTCLR_UE | HINFC610_INTCLR_CE,
+			    HINFC610_INTCLR);
+		hinfc_write(host, host->NFC_CON, HINFC610_CON);
+		hinfc_write(host, host->addr_value[0] & 0xffff0000,
+			    HINFC610_ADDRL);
+		hinfc_write(host, host->addr_value[1], HINFC610_ADDRH);
+		hinfc_write(host,
+			    HINFC_CMD_SEQ(NAND_CMD_READ0, NAND_CMD_READSTART),
+			    HINFC610_CMD);
+
+		hinfc610_dma_transfer(host, 0);
+
+		if (hinfc_read(host, HINFC610_INTS) & HINFC610_INTS_UE)
+			host->page_status |= HINFC610_PS_UC_ECC;
+		else
+			host->page_status &= ~HINFC610_PS_UC_ECC;
+	}
+
+	host->page_status = hinfc610_get_data_status(host);
+
+	hinfc610_dbg_read_retry(host, ix);
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+	host->read_retry->reset_rr_param(host);
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_send_cmd_readstart(struct hinfc_host *host)
+{
+	if ((host->addr_value[0] == host->cache_addr_value[0]) &&
+	    (host->addr_value[1] == host->cache_addr_value[1]))
+		return 0;
+
+	if (IS_NAND_SYNC_ASYNC(host))
+		hinfc610_sync_entry(host);
+
+	host->page_status = 0;
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	hinfc_write(host, HINFC610_INTCLR_UE | HINFC610_INTCLR_CE,
+		    HINFC610_INTCLR);
+	hinfc_write(host, host->NFC_CON, HINFC610_CON);
+	hinfc_write(host, host->addr_value[0] & 0xffff0000, HINFC610_ADDRL);
+	hinfc_write(host, host->addr_value[1], HINFC610_ADDRH);
+	hinfc_write(host, NAND_CMD_READSTART << 8 | NAND_CMD_READ0,
+		    HINFC610_CMD);
+
+	hinfc610_dma_transfer(host, 0);
+
+	if (hinfc_read(host, HINFC610_INTS) & HINFC610_INTS_UE)
+		host->page_status |= HINFC610_PS_UC_ECC;
+
+	if (host->read_retry || IS_NAND_RANDOM(host)) {
+		host->page_status |= hinfc610_get_data_status(host);
+
+		if (IS_PS_EMPTY_PAGE(host)) {
+			/*
+			 * oob area used by yaffs2 only 32 bytes,
+			 * so we only fill 32 bytes.
+			 */
+			if (IS_NAND_RANDOM(host))
+				memset(host->buffer, 0xFF,
+				       host->pagesize + host->oobsize);
+
+		} else if (!IS_PS_BAD_BLOCK(host)) {
+			/* if NAND chip support read retry */
+			if (IS_PS_UN_ECC(host) && host->read_retry)
+				hinfc610_do_read_retry(host);
+
+		} /* 'else' NAND have a bad block, do nothing. */
+	}
+
+	if (IS_NAND_SYNC_ASYNC(host))
+		hinfc610_sync_exit(host);
+
+	host->cache_addr_value[0] = host->addr_value[0];
+	host->cache_addr_value[1] = host->addr_value[1];
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_send_cmd_erase(struct hinfc_host *host)
+{
+	unsigned int regval;
+
+	/* Don't case the read retry config */
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, host->addr_value[0], HINFC610_ADDRL);
+	hinfc_write(host, (NAND_CMD_ERASE2 << 8) | NAND_CMD_ERASE1,
+		HINFC610_CMD);
+
+	regval = HINFC610_OP_WAIT_READY_EN
+		 | HINFC610_OP_CMD2_EN
+		 | HINFC610_OP_CMD1_EN
+		 | HINFC610_OP_ADDR_EN
+		 | (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK)
+		    << HINFC610_OP_NF_CS_SHIFT)
+		 | ((host->addr_cycle & HINFC610_OP_ADDR_CYCLE_MASK)
+		    << HINFC610_OP_ADDR_CYCLE_SHIFT);
+
+	hinfc_write(host, regval, HINFC610_OP);
+
+	WAIT_CONTROLLER_FINISH();
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_send_cmd_sync_readid(struct hinfc_host *host)
+{
+	unsigned int regval;
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, HINFC610_NANDINFO_LEN, HINFC610_DATA_NUM);
+	hinfc_write(host, NAND_CMD_READID, HINFC610_CMD);
+	hinfc_write(host, 0, HINFC610_ADDRL);
+
+	/* no need to config HINFC610_OP_WAIT_READY_EN, here not config. */
+	regval = HINFC610_OP_CMD1_EN
+		 | HINFC610_OP_ADDR_EN
+		 | HINFC610_OP_READ_DATA_EN
+		 | (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK)
+		    << HINFC610_OP_NF_CS_SHIFT)
+		 | (1 << HINFC610_OP_ADDR_CYCLE_SHIFT)
+		 | HINFC610_OP_READID_EN
+		 | HINFC610_OP_RW_REG_EN;
+
+	hinfc_write(host, regval, HINFC610_OP);
+
+	host->addr_cycle = 0x0;
+
+	WAIT_CONTROLLER_FINISH();
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_send_cmd_async_readid(struct hinfc_host *host)
+{
+	unsigned int regval;
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, HINFC610_NANDINFO_LEN, HINFC610_DATA_NUM);
+	hinfc_write(host, NAND_CMD_READID, HINFC610_CMD);
+	hinfc_write(host, 0, HINFC610_ADDRL);
+
+	/* no need to config HINFC610_OP_WAIT_READY_EN, here not config. */
+	regval = HINFC610_OP_CMD1_EN
+		 | HINFC610_OP_ADDR_EN
+		 | HINFC610_OP_READ_DATA_EN
+		 | (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK)
+		    << HINFC610_OP_NF_CS_SHIFT)
+		 | (1 << HINFC610_OP_ADDR_CYCLE_SHIFT);
+
+	hinfc_write(host, regval, HINFC610_OP);
+
+	host->addr_cycle = 0x0;
+
+	WAIT_CONTROLLER_FINISH();
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_send_cmd_readid(struct hinfc_host *host)
+{
+	if (HINFC610_IS_SYNC(host))
+		return hinfc610_send_cmd_sync_readid(host);
+	else
+		return hinfc610_send_cmd_async_readid(host);
+}
+/*****************************************************************************/
+
+static int hinfc610_enable_ecc_randomizer(struct hinfc_host *host, int ecc_en,
+					  int randomizer_en)
+{
+	unsigned int nfc_con;
+
+	if (IS_NAND_RANDOM(host)) {
+		if (randomizer_en) {
+			host->NFC_CON |= HINFC610_CON_RANDOMIZER_EN;
+			host->NFC_CON_ECC_NONE |= HINFC610_CON_RANDOMIZER_EN;
+		} else {
+			host->NFC_CON &= ~HINFC610_CON_RANDOMIZER_EN;
+			host->NFC_CON_ECC_NONE &= ~HINFC610_CON_RANDOMIZER_EN;
+		}
+	}
+
+	nfc_con = (ecc_en ? host->NFC_CON : host->NFC_CON_ECC_NONE);
+
+	hinfc_write(host, nfc_con, HINFC610_CON);
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_send_cmd_status(struct hinfc_host *host)
+{
+	unsigned int regval;
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, HINFC610_NANDINFO_LEN, HINFC610_DATA_NUM);
+	hinfc_write(host, NAND_CMD_STATUS, HINFC610_CMD);
+
+	/* no need config HINFC610_OP_WAIT_READY_EN, here not config */
+	regval = HINFC610_OP_CMD1_EN
+		 | HINFC610_OP_READ_DATA_EN
+		 | (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK)
+		    << HINFC610_OP_NF_CS_SHIFT);
+
+	hinfc_write(host, regval, HINFC610_OP);
+
+	WAIT_CONTROLLER_FINISH();
+
+	return 0;
+}
+
+/*****************************************************************************/
+static int hinfc610_send_cmd_async_reset(struct hinfc_host *host,
+					 int chipselect)
+{
+	unsigned int regval;
+
+	hinfc_write(host, NAND_CMD_RESET, HINFC610_CMD);
+
+	/* need to config HINFC610_OP_WAIT_READY_EN */
+	regval = HINFC610_OP_CMD1_EN
+		 | ((((unsigned int)chipselect & HINFC610_OP_NF_CS_MASK)
+		    << HINFC610_OP_NF_CS_SHIFT)
+		 | HINFC610_OP_WAIT_READY_EN);
+
+	hinfc_write(host, regval, HINFC610_OP);
+
+	WAIT_CONTROLLER_FINISH();
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_send_cmd_sync_reset(struct hinfc_host *host,
+					int chipselect)
+{
+	unsigned int regval;
+
+	/*
+	 * Regarding the ONFI chip sync mode,
+	 * NAND_CMD_SYNC_RESET make chip remain sync mode.
+	 * But NAND_CMD_RESET will change chip mode to async mode.
+	 */
+	hinfc_write(host, NAND_CMD_SYNC_RESET, HINFC610_CMD);
+
+	/* need to config HINFC610_OP_WAIT_READY_EN */
+	regval = HINFC610_OP_CMD1_EN
+		 | (((unsigned int)chipselect & HINFC610_OP_NF_CS_MASK)
+		     << HINFC610_OP_NF_CS_SHIFT)
+		 | HINFC610_OP_WAIT_READY_EN;
+
+	hinfc_write(host, regval, HINFC610_OP);
+
+	WAIT_CONTROLLER_FINISH();
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_send_cmd_reset(struct hinfc_host *host, int chipselect)
+{
+	if (HINFC610_IS_SYNC(host))
+		return hinfc610_send_cmd_sync_reset(host, chipselect);
+	else
+		return hinfc610_send_cmd_async_reset(host, chipselect);
+}
+/*****************************************************************************/
+
+int hinfc610_dev_ready(struct mtd_info *mtd)
+{
+	return 0x1;
+}
+/*****************************************************************************/
+
+void hinfc610_select_chip(struct mtd_info *mtd, int chipselect)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hinfc_host *host = chip->priv;
+
+	if (chipselect < 0)
+		return;
+
+	if (chipselect > CONFIG_HINFC610_MAX_CHIP)
+		PR_BUG("invalid chipselect: %d\n", chipselect);
+
+	host->chipselect = chipselect;
+}
+/*****************************************************************************/
+
+uint8_t hinfc610_read_byte(struct mtd_info *mtd)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hinfc_host *host = chip->priv;
+
+	if (host->command == NAND_CMD_STATUS)
+		return readb(chip->IO_ADDR_R);
+
+	host->offset++;
+
+	if (host->command == NAND_CMD_READID)
+		return readb(chip->IO_ADDR_R + host->offset - 1);
+
+	return readb(host->buffer + host->column + host->offset - 1);
+}
+/*****************************************************************************/
+
+u16 hinfc610_read_word(struct mtd_info *mtd)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hinfc_host *host = chip->priv;
+
+	host->offset += 2;
+	return readw(host->buffer + host->column + host->offset - 2);
+}
+/*****************************************************************************/
+
+void hinfc610_write_buf(struct mtd_info *mtd, const uint8_t *buf,
+			       int len)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hinfc_host *host = chip->priv;
+
+	memcpy(host->buffer + host->column + host->offset, buf, len);
+	host->offset += len;
+}
+/*****************************************************************************/
+static void hinfc610_ecc_err_num_count(struct mtd_info *mtd,
+		uint8_t ecc_st, int reg)
+{
+	u_char err_num;
+
+	if (ecc_st > 4)
+		ecc_st = 4;
+
+	while (ecc_st) {
+		err_num = GET_ECC_ERR_NUM(--ecc_st, reg);
+		if (err_num == 0xff)
+			mtd->ecc_stats.failed++;
+		else
+			mtd->ecc_stats.corrected += err_num;
+	}
+}
+
+/*****************************************************************************/
+
+void hinfc610_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hinfc_host *host = chip->priv;
+	int reg;
+	uint8_t ecc_step = host->pagesize >> 10;
+
+	memcpy(buf, host->buffer + host->column + host->offset, len);
+	host->offset += len;
+
+	/* 2K or 4K or 8K(1) or 16K(1-1) pagesize */
+	reg = hinfc_read(host, HINFC_ECC_ERR_NUM0_BUF0);
+	hinfc610_ecc_err_num_count(mtd, ecc_step, reg);
+
+	if (ecc_step > 4) {
+		/* 8K(2) or 16K(1-2) pagesize */
+		reg = hinfc_read(host, HINFC_ECC_ERR_NUM1_BUF0);
+		hinfc610_ecc_err_num_count(mtd, ecc_step, reg);
+		if (ecc_step > 8) {
+			/* 16K(2-1) pagesize */
+			reg = hinfc_read(host, HINFC_ECC_ERR_NUM0_BUF1);
+			hinfc610_ecc_err_num_count(mtd, ecc_step, reg);
+			/* 16K(2-2) pagesize */
+			reg = hinfc_read(host, HINFC_ECC_ERR_NUM1_BUF1);
+			hinfc610_ecc_err_num_count(mtd, ecc_step, reg);
+		}
+	}
+}
+/*****************************************************************************/
+/*
+ * 'host->epm' only use the first oobfree[0] field, it looks very simple, But...
+ */
+
+/* Default OOB area layout */
+static int hinfc_ooblayout_ecc_64(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 32;
+	oobregion->offset = 32;
+
+	return 0;
+}
+
+static int hinfc_ooblayout_free_64(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 30;
+	oobregion->offset = 2;
+
+	return 0;
+}
+
+static struct mtd_ooblayout_ops hinfc_ooblayout_64_ops = {
+	.ecc = hinfc_ooblayout_ecc_64,
+	.free = hinfc_ooblayout_free_64,
+};
+
+/*****************************************************************************/
+
+static struct nand_config_info hinfc610_soft_auto_config_table[] = {
+	{NAND_PAGE_16K, NAND_ECC_64BIT, 60, 1824/*1824*/, &hinfc_ooblayout_64_ops},
+	{NAND_PAGE_16K, NAND_ECC_40BIT, 40, 1200/*1152*/, &hinfc_ooblayout_64_ops},
+	{NAND_PAGE_16K, NAND_ECC_NONE,  0, 32, &hinfc_ooblayout_64_ops},
+
+	{NAND_PAGE_8K, NAND_ECC_64BIT, 60, 928 /*928*/, &hinfc_ooblayout_64_ops},
+	{NAND_PAGE_8K, NAND_ECC_40BIT, 40, 600 /*592*/, &hinfc_ooblayout_64_ops},
+	{NAND_PAGE_8K, NAND_ECC_24BIT, 24, 368 /*368*/, &hinfc_ooblayout_64_ops},
+	{NAND_PAGE_8K, NAND_ECC_NONE,  0, 32, &hinfc_ooblayout_64_ops},
+
+	{NAND_PAGE_4K, NAND_ECC_24BIT, 24, 200 /*200*/, &hinfc_ooblayout_64_ops},
+	{NAND_PAGE_4K, NAND_ECC_4BIT_512,  8, 128  /*88*/, &hinfc_ooblayout_64_ops},
+	{NAND_PAGE_4K, NAND_ECC_NONE,  0, 32, &hinfc_ooblayout_64_ops},
+
+	{NAND_PAGE_2K, NAND_ECC_24BIT, 24, 128 /*116*/, &hinfc_ooblayout_64_ops},
+	{NAND_PAGE_2K, NAND_ECC_4BIT_512,  8, 64  /*60*/, &hinfc_ooblayout_64_ops},
+	{NAND_PAGE_2K, NAND_ECC_NONE,  0, 32, &hinfc_ooblayout_64_ops},
+
+	{0, 0, 0, 0, NULL},
+};
+/*****************************************************************************/
+/* used the best correct arithmetic. */
+struct nand_config_info *hinfc610_get_best_ecc(struct mtd_info *mtd)
+{
+	struct nand_config_info *best = NULL;
+	struct nand_config_info *config = hinfc610_soft_auto_config_table;
+
+	for (; config->ooblayout_ops; config++) {
+		if (nandpage_type2size(config->pagetype) != mtd->writesize)
+			continue;
+
+		if (mtd->oobsize < config->oobsize)
+			continue;
+
+		if (!best || (best->ecctype < config->ecctype))
+			best = config;
+	}
+
+	if (!best)
+		PR_BUG(ERSTR_DRIVER
+		       "Driver does not support the pagesize(%d) "
+		       "and oobsize(%d).\n",
+		       mtd->writesize, mtd->oobsize);
+
+	return best;
+}
+/*****************************************************************************/
+/* force the pagesize and ecctype */
+struct nand_config_info *hinfc610_force_ecc(struct mtd_info *mtd, int pagetype,
+					     int oobsize, char *cfgmsg,
+					     int allow_pagediv)
+{
+	struct nand_config_info *fit = NULL;
+	struct nand_config_info *config = hinfc610_soft_auto_config_table;
+
+	for (; config->ooblayout_ops; config++) {
+		if (config->pagetype == pagetype
+			&& config->oobsize <= oobsize) {
+			fit = config;
+			break;
+		}
+	}
+
+	if (!fit) {
+		PR_BUG(ERSTR_DRIVER
+		       "Driver(%s mode) does not support this Nand Flash "
+		       "pagesize:%s, oobsize:%d\n",
+		       cfgmsg,
+		       nand_page_name(pagetype),
+		       oobsize);
+		return NULL;
+	}
+	return fit;
+}
+/*****************************************************************************/
+static unsigned int  nand_otp_len;
+static unsigned char nand_otp[128] = {0};
+
+/* Get NAND parameter table. */
+static int __init parse_nand_param(const struct tag *tag)
+{
+	if (tag->hdr.size <= 2)
+		return 0;
+
+	nand_otp_len = ((tag->hdr.size << 2) - sizeof(struct tag_header));
+
+	if (nand_otp_len > sizeof(nand_otp)) {
+		pr_warn("%s(%d): Get Nand OTP from tag fail.\n",
+			__func__, __LINE__);
+		return 0;
+	}
+	memcpy(nand_otp, &tag->u, nand_otp_len);
+	return 0;
+}
+/* 0x48694E77 equal to fastoot ATAG_NAND_PARAM */
+__tagtable(0x48694E77, parse_nand_param);
+
+/*****************************************************************************/
+int hinfc610_ecc_type2reg_intf(int type, struct hinfc_host *host)
+{
+	if (HINFC_VER_620 == host->version)
+		return hinfc620_ecc_type2reg(type);
+	else
+		return hinfc610_ecc_type2reg(type);
+}
+/*****************************************************************************/
+int hinfc610_ecc_reg2type_intf(int reg, struct hinfc_host *host)
+{
+	if (HINFC_VER_620 == host->version)
+		return hinfc620_ecc_reg2type(reg);
+	else
+		return hinfc610_ecc_reg2type(reg);
+}
+
+/*****************************************************************************/
+static int hinfc610_param_adjust(struct mtd_info *mtd, struct nand_chip *chip,
+				 struct nand_dev_t *nand_dev)
+{
+	int pagetype;
+	int oobsize;
+	int regval;
+	char *start_type = "unknown";
+	struct nand_config_info *best = NULL;
+	struct hinfc_host *host = chip->priv;
+	struct mtd_oob_region *hinfc_oobregion;
+
+	hinfc_oobregion = kmalloc(sizeof(struct mtd_oob_region), GFP_KERNEL);
+	if (!hinfc_oobregion) {
+		PR_BUG("failed to allocate hinfc_oobregion structure.\n");
+		return -ENOMEM;
+	}
+
+	if (IS_NANDC_HW_AUTO(host))
+		start_type = "HW-Auto";
+	else
+		start_type = "HW-Reg";
+
+	if ((mtd->writesize == SZ_8K)
+	|| (mtd->writesize == SZ_16K)
+	|| (mtd->writesize == SZ_32K))
+		host->flags |= NAND_RANDOMIZER;
+
+	pagetype = nandpage_size2type(mtd->writesize);
+	oobsize = mtd->oobsize;
+
+	best = hinfc610_force_ecc(mtd, pagetype, oobsize,
+		start_type, 0);
+
+#ifdef CONFIG_HINFC610_PAGESIZE_AUTO_ECC_NONE
+#  ifdef CONFIG_HINFC610_AUTO_PAGESIZE_ECC
+#  error you SHOULD NOT define CONFIG_HINFC610_PAGESIZE_AUTO_ECC_NONE \
+	and CONFIG_HINFC610_AUTO_PAGESIZE_ECC at the same time
+#  endif
+#  ifdef CONFIG_HINFC610_HARDWARE_PAGESIZE_ECC
+#  error you SHOULD NOT define CONFIG_HINFC610_PAGESIZE_AUTO_ECC_NONE \
+	and CONFIG_HINFC610_HARDWARE_PAGESIZE_ECC at the same time
+#  endif
+
+	pagetype = nandpage_size2type(mtd->writesize);
+	oobsize = 32;
+	best = hinfc610_force_ecc(mtd, pagetype, oobsize,
+				  "force config", 0);
+	start_type = "AutoForce";
+
+#endif /* CONFIG_HINFC610_PAGESIZE_AUTO_ECC_NONE */
+
+	if (!best) {
+		kfree(hinfc_oobregion);
+		PR_BUG(ERSTR_HARDWARE
+		       "Please configure Nand Flash pagesize and ecctype!\n");
+		return -1;
+	}
+
+	/* only in case fastboot check randomizer failed.
+	 * Update fastboot or configure hardware randomizer pin
+	 * fix this problem.
+	 */
+	if (IS_NAND_RANDOM(nand_dev) && !(IS_NAND_RANDOM(host)))
+		PR_BUG(ERSTR_HARDWARE
+		       "Hardware is not configure randomizer, "
+		       "but it is more suitable for this Nand Flash. "
+		       "1. Please configure hardware randomizer PIN."
+		       "2. Please updata fastboot.\n");
+
+	host->flags |= (IS_NAND_RANDOM(nand_dev) |
+		IS_NAND_SYNC_ASYNC(nand_dev) |
+		IS_NAND_ONLY_SYNC(nand_dev) |
+		IS_NAND_ONFI(nand_dev));
+
+	/* only for print nand info. */
+	nand_dev->flags |= (IS_NANDC_HW_AUTO(host) |
+		IS_NANDC_SYNC_BOOT(host));
+
+	/* only in case fastboot check sync boot pin failed.
+	 * Update fastboot or configure hardware sync boot pin fix this problem.
+	 */
+	if (IS_NANDC_SYNC_BOOT(host)) {
+		/* But NAND do not support sync mode, warning ! */
+		if (!IS_NAND_ONLY_SYNC(nand_dev))
+			PR_BUG(ERSTR_HARDWARE
+				"Hardware SYNC BOOT PIN has configured sync mode, "
+				"but the Nand Flash is async mode.\n"
+				"1. DO NOT configure SYNC BOOT PIN. "
+				"2. Update fastboot.\n");
+	} else {
+		if (IS_NAND_ONLY_SYNC(nand_dev))
+			PR_BUG(ERSTR_HARDWARE
+				"Hardware SYNC BOOT PIN has configured async mode, "
+				"but the Nand Flash only support sync mode.\n"
+				"1. Please configure SYNC BOOT PIN."
+				"2. Update fastboot.\n");
+	}
+
+	if (IS_NAND_SYNC_ASYNC(nand_dev))
+		hinfc610_get_sync_info(host);
+
+	if (best->ecctype != NAND_ECC_NONE)
+		mtd->oobsize = best->oobsize;
+
+	if (best->ooblayout_ops->free)
+		best->ooblayout_ops->free(mtd, 0, hinfc_oobregion);
+
+	host->ecctype  = best->ecctype;
+	host->pagesize = nandpage_type2size(best->pagetype);
+	host->oobsize  = mtd->oobsize;
+	host->block_page_mask = ((mtd->erasesize / mtd->writesize) - 1);
+
+	host->buffer = dma_alloc_coherent(host->dev,
+		(host->pagesize + host->oobsize),
+		&host->dma_buffer, GFP_KERNEL);
+	if (!host->buffer) {
+		kfree(hinfc_oobregion);
+		PR_BUG("Can't malloc memory for NAND driver.");
+		return -EIO;
+	}
+	memset(host->buffer, 0xff, (host->pagesize + host->oobsize));
+
+	host->dma_oob = host->dma_buffer + host->pagesize;
+	host->bbm = (unsigned char *)(host->buffer
+		+ host->pagesize + HINFC_BAD_BLOCK_POS);
+
+	host->epm = (unsigned short *)(host->buffer
+		+ host->pagesize + hinfc_oobregion->offset + 28);
+
+	regval = ~(HINFC610_CON_PAGESIZE_MASK << HINFC610_CON_PAGEISZE_SHIFT);
+	host->NFC_CON &= regval;
+	host->NFC_CON_ECC_NONE &= regval;
+	regval = (hinfc610_page_type2reg(best->pagetype)
+		& HINFC610_CON_PAGESIZE_MASK) << HINFC610_CON_PAGEISZE_SHIFT;
+	host->NFC_CON |= regval;
+	host->NFC_CON_ECC_NONE |= regval;
+
+	regval = ~(HINFC610_CON_ECCTYPE_MASK << HINFC610_CON_ECCTYPE_SHIFT);
+	host->NFC_CON &= regval;
+	host->NFC_CON_ECC_NONE &= regval;
+	regval = (hinfc610_ecc_type2reg_intf(best->ecctype, host)
+		& HINFC610_CON_ECCTYPE_MASK) << HINFC610_CON_ECCTYPE_SHIFT;
+	host->NFC_CON |= regval;
+
+	if (mtd->writesize > NAND_MAX_PAGESIZE ||
+	    mtd->oobsize > NAND_MAX_OOBSIZE) {
+		PR_BUG(ERSTR_DRIVER
+		       "Driver does not support this Nand Flash. "
+		       "Please increase NAND_MAX_PAGESIZE and NAND_MAX_OOBSIZE.\n");
+	}
+
+	if (mtd->writesize != host->pagesize) {
+		unsigned int shift = 0;
+		unsigned int writesize = mtd->writesize;
+
+		while (writesize > host->pagesize) {
+			writesize >>= 1;
+			shift++;
+		}
+		chip->chipsize = chip->chipsize >> shift;
+		mtd->erasesize = mtd->erasesize >> shift;
+		mtd->writesize = host->pagesize;
+		PR_MSG("Nand divide into 1/%u\n", (1 << shift));
+	}
+
+	nand_dev->start_type = start_type;
+	nand_dev->ecctype = host->ecctype;
+	nand_dev->oobsize = mtd->oobsize;
+
+	host->read_retry = NULL;
+	if (nand_dev->read_retry_type != NAND_RR_NONE) {
+		host->read_retry
+		    = hinfc610_find_read_retry(nand_dev->read_retry_type);
+		if (!host->read_retry) {
+			PR_BUG(ERSTR_DRIVER
+			       "This Nand Flash need to enable the "
+			       "'read retry' feature. "
+			       "but the driver dose not offer the feature");
+		}
+
+		if (nand_otp_len)
+			memcpy(host->rr_data, nand_otp, nand_otp_len);
+	}
+
+	/*
+	 * If it want to support the 'read retry' feature, the 'randomizer'
+	 * feature must be support first.
+	 */
+	if (host->read_retry && !IS_NAND_RANDOM(host)) {
+		PR_BUG(ERSTR_HARDWARE
+			"This Nand flash need to enable 'randomizer' feature. "
+			"Please configure hardware randomizer PIN.");
+	}
+
+
+	mtd_set_ooblayout(mtd, &hinfc_ooblayout_64_ops);
+	hinfc610_dbg_init(host);
+
+	kfree(hinfc_oobregion);
+
+	return 0;
+}
+/*****************************************************************************/
+
+int hinfc610_nand_init(struct hinfc_host *host, struct nand_chip *chip)
+{
+	unsigned int regval;
+
+	host->version = hinfc_read(host, HINFC610_VERSION);
+
+	host->addr_cycle    = 0;
+	host->addr_value[0] = 0;
+	host->addr_value[1] = 0;
+	host->cache_addr_value[0] = ~0;
+	host->cache_addr_value[1] = ~0;
+	host->chipselect    = 0;
+
+	host->send_cmd_pageprog = hinfc610_send_cmd_pageprog;
+	host->send_cmd_readstart = hinfc610_send_cmd_readstart;
+	host->send_cmd_erase = hinfc610_send_cmd_erase;
+	host->send_cmd_readid = hinfc610_send_cmd_readid;
+	host->send_cmd_status = hinfc610_send_cmd_status;
+	host->send_cmd_reset = hinfc610_send_cmd_reset;
+
+	host->flags = 0;
+
+	regval = hinfc_read(host, HINFC610_CON);
+
+	host->NFC_CON = (regval
+		| HINFC610_CON_OP_MODE_NORMAL
+		| HINFC610_CON_READY_BUSY_SEL);
+
+	host->NFC_CON_ECC_NONE = host->NFC_CON
+		& (~(HINFC610_CON_ECCTYPE_MASK
+		     << HINFC610_CON_ECCTYPE_SHIFT))
+		& (~HINFC610_CON_RANDOMIZER_EN);
+
+	hinfc_write(host,
+		(SET_HINFC610_PWIDTH(CONFIG_HINFC610_W_LATCH,
+				     CONFIG_HINFC610_R_LATCH,
+				     CONFIG_HINFC610_RW_LATCH)),
+		HINFC610_PWIDTH);
+
+	host->flags |= NANDC_HW_AUTO;
+
+	/* check if chip is sync mode. */
+	if (regval & HINFC610_BOOT_CFG_SYC_NAND_PAD) {
+		host->flags |= NANDC_IS_SYNC_BOOT;
+
+		/*
+		 * NAND default is sync mode, and read id, reset in sync mode.
+		 */
+		host->NFC_CON |= HINFC610_CON_NF_MODE_TOGGLE;
+		host->NFC_CON_ECC_NONE |= HINFC610_CON_NF_MODE_TOGGLE;
+
+		/* set synchronous clock and timing. */
+		clk_prepare_enable(host->clk);
+	}
+
+	memset((char *)chip->IO_ADDR_R,
+		0xff, HINFC610_BUFFER_BASE_ADDRESS_LEN);
+
+	host->enable_ecc_randomizer = hinfc610_enable_ecc_randomizer;
+	hinfc_param_adjust = hinfc610_param_adjust;
+
+	return 0;
+}
diff --git a/drivers/mtd/nand/hinfc610/hinfc610.h b/drivers/mtd/nand/hinfc610/hinfc610.h
new file mode 100644
index 0000000..18d90fd
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610.h
@@ -0,0 +1,512 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef HINFCV610H
+#define HINFCV610H
+/******************************************************************************/
+
+#ifndef CONFIG_HINFC610_W_LATCH
+	#define CONFIG_HINFC610_W_LATCH			(5)
+#endif /* CONFIG_HINFC610_W_LATCH */
+
+#ifndef CONFIG_HINFC610_R_LATCH
+	#define CONFIG_HINFC610_R_LATCH			(7)
+#endif /* CONFIG_HINFC610_R_LATCH */
+
+#ifndef CONFIG_HINFC610_RW_LATCH
+	#define CONFIG_HINFC610_RW_LATCH		(3)
+#endif /* CONFIG_HINFC610_RW_LATCH */
+
+#ifndef CONFIG_HINFC610_MAX_CHIP
+	#define CONFIG_HINFC610_MAX_CHIP		(1)
+	#warning NOT config CONFIG_HINFC610_MAX_CHIP, \
+	used default value, maybe invalid.
+#endif /* CONFIG_HINFC610_MAX_CHIP */
+/*****************************************************************************/
+#define HINFC_ECC_ERR_NUM0_BUF0			0xa0
+#define HINFC_ECC_ERR_NUM1_BUF0			0xa4
+#define HINFC_ECC_ERR_NUM0_BUF1			0xa8
+#define HINFC_ECC_ERR_NUM1_BUF1			0xcc
+
+#define GET_ECC_ERR_NUM(_i, _reg)		(((_reg) >> ((_i) * 8)) & 0xff)
+
+/*****************************************************************************/
+#define HINFC610_REG_BASE_ADDRESS_LEN                 (0x100)
+#define HINFC610_BUFFER_BASE_ADDRESS_LEN              (2048 + 128)
+
+#define HINFC610_CHIP_DELAY                           (25)
+
+#define HINFC610_ADDR_CYCLE_MASK                      0x4
+#define HINFC610_DMA_ADDR_OFFSET                      4096
+/*****************************************************************************/
+#define HINFC610_CON                                 0x00
+#define HINFC610_CON_OP_MODE_NORMAL      (1U << 0)
+#define HINFC610_CON_PAGEISZE_SHIFT      (1)
+#define HINFC610_CON_PAGESIZE_MASK       (0x07)
+#define HINFC610_CON_BUS_WIDTH           (1U << 4)
+#define HINFC610_CON_READY_BUSY_SEL      (1U << 8)
+#define HINFC610_CON_ECCTYPE_SHIFT       (9)
+#define HINFC610_CON_ECCTYPE_MASK        (0x0f)
+#define HINFC610_CON_RANDOMIZER_EN       (1 << 14)
+#define HINFC610_CON_NF_MODE_SHIFT       15
+#define HINFC610_CON_NF_MODE_MASK        (3 << HINFC610_CON_NF_MODE_SHIFT)
+#define HINFC610_CON_NF_MODE_TOGGLE      (1 << HINFC610_CON_NF_MODE_SHIFT)
+#define HINFC610_CON_NF_MODE_ONFI_23     (2 << HINFC610_CON_NF_MODE_SHIFT)
+#define HINFC610_CON_NF_MODE_ONFI_30     (3 << HINFC610_CON_NF_MODE_SHIFT)
+
+#define HINFC610_PWIDTH                              0x04
+#define SET_HINFC610_PWIDTH(_w_lcnt, _r_lcnt, _rw_hcnt) \
+	((_w_lcnt) | (((_r_lcnt) & 0x0F) << 4) | (((_rw_hcnt) & 0x0F) << 8))
+
+#define HINFC610_CMD                                 0x0C
+#define HINFC610_ADDRL                               0x10
+#define HINFC610_ADDRH                               0x14
+#define HINFC610_DATA_NUM                            0x18
+
+#define HINFC610_OP                                  0x1C
+#define HINFC610_OP_READ_STATUS_EN       (1U << 0)
+#define HINFC610_OP_READ_DATA_EN         (1U << 1)
+#define HINFC610_OP_WAIT_READY_EN        (1U << 2)
+#define HINFC610_OP_CMD2_EN              (1U << 3)
+#define HINFC610_OP_WRITE_DATA_EN        (1U << 4)
+#define HINFC610_OP_ADDR_EN              (1U << 5)
+#define HINFC610_OP_CMD1_EN              (1U << 6)
+#define HINFC610_OP_NF_CS_SHIFT          (7)
+#define HINFC610_OP_NF_CS_MASK           (3)
+#define HINFC610_OP_ADDR_CYCLE_SHIFT     (9)
+#define HINFC610_OP_ADDR_CYCLE_MASK      (7)
+#define HINFC610_OP_READID_EN            (1U << 12)
+#define HINFC610_OP_RW_REG_EN            (1U << 13)
+
+#define HINFC610_STATUS                               0x20
+
+#define HINFC610_INTS                                 0x28
+#define HINFC610_INTS_UE                 (1U << 6)
+#define HINFC610_INTCLR                               0x2C
+#define HINFC610_INTCLR_UE               (1U << 6)
+#define HINFC610_INTCLR_CE               (1U << 5)
+
+#define HINFC610_DMA_CTRL                             0x60
+#define HINFC610_DMA_CTRL_DMA_START      (1U << 0)
+#define HINFC610_DMA_CTRL_WE             (1U << 1)
+#define HINFC610_DMA_CTRL_BURST4_EN      (1U << 4)
+#define HINFC610_DMA_CTRL_BURST8_EN      (1U << 5)
+#define HINFC610_DMA_CTRL_BURST16_EN     (1U << 6)
+#define HINFC610_DMA_CTRL_ADDR_NUM_SHIFT (7)
+#define HINFC610_DMA_CTRL_ADDR_NUM_MASK  (1)
+#define HINFC610_DMA_CTRL_CS_SHIFT       (8)
+#define HINFC610_DMA_CTRL_CS_MASK        (0x03)
+
+#define HINFC610_DMA_ADDR_DATA                        0x64
+#define HINFC610_DMA_ADDR_OOB                         0x68
+#define HINFC610_DMA_ADDR_DATA1                       0xB4
+#define HINFC610_DMA_ADDR_DATA2                       0xB8
+#define HINFC610_DMA_ADDR_DATA3                       0xBC
+#define HINFC610_DMA_ADDR_DATA4                       0xEC
+#define HINFC610_DMA_ADDR_DATA5                       0xF0
+#define HINFC610_DMA_ADDR_DATA6                       0xF4
+#define HINFC610_DMA_ADDR_DATA7                       0xF8
+
+#define HINFC610_DMA_LEN                              0x6C
+#define HINFC610_DMA_LEN_OOB_SHIFT       (16)
+#define HINFC610_DMA_LEN_OOB_MASK        (0x1FFF)
+
+#define HINFC610_DMA_PARA                             0x70
+#define HINFC610_DMA_PARA_DATA_RW_EN     (1U << 0)
+#define HINFC610_DMA_PARA_OOB_RW_EN      (1U << 1)
+#define HINFC610_DMA_PARA_DATA_EDC_EN    (1U << 2)
+#define HINFC610_DMA_PARA_OOB_EDC_EN     (1U << 3)
+#define HINFC610_DMA_PARA_EXT_LEN_SHIFT  (6)
+#define HINFC610_DMA_PARA_EXT_LEN_MASK   (0x03)
+
+#define HINFC610_VERSION                              0x74
+#define HINFC610_LOG_READ_ADDR                        0x7C
+#define HINFC610_LOG_READ_LEN                         0x80
+
+#define HINFC610_ECC_REG0                             0xA0
+#define HINFC610_ECC_REG1                             0xA4
+#define HINFC610_ECC_REG2                             0xA8
+#define HINFC610_ECC_REG3                             0xAC
+
+#define HINFC610_RANDOMIZER                           0xC0
+#define HINFC610_RANDOMIZER_PAD           0x02
+#define HINFC610_RANDOMIZER_ENABLE        0x01
+/* read nand id or nand status, return from nand data length */
+#define HINFC610_NANDINFO_LEN             0x10
+
+#define HINFC610_BOOT_CFG                             0xC4
+#define HINFC610_BOOT_CFG_RANDOMIZER_PAD  0x01
+#define HINFC610_BOOT_CFG_SAVE_PIN_MODE_SHIFT    13
+#define HINFC610_BOOT_CFG_SAVE_PIN_MODE   \
+	(1U << HINFC610_BOOT_CFG_SAVE_PIN_MODE_SHIFT)
+#define HINFC610_BOOT_CFG_SYC_NAND_PAD_SHIFT     12
+#define HINFC610_BOOT_CFG_SYC_NAND_PAD    \
+	(1U << HINFC610_BOOT_CFG_SYC_NAND_PAD_SHIFT)
+
+#define HINFC610_SYNC_TIMING                          0xD0
+
+/* ONFI: sync nand timing config */
+#define HINFC610_SYNC_ONFI_T_CAD          (0xF << 24)
+#define HINFC610_SYNC_ONFI_T_DQZ          (0xF << 20)
+
+/* TOGGLE: sync nand timing config */
+#define HINFC610_SYNC_TOGGLE_PRE_RDQS     (0xF << 16)
+#define HINFC610_SYNC_TOGGLE_POST_RDQS    (0xF << 12)
+#define HINFC610_SYNC_TOGGLE_PRE_WDQS     (0xF << 8)
+#define HINFC610_SYNC_TOGGLE_POST_WDQS    (0xF << 4)
+#define HINFC610_SYNC_TOGGLE_RW_PSTH      (0xF << 0)
+
+/*****************************************************************************/
+/*
+ * This constant declares the max. oobsize / page, which
+ * is supported now. If you add a chip with bigger oobsize/page
+ * adjust this accordingly.
+ */
+#define NAND_MAX_OOBSIZE	4800
+#define NAND_MAX_PAGESIZE	32768
+
+/* DMA address align with 32 bytes. */
+#define HINFC610_DMA_ALIGN                            64
+/*****************************************************************************/
+#include "../hinfc_gen.h"
+
+#undef  READ
+#define READ           1
+
+#undef  WRITE
+#define WRITE          0
+
+#undef  FALSE
+#define FALSE          0
+
+#undef  TRUE
+#define TRUE           1
+
+#undef ENABLE
+#define ENABLE         1
+
+#undef DISABLE
+#define DISABLE        0
+/*****************************************************************************/
+
+struct hinfc_host {
+	struct nand_chip *chip;
+	struct mtd_info  *mtd;
+	void __iomem *iobase;
+	struct device *dev;
+
+	unsigned int offset;
+	unsigned int command;
+
+	int chipselect;
+
+	unsigned int n24bit_ext_len;
+	int ecctype;
+
+/* Current system has already gone to sync mode */
+#define HINFC610_IS_SYNC(_host) ((_host)->NFC_CON & HINFC610_CON_NF_MODE_MASK)
+	unsigned long NFC_CON;
+	unsigned long NFC_CON_ECC_NONE;
+
+	unsigned int addr_cycle;
+	unsigned int addr_value[2];
+	unsigned int cache_addr_value[2];
+	unsigned int column;
+	unsigned int block_page_mask;
+
+	unsigned int dma_oob;
+	unsigned int dma_buffer;
+	unsigned int pagesize;
+	unsigned int oobsize;
+	/* This is maybe an un-aligment address, only for malloc or free */
+	char *buforg;
+	char *buffer;
+
+	int  need_rr_data;
+#define HINFC_READ_RETRY_DATA_LEN         128
+	char rr_data[HINFC_READ_RETRY_DATA_LEN];
+	int  version;
+	int   add_partition;
+
+	/* BOOTROM read two bytes to detect the bad block flag */
+#define HINFC_BAD_BLOCK_POS              0
+	unsigned char *bbm;       /* nand bad block mark */
+	unsigned short *epm;      /* nand empty page mark */
+	unsigned int flags;
+
+#define HINFC610_PS_UC_ECC        0x01 /* page has ecc error */
+#define HINFC610_PS_BAD_BLOCK     0x02 /* bad block */
+#define HINFC610_PS_EMPTY_PAGE    0x04 /* page is empty */
+#define HINFC610_PS_EPM_ERROR     0x0100 /* empty page mark word has ecc error*/
+#define HINFC610_PS_BBM_ERROR     0x0200 /* bad block mark word has ecc error*/
+	unsigned int page_status;
+
+	struct clk *clk;
+
+	int (*send_cmd_pageprog)(struct hinfc_host *host);
+	int (*send_cmd_status)(struct hinfc_host *host);
+	int (*send_cmd_readstart)(struct hinfc_host *host);
+	int (*send_cmd_erase)(struct hinfc_host *host);
+	int (*send_cmd_readid)(struct hinfc_host *host);
+	int (*send_cmd_reset)(struct hinfc_host *host, int chipselect);
+	int (*enable)(struct hinfc_host *host, int enable);
+
+	int (*enable_ecc_randomizer)(struct hinfc_host *host,
+				     int ecc_en, int randomizer_en);
+
+	struct read_retry_t *read_retry;
+	struct nand_sync *sync;
+};
+
+#define HINFC610_UC_ECC               0x01
+#define HINFC610_BAD_BLOCK            0x02
+#define HINFC610_EMPTY_PAGE           0x04
+
+#define IS_PS_EMPTY_PAGE(_host)  ((_host)->page_status & HINFC610_PS_EMPTY_PAGE)
+#define IS_PS_BAD_BLOCK(_host)   ((_host)->page_status & HINFC610_PS_BAD_BLOCK)
+#define IS_PS_UN_ECC(_host)      ((_host)->page_status & HINFC610_PS_UC_ECC)
+#define IS_PS_EPM_ERR(_host)      ((_host)->page_status & HINFC610_PS_EPM_ERROR)
+#define IS_PS_BBM_ERR(_host)      ((_host)->page_status & HINFC610_PS_BBM_ERROR)
+
+/*****************************************************************************/
+
+#define HINFC610_READ_1CMD_0ADD_NODATA \
+	(HINFC610_OP_CMD1_EN \
+	| ((host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT))
+
+#define HINFC610_READ_1CMD_1ADD_DATA    \
+	(HINFC610_OP_CMD1_EN \
+	| HINFC610_OP_ADDR_EN \
+	| HINFC610_OP_READ_DATA_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT) \
+	| (1 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_READ_1CMD_1ADD_DATA_WAIT_READY    \
+	(HINFC610_OP_CMD1_EN \
+	| HINFC610_OP_ADDR_EN \
+	| HINFC610_OP_READ_DATA_EN \
+	| HINFC610_OP_WAIT_READY_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT) \
+	| (1 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_READ_1CMD_1ADD_DATA_SYNC \
+	(HINFC610_OP_CMD1_EN \
+	| HINFC610_OP_ADDR_EN \
+	| HINFC610_OP_READ_DATA_EN \
+	| HINFC610_OP_WAIT_READY_EN \
+	| HINFC610_OP_RW_REG_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT) \
+	| (1 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_READ_2CMD_5ADD    \
+	(HINFC610_OP_CMD1_EN \
+	| HINFC610_OP_CMD2_EN \
+	| HINFC610_OP_ADDR_EN \
+	| HINFC610_OP_READ_DATA_EN \
+	| HINFC610_OP_WAIT_READY_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT) \
+	| (5 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_WRITE_0CMD_1ADD_DATA \
+	(HINFC610_OP_ADDR_EN \
+	| HINFC610_OP_WRITE_DATA_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT) \
+	| (1 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_WRITE_0CMD_1ADD_DATA_WAIT_READY \
+	(HINFC610_OP_ADDR_EN \
+	| HINFC610_OP_WRITE_DATA_EN \
+	| HINFC610_OP_WAIT_READY_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT) \
+	| (1 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_WRITE_0CMD_1ADD_DATA_SYNC \
+	(HINFC610_OP_ADDR_EN \
+	 | HINFC610_OP_WRITE_DATA_EN \
+	 | HINFC610_OP_RW_REG_EN \
+	 | (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		 << HINFC610_OP_NF_CS_SHIFT) \
+	 | (1 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_WRITE_0CMD_1ADD_DATA_SYNC_WAIT_READY \
+	(HINFC610_OP_ADDR_EN \
+	 | HINFC610_OP_WRITE_DATA_EN \
+	 | HINFC610_OP_RW_REG_EN \
+	 | HINFC610_OP_WAIT_READY_EN \
+	 | (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		 << HINFC610_OP_NF_CS_SHIFT) \
+	 | (1 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_WRITE_1CMD_1ADD_DATA  \
+	(HINFC610_OP_CMD1_EN \
+	| HINFC610_OP_ADDR_EN \
+	| HINFC610_OP_WRITE_DATA_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT) \
+	| (1 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_WRITE_1CMD_1ADD_DATA_WAIT_READY  \
+	(HINFC610_OP_CMD1_EN \
+	| HINFC610_OP_ADDR_EN \
+	| HINFC610_OP_WRITE_DATA_EN \
+	| HINFC610_OP_WAIT_READY_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT) \
+	| (1 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_WRITE_1CMD_1ADD_DATA_SYNC  \
+	(HINFC610_OP_CMD1_EN \
+	 | HINFC610_OP_ADDR_EN \
+	 | HINFC610_OP_WRITE_DATA_EN \
+	 | HINFC610_OP_RW_REG_EN \
+	 | (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		 << HINFC610_OP_NF_CS_SHIFT) \
+	 | (1 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_WRITE_1CMD_1ADD_DATA_SYNC_WAIT_READY  \
+	(HINFC610_OP_CMD1_EN \
+	 | HINFC610_OP_ADDR_EN \
+	 | HINFC610_OP_WRITE_DATA_EN \
+	 | HINFC610_OP_WAIT_READY_EN \
+	 | HINFC610_OP_RW_REG_EN \
+	 | (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		 << HINFC610_OP_NF_CS_SHIFT) \
+	 | (1 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_WRITE_1CMD_2ADD_DATA  \
+	(HINFC610_OP_CMD1_EN \
+	| HINFC610_OP_ADDR_EN \
+	| HINFC610_OP_WRITE_DATA_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT) \
+	| (2 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_WRITE_1CMD_2ADD_DATA_SYNC  \
+	(HINFC610_OP_CMD1_EN \
+	 | HINFC610_OP_ADDR_EN \
+	 | HINFC610_OP_WRITE_DATA_EN \
+	 | HINFC610_OP_RW_REG_EN \
+	 | (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		 << HINFC610_OP_NF_CS_SHIFT) \
+	 | (2 << HINFC610_OP_ADDR_CYCLE_SHIFT))
+
+#define HINFC610_WRITE_2CMD_0ADD_NODATA \
+	(HINFC610_OP_CMD1_EN \
+	| HINFC610_OP_CMD2_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT))
+
+#define HINFC610_WRITE_2CMD_0ADD_NODATA_SYNC \
+	(HINFC610_OP_CMD1_EN \
+	| HINFC610_OP_CMD2_EN \
+	| HINFC610_OP_RW_REG_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT))
+
+#define HINFC610_WRITE_1CMD_0ADD_NODATA \
+	(HINFC610_OP_CMD1_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT))
+
+#define HINFC610_WRITE_1CMD_0ADD_NODATA_WAIT_READY \
+	(HINFC610_OP_CMD1_EN \
+	| HINFC610_OP_WAIT_READY_EN \
+	| (((unsigned int)host->chipselect & HINFC610_OP_NF_CS_MASK) \
+		<< HINFC610_OP_NF_CS_SHIFT))
+
+/*****************************************************************************/
+
+#define WAIT_CONTROLLER_FINISH() \
+do { \
+	unsigned int timeout = 0x800000; \
+	while ((hinfc_read(host, HINFC610_STATUS) & 0x1) == 0x0 && timeout) \
+		timeout--; \
+	if (!timeout) \
+		PR_ERR("Wait NAND controller finish timeout.\n"); \
+} while (0)
+
+/*****************************************************************************/
+
+#define hinfc_read(_host, _reg) \
+	readl((char *)_host->iobase + (_reg))
+
+#define hinfc_write(_host, _value, _reg) \
+	writel((_value), (char *)_host->iobase + (_reg))
+
+#define HINFC_CMD_SEQ(_cmd0, _cmd1)        \
+	(((_cmd0) & 0xFF) | ((_cmd1) & 0xFF) << 8)
+/*****************************************************************************/
+
+#define GET_PAGE_INDEX(host) \
+	((host->addr_value[0] >> 16) | (host->addr_value[1] << 16))
+
+/*****************************************************************************/
+
+void hinfc610_cmd_ctrl(struct mtd_info *mtd, int dat, unsigned int ctrl);
+int hinfc610_dev_ready(struct mtd_info *mtd);
+void hinfc610_select_chip(struct mtd_info *mtd, int chipselect);
+uint8_t hinfc610_read_byte(struct mtd_info *mtd);
+u16 hinfc610_read_word(struct mtd_info *mtd);
+void hinfc610_write_buf(struct mtd_info *mtd, const uint8_t *buf, int len);
+void hinfc610_read_buf(struct mtd_info *mtd, uint8_t *buf, int len);
+int hinfc610_nand_init(struct hinfc_host *host, struct nand_chip *chip);
+/******************************************************************************/
+
+extern struct nand_sync hinfc610_sync_onfi_23;
+extern struct nand_sync hinfc610_sync_onfi_30;
+extern struct nand_sync hinfc610_sync_toggle_10;
+extern struct read_retry_t hinfc610_hynix_bg_cdie_read_retry;
+extern struct read_retry_t hinfc610_hynix_bg_bdie_read_retry;
+extern struct read_retry_t hinfc610_hynix_cg_adie_read_retry;
+extern struct read_retry_t hinfc610_micron_read_retry;
+extern struct read_retry_t hinfc610_toshiba_24nm_read_retry;
+extern struct read_retry_t hinfc610_samsung_read_retry;
+
+#if 0
+#ifdef CONFIG_MTD_PART_CHANGE
+extern int register_mtd_partdev(struct mtd_info *mtd);
+extern int unregister_mtd_partdev(struct mtd_info *mtd);
+#else
+int register_mtd_partdev(struct mtd_info *mtd)
+{
+	return 0;
+};
+
+int unregister_mtd_partdev(struct mtd_info *mtd)
+{
+	return 0;
+};
+#endif
+
+void hinfc610_controller_enable(struct hinfc_host *host, int enable);
+#endif
+
+extern int hinfc610_dbgfs_debug_init(struct hinfc_host *host);
+
+#ifdef CONFIG_HINFC610_DBG_NAND_DEBUG
+extern struct hinfc610_dbg_inf_t *hinfc610_dbg_inf[];
+#endif
+
+#endif /* HINFCV610H */
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_dbg.c b/drivers/mtd/nand/hinfc610/hinfc610_dbg.c
new file mode 100644
index 0000000..ee25956
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_dbg.c
@@ -0,0 +1,294 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/moduleparam.h>
+#include <linux/vmalloc.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>
+#include <linux/ctype.h>
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+#include "hinfc610_dbg.h"
+
+struct hinfc610_dbg_inf_t *hinfc610_dbg_inf[] = {
+	&hinfc610_dbg_inf_ecc_notice,
+	&hinfc610_dbg_inf_read_retry_notice,
+#ifdef CONFIG_HINFC610_DBG_NAND_DUMP
+	&hinfc610_dbg_inf_dump,
+#endif
+#ifdef CONFIG_HINFC610_DBG_NAND_ERASE_COUNT
+	&hinfc610_dbg_inf_erase_count,
+#endif
+#ifdef CONFIG_HINFC610_DBG_NAND_ECC_COUNT
+	&hinfc610_dbg_inf_ecc_count,
+#endif
+#ifdef CONFIG_HINFC610_DBG_NAND_READ_RETRY
+	&hinfc610_dbg_inf_read_retry,
+#endif
+	NULL,
+};
+
+static struct dentry *dbgfs_root;
+static struct hinfc_host *dbgfs_host;
+
+/*****************************************************************************/
+static ssize_t dbgfs_debug_read(struct file *filp, char __user *buffer,
+				size_t count, loff_t *ppos)
+{
+	char *msg, *p;
+	struct hinfc610_dbg_inf_t **inf;
+
+	if (*ppos != 0)
+		return 0;
+
+	msg = (char *)__get_free_page(GFP_TEMPORARY);
+	if (!msg)
+		return -ENOMEM;
+
+	p = msg;
+	if (count > PAGE_SIZE)
+		count = PAGE_SIZE;
+
+	for (inf = hinfc610_dbg_inf; *inf; inf++) {
+		if ((p - msg) + MAX_OPTION_SIZE + 2 > count) {
+			PR_ERR("Not enough memory.\n");
+			break;
+		}
+		p += snprintf(p, (MAX_OPTION_SIZE + 2), "%c%s,",
+			      ((*inf)->enable ? '+' : '-'),
+			      (*inf)->name);
+	}
+
+	p += sprintf(p, "\n");
+	count = (p - msg);
+	if (copy_to_user(buffer, msg, count)) {
+		free_page((unsigned long) msg);
+		return -EFAULT;
+	}
+
+	free_page((unsigned long) msg);
+
+	*ppos += count;
+	return count;
+}
+/*****************************************************************************/
+
+static void dbgfs_debug_do_cmd(struct hinfc610_dbg_inf_t **dbg_inf,
+			       const char *cmd, unsigned int length, int enable)
+{
+	int ret = 0;
+	struct hinfc610_dbg_inf_t **inf;
+
+	if (length >= sizeof((*inf)->name))
+		return;
+
+	for (inf = dbg_inf; *inf; inf++) {
+		if (!(*inf)->name[length] &&
+		    !memcmp((*inf)->name, cmd, length))
+			break;
+	}
+
+	if (!(*inf) || (*inf)->enable == enable)
+		return;
+
+	if (enable) {
+		if ((*inf)->init)
+			ret = (*inf)->init(dbgfs_root, dbgfs_host);
+	} else {
+		if ((*inf)->uninit)
+			ret = (*inf)->uninit();
+	}
+
+	if (!ret)
+		(*inf)->enable = enable;
+}
+/*****************************************************************************/
+
+static void dbgfs_debug_ops(const char *options,
+			    struct hinfc610_dbg_inf_t **dbg_inf)
+{
+	int enable;
+	const char *pos, *cmd;
+
+	pos = options;
+
+	while (*pos) {
+
+		while (*pos && *pos != '+' && *pos != '-')
+			pos++;
+
+		switch (*pos++) {
+		case '+':
+			enable = 1;
+			break;
+		case '-':
+			enable = 0;
+			break;
+		default:
+			return;
+		}
+
+		cmd = pos;
+		while (*pos == '_' || isalpha(*pos))
+			pos++;
+
+		if (*cmd && pos > cmd)
+			dbgfs_debug_do_cmd(dbg_inf, cmd, (pos - cmd), enable);
+
+		while (isspace(*pos) || *pos == ',' || *pos == ';')
+			pos++;
+	}
+}
+/*****************************************************************************/
+/*
+ * echo "+dump, +read_retry, +ecc_count, +erase_count"  > debug
+ */
+static ssize_t dbgfs_debug_write(struct file *filp, const char __user *buffer,
+				 size_t count, loff_t *ppos)
+{
+	char *options;
+	size_t num = count;
+
+	if (count > PAGE_SIZE)
+		num = (PAGE_SIZE - 1);
+
+	options = (char *)__get_free_page(GFP_TEMPORARY);
+	if (!options)
+		return -ENOMEM;
+
+	if (copy_from_user(options, buffer, num)) {
+		free_page((unsigned long) options);
+		return -EFAULT;
+	}
+
+	options[num] = 0;
+
+	dbgfs_debug_ops(options, hinfc610_dbg_inf);
+
+	free_page((unsigned long) options);
+
+	*ppos += count;
+	return count;
+}
+/*****************************************************************************/
+
+static const struct file_operations dbgfs_debug_fops = {
+	.owner = THIS_MODULE,
+	.read  = dbgfs_debug_read,
+	.write = dbgfs_debug_write,
+};
+/*****************************************************************************/
+
+int hinfc610_dbgfs_debug_init(struct hinfc_host *host)
+{
+	struct dentry *dentry;
+
+	if (dbgfs_root)
+		return 0;
+
+	dbgfs_root = debugfs_create_dir("nand", NULL);
+	if (!dbgfs_root) {
+		PR_ERR("Can't create 'nand' dir.\n");
+		return -ENOENT;
+	}
+
+	dentry = debugfs_create_file("debug", S_IFREG | S_IRUSR | S_IWUSR,
+				     dbgfs_root, NULL, &dbgfs_debug_fops);
+	if (!dentry) {
+		PR_ERR("Can't create 'debug' file.\n");
+		goto fail;
+	}
+
+	dbgfs_host = host;
+
+	if (nand_dbgfs_options)
+		dbgfs_debug_ops(nand_dbgfs_options, hinfc610_dbg_inf);
+
+	return 0;
+
+fail:
+	debugfs_remove_recursive(dbgfs_root);
+	dbgfs_root = NULL;
+
+	return -ENOENT;
+}
+/*****************************************************************************/
+
+static int dbgfs_read_retry_notice_init(struct dentry *root,
+					struct hinfc_host *host)
+{
+	if (!host->read_retry) {
+		pr_warn("read_retry_notice: The NAND not support this interface.\n");
+		return -1;
+	}
+
+	return 0;
+}
+
+static void hinfc610_dbg_read_retry_notice(struct hinfc_host *host, int index)
+{
+	pr_warn("Page 0x%08x do read retry (%d/%d) %s.\n",
+		GET_PAGE_INDEX(host), index, host->read_retry->count,
+		(IS_PS_UN_ECC(host) ? "Fail" : "Success"));
+}
+
+struct hinfc610_dbg_inf_t hinfc610_dbg_inf_read_retry_notice = {
+	"read_retry_notice", 0,
+	dbgfs_read_retry_notice_init,
+	NULL,
+	NULL,
+	NULL,
+	NULL,
+	hinfc610_dbg_read_retry_notice,
+};
+/*****************************************************************************/
+
+static void hinfc610_dbg_ecc_notice_read(struct hinfc_host *host)
+{
+	unsigned int pageindex =  GET_PAGE_INDEX(host);
+
+	if (IS_PS_BAD_BLOCK(host) || IS_PS_EMPTY_PAGE(host)) {
+		if (IS_PS_BBM_ERR(host))
+			pr_warn("page 0x%08x bbm is corruption, bbm: 0x%x.\n",
+				pageindex, *host->bbm);
+
+		if (IS_PS_EPM_ERR(host))
+			pr_warn("page 0x%08x epm is corruption, epm: 0x%x.\n",
+				pageindex, *host->epm);
+
+		return;
+	}
+
+	if (IS_PS_UN_ECC(host))
+		pr_warn("page 0x%08x has uncorrect ecc.\n", pageindex);
+}
+
+struct hinfc610_dbg_inf_t hinfc610_dbg_inf_ecc_notice = {
+	"ecc_notice", 0,
+	NULL,
+	NULL,
+	hinfc610_dbg_ecc_notice_read,
+	NULL,
+	NULL,
+	NULL,
+};
+/*****************************************************************************/
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_dbg.h b/drivers/mtd/nand/hinfc610/hinfc610_dbg.h
new file mode 100644
index 0000000..8fd4deb
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_dbg.h
@@ -0,0 +1,63 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+
+#ifndef HINFC610_DBGH
+#define HINFC610_DBGH
+/******************************************************************************/
+
+#define MAX_OPTION_SIZE                20
+
+struct hinfc610_dbg_inf_t {
+	const char name[MAX_OPTION_SIZE];
+	int enable;
+	int (*init)(struct dentry *root, struct hinfc_host *host);
+	int (*uninit)(void);
+
+	void (*read)(struct hinfc_host *host);
+	void (*write)(struct hinfc_host *host);
+	void (*erase)(struct hinfc_host *host);
+
+	void (*read_retry)(struct hinfc_host *host, int index);
+};
+
+#define CMD_WORD_OFFSET             "offset="
+#define CMD_WORD_LENGTH             "length="
+#define CMD_WORD_CLEAN              "clear"
+#define CMD_WORD_ON                 "on"
+#define CMD_WORD_OFF                "off"
+
+struct hinfc610_ecc_inf_t {
+	int pagesize;
+	int ecctype;
+	int section;
+	void (*ecc_inf)(struct hinfc_host *host, unsigned char ecc[]);
+};
+
+struct hinfc610_ecc_inf_t *hinfc610_get_ecc_inf(struct hinfc_host *host,
+						int pagesize, int ecctype);
+
+extern struct hinfc610_dbg_inf_t hinfc610_dbg_inf_dump;
+extern struct hinfc610_dbg_inf_t hinfc610_dbg_inf_erase_count;
+extern struct hinfc610_dbg_inf_t hinfc610_dbg_inf_ecc_count;
+extern struct hinfc610_dbg_inf_t hinfc610_dbg_inf_read_retry;
+extern struct hinfc610_dbg_inf_t hinfc610_dbg_inf_read_retry_notice;
+extern struct hinfc610_dbg_inf_t hinfc610_dbg_inf_ecc_notice;
+
+/******************************************************************************/
+#endif /* HINFC610_DBGH */
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_dbg_dump.c b/drivers/mtd/nand/hinfc610/hinfc610_dbg_dump.c
new file mode 100644
index 0000000..e330bb5
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_dbg_dump.c
@@ -0,0 +1,448 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/moduleparam.h>
+#include <linux/vmalloc.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>
+#include <linux/mutex.h>
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+#include "hinfc610_dbg.h"
+
+#ifndef CONFIG_HINFC610_DBG_NAND_NUM_OF_LOGS
+#  define CONFIG_HINFC610_DBG_NAND_NUM_OF_LOGS      (80)
+#endif /* CONFIG_HINFC610_DBG_NAND_NUM_OF_LOGS */
+
+#ifndef CONFIG_HINFC610_DBG_NAND_LOG_LENGTH
+#  define CONFIG_HINFC610_DBG_NAND_LOG_LENGTH       (40)
+#endif /* CONFIG_HINFC610_DBG_NAND_LOG_LENGTH */
+
+struct hinfc610_dbg_dump_item_t {
+	unsigned short hour;
+	unsigned short min;
+	unsigned short sec;
+	unsigned short msec;
+
+	unsigned int cycle;
+
+	unsigned long  page;
+	unsigned long  offset;
+	unsigned long  length;
+
+	char page_status[4];
+	char op;
+
+	unsigned char data[CONFIG_HINFC610_DBG_NAND_LOG_LENGTH];
+};
+
+struct hinfc610_dbg_dump_t {
+
+	struct dentry *dentry;
+	unsigned int index; /* current logs index */
+	int count;          /* number of logs */
+
+	unsigned long offset;
+	unsigned long length;
+
+	struct hinfc610_dbg_dump_item_t
+		logs[CONFIG_HINFC610_DBG_NAND_NUM_OF_LOGS];
+
+	unsigned int read_index;
+};
+
+static DEFINE_MUTEX(dbg_dump_mutex);
+static struct hinfc610_dbg_dump_t *dbg_dump;
+
+/*****************************************************************************/
+
+static void do_gettime(unsigned short *hour, unsigned short *min,
+		       unsigned short *sec, unsigned short *msec)
+{
+	long val;
+	struct timeval tv;
+
+	do_gettimeofday(&tv);
+	val = tv.tv_sec % 86400; /* the second form 0 hour */
+
+	if (hour)
+		*hour = val / 3600;
+	val %= 3600;
+	if (min)
+		*min  = val / 60;
+	if (sec)
+		*sec  = val % 60;
+	if (msec)
+		*msec = tv.tv_usec / 1000;
+}
+/*****************************************************************************/
+/*
+ *
+# cat ./debugfs/nand/dump
+Print parameter: "offset=0 length=8"
+UTC Clock   op cylce  page-offset     data
+00:00:33.0321  W  5   0x0000258F-0000   31 18 10 06 18 EF FE 11
+00:00:33.0325  W  5   0x00002740-0000   31 18 10 06 7C D4 B3 0C
+*
+*/
+static ssize_t dbgfs_dump_read(struct file *filp, char __user *buffer,
+			       size_t count, loff_t *ppos)
+{
+	int len = 0;
+	char buf[128] = {0};
+	unsigned int read_index;
+	char __user *pusrbuf = buffer;
+	struct hinfc610_dbg_dump_item_t *logs;
+
+	if (*ppos == 0) {
+
+		if (dbg_dump->count
+		    < CONFIG_HINFC610_DBG_NAND_NUM_OF_LOGS)
+			dbg_dump->read_index = 0;
+		else
+			dbg_dump->read_index
+				= (dbg_dump->index + 1);
+
+		len = snprintf(buf, sizeof(buf),
+			       "Print parameter: \"offset=%ld length=%ld\"\n",
+			       dbg_dump->offset, dbg_dump->length);
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+
+		pusrbuf += len;
+
+		len += snprintf(buf, sizeof(buf),
+				"  UTC Clock   op cylce  page-offset     data\n");
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+
+		pusrbuf += len;
+
+	} else if (dbg_dump->read_index == dbg_dump->index)
+		return 0;
+
+	for (read_index = dbg_dump->read_index;
+	     (read_index != dbg_dump->index);
+	     ++read_index) {
+
+		if (read_index >= CONFIG_HINFC610_DBG_NAND_NUM_OF_LOGS)
+			read_index = 0;
+
+		logs = &dbg_dump->logs[read_index];
+
+		if ((count - (pusrbuf - buffer)) < (50 + logs->length * 3))
+			break;
+
+		len = snprintf(buf, sizeof(buf),
+			       "%02d:%02d:%02d.%04d  %c  %-2u  0x%08lX-%04lX",
+			       logs->hour, logs->min, logs->sec, logs->msec,
+			       logs->op, logs->cycle,
+			       logs->page, logs->offset);
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+
+		pusrbuf += len;
+
+		if (logs->op == 'E') {
+
+			len = snprintf(buf, sizeof(buf), "   ---");
+			if (copy_to_user(pusrbuf, buf, len))
+				return -EFAULT;
+			pusrbuf += len;
+
+		} else {
+
+			int ix;
+
+			len = snprintf(buf, sizeof(buf), "%s",
+				       logs->page_status);
+			if (copy_to_user(pusrbuf, buf, len))
+				return -EFAULT;
+			pusrbuf += len;
+
+			for (ix = 0; ix < logs->length; ix++) {
+				if ((ix % 16) == 15) {
+					len = snprintf(buf, sizeof(buf),
+						       "%02X-",
+						       logs->data[ix]);
+					if (copy_to_user(pusrbuf, buf, len))
+						return -EFAULT;
+					pusrbuf += len;
+				} else {
+					len = snprintf(buf, sizeof(buf),
+						       "%02X ",
+						       logs->data[ix]);
+					if (copy_to_user(pusrbuf, buf, len))
+						return -EFAULT;
+					pusrbuf += len;
+				}
+			}
+		}
+		len = snprintf(buf, sizeof(buf), "\n");
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+		pusrbuf += len;
+	}
+
+	dbg_dump->read_index = read_index;
+
+	*ppos += (pusrbuf - buffer);
+	return pusrbuf - buffer;
+}
+/*****************************************************************************/
+
+static ssize_t dbgfs_dump_write(struct file *filp, const char __user *buffer,
+				size_t count, loff_t *ppos)
+{
+	char *p;
+	int ret;
+	unsigned long value = 0;
+	char buf[128] = {0};
+	unsigned long pos = 0;
+
+	if (count > sizeof(buf))
+		count = sizeof(buf);
+
+	if (copy_from_user(buf, buffer, count))
+		return -EFAULT;
+
+	while (pos < count) {
+
+		while (pos < count
+		       && (buf[pos] == ' ' ||
+			   buf[pos] == ',' || buf[pos] == ';'))
+			pos++;
+
+		if (pos >= count)
+			break;
+
+		switch (buf[pos]) {
+		case 'o':
+			if (!memcmp(&buf[pos], CMD_WORD_OFFSET,
+				    sizeof(CMD_WORD_OFFSET) - 1)) {
+
+				pos += sizeof(CMD_WORD_OFFSET) - 1;
+				p = (char *)(buf + pos);
+				ret = kstrtoul(p, 10, &value);
+				if (ret < 0)
+					value = 0;
+				dbg_dump->offset = value;
+			}
+			break;
+
+		case 'l':
+			if (!memcmp(&buf[pos], CMD_WORD_LENGTH,
+				    sizeof(CMD_WORD_LENGTH) - 1)) {
+
+				pos += sizeof(CMD_WORD_LENGTH) - 1;
+				p = (char *)(buf + pos);
+				ret = kstrtoul(p, 10, &value);
+				if (ret < 0)
+					value = 0;
+				dbg_dump->length = value;
+			}
+			break;
+		}
+
+		while (pos < count &&
+		       (buf[pos] != ' ' && buf[pos] != ',' && buf[pos] != ';'))
+			pos++;
+	}
+
+	*ppos += count;
+	return count;
+}
+/*****************************************************************************/
+
+static const struct file_operations dbgfs_dump_fops = {
+	.owner = THIS_MODULE,
+	.read  = dbgfs_dump_read,
+	.write = dbgfs_dump_write,
+};
+/*****************************************************************************/
+
+static int dbgfs_dump_init(struct dentry *root, struct hinfc_host *host)
+{
+	struct hinfc610_dbg_dump_t *dump;
+
+	if (dbg_dump)
+		return 0;
+
+	dump = vmalloc(sizeof(struct hinfc610_dbg_dump_t));
+	if (!dump) {
+		PR_ERR("Can't allocate memory.\n");
+		return -ENOMEM;
+	}
+	memset(dump, 0, sizeof(struct hinfc610_dbg_dump_t));
+
+	dump->dentry = debugfs_create_file("dump",
+		S_IFREG | S_IRUSR | S_IWUSR,
+		root, NULL, &dbgfs_dump_fops);
+	if (!dump->dentry) {
+		PR_ERR("Can't create 'dump' file.\n");
+		vfree(dump);
+		return -ENOENT;
+	}
+
+	dump->length = 8;
+
+	dbg_dump = dump;
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int dbgfs_dump_uninit(void)
+{
+	if (!dbg_dump)
+		return 0;
+
+	mutex_lock(&dbg_dump_mutex);
+
+	debugfs_remove(dbg_dump->dentry);
+
+	vfree(dbg_dump);
+	dbg_dump = NULL;
+
+	mutex_unlock(&dbg_dump_mutex);
+
+	return 0;
+}
+/*****************************************************************************/
+
+static void dbg_dump_rw(struct hinfc_host *host, char op)
+{
+	unsigned long buflen;
+	struct hinfc610_dbg_dump_item_t *logs;
+
+	mutex_lock(&dbg_dump_mutex);
+
+	if (!dbg_dump)
+		goto exit;
+
+	buflen = (host->pagesize + host->oobsize);
+	logs = &dbg_dump->logs[dbg_dump->index];
+
+	dbg_dump->count++;
+
+	do_gettime(&logs->hour, &logs->min, &logs->sec, &logs->msec);
+
+	memcpy(logs->page_status, "\x20\x20\x20\x00", 4);
+
+	if (host->page_status) {
+		if (IS_PS_BAD_BLOCK(host))
+			logs->page_status[0] = 'B';
+		else if (IS_PS_EMPTY_PAGE(host))
+			logs->page_status[0] = 'E';
+
+		if (IS_PS_UN_ECC(host))
+			logs->page_status[1] = '*';
+
+		if (IS_PS_EPM_ERR(host) || IS_PS_BBM_ERR(host))
+			logs->page_status[2] = '?';
+	}
+
+	logs->op = op;
+	logs->cycle = host->addr_cycle;
+	logs->length = dbg_dump->length;
+	logs->offset = (host->addr_value[0] & 0xFFFF);
+	logs->page   = GET_PAGE_INDEX(host);
+
+	if (!logs->offset)
+		logs->offset = dbg_dump->offset;
+
+	if (logs->offset >= buflen)
+		logs->offset = 0;
+
+	if (logs->length > (buflen - logs->offset))
+		logs->length = (buflen - logs->offset);
+
+	if (logs->length > CONFIG_HINFC610_DBG_NAND_LOG_LENGTH)
+		logs->length = CONFIG_HINFC610_DBG_NAND_LOG_LENGTH;
+
+	memcpy(logs->data, (host->buffer + logs->offset), logs->length);
+
+	if (++dbg_dump->index >= CONFIG_HINFC610_DBG_NAND_NUM_OF_LOGS)
+		dbg_dump->index = 0;
+
+exit:
+	mutex_unlock(&dbg_dump_mutex);
+}
+/*****************************************************************************/
+
+static void dbg_dump_read(struct hinfc_host *host)
+{
+	dbg_dump_rw(host, 'R');
+}
+/*****************************************************************************/
+
+static void dbg_dump_write(struct hinfc_host *host)
+{
+	dbg_dump_rw(host, 'W');
+}
+/*****************************************************************************/
+
+static void dbg_dump_erase(struct hinfc_host *host)
+{
+	struct hinfc610_dbg_dump_item_t *logs;
+
+	mutex_lock(&dbg_dump_mutex);
+
+	if (!dbg_dump)
+		goto exit;
+
+	dbg_dump->count++;
+	logs = &dbg_dump->logs[dbg_dump->index];
+
+	do_gettime(&logs->hour, &logs->min, &logs->sec, &logs->msec);
+
+	memcpy(logs->page_status, "\x20\x20\x20\x00", 4);
+
+	logs->op = 'E';
+	logs->cycle  = host->addr_cycle;
+	logs->length = dbg_dump->length;
+
+	logs->offset = 0;
+	logs->page   = host->addr_value[0];
+	logs->length = 0;
+
+	if (++dbg_dump->index >= CONFIG_HINFC610_DBG_NAND_NUM_OF_LOGS)
+		dbg_dump->index = 0;
+
+exit:
+	mutex_unlock(&dbg_dump_mutex);
+}
+/*****************************************************************************/
+
+struct hinfc610_dbg_inf_t hinfc610_dbg_inf_dump = {
+	"dump", 0,
+	dbgfs_dump_init,
+	dbgfs_dump_uninit,
+	dbg_dump_read,
+	dbg_dump_write,
+	dbg_dump_erase,
+	NULL,
+};
+/*****************************************************************************/
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_dbg_ecc_count.c b/drivers/mtd/nand/hinfc610/hinfc610_dbg_ecc_count.c
new file mode 100644
index 0000000..b7174ab
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_dbg_ecc_count.c
@@ -0,0 +1,401 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/moduleparam.h>
+#include <linux/vmalloc.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>
+#include <linux/mutex.h>
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+#include "hinfc610_dbg.h"
+
+#ifndef CONFIG_HINFC610_DBG_ECC_COUNT_NUM
+#  define CONFIG_HINFC610_DBG_ECC_COUNT_NUM          (100)
+#endif /* CONFIG_HINFC610_DBG_ECC_COUNT_NUM */
+
+struct hinfc610_dbg_ecc_count_item_t {
+	unsigned int page;
+	unsigned int page_status;    /* the same as host->page_status */
+	unsigned short hour;
+	unsigned short min;
+	unsigned short sec;
+	unsigned short msec;
+
+	unsigned char ecc[4];
+};
+
+struct hinfc610_dbg_ecc_count_t {
+
+	struct dentry *dentry;
+	unsigned int index; /* current logs index */
+	int count;          /* number of logs */
+
+	struct hinfc610_ecc_inf_t *ecc_inf;
+	unsigned int offset;
+	unsigned int length;
+	unsigned int pagecount;
+
+	unsigned char *item;
+
+	unsigned int read_index;
+};
+
+#define GET_ITEM(_ecc_count, _index)     \
+	((struct hinfc610_dbg_ecc_count_item_t *)((_ecc_count)->item + \
+		((sizeof(struct hinfc610_dbg_ecc_count_item_t) + \
+			(_ecc_count)->ecc_inf->section) * (_index))))
+
+static DEFINE_MUTEX(dbg_ecc_count_mutex);
+static struct hinfc610_dbg_ecc_count_t *dbg_ecc_count;
+/*****************************************************************************/
+
+static void do_gettime(unsigned short *hour, unsigned short *min,
+		       unsigned short *sec, unsigned short *msec)
+{
+	long val;
+	struct timeval tv;
+
+	do_gettimeofday(&tv);
+	val = tv.tv_sec % 86400; /* the second form 0 hour */
+
+	if (hour)
+		*hour = val / 3600;
+	val %= 3600;
+	if (min)
+		*min  = val / 60;
+	if (sec)
+		*sec  = val % 60;
+	if (msec)
+		*msec = tv.tv_usec / 1000;
+}
+/*****************************************************************************/
+
+static ssize_t dbgfs_ecc_count_read(struct file *filp, char __user *buffer,
+				    size_t count, loff_t *ppos)
+{
+	int len = 0;
+	char buf[128] = {0};
+	unsigned int read_index;
+	char __user *pusrbuf = buffer;
+	struct hinfc610_dbg_ecc_count_item_t *item;
+
+	if (*ppos == 0) {
+
+		if (dbg_ecc_count->count
+		    < CONFIG_HINFC610_DBG_ECC_COUNT_NUM)
+			dbg_ecc_count->read_index = 0;
+		else
+			dbg_ecc_count->read_index
+				= (dbg_ecc_count->index + 1);
+
+		len = snprintf(buf, sizeof(buf),
+			"Print parameter: \"offset=%d length=%d\"\n",
+			dbg_ecc_count->offset,
+			dbg_ecc_count->length);
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+
+		pusrbuf += len;
+
+		len = snprintf(buf, sizeof(buf),
+			"  UTC Clock    page          ecc data\n");
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+
+		pusrbuf += len;
+
+	} else if (dbg_ecc_count->read_index == dbg_ecc_count->index)
+		return 0;
+
+	for (read_index = dbg_ecc_count->read_index;
+	     (read_index != dbg_ecc_count->index); ++read_index) {
+
+		if (read_index >= CONFIG_HINFC610_DBG_ECC_COUNT_NUM)
+			read_index = 0;
+
+		item = GET_ITEM(dbg_ecc_count, read_index);
+
+		if ((count - (pusrbuf - buffer)) < 80)
+			break;
+
+		len = snprintf(buf, sizeof(buf),
+			"%02d:%02d:%02d.%04d  0x%08X    ",
+			item->hour, item->min, item->sec, item->msec,
+			item->page);
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+
+		pusrbuf += len;
+
+		if (IS_PS_BAD_BLOCK(item) || IS_PS_EMPTY_PAGE(item) ||
+		    IS_PS_UN_ECC(item)) {
+			char *ptr = buf;
+
+			if (IS_PS_BAD_BLOCK(item))
+				ptr += snprintf(ptr, 16, "bb ");
+			else if (IS_PS_EMPTY_PAGE(item))
+				ptr += snprintf(ptr, 16, "ep ");
+
+			if (IS_PS_UN_ECC(item))
+				ptr += snprintf(ptr, 16, "ecc ");
+
+			if (IS_PS_EPM_ERR(item) || IS_PS_BBM_ERR(item))
+				ptr += snprintf(ptr, 16, "? ");
+
+			ptr += snprintf(ptr, 16, "\n");
+			len = (ptr - buf);
+
+		} else {
+			int ix;
+			char *ptr = buf;
+
+			for (ix = 0; ix < dbg_ecc_count->ecc_inf->section; ix++)
+				ptr += snprintf(ptr, 16, "%d/", item->ecc[ix]);
+
+			if (IS_PS_EPM_ERR(item))
+				ptr += snprintf(ptr, 16, " ?");
+
+			ptr += snprintf(ptr, 16, "\n");
+			len = (ptr - buf);
+		}
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+		pusrbuf += len;
+	}
+
+	dbg_ecc_count->read_index = read_index;
+
+	*ppos += (pusrbuf - buffer);
+	return pusrbuf - buffer;
+}
+/******************************************************************************/
+/*
+ * echo "offset=8192,length=102400" > ecc_count
+ *
+ */
+static ssize_t dbgfs_ecc_count_write(struct file *filp,
+				     const char __user *buffer, size_t count,
+				     loff_t *ppos)
+{
+	char *str;
+	char buf[128] = {0};
+	int ret;
+	unsigned long value = 0;
+	unsigned long pos = 0;
+
+	if (count > sizeof(buf))
+		count = sizeof(buf);
+
+	if (copy_from_user(buf, buffer, count))
+		return -EFAULT;
+
+	while (pos < count) {
+		while (pos < count &&
+			(buf[pos] == ' ' || buf[pos] == ',' || buf[pos] == ';'))
+			pos++;
+
+		if (pos >= count)
+			break;
+
+		switch (buf[pos]) {
+
+		case 'o':
+
+			if (memcmp(&buf[pos], CMD_WORD_OFFSET,
+				sizeof(CMD_WORD_OFFSET) - 1))
+				break;
+
+			pos += sizeof(CMD_WORD_OFFSET) - 1;
+			str = (char *)(buf + pos);
+			ret = kstrtoul(str, 10, &value);
+
+			if (ret < 0)
+				value = 0;
+			if (value >= dbg_ecc_count->pagecount)
+				value = 0;
+
+			dbg_ecc_count->offset = (value & ~7);
+
+			break;
+
+		case 'l':
+			if (memcmp(&buf[pos], CMD_WORD_LENGTH,
+				sizeof(CMD_WORD_LENGTH) - 1))
+				break;
+
+			pos += sizeof(CMD_WORD_LENGTH) - 1;
+			str = (char *)(buf + pos);
+			ret = kstrtoul(str, 10, &value);
+
+			if (ret < 0)
+				value = dbg_ecc_count->pagecount;
+
+			value = ((value + 7) & ~7);
+
+			if (dbg_ecc_count->offset + value >
+			    dbg_ecc_count->pagecount)
+				value = dbg_ecc_count->pagecount
+					- dbg_ecc_count->offset;
+
+			dbg_ecc_count->length = value;
+
+			break;
+		}
+
+		while (pos < count &&
+			(buf[pos] != ' ' && buf[pos] != ',' && buf[pos] != ';'))
+			pos++;
+	}
+
+	return count;
+}
+/******************************************************************************/
+
+static const struct file_operations dbgfs_ecc_count_fops = {
+	.owner = THIS_MODULE,
+	.read  = dbgfs_ecc_count_read,
+	.write = dbgfs_ecc_count_write,
+};
+/*****************************************************************************/
+
+static int dbgfs_ecc_count_init(struct dentry *root, struct hinfc_host *host)
+{
+	unsigned int size;
+	unsigned int pagesize;
+	unsigned int chipsize;
+	struct hinfc610_ecc_inf_t *ecc_inf;
+	struct hinfc610_dbg_ecc_count_t *ecc_count;
+
+	if (dbg_ecc_count)
+		return 0;
+
+	ecc_inf = hinfc610_get_ecc_inf(host, host->pagesize, host->ecctype);
+	if (!ecc_inf) {
+		pr_warn("ecc_count: The NAND not support this interface.\n");
+		return -1;
+	}
+
+	size = sizeof(struct hinfc610_dbg_ecc_count_t);
+	size += CONFIG_HINFC610_DBG_ECC_COUNT_NUM *
+		(sizeof(struct hinfc610_dbg_ecc_count_item_t)
+		 + ecc_inf->section);
+
+	ecc_count = vmalloc(size);
+	if (!ecc_count) {
+		PR_ERR("Can't allocate memory.\n");
+		return -ENOMEM;
+	}
+	memset(ecc_count, 0, size);
+
+	ecc_count->item = (char *)ecc_count +
+		sizeof(struct hinfc610_dbg_ecc_count_t);
+	ecc_count->ecc_inf = ecc_inf;
+
+	pagesize  = (host->pagesize >> 10);
+	chipsize = (unsigned int)(host->chip->chipsize >> 10);
+	ecc_count->pagecount = (chipsize / pagesize);
+	ecc_count->length = ecc_count->pagecount;
+
+	ecc_count->dentry = debugfs_create_file("ecc_count",
+		S_IFREG | S_IRUSR | S_IWUSR,
+		root, NULL, &dbgfs_ecc_count_fops);
+	if (!ecc_count->dentry) {
+		PR_ERR("Can't create 'ecc_count' file.\n");
+		vfree(ecc_count);
+		return -ENOENT;
+	}
+
+	dbg_ecc_count = ecc_count;
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int dbgfs_ecc_count_uninit(void)
+{
+	if (!dbg_ecc_count)
+		return 0;
+
+	mutex_lock(&dbg_ecc_count_mutex);
+
+	debugfs_remove(dbg_ecc_count->dentry);
+
+	vfree(dbg_ecc_count);
+	dbg_ecc_count = NULL;
+
+	mutex_unlock(&dbg_ecc_count_mutex);
+
+	return 0;
+}
+/*****************************************************************************/
+
+static void dbg_ecc_count_read(struct hinfc_host *host)
+{
+	unsigned int page;
+	struct hinfc610_dbg_ecc_count_item_t *item;
+
+	mutex_lock(&dbg_ecc_count_mutex);
+
+	if (!dbg_ecc_count)
+		goto exit;
+
+	page = GET_PAGE_INDEX(host);
+
+	if (page < dbg_ecc_count->offset ||
+	    page > (dbg_ecc_count->offset + dbg_ecc_count->length))
+		goto exit;
+
+	item = GET_ITEM(dbg_ecc_count, dbg_ecc_count->index);
+
+	dbg_ecc_count->count++;
+
+	do_gettime(&item->hour, &item->min, &item->sec, &item->msec);
+
+	item->page = page;
+	item->page_status = host->page_status;
+
+	if (!IS_PS_UN_ECC(host))
+		dbg_ecc_count->ecc_inf->ecc_inf(host, item->ecc);
+
+	if (++dbg_ecc_count->index >= CONFIG_HINFC610_DBG_ECC_COUNT_NUM)
+		dbg_ecc_count->index = 0;
+
+exit:
+	mutex_unlock(&dbg_ecc_count_mutex);
+}
+/*****************************************************************************/
+
+struct hinfc610_dbg_inf_t hinfc610_dbg_inf_ecc_count = {
+	"ecc_count", 0,
+	dbgfs_ecc_count_init,
+	dbgfs_ecc_count_uninit,
+	dbg_ecc_count_read,
+	NULL,
+	NULL,
+	NULL,
+};
+/*****************************************************************************/
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_dbg_ecc_dump.c b/drivers/mtd/nand/hinfc610/hinfc610_dbg_ecc_dump.c
new file mode 100644
index 0000000..a1b7eda
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_dbg_ecc_dump.c
@@ -0,0 +1,141 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/moduleparam.h>
+#include <linux/vmalloc.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+#include "hinfc610_dbg.h"
+
+/*****************************************************************************/
+static inline void hinfc610_detect_ecc(unsigned char ecc[], int begin,
+				       int end, unsigned int reg)
+{
+	while (begin < end) {
+		ecc[begin] = (reg & 0xff);
+		reg = (reg >> 8);
+		begin++;
+	}
+}
+/*****************************************************************************/
+
+static void hinfc610_ecc_32k(struct hinfc_host *host, unsigned char ecc[])
+{
+	int ix, jx, kx;
+
+	for (ix = 0, jx = 0; ix < 4; ix ++, jx += 4)
+		hinfc610_detect_ecc(ecc, jx, jx + 4,
+				    hinfc_read(host, 0xA0 + jx));
+	kx = jx;
+	for (ix = 0, jx = 0; ix < 4; ix ++, jx += 4)
+		hinfc610_detect_ecc(ecc, kx, kx + 4,
+				    hinfc_read(host, 0xDC + jx));
+}
+/*****************************************************************************/
+
+static void hinfc610_ecc_16k(struct hinfc_host *host, unsigned char ecc[])
+{
+	int ix, jx;
+
+	for (ix = 0, jx = 0; ix < 4; ix ++, jx += 4)
+		hinfc610_detect_ecc(ecc, jx, jx + 4,
+				    hinfc_read(host, 0xA0 + jx));
+}
+/*****************************************************************************/
+
+static void hinfc610_ecc_8k(struct hinfc_host *host, unsigned char ecc[])
+{
+	int ix, jx;
+
+	for (ix = 0, jx = 0; ix < 2; ix ++, jx += 4)
+		hinfc610_detect_ecc(ecc, jx, jx + 4,
+				    hinfc_read(host, 0xA0 + jx));
+}
+/*****************************************************************************/
+
+static void hinfc610_ecc_4k(struct hinfc_host *host, unsigned char ecc[])
+{
+	hinfc610_detect_ecc(ecc, 0, 4, hinfc_read(host, 0xA0));
+}
+/*****************************************************************************/
+
+static void hinfc610_ecc_2k(struct hinfc_host *host, unsigned char ecc[])
+{
+	hinfc610_detect_ecc(ecc, 0, 2, hinfc_read(host, 0xA0));
+}
+/*****************************************************************************/
+
+static struct hinfc610_ecc_inf_t hinfc610_ecc_inf[] = {
+
+	{32768, NAND_ECC_80BIT, 32, hinfc610_ecc_32k},
+	{32768, NAND_ECC_72BIT, 32, hinfc610_ecc_32k},
+	{32768, NAND_ECC_60BIT, 32, hinfc610_ecc_32k},
+	{32768, NAND_ECC_48BIT, 32, hinfc610_ecc_32k},
+	{32768, NAND_ECC_41BIT, 32, hinfc610_ecc_32k},
+
+	{16384, NAND_ECC_80BIT, 16, hinfc610_ecc_16k},
+	{16384, NAND_ECC_72BIT, 16, hinfc610_ecc_16k},
+	{16384, NAND_ECC_60BIT, 16, hinfc610_ecc_16k},
+	{16384, NAND_ECC_48BIT, 16, hinfc610_ecc_16k},
+	{16384, NAND_ECC_41BIT, 16, hinfc610_ecc_16k},
+
+	{8192, NAND_ECC_80BIT, 8, hinfc610_ecc_8k},
+	{8192, NAND_ECC_72BIT, 8, hinfc610_ecc_8k},
+	{8192, NAND_ECC_60BIT, 8, hinfc610_ecc_8k},
+	{8192, NAND_ECC_48BIT, 8, hinfc610_ecc_8k},
+	{8192, NAND_ECC_41BIT, 8, hinfc610_ecc_8k},
+	{8192, NAND_ECC_32BIT, 8, hinfc610_ecc_8k},
+	{8192, NAND_ECC_27BIT, 8, hinfc610_ecc_8k},
+	{8192, NAND_ECC_24BIT, 8, hinfc610_ecc_8k},
+
+
+
+	{4096, NAND_ECC_32BIT, 4, hinfc610_ecc_4k},
+	{4096, NAND_ECC_27BIT, 4, hinfc610_ecc_4k},
+	{4096, NAND_ECC_24BIT, 4, hinfc610_ecc_4k},
+	{4096, NAND_ECC_18BIT, 4, hinfc610_ecc_4k},
+	{4096, NAND_ECC_13BIT, 4, hinfc610_ecc_4k},
+	{4096, NAND_ECC_8BIT,  4, hinfc610_ecc_4k},
+
+	{2048, NAND_ECC_32BIT, 2, hinfc610_ecc_2k},
+	{2048, NAND_ECC_27BIT, 2, hinfc610_ecc_2k},
+	{2048, NAND_ECC_24BIT, 2, hinfc610_ecc_2k},
+	{2048, NAND_ECC_18BIT, 2, hinfc610_ecc_2k},
+	{2048, NAND_ECC_13BIT, 2, hinfc610_ecc_2k},
+	{2048, NAND_ECC_8BIT,  2, hinfc610_ecc_2k},
+	{0, 0, 0},
+};
+/*****************************************************************************/
+
+struct hinfc610_ecc_inf_t *hinfc610_get_ecc_inf(struct hinfc_host *host,
+						int pagesize, int ecctype)
+{
+	struct hinfc610_ecc_inf_t *inf;
+
+	for (inf = hinfc610_ecc_inf; inf->pagesize; inf++)
+		if (inf->pagesize == pagesize && inf->ecctype == ecctype)
+			return inf;
+
+	return NULL;
+}
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_dbg_erase_count.c b/drivers/mtd/nand/hinfc610/hinfc610_dbg_erase_count.c
new file mode 100644
index 0000000..eedbd2b
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_dbg_erase_count.c
@@ -0,0 +1,317 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/moduleparam.h>
+#include <linux/vmalloc.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>
+#include <linux/mutex.h>
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+#include "hinfc610_dbg.h"
+
+struct hinfc610_dbg_erase_count_t {
+
+	unsigned int index;  /* display pos */
+	unsigned int offset; /* display offset */
+	unsigned int length; /* display length */
+
+	struct dentry *dentry;
+
+	unsigned int blocknum;
+	unsigned int page_per_block;
+
+	unsigned int pe[1];
+};
+
+static DEFINE_MUTEX(dbg_erase_count_mutex);
+static struct hinfc610_dbg_erase_count_t *dbg_erase_count;
+
+/*****************************************************************************/
+
+static int dbgfs_erase_count_read(struct file *filp, char __user *buffer,
+				  size_t count, loff_t *ppos)
+{
+	int len = 0;
+	int value = 0;
+	unsigned int *pe;
+	unsigned int index;
+	char buf[128] = {0};
+	char __user *pusrbuf = buffer;
+
+	if (*ppos == 0) {
+		dbg_erase_count->index = dbg_erase_count->offset;
+
+		len = snprintf(buf, sizeof(buf),
+			"Print parameter: \"offset=%d length=%d\"\n",
+			dbg_erase_count->offset,
+			dbg_erase_count->length);
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+		pusrbuf += len;
+
+		len = snprintf(buf, sizeof(buf),
+			"Block Index  ---------------- "
+			"Erase count from system startup ----------------\n");
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+		pusrbuf += len;
+	}
+
+	for (index = dbg_erase_count->index;
+	     index < (dbg_erase_count->offset + dbg_erase_count->length) &&
+		     ((pusrbuf - buffer) < (count - 100));
+	     index += 8) {
+
+		pe = &dbg_erase_count->pe[index];
+
+		len = snprintf(buf, sizeof(buf),
+			"%4d: %8u %8u %8u %8u  %8u %8u %8u %8u\n",
+			index,
+			pe[0], pe[1], pe[2], pe[3],
+			pe[4], pe[5], pe[6], pe[7]);
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+		pusrbuf += len;
+	}
+
+	dbg_erase_count->index = index;
+
+	*ppos += (pusrbuf - buffer);
+	value = pusrbuf - buffer;
+	return value;
+}
+/*****************************************************************************/
+/*
+ * echo "offset=48,length=78" > /sys/kernel/debug/nand/erase_count
+ * echo "clear" > /sys/kernel/debug/nand/erase_count
+ *
+
+ # cat ./debugfs/nand/erase_count
+ Print parameter: "offset=0 length=1024"
+ Block Index  ---------------- Erase count from system startup ----------------
+  0:        0        0        0        0         0        0        0        0
+  8:        0        0        0        0         0        0        0        0
+ 16:        0        0        0        0         0        0        0        0
+ 24:        0        0        0        0         0        0        0        0
+ 32:        0        0        0        0         0        0        0        0
+ 40:        0        0        0        0         0        0        0        0
+ 48:        0        0        0        0         0        0        0        0
+ 56:        0        0        0        0         0        0        0        0
+ 64:        0        0        0        0         0        0        0        0
+ 72:        0        0        0        0         0        0        0        0
+ 80:        0        0        0        0         0        0        0        0
+
+ */
+static int dbgfs_erase_count_write(struct file *filp,
+				   const char __user *buffer,
+				   size_t count, loff_t *ppos)
+{
+	char *str;
+	char buf[128] = {0};
+	int ret;
+	unsigned long value = 0;
+	unsigned long pos = 0;
+
+	if (count > sizeof(buf))
+		count = sizeof(buf);
+
+	if (copy_from_user(buf, buffer, count))
+		return -EFAULT;
+
+	while (pos < count) {
+		while (pos < count &&
+		       (buf[pos] == ' ' || buf[pos] == ',' || buf[pos] == ';'))
+			pos++;
+
+		if (pos >= count)
+			break;
+
+		switch (buf[pos]) {
+
+		case 'o':
+
+			if (memcmp(&buf[pos], CMD_WORD_OFFSET,
+				    sizeof(CMD_WORD_OFFSET) - 1))
+				break;
+
+			pos += sizeof(CMD_WORD_OFFSET) - 1;
+			str = (char *)(buf + pos);
+			ret = kstrtoul(str, 10, &value);
+			if (ret < 0)
+				value = 0;
+			if (value >= dbg_erase_count->blocknum)
+				value = 0;
+
+			dbg_erase_count->offset = (value & ~7);
+
+			break;
+
+		case 'l':
+			if (memcmp(&buf[pos], CMD_WORD_LENGTH,
+				sizeof(CMD_WORD_LENGTH) - 1))
+				break;
+
+			pos += sizeof(CMD_WORD_LENGTH) - 1;
+			str = (char *)(buf + pos);
+			ret = kstrtoul(str, 10, &value);
+			if (ret < 0)
+				value = dbg_erase_count->blocknum;
+
+			value = ((value + 7) & ~7);
+
+			if (dbg_erase_count->offset + value
+			    > dbg_erase_count->blocknum)
+				value = dbg_erase_count->blocknum
+					- dbg_erase_count->offset;
+
+			dbg_erase_count->length = value;
+
+			break;
+
+		case 'c':
+			if (memcmp(&buf[pos], CMD_WORD_CLEAN,
+				sizeof(CMD_WORD_CLEAN) - 1))
+				break;
+
+			memset(dbg_erase_count->pe, 0,
+			       dbg_erase_count->blocknum *
+			       sizeof(struct hinfc610_dbg_erase_count_t));
+
+			return count;
+		}
+
+		while (pos < count &&
+		       (buf[pos] != ' ' && buf[pos] != ',' && buf[pos] != ';'))
+			pos++;
+	}
+
+	return count;
+}
+/*****************************************************************************/
+
+static const struct file_operations dbgfs_erase_count_fops = {
+	.owner = THIS_MODULE,
+	.read  = dbgfs_erase_count_read,
+	.write = dbgfs_erase_count_write,
+};
+/*****************************************************************************/
+
+static int dbgfs_erase_count_init(struct dentry *root, struct hinfc_host *host)
+{
+	unsigned int size;
+	unsigned int blocknum;
+	unsigned int pagesize;
+	unsigned int blocksize;
+	unsigned int chipsize;
+	struct hinfc610_dbg_erase_count_t *erase_count;
+
+	if (dbg_erase_count)
+		return 0;
+
+	pagesize  = (host->pagesize >> 10);
+	blocksize = (host->mtd->erasesize >> 10);
+	chipsize = (unsigned int)(host->chip->chipsize >> 10);
+
+	blocknum = chipsize / blocksize;
+	size = sizeof(int) * blocknum
+		+ sizeof(struct hinfc610_dbg_erase_count_t);
+
+	erase_count = vmalloc(size);
+	if (!erase_count) {
+		PR_ERR("Can't allocate memory.\n");
+		return -ENOMEM;
+	}
+	memset(erase_count, 0, size);
+
+	erase_count->blocknum = blocknum;
+	erase_count->page_per_block = blocksize / pagesize;
+	erase_count->length = blocknum;
+
+	erase_count->dentry = debugfs_create_file("erase_count",
+		S_IFREG | S_IRUSR | S_IWUSR,
+		root, NULL, &dbgfs_erase_count_fops);
+	if (!erase_count->dentry) {
+		PR_ERR("Can't create 'erase_count' file.\n");
+		vfree(erase_count);
+		return -ENOENT;
+	}
+
+	dbg_erase_count = erase_count;
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int dbgfs_erase_count_uninit(void)
+{
+	if (!dbg_erase_count)
+		return 0;
+
+	mutex_lock(&dbg_erase_count_mutex);
+
+	debugfs_remove(dbg_erase_count->dentry);
+
+	vfree(dbg_erase_count);
+	dbg_erase_count = NULL;
+
+	mutex_unlock(&dbg_erase_count_mutex);
+
+	return 0;
+}
+/*****************************************************************************/
+
+static void dbg_erase_count_erase(struct hinfc_host *host)
+{
+	unsigned int block_index;
+
+	mutex_lock(&dbg_erase_count_mutex);
+
+	if (!dbg_erase_count)
+		goto exit;
+
+	block_index = (host->addr_value[0] / dbg_erase_count->page_per_block);
+
+	if (block_index > dbg_erase_count->blocknum) {
+		PR_ERR("Block out of range.\n");
+		return;
+	}
+
+	dbg_erase_count->pe[block_index]++;
+
+exit:
+	mutex_unlock(&dbg_erase_count_mutex);
+}
+/*****************************************************************************/
+
+struct hinfc610_dbg_inf_t hinfc610_dbg_inf_erase_count = {
+	"erase_count", 0,
+	dbgfs_erase_count_init,
+	dbgfs_erase_count_uninit,
+	NULL,
+	NULL,
+	dbg_erase_count_erase,
+	NULL,
+};
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_dbg_inf.c b/drivers/mtd/nand/hinfc610/hinfc610_dbg_inf.c
new file mode 100644
index 0000000..f3e7140
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_dbg_inf.c
@@ -0,0 +1,81 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/moduleparam.h>
+#include <linux/vmalloc.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+#include "hinfc610_dbg.h"
+
+void hinfc610_dbg_write(struct hinfc_host *host)
+{
+#ifdef CONFIG_HINFC610_DBG_NAND_DEBUG
+	struct hinfc610_dbg_inf_t **inf;
+
+	for (inf = hinfc610_dbg_inf; *inf; inf++)
+		if ((*inf)->enable && (*inf)->write)
+			(*inf)->write(host);
+#endif
+}
+
+void hinfc610_dbg_erase(struct hinfc_host *host)
+{
+#ifdef CONFIG_HINFC610_DBG_NAND_DEBUG
+	struct hinfc610_dbg_inf_t **inf;
+
+	for (inf = hinfc610_dbg_inf; *inf; inf++)
+		if ((*inf)->enable && (*inf)->erase)
+			(*inf)->erase(host);
+#endif
+}
+
+void hinfc610_dbg_read(struct hinfc_host *host)
+{
+#ifdef CONFIG_HINFC610_DBG_NAND_DEBUG
+	struct hinfc610_dbg_inf_t **inf;
+
+	for (inf = hinfc610_dbg_inf; *inf; inf++)
+		if ((*inf)->enable && (*inf)->read)
+			(*inf)->read(host);
+#endif
+}
+
+void hinfc610_dbg_read_retry(struct hinfc_host *host, int index)
+{
+#ifdef CONFIG_HINFC610_DBG_NAND_DEBUG
+	struct hinfc610_dbg_inf_t **inf;
+
+	for (inf = hinfc610_dbg_inf; *inf; inf++)
+		if ((*inf)->enable && (*inf)->read_retry)
+			(*inf)->read_retry(host, index);
+#endif
+}
+
+int hinfc610_dbg_init(struct hinfc_host *host)
+{
+#ifdef CONFIG_HINFC610_DBG_NAND_DEBUG
+	return hinfc610_dbgfs_debug_init(host);
+#endif
+	return 0;
+}
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_dbg_inf.h b/drivers/mtd/nand/hinfc610/hinfc610_dbg_inf.h
new file mode 100644
index 0000000..10ac797
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_dbg_inf.h
@@ -0,0 +1,34 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef HINFC610_DBG_INFH
+#define HINFC610_DBG_INFH
+/******************************************************************************/
+
+int hinfc610_dbg_init(struct hinfc_host *host);
+
+void hinfc610_dbg_write(struct hinfc_host *host);
+
+void hinfc610_dbg_erase(struct hinfc_host *host);
+
+void hinfc610_dbg_read(struct hinfc_host *host);
+
+void hinfc610_dbg_read_retry(struct hinfc_host *host, int index);
+
+/******************************************************************************/
+#endif /* HINFC610_DBG_INFH */
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_dbg_read_retry.c b/drivers/mtd/nand/hinfc610/hinfc610_dbg_read_retry.c
new file mode 100644
index 0000000..176d9c1
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_dbg_read_retry.c
@@ -0,0 +1,385 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/moduleparam.h>
+#include <linux/vmalloc.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/debugfs.h>
+#include <linux/uaccess.h>
+#include <linux/mutex.h>
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+#include "hinfc610_dbg.h"
+
+#ifndef CONFIG_HINFC610_DBG_READ_RETRY_NUM
+#  define CONFIG_HINFC610_DBG_READ_RETRY_NUM          (100)
+#endif /* CONFIG_HINFC610_DBG_READ_RETRY_NUM */
+
+struct hinfc610_dbg_read_retry_item_t {
+	unsigned int page;
+
+	unsigned short hour;
+	unsigned short min;
+	unsigned short sec;
+	unsigned short msec;
+
+	unsigned short retry;  /* success retry */
+	unsigned short ecc_err;
+};
+
+struct hinfc610_dbg_read_retry_t {
+
+	struct dentry *dentry;
+	unsigned int index; /* current logs index */
+	int count;          /* number of logs */
+
+	unsigned int offset;
+	unsigned int length;
+	unsigned int pagecount;
+
+	unsigned int read_index;
+
+	unsigned int max_retry; /* the max read retry times */
+	unsigned int retry[16];
+
+	struct hinfc610_dbg_read_retry_item_t
+		item[CONFIG_HINFC610_DBG_READ_RETRY_NUM];
+};
+
+static DEFINE_MUTEX(dbg_read_retry_mutex);
+static struct hinfc610_dbg_read_retry_t *dbg_read_retry;
+/*****************************************************************************/
+
+static void do_gettime(unsigned short *hour, unsigned short *min,
+		       unsigned short *sec, unsigned short *msec)
+{
+	long val;
+	struct timeval tv;
+
+	do_gettimeofday(&tv);
+	val = tv.tv_sec % 86400; /* the second form 0 hour */
+
+	if (hour)
+		*hour = val / 3600;
+	val %= 3600;
+	if (min)
+		*min  = val / 60;
+	if (sec)
+		*sec  = val % 60;
+	if (msec)
+		*msec = tv.tv_usec / 1000;
+}
+/*****************************************************************************/
+
+static ssize_t dbgfs_read_retry_read(struct file *filp, char __user *buffer,
+				    size_t count, loff_t *ppos)
+{
+	int ix;
+	char *ptr;
+	int len = 0;
+	char buf[128] = {0};
+	unsigned int read_index;
+	char __user *pusrbuf = buffer;
+	struct hinfc610_dbg_read_retry_item_t *item;
+
+	if (*ppos == 0) {
+
+		if (dbg_read_retry->count
+		    < CONFIG_HINFC610_DBG_READ_RETRY_NUM)
+			dbg_read_retry->read_index = 0;
+		else
+			dbg_read_retry->read_index
+				= (dbg_read_retry->index + 1);
+
+		len = snprintf(buf, sizeof(buf),
+			"Print parameter: \"offset=%d length=%d\"\n",
+			dbg_read_retry->offset,
+			dbg_read_retry->length);
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+		pusrbuf += len;
+
+		len = snprintf(buf, sizeof(buf),
+			"  UTC Clock    page          read retry (max: %d)\n",
+			dbg_read_retry->max_retry);
+
+		ptr = buf;
+		ptr += sprintf(ptr, "Read retry: ");
+		for (ix = 1; ix <= dbg_read_retry->max_retry; ix++)
+			ptr += sprintf(ptr, "%d, ", dbg_read_retry->retry[ix]);
+		ptr += sprintf(ptr, "\n");
+
+		len = (ptr - buf);
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+		pusrbuf += len;
+
+
+		len = snprintf(buf, sizeof(buf),
+			"  UTC Clock    page          read retry (max: %d)\n",
+			dbg_read_retry->max_retry);
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+		pusrbuf += len;
+
+	} else if (dbg_read_retry->read_index == dbg_read_retry->index)
+		return 0;
+
+	for (read_index = dbg_read_retry->read_index;
+	     (read_index != dbg_read_retry->index); ++read_index) {
+
+		if (read_index >= CONFIG_HINFC610_DBG_READ_RETRY_NUM)
+			read_index = 0;
+
+		item = &dbg_read_retry->item[read_index];
+
+		if ((count - (pusrbuf - buffer)) < 80)
+			break;
+
+		len = snprintf(buf, sizeof(buf),
+			"%02d:%02d:%02d.%04d  0x%08X    ",
+			item->hour, item->min, item->sec, item->msec,
+			item->page);
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+		pusrbuf += len;
+
+		if (!item->ecc_err)
+			len = sprintf(buf, "%d\n", item->retry);
+		else
+			len = sprintf(buf, "fail\n");
+
+		if (copy_to_user(pusrbuf, buf, len))
+			return -EFAULT;
+		pusrbuf += len;
+	}
+
+	dbg_read_retry->read_index = read_index;
+
+	*ppos += (pusrbuf - buffer);
+	return pusrbuf - buffer;
+}
+/******************************************************************************/
+/*
+ * echo "offset=8192,length=102400" > read_retry
+ *
+ */
+static ssize_t dbgfs_read_retry_write(struct file *filp,
+				     const char __user *buffer, size_t count,
+				     loff_t *ppos)
+{
+	char *str;
+	char buf[128] = {0};
+	int ret;
+	unsigned long value = 0;
+	unsigned long pos = 0;
+
+	if (count > sizeof(buf))
+		count = sizeof(buf);
+
+	if (copy_from_user(buf, buffer, count))
+		return -EFAULT;
+
+	while (pos < count) {
+		while (pos < count &&
+			(buf[pos] == ' ' || buf[pos] == ',' || buf[pos] == ';'))
+			pos++;
+
+		if (pos >= count)
+			break;
+
+		switch (buf[pos]) {
+
+		case 'o':
+
+			if (memcmp(&buf[pos], CMD_WORD_OFFSET,
+				sizeof(CMD_WORD_OFFSET) - 1))
+				break;
+
+			pos += sizeof(CMD_WORD_OFFSET) - 1;
+			str = (char *)(buf + pos);
+			ret = kstrtoul(str, 10, &value);
+
+			if (ret < 0)
+				value = 0;
+			if (value >= dbg_read_retry->pagecount)
+				value = 0;
+
+			dbg_read_retry->offset = (value & ~7);
+
+			break;
+
+		case 'l':
+			if (memcmp(&buf[pos], CMD_WORD_LENGTH,
+				sizeof(CMD_WORD_LENGTH) - 1))
+				break;
+
+			pos += sizeof(CMD_WORD_LENGTH) - 1;
+			str = (char *)(buf + pos);
+			ret = kstrtoul(str, 10, &value);
+
+			if (ret < 0)
+				value = dbg_read_retry->pagecount;
+
+			value = ((value + 7) & ~7);
+
+			if (dbg_read_retry->offset + value >
+			    dbg_read_retry->pagecount)
+				value = dbg_read_retry->pagecount
+					- dbg_read_retry->offset;
+
+			dbg_read_retry->length = value;
+
+			break;
+		}
+
+		while (pos < count &&
+			(buf[pos] != ' ' && buf[pos] != ',' && buf[pos] != ';'))
+			pos++;
+	}
+
+	return count;
+}
+/******************************************************************************/
+
+static const struct file_operations dbgfs_read_retry_fops = {
+	.owner = THIS_MODULE,
+	.read  = dbgfs_read_retry_read,
+	.write = dbgfs_read_retry_write,
+};
+/*****************************************************************************/
+
+static int dbgfs_read_retry_init(struct dentry *root, struct hinfc_host *host)
+{
+	unsigned int pagesize;
+	unsigned int chipsize;
+	struct hinfc610_dbg_read_retry_t *read_retry;
+
+	if (dbg_read_retry)
+		return 0;
+
+	if (!host->read_retry) {
+		pr_warn("read_retry: The NAND not support this interface.\n");
+		return -1;
+	}
+
+	read_retry = vmalloc(sizeof(struct hinfc610_dbg_read_retry_t));
+	if (!read_retry) {
+		PR_ERR("Can't allocate memory.\n");
+		return -ENOMEM;
+	}
+	memset(read_retry, 0, sizeof(struct hinfc610_dbg_read_retry_t));
+
+	pagesize  = (host->pagesize >> 10);
+	chipsize = (unsigned int)(host->chip->chipsize >> 10);
+	read_retry->pagecount = (chipsize / pagesize);
+	read_retry->length = read_retry->pagecount;
+	read_retry->max_retry = host->read_retry->count;
+
+	if (read_retry->max_retry > 16) {
+		vfree(read_retry);
+		PR_ERR("Bug, max_retry too small.\n");
+		return -EFAULT;
+	}
+
+	read_retry->dentry = debugfs_create_file("read_retry",
+		S_IFREG | S_IRUSR | S_IWUSR,
+		root, NULL, &dbgfs_read_retry_fops);
+	if (!read_retry->dentry) {
+		PR_ERR("Can't create 'read_retry' file.\n");
+		vfree(read_retry);
+		return -ENOENT;
+	}
+
+	dbg_read_retry = read_retry;
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int dbgfs_read_retry_uninit(void)
+{
+	if (!dbg_read_retry)
+		return 0;
+
+	mutex_lock(&dbg_read_retry_mutex);
+
+	debugfs_remove(dbg_read_retry->dentry);
+
+	vfree(dbg_read_retry);
+	dbg_read_retry = NULL;
+
+	mutex_unlock(&dbg_read_retry_mutex);
+
+	return 0;
+}
+/*****************************************************************************/
+
+static void hinfc610_dbg_read_retry_rr(struct hinfc_host *host, int index)
+{
+	unsigned int page;
+	struct hinfc610_dbg_read_retry_item_t *item;
+
+	mutex_lock(&dbg_read_retry_mutex);
+
+	if (!dbg_read_retry)
+		goto exit;
+
+	page = GET_PAGE_INDEX(host);
+
+	if (page < dbg_read_retry->offset ||
+	    page > (dbg_read_retry->offset + dbg_read_retry->length))
+		goto exit;
+
+	item = &dbg_read_retry->item[dbg_read_retry->index];
+
+	dbg_read_retry->count++;
+
+	do_gettime(&item->hour, &item->min, &item->sec, &item->msec);
+
+	item->page = page;
+	item->retry = index;
+
+	item->ecc_err = IS_PS_UN_ECC(host) ? 1 : 0;
+	if (!item->ecc_err)
+		dbg_read_retry->retry[index]++;
+
+	if (++dbg_read_retry->index >= CONFIG_HINFC610_DBG_READ_RETRY_NUM)
+		dbg_read_retry->index = 0;
+
+exit:
+	mutex_unlock(&dbg_read_retry_mutex);
+}
+/*****************************************************************************/
+
+struct hinfc610_dbg_inf_t hinfc610_dbg_inf_read_retry = {
+	"read_retry", 0,
+	dbgfs_read_retry_init,
+	dbgfs_read_retry_uninit,
+	NULL,
+	NULL,
+	NULL,
+	hinfc610_dbg_read_retry_rr,
+};
+/*****************************************************************************/
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_gen.c b/drivers/mtd/nand/hinfc610/hinfc610_gen.c
new file mode 100644
index 0000000..2b43cf9
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_gen.c
@@ -0,0 +1,85 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "../match_table.h"
+#include "hinfc610_gen.h"
+
+/*****************************************************************************/
+
+static struct match_reg_type page_type2reg[] = {
+	{
+		hinfc610_pagesize_2K, NAND_PAGE_2K,
+	}, {
+		hinfc610_pagesize_4K, NAND_PAGE_4K,
+	}, {
+		hinfc610_pagesize_8K, NAND_PAGE_8K,
+	}, {
+		hinfc610_pagesize_16K, NAND_PAGE_16K,
+	}, {
+		hinfc610_pagesize_32K, NAND_PAGE_32K,
+	}
+};
+
+enum hinfc610_page_reg hinfc610_page_type2reg(int type)
+{
+	return type2reg(page_type2reg, ARRAY_SIZE(page_type2reg), type, 0);
+}
+
+int hinfc610_page_reg2type(enum hinfc610_page_reg reg)
+{
+	return reg2type(page_type2reg, ARRAY_SIZE(page_type2reg), reg, 0);
+}
+/*****************************************************************************/
+
+static struct match_reg_type ecc_type2reg[] = {
+	{
+		hinfc610_ecc_none, NAND_ECC_NONE,
+	}, {
+		hinfc610_ecc_8bit, NAND_ECC_8BIT,
+	}, {
+		hinfc610_ecc_13bit, NAND_ECC_13BIT,
+	}, {
+		hinfc610_ecc_18bit, NAND_ECC_18BIT,
+	}, {
+		hinfc610_ecc_24bit, NAND_ECC_24BIT,
+	}, {
+		hinfc610_ecc_27bit, NAND_ECC_27BIT,
+	}, {
+		hinfc610_ecc_32bit, NAND_ECC_32BIT,
+	}, {
+		hinfc610_ecc_41bit, NAND_ECC_41BIT,
+	}, {
+		hinfc610_ecc_48bit, NAND_ECC_48BIT,
+	}, {
+		hinfc610_ecc_60bit, NAND_ECC_60BIT,
+	}, {
+		hinfc610_ecc_72bit, NAND_ECC_72BIT,
+	}, {
+		hinfc610_ecc_80bit, NAND_ECC_80BIT,
+	}
+};
+
+enum hinfc610_ecc_reg hinfc610_ecc_type2reg(int type)
+{
+	return type2reg(ecc_type2reg, ARRAY_SIZE(ecc_type2reg), type, 0);
+}
+
+int hinfc610_ecc_reg2type(enum hinfc610_ecc_reg reg)
+{
+	return reg2type(ecc_type2reg, ARRAY_SIZE(ecc_type2reg), reg, 0);
+}
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_gen.h b/drivers/mtd/nand/hinfc610/hinfc610_gen.h
new file mode 100644
index 0000000..c41ff6f
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_gen.h
@@ -0,0 +1,57 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef HINFC610_GENH
+#define HINFC610_GENH
+/******************************************************************************/
+
+#include "../hinfc_gen.h"
+
+enum hinfc610_ecc_reg {
+	hinfc610_ecc_none   = 0x00,
+	hinfc610_ecc_8bit   = 0x01,
+	hinfc610_ecc_13bit  = 0x02,
+	hinfc610_ecc_18bit  = 0x03,
+	hinfc610_ecc_24bit  = 0x04,
+	hinfc610_ecc_27bit  = 0x05,
+	hinfc610_ecc_32bit  = 0x06,
+	hinfc610_ecc_41bit  = 0x07,
+	hinfc610_ecc_48bit  = 0x08,
+	hinfc610_ecc_60bit  = 0x09,
+	hinfc610_ecc_72bit  = 0x0a,
+	hinfc610_ecc_80bit  = 0x0b,
+};
+
+enum hinfc610_page_reg {
+	hinfc610_pagesize_2K    = 0x01,
+	hinfc610_pagesize_4K    = 0x02,
+	hinfc610_pagesize_8K    = 0x03,
+	hinfc610_pagesize_16K   = 0x04,
+	hinfc610_pagesize_32K   = 0x05,
+};
+
+enum hinfc610_page_reg hinfc610_page_type2reg(int type);
+
+int hinfc610_page_reg2type(enum hinfc610_page_reg reg);
+
+enum hinfc610_ecc_reg hinfc610_ecc_type2reg(int type);
+
+int hinfc610_ecc_reg2type(enum hinfc610_ecc_reg reg);
+
+/******************************************************************************/
+#endif /* HINFC610_GENH */
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_os.c b/drivers/mtd/nand/hinfc610/hinfc610_os.c
new file mode 100644
index 0000000..9682000
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_os.c
@@ -0,0 +1,245 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/of_platform.h>
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+
+/*****************************************************************************/
+
+static int hinfc610_nand_pre_probe(struct nand_chip *chip)
+{
+	uint8_t nand_maf_id;
+	struct hinfc_host *host = chip->priv;
+
+	/* Reset the chip first */
+	host->send_cmd_reset(host, 0);
+
+	/* Check the ID */
+	host->offset = 0;
+	memset((unsigned char *)(chip->IO_ADDR_R), 0, 0x10);
+	host->send_cmd_readid(host);
+	nand_maf_id = readb(chip->IO_ADDR_R);
+
+	if (nand_maf_id == 0x00 || nand_maf_id == 0xff) {
+		PR_BUG("\nCannot found a valid Nand Device\n");
+		return 1;
+	}
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_os_probe(struct platform_device *pltdev)
+{
+	int size;
+	int result = 0;
+	struct hinfc_host *host;
+	struct nand_chip *chip;
+	struct mtd_info *mtd;
+	struct resource *rs_reg, *rs_io = NULL;
+	struct device *dev = &pltdev->dev;
+	struct device_node *np = NULL;
+
+	size = sizeof(struct hinfc_host) + sizeof(struct nand_chip)
+		+ sizeof(struct mtd_info);
+	host = kmalloc(size, GFP_KERNEL);
+	if (!host) {
+		PR_BUG("failed to allocate device structure.\n");
+		return -ENOMEM;
+	}
+	memset((char *)host, 0, size);
+	platform_set_drvdata(pltdev, host);
+
+	host->dev  = dev;
+	host->chip = chip = (struct nand_chip *)&host[1];
+	host->mtd  = mtd  = (struct mtd_info *)&chip[1];
+
+	host->clk = devm_clk_get(dev, NULL);
+	if (IS_ERR(host->clk))
+		return PTR_ERR(host->clk);
+	/* enable and set system clock */
+	clk_prepare_enable(host->clk);
+
+	rs_reg = platform_get_resource_byname(pltdev, IORESOURCE_MEM,
+				"control");
+	host->iobase = devm_ioremap_resource(dev, rs_reg);
+	if (IS_ERR(host->iobase)) {
+		PR_BUG("Error: Can't get resource for reg address.\n");
+		result = -EIO;
+		goto fail;
+	}
+
+	np = of_get_next_available_child(dev->of_node, NULL);
+
+	mtd->type = MTD_NANDFLASH;
+	mtd = nand_to_mtd(chip);
+	mtd->flags = MTD_CAP_NANDFLASH;
+	mtd->owner = THIS_MODULE;
+	mtd->name = np->name;
+
+	rs_io = platform_get_resource_byname(pltdev, IORESOURCE_MEM,
+					"memory");
+	chip->IO_ADDR_R = chip->IO_ADDR_W = devm_ioremap_resource(dev, rs_io);
+	if (IS_ERR(chip->IO_ADDR_R)) {
+		PR_BUG("Error: Can't get resource for buffer address.\n");
+		result = -EIO;
+		goto fail;
+	}
+
+	host->buffer = dma_alloc_coherent(host->dev,
+		(NAND_MAX_PAGESIZE + NAND_MAX_OOBSIZE),
+		&host->dma_buffer, GFP_KERNEL);
+	if (!host->buffer) {
+		PR_BUG("Can't malloc memory for NAND driver.");
+		result = -EIO;
+		goto fail;
+	}
+
+	chip->priv        = host;
+	host->chip        = chip;
+	chip->cmd_ctrl    = hinfc610_cmd_ctrl;
+	chip->dev_ready   = hinfc610_dev_ready;
+	chip->select_chip = hinfc610_select_chip;
+	chip->read_byte   = hinfc610_read_byte;
+	chip->read_word   = hinfc610_read_word;
+	chip->write_buf   = hinfc610_write_buf;
+	chip->read_buf    = hinfc610_read_buf;
+
+	chip->chip_delay = HINFC610_CHIP_DELAY;
+	chip->options    = NAND_NEED_READRDY
+			| NAND_BROKEN_XD
+			| NAND_SKIP_BBTSCAN;
+	chip->ecc.mode   = NAND_ECC_NONE;
+
+	if (hinfc610_nand_init(host, chip)) {
+		PR_BUG("failed to allocate device buffer.\n");
+		result = -EIO;
+		goto fail;
+	}
+
+	if (hinfc610_nand_pre_probe(chip)) {
+		result = -EXDEV;
+		goto fail;
+	}
+
+	if (nand_scan(mtd, CONFIG_HINFC610_MAX_CHIP)) {
+		result = -ENXIO;
+		goto fail;
+	}
+
+	result = mtd_device_register(mtd, NULL, 0);
+	if (result)
+		goto fail;
+
+	return result;
+
+fail:
+	if (host->buffer) {
+		dma_free_coherent(host->dev,
+			(NAND_MAX_PAGESIZE + NAND_MAX_OOBSIZE),
+			host->buffer,
+			host->dma_buffer);
+		host->buffer = NULL;
+	}
+	nand_release(host->mtd);
+	kfree(host);
+	platform_set_drvdata(pltdev, NULL);
+
+	return result;
+}
+/*****************************************************************************/
+
+static int hinfc610_os_remove(struct platform_device *pltdev)
+{
+	struct hinfc_host *host = platform_get_drvdata(pltdev);
+
+	clk_disable_unprepare(host->clk);
+
+	nand_release(host->mtd);
+
+	dma_free_coherent(host->dev,
+		(NAND_MAX_PAGESIZE + NAND_MAX_OOBSIZE),
+		host->buffer,
+		host->dma_buffer);
+	kfree(host);
+	platform_set_drvdata(pltdev, NULL);
+
+	return 0;
+}
+/*****************************************************************************/
+#ifdef CONFIG_PM
+static int hinfc610_os_suspend(struct platform_device *pltdev,
+			       pm_message_t state)
+{
+	struct hinfc_host *host = platform_get_drvdata(pltdev);
+
+	while ((hinfc_read(host, HINFC610_STATUS) & 0x1) == 0x0)
+		;
+
+	while ((hinfc_read(host, HINFC610_DMA_CTRL))
+		& HINFC610_DMA_CTRL_DMA_START)
+		_cond_resched();
+
+	clk_disable_unprepare(host->clk);
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_os_resume(struct platform_device *pltdev)
+{
+	int cs;
+	struct hinfc_host *host = platform_get_drvdata(pltdev);
+	struct nand_chip *chip = host->chip;
+
+	clk_prepare_enable(host->clk);
+	for (cs = 0; cs < chip->numchips; cs++)
+		host->send_cmd_reset(host, cs);
+	hinfc_write(host,
+		SET_HINFC610_PWIDTH(CONFIG_HINFC610_W_LATCH,
+			CONFIG_HINFC610_R_LATCH, CONFIG_HINFC610_RW_LATCH),
+		HINFC610_PWIDTH);
+
+	return 0;
+}
+#endif /* CONFIG_PM */
+/*****************************************************************************/
+static const struct of_device_id hisi_nand_dt_ids[] = {
+	{ .compatible = "hisilicon,hisi-parallel-nand" },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, hisi_nand_dt_ids);
+
+static struct platform_driver hisi_nand_driver = {
+	.driver = {
+		.name	= "hisi-nand",
+		.of_match_table = hisi_nand_dt_ids,
+	},
+	.probe	= hinfc610_os_probe,
+	.remove = hinfc610_os_remove,
+#ifdef CONFIG_PM
+	.suspend	= hinfc610_os_suspend,
+	.resume		= hinfc610_os_resume,
+#endif
+};
+module_platform_driver(hisi_nand_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("BVT_BSP");
+MODULE_DESCRIPTION("Hisilicon Flash Memory Controller NFC610 Nand Driver");
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_os.h b/drivers/mtd/nand/hinfc610/hinfc610_os.h
new file mode 100644
index 0000000..1dafd9e
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_os.h
@@ -0,0 +1,78 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+
+#ifndef HINFC610_OSH
+#define HINFC610_OSH
+/******************************************************************************/
+
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/nand.h>
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/io.h>
+#include <asm/setup.h>
+#include <linux/errno.h>
+#include <linux/platform_device.h>
+#include <linux/mtd/partitions.h>
+#include <linux/clk.h>
+#include <linux/clkdev.h>
+
+#include "../../mtdcore.h"
+
+/*****************************************************************************/
+
+#define DUMP_DATA(_p, _n) do { \
+	int ix; \
+	unsigned char *rr = (unsigned char *)(_p); \
+	for (ix = 0; ix < _n; ix++) { \
+		pr_info("%02X ", rr[ix]); \
+		if (!((ix + 1) % 16)) \
+			pr_info("\n"); \
+	} \
+} while (0)
+
+#define DBG_OUT(fmt, args...)\
+	pr_warn("%s(%d): " fmt, __FILE__, __LINE__, ##args) \
+
+#if 1
+#  define DBG_MSG(_fmt, arg...)
+#else
+#  define DBG_MSG(_fmt, arg...) \
+	pr_info("%s(%d): " _fmt, __FILE__, __LINE__, ##arg)
+#endif
+
+#define PR_BUG(fmt, args...) do {\
+	pr_debug("%s(%d): bug " fmt, __FILE__, __LINE__, ##args); \
+	asm("b ."); \
+} while (0)
+
+#define PR_ERR(fmt, args...)\
+	pr_err("%s(%d): " fmt, __FILE__, __LINE__, ##args) \
+
+#define PR_MSG(_fmt, arg...) \
+	printk(_fmt, ##arg)
+
+/******************************************************************************/
+#endif /* HINFC610_OSH */
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_read_retry.c b/drivers/mtd/nand/hinfc610/hinfc610_read_retry.c
new file mode 100644
index 0000000..3f1a9f2
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_read_retry.c
@@ -0,0 +1,43 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "hinfc610_gen.h"
+#include "hinfc610.h"
+#include "hinfc610_read_retry.h"
+
+static struct read_retry_t *read_retry_table[] = {
+	&hinfc610_hynix_bg_bdie_read_retry,
+	&hinfc610_hynix_bg_cdie_read_retry,
+	&hinfc610_hynix_cg_adie_read_retry,
+	&hinfc610_micron_read_retry,
+	&hinfc610_toshiba_24nm_read_retry,
+	&hinfc610_samsung_read_retry,
+	NULL,
+};
+
+struct read_retry_t *hinfc610_find_read_retry(int type)
+{
+	struct read_retry_t **rr;
+
+	for (rr = read_retry_table; rr; rr++) {
+		if ((*rr)->type == type)
+			return *rr;
+	}
+
+	return NULL;
+}
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_read_retry.h b/drivers/mtd/nand/hinfc610/hinfc610_read_retry.h
new file mode 100644
index 0000000..cfd8880
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_read_retry.h
@@ -0,0 +1,25 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef HINFC610_READ_RETRY_H
+#define HINFC610_READ_RETRY_H
+
+struct read_retry_t *hinfc610_find_read_retry(int type);
+
+#endif /* HINFC610_READ_RETRY_H */
+
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_read_retry_hynix_bg_bdie.c b/drivers/mtd/nand/hinfc610/hinfc610_read_retry_hynix_bg_bdie.c
new file mode 100644
index 0000000..b6fb1a8
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_read_retry_hynix_bg_bdie.c
@@ -0,0 +1,136 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+
+/*****************************************************************************/
+
+static int hynix_bg_bdie_rr_org_exist;
+static char hynix_bg_bdie_rr_org[4] = {0};
+
+/*****************************************************************************/
+
+static int hinfc610_hynix_bg_bdie_set_rr_reg(struct hinfc_host *host, int index)
+{
+	int ix;
+	char HYNIX_BG_BDIE_RR_REG[4] = {0xA7,  0xAD,  0xAE,  0xAF};
+	char value_offset[7][4] = {
+		{0x00,  0x00,  0x00,  0x00},
+		{0x00,  0x06,  0x0A,  0x06},
+		{0x7F, -0x03, -0x07, -0x08},
+		{0x7F, -0x06, -0x0D, -0x0F},
+		{0x7F, -0x09, -0x14, -0x17},
+		{0x7F,  0x7F, -0x1A, -0x1E},
+		{0x7F,  0x7F, -0x20, -0x25}
+	};
+	char *value = &value_offset[index][0];
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+	hinfc_write(host, 1, HINFC610_DATA_NUM);
+
+	if (!hynix_bg_bdie_rr_org_exist) {
+
+		for (ix = 0; ix < 4; ix++) {
+
+			memset(host->chip->IO_ADDR_R, 0xff, 32);
+
+			hinfc_write(host, 0x37, HINFC610_CMD);
+			hinfc_write(host, HYNIX_BG_BDIE_RR_REG[ix],
+				HINFC610_ADDRL);
+			/*
+			 * according to hynix doc, no need to config
+			 * HINFC610_OP_WAIT_READY_EN,
+			 * here not config this bit.
+			 */
+			hinfc_write(host, HINFC610_READ_1CMD_1ADD_DATA,
+				HINFC610_OP);
+			WAIT_CONTROLLER_FINISH();
+
+			hynix_bg_bdie_rr_org[ix]
+				= (char)(readl(host->chip->IO_ADDR_R) & 0xff);
+		}
+		hynix_bg_bdie_rr_org_exist = 1;
+	}
+
+	for (ix = 0; ix < 4; ix++) {
+		if (value[ix] == 0x7F)
+			value[ix] = 0x00;
+		else
+			value[ix] += hynix_bg_bdie_rr_org[ix];
+	}
+
+	writel(value[0], host->chip->IO_ADDR_W);
+	hinfc_write(host, HYNIX_BG_BDIE_RR_REG[0], HINFC610_ADDRL);
+	hinfc_write(host, 0x36, HINFC610_CMD);
+	/*
+	 * according to hynix doc, no need to config HINFC610_OP_WAIT_READY_EN,
+	 * here not config this bit.
+	 */
+	hinfc_write(host, HINFC610_WRITE_1CMD_1ADD_DATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	for (ix = 1; ix < 4; ix++) {
+		writel(value[ix], host->chip->IO_ADDR_W);
+		hinfc_write(host, HYNIX_BG_BDIE_RR_REG[ix], HINFC610_ADDRL);
+		/*
+		 * according to hynix doc, no need to config
+		 * HINFC610_OP_WAIT_READY_EN,
+		 * here not config this bit.
+		 */
+		hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA, HINFC610_OP);
+		WAIT_CONTROLLER_FINISH();
+	}
+
+	hinfc_write(host, 0x16, HINFC610_CMD);
+	/*
+	 * according to hynix doc, only 1 cmd: 0x16.
+	 * And no need to config HINFC610_OP_WAIT_READY_EN,
+	 * here not config this bit.
+	 */
+	hinfc_write(host, HINFC610_WRITE_1CMD_0ADD_NODATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_hynix_bg_bdie_set_rr_param(struct hinfc_host *host,
+		int param)
+{
+	if (!param)
+		return 0;
+	return hinfc610_hynix_bg_bdie_set_rr_reg(host, param);
+}
+/*****************************************************************************/
+
+static int hinfc610_hynix_bg_bdie_reset_rr_param(struct hinfc_host *host)
+{
+	return hinfc610_hynix_bg_bdie_set_rr_param(host, 0);
+}
+/*****************************************************************************/
+
+struct read_retry_t hinfc610_hynix_bg_bdie_read_retry = {
+	.type = NAND_RR_HYNIX_BG_BDIE,
+	.count = 7,
+	.set_rr_param = hinfc610_hynix_bg_bdie_set_rr_param,
+	.get_rr_param = NULL,
+	.reset_rr_param = hinfc610_hynix_bg_bdie_reset_rr_param,
+};
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_read_retry_hynix_bg_cdie.c b/drivers/mtd/nand/hinfc610/hinfc610_read_retry_hynix_bg_cdie.c
new file mode 100644
index 0000000..fc39d70
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_read_retry_hynix_bg_cdie.c
@@ -0,0 +1,225 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+
+/*****************************************************************************/
+
+static char *hinfc610_hynix_bg_cdie_otp_check(char *otp)
+{
+	int index = 0;
+	int ix, jx;
+	char *ptr = NULL;
+	int min, cur;
+	char *otp_origin, *otp_inverse;
+
+	min = 64;
+	for (ix = 0; ix < 8; ix++, otp += 128) {
+
+		otp_origin  = otp;
+		otp_inverse = otp + 64;
+		cur = 0;
+
+		for (jx = 0; jx < 64; jx++, otp_origin++, otp_inverse++) {
+			if (((*otp_origin) ^ (*otp_inverse)) == 0xFF)
+				continue;
+			cur++;
+		}
+
+		if (cur < min) {
+			min = cur;
+			index = ix;
+			ptr = otp;
+			if (!cur)
+				break;
+		}
+	}
+
+	pr_info("RR select parameter %d from %d, error %d\n",
+		index, ix, min);
+	return ptr;
+}
+/*****************************************************************************/
+
+static int hinfc610_hynix_bg_cdie_get_rr_param(struct hinfc_host *host)
+{
+	char *otp;
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+	/* step1: reset the chip */
+	host->send_cmd_reset(host, host->chipselect);
+
+	/* step2: cmd: 0x36, address: 0xAE, data: 0x00 */
+	hinfc_write(host, 1, HINFC610_DATA_NUM);/* data length 1 */
+	writel(0x00, host->chip->IO_ADDR_R); /* data: 0x00 */
+	hinfc_write(host, 0xAE, HINFC610_ADDRL);/* address: 0xAE */
+	hinfc_write(host, 0x36, HINFC610_CMD);  /* cmd: 0x36 */
+	/* according to hynix doc, no need to config
+	 * HINFC610_OP_WAIT_READY_EN */
+	hinfc_write(host, HINFC610_WRITE_1CMD_1ADD_DATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	/* step3: address: 0xB0, data: 0x4D */
+	hinfc_write(host, 1, HINFC610_DATA_NUM);/* data length 1 */
+	writel(0x4D, host->chip->IO_ADDR_R); /* data: 0x4d */
+	hinfc_write(host, 0xB0, HINFC610_ADDRL);/* address: 0xB0 */
+	/* only address and data, without cmd */
+	/* according to hynix doc, no need to config
+	 * HINFC610_OP_WAIT_READY_EN */
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	/* step4: cmd: 0x16, 0x17, 0x04, 0x19 */
+	hinfc_write(host, 0x17 << 8 | 0x16, HINFC610_CMD);
+	/* according to hynix doc, no need to config
+	 * HINFC610_OP_WAIT_READY_EN */
+	hinfc_write(host, HINFC610_WRITE_2CMD_0ADD_NODATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	hinfc_write(host, 0x19 << 8 | 0x04, HINFC610_CMD);
+	/* according to hynix doc, no need to config
+	 * HINFC610_OP_WAIT_READY_EN */
+	hinfc_write(host, HINFC610_WRITE_2CMD_0ADD_NODATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	/* step5: cmd: 0x00 0x30, address: 0x02 00 00 00 */
+	hinfc_write(host, 0x2000000, HINFC610_ADDRL);
+	hinfc_write(host, 0x00, HINFC610_ADDRH);
+	hinfc_write(host, 0x30 << 8 | 0x00, HINFC610_CMD);
+	hinfc_write(host, 0x800, HINFC610_DATA_NUM);
+	/* according to hynix doc, need to config
+	 * HINFC610_OP_WAIT_READY_EN */
+	hinfc_write(host, HINFC610_READ_2CMD_5ADD, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	/*step6 save otp read retry table to mem*/
+	otp = hinfc610_hynix_bg_cdie_otp_check(host->chip->IO_ADDR_R + 2);
+	if (!otp) {
+		pr_err("Read Retry select parameter failed, this Nand Chip maybe invalidation.\n");
+		return -1;
+	}
+	memcpy(host->rr_data, otp, 64);
+	host->need_rr_data = 1;
+
+	/* step7: reset the chip */
+	host->send_cmd_reset(host, host->chipselect);
+
+	/* step8: cmd: 0x38 */
+	hinfc_write(host, 0x38, HINFC610_CMD);
+	/* according to hynix doc, need to config HINFC610_OP_WAIT_READY_EN */
+	hinfc_write(host, HINFC610_WRITE_1CMD_0ADD_NODATA_WAIT_READY,
+			HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+	/* get hynix otp table finish */
+	return 0;
+}
+/*****************************************************************************/
+static char hinfc610_hynix_bg_cdie_rr_reg[8] = {
+	0xB0, 0xB1, 0xB2, 0xB3, 0xB4, 0xB5, 0xB6, 0xB7};
+
+static int hinfc610_hynix_bg_cdie_set_rr_reg(struct hinfc_host *host,
+					     char *val)
+{
+	int i;
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+	hinfc_write(host, 1, HINFC610_DATA_NUM);/* data length 1 */
+
+	for (i = 0; i <= 8; i++) {
+		switch (i) {
+		case 0:
+			writel(val[i], host->chip->IO_ADDR_R);
+			hinfc_write(host,
+				hinfc610_hynix_bg_cdie_rr_reg[i],
+				HINFC610_ADDRL);
+			hinfc_write(host,
+				0x36, HINFC610_CMD);
+			/*
+			 * no need to config HINFC610_OP_WAIT_READY_EN,
+			 * here not config this bit.
+			 */
+			hinfc_write(host,
+				HINFC610_WRITE_1CMD_1ADD_DATA,
+				HINFC610_OP);
+			break;
+		case 8:
+			hinfc_write(host,
+				0x16, HINFC610_CMD);
+			/*
+			 * according to hynix doc, only 1 cmd: 0x16.
+			 * And no need to config HINFC610_OP_WAIT_READY_EN,
+			 * here not config this bit.
+			 */
+			hinfc_write(host,
+				HINFC610_WRITE_1CMD_0ADD_NODATA,
+				HINFC610_OP);
+			break;
+		default:
+			writel(val[i], host->chip->IO_ADDR_R);
+			hinfc_write(host,
+				hinfc610_hynix_bg_cdie_rr_reg[i],
+				HINFC610_ADDRL);
+			/*
+			 * no need to config HINFC610_OP_WAIT_READY_EN,
+			 * here not config this bit.
+			 */
+			hinfc_write(host,
+				HINFC610_WRITE_0CMD_1ADD_DATA,
+				HINFC610_OP);
+			break;
+		}
+		WAIT_CONTROLLER_FINISH();
+	}
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+	return 0;
+}
+
+/*****************************************************************************/
+
+static int hinfc610_hynix_bg_cdie_set_rr_param(struct hinfc_host *host,
+					       int param)
+{
+	unsigned char *rr;
+
+	if (!(host->rr_data[0] | host->rr_data[1]
+	    | host->rr_data[2] | host->rr_data[3]) || !param)
+		return -1;
+
+	rr = (unsigned char *)&host->rr_data[((param & 0x07) << 3)];
+
+	/* set the read retry regs to adjust reading level */
+	return hinfc610_hynix_bg_cdie_set_rr_reg(host, (char *)rr);
+}
+/*****************************************************************************/
+
+static int hinfc610_hynix_bg_cdie_reset_rr_param(struct hinfc_host *host)
+{
+	return hinfc610_hynix_bg_cdie_set_rr_param(host, 0);
+}
+/*****************************************************************************/
+
+struct read_retry_t hinfc610_hynix_bg_cdie_read_retry = {
+	.type = NAND_RR_HYNIX_BG_CDIE,
+	.count = 8,
+	.set_rr_param = hinfc610_hynix_bg_cdie_set_rr_param,
+	.get_rr_param = hinfc610_hynix_bg_cdie_get_rr_param,
+	.reset_rr_param = hinfc610_hynix_bg_cdie_reset_rr_param,
+};
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_read_retry_hynix_cg_adie.c b/drivers/mtd/nand/hinfc610/hinfc610_read_retry_hynix_cg_adie.c
new file mode 100644
index 0000000..b7444b8
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_read_retry_hynix_cg_adie.c
@@ -0,0 +1,234 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+
+/*****************************************************************************/
+static char *hinfc610_hynix_cg_adie_otp_check(char *otp)
+{
+	int index = 0;
+	int ix, jx;
+	char *ptr = NULL;
+	int min, cur;
+	char *otp_origin, *otp_inverse;
+
+	min = 64;
+	for (ix = 0; ix < 8; ix++, otp += 128) {
+
+		otp_origin  = otp;
+		otp_inverse = otp + 64;
+		cur = 0;
+
+		for (jx = 0; jx < 64; jx++, otp_origin++, otp_inverse++) {
+			if (((*otp_origin) ^ (*otp_inverse)) == 0xFF)
+				continue;
+			cur++;
+		}
+
+		if (cur < min) {
+			min = cur;
+			index = ix;
+			ptr = otp;
+			if (!cur)
+				break;
+		}
+	}
+
+	pr_info("RR select parameter %d from %d, error %d\n",
+		index, ix, min);
+	return ptr;
+}
+/*****************************************************************************/
+
+static int hinfc610_hynix_cg_adie_get_rr_param(struct hinfc_host *host)
+{
+	char *otp;
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+	/* step1: reset the chip */
+	host->send_cmd_reset(host, host->chipselect);
+
+	/* step2: cmd: 0x36, address: 0xFF, data: 0x40 */
+	hinfc_write(host, 1, HINFC610_DATA_NUM);/* data length 1 */
+	writel(0x40, host->chip->IO_ADDR_R); /* data: 0x00 */
+	hinfc_write(host, 0xFF, HINFC610_ADDRL);/* address: 0xAE */
+	hinfc_write(host, 0x36, HINFC610_CMD);  /* cmd: 0x36 */
+	/*
+	 * no need to config HINFC610_OP_WAIT_READY_EN,
+	 * here not config this bit.
+	 */
+	hinfc_write(host, HINFC610_WRITE_1CMD_1ADD_DATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	/* step3: address: 0xCC, data: 0x4D */
+	hinfc_write(host, 1, HINFC610_DATA_NUM);/* data length 1 */
+	writel(0x4D, host->chip->IO_ADDR_R); /* data: 0x4d */
+	hinfc_write(host, 0xCC, HINFC610_ADDRL);/* address: 0xB0 */
+	/*
+	 * no need to config HINFC610_OP_WAIT_READY_EN,
+	 * here not config this bit.
+	 * only address and data, without cmd
+	 */
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	/* step4: cmd: 0x16, 0x17, 0x04, 0x19 */
+	hinfc_write(host, 0x17 << 8 | 0x16, HINFC610_CMD);
+	/*
+	 * no need to config HINFC610_OP_WAIT_READY_EN,
+	 * here not config this bit.
+	 */
+	hinfc_write(host, HINFC610_WRITE_2CMD_0ADD_NODATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	hinfc_write(host, 0x19 << 8 | 0x04, HINFC610_CMD);
+	/*
+	 * no need to config HINFC610_OP_WAIT_READY_EN,
+	 * here not config this bit.
+	 */
+	hinfc_write(host, HINFC610_WRITE_2CMD_0ADD_NODATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	/* step5: cmd: 0x00 0x30, address: 0x02 00 00 00 */
+	hinfc_write(host, 0x2000000, HINFC610_ADDRL);
+	hinfc_write(host, 0x00, HINFC610_ADDRH);
+	hinfc_write(host, 0x30 << 8 | 0x00, HINFC610_CMD);
+	hinfc_write(host, 0x800, HINFC610_DATA_NUM);
+	/*
+	 * need to config HINFC610_OP_WAIT_READY_EN, here config this bit.
+	 */
+	hinfc_write(host, HINFC610_READ_2CMD_5ADD, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	/*step6 save otp read retry table to mem*/
+	otp = hinfc610_hynix_cg_adie_otp_check(host->chip->IO_ADDR_R + 2);
+	if (!otp) {
+		pr_err("Read Retry select parameter failed, this Nand Chip maybe invalidation.\n");
+		return -1;
+	}
+	memcpy(host->rr_data, otp, 64);
+	host->need_rr_data = 1;
+
+	/* step7: reset the chip */
+	host->send_cmd_reset(host, host->chipselect);
+
+	/* step8: cmd: 0x38 */
+	hinfc_write(host, 0x38, HINFC610_CMD);
+	/*
+	 * need to config HINFC610_OP_WAIT_READY_EN, here config this bit.
+	 */
+	hinfc_write(host, HINFC610_WRITE_1CMD_0ADD_NODATA_WAIT_READY,
+			HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+	/* get hynix otp table finish */
+	return 0;
+}
+/*****************************************************************************/
+static char hinfc610_hynix_cg_adie__rr_reg[8] = {
+	0xCC, 0xBF, 0xAA, 0xAB, 0xCD, 0xAD, 0xAE, 0xAF};
+
+static int hinfc610_hynix_cg_adie_set_rr_reg(struct hinfc_host *host, char *val)
+{
+	int i;
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+	hinfc_write(host, 1, HINFC610_DATA_NUM);/* data length 1 */
+
+	for (i = 0; i <= 8; i++) {
+		switch (i) {
+		case 0:
+			writel(val[i], host->chip->IO_ADDR_R);
+			hinfc_write(host,
+				hinfc610_hynix_cg_adie__rr_reg[i],
+				HINFC610_ADDRL);
+			hinfc_write(host,
+				0x36, HINFC610_CMD);
+			/*
+			 * no need to config HINFC610_OP_WAIT_READY_EN,
+			 * here not config this bit.
+			 */
+			hinfc_write(host,
+				HINFC610_WRITE_1CMD_1ADD_DATA,
+				HINFC610_OP);
+			break;
+		case 8:
+			hinfc_write(host,
+				0x16, HINFC610_CMD);
+			/*
+			 * only have 1 cmd: 0x16
+			 * no need to config HINFC610_OP_WAIT_READY_EN,
+			 * here not config this bit.
+			 */
+			hinfc_write(host,
+				HINFC610_WRITE_1CMD_0ADD_NODATA,
+				HINFC610_OP);
+			break;
+		default:
+			writel(val[i], host->chip->IO_ADDR_R);
+			hinfc_write(host,
+				hinfc610_hynix_cg_adie__rr_reg[i],
+				HINFC610_ADDRL);
+			/*
+			 * no need to config HINFC610_OP_WAIT_READY_EN,
+			 * here not config this bit.
+			 */
+			hinfc_write(host,
+				HINFC610_WRITE_0CMD_1ADD_DATA,
+				HINFC610_OP);
+			break;
+		}
+		WAIT_CONTROLLER_FINISH();
+	}
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+	return 0;
+}
+
+/*****************************************************************************/
+
+static int hinfc610_hynix_cg_adie_set_rr_param(struct hinfc_host *host,
+		int param)
+{
+	unsigned char *rr;
+
+	if (!(host->rr_data[0] | host->rr_data[1]
+	    | host->rr_data[2] | host->rr_data[3]) || !param)
+		return -1;
+
+	rr = (unsigned char *)&host->rr_data[((param & 0x07) << 3)];
+
+	/* set the read retry regs to adjust reading level */
+	return hinfc610_hynix_cg_adie_set_rr_reg(host, (char *)rr);
+}
+/*****************************************************************************/
+
+static int hinfc610_hynix_cg_adie_reset_rr_param(struct hinfc_host *host)
+{
+	return hinfc610_hynix_cg_adie_set_rr_param(host, 0);
+}
+/*****************************************************************************/
+
+struct read_retry_t hinfc610_hynix_cg_adie_read_retry = {
+	.type = NAND_RR_HYNIX_CG_ADIE,
+	.count = 8,
+	.set_rr_param = hinfc610_hynix_cg_adie_set_rr_param,
+	.get_rr_param = hinfc610_hynix_cg_adie_get_rr_param,
+	.reset_rr_param = hinfc610_hynix_cg_adie_reset_rr_param,
+};
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_read_retry_micron.c b/drivers/mtd/nand/hinfc610/hinfc610_read_retry_micron.c
new file mode 100644
index 0000000..c4c0716
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_read_retry_micron.c
@@ -0,0 +1,74 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+
+/*****************************************************************************/
+
+#define MICRON_RR_ADDR         0x89
+
+static int hinfc610_micron_set_rr_reg(struct hinfc_host *host, int rr)
+{
+	int regval;
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, 1, HINFC610_DATA_NUM);
+
+	writel(rr, host->chip->IO_ADDR_W);
+	hinfc_write(host, MICRON_RR_ADDR, HINFC610_ADDRL);
+	/* set read retry */
+	hinfc_write(host, 0xEF, HINFC610_CMD);
+
+	/* need to config WAIT_READY_EN, here config WAIT_READY_EN bit. */
+	regval = (HINFC610_IS_SYNC(host) ?
+		HINFC610_WRITE_1CMD_1ADD_DATA_SYNC_WAIT_READY :
+		HINFC610_WRITE_1CMD_1ADD_DATA_WAIT_READY);
+
+	hinfc_write(host, regval, HINFC610_OP);
+
+	WAIT_CONTROLLER_FINISH();
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	return 0;
+}
+/*****************************************************************************/
+#undef MICRON_RR_ADDR
+/*****************************************************************************/
+
+static int hinfc610_micron_set_rr_param(struct hinfc_host *host, int rr_option)
+{
+	return hinfc610_micron_set_rr_reg(host, rr_option);
+}
+/*****************************************************************************/
+
+static int hinfc610_micron_reset_rr_param(struct hinfc_host *host)
+{
+	return hinfc610_micron_set_rr_reg(host, 0);
+}
+/*****************************************************************************/
+
+struct read_retry_t hinfc610_micron_read_retry = {
+	.type = NAND_RR_MICRON,
+	.count = 8,
+	.set_rr_param = hinfc610_micron_set_rr_param,
+	.get_rr_param = NULL,
+	.reset_rr_param = hinfc610_micron_reset_rr_param,
+};
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_read_retry_samsung.c b/drivers/mtd/nand/hinfc610/hinfc610_read_retry_samsung.c
new file mode 100644
index 0000000..6d9adcb
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_read_retry_samsung.c
@@ -0,0 +1,109 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+
+/*****************************************************************************/
+
+static int hinfc610_samsung_set_rr_reg(struct hinfc_host *host, int param)
+{
+#define SAMSUNG_RR_CMD     0xA1
+	int opval;
+
+	unsigned char samsung_rr_params[15][4] = {
+		{0x00, 0x00, 0x00, 0x00},
+		{0x05, 0x0A, 0x00, 0x00},
+		{0x28, 0x00, 0xEC, 0xD8},
+		{0xED, 0xF5, 0xED, 0xE6},
+		{0x0A, 0x0F, 0x05, 0x00},
+		{0x0F, 0x0A, 0xFB, 0xEC},
+		{0xE8, 0xEF, 0xE8, 0xDC},
+		{0xF1, 0xFB, 0xFE, 0xF0},
+		{0x0A, 0x00, 0xFB, 0xEC},
+		{0xD0, 0xE2, 0xD0, 0xC2},
+		{0x14, 0x0F, 0xFB, 0xEC},
+		{0xE8, 0xFB, 0xE8, 0xDC},
+		{0x1E, 0x14, 0xFB, 0xEC},
+		{0xFB, 0xFF, 0xFB, 0xF8},
+		{0x07, 0x0C, 0x02, 0x00}
+	};
+
+	if (param >= 15)
+		param = (param % 15);
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	/* no need to config WAIT_READY_EN, here not config WAIT_READY_EN bit */
+	opval = (HINFC610_IS_SYNC(host) ? HINFC610_WRITE_1CMD_2ADD_DATA_SYNC
+		: HINFC610_WRITE_1CMD_2ADD_DATA);
+
+	hinfc_write(host, 1, HINFC610_DATA_NUM);
+
+	writel(samsung_rr_params[param][0], host->chip->IO_ADDR_R);
+	hinfc_write(host, 0xA700, HINFC610_ADDRL);
+	hinfc_write(host, SAMSUNG_RR_CMD, HINFC610_CMD);
+	hinfc_write(host, opval, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(samsung_rr_params[param][1], host->chip->IO_ADDR_R);
+	hinfc_write(host, 0xA400, HINFC610_ADDRL);
+	hinfc_write(host, SAMSUNG_RR_CMD, HINFC610_CMD);
+	hinfc_write(host, opval, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(samsung_rr_params[param][2], host->chip->IO_ADDR_R);
+	hinfc_write(host, 0xA500, HINFC610_ADDRL);
+	hinfc_write(host, SAMSUNG_RR_CMD, HINFC610_CMD);
+	hinfc_write(host, opval, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(samsung_rr_params[param][3], host->chip->IO_ADDR_R);
+	hinfc_write(host, 0xA600, HINFC610_ADDRL);
+	hinfc_write(host, SAMSUNG_RR_CMD, HINFC610_CMD);
+	hinfc_write(host, opval, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	return 0;
+
+#undef SAMSUNG_RR_CMD
+}
+/*****************************************************************************/
+
+static int hinfc610_samsung_set_rr_param(struct hinfc_host *host, int param)
+{
+	return hinfc610_samsung_set_rr_reg(host, param);
+}
+/*****************************************************************************/
+
+static int hinfc610_samsung_reset_rr_param(struct hinfc_host *host)
+{
+	return hinfc610_samsung_set_rr_reg(host, 0);
+}
+/*****************************************************************************/
+
+struct read_retry_t hinfc610_samsung_read_retry = {
+	.type = NAND_RR_SAMSUNG,
+	.count = 15,
+	.set_rr_param = hinfc610_samsung_set_rr_param,
+	.get_rr_param = NULL,
+	.reset_rr_param = hinfc610_samsung_reset_rr_param,
+};
+
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_read_retry_toshiba.c b/drivers/mtd/nand/hinfc610/hinfc610_read_retry_toshiba.c
new file mode 100644
index 0000000..0a1a87e
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_read_retry_toshiba.c
@@ -0,0 +1,113 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+
+/*****************************************************************************/
+
+static int hinfc610_toshiba_24nm_set_rr_reg(struct hinfc_host *host, int param)
+{
+#define TOSHIBA_RR_CMD     0x55
+	int opval;
+	static char toshiba_rr_param[] = {0x00, 0x04, 0x7c, 0x78, 0x74, 0x08};
+
+	if (!param) {
+		host->send_cmd_reset(host, host->chipselect);
+		return 0;
+	}
+
+	if (param >= 6)
+		param = (param % 6);
+
+	/*
+	 * no need to config WAIT_READY_EN, here not config WAIT_READY_EN
+	 */
+	opval = (HINFC610_IS_SYNC(host) ? HINFC610_WRITE_1CMD_1ADD_DATA_SYNC
+		: HINFC610_WRITE_1CMD_1ADD_DATA);
+
+	hinfc_write(host, 1, HINFC610_DATA_NUM);
+
+	writel(toshiba_rr_param[param], host->chip->IO_ADDR_R);
+	hinfc_write(host, 0x4, HINFC610_ADDRL);
+	hinfc_write(host, TOSHIBA_RR_CMD, HINFC610_CMD);
+	hinfc_write(host, opval, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(toshiba_rr_param[param], host->chip->IO_ADDR_R);
+	hinfc_write(host, 0x5, HINFC610_ADDRL);
+	hinfc_write(host, TOSHIBA_RR_CMD, HINFC610_CMD);
+	hinfc_write(host, opval, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(toshiba_rr_param[param], host->chip->IO_ADDR_R);
+	hinfc_write(host, 0x6, HINFC610_ADDRL);
+	hinfc_write(host, TOSHIBA_RR_CMD, HINFC610_CMD);
+	hinfc_write(host, opval, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(toshiba_rr_param[param], host->chip->IO_ADDR_R);
+	hinfc_write(host, 0x7, HINFC610_ADDRL);
+	hinfc_write(host, TOSHIBA_RR_CMD, HINFC610_CMD);
+	hinfc_write(host, opval, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	return 0;
+
+#undef TOSHIBA_RR_CMD
+}
+/*****************************************************************************/
+
+static int hinfc610_toshiba_24nm_set_rr_param(struct hinfc_host *host,
+		int param)
+{
+	int opval;
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	opval = (HINFC610_IS_SYNC(host) ? HINFC610_WRITE_2CMD_0ADD_NODATA_SYNC
+		: HINFC610_WRITE_2CMD_0ADD_NODATA);
+
+	hinfc_write(host, HINFC_CMD_SEQ(0x5C, 0xC5), HINFC610_CMD);
+	hinfc_write(host, opval, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	hinfc610_toshiba_24nm_set_rr_reg(host, param);
+
+	hinfc_write(host, HINFC_CMD_SEQ(0x26, 0x5D), HINFC610_CMD);
+	hinfc_write(host, opval, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_toshiba_24nm_reset_rr_param(struct hinfc_host *host)
+{
+	return hinfc610_toshiba_24nm_set_rr_reg(host, 0);
+}
+/*****************************************************************************/
+struct read_retry_t hinfc610_toshiba_24nm_read_retry = {
+	.type = NAND_RR_TOSHIBA_24nm,
+	.count = 6,
+	.set_rr_param = hinfc610_toshiba_24nm_set_rr_param,
+	.get_rr_param = NULL,
+	.reset_rr_param = hinfc610_toshiba_24nm_reset_rr_param,
+};
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_sync.c b/drivers/mtd/nand/hinfc610/hinfc610_sync.c
new file mode 100644
index 0000000..c389d98
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_sync.c
@@ -0,0 +1,187 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "hinfc610_os.h"
+#include "hinfc610_gen.h"
+#include "hinfc610.h"
+#include "hinfc610_sync.h"
+
+static struct nand_sync *nand_sync_table[] = {
+	&hinfc610_sync_onfi_23,
+	&hinfc610_sync_onfi_30,
+	&hinfc610_sync_toggle_10,
+	NULL,
+};
+
+static struct nand_sync *hinfc610_find_sync_type(int type)
+{
+	struct nand_sync **sync;
+
+	for (sync = nand_sync_table; sync; sync++) {
+		if ((*sync)->type == type)
+			return *sync;
+	}
+
+	return NULL;
+}
+/*****************************************************************************/
+
+static int hinfc610_onfi_support_sync(struct hinfc_host *host)
+{
+	char buf[6] = {0};
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, sizeof(buf), HINFC610_DATA_NUM);
+	hinfc_write(host, NAND_CMD_READID, HINFC610_CMD);
+	hinfc_write(host, 0x20, HINFC610_ADDRL);
+	hinfc_write(host, HINFC610_READ_1CMD_1ADD_DATA, HINFC610_OP);
+
+	WAIT_CONTROLLER_FINISH();
+	memcpy(buf, host->chip->IO_ADDR_R, sizeof(buf));
+
+	if (memcmp(buf, "ONFI", 4))
+		return 0;
+
+	hinfc_write(host, sizeof(buf), HINFC610_DATA_NUM);
+	hinfc_write(host, NAND_CMD_READID, HINFC610_CMD);
+	hinfc_write(host, 0x40, HINFC610_ADDRL);
+	hinfc_write(host, HINFC610_READ_1CMD_1ADD_DATA, HINFC610_OP);
+
+	WAIT_CONTROLLER_FINISH();
+	memcpy(buf, host->chip->IO_ADDR_R, sizeof(buf));
+
+	if (memcmp(buf, "JEDEC", 5))
+		return 0;
+
+	return (buf[5] == 0x05);
+}
+/*****************************************************************************/
+
+static int hinfc610_get_onfi_info(struct hinfc_host *host, int *type)
+{
+	char buf[6] = {0};
+
+	*type = 0;
+
+	if (!hinfc610_onfi_support_sync(host))
+		return 0;
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, sizeof(buf), HINFC610_DATA_NUM);
+	hinfc_write(host, NAND_CMD_PARAM, HINFC610_CMD);
+	hinfc_write(host, 0x00, HINFC610_ADDRL);
+	hinfc_write(host, HINFC610_READ_1CMD_1ADD_DATA, HINFC610_OP);
+
+	WAIT_CONTROLLER_FINISH();
+	memcpy(buf, host->chip->IO_ADDR_R, sizeof(buf));
+
+	if (memcmp(buf, "ONFI", 4))
+		return 0;
+
+	if (buf[4] & (1 << 6))
+		*type = NAND_TYPE_ONFI_30;
+	else if (buf[4] & (1 << 5) ||
+		 buf[4] & (1 << 4) ||
+		 buf[4] & (1 << 3) ||
+		 buf[4] & (1 << 2))
+		*type = NAND_TYPE_ONFI_23;
+
+	return 1;
+}
+/*****************************************************************************/
+
+static int hinfc610_toggle_support_sync(struct hinfc_host *host)
+{
+	char buf[6] = {0};
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, sizeof(buf), HINFC610_DATA_NUM);
+	hinfc_write(host, NAND_CMD_READID, HINFC610_CMD);
+	hinfc_write(host, 0x40, HINFC610_ADDRL);
+	hinfc_write(host, HINFC610_READ_1CMD_1ADD_DATA, HINFC610_OP);
+
+	WAIT_CONTROLLER_FINISH();
+
+	memcpy(buf, host->chip->IO_ADDR_R, sizeof(buf));
+
+	if (memcmp(buf, "JEDEC", 5))
+		return 0;
+
+	return 1;
+}
+/*****************************************************************************/
+
+static int hinfc610_get_toggle_info(struct hinfc_host *host, int *type)
+{
+	char buf[8] = {0};
+
+	*type = 0;
+
+	if (!hinfc610_toggle_support_sync(host))
+		return 0;
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, sizeof(buf), HINFC610_DATA_NUM);
+	hinfc_write(host, NAND_CMD_PARAM, HINFC610_CMD);
+	hinfc_write(host, 0x40, HINFC610_ADDRL);
+	hinfc_write(host, HINFC610_READ_1CMD_1ADD_DATA, HINFC610_OP);
+
+	WAIT_CONTROLLER_FINISH();
+
+	memcpy(buf, host->chip->IO_ADDR_R, sizeof(buf));
+
+	if (memcmp(buf, "JESD", 4))
+		return 0;
+
+	if (buf[4] & (1 << 1))
+		/* supports revision 1.0 */
+		*type = NAND_TYPE_TOGGLE_10;
+	else
+		pr_warn("sync NAND has unknown toggle revision.\n");
+
+	return 1;
+}
+/*****************************************************************************/
+
+int hinfc610_get_sync_info(struct hinfc_host *host)
+{
+	int type = 0;
+
+	if (IS_NAND_ONFI(host))
+		hinfc610_get_onfi_info(host, &type);
+	else
+		hinfc610_get_toggle_info(host, &type);
+
+	if (!type) {
+		host->flags &= ~NAND_MODE_SYNC_ASYNC;
+		return 0;
+	}
+
+	host->sync = hinfc610_find_sync_type(type);
+	if (!host->sync)
+		PR_BUG(ERSTR_DRIVER
+			"This Nand Flash need to enable the 'synchronous' feature. "
+			"but the driver dose not offer the feature");
+
+	return 0;
+}
+/*****************************************************************************/
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_sync.h b/drivers/mtd/nand/hinfc610/hinfc610_sync.h
new file mode 100644
index 0000000..906fd10
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_sync.h
@@ -0,0 +1,25 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef HINFC610_SYNC_H
+#define HINFC610_SYNC_H
+
+int hinfc610_get_sync_info(struct hinfc_host *host);
+
+#endif /* HINFC610_SYNC_H */
+
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_sync_onfi_23.c b/drivers/mtd/nand/hinfc610/hinfc610_sync_onfi_23.c
new file mode 100644
index 0000000..8fba306
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_sync_onfi_23.c
@@ -0,0 +1,107 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/io.h>
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+
+/*****************************************************************************/
+
+static int hinfc610_onfi_enable_sync(struct nand_chip *chip)
+{
+	struct hinfc_host *host = chip->priv;
+	unsigned char micron_sync_param[4] = {
+		0x14, /* set sync mode timing */ 0x00, 0x00, 0x00,
+	};
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, 1, HINFC610_DATA_NUM);
+	hinfc_write(host, 0xEF, HINFC610_CMD);
+	hinfc_write(host, 0x01, HINFC610_ADDRL);
+	writel(micron_sync_param[0], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_1CMD_1ADD_DATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(micron_sync_param[1], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(micron_sync_param[2], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	/* need to config WAIT_READY_EN, here config this bit. */
+	writel(micron_sync_param[3], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA_WAIT_READY,
+			HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	return 0;
+}
+
+/*****************************************************************************/
+
+static int hinfc610_onfi_disable_sync(struct nand_chip *chip)
+{
+	struct hinfc_host *host = chip->priv;
+	unsigned char micron_sync_param[4] = {
+		0x00, 0x00, 0x00, 0x00,
+	};
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, 1, HINFC610_DATA_NUM);
+	hinfc_write(host, 0xEF, HINFC610_CMD);
+	hinfc_write(host, 0x01, HINFC610_ADDRL);
+	writel(micron_sync_param[0], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_1CMD_1ADD_DATA_SYNC, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(micron_sync_param[1], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA_SYNC, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(micron_sync_param[2], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA_SYNC, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(micron_sync_param[3], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA_SYNC_WAIT_READY,
+			HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	return 0;
+}
+/*****************************************************************************/
+
+struct nand_sync hinfc610_sync_onfi_23 = {
+	.type    = NAND_TYPE_ONFI_23,
+	.enable  = hinfc610_onfi_enable_sync,
+	.disable = hinfc610_onfi_disable_sync,
+};
+
+struct nand_sync hinfc610_sync_onfi_30 = {
+	.type    = NAND_TYPE_ONFI_30,
+	.enable  = hinfc610_onfi_enable_sync,
+	.disable = hinfc610_onfi_disable_sync,
+};
diff --git a/drivers/mtd/nand/hinfc610/hinfc610_sync_toggle.c b/drivers/mtd/nand/hinfc610/hinfc610_sync_toggle.c
new file mode 100644
index 0000000..918b210
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc610_sync_toggle.c
@@ -0,0 +1,101 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/io.h>
+#include "hinfc610_os.h"
+#include "hinfc610.h"
+
+/*****************************************************************************/
+
+static int hinfc610_toggle_enable_sync(struct nand_chip *chip)
+{
+	struct hinfc_host *host = chip->priv;
+	unsigned char toshiba_sync_param[4] = {
+		0x00, 0x00, 0x00, 0x00,
+	};
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, 1, HINFC610_DATA_NUM);
+	hinfc_write(host, 0xEF, HINFC610_CMD);
+	hinfc_write(host, 0x80, HINFC610_ADDRL);
+	writel(toshiba_sync_param[0], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_1CMD_1ADD_DATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(toshiba_sync_param[1], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(toshiba_sync_param[2], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	/* need to config WAIT_READY_EN. */
+	writel(toshiba_sync_param[3], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA_WAIT_READY,
+			HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	return 0;
+}
+/*****************************************************************************/
+
+static int hinfc610_toggle_disable_sync(struct nand_chip *chip)
+{
+	struct hinfc_host *host = chip->priv;
+	unsigned char toshiba_sync_param[4] = {
+		0x01, 0x00, 0x00, 0x00,
+	};
+
+	host->enable_ecc_randomizer(host, DISABLE, DISABLE);
+
+	hinfc_write(host, 1, HINFC610_DATA_NUM);
+	hinfc_write(host, 0xEF, HINFC610_CMD);
+	hinfc_write(host, 0x80, HINFC610_ADDRL);
+	writel(toshiba_sync_param[0], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_1CMD_1ADD_DATA_SYNC, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(toshiba_sync_param[1], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA_SYNC, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	writel(toshiba_sync_param[2], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA_SYNC, HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	/* need to config WAIT_READY_EN */
+	writel(toshiba_sync_param[3], host->chip->IO_ADDR_R);
+	hinfc_write(host, HINFC610_WRITE_0CMD_1ADD_DATA_SYNC_WAIT_READY,
+			HINFC610_OP);
+	WAIT_CONTROLLER_FINISH();
+
+	host->enable_ecc_randomizer(host, ENABLE, ENABLE);
+
+	return 0;
+}
+/*****************************************************************************/
+
+struct nand_sync hinfc610_sync_toggle_10 = {
+	.type    = NAND_TYPE_TOGGLE_10,
+	.enable  = hinfc610_toggle_enable_sync,
+	.disable = hinfc610_toggle_disable_sync,
+};
diff --git a/drivers/mtd/nand/hinfc610/hinfc620_gen.c b/drivers/mtd/nand/hinfc610/hinfc620_gen.c
new file mode 100644
index 0000000..a1e68f8
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc620_gen.c
@@ -0,0 +1,78 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "../match_table.h"
+#include "hinfc620_gen.h"
+
+/*****************************************************************************/
+
+static struct match_reg_type page_type2reg[] = {
+	{
+		hinfc620_pagesize_2K, NAND_PAGE_2K,
+	}, {
+		hinfc620_pagesize_4K, NAND_PAGE_4K,
+	}, {
+		hinfc620_pagesize_8K, NAND_PAGE_8K,
+	}, {
+		hinfc620_pagesize_16K, NAND_PAGE_16K,
+	}, {
+		hinfc620_pagesize_32K, NAND_PAGE_32K,
+	}
+};
+
+enum hinfc620_page_reg hinfc620_page_type2reg(int type)
+{
+	return type2reg(page_type2reg, ARRAY_SIZE(page_type2reg), type, 0);
+}
+
+int hinfc620_page_reg2type(enum hinfc620_page_reg reg)
+{
+	return reg2type(page_type2reg, ARRAY_SIZE(page_type2reg), reg, 0);
+}
+/*****************************************************************************/
+
+static struct match_reg_type ecc_type2reg[] = {
+	{
+		hinfc620_ecc_none, NAND_ECC_NONE,
+	}, {
+		hinfc620_ecc_8bit, NAND_ECC_4BIT_512,
+	}, {
+		hinfc620_ecc_16bit, NAND_ECC_8BIT_512,
+	}, {
+		hinfc620_ecc_24bit, NAND_ECC_24BIT,
+	}, {
+		hinfc620_ecc_40bit, NAND_ECC_40BIT,
+	}, {
+		hinfc620_ecc_64bit, NAND_ECC_64BIT,
+	}, {
+		hinfc620_ecc_28bit, NAND_ECC_28BIT,
+	}, {
+		hinfc620_ecc_42bit, NAND_ECC_42BIT,
+	}
+};
+
+enum hinfc620_ecc_reg hinfc620_ecc_type2reg(int type)
+{
+	return type2reg(ecc_type2reg, ARRAY_SIZE(ecc_type2reg), type, 0);
+}
+
+int hinfc620_ecc_reg2type(enum hinfc620_ecc_reg reg)
+{
+	return reg2type(ecc_type2reg, ARRAY_SIZE(ecc_type2reg), reg, 0);
+}
+
diff --git a/drivers/mtd/nand/hinfc610/hinfc620_gen.h b/drivers/mtd/nand/hinfc610/hinfc620_gen.h
new file mode 100644
index 0000000..88fb1e4
--- /dev/null
+++ b/drivers/mtd/nand/hinfc610/hinfc620_gen.h
@@ -0,0 +1,53 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef HINFC620_GENH
+#define HINFC620_GENH
+/******************************************************************************/
+
+#include "../hinfc_gen.h"
+
+enum hinfc620_ecc_reg {
+	hinfc620_ecc_none   = 0x00,
+	hinfc620_ecc_8bit   = 0x02,
+	hinfc620_ecc_16bit  = 0x03,
+	hinfc620_ecc_24bit  = 0x04,
+	hinfc620_ecc_40bit  = 0x05,
+	hinfc620_ecc_64bit  = 0x06,
+	hinfc620_ecc_28bit  = 0x07,
+	hinfc620_ecc_42bit  = 0x08,
+};
+
+enum hinfc620_page_reg {
+	hinfc620_pagesize_2K    = 0x01,
+	hinfc620_pagesize_4K    = 0x02,
+	hinfc620_pagesize_8K    = 0x03,
+	hinfc620_pagesize_16K   = 0x04,
+	hinfc620_pagesize_32K   = 0x05,
+};
+
+enum hinfc620_page_reg hinfc620_page_type2reg(int type);
+
+int hinfc620_page_reg2type(enum hinfc620_page_reg reg);
+
+enum hinfc620_ecc_reg hinfc620_ecc_type2reg(int type);
+
+int hinfc620_ecc_reg2type(enum hinfc620_ecc_reg reg);
+
+/******************************************************************************/
+#endif /* HINFC620_GENH */
diff --git a/drivers/mtd/nand/hinfc_gen.c b/drivers/mtd/nand/hinfc_gen.c
new file mode 100644
index 0000000..d899ff4
--- /dev/null
+++ b/drivers/mtd/nand/hinfc_gen.c
@@ -0,0 +1,244 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+ 
+#include <linux/mfd/hisi_fmc.h>
+#include "match_table.h"
+#include "hinfc_gen.h"
+
+/*****************************************************************************/
+struct nand_flash_dev *(*get_spi_nand_flash_type_hook)(struct mtd_info *mtd,
+		unsigned char *id) = NULL;
+
+/*****************************************************************************/
+static struct match_t match_ecc[] = {
+	MATCH_SET_TYPE_DATA(NAND_ECC_NONE, "none"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_0BIT, "none"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_1BIT_512, "1bit/512"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_4BIT, "4bit/512"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_4BIT_512, "4bit/512"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_4BYTE, "4byte/1k"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_8BIT, "4bit/512"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_8BIT_512, "8bit/512"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_8BYTE, "8byte/1k"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_13BIT, "13bit/1k"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_16BIT, "8bit/512"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_18BIT, "18bit/1k"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_24BIT, "24bit/1k"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_27BIT, "27bit/1k"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_32BIT, "32bit/1k"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_40BIT, "40bit/1k"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_41BIT, "41bit/1k"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_48BIT, "48bit/1k"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_60BIT, "60bit/1k"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_72BIT, "72bit/1k"),
+	MATCH_SET_TYPE_DATA(NAND_ECC_80BIT, "80bit/1k"),
+};
+
+const char *nand_ecc_name(int type)
+{
+	return (char *)match_type_to_data(match_ecc, ARRAY_SIZE(match_ecc),
+		type, "unknown");
+}
+
+char *get_ecctype_str(enum ecc_type ecctype)
+{
+	static char *ecctype_string[] = {
+		"None", "1bit/512Byte", "4bits/512Byte", "8bits/512Byte",
+		"24bits/1K", "40bits/1K", "unknown", "unknown"};
+	return ecctype_string[(ecctype & 0x07)];
+}
+
+/*****************************************************************************/
+static struct match_type_str page2name[] = {
+	{ NAND_PAGE_512B, "512" },
+	{ NAND_PAGE_2K,   "2K" },
+	{ NAND_PAGE_4K,   "4K" },
+	{ NAND_PAGE_8K,   "8K" },
+	{ NAND_PAGE_16K,  "16K" },
+	{ NAND_PAGE_32K,  "32K" },
+};
+
+const char *nand_page_name(int type)
+{
+	return type2str(page2name, ARRAY_SIZE(page2name), type, "unknown");
+}
+
+char *get_pagesize_str(enum page_type pagetype)
+{
+	static char *pagesize_str[] = {
+		"512", "2K", "4K", "8K", "16K", "unknown",
+		"unknown", "unknown"};
+	return pagesize_str[(pagetype & 0x07)];
+}
+
+/*****************************************************************************/
+static struct match_reg_type page2size[] = {
+	{ _512B, NAND_PAGE_512B },
+	{ _2K, NAND_PAGE_2K },
+	{ _4K, NAND_PAGE_4K },
+	{ _8K, NAND_PAGE_8K },
+	{ _16K, NAND_PAGE_16K },
+	{ _32K, NAND_PAGE_32K },
+};
+
+unsigned int get_pagesize(enum page_type pagetype)
+{
+	unsigned int pagesize[] = {
+		_512B, _2K, _4K, _8K, _16K, 0, 0, 0};
+	return pagesize[(pagetype & 0x07)];
+}
+
+int nandpage_size2type(int size)
+{
+	return reg2type(page2size, ARRAY_SIZE(page2size), size, NAND_PAGE_2K);
+}
+
+int nandpage_type2size(int size)
+{
+	return type2reg(page2size, ARRAY_SIZE(page2size), size, NAND_PAGE_2K);
+}
+
+char *nand_dbgfs_options;
+
+static int __init dbgfs_options_setup(char *s)
+{
+	nand_dbgfs_options = s;
+	return 1;
+}
+__setup("nanddbgfs=", dbgfs_options_setup);
+
+/*****************************************************************************/
+
+int get_bits(unsigned int n)
+{
+	int loop;
+	int ret = 0;
+
+	if (!n)
+		return 0;
+
+	if (n > 0xFFFF)
+		loop = n > 0xFFFFFF ? 32 : 24;
+	else
+		loop = n > 0xFF ? 16 : 8;
+
+	while (loop-- > 0 && n) {
+		if (n & 1)
+			ret++;
+		n >>= 1;
+	}
+	return ret;
+}
+
+/*****************************************************************************/
+#define et_ecc_none	0x00
+#define et_ecc_4bit	0x02
+#define et_ecc_8bit	0x03
+#define et_ecc_24bit1k	0x04
+#define et_ecc_40bit1k	0x05
+#define et_ecc_64bit1k	0x06
+
+static struct match_reg_type ecc_yaffs_type_t[] = {
+	{et_ecc_none,		NAND_ECC_0BIT},
+	{et_ecc_4bit,		NAND_ECC_8BIT},
+	{et_ecc_8bit,		NAND_ECC_16BIT},
+	{et_ecc_24bit1k,	NAND_ECC_24BIT},
+	{et_ecc_40bit1k,	NAND_ECC_40BIT},
+	{et_ecc_64bit1k,	NAND_ECC_64BIT}
+};
+
+unsigned char match_ecc_type_to_yaffs(unsigned char type)
+{
+	return type2reg(ecc_yaffs_type_t, ARRAY_SIZE(ecc_yaffs_type_t), type,
+			et_ecc_4bit);
+}
+
+/*****************************************************************************/
+static struct match_t page_table[] = {
+	{NAND_PAGE_2K,	PAGE_SIZE_2KB,	"2K"},
+	{NAND_PAGE_4K,	PAGE_SIZE_4KB,	"4K"},
+	{NAND_PAGE_8K,	PAGE_SIZE_8KB,	"8K"},
+	{NAND_PAGE_16K,	PAGE_SIZE_16KB,	"16K"},
+};
+
+unsigned char match_page_reg_to_type(unsigned char reg)
+{
+	return match_reg_to_type(page_table, ARRAY_SIZE(page_table), reg,
+			NAND_PAGE_2K);
+}
+
+unsigned char match_page_type_to_reg(unsigned char type)
+{
+	return match_type_to_reg(page_table, ARRAY_SIZE(page_table), type,
+			PAGE_SIZE_2KB);
+}
+
+const char *match_page_type_to_str(unsigned char type)
+{
+	return match_type_to_data(page_table, ARRAY_SIZE(page_table), type,
+			"unknown");
+}
+
+/*****************************************************************************/
+static struct match_t ecc_table[] = {
+	{NAND_ECC_0BIT,		ECC_TYPE_0BIT,	"none"},
+	{NAND_ECC_8BIT,		ECC_TYPE_8BIT,	"4bit/512"},
+	{NAND_ECC_16BIT,	ECC_TYPE_16BIT,	"8bit/512"},
+	{NAND_ECC_24BIT,	ECC_TYPE_24BIT,	"24bit/1K"},
+	{NAND_ECC_28BIT,	ECC_TYPE_28BIT,	"28bit/1K"},
+	{NAND_ECC_40BIT,	ECC_TYPE_40BIT,	"40bit/1K"},
+	{NAND_ECC_64BIT,	ECC_TYPE_64BIT,	"64bit/1K"},
+};
+
+unsigned char match_ecc_reg_to_type(unsigned char reg)
+{
+	return match_reg_to_type(ecc_table, ARRAY_SIZE(ecc_table), reg,
+			NAND_ECC_8BIT);
+}
+
+unsigned char match_ecc_type_to_reg(unsigned char type)
+{
+	return match_type_to_reg(ecc_table, ARRAY_SIZE(ecc_table), type,
+			ECC_TYPE_8BIT);
+}
+
+const char *match_ecc_type_to_str(unsigned char type)
+{
+	return match_type_to_data(ecc_table, ARRAY_SIZE(ecc_table), type,
+			"unknown");
+}
+
+/*****************************************************************************/
+static struct match_t page_type_size_table[] = {
+	{NAND_PAGE_2K,	_2K,	NULL},
+	{NAND_PAGE_4K,	_4K,	NULL},
+	{NAND_PAGE_8K,	_8K,	NULL},
+	{NAND_PAGE_16K,	_16K,	NULL},
+};
+
+unsigned char match_page_size_to_type(unsigned int size)
+{
+	return match_reg_to_type(page_type_size_table,
+			ARRAY_SIZE(page_type_size_table), size, NAND_PAGE_2K);
+}
+
+unsigned int match_page_type_to_size(unsigned char type)
+{
+	return match_type_to_reg(page_type_size_table,
+			ARRAY_SIZE(page_type_size_table), type, _2K);
+}
diff --git a/drivers/mtd/nand/hinfc_gen.h b/drivers/mtd/nand/hinfc_gen.h
new file mode 100644
index 0000000..3d08c70
--- /dev/null
+++ b/drivers/mtd/nand/hinfc_gen.h
@@ -0,0 +1,294 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef __HINFC_GEN_H__
+#define __HINFC_GEN_H__
+
+/*****************************************************************************/
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/nand.h>
+#include <linux/string_helpers.h>
+#include <asm/setup.h>
+#include <linux/module.h>
+
+/*****************************************************************************/
+#define HINFC_VER_300                   (0x300)
+#define HINFC_VER_301                   (0x301)
+#define HINFC_VER_310                   (0x310)
+#define HINFC_VER_504                   (0x504)
+#define HINFC_VER_505                   (0x505)
+#define HINFC_VER_600                   (0x600)
+#define HINFC_VER_610                   (0x610)
+#define HINFC_VER_620                   (0x620)
+
+#define HISNFC_VER_100                  (0x400)
+
+/*****************************************************************************/
+#define NAND_PAGE_512B                   0
+#define NAND_PAGE_1K                     1
+#define NAND_PAGE_2K                     2
+#define NAND_PAGE_4K                     3
+#define NAND_PAGE_8K                     4
+#define NAND_PAGE_16K                    5
+#define NAND_PAGE_32K                    6
+
+/*****************************************************************************/
+#define NAND_ECC_NONE                    0
+#define NAND_ECC_0BIT                    0
+#define NAND_ECC_1BIT                    1
+#define NAND_ECC_1BIT_512                1
+#define NAND_ECC_4BIT                    2
+#define NAND_ECC_4BIT_512                2
+#define NAND_ECC_4BYTE                   2
+#define NAND_ECC_8BIT                    2
+#define NAND_ECC_8BIT_512                3
+#define NAND_ECC_8BYTE                   3
+#define NAND_ECC_13BIT                   4
+#define NAND_ECC_16BIT                   5
+#define NAND_ECC_18BIT                   6
+#define NAND_ECC_24BIT                   7
+#define NAND_ECC_27BIT                   8
+#define NAND_ECC_28BIT                   9
+#define NAND_ECC_32BIT                   10
+#define NAND_ECC_40BIT                   11
+#define NAND_ECC_41BIT                   12
+#define NAND_ECC_42BIT                   13
+#define NAND_ECC_48BIT                   14
+#define NAND_ECC_60BIT                   15
+#define NAND_ECC_64BIT                   16
+#define NAND_ECC_72BIT                   17
+#define NAND_ECC_80BIT                   18
+
+enum ecc_type {
+	et_ecc_none    = 0x00,
+	et_ecc_1bit    = 0x01,
+	et_ecc_4bit    = 0x02,
+	et_ecc_8bit    = 0x03,
+	et_ecc_24bit1k = 0x04,
+	et_ecc_40bit1k = 0x05,
+	et_ecc_64bit1k = 0x06,
+};
+
+enum page_type {
+	pt_pagesize_512   = 0x00,
+	pt_pagesize_2K    = 0x01,
+	pt_pagesize_4K    = 0x02,
+	pt_pagesize_8K    = 0x03,
+	pt_pagesize_16K   = 0x04,
+};
+
+/*****************************************************************************/
+struct nand_config_info {
+	unsigned int pagetype;
+	unsigned int ecctype;
+	unsigned int ecc_strength;
+	unsigned int oobsize;
+	struct mtd_ooblayout_ops *ooblayout_ops;
+};
+
+struct hinfc_host;
+
+struct nand_sync {
+
+#define SET_NAND_SYNC_TYPE(_mfr, _onfi, _version) \
+	((((_mfr) & 0xFF) << 16) | (((_version) & 0xFF) << 8) \
+	 | ((_onfi) & 0xFF))
+
+#define GET_NAND_SYNC_TYPE_MFR(_type) (((_type) >> 16) & 0xFF)
+#define GET_NAND_SYNC_TYPE_VER(_type) (((_type) >> 8) & 0xFF)
+#define GET_NAND_SYNC_TYPE_INF(_type) ((_type) & 0xFF)
+
+#define NAND_TYPE_ONFI_23_MICRON    \
+	SET_NAND_SYNC_TYPE(NAND_MFR_MICRON, NAND_IS_ONFI, 0x23)
+#define NAND_TYPE_ONFI_30_MICRON    \
+	SET_NAND_SYNC_TYPE(NAND_MFR_MICRON, NAND_IS_ONFI, 0x30)
+#define NAND_TYPE_TOGGLE_TOSHIBA    \
+	SET_NAND_SYNC_TYPE(NAND_MFR_TOSHIBA, 0, 0)
+#define NAND_TYPE_TOGGLE_SAMSUNG    \
+	SET_NAND_SYNC_TYPE(NAND_MFR_SAMSUNG, 0, 0)
+
+#define NAND_TYPE_TOGGLE_10         SET_NAND_SYNC_TYPE(0, 0, 0x10)
+#define NAND_TYPE_ONFI_30           SET_NAND_SYNC_TYPE(0, NAND_IS_ONFI, 0x30)
+#define NAND_TYPE_ONFI_23           SET_NAND_SYNC_TYPE(0, NAND_IS_ONFI, 0x23)
+
+	int type;
+	int (*enable)(struct nand_chip *chip);
+	int (*disable)(struct nand_chip *chip);
+};
+
+struct read_retry_t {
+	int type;
+	int count;
+	int (*set_rr_param)(struct hinfc_host *host, int param);
+	int (*get_rr_param)(struct hinfc_host *host);
+	int (*reset_rr_param)(struct hinfc_host *host);
+};
+
+struct ecc_info_t {
+	int pagesize;
+	int ecctype;
+	int threshold;
+	int section;
+	void (*dump)(struct hinfc_host *host, unsigned char ecc[],
+		     int *max_bitsflag);
+};
+
+struct nand_dev_t {
+	struct nand_flash_dev flash_dev;
+
+	char *start_type;
+	unsigned char ids[8];
+	int oobsize;
+	int ecctype;
+
+	/* (Controller) support ecc/page detect, driver don't need detect */
+#define NANDC_HW_AUTO                         0x01
+	/* (Controller) support ecc/page detect,
+	 * and current ecc/page config finish */
+#define NANDC_CONFIG_DONE                     0x02
+	/* (Controller) is sync, default is async */
+#define NANDC_IS_SYNC_BOOT                    0x04
+
+/* (NAND) need randomizer */
+#define NAND_RANDOMIZER                       0x10
+/* (NAND) is ONFI interface, combine with sync/async symble */
+#define NAND_IS_ONFI                          0x20
+/* (NAND) support async and sync, such micron onfi, toshiba toggle 1.0 */
+#define NAND_MODE_SYNC_ASYNC                  0x40
+/* (NAND) support only sync, such samsung sync. */
+#define NAND_MODE_ONLY_SYNC                   0x80
+
+#define NAND_CHIP_MICRON   (NAND_MODE_SYNC_ASYNC | NAND_IS_ONFI)
+/* This NAND is async, or sync/async, default is async mode,
+ * toggle1.0 interface */
+#define NAND_CHIP_TOSHIBA_TOGGLE_10  (NAND_MODE_SYNC_ASYNC)
+/* This NAND is only sync mode, toggle2.0 interface */
+#define NAND_CHIP_TOSHIBA_TOGGLE_20   (NAND_MODE_ONLY_SYNC)
+/* This NAND is only sync mode */
+#define NAND_CHIP_SAMSUNG  (NAND_MODE_ONLY_SYNC)
+
+	unsigned int flags;
+
+#define NAND_RR_NONE                   0x00
+#define NAND_RR_HYNIX_BG_BDIE          0x10
+#define NAND_RR_HYNIX_BG_CDIE          0x11
+#define NAND_RR_HYNIX_CG_ADIE          0x12
+#define NAND_RR_MICRON                 0x20
+#define NAND_RR_SAMSUNG                0x30
+#define NAND_RR_TOSHIBA_24nm           0x40
+#define NAND_RR_TOSHIBA_19nm           0x41
+	int read_retry_type;
+};
+
+/*****************************************************************************/
+
+#define IS_NANDC_HW_AUTO(_host)         ((_host)->flags & NANDC_HW_AUTO)
+#define IS_NANDC_CONFIG_DONE(_host)     ((_host)->flags & NANDC_CONFIG_DONE)
+#define IS_NANDC_SYNC_BOOT(_host)       ((_host)->flags & NANDC_IS_SYNC_BOOT)
+
+#define IS_NAND_RANDOM(_dev)         ((_dev)->flags & NAND_RANDOMIZER)
+#define IS_NAND_ONLY_SYNC(_dev)      ((_dev)->flags & NAND_MODE_ONLY_SYNC)
+#define IS_NAND_SYNC_ASYNC(_dev)     ((_dev)->flags & NAND_MODE_SYNC_ASYNC)
+#define IS_NAND_ONFI(_dev)           ((_dev)->flags & NAND_IS_ONFI)
+
+#define ERSTR_HARDWARE  "Hardware configuration error. "
+#define ERSTR_DRIVER    "Driver does not support. "
+
+#define ENABLE                    1
+#define DISABLE                   0
+
+/*****************************************************************************/
+
+char *get_ecctype_str(enum ecc_type ecctype);
+
+char *get_pagesize_str(enum page_type pagetype);
+
+unsigned int get_pagesize(enum page_type pagetype);
+
+const char *nand_ecc_name(int type);
+
+const char *nand_page_name(int type);
+
+int nandpage_size2type(int size);
+
+int nandpage_type2size(int size);
+
+/*****************************************************************************/
+extern int (*hinfc_param_adjust)(struct mtd_info *mtd, struct nand_chip *chip,
+	struct nand_dev_t *nand_dev);
+
+extern struct nand_flash_dev *(*nand_get_flash_type_func)(struct mtd_info *mtd,
+	struct nand_chip *chip, struct nand_dev_t *spinand_dev_t);
+
+extern struct nand_flash_dev *(*get_spi_nand_flash_type_hook)
+		(struct mtd_info *mtd, unsigned char *id);
+
+extern int (*hinfc_param_adjust)(struct mtd_info *,
+		struct nand_chip *, struct nand_dev_t *);
+
+/*****************************************************************************/
+struct nand_flash_dev *hinfc_get_flash_type(struct mtd_info *mtd,
+	struct nand_chip *chip, u8 *id_data, int *busw);
+
+extern struct nand_flash_dev *(*get_spi_nand_flash_type_hook)
+	(struct mtd_info *mtd, unsigned char *id);
+
+void hinfc_nand_param_adjust(struct mtd_info *mtd, struct nand_chip *chip);
+
+void hinfc_show_info(struct mtd_info *mtd, char *vendor, char *chipname);
+
+void hinfc_show_chipsize(struct nand_chip *chip);
+
+int get_bits(unsigned int n);
+
+/*****************************************************************************/
+#define hinfc_pr_msg(_fmt, arg...) printk(_fmt, ##arg)
+
+#define hinfc_pr_bug(fmt, args...) do { \
+	printk("%s(%d): bug " fmt, __FILE__, __LINE__, ##args); \
+	while (1) \
+		; \
+} while (0)
+
+#define PR_MSG(_fmt, arg...) \
+	    printk(_fmt, ##arg)
+
+extern char *nand_dbgfs_options;
+/*****************************************************************************/
+extern unsigned char match_page_reg_to_type(unsigned char reg);
+
+extern unsigned char match_page_type_to_reg(unsigned char type);
+
+extern const char *match_page_type_to_str(unsigned char type);
+
+/*****************************************************************************/
+extern unsigned char match_ecc_reg_to_type(unsigned char reg);
+
+extern unsigned char match_ecc_type_to_reg(unsigned char type);
+
+extern const char *match_ecc_type_to_str(unsigned char type);
+
+/*****************************************************************************/
+extern unsigned char match_page_size_to_type(unsigned int size);
+
+extern unsigned int match_page_type_to_size(unsigned char type);
+
+const char *nand_ecc_name(int type);
+/*****************************************************************************/
+
+#endif /* End of __HINFC_GEN_H__ */
diff --git a/drivers/mtd/nand/hinfc_spl_ids.c b/drivers/mtd/nand/hinfc_spl_ids.c
new file mode 100644
index 0000000..ccc15de
--- /dev/null
+++ b/drivers/mtd/nand/hinfc_spl_ids.c
@@ -0,0 +1,979 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/mtd/mtd.h>
+#include <linux/mfd/hisi_fmc.h>
+#include "hinfc_gen.h"
+
+/*****************************************************************************/
+
+struct nand_flash_special_dev {
+	unsigned char id[8];
+	int length;             /* length of id. */
+	unsigned long long chipsize;
+	struct nand_flash_dev *(*probe)(struct nand_dev_t *nand_dev);
+	char *name;
+
+	unsigned long pagesize;
+	unsigned long erasesize;
+	unsigned long oobsize;
+	unsigned long options;
+	unsigned int read_retry_type;
+
+#define BBP_LAST_PAGE                    0x01
+#define BBP_FIRST_PAGE                   0x02
+	unsigned int badblock_pos;
+	unsigned int flags;
+};
+
+/*****************************************************************************/
+/*                    this is nand probe function.                           */
+/*****************************************************************************/
+
+static struct nand_flash_dev *hynix_probe_v02(
+	struct nand_dev_t *nand_dev)
+{
+	unsigned char *id = nand_dev->ids;
+	struct nand_flash_dev *type = &nand_dev->flash_dev;
+
+	int pagesizes[]   = {SZ_2K, SZ_4K, SZ_8K, 0};
+	int oobsizes[]    = {128, 224, 448, 0, 0, 0, 0, 0};
+	int blocksizes[]  = {SZ_128K, SZ_256K, SZ_512K,
+				(SZ_256K + SZ_512K), SZ_1M, SZ_2M, 0, 0};
+
+	int blocktype = (((id[3] >> 5) & 0x04) | ((id[3] >> 4) & 0x03));
+	int oobtype   = (((id[3] >> 2) & 0x03) | ((id[3] >> 4) & 0x04));
+
+	type->options   = 0;
+	type->pagesize  = pagesizes[(id[3] & 0x03)];
+	type->erasesize = blocksizes[blocktype];
+	nand_dev->oobsize = oobsizes[oobtype];
+
+	return type;
+}
+/*****************************************************************************/
+
+static struct nand_flash_dev *samsung_probe_v02(
+	struct nand_dev_t *nand_dev)
+{
+	unsigned char *id = nand_dev->ids;
+	struct nand_flash_dev *type = &nand_dev->flash_dev;
+
+	int pagesizes[]   = {SZ_2K, SZ_4K, SZ_8K, 0};
+	int oobsizes[]    = {0, 128, 218, 400, 436, 0, 0, 0};
+	int blocksizes[]  = {SZ_128K, SZ_256K, SZ_512K, SZ_1M, 0, 0, 0, 0};
+
+	int blocktype = (((id[3] >> 5) & 0x04) | ((id[3] >> 4) & 0x03));
+	int oobtype   = (((id[3] >> 4) & 0x04) | ((id[3] >> 2) & 0x03));
+
+	type->options   = 0;
+	type->pagesize  = pagesizes[(id[3] & 0x03)];
+	type->erasesize = blocksizes[blocktype];
+	nand_dev->oobsize = oobsizes[oobtype];
+
+	return type;
+}
+/*****************************************************************************/
+
+#define DRV_VERSION     "1.38"
+
+/*****************************************************************************/
+/*
+ * samsung:  27nm need randomizer, 21nm need read retry;
+ * micron:   25nm need read retry, datasheet will explain read retry.
+ * toshaba   32nm need randomizer, 24nm need read retry.
+ * hynix:    2xnm need read retry.
+ *
+ *		The special nand flash ID table version 1.37
+ *
+ * manufactory  |  type  |       name 	     |   ecc_type  | version_tag
+ * Micron		|  MLC	 |  MT29F64G08CBABA  |   40bit/1k  |  1.36
+ * Micron		|  MLC	 |  MT29F32G08CBADA  |   40bit/1k  |
+ * Micron		|  SLC	 |  MT29F8G08ABxBA   |   4bit/512  |
+ * Micron		|  MLC	 |  MT29F16G08CBABx  |   12bit/512 |
+ * Micron		|  MLC	 |  MT29F16G08CBACA  |   24bit/1k  |
+ * Micron		|  MLC	 |  MT29F32G08CBACA  |   24bit/1k  |
+ * Micron		|  MLC	 |  MT29F64G08CxxAA  |   24bit/1k  |
+ * Micron		|  MLC	 |  MT29F256G08CJAAA |   24bit/1k  |   2CE
+ * Micron		|  MLC	 |  MT29F256G08CMCBB |   24bit/1k  |
+ * Micron		|  SLC	 |  MT29F8G08ABACA   |   8bit/512  |
+ * Micron		|  SLC	 |  MT29F4G08ABAEA   |   8bit/512  |
+ * Micron		|  SLC	 |  MT29F2G08ABAFA   |   8bit/512  |
+ * Micron		|  SLC	 |  MT29F16G08ABACA  |   8bit/512  |
+ * Toshiba		|  MLC   |  TC58NVG4D2FTA00  |   24bit/1k  |
+ * Toshiba		|  MLC   |  TH58NVG6D2FTA20  |   24bit/1k  |   2CE
+ * Toshiba		|  MLC   |  TC58NVG5D2HTA00  |   40bit/1k  |
+ * Toshiba		|  MLC   |  TC58NVG6D2GTA00  |   40bit/1k  |
+ * Toshiba		|  MLC   |  TC58NVG6DCJTA00  |			   |
+ * Toshiba		|  MLC   |  TC58TEG5DCJTA00  |			   |
+ * Toshiba		|  SLC   |  TC58NVG0S3HTA00  |   8bit/512  |
+ * Toshiba		|  SLC   |  TC58NVG1S3HTA00  |   8bit/512  |
+ * Toshiba		|  SLC   |  TC58NVG1S3ETA00  |   4bit/512  |
+ * Toshiba		|  SLC   |  TC58NVG3S0FTA00  |   4bit/512  |
+ * Toshiba		|  SLC   |  TC58NVG2S0FTA00  |   4bit/512  |
+ * Toshiba		|  SLC   |  TH58NVG2S3HTA00  |   4bit/512  |
+ * Toshiba		|  TLC   |  TC58NVG5T2JTA00  |   60bit/1k  |
+ * Toshiba		|  TLC   |  TC58TEG5DCKTAx0  |   60bit/1k  |
+ * Toshiba		|  MLC   |  Tx58TEGxDDKTAx0  |			   |
+ * Samsung		|  MLC   |  K9LB(HC/PD/MD)G08U0(1)D  |   8bit/512B  |
+ * Samsung		|  MLC   |  K9GAG08U0E	     |   24bit/1KB |
+ * Samsung		|  MLC   |  K9LBG08U0E	     |   24bit/1KB |
+ * Samsung		|  MLC   |  K9G8G08U0C	     |   24bit/1KB |
+ * Samsung		|  MLC   |  K9GAG08U0F	     |   24bit/1KB |
+ * Samsung		|  MLC   |  K9LBG08U0M	     |             |
+ * Samsung		|  MLC   |  K9GBG08U0A	     |   24bit/1KB |
+ * Samsung		|  MLC   |  K9GBG08U0B	     |   40bit/1KB |
+ * Hynix		|  MLC   |  H27UAG8T2A	     |			   |
+ * Hynix		|  MLC   |  H27UAG8T2B	     |			   |
+ * Hynix		|  MLC   |  H27UBG8T2A	     |			   |
+ * Hynix		|  MLC   |  H27UBG8T2BTR	 |	 24bit/1KB |
+ * Hynix		|  MLC   |  H27UCG8T2A		 |	 40bit/1KB |
+ * Hynix		|  MLC   |  H27UBG8T2C		 |	 40bit/1KB |
+ * MISC			|  MLC   |  P1UAGA30AT-GCA	 |	 8bit/512  |
+ * MISC			|  MLC   |  PSU8GA30AT-GIA/ASU8GA30IT-G30CA	 |	 4bit/512  |
+ * MISC			|  SLC   |  PSU2GA30AT   	 |	 1bit/512  |   1.36
+ * Toshiba		|  SLC   |  TC58NVG2S0HTA00  |	 24bit/1K  |   1.37
+ * Toshiba		|  SLC   |  TC58NVG3S0HTA00  |   24bit/1K  |   1.37
+ * Micron		|  SLC	 |  MT29F2G08ABAEA   |   4bit/512 |
+ * Spansion		|  SLC	 | S34ML02G200TFI000	 | 24bit/1K |
+ * Spansion		|  SLC	 | S34ML04G200TFI000	 | 24bit/1K |  1.38
+ *
+ */
+
+static struct nand_flash_special_dev nand_flash_special_dev[] = {
+
+/****************************** Spansion *******************************/
+
+	{		/* SLC S34ML02G200TFI000 */
+		.name      = "S34ML02G200TFI000",
+		.id        = {0x01, 0xDA, 0x90, 0x95, 0x46, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _256M,
+		.probe     = NULL,
+		.pagesize  = SZ_2K,
+		.erasesize = SZ_128K,
+		.oobsize   = 128,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+
+	{		/* SLC S34ML04G200TFI000 */
+		.name      = "S34ML04G200TFI000",
+		.id        = {0x01, 0xDC, 0x90, 0x95, 0x56, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _512M,
+		.probe     = NULL,
+		.pagesize  = SZ_2K,
+		.erasesize = SZ_128K,
+		.oobsize   = 128,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+
+/****************************** Micron *******************************/
+	{        /* MLC 40bit/1k */
+		.name      = "MT29F64G08CBABA",
+		.id        = {0x2C, 0x64, 0x44, 0x4B, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _8G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_2M,
+		.oobsize   = 744,
+		.options   = 0,
+		.read_retry_type = NAND_RR_MICRON,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = NAND_RANDOMIZER | NAND_CHIP_MICRON,
+	},
+	{        /* MLC 40bit/1k */
+		.name      = "MT29F32G08CBADA",
+		.id        = {0x2C, 0x44, 0x44, 0x4B, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_2M,
+		.oobsize   = 744,
+		.options   = 0,
+		.read_retry_type = NAND_RR_MICRON,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{        /* SLC 4bit/512 */
+		.name      = "MT29F8G08ABxBA",
+		.id        = {0x2C, 0x38, 0x00, 0x26, 0x85, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = SZ_1G,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_512K,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 12bit/512 */
+		.name      = "MT29F16G08CBABx",
+		.id        = {0x2C, 0x48, 0x04, 0x46, 0x85, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = SZ_2G,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_1M,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 24bit/1k */
+		.name      = "MT29F16G08CBACA",
+		.id        = {0x2C, 0x48, 0x04, 0x4A, 0xA5, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = SZ_2G,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_1M,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 24bit/1k */
+		.name      = "MT29F32G08CBACA",
+		.id        = {0x2C, 0x68, 0x04, 0x4A, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_1M,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 24bit/1k */
+		.name      = "MT29F64G08CxxAA",
+		.id        = {0x2C, 0x88, 0x04, 0x4B, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _8G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_2M,
+		.oobsize   = 448,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 24bit/1k 2CE */
+		.name      = "MT29F256G08CJAAA",
+		.id        = {0x2C, 0xA8, 0x05, 0xCB, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _16G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_2M,
+		.oobsize   = 448,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 40bit/1k */
+		.name      = "MT29F256G08CMCBB",
+		.id        = {0x2C, 0x64, 0x44, 0x4B, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 8,
+		.chipsize  = _8G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_2M,
+		.oobsize   = 744,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* SLC 8bit/512 */
+		.name      = "MT29F8G08ABACA",
+		.id        = {0x2C, 0xD3, 0x90, 0xA6, 0x64, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = SZ_1G,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_256K,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* SLC 8bit/512 */
+		.name      = "MT29F4G08ABAEA",
+		.id        = {0x2C, 0xDC, 0x90, 0xA6, 0x54, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = SZ_512M,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_256K,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* SLC 8bit/512 */
+		.name      = "MT29F2G08ABAFA",
+		.id        = {0x2C, 0xDA, 0x90, 0x95, 0x04, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = SZ_256M,
+		.probe     = NULL,
+		.pagesize  = SZ_2K,
+		.erasesize = SZ_128K,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{		/* SLC MT29F2G08ABAEA */
+		.name      = "MT29F2G08ABAEA",
+		.id        = {0x2C, 0xDA, 0x90, 0x95, 0x06, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _256M,
+		.probe     = NULL,
+		.pagesize  = SZ_2K,
+		.erasesize = SZ_128K,
+		.oobsize   = 64,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{        /* SLC 8bit/512 */
+		.name      = "MT29F16G08ABACA",
+		.id        = {0x2C, 0x48, 0x00, 0x26, 0xA9, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = SZ_2G,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_512K,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+
+/****************************** Toshaba *******************************/
+
+	{       /* MLC 24bit/1k 32nm */
+		.name      = "TC58NVG4D2FTA00",
+		.id        = {0x98, 0xD5, 0x94, 0x32, 0x76, 0x55, 0x00, 0x00},
+		.length    = 6,
+		.chipsize  = SZ_2G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_1M,
+		.oobsize   = 448,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 24bit/1k 32nm 2CE*/
+		.name      = "TH58NVG6D2FTA20",
+		.id        = {0x98, 0xD7, 0x94, 0x32, 0x76, 0x55, 0x00, 0x00},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_1M,
+		.oobsize   = 448,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 40bit/1k 24nm */
+		.name      = "TC58NVG5D2HTA00 24nm",
+		.id        = {0x98, 0xD7, 0x94, 0x32, 0x76, 0x56, 0x08, 0x00},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_1M,
+		.oobsize   = 640,
+		.options   = 0,
+		.read_retry_type = NAND_RR_TOSHIBA_24nm,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{       /* MLC 40bit/1k */
+		.name      = "TC58NVG6D2GTA00",
+		.id        = {0x98, 0xDE, 0x94, 0x82, 0x76, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _8G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_2M,
+		.oobsize   = 640,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 19nm */
+		.name      = "TC58NVG6DCJTA00 19nm",
+		.id        = {0x98, 0xDE, 0x84, 0x93, 0x72, 0x57, 0x08, 0x04},
+		.length    = 8,
+		.chipsize  = _8G,
+		.probe     = NULL,
+		.pagesize  = SZ_16K,
+		.erasesize = SZ_4M,
+		.oobsize   = 1280,
+		.options   = 0,
+		.read_retry_type = NAND_RR_TOSHIBA_24nm,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{       /* MLC 19nm */
+		.name      = "TC58TEG5DCJTA00 19nm",
+		.id        = {0x98, 0xD7, 0x84, 0x93, 0x72, 0x57, 0x08, 0x04},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = SZ_16K,
+		.erasesize = SZ_4M,
+		.oobsize   = 1280,
+		.options   = 0,
+		.read_retry_type = NAND_RR_TOSHIBA_24nm,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER | NAND_CHIP_TOSHIBA_TOGGLE_10,
+	},
+	{       /* SLC 8bit/512 */
+		.name      = "TC58NVG0S3HTA00",
+		.id        = {0x98, 0xF1, 0x80, 0x15, 0x72, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = SZ_128M,
+		.probe     = NULL,
+		.pagesize  = SZ_2K,
+		.erasesize = SZ_128K,
+		.oobsize   = 128,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		/*
+		 * Datasheet: read one column of any page in each block. If the
+		 * data of the column is 00 (Hex), define the block as a bad
+		 * block.
+		 */
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 8bit/512 */
+		.name      = "TC58NVG1S3HTA00",
+		.id        = {0x98, 0xDA, 0x90, 0x15, 0x76, 0x16, 0x08, 0x00},
+		.length    = 7,
+		.chipsize  = SZ_256M,
+		.probe     = NULL,
+		.pagesize  = SZ_2K,
+		.erasesize = SZ_128K,
+		.oobsize   = 128,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 4bit/512 */
+		.name      = "TC58NVG1S3ETA00",
+		.id        = {0x98, 0xDA, 0x90, 0x15, 0x76, 0x14, 0x03, 0x00},
+		.length    = 7,
+		.chipsize  = SZ_256M,
+		.probe     = NULL,
+		.pagesize  = SZ_2K,
+		.erasesize = SZ_128K,
+		.oobsize   = 64,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 4bit/512 */
+		.name      = "TC58NVG3S0FTA00",
+		.id        = {0x98, 0xD3, 0x90, 0x26, 0x76, 0x15, 0x02, 0x08},
+		.length    = 8,
+		.chipsize  = SZ_1G,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_256K,
+		.oobsize   = 232,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 4bit/512 */
+		.name      = "TC58NVG3S0HTA00",
+		.id        = {0x98, 0xD3, 0x91, 0x26, 0x76, 0x16, 0x08, 0x00},
+		.length    = 8,
+		.chipsize  = SZ_1G,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_256K,
+		.oobsize   = 256,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 24bit/1k */
+		.name      = "TC58NVG2S0HTA00",
+		.id        = {0x98, 0xDC, 0x90, 0x26, 0x76, 0x16, 0x08, 0x00},
+		.length    = 8,
+		.chipsize  = SZ_512M,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_256K,
+		.oobsize   = 256,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 4bit/512 */
+		.name      = "TC58NVG2S0FTA00",
+		.id        = {0x98, 0xDC, 0x90, 0x26, 0x76, 0x15, 0x01, 0x08},
+		.length    = 8,
+		.chipsize  = SZ_512M,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_256K,
+		.oobsize   = 224,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* SLC 4bit/512 */
+		.name      = "TH58NVG2S3HTA00",
+		.id        = {0x98, 0xDC, 0x91, 0x15, 0x76},
+		.length    = 5,
+		.chipsize  = SZ_512M,
+		.probe     = NULL,
+		.pagesize  = SZ_2K,
+		.erasesize = SZ_128K,
+		.oobsize   = 128,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.flags = 0,
+	},
+	{       /* TLC 60bit/1k 19nm */
+		.name      = "TC58NVG5T2JTA00 19nm TLC",
+		.id        = {0x98, 0xD7, 0x98, 0x92, 0x72, 0x57, 0x08, 0x10},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_4M,
+		.oobsize   = 1024,
+		.options   = 0,
+		.read_retry_type = NAND_RR_TOSHIBA_24nm,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{	/* TLC 60bit/1k 19nm */
+		.name	   = "TC58TEG5DCKTAx0 19nm MLC",
+		/* datasheet says 6 ids id data, but really has 8 ids. */
+		.id	   = {0x98, 0xD7, 0x84, 0x93, 0x72, 0x50, 0x08, 0x04},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe	   = NULL,
+		.pagesize  = SZ_16K,
+		.erasesize = SZ_4M,
+		.oobsize   = 1280,
+		.options   = 0,
+		.read_retry_type = NAND_RR_TOSHIBA_19nm,
+		.badblock_pos	 = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{
+		.name	   = "Tx58TEGxDDKTAx0 19nm MLC",
+		.id	   = {0x98, 0xDE, 0x94, 0x93, 0x76, 0x50},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe	   = NULL,
+		.pagesize  = SZ_16K,
+		.erasesize = SZ_4M,
+		.oobsize   = 1280,
+		.options   = 0,
+		.read_retry_type = NAND_RR_TOSHIBA_19nm,
+		.badblock_pos	 = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+/******************************* Samsung ******************************/
+	{       /* MLC 8bit/512B */
+		.name     = "K9LB(HC/PD/MD)G08U0(1)D",
+		.id       = {0xEC, 0xD7, 0xD5, 0x29, 0x38, 0x41, 0x00, 0x00},
+		.length   = 6,
+		.chipsize = _4G,
+		.probe    = samsung_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 24bit/1KB */
+		.name      = "K9GAG08U0E",
+		.id        = {0xEC, 0xD5, 0x84, 0x72, 0x50, 0x42, 0x00, 0x00},
+		.length    = 6,
+		.chipsize  = SZ_2G,
+		.probe     = samsung_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 24bit/1KB */
+		.name     = "K9LBG08U0E",
+		.id       = {0xEC, 0xD7, 0xC5, 0x72, 0x54, 0x42, 0x00, 0x00},
+		.length   = 6,
+		.chipsize = _4G,
+		.probe    = samsung_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 24bit/1KB */
+		.name     = "K9G8G08U0C",
+		.id       = {0xEC, 0xD3, 0x84, 0x72, 0x50, 0x42, 0x00, 0x00},
+		.length   = 6,
+		.chipsize = SZ_1G,
+		.probe    = samsung_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 24bit/1k */
+		.name      = "K9GAG08U0F",
+		.id        = {0xEC, 0xD5, 0x94, 0x76, 0x54, 0x43, 0x00, 0x00},
+		.length    = 6,
+		.chipsize  = SZ_2G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_1M,
+		.oobsize   = 512,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC */
+		.name      = "K9LBG08U0M",
+		.id        = {0xEC, 0xD7, 0x55, 0xB6, 0x78, 0x00, 0x00, 0x00},
+		.length    = 5,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_512K,
+		.oobsize   = 128,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{        /* MLC 24bit/1k */
+		.name      = "K9GBG08U0A 20nm",
+		.id        = {0xEC, 0xD7, 0x94, 0x7A, 0x54, 0x43, 0x00, 0x00},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_1M,
+		.oobsize   = 640,
+		.options   = 0,
+		.read_retry_type = NAND_RR_SAMSUNG,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{        /* MLC 40bit/1k */
+		.name      = "K9GBG08U0B",
+		.id        = {0xEC, 0xD7, 0x94, 0x7E, 0x64, 0x44, 0x00, 0x00},
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_1M,
+		.oobsize   = 1024,
+		.options   = 0,
+		.read_retry_type = NAND_RR_SAMSUNG,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+
+/*********************************** Hynix ****************************/
+	{       /* MLC */
+		.name     = "H27UAG8T2A",
+		.id       = {0xAD, 0xD5, 0x94, 0x25, 0x44, 0x41, },
+		.length   = 6,
+		.chipsize = SZ_2G,
+		.probe    = hynix_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC */
+		.name     = "H27UAG8T2B",
+		.id       = {0xAD, 0xD5, 0x94, 0x9A, 0x74, 0x42, },
+		.length   = 6,
+		.chipsize = SZ_2G,
+		.probe    = hynix_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC */
+		.name     = "H27UBG8T2A",
+		.id       = {0xAD, 0xD7, 0x94, 0x9A, 0x74, 0x42, },
+		.length   = 6,
+		.chipsize = _4G,
+		.probe    = hynix_probe_v02,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 24bit/1K, 26nm TODO: Need read retry, chip is EOS */
+		.name      = "H27UBG8T2BTR 26nm",
+		.id        = {0xAD, 0xD7, 0x94, 0xDA, 0x74, 0xC3, },
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_2M,
+		.oobsize   = 640,
+		.options   = 0,
+		.read_retry_type = NAND_RR_HYNIX_BG_BDIE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{        /* MLC 40bit/1k */
+		.name      = "H27UCG8T2A",
+		.id        = {0xAD, 0xDE, 0x94, 0xDA, 0x74, 0xC4, },
+		.length    = 6,
+		.chipsize  = _8G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_2M,
+		.oobsize   = 640,
+		.options   = 0,
+		.read_retry_type = NAND_RR_HYNIX_CG_ADIE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+	{        /* MLC 40bit/1k */
+		.name      = "H27UBG8T2C",
+		.id        = {0xAD, 0xD7, 0x94, 0x91, 0x60, 0x44, },
+		.length    = 6,
+		.chipsize  = _4G,
+		.probe     = NULL,
+		.pagesize  = SZ_8K,
+		.erasesize = SZ_2M,
+		.oobsize   = 640,
+		.options   = 0,
+		.read_retry_type = NAND_RR_HYNIX_BG_CDIE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = NAND_RANDOMIZER,
+	},
+
+/********************** MISC ******************************************/
+	{        /* MLC 8bit/512 */
+		.name      = "P1UAGA30AT-GCA",
+		.id        = {0xC8, 0xD5, 0x14, 0x29, 0x34, 0x01, },
+		.length    = 6,
+		.chipsize  = SZ_2G,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_512K,
+		.oobsize   = 218,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{       /* MLC 4bit/512 */
+		/*
+		 * PowerFlash ASU8GA30IT-G30CA ID and MIRA PSU8GA30AT-GIA ID are
+		 * the same ID
+		 */
+		.name      = "PSU8GA30AT-GIA/ASU8GA30IT-G30CA",
+		.id        = {0xC8, 0xD3, 0x90, 0x19, 0x34, 0x01, },
+		.length    = 6,
+		.chipsize  = SZ_1G,
+		.probe     = NULL,
+		.pagesize  = SZ_4K,
+		.erasesize = SZ_256K,
+		.oobsize   = 218,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{        /* SLC 1bit/512 */
+		.name      = "PSU2GA30AT",
+		.id        = {0x7F, 0x7F, 0x7F, 0x7F, 0xC8, 0xDA, 0x00, 0x15, },
+		.length    = 8,
+		.chipsize  = SZ_256M,
+		.probe     = NULL,
+		.pagesize  = SZ_2K,
+		.erasesize = SZ_128K,
+		.oobsize   = 64,
+		.options   = 0,
+		.read_retry_type = NAND_RR_NONE,
+		.badblock_pos    = BBP_FIRST_PAGE | BBP_LAST_PAGE,
+		.flags = 0,
+	},
+	{{0}, 0, 0, 0, 0, 0, 0, 0, 0},
+};
+
+#define NUM_OF_SPECIAL_DEVICE  \
+	(sizeof(nand_flash_special_dev)/sizeof(struct nand_flash_special_dev))
+
+int (*hinfc_param_adjust)(struct mtd_info *, struct nand_chip *,
+			struct nand_dev_t *) = NULL;
+
+static struct nand_dev_t __nand_dev;
+/*****************************************************************************/
+
+static struct nand_flash_dev *hinfc_nand_probe(struct mtd_info *mtd,
+					       struct nand_chip *chip,
+					       struct nand_dev_t *nand_dev)
+{
+	struct nand_flash_special_dev *spl_dev;
+	unsigned char *byte = nand_dev->ids;
+	struct nand_flash_dev *type = &nand_dev->flash_dev;
+
+	hinfc_pr_msg("Nand ID: 0x%02X 0x%02X 0x%02X 0x%02X",
+			byte[0], byte[1], byte[2], byte[3]);
+	hinfc_pr_msg(" 0x%02X 0x%02X 0x%02X 0x%02X\n",
+			byte[4], byte[5], byte[6], byte[7]);
+
+	for (spl_dev = nand_flash_special_dev; spl_dev->length; spl_dev++) {
+		if (memcmp(byte, spl_dev->id, spl_dev->length))
+			continue;
+
+		hinfc_pr_msg("The Special NAND id table Version: %s\n", DRV_VERSION);
+
+		if (spl_dev->probe) {
+			type = spl_dev->probe(nand_dev);
+		} else {
+			type->options   = spl_dev->options;
+			type->pagesize  = spl_dev->pagesize;
+			type->erasesize = spl_dev->erasesize;
+			nand_dev->oobsize = spl_dev->oobsize;
+		}
+
+		nand_dev->read_retry_type = spl_dev->read_retry_type;
+		nand_dev->flags = spl_dev->flags;
+
+		type->id[1] = byte[1];
+		type->chipsize = (unsigned long)(spl_dev->chipsize >> 20);
+		type->name = spl_dev->name;
+		return type;
+	}
+	nand_dev->read_retry_type = NAND_RR_NONE;
+
+	return NULL;
+}
+/*****************************************************************************/
+
+struct nand_flash_dev *hinfc_get_flash_type(struct mtd_info *mtd,
+					    struct nand_chip *chip,
+					    u8 *id_data, int *busw)
+{
+	struct nand_flash_dev *type;
+	struct nand_dev_t *nand_dev = &__nand_dev;
+
+	memset(nand_dev, 0, sizeof(struct nand_dev_t));
+	memcpy(nand_dev->ids, id_data, 8);
+
+	if (!hinfc_nand_probe(mtd, chip, nand_dev))
+		return NULL;
+
+	type = &nand_dev->flash_dev;
+
+	if (!mtd->name)
+		mtd->name = type->name;
+
+	chip->chipsize = (uint64_t)type->chipsize << 20;
+	mtd->erasesize = type->erasesize;
+	mtd->writesize = type->pagesize;
+	mtd->oobsize   = nand_dev->oobsize;
+	*busw = (type->options & NAND_BUSWIDTH_16);
+
+	return type;
+}
+/*****************************************************************************/
+
+void hinfc_nand_param_adjust(struct mtd_info *mtd, struct nand_chip *chip)
+{
+	struct nand_dev_t *nand_dev = &__nand_dev;
+
+	if (!nand_dev->oobsize)
+		nand_dev->oobsize = mtd->oobsize;
+
+	if (hinfc_param_adjust)
+		hinfc_param_adjust(mtd, chip, nand_dev);
+}
+/*****************************************************************************/
+
+void hinfc_show_info(struct mtd_info *mtd, char *vendor, char *chipname)
+{
+	/* char buf[20]; */
+	struct nand_dev_t *nand_dev = &__nand_dev;
+
+	/* hinfc_pr_msg("Nand: %s %s ", vendor, chipname); */
+
+	if (IS_NAND_RANDOM(nand_dev))
+		hinfc_pr_msg("Randomizer \n");
+
+	if (nand_dev->read_retry_type != NAND_RR_NONE)
+		hinfc_pr_msg("Read-Retry \n");
+
+	if (nand_dev->start_type)
+		hinfc_pr_msg("Nand(%s): ", nand_dev->start_type);
+	else
+		hinfc_pr_msg("Nand: ");
+
+	hinfc_pr_msg("OOB:%dB ", nand_dev->oobsize);
+	hinfc_pr_msg("ECC:%s ", nand_ecc_name(nand_dev->ecctype));
+}
+/*****************************************************************************/
+
+void hinfc_show_chipsize(struct nand_chip *chip)
+{
+	/*char buf[20];*/
+
+	/*hinfc_pr_msg("Chip:%sB*%d\n",
+		     ultohstr(chip->chipsize, buf, sizeof(buf)),
+		     chip->numchips);*/
+}
diff --git a/drivers/mtd/nand/hisnfc100/Kconfig b/drivers/mtd/nand/hisnfc100/Kconfig
new file mode 100644
index 0000000..bde6a76
--- /dev/null
+++ b/drivers/mtd/nand/hisnfc100/Kconfig
@@ -0,0 +1,55 @@
+#
+# drivers/mtd/nand/hisnfc100/Kconfig
+# add by hisilicon 2017.10.26
+#
+
+menuconfig MTD_NAND_HISNFC100
+	tristate "Hisilicon SPI Nand Controller v100 SPI Nand devices support"
+	depends on MTD_SPI_NAND_HISI_BVT && (ARCH_HI3516A)
+	select YAFFS_FS
+	select MISC_FILESYSTEMS
+	select MTD_BLOCK
+	select YAFFS_YAFFS2
+	help
+	  Hisilicon SPI Nand Controller version 100 is called HISNFC100 for
+	  short. The controller support registers and DMA transfers while
+	  reading or writing the spi nand flash.
+
+if MTD_NAND_HISNFC100
+
+config HISNFC100_MAX_CHIP
+	int "number of spi nand flash chip (1, 2)"
+	range 1 2
+	default 1
+	help
+	  spi nand controller v100 device only support 1 or 2 spi nand
+	  flash chip, your should not config other value.
+
+choice
+	prompt "Pagesize and Ecc Type Select"
+
+config HISNFC100_HARDWARE_PAGESIZE_ECC
+	bool "Hardware"
+	help
+	  the configure of page size and ecc type lie on switch
+	  on the board.
+	  so the page size and ecc type is controlled by Hardware
+	  see demo board of SOC.
+
+config HISNFC100_AUTO_PAGESIZE_ECC
+	bool "Auto"
+	help
+	  auto-sensed the page size and ecc type value. driver will
+	  try each of page size and ecc type one by one till flash
+	  can be read and wrote accurately.
+	  so the page size and ecc type is match adaptively without
+	  switch on the board
+
+config HISNFC100_PAGESIZE_AUTO_ECC_NONE
+	bool "Pagesize Auto, Ecc None"
+	help
+	  select pagesize 2K, ecc none.
+
+endchoice
+
+endif # MTD_NAND_HISNFC100
diff --git a/drivers/mtd/nand/hisnfc100/Makefile b/drivers/mtd/nand/hisnfc100/Makefile
new file mode 100644
index 0000000..4ed5f59
--- /dev/null
+++ b/drivers/mtd/nand/hisnfc100/Makefile
@@ -0,0 +1,7 @@
+#
+# drivers/mtd/nand/hisnfc100/Makefile
+#
+
+obj-$(CONFIG_MTD_NAND_HISNFC100) += hisnfc100.o hisnfc100_os.o hisnfc100_spi_ids.o
+
+
diff --git a/drivers/mtd/nand/hisnfc100/hisnfc100.c b/drivers/mtd/nand/hisnfc100/hisnfc100.c
new file mode 100644
index 0000000..e1d59d4
--- /dev/null
+++ b/drivers/mtd/nand/hisnfc100/hisnfc100.c
@@ -0,0 +1,989 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "hisnfc100_os.h"
+#include "hisnfc100_spi_ids.h"
+#include "hisnfc100.h"
+
+#ifdef CONFIG_ARCH_HI3516A
+	#include "hisnfc100_hi3516a.c"
+#endif
+
+#define DEBUG_ERASE	0
+#define DEBUG_WRITE	0
+#define DEBUG_READ	0
+
+/*****************************************************************************/
+static void hisnfc100_send_cmd_pageprog(struct hisnfc_host *host)
+{
+	unsigned char pages_per_block_shift;
+	unsigned val, block_num, block_num_h, page_num;
+	struct hisnfc_op *spi = host->spi;
+	struct nand_chip *chip = host->chip;
+#ifdef HISNFC100_SUPPORT_REG_WRITE
+	const char *op_type = "reg";
+#else
+	const char *op_type = "dma";
+#endif
+
+	if (DEBUG_WRITE)
+		pr_info("* Enter %s page program!\n", op_type);
+
+	val = spi->driver->wait_ready(spi);
+	if (val) {
+		pr_info("%s: %s page program wait ready fail! status[%#x]\n",
+			__func__, op_type, val);
+		return;
+	}
+
+	if (spi->driver->write_enable(spi)) {
+		pr_info("%s %s page program write enable failed!\n", __func__,
+			op_type);
+		return;
+	}
+
+	host->set_system_clock(spi->write, ENABLE);
+
+	val = HISNFC100_INT_CLR_ALL;
+	hisfc_write(host, HISNFC100_INT_CLR, val);
+	if (DEBUG_WRITE)
+		pr_info("  Set REG INT_CLR[0x14]%#x\n", val);
+
+	val = HISNFC100_OP_CFG_MEM_IF_TYPE(spi->write->iftype);
+	hisfc_write(host, HISNFC100_OP_CFG, val);
+	if (DEBUG_WRITE)
+		pr_info("  Set REG OP_CFG[0x28]%#x\n", val);
+
+	pages_per_block_shift = chip->phys_erase_shift - chip->page_shift;
+	block_num = host->addr_value[1] >> pages_per_block_shift;
+	block_num_h = block_num >> REG_CNT_HIGH_BLOCK_NUM_SHIFT;
+	val = HISNFC100_ADDRH_SET(block_num_h);
+	hisfc_write(host, HISNFC100_ADDRH, val);
+	if (DEBUG_WRITE)
+		pr_info("  Set REG ADDRH[0x2c]%#x\n", val);
+
+	page_num = host->addr_value[1] - (block_num << pages_per_block_shift);
+	val = ((block_num & REG_CNT_BLOCK_NUM_MASK) << REG_CNT_BLOCK_NUM_SHIFT)
+	     | ((page_num & REG_CNT_PAGE_NUM_MASK) << REG_CNT_PAGE_NUM_SHIFT);
+	hisfc_write(host, HISNFC100_ADDRL, val);
+	if (DEBUG_WRITE)
+		pr_info("  Set REG ADDRL[0x30]%#x\n", val);
+
+#ifndef HISNFC100_SUPPORT_REG_WRITE
+	val = HISNFC100_DMA_CTRL_ALL_ENABLE;
+	hisfc_write(host, HISNFC100_DMA_CTRL, val);
+	if (DEBUG_WRITE)
+		pr_info("  Set REG DMA_CTRL[0x3c]%#x\n", val);
+
+	val = host->dma_buffer;
+	hisfc_write(host, HISNFC100_DMA_SADDR_D, val);
+	if (DEBUG_WRITE)
+		pr_info("  Set REG DMA_SADDR_D[0x40]%#x\n", val);
+
+	val = host->dma_oob;
+	hisfc_write(host, HISNFC100_DMA_SADDR_OOB, val);
+	if (DEBUG_WRITE)
+		pr_info("  Set REG DMA_SADDR_OOB[%#x]%#x\n",
+			HISNFC100_DMA_SADDR_OOB, val);
+#endif
+
+	val = HISNFC100_OP_CTRL_WR_OPCODE(spi->write->cmd)
+		| HISNFC100_OP_CTRL_CS_OP(host->cmd_option.chipselect)
+#ifdef HISNFC100_SUPPORT_REG_WRITE
+		| HISNFC100_OP_CTRL_OP_TYPE(OP_TYPE_REG)
+#else
+		| HISNFC100_OP_CTRL_OP_TYPE(OP_TYPE_DMA)
+#endif
+		| HISNFC100_OP_CTRL_RW_OP(RW_OP_WRITE)
+		| HISNFC100_OP_CTRL_OP_READY;
+	hisfc_write(host, HISNFC100_OP_CTRL, val);
+	if (DEBUG_WRITE)
+		pr_info("  Set REG OP_CTRL[0x34]%#x\n", val);
+
+	HISNFC100_DMA_WAIT_INT_FINISH(host);
+
+	if (DEBUG_WRITE) {
+		val = spi->driver->wait_ready(spi);
+		if (val & STATUS_P_FAIL_MASK)
+			pr_info("hisnfc100: %s page program failed!" \
+				" status[%#x]\n", op_type, val);
+	}
+
+	if (DEBUG_WRITE)
+		pr_info("* End %s page program!\n", op_type);
+}
+
+/*****************************************************************************/
+static void hisnfc100_send_cmd_readstart(struct hisnfc_host *host)
+{
+	unsigned char pages_per_block_shift, only_oob = 0;
+	unsigned short wrap = 0;
+	unsigned val, block_num, block_num_h, page_num, addr_of = 0;
+	struct hisnfc_op *spi = host->spi;
+	struct nand_chip *chip = host->chip;
+#ifdef HISNFC100_SUPPORT_REG_READ
+	char *op_type = "reg";
+#else
+	char *op_type = "dma";
+#endif
+
+	if (DEBUG_READ)
+		pr_info("* Enter %s page read start!\n", op_type);
+
+	if ((host->addr_value[0] == host->cache_addr_value[0])
+		&& (host->addr_value[1] == host->cache_addr_value[1])) {
+		if (DEBUG_READ)
+			pr_info("* %s page read cache hit! addr1[%#x], " \
+				"addr0[%#x]\n", op_type, host->addr_value[1],
+				host->addr_value[0]);
+		return;
+	}
+
+	val = spi->driver->wait_ready(spi);
+	if (val) {
+		pr_info("%s: %s read wait ready fail! status[%#x]\n", __func__,
+			op_type, val);
+		return;
+	}
+
+	host->set_system_clock(spi->read, ENABLE);
+
+	val = HISNFC100_INT_CLR_ALL;
+	hisfc_write(host, HISNFC100_INT_CLR, val);
+	if (DEBUG_READ)
+		pr_info("  Set REG INT_CLR[0x14]%#x\n", val);
+
+	if (host->cmd_option.last_cmd == NAND_CMD_READOOB) {
+		only_oob = 1;
+		host->cmd_option.op_config =
+				HISNFC100_OP_CFG_RD_OP_SEL(RD_OP_READ_OOB);
+	} else
+		host->cmd_option.op_config =
+				HISNFC100_OP_CFG_RD_OP_SEL(RD_OP_READ_PAGE);
+
+	val = host->cmd_option.op_config
+		| HISNFC100_OP_CFG_MEM_IF_TYPE(spi->read->iftype)
+		| HISNFC100_OP_CFG_DUMMY_ADDR_NUM(spi->read->dummy);
+	hisfc_write(host, HISNFC100_OP_CFG, val);
+	if (DEBUG_READ)
+		pr_info("  Set REG OP_CFG[0x28]%#x\n", val);
+
+	pages_per_block_shift = chip->phys_erase_shift - chip->page_shift;
+	block_num = host->addr_value[1] >> pages_per_block_shift;
+	block_num_h = block_num >> REG_CNT_HIGH_BLOCK_NUM_SHIFT;
+
+	val = HISNFC100_ADDRH_SET(block_num_h);
+	hisfc_write(host, HISNFC100_ADDRH, val);
+	if (DEBUG_READ)
+		pr_info("  Set REG ADDRH[0x2c]%#x\n", val);
+
+	page_num = host->addr_value[1] - (block_num << pages_per_block_shift);
+	if (only_oob)
+		switch (host->ecctype) {
+		case NAND_ECC_8BIT:
+			addr_of = REG_CNT_ECC_8BIT_OFFSET;
+			break;
+		case NAND_ECC_16BIT:
+			addr_of = REG_CNT_ECC_16BIT_OFFSET;
+			break;
+		case NAND_ECC_24BIT:
+			addr_of = REG_CNT_ECC_24BIT_OFFSET;
+			break;
+		case NAND_ECC_0BIT:
+		default:
+			break;
+		}
+
+	val = (((block_num & REG_CNT_BLOCK_NUM_MASK) << REG_CNT_BLOCK_NUM_SHIFT)
+		| ((page_num & REG_CNT_PAGE_NUM_MASK) << REG_CNT_PAGE_NUM_SHIFT)
+		| ((wrap & REG_CNT_WRAP_MASK) << REG_CNT_WRAP_SHIFT)
+		| (addr_of & REG_CNT_ECC_OFFSET_MASK));
+	hisfc_write(host, HISNFC100_ADDRL, val);
+	if (DEBUG_READ)
+		pr_info("  Set REG ADDRL[0x30]%#x\n", val);
+
+#ifndef HISNFC100_SUPPORT_REG_READ
+	val = HISNFC100_DMA_CTRL_ALL_ENABLE;
+	hisfc_write(host, HISNFC100_DMA_CTRL, val);
+	if (DEBUG_READ)
+		pr_info("  Set REG DMA_CTRL[0x3c]%#x\n", val);
+
+	val = host->dma_buffer;
+	hisfc_write(host, HISNFC100_DMA_SADDR_D, val);
+	if (DEBUG_READ)
+		pr_info("  Set REG DMA_SADDR_D[0x40]%#x\n", val);
+
+	val = host->dma_oob;
+	hisfc_write(host, HISNFC100_DMA_SADDR_OOB, val);
+	if (DEBUG_READ)
+		pr_info("  Set REG DMA_SADDR_OOB[%#x]%#x\n",
+			HISNFC100_DMA_SADDR_OOB, val);
+#endif
+
+	val = HISNFC100_OP_CTRL_RD_OPCODE(spi->read->cmd)
+		| HISNFC100_OP_CTRL_CS_OP(host->cmd_option.chipselect)
+#ifdef HISNFC100_SUPPORT_REG_READ
+		| HISNFC100_OP_CTRL_OP_TYPE(OP_TYPE_REG)
+#else
+		| HISNFC100_OP_CTRL_OP_TYPE(OP_TYPE_DMA)
+#endif
+		| HISNFC100_OP_CTRL_RW_OP(RW_OP_READ)
+		| HISNFC100_OP_CTRL_OP_READY;
+	hisfc_write(host, HISNFC100_OP_CTRL, val);
+	if (DEBUG_READ)
+		pr_info("  Set REG OP_CTRL[0x34]%#x\n", val);
+
+	HISNFC100_DMA_WAIT_INT_FINISH(host);
+
+	host->cache_addr_value[0] = host->addr_value[0];
+	host->cache_addr_value[1] = host->addr_value[1];
+
+	if (DEBUG_READ)
+		pr_info("* End %s page read start!\n", op_type);
+}
+
+/*****************************************************************************/
+static void hisnfc100_send_cmd_erase(struct hisnfc_host *host)
+{
+	unsigned val;
+	struct hisnfc_op *spi = host->spi;
+
+	if (DEBUG_ERASE)
+		pr_info("* Enter send cmd erase!\n");
+
+	val = spi->driver->wait_ready(spi);
+	if (val) {
+		pr_info("hisnfc: erase wait ready fail! status[%#x]\n", val);
+		return;
+	}
+
+	if (spi->driver->write_enable(spi)) {
+		pr_info("%s erase write enable failed!\n", __func__);
+		return;
+	}
+
+	if (DEBUG_ERASE) {
+		spi_feature_op(host, GET_OP, STATUS_ADDR, &val);
+		pr_info("  Get feature addr[0xC0], val[%#x]\n", val);
+	}
+
+	host->set_system_clock(spi->erase, ENABLE);
+
+	val = HISNFC100_INT_CLR_ALL;
+	hisfc_write(host, HISNFC100_INT_CLR, val);
+	if (DEBUG_ERASE)
+		pr_info("  Set REG INT_CLR[0x14]%#x\n", val);
+
+	val = spi->erase->cmd;
+	hisfc_write(host, HISNFC100_OPCODE, val);
+	if (DEBUG_ERASE)
+		pr_info("  Set REG OPCODE[0x18]%#x\n", val);
+
+	val = HISNFC100_OP_ADDRH_BLOCK_MASK(host->addr_value[1])
+		| HISNFC100_OP_ADDRL_BLOCK_MASK(host->addr_value[0]);
+	hisfc_write(host, HISNFC100_OP_ADDR, val);
+	if (DEBUG_ERASE)
+		pr_info("  Set REG OP_ADDR[0x18]%#x\n", val);
+
+	val = HISNFC100_OP_CFG_DIR_TRANS_ENABLE;
+	hisfc_write(host, HISNFC100_OP_CFG, val);
+	if (DEBUG_ERASE)
+		pr_info("  Set REG OP_CFG[0x28]%#x\n", val);
+
+	val = HISNFC100_OP_SEL_CS(host->cmd_option.chipselect)
+		| HISNFC100_OP_ADDR_NUM(STD_OP_ADDR_NUM)
+		| HISNFC100_OP_OPCODE_EN(ENABLE)
+		| HISNFC100_OP_ADDR_EN(ENABLE)
+		| HISNFC100_OP_START;
+	hisfc_write(host, HISNFC100_OP, val);
+	if (DEBUG_ERASE)
+		pr_info("  Set REG OP[0x20]%#x\n", val);
+
+	HISNFC100_CMD_WAIT_CPU_FINISH(host);
+
+	if (DEBUG_ERASE) {
+		val = spi->driver->wait_ready(spi);
+		if (val & STATUS_E_FAIL_MASK)
+			pr_info("hisnfc100: erase failed! status[%#x]\n", val);
+	}
+
+	if (DEBUG_ERASE)
+		pr_info("* End send cmd erase!\n");
+}
+
+/*****************************************************************************/
+static void hisnfc100_send_cmd_status(struct hisnfc_host *host)
+{
+	unsigned regval, addr = 0;
+
+	if ((host->cmd_option.last_cmd == NAND_CMD_ERASE1)
+	    || (host->cmd_option.last_cmd == NAND_CMD_PAGEPROG))
+		addr = PROTECTION_ADDR;
+	else
+		addr = STATUS_ADDR;
+
+	spi_feature_op(host, GET_OP, addr, &regval);
+
+	if (DEBUG_ERASE || DEBUG_WRITE)
+		pr_info("hisnfc100: %s get %#x status[%#x]\n",
+			((host->cmd_option.last_cmd == NAND_CMD_ERASE1)
+			 ? "erase" : "write"), addr, regval);
+}
+
+/*****************************************************************************/
+static void hisnfc100_send_cmd_readid(struct hisnfc_host *host)
+{
+	hisfc_write(host, HISNFC100_INT_CLR, HISNFC100_INT_CLR_OP_DONE);
+	hisfc_write(host, HISNFC100_OPCODE, SPI_CMD_RDID);
+	hisfc_write(host, HISNFC100_OP_ADDR, READ_ID_ADDR);
+	hisfc_write(host, HISNFC100_DATA_NUM,
+			HISNFC100_DATA_NUM_CNT(MAX_ID_LEN));
+	hisfc_write(host, HISNFC100_OP_CFG, HISNFC100_OP_CFG_DIR_TRANS_ENABLE);
+
+	hisfc_write(host, HISNFC100_OP,
+			HISNFC100_OP_SEL_CS(host->cmd_option.chipselect)
+			| HISNFC100_OP_ADDR_NUM(READ_ID_ADDR_NUM)
+			| HISNFC100_OP_OPCODE_EN(ENABLE)
+			| HISNFC100_OP_ADDR_EN(ENABLE)
+			| HISNFC100_OP_DATE_READ_EN(ENABLE)
+			| HISNFC100_OP_START);
+
+	HISNFC100_CMD_WAIT_CPU_FINISH(host);
+}
+
+/*****************************************************************************/
+static void hisnfc100_send_cmd_reset(struct hisnfc_host *host)
+{
+	hisfc_write(host, HISNFC100_INT_CLR, HISNFC100_INT_CLR_OP_DONE);
+	hisfc_write(host, HISNFC100_OPCODE, SPI_CMD_RESET);
+	hisfc_write(host, HISNFC100_OP_CFG, HISNFC100_OP_CFG_DIR_TRANS_ENABLE);
+	hisfc_write(host, HISNFC100_OP,
+			HISNFC100_OP_SEL_CS(host->cmd_option.chipselect)
+			| HISNFC100_OP_OPCODE_EN(ENABLE)
+			| HISNFC100_OP_START);
+
+	HISNFC100_CMD_WAIT_CPU_FINISH(host);
+}
+
+/*****************************************************************************/
+static uint8_t hisnfc100_read_byte(struct mtd_info *mtd)
+{
+	unsigned char value = 0, ret_val = 0;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hisnfc_host *host = chip->priv;
+
+	if (host->cmd_option.last_cmd == NAND_CMD_READID) {
+		value = readb(chip->IO_ADDR_R + host->offset);
+		host->offset++;
+		if (host->cmd_option.date_num == host->offset)
+			host->cmd_option.last_cmd = 0;
+		return value;
+	}
+
+	if ((host->cmd_option.last_cmd == NAND_CMD_ERASE1)
+	    || (host->cmd_option.last_cmd == NAND_CMD_PAGEPROG)) {
+		value = hisfc_read(host, HISNFC100_STATUS);
+		if (ANY_BP_ENABLE(value))
+			value &= ~NAND_STATUS_WP;
+		else
+			value |= NAND_STATUS_WP;
+
+		host->cmd_option.last_cmd = 0;
+
+		return value;
+	}
+
+	if (host->cmd_option.last_cmd == NAND_CMD_ERASE2) {
+		value = hisfc_read(host, HISNFC100_STATUS);
+		if (!(value & STATUS_OIP_MASK))
+			ret_val |= NAND_STATUS_READY;
+
+		if (value & STATUS_E_FAIL_MASK)
+			ret_val |= NAND_STATUS_FAIL;
+
+		return ret_val;
+	}
+
+	if (host->cmd_option.command == NAND_CMD_STATUS) {
+		value = hisfc_read(host, HISNFC100_STATUS);
+
+		if (!(value & STATUS_OIP_MASK))
+			ret_val |= NAND_STATUS_READY;
+
+		if (value & STATUS_P_FAIL_MASK)
+			ret_val |= NAND_STATUS_FAIL;
+
+		return ret_val;
+	}
+
+	if (host->cmd_option.last_cmd == NAND_CMD_READOOB) {
+		value = readb(host->buffer + host->pagesize + host->offset);
+		host->offset++;
+		return value;
+	}
+
+	host->offset++;
+
+	return readb(host->buffer + host->column + host->offset - 1);
+}
+
+/*****************************************************************************/
+static u16 hisnfc100_read_word(struct mtd_info *mtd)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hisnfc_host *host = chip->priv;
+
+	host->offset += 2;
+	return readw(host->buffer + host->column + host->offset - 2);
+}
+
+/*****************************************************************************/
+static void hisnfc100_write_buf(struct mtd_info *mtd,
+	const uint8_t *buf, int len)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hisnfc_host *host = chip->priv;
+
+#ifdef HISNFC100_SUPPORT_REG_WRITE
+	if (buf == chip->oob_poi)
+		memcpy((char *)host->iobase + host->pagesize, buf, len);
+	else
+		memcpy((char *)host->iobase, buf, len);
+#else
+	if (buf == chip->oob_poi)
+		memcpy((char *)(host->buffer + host->pagesize), buf, len);
+	else
+		memcpy((char *)host->buffer, buf, len);
+#endif
+	return;
+}
+
+/*****************************************************************************/
+static void hisnfc100_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hisnfc_host *host = chip->priv;
+
+#ifdef HISNFC100_SUPPORT_REG_READ
+	if (buf == chip->oob_poi)
+		memcpy(buf, (char *)host->iobase + host->pagesize, len);
+	else
+		memcpy(buf, (char *)host->iobase, len);
+#else
+	if (buf == chip->oob_poi)
+		memcpy(buf, (char *)(host->buffer + host->pagesize), len);
+	else
+		memcpy(buf, (char *)host->buffer, len);
+#endif
+
+	if (buf != chip->oob_poi) {
+		u_int reg, ecc_step = host->pagesize >> 10;
+
+		reg = hisfc_read(host, HISNFC100_ECC_ERR_NUM);
+		while (ecc_step) {
+			u_char err_num;
+
+			err_num = GET_ECC_ERR_NUM(--ecc_step, reg);
+			if (err_num == 0xff)
+				mtd->ecc_stats.failed++;
+			else
+				mtd->ecc_stats.corrected += err_num;
+		}
+	}
+
+	return;
+}
+
+/*****************************************************************************/
+static void hisnfc100_select_chip(struct mtd_info *mtd, int chipselect)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hisnfc_host *host = chip->priv;
+
+	if (chipselect < 0)
+		return;
+
+	if (chipselect > CONFIG_HISNFC100_MAX_CHIP)
+		DBG_BUG("invalid chipselect: %d\n", chipselect);
+
+	host->cmd_option.chipselect = chipselect + 1;
+
+	switch (chip->state) {
+	case FL_ERASING:
+		host->cmd_option.last_cmd = NAND_CMD_ERASE1;
+		break;
+
+	case FL_WRITING:
+		host->cmd_option.last_cmd = NAND_CMD_PAGEPROG;
+		break;
+
+	default:
+		break;
+	}
+}
+
+/*****************************************************************************/
+static void hisnfc100_cmd_ctrl(struct mtd_info *mtd, int dat, unsigned ctrl)
+{
+	unsigned char cmd;
+	int is_cache_invalid = 1;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hisnfc_host *host = chip->priv;
+
+	if (ctrl & NAND_ALE) {
+		unsigned int addr_value = 0;
+		unsigned int addr_offset = 0;
+
+		if (ctrl & NAND_CTRL_CHANGE) {
+			host->addr_cycle = 0x0;
+			host->addr_value[0] = 0x0;
+			host->addr_value[1] = 0x0;
+		}
+		addr_offset = host->addr_cycle << 3;
+
+		if (host->addr_cycle >= HISNFC100_ADDR_CYCLE_MASK) {
+			addr_offset = (host->addr_cycle -
+					HISNFC100_ADDR_CYCLE_MASK) << 3;
+			addr_value = 1;
+		}
+
+		host->addr_value[addr_value] |=
+			((dat & 0xff) << addr_offset);
+
+		host->addr_cycle++;
+	}
+
+	if ((ctrl & NAND_CLE) && (ctrl & NAND_CTRL_CHANGE)) {
+		cmd = dat & 0xff;
+		host->cmd_option.command = cmd;
+		switch (cmd) {
+		case NAND_CMD_PAGEPROG:
+			host->offset = 0;
+			host->send_cmd_pageprog(host);
+			break;
+
+		case NAND_CMD_READSTART:
+			is_cache_invalid = 0;
+			if (host->addr_value[0] == host->pagesize)
+				host->cmd_option.last_cmd = NAND_CMD_READOOB;
+			host->send_cmd_readstart(host);
+			break;
+
+		case NAND_CMD_ERASE2:
+			host->cmd_option.last_cmd = cmd;
+			host->send_cmd_erase(host);
+			break;
+
+		case NAND_CMD_READID:
+			memset((unsigned char *)(chip->IO_ADDR_R), 0,
+				MAX_ID_LEN);
+			host->cmd_option.last_cmd = cmd;
+			host->cmd_option.date_num = MAX_ID_LEN;
+			host->send_cmd_readid(host);
+			break;
+
+		case NAND_CMD_STATUS:
+			host->send_cmd_status(host);
+			break;
+
+		case NAND_CMD_SEQIN:
+			break;
+
+		case NAND_CMD_ERASE1:
+			break;
+
+		case NAND_CMD_READ0:
+			host->cmd_option.last_cmd = cmd;
+			break;
+
+		case NAND_CMD_RESET:
+			host->send_cmd_reset(host);
+			break;
+
+		default:
+			break;
+		}
+	}
+
+	if ((dat == NAND_CMD_NONE) && host->addr_cycle) {
+		if (host->cmd_option.command == NAND_CMD_SEQIN
+		    || host->cmd_option.command == NAND_CMD_READ0
+		    || host->cmd_option.command == NAND_CMD_READID) {
+			host->offset = 0x0;
+			host->column = (host->addr_value[0] & 0xffff);
+		}
+	}
+
+	if (is_cache_invalid) {
+		host->cache_addr_value[0] = ~0;
+		host->cache_addr_value[1] = ~0;
+	}
+}
+
+/*****************************************************************************/
+static int hisnfc100_dev_ready(struct mtd_info *mtd)
+{
+	unsigned regval;
+	unsigned deadline = 0;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hisnfc_host *host = chip->priv;
+
+	do {
+		spi_feature_op(host, GET_OP, STATUS_ADDR, &regval);
+		if (!(regval & STATUS_OIP_MASK))
+			return 1;
+		udelay(1);
+	} while (deadline++ < (40 << 20));
+
+	pr_info("Wait spi nand flash ready timeout.\n");
+
+	return 0;
+}
+
+/*****************************************************************************/
+/*
+ * 'host->epm' only use the first oobfree[0] field, it looks very simple, But...
+ */
+/* Default OOB area layout */
+static int hisnfc_ooblayout_ecc_64(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 32;
+	oobregion->offset = 32;
+
+	return 0;
+}
+
+static int hisnfc_ooblayout_free_64(struct mtd_info *mtd, int section,
+		struct mtd_oob_region *oobregion)
+{
+	if (section)
+		return -ERANGE;
+
+	oobregion->length = 30;
+	oobregion->offset = 2;
+
+	return 0;
+}
+
+static struct mtd_ooblayout_ops hisnfc_ooblayout_64_ops = {
+	.ecc = hisnfc_ooblayout_ecc_64,
+	.free = hisnfc_ooblayout_free_64,
+};
+
+/*****************************************************************************/
+static struct nand_config_info hisnfc_spi_nand_config_table[] = {
+	{NAND_PAGE_4K,	NAND_ECC_24BIT,	24, 200,		&hisnfc_ooblayout_64_ops},
+	{NAND_PAGE_4K,	NAND_ECC_16BIT,	16, 144,		&hisnfc_ooblayout_64_ops},
+	{NAND_PAGE_4K,	NAND_ECC_8BIT,	8, 128/*88*/,	&hisnfc_ooblayout_64_ops},
+	{NAND_PAGE_4K,	NAND_ECC_0BIT,	0, 32,		&hisnfc_ooblayout_64_ops},
+
+	{NAND_PAGE_2K,	NAND_ECC_24BIT,	24, 128/*116*/,	&hisnfc_ooblayout_64_ops},
+	{NAND_PAGE_2K,	NAND_ECC_16BIT,	16, 88,		&hisnfc_ooblayout_64_ops},
+	{NAND_PAGE_2K,	NAND_ECC_8BIT,	8, 64/*60*/,	&hisnfc_ooblayout_64_ops},
+	{NAND_PAGE_2K,	NAND_ECC_0BIT,	0, 32,		&hisnfc_ooblayout_64_ops},
+
+	{0, 0, 0, 0, NULL},
+};
+
+/*****************************************************************************/
+/* used the best correct arithmetic. */
+struct nand_config_info *hisnfc100_get_best_ecc(struct mtd_info *mtd)
+{
+	struct nand_config_info *best = NULL;
+	struct nand_config_info *info = hisnfc_spi_nand_config_table;
+
+	for (; info->ooblayout_ops; info++) {
+		if (nandpage_type2size(info->pagetype) != mtd->writesize)
+			continue;
+
+		if (mtd->oobsize < info->oobsize)
+			continue;
+
+		if (!best || (best->ecctype < info->ecctype))
+			best = info;
+	}
+
+	if (!best)
+		DBG_BUG(ERSTR_DRIVER "Driver does not support the pagesize" \
+		"(%d) and oobsize(%d).\n", mtd->writesize, mtd->oobsize);
+
+	return best;
+}
+
+/*****************************************************************************/
+/* force the pagesize and ecctype */
+struct nand_config_info *hisnfc100_force_ecc(struct mtd_info *mtd, int pagetype,
+		int ecctype, char *cfgmsg, int allow_pagediv)
+{
+	int pagesize;
+	struct nand_config_info *fit = NULL;
+	struct nand_config_info *info = hisnfc_spi_nand_config_table;
+
+	for (; info->ooblayout_ops; info++) {
+		if (info->pagetype == pagetype && info->ecctype == ecctype) {
+			fit = info;
+			break;
+		}
+	}
+
+	if (!fit) {
+		DBG_BUG(ERSTR_DRIVER "Driver(%s mode) does not support this" \
+			" Nand Flash pagesize:%s, ecctype:%s\n", cfgmsg,
+			nand_page_name(pagetype), nand_ecc_name(ecctype));
+		return NULL;
+	}
+
+	pagesize = nandpage_type2size(pagetype);
+	if ((pagesize != mtd->writesize)
+		&& (pagesize > mtd->writesize || !allow_pagediv)) {
+		DBG_BUG(ERSTR_HARDWARE "Hardware (%s mode) configure pagesize" \
+			" %d, but the Nand Flash pageszie is %d\n", cfgmsg,
+			pagesize, mtd->writesize);
+		return NULL;
+	}
+
+	if (fit->oobsize > mtd->oobsize) {
+		DBG_BUG(ERSTR_HARDWARE "(%s mode) The Nand Flash offer space" \
+			" area is %d bytes, but the controller request %d" \
+			"bytes in ecc %s. Please make sure the hardware ECC " \
+			"configuration is correct.", cfgmsg, mtd->oobsize,
+			fit->oobsize, nand_ecc_name(ecctype));
+		return NULL;
+	}
+
+	return fit;
+}
+
+/*****************************************************************************/
+int hisnfc100_ecc_probe(struct mtd_info *mtd, struct nand_chip *chip,
+	struct nand_dev_t *nand_dev)
+{
+	char *start_type = "unknown";
+	struct nand_config_info *best = NULL;
+	struct hisnfc_host *host = chip->priv;
+	struct mtd_oob_region *hisnfc_oobregion;
+	unsigned reg_pagetype, reg_ecctype, pagetype, ecctype;
+
+	hisnfc_oobregion = kmalloc(sizeof(struct mtd_oob_region), GFP_KERNEL);
+	if (!hisnfc_oobregion) {
+		PR_BUG("failed to allocate hinfc_oobregion structure.\n");
+		return -ENOMEM;
+	}
+
+#ifdef CONFIG_HISNFC100_AUTO_PAGESIZE_ECC
+	best = hisnfc100_get_best_ecc(mtd);
+	start_type = "Auto";
+#endif /* CONFIG_HISNFC100_AUTO_PAGESIZE_ECC */
+
+#ifdef CONFIG_HISNFC100_HARDWARE_PAGESIZE_ECC
+#  ifdef CONFIG_HISNFC100_AUTO_PAGESIZE_ECC
+#  error you SHOULD NOT define CONFIG_HISNFC100_AUTO_PAGESIZE_ECC \
+	and CONFIG_HISNFC100_HARDWARE_PAGESIZE_ECC at the same time
+#  endif
+
+	reg_pagetype = (host->NFC_CFG & PAGE_SIZE_MASK) >> PAGE_SIZE_SHIFT;
+	switch (reg_pagetype) {
+	case 0:
+		pagetype = NAND_PAGE_2K;
+		break;
+	case 1:
+		pagetype = NAND_PAGE_4K;
+		break;
+	default:
+		pagetype = NAND_PAGE_2K;
+	}
+
+	reg_ecctype = (host->NFC_CFG & ECC_TYPE_MASK) >> ECC_TYPE_SHIFT;
+	switch (reg_ecctype) {
+	case 0x01:
+		ecctype = NAND_ECC_8BIT;
+		break;
+	case 0x02:
+		ecctype = NAND_ECC_16BIT;
+		break;
+	case 0x03:
+		ecctype = NAND_ECC_24BIT;
+		break;
+	case 0:
+	default:
+		ecctype = NAND_ECC_8BIT;
+	}
+	best = hisnfc100_force_ecc(mtd, pagetype, ecctype,
+			"hardware config", 0);
+	start_type = "Hardware";
+
+#endif /* CONFIG_HISNFC100_HARDWARE_PAGESIZE_ECC */
+
+#ifdef CONFIG_HISNFC100_PAGESIZE_AUTO_ECC_NONE
+#  ifdef CONFIG_HISNFC100_AUTO_PAGESIZE_ECC
+#  error you SHOULD NOT define CONFIG_HISNFC100_PAGESIZE_AUTO_ECC_NONE \
+	and CONFIG_HISNFC100_AUTO_PAGESIZE_ECC at the same time
+#  endif
+#  ifdef CONFIG_HISNFC100_HARDWARE_PAGESIZE_ECC
+#  error you SHOULD NOT define CONFIG_HISNFC100_PAGESIZE_AUTO_ECC_NONE \
+	and CONFIG_HISNFC100_HARDWARE_PAGESIZE_ECC at the same time
+#  endif
+
+	{
+		int pagetype;
+
+		switch (mtd->writesize) {
+		case _2K:
+			pagetype = NAND_PAGE_2K;
+			break;
+		case _4K:
+			pagetype = NAND_PAGE_4K;
+			break;
+		default:
+			pagetype = NAND_PAGE_2K;
+			break;
+		}
+		best = hisnfc100_force_ecc(mtd, pagetype, NAND_ECC_0BIT,
+					  "force config", 0);
+		start_type = "AutoForce";
+	}
+#endif /* CONFIG_HISNFC100_PAGESIZE_AUTO_ECC_NONE */
+
+	if (!best)
+		DBG_BUG(ERSTR_HARDWARE
+			"Please configure SPI Nand Flash pagesize and ecctype!\n");
+
+	if (best->ecctype != NAND_ECC_0BIT)
+		mtd->oobsize = best->oobsize;
+
+	host->ecctype  = best->ecctype;
+	host->pagesize = nandpage_type2size(best->pagetype);
+	host->oobsize  = mtd->oobsize;
+	host->block_page_mask = ((mtd->erasesize / mtd->writesize) - 1);
+
+	host->dma_oob = host->dma_buffer + host->pagesize;
+
+	host->bbm = (unsigned char *)(host->buffer + host->pagesize
+			+ HINFC_BAD_BLOCK_POS);
+
+	if (best->ooblayout_ops->free)
+		best->ooblayout_ops->free(mtd, 0, hisnfc_oobregion);
+
+	host->epm = (unsigned short *)(host->buffer + host->pagesize
+			+ hisnfc_oobregion->offset + 28);
+
+	mtd_set_ooblayout(mtd, &hisnfc_ooblayout_64_ops);
+
+	host->NFC_CFG |= (HISNFC100_CFG_ECC_TYPE(best->ecctype)
+		| HISNFC100_CFG_PAGE_SIZE(best->pagetype)
+		| HISNFC100_CFG_OP_MODE(OP_MODE_NORMAL));
+
+	if (mtd->writesize > SPI_NAND_MAX_PAGESIZE
+		|| mtd->oobsize > SPI_NAND_MAX_OOBSIZE) {
+		DBG_BUG(ERSTR_DRIVER "Driver does not support this Nand " \
+			"Flash. Please increase SPI_NAND_MAX_PAGESIZE and " \
+			"SPI_NAND_MAX_OOBSIZE.\n");
+	}
+
+	if (mtd->writesize != host->pagesize) {
+		unsigned int shift = 0;
+		unsigned int writesize = mtd->writesize;
+		while (writesize > host->pagesize) {
+			writesize >>= 1;
+			shift++;
+		}
+		chip->chipsize = chip->chipsize >> shift;
+		mtd->erasesize = mtd->erasesize >> shift;
+		mtd->writesize = host->pagesize;
+		pr_info("Nand divide into 1/%u\n", (1 << shift));
+	}
+
+	nand_dev->start_type = start_type;
+	nand_dev->ecctype = host->ecctype;
+	nand_dev->oobsize = host->oobsize;
+
+	/* All SPI NAND are small-page, SLC */
+	chip->bits_per_cell = 1;
+
+	kfree(hisnfc_oobregion);
+
+	return 0;
+}
+
+/*****************************************************************************/
+void hisnfc100_nand_init(struct nand_chip *chip)
+{
+	chip->read_byte   = hisnfc100_read_byte;
+	chip->read_word   = hisnfc100_read_word;
+	chip->write_buf   = hisnfc100_write_buf;
+	chip->read_buf    = hisnfc100_read_buf;
+
+	chip->select_chip = hisnfc100_select_chip;
+
+	chip->cmd_ctrl    = hisnfc100_cmd_ctrl;
+	chip->dev_ready   = hisnfc100_dev_ready;
+
+	chip->chip_delay  = HISNFC100_CHIP_DELAY;
+
+	chip->options	  = NAND_SKIP_BBTSCAN;
+
+	chip->ecc.mode    = NAND_ECC_NONE;
+}
+
+/*****************************************************************************/
+int hisnfc100_host_init(struct hisnfc_host *host)
+{
+	unsigned regval;
+
+	regval = hisfc_read(host, HISNFC100_CFG);
+	if (((regval & DEVICE_TYPE_MASK) >> DEVICE_TYPE_SHIFT)
+		!= DEVICE_TYPE_NAND_FLASH) {
+		pr_info("%s: Device type(SPI nor flash) error.\n", __func__);
+		return -ENXIO;
+	}
+
+	if ((regval & OP_MODE_MASK) == OP_MODE_BOOT)
+		regval |= HISNFC100_CFG_OP_MODE(OP_MODE_NORMAL);
+
+	if (!(regval & HISNFC100_CFG_DEVICE_INTERNAL_ECC_ENABLE))
+		regval &= ~HISNFC100_CFG_DEVICE_INTERNAL_ECC_ENABLE;
+
+	hisfc_write(host, HISNFC100_CFG, regval);
+
+	host->NFC_CFG = regval;
+
+	host->addr_cycle    = 0;
+	host->addr_value[0] = 0;
+	host->addr_value[1] = 0;
+	host->cache_addr_value[0] = ~0;
+	host->cache_addr_value[1] = ~0;
+
+	host->send_cmd_pageprog  = hisnfc100_send_cmd_pageprog;
+	host->send_cmd_status    = hisnfc100_send_cmd_status;
+	host->send_cmd_readstart = hisnfc100_send_cmd_readstart;
+	host->send_cmd_erase     = hisnfc100_send_cmd_erase;
+	host->send_cmd_readid    = hisnfc100_send_cmd_readid;
+	host->send_cmd_reset     = hisnfc100_send_cmd_reset;
+	host->set_system_clock = hisnfc100_set_system_clock;
+
+	hisfc_write(host, HISNFC100_TIMING_CFG,
+			HISNFC100_TIMING_CFG_TCSH(CS_HOLD_TIME)
+			| HISNFC100_TIMING_CFG_TCSS(CS_SETUP_TIME)
+			| HISNFC100_TIMING_CFG_TSHSL(CS_DESELECT_TIME));
+	return 0;
+}
+
diff --git a/drivers/mtd/nand/hisnfc100/hisnfc100.h b/drivers/mtd/nand/hisnfc100/hisnfc100.h
new file mode 100644
index 0000000..ae74408
--- /dev/null
+++ b/drivers/mtd/nand/hisnfc100/hisnfc100.h
@@ -0,0 +1,375 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef HISNFC100H
+#define HISNFC100H
+
+#include "../hinfc_gen.h"
+
+/******************************************************************************/
+/* These macroes are for debug only, reg option is slower then dma option */
+#undef HISNFC100_SUPPORT_REG_READ
+/* #define HISNFC100_SUPPORT_REG_READ */
+
+#undef HISNFC100_SUPPORT_REG_WRITE
+/* #define HISNFC100_SUPPORT_REG_WRITE */
+
+/*****************************************************************************/
+#define HISNFC100_CFG					0x00
+#define HISNFC100_CFG_BOOT_MODE(_mode)			((_mode) << 17)
+#define HISNFC100_CFG_DEVICE_INTERNAL_ECC_ENABLE	(1 << 16)
+#define HISNFC100_CFG_FLASH_SIZE_CS1(_size)		(((_size) & 0xf) << 10)
+#define HISNFC100_CFG_FLASH_SIZE_CS0(_size)		(((_size) & 0xf) << 6)
+#define HISNFC100_CFG_ADDR_MODE(_mode)			((_mode) << 5)
+#define HISNFC100_CFG_ECC_TYPE(type)			(((type) & 0x3) << 3)
+#define HISNFC100_CFG_PAGE_SIZE(size)			((size) << 2)
+#define HISNFC100_CFG_DEVICE_TYPE(_type)		((_type) << 1)
+#define HISNFC100_CFG_OP_MODE(_mode)			((_mode) << 0)
+
+#define BOOT_MODE_MASK				(0x1 << 17)
+
+#define FLASH_SIZE_CS1_SHIFT			10
+#define FLASH_SIZE_CS1_MASK			(0xf << 10)
+
+#define FLASH_SIZE_CS0_SHIFT			6
+#define FLASH_SIZE_CS0_MASK			(0xf << 6)
+
+#define ECC_TYPE_SHIFT				3
+#define ECC_TYPE_MASK				(0x3 << 3)
+
+#define PAGE_SIZE_SHIFT				2
+#define PAGE_SIZE_MASK				(0x1 << 2)
+
+#define DEVICE_TYPE_SHIFT			1
+#define DEVICE_TYPE_MASK			(0x1 << 1)
+#define DEVICE_TYPE_NOR_FLASH			0
+#define DEVICE_TYPE_NAND_FLASH			1
+
+#define OP_MODE_MASK				(0x1 << 0)
+#define OP_MODE_BOOT				0
+#define OP_MODE_NORMAL				1
+
+/*****************************************************************************/
+#define HISNFC100_GLOBAL_CFG			0x04
+#define HISNFC100_GLOBAL_CFG_WP_ENABLE		(1 << 5)
+
+/*****************************************************************************/
+#define HISNFC100_TIMING_CFG			0x08
+#define HISNFC100_TIMING_CFG_TCSH(_n)		(((_n) & 0xf) << 8)
+#define HISNFC100_TIMING_CFG_TCSS(_n)		(((_n) & 0xf) << 4)
+#define HISNFC100_TIMING_CFG_TSHSL(_n)		((_n) & 0xf)
+
+#define CS_HOLD_TIME				0x6
+#define CS_SETUP_TIME				0x6
+#define CS_DESELECT_TIME			0xf
+
+/*****************************************************************************/
+#define HISNFC100_INT				0x0c
+#define HISNFC100_INT_OP_DONE			(1 << 0)
+
+/*****************************************************************************/
+#define HISNFC100_INT_CLR			0x14
+#define HISNFC100_INT_CLR_DMA_ERR		(1 << 5)
+#define HISNFC100_INT_CLR_OP_FAIL		(1 << 2)
+#define HISNFC100_INT_CLR_OP_DONE		(1 << 0)
+
+#define HISNFC100_INT_CLR_ALL			0x7f
+
+/*****************************************************************************/
+#define HISNFC100_OPCODE			0x18
+
+/*****************************************************************************/
+#define HISNFC100_OP_ADDR			0x1c
+#define HISNFC100_OP_ADDRH_BLOCK_MASK(_page)	(((_page) & 0xffff) << 16)
+#define HISNFC100_OP_ADDRL_BLOCK_MASK(_page)	((_page) & 0xffc0)
+
+#define READ_ID_ADDR				0x00
+#define PROTECTION_ADDR				0xa0
+#define FEATURE_ADDR				0xb0
+#define STATUS_ADDR				0xc0
+
+/*****************************************************************************/
+#define HISNFC100_OP				0x20
+#define HISNFC100_OP_SEL_CS(_cs)		((_cs) << 11)
+#define HISNFC100_OP_ADDR_NUM(_n)		(((_n) & 0x7) << 8)
+#define HISNFC100_OP_DUMMY_CMD_EN(_en)		((_en) << 7)
+#define HISNFC100_OP_DUMMY_ADDR_EN(_en)		((_en) << 6)
+#define HISNFC100_OP_OPCODE_EN(_en)		((_en) << 5)
+#define HISNFC100_OP_ADDR_EN(_en)		((_en) << 4)
+#define HISNFC100_OP_DATE_WRITE_EN(_en)		((_en) << 3)
+#define HISNFC100_OP_DATE_READ_EN(_en)		((_en) << 2)
+#define HISNFC100_OP_STATUS_READ_EN(_en)	((_en) << 1)
+#define HISNFC100_OP_START			(1 << 0)
+
+#define STD_OP_ADDR_NUM				3
+#define READ_ID_ADDR_NUM			1
+
+#define FEATURES_OP_ADDR_NUM			1
+
+/*****************************************************************************/
+#define HISNFC100_DATA_NUM			0x24
+#define HISNFC100_DATA_NUM_CNT(_n)		((_n) & 0x1fff)
+
+#define FEATURES_DATE_NUM			1
+
+#define READ_OOB_BB_LEN				1
+
+/*****************************************************************************/
+#define HISNFC100_OP_CFG			0x28
+#define HISNFC100_OP_CFG_DIR_TRANS_ENABLE	(1 << 11)
+#define HISNFC100_OP_CFG_RD_OP_SEL(_type)	(((_type) & 0x3) << 9)
+#define HISNFC100_OP_CFG_MEM_IF_TYPE(_type)	(((_type) & 0x7) << 6)
+#define HISNFC100_OP_CFG_DUMMY_CMD_NUM(_no)	(((_no) & 0x7) << 3)
+#define HISNFC100_OP_CFG_DUMMY_ADDR_NUM(_no)	(((_no) & 0x7) << 0)
+
+#define RD_OP_READ_PAGE				0x0
+#define RD_OP_READ_DATE				0x1
+#define RD_OP_READ_OOB				0x2
+
+/*****************************************************************************/
+#define HISNFC100_ADDRH				0x2c
+#define HISNFC100_ADDRH_SET(_addr)		((_addr) & 0xff)
+
+/*****************************************************************************/
+#define HISNFC100_ADDRL				0x30
+
+/*****************************************************************************/
+#define HISNFC100_OP_CTRL			0x34
+#define HISNFC100_OP_CTRL_RD_OPCODE(_code)	(((_code) & 0xff) << 16)
+#define HISNFC100_OP_CTRL_WR_OPCODE(_code)	(((_code) & 0xff) << 8)
+#define HISNFC100_OP_CTRL_CS_OP(_cs)		((_cs) << 3)
+#define HISNFC100_OP_CTRL_OP_TYPE(_type)	((_type) << 2)
+#define HISNFC100_OP_CTRL_RW_OP(_op)		((_op) << 1)
+#define HISNFC100_OP_CTRL_OP_READY		(1 << 0)
+
+#define OP_TYPE_REG				0
+#define OP_TYPE_DMA				1
+
+#define RW_OP_READ				0
+#define RW_OP_WRITE				1
+
+/*****************************************************************************/
+#define HISNFC100_DMA_CTRL			0x3c
+
+#define HISNFC100_DMA_CTRL_ALL_ENABLE		0x7
+
+/*****************************************************************************/
+#define HISNFC100_DMA_SADDR_D			0x40
+
+/*****************************************************************************/
+#define HISNFC100_DMA_SADDR_OOB			0x44
+
+/*****************************************************************************/
+#define HISNFC100_DMA_LEN			0x48
+#define HISNFC100_DMA_LEN_SET(_len)		((_len) & 0xfffffff)
+
+/*****************************************************************************/
+#define HISNFC100_STATUS			0x54
+
+#define GET_OP					0
+#define SET_OP					1
+
+#define PROTECTION_BRWD_MASK			(1 << 7)
+#define PROTECTION_BP3_MASK			(1 << 6)
+#define PROTECTION_BP2_MASK			(1 << 5)
+#define PROTECTION_BP1_MASK			(1 << 4)
+#define PROTECTION_BP0_MASK			(1 << 3)
+
+#define ANY_BP_ENABLE(_val)		((PROTECTION_BP3_MASK & _val) \
+					|| (PROTECTION_BP2_MASK & _val) \
+					|| (PROTECTION_BP1_MASK & _val) \
+					|| (PROTECTION_BP0_MASK & _val))
+
+#define ALL_BP_MASK				(PROTECTION_BP3_MASK \
+						| PROTECTION_BP2_MASK \
+						| PROTECTION_BP1_MASK \
+						| PROTECTION_BP0_MASK)
+
+#define FEATURE_ECC_ENABLE			(1 << 4)
+#define FEATURE_QE_ENABLE			(1 << 0)
+
+#define STATUS_ECC_MASK				(0x3 << 4)
+#define STATUS_P_FAIL_MASK			(1 << 3)
+#define STATUS_E_FAIL_MASK			(1 << 2)
+#define STATUS_WEL_MASK				(1 << 1)
+#define STATUS_OIP_MASK				(1 << 0)
+
+/*****************************************************************************/
+#define HISNFC100_VERSION			0x68
+
+/*****************************************************************************/
+#define HISNFC100_ECC_ERR_NUM			0x6c
+
+#define GET_ECC_ERR_NUM(_i, _reg)		(((_reg) >> ((_i) * 8)) & 0xff)
+
+/*****************************************************************************/
+#define REG_CNT_HIGH_BLOCK_NUM_SHIFT		10
+
+#define REG_CNT_BLOCK_NUM_MASK			0x3ff
+#define REG_CNT_BLOCK_NUM_SHIFT			22
+
+#define REG_CNT_PAGE_NUM_MASK			0x3f
+#define REG_CNT_PAGE_NUM_SHIFT			16
+
+#define REG_CNT_WRAP_MASK			0xf
+#define REG_CNT_WRAP_SHIFT			12
+
+#define REG_CNT_ECC_OFFSET_MASK			0xfff
+#define REG_CNT_ECC_8BIT_OFFSET			1054
+#define REG_CNT_ECC_16BIT_OFFSET		1056
+#define REG_CNT_ECC_24BIT_OFFSET		1082
+
+/*****************************************************************************/
+#define SPI_NAND_MAX_PAGESIZE			4096
+#define SPI_NAND_MAX_OOBSIZE			256
+
+#define HISNFC100_BUFFER_LEN	(SPI_NAND_MAX_PAGESIZE + SPI_NAND_MAX_OOBSIZE)
+
+/* DMA address align with 32 bytes. */
+#define HISNFC100_DMA_ALIGN			32
+
+#define HISNFC100_CHIP_DELAY			25
+
+#define HISNFC100_ADDR_CYCLE_MASK		0x2
+
+/*****************************************************************************/
+struct hisfc_cmd_option {
+	unsigned char chipselect;
+	unsigned char command;
+	unsigned char last_cmd;
+	unsigned char address_h;
+	unsigned int address_l;
+	unsigned int date_num;
+	unsigned short option;
+	unsigned short op_config;
+};
+
+struct hisnfc_host;
+
+struct hisnfc_host {
+	struct nand_chip *chip;
+	struct mtd_info  *mtd;
+	struct hisnfc_op spi[CONFIG_HISNFC100_MAX_CHIP];
+	struct hisfc_cmd_option cmd_option;
+
+	void __iomem *iobase;
+	void __iomem *regbase;
+
+	unsigned int NFC_CFG;
+
+	unsigned int offset;
+
+	struct device *dev;
+	struct clk *clk;
+
+	unsigned int addr_cycle;
+	unsigned int addr_value[2];
+	unsigned int cache_addr_value[2];
+	unsigned int column;
+	unsigned int block_page_mask;
+
+	unsigned int dma_buffer;
+	unsigned int dma_oob;
+
+	unsigned int ecctype;
+	unsigned int pagesize;
+	unsigned int oobsize;
+
+	/* This is maybe an un-aligment address, only for malloc or free */
+	char *buforg;
+	char *buffer;
+
+	int add_partition;
+
+	/* BOOTROM read two bytes to detect the bad block flag */
+#define HINFC_BAD_BLOCK_POS              0
+	unsigned char *bbm;  /* nand bad block mark */
+	unsigned short *epm;  /* nand empty page mark */
+
+	unsigned int uc_er;
+
+	void (*set_system_clock)(struct spi_op_info *op, int clk_en);
+
+	void (*send_cmd_pageprog)(struct hisnfc_host *host);
+	void (*send_cmd_status)(struct hisnfc_host *host);
+	void (*send_cmd_readstart)(struct hisnfc_host *host);
+	void (*send_cmd_erase)(struct hisnfc_host *host);
+	void (*send_cmd_readid)(struct hisnfc_host *host);
+	void (*send_cmd_reset)(struct hisnfc_host *host);
+};
+
+/*****************************************************************************/
+#define hisfc_read(_host, _reg) \
+	readl(_host->regbase + (_reg))
+
+#define hisfc_write(_host, _reg, _value) \
+	writel((_value), _host->regbase + (_reg))
+
+/*****************************************************************************/
+#define DBG_BUG(fmt, args...) do { \
+	pr_info("%s(%d): BUG: " fmt, __FILE__, __LINE__, ##args); \
+	while (1) \
+		; \
+} while (0)
+
+/*****************************************************************************/
+#define HISNFC100_WAIT_TIMEOUT 10000000
+
+#define HISNFC100_CMD_WAIT_CPU_FINISH(_host) do { \
+	unsigned regval, timeout = HISNFC100_WAIT_TIMEOUT; \
+	do { \
+		regval = hisfc_read((_host), HISNFC100_OP); \
+		--timeout; \
+	} while ((regval & HISNFC100_OP_START) && timeout); \
+	if (!timeout) \
+		DBG_BUG("hisnfc100 wait cmd cpu finish timeout!\n"); \
+} while (0)
+
+/*****************************************************************************/
+#define HISNFC100_DMA_WAIT_INT_FINISH(_host) do { \
+	unsigned regval, timeout = HISNFC100_WAIT_TIMEOUT; \
+	do { \
+		regval = hisfc_read((_host), HISNFC100_INT); \
+		--timeout; \
+	} while ((!(regval & HISNFC100_INT_OP_DONE) && timeout)); \
+	if (!timeout) \
+		DBG_BUG("hisnfc100 wait dma int finish timeout!\n"); \
+} while (0)
+
+/*****************************************************************************/
+#define HISNFC100_DMA_WAIT_CPU_FINISH(_host) do { \
+	unsigned regval, timeout = HISNFC100_WAIT_TIMEOUT; \
+	do { \
+		regval = hisfc_read((_host), HISNFC100_OP_CTRL); \
+		--timeout; \
+	} while ((regval & HISNFC100_OP_CTRL_OP_READY) && timeout); \
+	if (!timeout) \
+		DBG_BUG("dma wait cpu finish timeout\n"); \
+} while (0)
+
+/*****************************************************************************/
+int hisnfc100_host_init(struct hisnfc_host *host);
+
+void hisnfc100_nand_init(struct nand_chip *chip);
+
+int hisnfc100_ecc_probe(struct mtd_info *mtd, struct nand_chip *chip,
+			struct nand_dev_t *nand_dev);
+
+/******************************************************************************/
+#endif /* HISNFC100H */
+
diff --git a/drivers/mtd/nand/hisnfc100/hisnfc100_hi3516a.c b/drivers/mtd/nand/hisnfc100/hisnfc100_hi3516a.c
new file mode 100644
index 0000000..b0e79aa
--- /dev/null
+++ b/drivers/mtd/nand/hisnfc100/hisnfc100_hi3516a.c
@@ -0,0 +1,89 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <mach/io.h>
+
+#include "hisnfc100_os.h"
+#include "hisnfc100.h"
+
+/*****************************************************************************/
+#define HISNFC100_CRG48					0xc0
+#define HISNFC100_CRG48_SPI_NAND_CLK_SEL(_clk)		(((_clk) & 0x3) << 6)
+#define HISNFC100_CRG48_SPI_NAND_CLK_EN			(1 << 5)
+#define HISNFC100_CRG48_SPI_NAND_SOFT_RST_REQ		(1 << 4)
+
+#define SPI_NAND_CLK_SEL_MASK				(0x3 << 6)
+
+#define CLK_24M						0
+#define CLK_75M						1
+#define CLK_125M					2
+
+#define CRG_REG_BASE			(0x20030000)
+
+#define SPI_NAND_CLK_SEL_24M	HISNFC100_CRG48_SPI_NAND_CLK_SEL(CLK_24M)
+#define SPI_NAND_CLK_SEL_75M	HISNFC100_CRG48_SPI_NAND_CLK_SEL(CLK_75M)
+#define SPI_NAND_CLK_SEL_125M	HISNFC100_CRG48_SPI_NAND_CLK_SEL(CLK_125M)
+
+/*****************************************************************************/
+void hisnfc100_set_system_clock(struct spi_op_info *op, int clk_en)
+{
+	unsigned int base = IO_ADDRESS(CRG_REG_BASE);
+	unsigned int regval, old_val;
+
+	old_val = regval = readl((void *)(base + HISNFC100_CRG48));
+
+	regval &= ~SPI_NAND_CLK_SEL_MASK;
+
+	if (op && op->clock)
+		regval |= op->clock &  SPI_NAND_CLK_SEL_MASK;
+	else
+		regval |= SPI_NAND_CLK_SEL_24M;
+
+	if (clk_en)
+		regval |= HISNFC100_CRG48_SPI_NAND_CLK_EN;
+	else
+		regval &= ~HISNFC100_CRG48_SPI_NAND_CLK_EN;
+
+	if (regval != old_val)
+		writel(regval, (void *)(base + HISNFC100_CRG48));
+}
+
+/*****************************************************************************/
+void hisnfc100_get_best_clock(unsigned int *clock)
+{
+	int ix;
+	int clk_reg;
+#define CLK_2X(_clk)	(((_clk) + 1) >> 1)
+	unsigned int sysclk[] = {
+		CLK_2X(24),	SPI_NAND_CLK_SEL_24M,
+		CLK_2X(75),	SPI_NAND_CLK_SEL_75M,
+		CLK_2X(125),	SPI_NAND_CLK_SEL_125M,
+		0, 0,
+	};
+#undef CLK_2X
+
+	clk_reg = SPI_NAND_CLK_SEL_24M;
+	for (ix = 0; sysclk[ix]; ix += 2) {
+		if (*clock < sysclk[ix])
+			break;
+		clk_reg = sysclk[ix + 1];
+	}
+
+	*clock = clk_reg;
+}
+
diff --git a/drivers/mtd/nand/hisnfc100/hisnfc100_os.c b/drivers/mtd/nand/hisnfc100/hisnfc100_os.c
new file mode 100644
index 0000000..f16ba47
--- /dev/null
+++ b/drivers/mtd/nand/hisnfc100/hisnfc100_os.c
@@ -0,0 +1,179 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/of_platform.h>
+#include "hisnfc100_os.h"
+#include "hisnfc100_spi_ids.h"
+#include "hisnfc100.h"
+
+/*****************************************************************************/
+static int hisnfc100_os_probe(struct platform_device *pltdev)
+{
+	int size, result = 0;
+	struct hisnfc_host *host;
+	struct nand_chip *chip;
+	struct mtd_info *mtd;
+	struct resource *res1, *res2 = NULL;
+	struct device *dev = &pltdev->dev;
+	struct device_node *np = NULL;
+
+	size = sizeof(struct hisnfc_host) + sizeof(struct nand_chip)
+		+ sizeof(struct mtd_info);
+	host = kmalloc(size, GFP_KERNEL);
+	if (!host) {
+		PR_BUG("failed to allocate device structure.\n");
+		return -ENOMEM;
+	}
+	memset((char *)host, 0, size);
+	platform_set_drvdata(pltdev, host);
+
+	host->dev  = dev;
+	host->chip = chip = (struct nand_chip *)&host[1];
+	host->mtd  = mtd  = nand_to_mtd(chip);;
+
+	host->clk = devm_clk_get(dev, NULL);
+	if (IS_ERR(host->clk))
+		return PTR_ERR(host->clk);
+	/* enable and set system clock */
+	clk_prepare_enable(host->clk);
+
+	res1 = platform_get_resource_byname(pltdev, IORESOURCE_MEM, "control");
+	host->regbase = devm_ioremap_resource(dev, res1);
+	if (IS_ERR(host->iobase)) {
+		PR_BUG("Error: Can't get resource for reg address.\n");
+		result = -EIO;
+		goto fail;
+	}
+
+	res2 = platform_get_resource_byname(pltdev, IORESOURCE_MEM, "memory");
+	host->iobase = devm_ioremap_resource(dev, res2);
+	if (IS_ERR(host->iobase)) {
+		PR_BUG("Error: Can't get resource for buffer address.\n");
+		result = -EIO;
+		goto fail;
+	}
+
+	memset((char *)host->iobase, 0xff, HISNFC100_BUFFER_BASE_ADDRESS_LEN);
+	chip->IO_ADDR_R = chip->IO_ADDR_W = host->iobase;
+
+	host->buffer = dma_alloc_coherent(host->dev, HISNFC100_BUFFER_LEN,
+						&host->dma_buffer, GFP_KERNEL);
+	if (!host->buffer) {
+		PR_BUG("Can't malloc memory for SPI Nand driver.");
+		result = -ENOMEM;
+		goto fail;
+	}
+	memset(host->buffer, 0xff, HISNFC100_BUFFER_LEN);
+
+	np = of_get_next_available_child(dev->of_node, NULL);
+	mtd->priv  = chip;
+	mtd->owner = THIS_MODULE;
+	mtd->type = MTD_NANDFLASH;
+	mtd->name = np->name;
+
+	result = hisnfc100_host_init(host);
+	if (result)
+		return result;
+
+	chip->priv = host;
+	hisnfc100_nand_init(chip);
+
+	spi_nand_ids_register();
+	hinfc_param_adjust = hisnfc100_ecc_probe;
+
+	if (nand_scan(mtd, CONFIG_HISNFC100_MAX_CHIP)) {
+		result = -ENXIO;
+		goto fail;
+	}
+
+	result = mtd_device_register(mtd, NULL, 0);
+	if (result)
+		goto fail;
+
+	return result;
+
+fail:
+	if (host->buffer) {
+		dma_free_coherent(host->dev, HISNFC100_BUFFER_LEN,
+					host->buffer, host->dma_buffer);
+		host->buffer = NULL;
+	}
+	nand_release(host->mtd);
+	kfree(host);
+	platform_set_drvdata(pltdev, NULL);
+
+	return result;
+}
+/*****************************************************************************/
+
+static int hisnfc100_os_remove(struct platform_device *pltdev)
+{
+	struct hisnfc_host *host = platform_get_drvdata(pltdev);
+
+	clk_disable_unprepare(host->clk);
+
+	nand_release(host->mtd);
+	dma_free_coherent(host->dev,
+				(SPI_NAND_MAX_PAGESIZE + SPI_NAND_MAX_OOBSIZE),
+				host->buffer, host->dma_buffer);
+	kfree(host);
+	platform_set_drvdata(pltdev, NULL);
+
+	return 0;
+}
+/*****************************************************************************/
+#ifdef CONFIG_PM
+/*****************************************************************************/
+static int hisnfc100_os_suspend(struct platform_device *pltdev,
+			       pm_message_t state)
+{
+	return 0;
+}
+
+/*****************************************************************************/
+static int hisnfc100_os_resume(struct platform_device *pltdev)
+{
+	return 0;
+}
+#endif /* CONFIG_PM */
+
+/*****************************************************************************/
+static const struct of_device_id hisi_spi_nand_dt_ids[] = {
+	{ .compatible = "hisilicon,hisi-spi-nand" },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, hisi_spi_nand_dt_ids);
+
+static struct platform_driver hisi_nand_driver = {
+	.driver = {
+		.name	= "hisi-nand",
+		.of_match_table = hisi_spi_nand_dt_ids,
+	},
+	.probe	= hisnfc100_os_probe,
+	.remove = hisnfc100_os_remove,
+#ifdef CONFIG_PM
+	.suspend	= hisnfc100_os_suspend,
+	.resume		= hisnfc100_os_resume,
+#endif
+};
+module_platform_driver(hisi_nand_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("BVT_BSP");
+MODULE_DESCRIPTION("Hisilicon snfc Device Driver, Version 100");
+
diff --git a/drivers/mtd/nand/hisnfc100/hisnfc100_os.h b/drivers/mtd/nand/hisnfc100/hisnfc100_os.h
new file mode 100644
index 0000000..e8daeb4
--- /dev/null
+++ b/drivers/mtd/nand/hisnfc100/hisnfc100_os.h
@@ -0,0 +1,74 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef HISNFC100_OSH
+#define HISNFC100_OSH
+
+/*****************************************************************************/
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/interrupt.h>
+#include <linux/slab.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/partitions.h>
+#include <linux/delay.h>
+#include <linux/sched.h>
+#include <asm/errno.h>
+#include <asm/setup.h>
+#include <linux/io.h>
+#include <linux/dma-mapping.h>
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/mtd/nand.h>
+
+#include <mach/platform.h>
+
+#include <linux/clk.h>
+#include <linux/clkdev.h>
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 4, 5))
+	#include "../../mtdcore.h"
+#endif
+
+#define HISNFC100_BUFFER_BASE_ADDRESS_LEN       (2048 + 256)
+
+/*****************************************************************************/
+#ifndef CONFIG_HISNFC100_MAX_CHIP
+#  define CONFIG_HISNFC100_MAX_CHIP                    (1)
+#  warning NOT config CONFIG_HISNFC100_MAX_CHIP, \
+	used default value, maybe invalid.
+#endif /* CONFIG_HISNFC100_MAX_CHIP */
+
+/*****************************************************************************/
+#define PR_BUG(fmt, args...) do { \
+	pr_info("%s(%d): bug " fmt, __FILE__, __LINE__, ##args); \
+	asm("b ."); \
+} while (0)
+
+#if 1
+#  define DBG_MSG(_fmt, arg...)
+#else
+#  define DBG_MSG(_fmt, arg...) \
+	printk(KERN_INFO "%s(%d): " _fmt, __FILE__, __LINE__, ##arg);
+#endif
+
+#endif /* HISNFC100_OSH */
+
diff --git a/drivers/mtd/nand/hisnfc100/hisnfc100_spi_general.c b/drivers/mtd/nand/hisnfc100/hisnfc100_spi_general.c
new file mode 100644
index 0000000..af8c06e
--- /dev/null
+++ b/drivers/mtd/nand/hisnfc100/hisnfc100_spi_general.c
@@ -0,0 +1,200 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "hisnfc100_os.h"
+#include "hisnfc100.h"
+
+#define DEBUG_SPI_NAND_DRV 0
+
+/*****************************************************************************/
+/*
+  Send set/get features command to SPI Nand flash
+*/
+void spi_feature_op(struct hisnfc_host *host, int op, int addr, unsigned *val)
+{
+	unsigned regval = 0;
+	struct nand_chip *chip = host->chip;
+
+	hisfc_write(host, HISNFC100_INT_CLR, HISNFC100_INT_CLR_OP_DONE);
+
+	hisfc_write(host, HISNFC100_OPCODE,
+			(op ? SPI_CMD_SET_FEATURE : SPI_CMD_GET_FEATURES));
+	hisfc_write(host, HISNFC100_OP_ADDR, addr);
+
+	hisfc_write(host, HISNFC100_OP_CFG, HISNFC100_OP_CFG_DIR_TRANS_ENABLE);
+
+	regval = (HISNFC100_OP_SEL_CS(host->cmd_option.chipselect)
+		| HISNFC100_OP_ADDR_NUM(FEATURES_OP_ADDR_NUM)
+		| HISNFC100_OP_OPCODE_EN(ENABLE)
+		| HISNFC100_OP_ADDR_EN(ENABLE)
+		| HISNFC100_OP_START);
+
+	if (SET_OP == op) {
+		hisfc_write(host, HISNFC100_DATA_NUM, FEATURES_DATE_NUM);
+		regval |= HISNFC100_OP_DATE_WRITE_EN(ENABLE);
+		writeb(*val, chip->IO_ADDR_W);
+		if (DEBUG_SPI_NAND_DRV)
+			pr_info("hisnfc: set feature [%#x]==>[%#x]\n", addr,
+				*val);
+	} else
+		regval |=  HISNFC100_OP_STATUS_READ_EN(ENABLE);
+
+	hisfc_write(host, HISNFC100_OP, regval);
+
+	HISNFC100_CMD_WAIT_CPU_FINISH(host);
+
+	if (GET_OP == op) {
+		*val = hisfc_read(host, HISNFC100_STATUS);
+		if (DEBUG_SPI_NAND_DRV && (addr != STATUS_ADDR))
+			pr_info("hisnfc: get feature [%#x]<==[%#x]\n", addr,
+				*val);
+	}
+}
+
+/*****************************************************************************/
+/*
+  Read status[C0H]:[0]bit OIP, judge whether the device is busy or not
+*/
+static int spi_general_wait_ready(struct hisnfc_op *spi)
+{
+	unsigned regval = 0;
+	unsigned deadline = 0;
+	struct hisnfc_host *host = (struct hisnfc_host *)spi->host;
+
+	do {
+		spi_feature_op(host, GET_OP, STATUS_ADDR, &regval);
+		if (!(regval & STATUS_OIP_MASK)) {
+			if ((host->cmd_option.last_cmd == NAND_CMD_ERASE2)
+			    && (regval & STATUS_E_FAIL_MASK))
+				return regval;
+			if ((host->cmd_option.last_cmd == NAND_CMD_PAGEPROG)
+			    && (regval & STATUS_P_FAIL_MASK))
+				return regval;
+			return 0;
+		}
+		udelay(1);
+	} while (deadline++ < (40 << 20));
+
+	pr_info("hisnfc: wait ready timeout.\n");
+
+	return 1;
+}
+
+/*****************************************************************************/
+/*
+  Send write enable command to SPI Nand, status[C0H]:[2]bit WEL must be set 1
+*/
+static int spi_general_write_enable(struct hisnfc_op *spi)
+{
+	unsigned val;
+	struct hisnfc_host *host = (struct hisnfc_host *)spi->host;
+
+	hisfc_write(host, HISNFC100_INT_CLR, HISNFC100_INT_CLR_OP_DONE);
+
+	val = hisfc_read(host, HISNFC100_GLOBAL_CFG);
+	if (val & HISNFC100_GLOBAL_CFG_WP_ENABLE) {
+		val &= ~HISNFC100_GLOBAL_CFG_WP_ENABLE;
+		hisfc_write(host, HISNFC100_GLOBAL_CFG, val);
+	}
+
+	hisfc_write(host, HISNFC100_OPCODE, SPI_CMD_WREN);
+
+	hisfc_write(host, HISNFC100_OP_CFG,
+			HISNFC100_OP_CFG_DIR_TRANS_ENABLE);
+
+	hisfc_write(host, HISNFC100_OP,
+			HISNFC100_OP_SEL_CS(host->cmd_option.chipselect)
+			| HISNFC100_OP_OPCODE_EN(ENABLE)
+			| HISNFC100_OP_START);
+
+	HISNFC100_CMD_WAIT_CPU_FINISH(host);
+
+	spi_feature_op(host, GET_OP, STATUS_ADDR, &val);
+	if (!(val & STATUS_WEL_MASK)) {
+		pr_info("hisnfc: write enable failed! val[%#x]\n", val);
+		return 1;
+	}
+
+	return 0;
+}
+
+/*****************************************************************************/
+/*
+  judge whether SPI Nand support QUAD read/write or not
+*/
+static int spi_is_quad(struct hisnfc_op *spi)
+{
+	if (DEBUG_SPI_NAND_DRV) {
+		pr_info("hisnfc: SPI write iftype:%d\n", spi->write->iftype);
+		pr_info("hisnfc: SPI read iftype:%d\n", spi->read->iftype);
+	}
+
+	if (HISNFC100_IFCYCLE_QUAD == spi->write->iftype
+	    || HISNFC100_IFCYCLE_QUAD == spi->read->iftype
+	    || HISNFC100_IFCYCLE_QUAD_ADDR == spi->read->iftype)
+		return 1;
+
+	return 0;
+}
+
+/*****************************************************************************/
+/*
+  Send set features command to SPI Nand, feature[B0H]:[0]bit QE would be set
+*/
+static int spi_general_qe_enable(struct hisnfc_op *spi)
+{
+	unsigned val, op;
+	const char *str[] = {"Disable", "Enable"};
+	struct hisnfc_host *host = (struct hisnfc_host *)spi->host;
+
+	if (DEBUG_SPI_NAND_DRV)
+		pr_info("* SPI Quad-Enable start.\n");
+
+	if (spi_is_quad(spi))
+		op = ENABLE;
+	else
+		op = DISABLE;
+
+	if (DEBUG_SPI_NAND_DRV)
+		pr_info("  Read Quad status.\n");
+	spi_feature_op(host, GET_OP, FEATURE_ADDR, &val);
+	if ((val & FEATURE_QE_ENABLE) == op) {
+		if (DEBUG_SPI_NAND_DRV)
+			pr_info("* Quad is %s!\n", str[op]);
+		return 0;
+	}
+
+	if (op == ENABLE)
+		val |= FEATURE_QE_ENABLE;
+	else
+		val &= ~FEATURE_QE_ENABLE;
+	if (DEBUG_SPI_NAND_DRV)
+		pr_info("  %s Quad\n", str[op]);
+	spi_feature_op(host, SET_OP, FEATURE_ADDR, &val);
+
+	spi->driver->wait_ready(spi);
+
+	spi_feature_op(host, GET_OP, FEATURE_ADDR, &val);
+	if ((val & FEATURE_QE_ENABLE) != op) {
+		pr_info("hisnfc: %s Quad failed! val[%#x]\n", str[op], val);
+		return 1;
+	} else if (DEBUG_SPI_NAND_DRV)
+		pr_info("*  %s Quad succeed!\n", str[op]);
+
+	return 0;
+}
diff --git a/drivers/mtd/nand/hisnfc100/hisnfc100_spi_ids.c b/drivers/mtd/nand/hisnfc100/hisnfc100_spi_ids.c
new file mode 100644
index 0000000..48e009e
--- /dev/null
+++ b/drivers/mtd/nand/hisnfc100/hisnfc100_spi_ids.c
@@ -0,0 +1,1131 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "hisnfc100_os.h"
+#include "hisnfc100_spi_ids.h"
+#include "hisnfc100.h"
+
+#include "hisnfc100_spi_general.c"
+
+/*****************************************************************************/
+#define SET_READ_STD(_dummy_, _size_, _clk_) \
+	static struct spi_op_info read_std_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_STD, SPI_CMD_READ_STD, _dummy_, _size_, _clk_ }
+
+#define READ_STD(_dummy_, _size_, _clk_) read_std_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+#define SET_READ_FAST(_dummy_, _size_, _clk_) \
+	static struct spi_op_info read_fast_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_FAST, SPI_CMD_READ_FAST, _dummy_, _size_, _clk_ }
+
+#define READ_FAST(_dummy_, _size_, _clk_) read_fast_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+#define SET_READ_DUAL(_dummy_, _size_, _clk_) \
+	static struct spi_op_info read_dual_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_DUAL, SPI_CMD_READ_DUAL, _dummy_, _size_, _clk_ }
+
+#define READ_DUAL(_dummy_, _size_, _clk_) read_dual_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+#define SET_READ_DUAL_ADDR(_dummy_, _size_, _clk_) \
+	static struct spi_op_info read_dual_addr_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_DUAL_ADDR, SPI_CMD_READ_DUAL_ADDR, _dummy_, _size_, _clk_ }
+
+#define READ_DUAL_ADDR(_dummy_, _size_, _clk_) \
+	read_dual_addr_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+#define SET_READ_QUAD(_dummy_, _size_, _clk_) \
+	static struct spi_op_info read_quad_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_QUAD, SPI_CMD_READ_QUAD, _dummy_, _size_, _clk_ }
+
+#define READ_QUAD(_dummy_, _size_, _clk_) read_quad_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+#define SET_READ_QUAD_ADDR(_dummy_, _size_, _clk_) \
+	static struct spi_op_info read_quad_addr_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_QUAD_ADDR, SPI_CMD_READ_QUAD_ADDR, _dummy_, _size_, _clk_ }
+
+#define READ_QUAD_ADDR(_dummy_, _size_, _clk_) \
+	read_quad_addr_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+#define SET_WRITE_STD(_dummy_, _size_, _clk_) \
+	static struct spi_op_info write_std_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_WRITE_STD, SPI_CMD_WRITE_STD, _dummy_, _size_, _clk_ }
+
+#define WRITE_STD(_dummy_, _size_, _clk_) write_std_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+#define SET_WRITE_QUAD(_dummy_, _size_, _clk_) \
+	static struct spi_op_info write_quad_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_WRITE_QUAD, SPI_CMD_WRITE_QUAD, _dummy_, _size_, _clk_ }
+
+#define WRITE_QUAD(_dummy_, _size_, _clk_) \
+	write_quad_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+#define SET_ERASE_SECTOR_128K(_dummy_, _size_, _clk_) \
+	static struct spi_op_info erase_sector_128k_##_dummy_##_size_##_clk_ \
+	= { SPI_IF_ERASE_SECTOR_128K, SPI_CMD_SE_128K, _dummy_, _size_, _clk_ }
+
+#define ERASE_SECTOR_128K(_dummy_, _size_, _clk_) \
+	erase_sector_128k_##_dummy_##_size_##_clk_
+
+#define SET_ERASE_SECTOR_256K(_dummy_, _size_, _clk_) \
+	static struct spi_op_info erase_sector_256k_##_dummy_##_size_##_clk_ \
+	= { SPI_IF_ERASE_SECTOR_256K, SPI_CMD_SE_256K, _dummy_, _size_, _clk_ }
+
+#define ERASE_SECTOR_256K(_dummy_, _size_, _clk_) \
+	erase_sector_256k_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+SET_READ_STD(1, INFINITE, 24);
+
+SET_READ_FAST(1, INFINITE, 50);
+SET_READ_FAST(1, INFINITE, 80);
+SET_READ_FAST(1, INFINITE, 104);
+SET_READ_FAST(1, INFINITE, 108);
+SET_READ_FAST(1, INFINITE, 120);
+
+SET_READ_DUAL(1, INFINITE, 50);
+SET_READ_DUAL(1, INFINITE, 80);
+SET_READ_DUAL(1, INFINITE, 104);
+SET_READ_DUAL(1, INFINITE, 108);
+SET_READ_DUAL(1, INFINITE, 120);
+
+SET_READ_DUAL_ADDR(1, INFINITE, 60);
+SET_READ_DUAL_ADDR(1, INFINITE, 80);
+SET_READ_DUAL_ADDR(1, INFINITE, 104);
+SET_READ_DUAL_ADDR(1, INFINITE, 108);
+SET_READ_DUAL_ADDR(1, INFINITE, 120);
+
+SET_READ_QUAD(1, INFINITE, 50);
+SET_READ_QUAD(1, INFINITE, 80);
+SET_READ_QUAD(1, INFINITE, 104);
+SET_READ_QUAD(1, INFINITE, 108);
+SET_READ_QUAD(1, INFINITE, 120);
+
+SET_READ_QUAD_ADDR(1, INFINITE, 60);
+SET_READ_QUAD_ADDR(1, INFINITE, 104);
+SET_READ_QUAD_ADDR(2, INFINITE, 80);
+SET_READ_QUAD_ADDR(2, INFINITE, 104);
+SET_READ_QUAD_ADDR(1, INFINITE, 108);
+SET_READ_QUAD_ADDR(1, INFINITE, 120);
+
+/*****************************************************************************/
+SET_WRITE_STD(0, 256, 24);
+SET_WRITE_STD(0, 256, 80);
+SET_WRITE_STD(0, 256, 104);
+
+SET_WRITE_QUAD(0, 256, 80);
+SET_WRITE_QUAD(0, 256, 104);
+SET_WRITE_QUAD(0, 256, 108);
+SET_WRITE_QUAD(0, 256, 120);
+
+/*****************************************************************************/
+SET_ERASE_SECTOR_128K(0, SZ_128K, 24);
+SET_ERASE_SECTOR_128K(0, SZ_128K, 80);
+SET_ERASE_SECTOR_128K(0, SZ_128K, 104);
+
+SET_ERASE_SECTOR_256K(0, SZ_256K, 24);
+SET_ERASE_SECTOR_256K(0, SZ_256K, 80);
+SET_ERASE_SECTOR_256K(0, SZ_256K, 104);
+
+/*****************************************************************************/
+static struct spi_nand_driver spi_nand_driver_general = {
+	.wait_ready   = spi_general_wait_ready,
+	.write_enable = spi_general_write_enable,
+	.qe_enable = spi_general_qe_enable,
+};
+
+/*
+ *   Some spi nand don't need set QE bit enable.
+ */
+static struct spi_nand_driver spi_nand_driver_no_qe = {
+	.wait_ready = spi_general_wait_ready,
+	.write_enable = spi_general_write_enable,
+};
+
+/*****************************************************************************/
+#define SPI_NAND_ID_TAB_VER		"2.2"
+
+/******* SPI Nand ID Table ***************************************************
+* Version	Manufacturer	Chip Name	Size		Operation
+* 1.0		ESMT		F50L512M41A	64MB		Add 5 chip
+*		GD		5F1GQ4UAYIG	128MB
+*		GD		5F2GQ4UAYIG	256MB
+*		GD		5F4GQ4UAYIG	512MB
+*		GD		5F4GQ4UBYIG	512MB
+* 1.1		ESMT		F50L1G41A	128MB		Add 2 chip
+*		Winbond		W25N01GV	128MB
+* 1.2		GD		5F1GQ4UBYIG	128MB		Add 2 chip
+*		GD		5F2GQ4UBYIG	256MB
+* 1.3		ATO		ATO25D1GA	128MB		Add 1 chip
+*		Micron		MT29F1G01	128MB		Add 3 chip
+*		Micron		MT29F2G01	256MB
+*		Micron		MT29F4G01	512MB
+* 1.4		MXIC		MX35LF1GE4AB	128MB		Add 2 chip
+* 1.5		Paragon		PN26G01A	128MB		Add 1 chip
+* 1.6		All-flash	AFS1GQ4UAC	128MB		Add 1 chip
+* 1.7		TOSHIBA		TC58CVG0S3H	128MB		Add 2 chip
+*		TOSHIBA		TC58CVG2S0H	512MB
+* 1.8		ALL-flash	AFS2GQ4UAD	256MB		Add 2 chip
+*		Paragon		PN26G02A	256MB
+* 1.9		TOSHIBA		TC58CVG1S3H	256MB		Add 1 chip
+* 2.0		HeYangTek	HYF1GQ4UAACAE	128MB		Add 3 chip
+*		HeYangTek	HYF2GQ4UAACAE	256MB
+*		HeYangTek	HYF4GQ4UAACBE	512MB
+* 2.1		Micron		MT29F1G01ABA	128MB		Add 1 chip
+* 2.2		Micron		MT29F2G01ABA	256MB		Add 1 chip
+******************************************************************************/
+struct hisnfc_chip_info hisnfc_spi_nand_flash_table[] = {
+	/* Micron MT29F1G01ABA 1GBit */
+	{
+		.name      = "MT29F1G01ABA",
+		.id        = {0x2C, 0x14},
+		.id_len    = 2,
+		.chipsize  = SZ_128M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(2, INFINITE, 80),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 80),
+			&WRITE_QUAD(0, 256, 80),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 80),
+			0
+		},
+		.driver    = &spi_nand_driver_no_qe,
+	},
+
+	/* Micron MT29F2G01ABA 2GBit */
+	{
+		.name      = "MT29F2G01ABA",
+		.id        = {0x2C, 0x24},
+		.id_len    = 2,
+		.chipsize  = SZ_256M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 108),
+			&READ_DUAL(1, INFINITE, 108),
+			&READ_DUAL_ADDR(1, INFINITE, 108),
+			&READ_QUAD(1, INFINITE, 108),
+			&READ_QUAD_ADDR(2, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 80),
+			&WRITE_QUAD(0, 256, 108),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 80),
+			0
+		},
+		.driver    = &spi_nand_driver_no_qe,
+	},
+
+	/* ESMT F50L512M41A 512Mbit */
+	{
+		.name      = "F50L512M41A",
+		.id        = {0xC8, 0x20},
+		.id_len    = 2,
+		.chipsize  = SZ_64M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 64,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_no_qe,
+	},
+
+	/* ESMT F50L1G41A 1Gbit */
+	{
+		.name      = "F50L1G41A",
+		.id        = {0xC8, 0x21},
+		.id_len    = 2,
+		.chipsize  = SZ_128M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 64,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_no_qe,
+	},
+
+	/* GD 5F1GQ4UAYIG 1Gbit */
+	{
+		.name      = "5F1GQ4UAYIG",
+		.id        = {0xc8, 0xf1},
+		.id_len    = 2,
+		.chipsize  = SZ_128M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 64,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 120),
+			&READ_DUAL(1, INFINITE, 120),
+			&READ_DUAL_ADDR(1, INFINITE, 120),
+			&READ_QUAD(1, INFINITE, 120),
+			&READ_QUAD_ADDR(1, INFINITE, 120),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 120),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* GD 5F1GQ4UBYIG 1Gbit */
+	{
+		.name      = "5F1GQ4UBYIG",
+		.id        = {0xc8, 0xd1},
+		.id_len    = 2,
+		.chipsize  = SZ_128M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 128,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 120),
+			&READ_DUAL(1, INFINITE, 120),
+			&READ_DUAL_ADDR(1, INFINITE, 120),
+			&READ_QUAD(1, INFINITE, 120),
+			&READ_QUAD_ADDR(1, INFINITE, 120),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 120),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* GD 5F2GQ4UAYIG 2Gbit */
+	{
+		.name      = "5F2GQ4UAYIG",
+		.id        = {0xc8, 0xf2},
+		.id_len    = 2,
+		.chipsize  = SZ_256M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 64,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 120),
+			&READ_DUAL(1, INFINITE, 120),
+			&READ_DUAL_ADDR(1, INFINITE, 120),
+			&READ_QUAD(1, INFINITE, 120),
+			&READ_QUAD_ADDR(1, INFINITE, 120),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 120),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* GD 5F2GQ4UBYIG 2Gbit */
+	{
+		.name      = "5F2GQ4UBYIG",
+		.id        = {0xc8, 0xd2},
+		.id_len    = 2,
+		.chipsize  = SZ_256M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 128,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 120),
+			&READ_DUAL(1, INFINITE, 120),
+			&READ_DUAL_ADDR(1, INFINITE, 120),
+			&READ_QUAD(1, INFINITE, 120),
+			&READ_QUAD_ADDR(1, INFINITE, 120),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 120),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* GD 5F4GQ4UAYIG 4Gbit */
+	{
+		.name      = "5F4GQ4UAYIG",
+		.id        = {0xc8, 0xf4},
+		.id_len    = 2,
+		.chipsize  = SZ_512M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 64,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 120),
+			&READ_DUAL(1, INFINITE, 120),
+			&READ_DUAL_ADDR(1, INFINITE, 120),
+			&READ_QUAD(1, INFINITE, 120),
+			&READ_QUAD_ADDR(1, INFINITE, 120),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 120),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* GD 5F4GQ4UBYIG 4Gbit */
+	{
+		.name      = "5F4GQ4UBYIG",
+		.id        = {0xc8, 0xd4},
+		.id_len    = 2,
+		.chipsize  = SZ_512M,
+		.erasesize = SZ_256K,
+		.pagesize  = SZ_4K,
+		.oobsize   = 256,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 120),
+			&READ_DUAL(1, INFINITE, 120),
+			&READ_DUAL_ADDR(1, INFINITE, 120),
+			&READ_QUAD(1, INFINITE, 120),
+			&READ_QUAD_ADDR(1, INFINITE, 120),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 120),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_256K(0, SZ_256K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* Winbond W25N01GV 1Gbit */
+	{
+		.name      = "W25N01GV",
+		.id        = {0xef, 0xaa, 0x21},
+		.id_len    = 3,
+		.chipsize  = SZ_128M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 64,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_DUAL_ADDR(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			&READ_QUAD_ADDR(2, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_no_qe,
+	},
+
+	/* ATO ATO25D1GA 1Gbit */
+	{
+		.name      = "ATO25D1GA",
+		.id        = {0x9b, 0x12},
+		.id_len    = 2,
+		.chipsize  = SZ_128M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 64,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* Micron MT29F1G01 */
+	{
+		.name      = "MT29F1G01",
+		.id        = {0x2c, 0x12},
+		.id_len    = 2,
+		.chipsize  = SZ_128M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 64,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 50),
+			&READ_DUAL(1, INFINITE, 50),
+			&READ_QUAD(1, INFINITE, 50),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_no_qe,
+	},
+
+	/* Micron MT29F2G01 */
+	{
+		.name      = "MT29F2G01",
+		.id        = {0x2c, 0x22},
+		.id_len    = 2,
+		.chipsize  = SZ_256M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 64,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 50),
+			&READ_DUAL(1, INFINITE, 50),
+			&READ_QUAD(1, INFINITE, 50),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_no_qe,
+	},
+
+	/* Micron MT29F4G01 */
+	{
+		.name      = "MT29F4G01",
+		.id        = {0x2c, 0x32},
+		.id_len    = 2,
+		.chipsize  = SZ_512M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 64,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 50),
+			&READ_DUAL(1, INFINITE, 50),
+			&READ_QUAD(1, INFINITE, 50),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_no_qe,
+	},
+
+	/* MXIC MX35LF1GE4AB 1Gbit */
+	{
+		.name      = "MX35LF1GE4AB",
+		.id        = {0xc2, 0x12},
+		.id_len    = 2,
+		.chipsize  = SZ_128M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 64,
+		.badblock_pos    = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* Paragon PN26G01A 1Gbit */
+	{
+		.name      = "PN26G01A",
+		.id        = {0xa1, 0xe1},
+		.id_len    = 2,
+		.chipsize  = SZ_128M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 108),
+			&READ_DUAL(1, INFINITE, 108),
+			&READ_DUAL_ADDR(1, INFINITE, 108),
+			&READ_QUAD(1, INFINITE, 108),
+			&READ_QUAD_ADDR(1, INFINITE, 108),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 108),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* Paragon PN26G02A 2Gbit */
+	{
+		.name      = "PN26G02A",
+		.id        = {0xa1, 0xe2},
+		.id_len    = 2,
+		.chipsize  = SZ_256M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 108),
+			&READ_DUAL(1, INFINITE, 108),
+			&READ_DUAL_ADDR(1, INFINITE, 108),
+			&READ_QUAD(1, INFINITE, 108),
+			&READ_QUAD_ADDR(1, INFINITE, 108),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 108),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* All-flash AFS1GQ4UAC 1Gbit */
+	{
+		.name      = "AFS1GQ4UAC",
+		.id        = {0xc1, 0x51},
+		.id_len    = 2,
+		.chipsize  = SZ_128M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_DUAL_ADDR(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			&READ_QUAD_ADDR(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* All-flash AFS2GQ4UAD 2Gbit */
+	{
+		.name      = "AFS2GQ4UAD",
+		.id        = {0xc1, 0x52},
+		.id_len    = 2,
+		.chipsize  = SZ_256M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_DUAL_ADDR(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			&READ_QUAD_ADDR(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 24),
+			&WRITE_QUAD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 24),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* TOSHIBA TC58CVG0S3H 1Gbit */
+	{
+		.name      = "TC58CVG0S3H",
+		.id        = {0x98, 0xc2},
+		.id_len    = 2,
+		.chipsize  = SZ_128M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 64,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 104),
+			0
+		},
+		.driver    = &spi_nand_driver_no_qe,
+	},
+
+	/* TOSHIBA TC58CVG2S0H 4Gbit */
+	{
+		.name      = "TC58CVG2S0H",
+		.id        = {0x98, 0xcd},
+		.id_len    = 2,
+		.chipsize  = SZ_512M,
+		.erasesize = SZ_256K,
+		.pagesize  = SZ_4K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 104),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_256K(0, SZ_256K, 104),
+			0
+		},
+		.driver    = &spi_nand_driver_no_qe,
+	},
+
+	/* HeYangTek HYF1GQ4UAACAE 1Gbit */
+	{
+		.name      = "HYF1GQ4UAACAE",
+		.id        = {0xc9, 0x51},
+		.id_len    = 2,
+		.chipsize  = SZ_128M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 50),
+			&READ_DUAL(1, INFINITE, 50),
+			&READ_DUAL_ADDR(1, INFINITE, 60),
+			&READ_QUAD(1, INFINITE, 50),
+			&READ_QUAD_ADDR(1, INFINITE, 60),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 80),
+			&WRITE_QUAD(0, 256, 80),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 80),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* HeYangTek HYF2GQ4UAACAE 2Gbit */
+	{
+		.name      = "HYF2GQ4UAACAE",
+		.id        = {0xc9, 0x52},
+		.id_len    = 2,
+		.chipsize  = SZ_256M,
+		.erasesize = SZ_128K,
+		.pagesize  = SZ_2K,
+		.oobsize   = 128,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 50),
+			&READ_DUAL(1, INFINITE, 50),
+			&READ_DUAL_ADDR(1, INFINITE, 60),
+			&READ_QUAD(1, INFINITE, 50),
+			&READ_QUAD_ADDR(1, INFINITE, 60),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 80),
+			&WRITE_QUAD(0, 256, 80),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_128K(0, SZ_128K, 80),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	/* HeYangTek HYF4GQ4UAACBE 4Gbit */
+	{
+		.name      = "HYF4GQ4UAACBE",
+		.id        = {0xc9, 0xd4},
+		.id_len    = 2,
+		.chipsize  = SZ_512M,
+		.erasesize = SZ_256K,
+		.pagesize  = SZ_4K,
+		.oobsize   = 256,
+		.badblock_pos = BBP_FIRST_PAGE,
+		.read      = {
+			&READ_STD(1, INFINITE, 24),
+			&READ_FAST(1, INFINITE, 50),
+			&READ_DUAL(1, INFINITE, 50),
+			&READ_DUAL_ADDR(1, INFINITE, 60),
+			&READ_QUAD(1, INFINITE, 50),
+			&READ_QUAD_ADDR(1, INFINITE, 60),
+			0
+		},
+		.write     = {
+			&WRITE_STD(0, 256, 80),
+			&WRITE_QUAD(0, 256, 80),
+			0
+		},
+		.erase     = {
+			&ERASE_SECTOR_256K(0, SZ_256K, 80),
+			0
+		},
+		.driver    = &spi_nand_driver_general,
+	},
+
+	{	.id_len    = 0,	},
+};
+
+/*****************************************************************************/
+static void hisnfc100_spi_search_rw(struct hisnfc_chip_info *spiinfo,
+				struct spi_op_info *spiop_rw, unsigned iftype,
+				unsigned max_dummy, int rw_type)
+{
+	int ix = 0;
+	struct spi_op_info **spiop, **fitspiop;
+
+	for (fitspiop = spiop = (rw_type ? spiinfo->write : spiinfo->read);
+		(*spiop) && ix < MAX_SPI_NAND_OP; spiop++, ix++)
+		if (((*spiop)->iftype & iftype)
+			&& ((*spiop)->dummy <= max_dummy)
+			&& (*fitspiop)->iftype < (*spiop)->iftype) {
+			fitspiop = spiop;
+		}
+
+	memcpy(spiop_rw, (*fitspiop), sizeof(struct spi_op_info));
+}
+
+/*****************************************************************************/
+static void hisnfc100_spi_get_erase(struct hisnfc_chip_info *spiinfo,
+				struct spi_op_info *spiop_erase)
+{
+	int ix;
+
+	spiop_erase->size = 0;
+	for (ix = 0; ix < MAX_SPI_NAND_OP; ix++) {
+		if (spiinfo->erase[ix] == NULL)
+			break;
+		if (spiinfo->erasesize == spiinfo->erase[ix]->size) {
+			memcpy(&spiop_erase[ix], spiinfo->erase[ix],
+					sizeof(struct spi_op_info));
+			break;
+		}
+	}
+}
+
+/*****************************************************************************/
+static void hisnfc100_map_iftype_and_clock(struct hisnfc_op *spi)
+{
+	int ix;
+	const int iftype_read[] = {
+		SPI_IF_READ_STD,       HISNFC100_IFCYCLE_STD,
+		SPI_IF_READ_FAST,      HISNFC100_IFCYCLE_STD,
+		SPI_IF_READ_DUAL,      HISNFC100_IFCYCLE_DUAL,
+		SPI_IF_READ_DUAL_ADDR, HISNFC100_IFCYCLE_DUAL_ADDR,
+		SPI_IF_READ_QUAD,      HISNFC100_IFCYCLE_QUAD,
+		SPI_IF_READ_QUAD_ADDR, HISNFC100_IFCYCLE_QUAD_ADDR,
+		0, 0,
+	};
+	const int iftype_write[] = {
+		SPI_IF_WRITE_STD,       HISNFC100_IFCYCLE_STD,
+		SPI_IF_WRITE_QUAD,      HISNFC100_IFCYCLE_QUAD,
+		0, 0,
+	};
+
+	for (ix = 0; iftype_write[ix]; ix += 2) {
+		if (spi->write->iftype == iftype_write[ix]) {
+			spi->write->iftype = iftype_write[ix + 1];
+			break;
+		}
+	}
+	hisnfc100_get_best_clock(&spi->write->clock);
+
+	for (ix = 0; iftype_read[ix]; ix += 2) {
+		if (spi->read->iftype == iftype_read[ix]) {
+			spi->read->iftype = iftype_read[ix + 1];
+			break;
+		}
+	}
+	hisnfc100_get_best_clock(&spi->read->clock);
+
+	hisnfc100_get_best_clock(&spi->erase->clock);
+	spi->erase->iftype = HISNFC100_IFCYCLE_STD;
+}
+
+/*****************************************************************************/
+static void hisnfc100_spi_probe(struct hisnfc_host *host,
+				struct hisnfc_chip_info *spi_dev)
+{
+	unsigned regval;
+	struct hisnfc_op *spi = host->spi;
+
+	spi->host = host;
+	spi->driver = spi_dev->driver;
+
+	hisnfc100_spi_search_rw(spi_dev, spi->read, HISNFC100_SUPPORT_READ,
+			HISNFC100_SUPPORT_MAX_DUMMY, SPI_NAND_READ);
+
+	hisnfc100_spi_search_rw(spi_dev, spi->write, HISNFC100_SUPPORT_WRITE,
+			HISNFC100_SUPPORT_MAX_DUMMY, SPI_NAND_WRITE);
+
+	hisnfc100_spi_get_erase(spi_dev, spi->erase);
+	hisnfc100_map_iftype_and_clock(spi);
+
+	if (spi->driver->qe_enable) {
+		if (spi->driver->qe_enable(spi))
+			pr_err("%s set feature QE failed!\n", __func__);
+	}
+
+	spi_feature_op(host, GET_OP, PROTECTION_ADDR, &regval);
+	if (ANY_BP_ENABLE(regval)) {
+		regval &= ~ALL_BP_MASK;
+		spi_feature_op(host, SET_OP, PROTECTION_ADDR, &regval);
+
+		spi->driver->wait_ready(spi);
+
+		spi_feature_op(host, GET_OP, PROTECTION_ADDR, &regval);
+		if (ANY_BP_ENABLE(regval))
+			pr_err("%s write protection disable fail! val[%#x]\n",
+				__func__, regval);
+	}
+
+	spi_feature_op(host, GET_OP, FEATURE_ADDR, &regval);
+	if (regval & FEATURE_ECC_ENABLE) {
+		regval &= ~FEATURE_ECC_ENABLE;
+		spi_feature_op(host, SET_OP, FEATURE_ADDR, &regval);
+
+		spi->driver->wait_ready(spi);
+
+		spi_feature_op(host, GET_OP, FEATURE_ADDR, &regval);
+		if (regval & FEATURE_ECC_ENABLE)
+			pr_err("%s Internal ECC disable fail! val[%#x]\n",
+				__func__, regval);
+	}
+}
+
+static struct nand_flash_dev spi_nand_dev;
+/*****************************************************************************/
+static struct nand_flash_dev *spi_nand_get_flash_info(struct mtd_info *mtd,
+		unsigned char *id)
+{
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct hisnfc_host *host = chip->priv;
+	struct hisnfc_chip_info *spi_dev = hisnfc_spi_nand_flash_table;
+	unsigned char ix = 0, len = 0, buffer[100];
+	struct nand_flash_dev *flash_type = &spi_nand_dev;
+
+	len = sprintf(buffer, "SPI Nand(cs %d) ID: %#x %#x",
+			host->cmd_option.chipselect, id[0], id[1]);
+
+	for (; spi_dev->id_len; spi_dev++) {
+		if (memcmp(id, spi_dev->id, spi_dev->id_len))
+			continue;
+
+		for (ix = 2; ix < spi_dev->id_len; ix++)
+			len += sprintf(buffer + len, " %#x", id[ix]);
+		pr_info("%s\n", buffer);
+
+		flash_type->name = spi_dev->name;
+		memcpy(flash_type->id, spi_dev->id, spi_dev->id_len);
+		flash_type->pagesize  = spi_dev->pagesize;
+		flash_type->chipsize = spi_dev->chipsize >> 20;
+		flash_type->erasesize = spi_dev->erasesize;
+		flash_type->oobsize = spi_dev->oobsize;
+
+		mtd->size = spi_dev->chipsize;
+		mtd->oobsize = spi_dev->oobsize;
+		mtd->erasesize = spi_dev->erasesize;
+		mtd->writesize = spi_dev->pagesize;
+		chip->chipsize = spi_dev->chipsize;
+
+		if (host->mtd != mtd)
+			host->mtd = mtd;
+		hisnfc100_spi_probe(host, spi_dev);
+
+		return flash_type;
+	}
+
+	return NULL;
+}
+
+/*****************************************************************************/
+void spi_nand_ids_register(void)
+{
+	pr_info("SPI Nand ID Table Version %s\n", SPI_NAND_ID_TAB_VER);
+	get_spi_nand_flash_type_hook = spi_nand_get_flash_info;
+}
+
diff --git a/drivers/mtd/nand/hisnfc100/hisnfc100_spi_ids.h b/drivers/mtd/nand/hisnfc100/hisnfc100_spi_ids.h
new file mode 100644
index 0000000..77cdcc3
--- /dev/null
+++ b/drivers/mtd/nand/hisnfc100/hisnfc100_spi_ids.h
@@ -0,0 +1,148 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef HISFC_SPI_IDSH
+#define HISFC_SPI_IDSH
+
+/*****************************************************************************/
+#define INFINITE			(0xFFFFFFFF)
+
+#define DEFAULT_ID_LEN			2
+#define MAX_ID_LEN			3
+#define MAX_SPI_NAND_OP			8
+
+#define BBP_LAST_PAGE			0x01
+#define BBP_FIRST_PAGE			0x02
+
+/*****************************************************************************/
+#define SPI_IF_READ_STD			(0x01)
+#define SPI_IF_READ_FAST		(0x02)
+#define SPI_IF_READ_DUAL		(0x04)
+#define SPI_IF_READ_DUAL_ADDR		(0x08)
+#define SPI_IF_READ_QUAD		(0x10)
+#define SPI_IF_READ_QUAD_ADDR		(0x20)
+
+#define SPI_IF_WRITE_STD		(0x01)
+#define SPI_IF_WRITE_DUAL		(0x02)
+#define SPI_IF_WRITE_DUAL_ADDR		(0x04)
+#define SPI_IF_WRITE_QUAD		(0x08)
+#define SPI_IF_WRITE_QUAD_ADDR		(0x10)
+
+#define SPI_IF_ERASE_SECTOR_128K	(0x08)  /* 128K */
+#define SPI_IF_ERASE_SECTOR_256K	(0x10)  /* 256K */
+
+/******************************************************************************/
+#define HISNFC100_SUPPORT_READ		(SPI_IF_READ_STD \
+					| SPI_IF_READ_FAST \
+					| SPI_IF_READ_DUAL \
+					| SPI_IF_READ_DUAL_ADDR \
+					| SPI_IF_READ_QUAD \
+					| SPI_IF_READ_QUAD_ADDR)
+
+#define HISNFC100_SUPPORT_WRITE		(SPI_IF_WRITE_STD | SPI_IF_WRITE_QUAD)
+
+#define HISNFC100_SUPPORT_MAX_DUMMY	8
+
+#define SPI_NAND_READ			0
+#define SPI_NAND_WRITE			1
+
+#define HISNFC100_IFCYCLE_STD				0
+#define HISNFC100_IFCYCLE_DUAL				1
+#define HISNFC100_IFCYCLE_DUAL_ADDR			2
+#define HISNFC100_IFCYCLE_QUAD				3
+#define HISNFC100_IFCYCLE_QUAD_ADDR			4
+
+/*****************************************************************************/
+#define SPI_CMD_WREN			0x06   /* Write Enable */
+#define SPI_CMD_WRDI			0x04   /* Write Disable */
+
+#define SPI_CMD_GET_FEATURES		0x0F   /* Get Features */
+#define SPI_CMD_SET_FEATURE		0x1F   /* Set Feature */
+
+#define SPI_CMD_PAGE_READ		0x13   /* Page Read to Cache */
+#define SPI_CMD_READ_STD	0x03   /* Read From Cache at Standard Speed */
+#define SPI_CMD_READ_FAST	0x0B   /* Read From Cache at Higher Speed */
+#define SPI_CMD_READ_DUAL	0x3B   /* Read From Cache at Dual Output */
+#define SPI_CMD_READ_QUAD	0x6B   /* Read From Cache at Quad Output */
+#define SPI_CMD_READ_DUAL_ADDR	0xBB   /* Read From Cache at Dual I/O */
+#define SPI_CMD_READ_QUAD_ADDR	0xEB   /* Read From Cache at Quad I/O */
+
+#define SPI_CMD_RDID			0x9F   /* Read Identification */
+
+#define SPI_CMD_WRITE_STD	0x02   /* Page Load at Standard Input */
+#define SPI_CMD_WRITE_QUAD	0x32   /* Page Load at Quad Input */
+
+#define SPI_CMD_SE_128K			0xD8   /* 128KB sector Erase */
+#define SPI_CMD_SE_256K			0xD8   /* 256KB sector Erase */
+
+#define SPI_CMD_RESET			0xff   /* Reset the device */
+
+/*****************************************************************************/
+/* SPI operation information */
+struct spi_op_info {
+	unsigned char  iftype;
+	unsigned char  cmd;
+	unsigned char  dummy;
+	unsigned int   size;
+	unsigned int   clock;
+};
+
+struct spi_nand_driver;
+
+struct hisnfc_op {
+	void *host;
+	struct spi_nand_driver *driver;
+	struct spi_op_info  read[1];
+	struct spi_op_info  write[1];
+	struct spi_op_info  erase[MAX_SPI_NAND_OP];
+};
+
+struct spi_nand_driver {
+	int (*wait_ready)(struct hisnfc_op *spi);
+	int (*write_enable)(struct hisnfc_op *spi);
+	int (*qe_enable)(struct hisnfc_op *spi);
+};
+
+struct hisnfc_chip_info {
+	char *name;
+	unsigned char id[MAX_ID_LEN];
+	unsigned char id_len;
+	unsigned long long chipsize;
+	unsigned int erasesize;
+	unsigned int pagesize;
+	unsigned int oobsize;
+	unsigned int badblock_pos;
+	struct spi_op_info *read[MAX_SPI_NAND_OP];
+	struct spi_op_info *write[MAX_SPI_NAND_OP];
+	struct spi_op_info *erase[MAX_SPI_NAND_OP];
+	struct spi_nand_driver *driver;
+};
+
+/*****************************************************************************/
+void spi_nand_ids_register(void);
+
+void hisnfc100_get_best_clock(unsigned int *clock);
+
+struct hisnfc_host;
+
+void spi_feature_op(struct hisnfc_host *host, int op, int addr, unsigned *val);
+
+/******************************************************************************/
+
+#endif /* HISFC_SPI_IDSH */
+
diff --git a/drivers/mtd/nand/match_table.c b/drivers/mtd/nand/match_table.c
new file mode 100644
index 0000000..271da05
--- /dev/null
+++ b/drivers/mtd/nand/match_table.c
@@ -0,0 +1,96 @@
+/******************************************************************************
+ *    COPYRIGHT (C) Hisilicon.2013
+ *    All rights reserved.
+ * ***
+ *    Create by Hisilicon 2013-08-15
+ *
+ *****************************************************************************/
+
+/*****************************************************************************/
+#include <linux/string.h>
+#include "match_table.h"
+
+/*****************************************************************************/
+int reg2type(struct match_reg_type *table, int length, int reg, int def)
+{
+	while (length-- > 0) {
+		if (table->reg == reg)
+			return table->type;
+		table++;
+	}
+	return def;
+}
+
+int type2reg(struct match_reg_type *table, int length, int type, int def)
+{
+	while (length-- > 0) {
+		if (table->type == type)
+			return table->reg;
+		table++;
+	}
+	return def;
+}
+
+int str2type(struct match_type_str *table, int length, const char *str,
+	     int size, int def)
+{
+	while (length-- > 0) {
+		if (!strncmp(table->str, str, size))
+			return table->type;
+		table++;
+	}
+	return def;
+}
+
+const char *type2str(struct match_type_str *table, int length, int type,
+		     const char *def)
+{
+	while (length-- > 0) {
+		if (table->type == type)
+			return table->str;
+		table++;
+	}
+	return def;
+}
+
+int match_reg_to_type(struct match_t *table, int nr_table, int reg, int def)
+{
+	while (nr_table-- > 0) {
+		if (table->reg == reg)
+			return table->type;
+		table++;
+	}
+	return def;
+}
+
+int match_type_to_reg(struct match_t *table, int nr_table, int type, int def)
+{
+	while (nr_table-- > 0) {
+		if (table->type == type)
+			return table->reg;
+		table++;
+	}
+	return def;
+}
+
+int match_data_to_type(struct match_t *table, int nr_table, char *data,
+		int size, int def)
+{
+	while (nr_table-- > 0) {
+		if (!memcmp(table->data, data, size))
+			return table->type;
+		table++;
+	}
+	return def;
+}
+
+void *match_type_to_data(struct match_t *table, int nr_table, int type,
+			 void *def)
+{
+	while (nr_table-- > 0) {
+		if (table->type == type)
+			return table->data;
+		table++;
+	}
+	return def;
+}
diff --git a/drivers/mtd/nand/match_table.h b/drivers/mtd/nand/match_table.h
new file mode 100644
index 0000000..6fb55cf
--- /dev/null
+++ b/drivers/mtd/nand/match_table.h
@@ -0,0 +1,56 @@
+/******************************************************************************
+ *    COPYRIGHT (C) Hisilicon 2013
+ *    All rights reserved.
+ * ***
+ *    Create by Hisilicon 2013-08-15
+ *
+ *****************************************************************************/
+#ifndef __MATCH_TABLE_H__
+#define __MATCH_TABLE_H__
+
+/*****************************************************************************/
+struct match_reg_type {
+	int reg;
+	int type;
+};
+
+struct match_type_str {
+	int type;
+	const char *str;
+};
+
+struct match_t {
+	int type;
+	int reg;
+	void *data;
+};
+
+/*****************************************************************************/
+#define MATCH_SET_TYPE_REG(_type, _reg)   {(_type), (_reg), (void *)0}
+#define MATCH_SET_TYPE_DATA(_type, _data) {(_type), 0, (void *)(_data)}
+#define MATCH_SET(_type, _reg, _data)     {(_type), (_reg), (void *)(_data)}
+
+/*****************************************************************************/
+int reg2type(struct match_reg_type *table, int length, int reg, int def);
+
+int type2reg(struct match_reg_type *table, int length, int type, int def);
+
+int str2type(struct match_type_str *table, int length, const char *str,
+	     int size, int def);
+
+const char *type2str(struct match_type_str *table, int length, int type,
+		     const char *def);
+
+int match_reg_to_type(struct match_t *table, int nr_table, int reg, int def);
+
+int match_type_to_reg(struct match_t *table, int nr_table, int type, int def);
+
+int match_data_to_type(struct match_t *table, int nr_table, char *data,
+		int size, int def);
+
+void *match_type_to_data(struct match_t *table, int nr_table, int type,
+			 void *def);
+
+/*****************************************************************************/
+
+#endif /* End of __MATCH_TABLE_H__ */
diff --git a/drivers/mtd/nand/nand_base.c b/drivers/mtd/nand/nand_base.c
index f222f8a..8a5e25d0 100644
--- a/drivers/mtd/nand/nand_base.c
+++ b/drivers/mtd/nand/nand_base.c
@@ -47,6 +47,8 @@
 #include <linux/mtd/partitions.h>
 #include <linux/of.h>
 
+#include "hinfc_gen.h"
+
 static int nand_get_device(struct mtd_info *mtd, int new_state);
 
 static int nand_do_write_oob(struct mtd_info *mtd, loff_t to,
@@ -4058,7 +4060,7 @@ static struct nand_flash_dev *nand_get_flash_type(struct mtd_info *mtd,
 						  int *maf_id, int *dev_id,
 						  struct nand_flash_dev *type)
 {
-	int busw;
+	int busw = 0;
 	int i, maf_idx;
 	u8 id_data[8];
 
@@ -4097,6 +4099,30 @@ static struct nand_flash_dev *nand_get_flash_type(struct mtd_info *mtd,
 		return ERR_PTR(-ENODEV);
 	}
 
+#if defined(CONFIG_MTD_NAND_HISNFC100) || defined(CONFIG_MTD_SPI_NAND_HIFMC100)
+	/* SPI Nand Flash*/
+	if (get_spi_nand_flash_type_hook)
+		type = get_spi_nand_flash_type_hook(mtd, id_data);
+
+	/* SPI Nand Flash only can support the devices on id table */
+	if (!type) {
+		pr_info("This device[%02x,%02x] cannot found in spi nand id table!!\n",
+				*maf_id, *dev_id);
+		return ERR_PTR(-ENODEV);
+	} else
+		goto ident_done;
+
+#elif defined(CONFIG_MTD_NAND_HINFC610) || defined(CONFIG_MTD_NAND_HIFMC100)
+	/* Parallel Nand Flash */
+
+	/* The 3rd id byte holds MLC / multichip data */
+	chip->bits_per_cell = nand_get_bits_per_cell(id_data[2]);
+
+	type = hinfc_get_flash_type(mtd, chip, id_data, &busw);
+	if (type)
+		goto ident_done;
+#endif
+
 	if (!type)
 		type = nand_flash_ids;
 
@@ -4144,6 +4170,9 @@ static struct nand_flash_dev *nand_get_flash_type(struct mtd_info *mtd,
 	if (*maf_id != NAND_MFR_SAMSUNG && !type->pagesize)
 		chip->options &= ~NAND_SAMSUNG_LP_OPTIONS;
 ident_done:
+#ifdef CONFIG_ARCH_HISI_BVT
+	hinfc_nand_param_adjust(mtd, chip);
+#endif
 
 	/* Try to identify manufacturer */
 	for (maf_idx = 0; nand_manuf_ids[maf_idx].id != 0x0; maf_idx++) {
@@ -4205,9 +4234,13 @@ static struct nand_flash_dev *nand_get_flash_type(struct mtd_info *mtd,
 		pr_info("%s %s\n", nand_manuf_ids[maf_idx].name,
 				type->name);
 
-	pr_info("%d MiB, %s, erase size: %d KiB, page size: %d, OOB size: %d\n",
+	pr_info("%dMiB, %s, page size: %d\n",
 		(int)(chip->chipsize >> 20), nand_is_slc(chip) ? "SLC" : "MLC",
-		mtd->erasesize >> 10, mtd->writesize, mtd->oobsize);
+		mtd->writesize);
+
+	/* Print ecc type and ecc mode about hisilicon flash controller */
+	hinfc_show_info(mtd, nand_manuf_ids[maf_idx].name, type->name);
+
 	return type;
 }
 
@@ -4727,7 +4760,7 @@ int nand_scan_tail(struct mtd_info *mtd)
 		break;
 
 	case NAND_ECC_NONE:
-		pr_warn("NAND_ECC_NONE selected by board driver. This is not recommended!\n");
+		pr_warn(" ECC provided by Flash Memory Controller\n");
 		ecc->read_page = nand_read_page_raw;
 		ecc->write_page = nand_write_page_raw;
 		ecc->read_oob = nand_read_oob_std;
@@ -4814,8 +4847,13 @@ int nand_scan_tail(struct mtd_info *mtd)
 		break;
 	}
 
+#ifdef CONFIG_MTD_UBI
+	/* mtd->type = MTD_MLCNANDFLASH isn't support by mtd_util ubi tools jet */
+	mtd->type = MTD_NANDFLASH;
+#else
 	/* Fill in remaining MTD driver data */
 	mtd->type = nand_is_slc(chip) ? MTD_NANDFLASH : MTD_MLCNANDFLASH;
+#endif
 	mtd->flags = (chip->options & NAND_ROM) ? MTD_CAP_ROM :
 						MTD_CAP_NANDFLASH;
 	mtd->_erase = nand_erase;
diff --git a/drivers/mtd/nand/nand_ids.c b/drivers/mtd/nand/nand_ids.c
index 2af9869..eae2460 100644
--- a/drivers/mtd/nand/nand_ids.c
+++ b/drivers/mtd/nand/nand_ids.c
@@ -168,7 +168,7 @@ struct nand_flash_dev nand_flash_ids[] = {
 /* Manufacturer IDs */
 struct nand_manufacturers nand_manuf_ids[] = {
 	{NAND_MFR_TOSHIBA, "Toshiba"},
-	{NAND_MFR_ESMT, "ESMT"},
+	{NAND_MFR_GD_ESMT,	"GD/ESMT"},
 	{NAND_MFR_SAMSUNG, "Samsung"},
 	{NAND_MFR_FUJITSU, "Fujitsu"},
 	{NAND_MFR_NATIONAL, "National"},
@@ -179,9 +179,15 @@ struct nand_manufacturers nand_manuf_ids[] = {
 	{NAND_MFR_AMD, "AMD/Spansion"},
 	{NAND_MFR_MACRONIX, "Macronix"},
 	{NAND_MFR_EON, "Eon"},
+	{NAND_MFR_WINBOND,	"Winbond"},
+	{NAND_MFR_ATO,		"ATO"},
+	{NAND_MFR_MXIC,		"MXIC"},
+	{NAND_MFR_ALL_FLASH,	"All-flash"},
+	{NAND_MFR_PARAGON,	"Paragon"},
 	{NAND_MFR_SANDISK, "SanDisk"},
 	{NAND_MFR_INTEL, "Intel"},
 	{NAND_MFR_ATO, "ATO"},
+	{NAND_MFR_HEYANGTEK, "HeYangTek"},
 	{0x0, "Unknown"}
 };
 
diff --git a/drivers/mtd/spi-nor/Kconfig b/drivers/mtd/spi-nor/Kconfig
index 4a682ee..b72cf27 100644
--- a/drivers/mtd/spi-nor/Kconfig
+++ b/drivers/mtd/spi-nor/Kconfig
@@ -59,11 +59,12 @@ config SPI_FSL_QUADSPI
 	  SPI NOR.
 
 config SPI_HISI_SFC
-	tristate "Hisilicon SPI-NOR Flash Controller(SFC)"
-	depends on ARCH_HISI || COMPILE_TEST
+	tristate "Hisilicon FMCV100 SPI-NOR Flash Controller(SFC)"
+	depends on ARCH_HISI || ARCH_HISI_BVT || COMPILE_TEST
 	depends on HAS_IOMEM && HAS_DMA
 	help
-	  This enables support for hisilicon SPI-NOR flash controller.
+	  This enables support for hisilicon flash memory contrller ver100
+	  (FMCV100)- SPI-NOR flash controller.
 
 config SPI_NXP_SPIFI
 	tristate "NXP SPI Flash Interface (SPIFI)"
@@ -76,4 +77,34 @@ config SPI_NXP_SPIFI
 	  Flash. Enable this option if you have a device with a SPIFI
 	  controller and want to access the Flash as a mtd device.
 
+config MTD_SPI_IDS
+    bool "SPI Flash Timing Cycles Probe Function"
+    default n
+    help
+      This option enables hisfc300/hisfc350 used spi flash timing cylces
+      probe function.
+      If your use hisfc300 and hisfc350, this function should be select.
+
+config CLOSE_SPI_8PIN_4IO
+	bool "Close SPI device Quad SPI mode for some 8PIN chip"
+	default y if ARCH_HISI_BVT
+	help
+	Hifmcv100 and Hisfcv350 support Quad SPI mode and Quad&addr SPI mode.
+	But some 8PIN chip does not support this mode when HOLD/IO3 PIN
+	was used by reset operation.
+	Usually, your should not config this option.
+
+config HISI_SPI_BLOCK_PROTECT
+	bool "Hisilicon Spi Nor Device BP(Block Protect) Support"
+	depends on SPI_HISI_SFC
+	default y if SPI_HISI_SFC
+	help
+	  HISI SFC supports BP(Block Protect) feature to preestablish a series
+	  area to avoid writing and erasing, except to reading. With this macro
+	  definition we can get the BP info which was setted before. The
+	  BOTTOM/TOP bit is setted to BOTTOM, it means the lock area starts
+	  from 0 address.
+
+source "drivers/mtd/spi-nor/hisfc350/Kconfig"
+
 endif # MTD_SPI_NOR
diff --git a/drivers/mtd/spi-nor/Makefile b/drivers/mtd/spi-nor/Makefile
index 121695e..ac5d355 100644
--- a/drivers/mtd/spi-nor/Makefile
+++ b/drivers/mtd/spi-nor/Makefile
@@ -5,3 +5,6 @@ obj-$(CONFIG_SPI_FSL_QUADSPI)	+= fsl-quadspi.o
 obj-$(CONFIG_SPI_HISI_SFC)	+= hisi-sfc.o
 obj-$(CONFIG_MTD_MT81xx_NOR)    += mtk-quadspi.o
 obj-$(CONFIG_SPI_NXP_SPIFI)	+= nxp-spifi.o
+
+obj-$(CONFIG_MTD_SPI_IDS)   += spi_ids.o
+obj-$(CONFIG_MTD_HISFC350)  += hisfc350/
diff --git a/drivers/mtd/spi-nor/hisfc350/Kconfig b/drivers/mtd/spi-nor/hisfc350/Kconfig
new file mode 100644
index 0000000..a999c92
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/Kconfig
@@ -0,0 +1,51 @@
+#
+# hisilicon spi flash controller device version 350
+#
+
+menuconfig MTD_HISFC350
+	tristate "hisilicon spi flash controller device version 350 driver"
+	depends on (ARCH_HI3516A)
+	default y if (ARCH_HI3516A)
+	select MTD_SPI_IDS
+	help
+	  Hisilicon spi flash controller device version 350.
+	  Hisilicon spi flash controller version 350 support
+	  DMA transfers while reading and write the spi flash,
+	  which will improve the performace very much.
+
+if MTD_HISFC350
+
+config HISFC350_SYSCTRL_ADDRESS
+	hex "cpu system control register base address"
+	default "0x20030000" if (ARCH_HI3516A)
+
+config HISFC350_CHIP_NUM
+	int "hisfc350 spi chip number"
+	default 2 if (ARCH_HI3516A)
+
+config HISFC350_SHOW_CYCLE_TIMING
+	bool "show spi read/write/erase cycle timing"
+	default n if (ARCH_HI3516A)
+	help
+	  Show spi read/write/erase cycle timing, command, clock.
+	  This is a debug option. When enabled, some command and
+	  cycles uesed on operations will show for you.
+	  If unsure, say no.
+
+config HISFC350_ENABLE_CHIPSELECT_0
+	bool "use spi device on chipselect 0"
+	default n if (ARCH_HI3516A)
+
+config HISFC350_ENABLE_CHIPSELECT_1
+	bool "use spi device on chipselect 1"
+	default y if (ARCH_HI3516A)
+
+config HISFC350_ENABLE_INTR_DMA
+	bool "use the IRQ mode of spi device R/W"
+	default n if (ARCH_HI3516A)
+
+config CMD_SPI_BLOCK_PROTECTION
+	bool "enable the SPI nor flash block protection"
+	default y if (ARCH_HI3516A)
+
+endif # MTD_HISFC350
diff --git a/drivers/mtd/spi-nor/hisfc350/Makefile b/drivers/mtd/spi-nor/hisfc350/Makefile
new file mode 100644
index 0000000..bc5f400
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/Makefile
@@ -0,0 +1,7 @@
+#
+# drivers/devices/hisfc350/Makefile
+#
+
+obj-$(CONFIG_MTD_HISFC350)     += hisfc350_spi_ids.o hisfc350.o
+
+
diff --git a/drivers/mtd/spi-nor/hisfc350/hisfc350.c b/drivers/mtd/spi-nor/hisfc350/hisfc350.c
new file mode 100644
index 0000000..0e7f82c
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/hisfc350.c
@@ -0,0 +1,1555 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+/*****************************************************************************/
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/interrupt.h>
+#include <linux/slab.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/partitions.h>
+#include <linux/delay.h>
+#include <linux/sched.h>
+#include <asm/setup.h>
+#include <linux/io.h>
+#include <linux/dma-mapping.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/iopoll.h>
+#include <linux/clk.h>
+
+#include "../../mtdcore.h"
+#include "../spi_ids.h"
+#include "hisfc350.h"
+
+#define THREE_BYTE_ADDR_BOOT 0
+
+#ifdef CONFIG_ARCH_HI3516A
+#include "hisfc350_hi3516a.c"
+#endif
+
+#ifndef GET_SFC_ADDR_MODE
+#define GET_SFC_ADDR_MODE  (0)
+#endif
+
+/* Don't change the follow config */
+#define HISFC350_SUPPORT_READ (SPI_IF_READ_STD \
+	| SPI_IF_READ_FAST \
+	| SPI_IF_READ_DUAL \
+	| SPI_IF_READ_DUAL_ADDR \
+	| SPI_IF_READ_QUAD \
+	| SPI_IF_READ_QUAD_ADDR)
+
+#define HISFC350_SUPPORT_WRITE (SPI_IF_WRITE_STD \
+	| SPI_IF_WRITE_DUAL \
+	| SPI_IF_WRITE_DUAL_ADDR \
+	| SPI_IF_WRITE_QUAD \
+	| SPI_IF_WRITE_QUAD_ADDR)
+
+#define HISFC350_SUPPORT_MAX_DUMMY        (7)
+
+#ifdef CONFIG_HISFC350_ENABLE_INTR_DMA
+static loff_t sfc_ft;
+static size_t sfc_length;
+static int sfc_num;
+static unsigned char *sfc_offset;
+static unsigned int sfc_rw;
+#endif
+
+static int  start_up_mode;
+
+static char *ultohstr(unsigned long long size)
+{
+	int ix;
+	static char buffer[20];
+	char *fmt[] = {"%u", "%uK", "%uM", "%uG", "%uT", "%uT"};
+
+	for (ix = 0; (ix < 5) && !(size & 0x3FF) && size; ix++)
+		size = (size >> 10);
+
+	sprintf(buffer, fmt[ix], size);
+	return buffer;
+}
+
+#ifdef CONFIG_HISFC350_SHOW_CYCLE_TIMING
+static char *hisfc350_get_ifcycle_str(int ifcycle)
+{
+	static char *ifcycle_str[] = {
+		"single",
+		"dual",
+		"dual-addr",
+		"dual-cmd",
+		"reserve",
+		"quad",
+		"quad-addr",
+		"quad-cmd",
+	};
+
+	return ifcycle_str[(ifcycle & 0x07)];
+}
+#endif
+
+static void hisfc350_set_host_addr_mode(struct hisfc_host *host, int enable)
+{
+	unsigned int regval;
+	regval = hisfc_read(host, HISFC350_GLOBAL_CONFIG);
+	if (enable)
+		regval |= HISFC350_GLOBAL_CONFIG_ADDR_MODE_4B;
+	else
+		regval &= ~HISFC350_GLOBAL_CONFIG_ADDR_MODE_4B;
+
+	hisfc_write(host, HISFC350_GLOBAL_CONFIG, regval);
+}
+
+static void hisfc350_spi_nor_shutdown(struct platform_device *pdev)
+{
+	if (start_up_mode == THREE_BYTE_ADDR_BOOT) {
+		int ix;
+
+		struct hisfc_host *host = platform_get_drvdata(pdev);
+		struct hisfc_spi *spi = host->spi;
+
+		for (ix = 0; ix < host->num_chip; ix++, spi++) {
+			if (spi->addrcycle == SPI_4BYTE_ADDR_LEN) {
+				spi->driver->wait_ready(spi);
+				spi->driver->entry_4addr(spi, 0);
+			}
+		}
+	}
+}
+static void hisfc350_map_iftype_and_clock(struct hisfc_spi *spi)
+{
+	int ix;
+	const int iftype_read[] = {
+		SPI_IF_READ_STD,       HISFC350_IFCYCLE_STD,
+		SPI_IF_READ_FAST,      HISFC350_IFCYCLE_STD,
+		SPI_IF_READ_DUAL,      HISFC350_IFCYCLE_DUAL,
+		SPI_IF_READ_DUAL_ADDR, HISFC350_IFCYCLE_DUAL_ADDR,
+		SPI_IF_READ_QUAD,      HISFC350_IFCYCLE_QUAD,
+		SPI_IF_READ_QUAD_ADDR, HISFC350_IFCYCLE_QUAD_ADDR,
+		0, 0,
+	};
+	const int iftype_write[] = {
+		SPI_IF_WRITE_STD,       HISFC350_IFCYCLE_STD,
+		SPI_IF_WRITE_DUAL,      HISFC350_IFCYCLE_DUAL,
+		SPI_IF_WRITE_DUAL_ADDR, HISFC350_IFCYCLE_DUAL_ADDR,
+		SPI_IF_WRITE_QUAD,      HISFC350_IFCYCLE_QUAD,
+		SPI_IF_WRITE_QUAD_ADDR, HISFC350_IFCYCLE_QUAD_ADDR,
+		0, 0,
+	};
+
+	for (ix = 0; iftype_write[ix]; ix += 2) {
+		if (spi->write->iftype == iftype_write[ix]) {
+			spi->write->iftype = iftype_write[ix + 1];
+			break;
+		}
+	}
+	hisfc350_get_best_clock(&spi->write->clock);
+
+	for (ix = 0; iftype_read[ix]; ix += 2) {
+		if (spi->read->iftype == iftype_read[ix]) {
+			spi->read->iftype = iftype_read[ix + 1];
+			break;
+		}
+	}
+	hisfc350_get_best_clock(&spi->read->clock);
+
+	hisfc350_get_best_clock(&spi->erase->clock);
+	spi->erase->iftype = HISFC350_IFCYCLE_STD;
+}
+
+static void hisfc350_dma_transfer(struct hisfc_host *host,
+	loff_t spi_start_addr, unsigned char *dma_buffer,
+	unsigned char is_read, size_t size, unsigned char chipselect)
+{
+	hisfc_write(host, HISFC350_BUS_DMA_MEM_SADDR, dma_buffer);
+
+	hisfc_write(host, HISFC350_BUS_DMA_FLASH_SADDR,
+		(u32)spi_start_addr);
+
+	hisfc_write(host, HISFC350_BUS_DMA_LEN,
+		HISFC350_BUS_DMA_LEN_DATA_CNT(size));
+
+	hisfc_write(host, HISFC350_BUS_DMA_AHB_CTRL,
+		HISFC350_BUS_DMA_AHB_CTRL_INCR4_EN
+		| HISFC350_BUS_DMA_AHB_CTRL_INCR8_EN
+		| HISFC350_BUS_DMA_AHB_CTRL_INCR16_EN);
+
+	hisfc_write(host, HISFC350_BUS_DMA_CTRL,
+		HISFC350_BUS_DMA_CTRL_RW(is_read)
+		| HISFC350_BUS_DMA_CTRL_CS(chipselect)
+		| HISFC350_BUS_DMA_CTRL_START);
+
+#ifndef CONFIG_HISFC350_ENABLE_INTR_DMA
+	HISFC350_DMA_WAIT_CPU_FINISH(host);
+#endif
+}
+
+#ifdef HISFCV350_SUPPORT_REG_READ
+static char *hisfc350_reg_read_buf(struct hisfc_host *host,
+	struct hisfc_spi *spi, loff_t spi_start_addr,
+	unsigned int size, unsigned char *buffer)
+{
+	int index = 0;
+
+	if (size > HISFC350_REG_BUF_SIZE)
+		DBG_BUG("reg read out of reg range.\n");
+
+	hisfc_write(host, HISFC350_CMD_INS, spi->read->cmd);
+	hisfc_write(host, HISFC350_CMD_ADDR,
+		((u32)spi_start_addr & HISFC350_CMD_ADDR_MASK));
+	hisfc_write(host, HISFC350_CMD_CONFIG,
+		HISFC350_CMD_CONFIG_MEM_IF_TYPE(spi->read->iftype)
+		| HISFC350_CMD_CONFIG_DATA_CNT(size)
+		| HISFC350_CMD_CONFIG_RW_READ
+		| HISFC350_CMD_CONFIG_DATA_EN
+		| HISFC350_CMD_CONFIG_DUMMY_CNT(spi->read->dummy)
+		| HISFC350_CMD_CONFIG_ADDR_EN
+		| HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+		| HISFC350_CMD_CONFIG_START);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	while (index < size) {
+		*(unsigned int *)(host->reg_buffer + index) = hisfc_read(host,
+			HISFC350_CMD_DATABUF0 + index);
+		index    += 4;
+	}
+
+	memcpy(buffer, host->reg_buffer, size);
+
+	return buffer;
+}
+
+static int hisfc350_reg_read(struct mtd_info *mtd, loff_t from, size_t len,
+	size_t *retlen, u_char *buf)
+{
+	int num;
+	int result = -EIO;
+	unsigned char *ptr = buf;
+	struct hisfc_host *host = MTD_TO_HOST(mtd);
+	struct hisfc_spi *spi = host->spi;
+
+	if ((from + len) > mtd->size) {
+		DBG_MSG("read area out of range.\n");
+		return -EINVAL;
+	}
+
+	*retlen = 0;
+	if (!len) {
+		DBG_MSG("read length is 0.\n");
+		return 0;
+	}
+	mutex_lock(&host->lock);
+
+	if (spi->driver->wait_ready(spi))
+		goto fail;
+	host->set_system_clock(host, spi->read, TRUE);
+
+	while (len > 0) {
+		while (from >= spi->chipsize) {
+			from -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("read memory out of range.\n");
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+			host->set_system_clock(host, spi->read, TRUE);
+		}
+
+		num = ((from + len) >= spi->chipsize)
+			? (spi->chipsize - from) : len;
+
+		while (num >= HISFC350_REG_BUF_SIZE) {
+			hisfc350_reg_read_buf(host, spi,
+				from, HISFC350_REG_BUF_SIZE, ptr);
+			ptr  += HISFC350_REG_BUF_SIZE;
+			from += HISFC350_REG_BUF_SIZE;
+			len  -= HISFC350_REG_BUF_SIZE;
+			num  -= HISFC350_REG_BUF_SIZE;
+		}
+
+		if (num) {
+			hisfc350_reg_read_buf(host, spi,
+				from, num, ptr);
+			from += num;
+			ptr  += num;
+			len  -= num;
+		}
+	}
+	result = 0;
+	*retlen = (size_t)(ptr - buf);
+fail:
+	mutex_unlock(&host->lock);
+	return result;
+}
+#endif /* HISFCV350_SUPPORT_REG_READ */
+
+#ifdef CONFIG_HISFC350_ENABLE_INTR_DMA
+static int hisfc350_dma_intr_read(struct mtd_info *mtd, loff_t from, size_t len,
+	size_t *retlen, u_char *buf)
+{
+	int result = -EIO;
+	struct hisfc_host *host = MTD_TO_HOST(mtd);
+	struct hisfc_spi *spi = host->spi;
+
+	if ((from + len) > mtd->size) {
+		DBG_MSG("read area out of range.\n");
+		return -EINVAL;
+	}
+
+	*retlen = 0;
+	if (!len) {
+		DBG_MSG("read length is 0.\n");
+		return 0;
+	}
+
+	mutex_lock(&host->lock);
+
+	sfc_offset = (unsigned char *)buf;
+	sfc_ft = from;
+	sfc_length = len;
+	sfc_rw = READ;
+	if (spi->driver->wait_ready(spi))
+		goto fail;
+	spi->driver->bus_prepare(spi, READ);
+
+	if (sfc_ft & HISFC350_DMA_ALIGN_MASK) {
+		sfc_num = HISFC350_DMA_ALIGN_SIZE -
+			(sfc_ft & HISFC350_DMA_ALIGN_MASK);
+		if (sfc_num > sfc_length)
+			sfc_num = sfc_length;
+		while (sfc_ft >= spi->chipsize) {
+			sfc_ft -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("write memory out of range.\n");
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+			spi->driver->bus_prepare(spi, sfc_rw);
+		}
+	} else{
+		while (sfc_ft >= spi->chipsize) {
+			sfc_ft -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("read memory out of range.\n");
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+			spi->driver->bus_prepare(spi, sfc_rw);
+		}
+		if ((sfc_ft + sfc_length) >= spi->chipsize) {
+			sfc_num = spi->chipsize - sfc_ft;
+			if (sfc_num >= HISFC350_DMA_MAX_SIZE)
+				sfc_num = HISFC350_DMA_MAX_SIZE;
+		} else{
+			sfc_num = sfc_length;
+			if (sfc_num >= HISFC350_DMA_MAX_SIZE)
+				sfc_num = HISFC350_DMA_MAX_SIZE;
+		}
+	}
+
+	hisfc350_dma_transfer(host, sfc_ft,
+		(unsigned char *)host->dma_buffer, sfc_rw,
+		sfc_num, spi->chipselect);
+	wait_event(host->intr_wait, host->wait_fg == SFC_WAIT_FLAG_R);
+	host->wait_fg = 0;
+	result = 0;
+	*retlen = (size_t)(sfc_offset - buf);
+fail:
+	mutex_unlock(&host->lock);
+	return result;
+}
+#else
+static int hisfc350_dma_read(struct mtd_info *mtd, loff_t from, size_t len,
+	size_t *retlen, u_char *buf)
+{
+	int num;
+	int result = -EIO;
+	unsigned char *ptr = buf;
+	struct hisfc_host *host = MTD_TO_HOST(mtd);
+	struct hisfc_spi *spi = host->spi;
+
+	if ((from + len) > mtd->size) {
+		DBG_MSG("read area out of range.\n");
+		return -EINVAL;
+	}
+
+	*retlen = 0;
+	if (!len) {
+		DBG_MSG("read length is 0.\n");
+		return 0;
+	}
+
+	mutex_lock(&host->lock);
+
+	if (spi->driver->wait_ready(spi))
+		goto fail;
+	spi->driver->bus_prepare(spi, READ);
+	host->set_system_clock(host, spi->read, TRUE);
+
+	if (from & HISFC350_DMA_ALIGN_MASK) {
+		num = HISFC350_DMA_ALIGN_SIZE -
+			(from & HISFC350_DMA_ALIGN_MASK);
+		if (num > len)
+			num = len;
+		while (from >= spi->chipsize) {
+			from -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("write memory out of range.\n");
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+			spi->driver->bus_prepare(spi, READ);
+			host->set_system_clock(host, spi->read, TRUE);
+		}
+		hisfc350_dma_transfer(host, from,
+			(unsigned char *)host->dma_buffer, READ,
+			num, spi->chipselect);
+		memcpy(ptr, host->buffer, num);
+		from  += num;
+		ptr += num;
+		len -= num;
+	}
+
+	while (len > 0) {
+		while (from >= spi->chipsize) {
+			from -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("read memory out of range.\n");
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+			spi->driver->bus_prepare(spi, READ);
+			host->set_system_clock(host, spi->read, TRUE);
+		}
+
+		num = ((from + len) >= spi->chipsize)
+			? (spi->chipsize - from) : len;
+		while (num >= HISFC350_DMA_MAX_SIZE) {
+			hisfc350_dma_transfer(host, from,
+				(unsigned char *)host->dma_buffer, READ,
+				HISFC350_DMA_MAX_SIZE, spi->chipselect);
+			memcpy(ptr, host->buffer, HISFC350_DMA_MAX_SIZE);
+			ptr  += HISFC350_DMA_MAX_SIZE;
+			from += HISFC350_DMA_MAX_SIZE;
+			len  -= HISFC350_DMA_MAX_SIZE;
+			num  -= HISFC350_DMA_MAX_SIZE;
+		}
+
+		if (num) {
+			hisfc350_dma_transfer(host, from,
+				(unsigned char *)host->dma_buffer, READ,
+				num, spi->chipselect);
+			memcpy(ptr, host->buffer, num);
+			from += num;
+			ptr  += num;
+			len  -= num;
+		}
+	}
+	result = 0;
+	*retlen = (size_t)(ptr - buf);
+fail:
+	mutex_unlock(&host->lock);
+	return result;
+}
+#endif
+
+static unsigned char *hisfc350_read_ids(struct hisfc_host *host,
+	int chipselect, unsigned char *buffer)
+{
+	int regindex = 0;
+	int numread = 8;
+	unsigned int *ptr = (unsigned int *)buffer;
+
+	if (numread > HISFC350_REG_BUF_SIZE)
+		numread = HISFC350_REG_BUF_SIZE;
+
+	hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_RDID);
+	hisfc_write(host, HISFC350_CMD_CONFIG,
+		HISFC350_CMD_CONFIG_SEL_CS(chipselect)
+		| HISFC350_CMD_CONFIG_RW_READ
+		| HISFC350_CMD_CONFIG_DATA_EN
+		| HISFC350_CMD_CONFIG_DATA_CNT(numread)
+		| HISFC350_CMD_CONFIG_START);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	while (numread) {
+		*ptr = hisfc_read(host,
+			HISFC350_CMD_DATABUF0 + regindex);
+		ptr      += 1;
+		regindex += 4;
+		numread  -= 4;
+	}
+
+	return buffer;
+}
+
+static int hisfc350_reg_erase_one_block(struct hisfc_host *host,
+	struct hisfc_spi *spi, unsigned int offset)
+{
+	if (spi->driver->wait_ready(spi))
+		return 1;
+
+	spi->driver->write_enable(spi);
+	host->set_system_clock(host, spi->erase, TRUE);
+
+	hisfc_write(host, HISFC350_CMD_INS, spi->erase->cmd);
+
+	hisfc_write(host, HISFC350_CMD_ADDR,
+		(offset & HISFC350_CMD_ADDR_MASK));
+
+	hisfc_write(host, HISFC350_CMD_CONFIG,
+		HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+		| HISFC350_CMD_CONFIG_MEM_IF_TYPE(spi->erase->iftype)
+		| HISFC350_CMD_CONFIG_DUMMY_CNT(spi->erase->dummy)
+		| HISFC350_CMD_CONFIG_ADDR_EN
+		| HISFC350_CMD_CONFIG_START);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	return 0;
+}
+
+#ifdef CONFIG_HISFC350_ENABLE_INTR_DMA
+static int hisfc350_dma_intr_write(struct mtd_info *mtd, loff_t to, size_t len,
+	size_t *retlen, const u_char *buf)
+{
+	int result = -EIO;
+	struct hisfc_host *host = MTD_TO_HOST(mtd);
+	struct hisfc_spi *spi = host->spi;
+
+	if ((to + len) > mtd->size) {
+		DBG_MSG("write data out of range.\n");
+		return -EINVAL;
+	}
+
+	*retlen = 0;
+	if (!len) {
+		DBG_MSG("write length is 0.\n");
+		return 0;
+	}
+
+#ifdef CONFIG_CMD_SPI_BLOCK_PROTECTION
+	if ((BP_CMP_TOP == host->cmp) && ((to + len) > host->start_addr)) {
+		DBG_MSG("write area to[%#x => %#x] is locked, please " \
+			"unlock these blocks on u-boot.\n",
+			host->start_addr, (to + len));
+		return -EINVAL;
+	}
+
+	if ((BP_CMP_BOTTOM == host->cmp) && (to <= host->end_addr)) {
+		unsigned end = ((to + len) > host->end_addr) \
+			       ? host->end_addr : (to + len);
+
+		DBG_MSG("write area to[%#x => %#x] is locked, please " \
+			"unlock these blocks on u-boot.\n", to, end);
+		return -EINVAL;
+	}
+#endif /* CONFIG_CMD_SPI_BLOCK_PROTECTION */
+
+	mutex_lock(&host->lock);
+
+	sfc_offset = (unsigned char *)buf;
+	sfc_ft = to;
+	sfc_length = len;
+	sfc_rw = WRITE;
+	if (spi->driver->wait_ready(spi))
+		goto fail;
+
+	spi->driver->write_enable(spi);
+	spi->driver->bus_prepare(spi, sfc_rw);
+
+	if (sfc_ft & HISFC350_DMA_ALIGN_MASK) {
+		sfc_num = HISFC350_DMA_ALIGN_SIZE
+			- (sfc_ft & HISFC350_DMA_ALIGN_MASK);
+		if (sfc_num > sfc_length)
+			sfc_num = sfc_length;
+		while (sfc_ft >= spi->chipsize) {
+			sfc_ft -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("write memory out of range.\n");
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+			spi->driver->write_enable(spi);
+			spi->driver->bus_prepare(spi, sfc_rw);
+		}
+	} else{
+		while (sfc_ft >= spi->chipsize) {
+			sfc_ft -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("read memory out of range.\n");
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+			spi->driver->write_enable(spi);
+			spi->driver->bus_prepare(spi, sfc_rw);
+		}
+		if ((sfc_ft + sfc_length) >= spi->chipsize) {
+			sfc_num = spi->chipsize - sfc_ft;
+			if (sfc_num >= HISFC350_DMA_MAX_SIZE)
+				sfc_num = HISFC350_DMA_MAX_SIZE;
+		} else{
+			sfc_num = sfc_length;
+			if (sfc_num >= HISFC350_DMA_MAX_SIZE)
+				sfc_num = HISFC350_DMA_MAX_SIZE;
+		}
+	}
+
+	memcpy(host->buffer, sfc_offset, sfc_num);
+	hisfc350_dma_transfer(host, sfc_ft,
+		(unsigned char *)host->dma_buffer, sfc_rw,
+		sfc_num, spi->chipselect);
+	wait_event(host->intr_wait, host->wait_fg == SFC_WAIT_FLAG_W);
+	host->wait_fg = 0;
+	*retlen = (size_t)(sfc_offset - buf);
+	result = 0;
+fail:
+	mutex_unlock(&host->lock);
+	return result;
+}
+#else
+static int hisfc350_dma_write(struct mtd_info *mtd, loff_t to, size_t len,
+	size_t *retlen, const u_char *buf)
+{
+	int num;
+	int result = -EIO;
+
+	unsigned char *ptr = (unsigned char *)buf;
+	struct hisfc_host *host = MTD_TO_HOST(mtd);
+	struct hisfc_spi *spi = host->spi;
+
+	if ((to + len) > mtd->size) {
+		DBG_MSG("write data out of range.\n");
+		return -EINVAL;
+	}
+
+	*retlen = 0;
+	if (!len) {
+		DBG_MSG("write length is 0.\n");
+		return 0;
+	}
+
+#ifdef CONFIG_CMD_SPI_BLOCK_PROTECTION
+	if (host->level) {
+		if ((BP_CMP_TOP == host->cmp)
+		    && ((to + len) > host->start_addr)) {
+			DBG_MSG("write area to[%#x => %#x] is locked, please " \
+				"unlock these blocks on u-boot.\n",
+				host->start_addr, (unsigned)(to + len));
+			return -EINVAL;
+		}
+
+		if ((BP_CMP_BOTTOM == host->cmp) && (to < host->end_addr)) {
+			unsigned end = ((to + len) > host->end_addr) \
+				       ? host->end_addr : (to + len);
+
+			DBG_MSG("write area to[%#x => %#x] is locked, please " \
+				"unlock these blocks on u-boot.\n",
+				(unsigned)to, end);
+			return -EINVAL;
+		}
+	}
+#endif /* CONFIG_CMD_SPI_BLOCK_PROTECTION */
+
+	mutex_lock(&host->lock);
+
+	if (spi->driver->wait_ready(spi))
+		goto fail;
+
+	spi->driver->write_enable(spi);
+	spi->driver->bus_prepare(spi, WRITE);
+	host->set_system_clock(host, spi->write, TRUE);
+
+	if (to & HISFC350_DMA_ALIGN_MASK) {
+		num = HISFC350_DMA_ALIGN_SIZE - (to & HISFC350_DMA_ALIGN_MASK);
+		if (num > len)
+			num = len;
+		while (to >= spi->chipsize) {
+			to -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("write memory out of range.\n");
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+			spi->driver->write_enable(spi);
+			spi->driver->bus_prepare(spi, WRITE);
+			host->set_system_clock(host, spi->write, TRUE);
+		}
+		memcpy(host->buffer, ptr, num);
+		hisfc350_dma_transfer(host, to,
+			(unsigned char *)host->dma_buffer, WRITE,
+			num, spi->chipselect);
+
+		to  += num;
+		ptr += num;
+		len -= num;
+	}
+
+	while (len > 0) {
+		num = ((len >= HISFC350_DMA_MAX_SIZE)
+			? HISFC350_DMA_MAX_SIZE : len);
+		while (to >= spi->chipsize) {
+			to -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("write memory out of range.\n");
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+			spi->driver->write_enable(spi);
+			spi->driver->bus_prepare(spi, WRITE);
+			host->set_system_clock(host, spi->write, TRUE);
+		}
+
+		memcpy(host->buffer, ptr, num);
+		hisfc350_dma_transfer(host, to,
+			(unsigned char *)host->dma_buffer, WRITE,
+			num, spi->chipselect);
+
+		to  += num;
+		ptr += num;
+		len -= num;
+	}
+	*retlen = (size_t)(ptr - buf);
+	result = 0;
+fail:
+	mutex_unlock(&host->lock);
+	return result;
+}
+#endif
+
+#ifdef HISFCV350_SUPPORT_REG_WRITE
+static int hisfc350_reg_write_buf(struct hisfc_host *host,
+	struct hisfc_spi *spi, unsigned int spi_start_addr,
+	unsigned int size, unsigned char *buffer)
+{
+	int index = 0;
+
+	if (size > HISFC350_REG_BUF_SIZE)
+		DBG_BUG("reg read out of reg range.\n");
+
+	if (spi->driver->wait_ready(spi))
+		return 1;
+
+	memcpy(host->reg_buffer, buffer, size);
+
+	while (index < size) {
+		hisfc_write(host, HISFC350_CMD_DATABUF0 + index,
+			*(unsigned int *)(host->reg_buffer + index));
+		index    += 4;
+	}
+
+	spi->driver->write_enable(spi);
+
+	hisfc_write(host, HISFC350_CMD_INS, spi->write->cmd);
+	hisfc_write(host, HISFC350_CMD_ADDR,
+		((u32)spi_start_addr & HISFC350_CMD_ADDR_MASK));
+	hisfc_write(host, HISFC350_CMD_CONFIG,
+		HISFC350_CMD_CONFIG_MEM_IF_TYPE(spi->write->iftype)
+		| HISFC350_CMD_CONFIG_DATA_CNT(size)
+		| HISFC350_CMD_CONFIG_DATA_EN
+		| HISFC350_CMD_CONFIG_DUMMY_CNT(spi->write->dummy)
+		| HISFC350_CMD_CONFIG_ADDR_EN
+		| HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+		| HISFC350_CMD_CONFIG_START);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	return 0;
+}
+
+static int hisfc350_reg_write(struct mtd_info *mtd, loff_t to, size_t len,
+	size_t *retlen, const u_char *buf)
+{
+	int num;
+	int result = -EIO;
+	unsigned char *ptr = (unsigned char *)buf;
+	struct hisfc_host *host = MTD_TO_HOST(mtd);
+	struct hisfc_spi *spi = host->spi;
+
+	if ((to + len) > mtd->size) {
+		DBG_MSG("write data out of range.\n");
+		return -EINVAL;
+	}
+
+	*retlen = 0;
+	if (!len) {
+		DBG_MSG("write length is 0.\n");
+		return 0;
+	}
+
+#ifdef CONFIG_CMD_SPI_BLOCK_PROTECTION
+	if (host->level) {
+		if ((BP_CMP_TOP == host->cmp)
+		    && ((to + len) > host->start_addr)) {
+			DBG_MSG("write area to[%#x => %#x] is locked, please " \
+				"unlock these blocks on u-boot.\n",
+				host->start_addr, (to + len));
+			return -EINVAL;
+		}
+
+		if ((BP_CMP_BOTTOM == host->cmp) && (to < host->end_addr)) {
+			unsigned end = ((to + len) > host->end_addr) \
+				       ? host->end_addr : (to + len);
+
+			DBG_MSG("write area to[%#x => %#x] is locked, please " \
+				"unlock these blocks on u-boot.\n", to, end);
+			return -EINVAL;
+		}
+	}
+#endif /* CONFIG_CMD_SPI_BLOCK_PROTECTION */
+
+	mutex_lock(&host->lock);
+
+	if (spi->driver->wait_ready(spi))
+		goto fail;
+
+	host->set_system_clock(host, spi->write, TRUE);
+
+	if (to & HISFC350_REG_BUF_MASK) {
+		num = HISFC350_REG_BUF_SIZE - (to & HISFC350_REG_BUF_MASK);
+		if (num > (int)len)
+			num = (int)len;
+
+		while (to >= spi->chipsize) {
+			to -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("write memory out of range.\n");
+
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+
+			host->set_system_clock(host, spi->write, TRUE);
+		}
+		if (hisfc350_reg_write_buf(host, spi, to, num, ptr))
+			goto fail;
+		to  += num;
+		ptr += num;
+		len -= num;
+	}
+
+	while (len > 0)	{
+		num = ((len >= HISFC350_REG_BUF_SIZE) ?
+				HISFC350_REG_BUF_SIZE : len);
+		while (to >= spi->chipsize) {
+			to -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("write memory out of range.\n");
+
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+
+			host->set_system_clock(host, spi->write, TRUE);
+		}
+		if (hisfc350_reg_write_buf(host, spi, to, num, ptr))
+			goto fail;
+		to  += num;
+		ptr += num;
+		len -= num;
+	}
+	*retlen = (size_t)(ptr - buf);
+	result = 0;
+fail:
+	mutex_unlock(&host->lock);
+	return result;
+}
+#endif /* HISFCV350_SUPPORT_REG_WRITE */
+
+static int hisfc350_reg_erase(struct mtd_info *mtd, struct erase_info *instr)
+{
+	struct hisfc_host *host = MTD_TO_HOST(mtd);
+	struct hisfc_spi *spi = host->spi;
+
+	unsigned long long offset = instr->addr;
+	unsigned long long length = instr->len;
+
+	if (offset + length > mtd->size) {
+		DBG_MSG("erase area out of range of mtd.\n");
+		return -EINVAL;
+	}
+
+	if ((unsigned int)offset & (mtd->erasesize-1)) {
+		DBG_MSG("erase start address is not alignment.\n");
+		return -EINVAL;
+	}
+
+	if ((unsigned int)length & (mtd->erasesize-1)) {
+		DBG_MSG("erase length is not alignment.\n");
+		return -EINVAL;
+	}
+
+#ifdef CONFIG_CMD_SPI_BLOCK_PROTECTION
+	if (host->level) {
+		if ((BP_CMP_TOP == host->cmp)
+		    && ((offset + length) > host->start_addr)) {
+			DBG_MSG("erase area offset[%#x => %#x] is locked," \
+				" please unlock these blocks on u-boot.\n",
+				host->start_addr, (unsigned)(offset + length));
+			return -EINVAL;
+		}
+
+		if ((BP_CMP_BOTTOM == host->cmp) && (offset < host->end_addr)) {
+			unsigned end = ((offset + length) > host->end_addr) \
+				       ? host->end_addr : (offset + length);
+
+			DBG_MSG("erase area offset[%#x => %#x] is locked," \
+				" please unlock these blocks on u-boot.\n",
+				(unsigned)offset, end);
+			return -EINVAL;
+		}
+	}
+#endif /* CONFIG_CMD_SPI_BLOCK_PROTECTION */
+
+	mutex_lock(&host->lock);
+	while (length) {
+		if (spi->chipsize <= offset) {
+			offset -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("erase memory out of range.\n");
+		}
+
+		if (hisfc350_reg_erase_one_block(host, spi, offset)) {
+			instr->state = MTD_ERASE_FAILED;
+			mutex_unlock(&host->lock);
+			return -EIO;
+		}
+
+		offset += spi->erase->size;
+		length -= spi->erase->size;
+	}
+
+	instr->state = MTD_ERASE_DONE;
+	mutex_unlock(&host->lock);
+	mtd_erase_callback(instr);
+	return 0;
+}
+
+#ifdef HISFCV350_SUPPORT_BUS_READ
+static int hisfc350_bus_read(struct mtd_info *mtd, loff_t from, size_t len,
+		size_t *retlen, u_char *buf)
+{
+	int num;
+	int result = -EIO;
+	unsigned char *ptr = buf;
+	struct hisfc_host *host = MTD_TO_HOST(mtd);
+	struct hisfc_spi *spi = host->spi;
+
+	if ((from + len) > mtd->size) {
+		DBG_MSG("read area out of range.\n");
+		return -EINVAL;
+	}
+
+	*retlen = 0;
+	if (!len) {
+		DBG_MSG("read length is 0.\n");
+		return 0;
+	}
+
+	mutex_lock(&host->lock);
+
+	if (spi->driver->wait_ready(spi))
+		goto fail;
+	spi->driver->bus_prepare(spi, READ);
+
+	while (len > 0) {
+		while (from >= spi->chipsize) {
+			from -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("read memory out of range.\n");
+
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+			spi->driver->bus_prepare(spi, READ);
+		}
+
+		num = ((from + len) >= spi->chipsize)
+				? (spi->chipsize - from) : len;
+
+		if (num) {
+			memcpy(ptr, (char *)spi->iobase + from, num);
+			from += num;
+			ptr  += num;
+			len  -= num;
+		}
+	}
+	*retlen = (size_t)(ptr - buf);
+	result = 0;
+fail:
+	mutex_unlock(&host->lock);
+	return result;
+}
+#endif /* HISFCV350_SUPPORT_BUS_READ */
+
+#ifdef HISFCV350_SUPPORT_BUS_WRITE
+static int hisfc350_bus_write(struct mtd_info *mtd, loff_t to, size_t len,
+		size_t *retlen, u_char *buf)
+{
+	int num;
+	int result = -EIO;
+	unsigned char *ptr = buf;
+	struct hisfc_host *host = MTD_TO_HOST(mtd);
+	struct hisfc_spi *spi = host->spi;
+
+	if ((to + len) > mtd->size) {
+		DBG_MSG("write data out of range.\n");
+		return -EINVAL;
+	}
+
+	*retlen = 0;
+	if (!len) {
+		DBG_MSG("write length is 0.\n");
+		return 0;
+	}
+
+#ifdef CONFIG_CMD_SPI_BLOCK_PROTECTION
+	if (host->level) {
+		if ((BP_CMP_TOP == host->cmp)
+		    && ((to + len) > host->start_addr)) {
+			DBG_MSG("write area to[%#x => %#x] is locked, please " \
+				"unlock these blocks on u-boot.\n",
+				host->start_addr, (to + len));
+			return -EINVAL;
+		}
+
+		if ((BP_CMP_BOTTOM == host->cmp) && (to < host->end_addr)) {
+			unsigned end = ((to + len) > host->end_addr) \
+				       ? host->end_addr : (to + len);
+
+			DBG_MSG("write area to[%#x => %#x] is locked, please " \
+				"unlock these blocks on u-boot.\n", to, end);
+			return -EINVAL;
+		}
+	}
+#endif /* CONFIG_CMD_SPI_BLOCK_PROTECTION */
+
+	mutex_lock(&host->lock);
+
+	if (spi->driver->wait_ready(spi))
+		goto fail;
+
+	spi->driver->bus_prepare(spi, WRITE);
+
+	while (len > 0) {
+		while (to >= spi->chipsize) {
+			to -= spi->chipsize;
+			spi++;
+			if (!spi->name)
+				DBG_BUG("write spi space out of range.\n");
+
+			if (spi->driver->wait_ready(spi))
+				goto fail;
+			spi->driver->bus_prepare(spi, WRITE);
+		}
+
+		num = ((to + len) >= spi->chipsize)
+				? (spi->chipsize - to) : len;
+
+		if (num) {
+			memcpy((char *)spi->iobase + to, ptr, num);
+			ptr += num;
+			to += num;
+			len -= num;
+		}
+	}
+
+	*retlen = (size_t)(ptr - buf);
+	result = 0;
+fail:
+	mutex_unlock(&host->lock);
+	return result;
+}
+#endif
+
+static int hisfc350_map_chipsize(unsigned long long chipsize)
+{
+	int shift = 0;
+	chipsize >>= (19 - 3); /* 19: 512K; 3: Bytes -> bit */
+
+	while (chipsize) {
+		chipsize >>= 1;
+		shift++;
+	}
+	return shift;
+}
+
+#ifdef CONFIG_HISFC350_ENABLE_INTR_DMA
+static irqreturn_t hisfc_irq(int irq, void *dev_id)
+{
+	struct hisfc_host *host = dev_id;
+	struct hisfc_spi *spi = host->spi;
+	u32 state = 0;
+	unsigned int tmp_reg = 0;
+
+	state = hisfc_read(host, SFC_RINTSTS);
+	/* clear interrupt */
+	tmp_reg = hisfc_read(host, SFC_INTCLR);
+	tmp_reg |= ALL_INT_CLR;
+	hisfc_write(host , SFC_INTCLR , tmp_reg);
+
+	if (sfc_rw == READ)
+		memcpy(sfc_offset, host->buffer, sfc_num);
+
+	sfc_ft += sfc_num;
+	sfc_offset += sfc_num;
+	sfc_length -= sfc_num;
+
+	if (state & SFC_DMA_INT_STATUS) {
+		if (sfc_length > 0) {
+			while (sfc_ft >= spi->chipsize) {
+				sfc_ft -= spi->chipsize;
+				spi++;
+				if (sfc_rw == WRITE)
+					spi->driver->write_enable(spi);
+				spi->driver->bus_prepare(spi, sfc_rw);
+			}
+			if ((sfc_ft + sfc_length) >= spi->chipsize) {
+				sfc_num = spi->chipsize - sfc_ft;
+				if (sfc_num >= HISFC350_DMA_MAX_SIZE)
+					sfc_num = HISFC350_DMA_MAX_SIZE;
+			} else{
+				sfc_num = sfc_length;
+				if (sfc_num >= HISFC350_DMA_MAX_SIZE)
+					sfc_num = HISFC350_DMA_MAX_SIZE;
+			}
+			if (sfc_rw == WRITE)
+				memcpy(host->buffer, sfc_offset, sfc_num);
+			hisfc350_dma_transfer(host, sfc_ft,
+				(unsigned char *)host->dma_buffer, sfc_rw,
+				sfc_num, spi->chipselect);
+		} else{
+			if (sfc_rw == READ)
+				host->wait_fg = SFC_WAIT_FLAG_R;
+			else if (sfc_rw == WRITE)
+				host->wait_fg = SFC_WAIT_FLAG_W;
+			wake_up(&host->intr_wait);
+		}
+	}
+	return IRQ_HANDLED;
+}
+#endif
+
+static int hisfc350_spi_probe(struct hisfc_host *host)
+{
+	unsigned int regval = 0;
+	unsigned int total = 0;
+	unsigned char ids[8];
+	struct spi_info *spiinfo;
+	struct hisfc_spi *spi = host->spi;
+	int chipselect = (CONFIG_HISFC350_CHIP_NUM - 1);
+
+	host->num_chip = 0;
+
+	for (; chipselect >= 0; chipselect--) {
+
+		hisfc350_read_ids(host, chipselect, ids);
+
+		/* can't find spi flash device. */
+		if (!(ids[0] | ids[1] | ids[2])
+			|| ((ids[0] & ids[1] & ids[2]) == 0xFF))
+			continue;
+
+		printk(KERN_INFO "Spi(cs%d) ID: 0x%02X 0x%02X 0x%02X"
+			" 0x%02X 0x%02X 0x%02X\n",
+			chipselect,
+			ids[0], ids[1], ids[2], ids[3], ids[4], ids[5]);
+
+		spiinfo = spi_serach_ids(ids);
+
+		if (spiinfo) {
+			spi->name = spiinfo->name;
+			spi->chipselect = chipselect;
+			spi->chipsize   = spiinfo->chipsize;
+			spi->erasesize  = spiinfo->erasesize;
+			spi->addrcycle  = spiinfo->addrcycle;
+			spi->driver     = spiinfo->driver;
+			spi->host       = host;
+
+			spi_search_rw(spiinfo, spi->read,
+				HISFC350_SUPPORT_READ,
+				HISFC350_SUPPORT_MAX_DUMMY, READ);
+			hisfc350_map_iftype_and_clock(spi);
+
+			spi->driver->qe_enable(spi);
+
+			spi_search_rw(spiinfo, spi->read,
+				HISFC350_SUPPORT_READ,
+				HISFC350_SUPPORT_MAX_DUMMY, READ);
+
+			spi_search_rw(spiinfo, spi->write,
+				HISFC350_SUPPORT_WRITE,
+				HISFC350_SUPPORT_MAX_DUMMY, WRITE);
+
+			spi_get_erase(spiinfo, spi->erase);
+			hisfc350_map_iftype_and_clock(spi);
+
+			regval = hisfc_read(host, HISFC350_BUS_FLASH_SIZE);
+			regval &= ~(HISFC350_BUS_FLASH_SIZE_CS0_MASK
+				<< (chipselect << 3));
+			regval |= (hisfc350_map_chipsize(spi->chipsize)
+				<< (chipselect << 3));
+			hisfc_write(host, HISFC350_BUS_FLASH_SIZE, regval);
+
+			hisfc_write(host,
+				(HISFC350_BUS_BASE_ADDR_CS0
+					+ (chipselect << 2)),
+				(host->iobase + total));
+
+			spi->iobase = (char *)host->iobase + total;
+
+			/* auto check sfc_addr_mode 3 bytes or 4 bytes */
+			start_up_mode = GET_SFC_ADDR_MODE;
+
+			if (start_up_mode == THREE_BYTE_ADDR_BOOT) {
+				printk(KERN_INFO "SPI nor flash boot mode is" \
+						" 3 Bytes\n");
+				spi->driver->entry_4addr(spi, TRUE);
+			} else
+				printk(KERN_INFO "SPI nor flash boot mode is" \
+						" 4 Bytes\n");
+
+			printk(KERN_INFO "Spi(cs%d): ", spi->chipselect);
+			printk(KERN_INFO "Block:%sB", ultohstr(spi->erasesize));
+			printk(KERN_INFO "Chip:%sB ", ultohstr(spi->chipsize));
+			printk(KERN_INFO "Name:\"%s\"\n", spi->name);
+
+#ifdef CONFIG_HISFC350_SHOW_CYCLE_TIMING
+
+			printk(KERN_INFO "Spi(cs%d): ", spi->chipselect);
+			if (spi->addrcycle == SPI_4BYTE_ADDR_LEN)
+				printk(KERN_INFO "4 addrcycle ");
+			printk(KERN_INFO "read:%s,%02X,%s ",
+				hisfc350_get_ifcycle_str(spi->read->iftype),
+				spi->read->cmd,
+				hisfc350_get_clock_str(spi->read->clock));
+			printk(KERN_INFO "write:%s,%02X,%s ",
+				hisfc350_get_ifcycle_str(spi->write->iftype),
+				spi->write->cmd,
+				hisfc350_get_clock_str(spi->write->clock));
+			printk(KERN_INFO "erase:%s,%02X,%s\n",
+				hisfc350_get_ifcycle_str(spi->erase[0].iftype),
+				spi->erase[0].cmd,
+				hisfc350_get_clock_str(spi->erase[0].clock));
+
+#endif /* CONFIG_HISFC350_SHOW_CYCLE_TIMING */
+			host->num_chip++;
+			total += spi->chipsize;
+			spi++;
+		} else
+			printk(KERN_ERR"Spi(cs%d): find unrecognized spi flash.\n",
+				chipselect);
+	}
+
+	return host->num_chip;
+}
+
+static void hisfc_probe_spi_size(struct hisfc_host *host)
+{
+	int ix = 1;
+	struct mtd_info *mtd = host->mtd;
+	struct hisfc_spi *spi = host->spi;
+
+	int total     = spi->chipsize;
+	int erasesize = spi->erasesize;
+
+	for (++spi; ix < host->num_chip; ix++, spi++)
+		total += spi->chipsize;
+
+	mtd->size = total;
+	mtd->erasesize = erasesize;
+
+	printk(KERN_INFO "spi size: %sB\n", ultohstr(mtd->size));
+	printk(KERN_INFO "chip num: %x\n", host->num_chip);
+}
+
+static int hisfc350_probe(struct hisfc_host *host)
+{
+	struct device *dev = host->dev;
+	struct mtd_info *mtd = host->mtd;
+	struct device_node *np = NULL;
+	int ret = 0;
+
+	np = of_get_next_available_child(dev->of_node, NULL);
+	ret = hisfc350_spi_probe(host);
+	if (!ret)
+		return -1;
+
+	hisfc_probe_spi_size(host);
+	mtd->type = MTD_NORFLASH;
+	mtd->writesize = 1;
+	mtd->flags = MTD_CAP_NORFLASH;
+	mtd->owner = THIS_MODULE;
+	mtd->name = np->name;
+
+	mtd->_erase = hisfc350_reg_erase;
+#ifdef HISFCV350_SUPPORT_REG_WRITE
+	mtd->_write = hisfc350_reg_write;
+#elif defined HISFCV350_SUPPORT_BUS_WRITE
+	mtd->_write = hisfc350_bus_write;
+#elif defined CONFIG_HISFC350_ENABLE_INTR_DMA
+	mtd->_write = hisfc350_dma_intr_write;
+#else
+	mtd->_write = hisfc350_dma_write;
+#endif
+#ifdef HISFCV350_SUPPORT_REG_READ
+	mtd->_read  = hisfc350_reg_read;
+#elif defined HISFCV350_SUPPORT_BUS_READ
+	mtd->_read  = hisfc350_bus_read;
+#elif defined CONFIG_HISFC350_ENABLE_INTR_DMA
+	mtd->_read  = hisfc350_dma_intr_read;
+#else
+	mtd->_read  = hisfc350_dma_read;
+#endif
+	return 0;
+}
+
+static void hisfc350_spi_nor_init(struct hisfc_host *host)
+{
+	clk_prepare_enable(host->clk);
+
+	hisfc_write(host, HISFC350_TIMING, HISFC350_TIMING_TCSS(0x6)
+			| HISFC350_TIMING_TCSH(0x6)
+			| HISFC350_TIMING_TSHSL(0xf));
+
+}
+
+static int hisfc350_spi_nor_probe(struct platform_device *pdev)
+{
+	int result = -EIO;
+	struct hisfc_host *host;
+	struct mtd_info   *mtd = NULL;
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+#ifdef CONFIG_HISFC350_ENABLE_INTR_DMA
+	int irq;
+	unsigned int tmp_reg = 0;
+#endif
+
+	host = devm_kmalloc(dev, sizeof(struct hisfc_host), GFP_KERNEL);
+	if (!host)
+		return -ENOMEM;
+	memset(host, 0, sizeof(struct hisfc_host));
+
+	platform_set_drvdata(pdev, host);
+	host->dev = dev;
+
+	host->sysreg = ioremap_nocache(CONFIG_HISFC350_SYSCTRL_ADDRESS,
+		HISFC350_SYSCTRL_LENGTH);
+	if (!host->sysreg) {
+		printk(KERN_ERR "spi system reg ioremap failed.\n");
+		result = -EFAULT;
+		goto fail;
+	}
+
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "control");
+	host->regbase = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(host->regbase))
+		return PTR_ERR(host->regbase);
+
+	host->set_system_clock = hisfc350_set_system_clock;
+	host->set_host_addr_mode = hisfc350_set_host_addr_mode;
+
+#ifdef HISFCV350_SUPPORT_BUS_READ
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "memory");
+	host->iobase = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(hostt->iobase))
+		return PTR_ERR(fmc->iobase);
+#endif
+
+	host->clk = devm_clk_get(&pdev->dev, NULL);
+	if (IS_ERR(host->clk))
+		return PTR_ERR(host->clk);
+
+	result = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(32));
+	if (result) {
+		dev_warn(dev, "Unable to set dma mask\n");
+		goto fail;
+	}
+
+	host->buffer = dma_alloc_coherent(host->dev, HISFC350_DMA_MAX_SIZE,
+		&host->dma_buffer, GFP_KERNEL);
+	if (host->buffer == NULL) {
+		printk(KERN_ERR "spi alloc dma buffer failed.\n");
+		result = -ENOMEM;
+		goto fail;
+	}
+
+	mutex_init(&host->lock);
+	hisfc350_spi_nor_init(host);
+
+	mtd = host->mtd;
+	if (hisfc350_probe(host)) {
+		result = -ENODEV;
+		goto fail;
+	}
+
+	result = mtd_device_register(mtd, NULL, 0);
+	if (result)
+		goto fail;
+
+#ifdef CONFIG_CMD_SPI_BLOCK_PROTECTION
+	hisfc350_spi_lock_init(host);
+#endif
+
+#ifdef CONFIG_HISFC350_ENABLE_INTR_DMA
+	host->wait_fg = 0;
+	init_waitqueue_head(&host->intr_wait);
+
+	/* clear SFC intr */
+	tmp_reg |= ALL_INT_CLR;
+	hisfc_write(host , SFC_INTCLR , tmp_reg);
+	/* MASK SFC host intr */
+	tmp_reg = hisfc_read(host , SFC_INTMASK);
+	tmp_reg |= SFC_DMA_INT_MASK;
+	tmp_reg &= ~SFC_CMD_INT_MASK;
+	hisfc_write(host , SFC_INTMASK , tmp_reg);
+
+	irq = platform_get_irq(pdev, 0);
+	if (unlikely(irq < 0))
+		goto fail;
+	result = request_irq(irq, hisfc_irq, IRQF_SHARED, "hisfc", host);
+	if (result) {
+		printk(KERN_ERR "request_irq error!\n");
+		goto fail;
+	}
+#endif
+	return result;
+
+fail:
+	if (host->buffer)
+		dma_free_coherent(host->dev, HISFC350_DMA_MAX_SIZE,
+			host->buffer, host->dma_buffer);
+	if (host->sysreg)
+		iounmap(host->sysreg);
+	mutex_destroy(&host->lock);
+	clk_disable_unprepare(host->clk);
+	if (mtd)
+		mtd_device_unregister(mtd);
+	platform_set_drvdata(pdev, NULL);
+	return result;
+}
+
+static int hisfc350_spi_nor_remove(struct platform_device *pdev)
+{
+	struct hisfc_host *host = platform_get_drvdata(pdev);
+#ifdef CONFIG_HISFC350_ENABLE_INTR_DMA
+	int irq = SFC_IRQ_NUM;
+	free_irq(irq, host);
+#endif
+
+	mtd_device_unregister(host->mtd);
+
+	if (host->buffer)
+		dma_free_coherent(host->dev, HISFC350_DMA_MAX_SIZE,
+			host->buffer, host->dma_buffer);
+	if (host->sysreg)
+		iounmap(host->sysreg);
+
+	mutex_destroy(&host->lock);
+	clk_disable_unprepare(host->clk);
+	platform_set_drvdata(pdev, NULL);
+
+	return 0;
+}
+
+#ifdef CONFIG_CMD_SPI_BLOCK_PROTECTION
+void hisfc350_spi_lock_init(struct hisfc_host *host)
+{
+	unsigned char cmp, level, status, config;
+	unsigned int lock_len = 0;
+	struct hisfc_spi *spi = host->spi;
+
+	spi->driver->wait_ready(spi);
+
+	status = spi_general_get_flash_register(spi, SPI_CMD_RDSR);
+	level = (status & SPI_NOR_SR_BP_MASK) >> SPI_NOR_SR_BP0_SHIFT;
+
+	config = spi_general_get_flash_register(spi, SPI_CMD_RDCR);
+	cmp = (config & SPI_NOR_SR_TB_MASK) >> SPI_NOR_SR_TB_SHIFT;
+
+	host->start_addr = 0;
+	host->end_addr = spi->chipsize;
+
+	if (level) {
+		lock_len = spi->erasesize << (level - 1);
+		if (lock_len > spi->chipsize)
+			lock_len = spi->chipsize;
+
+		if (BP_CMP_BOTTOM == cmp)
+			host->end_addr = lock_len;
+		else if (BP_CMP_TOP == cmp)
+			host->start_addr = spi->chipsize - lock_len;
+
+		printk(KERN_INFO "Spi is locked. lock address[%#x => %#x]\n",
+			host->start_addr, host->end_addr);
+	} else {
+		if (BP_CMP_BOTTOM == cmp)
+			host->end_addr = 0;
+		else if (BP_CMP_TOP == cmp)
+			host->start_addr = spi->chipsize;
+	}
+
+	host->cmp = cmp;
+	host->level = level;
+}
+#endif /* CONFIG_CMD_SPI_BLOCK_PROTECTION */
+
+#ifdef CONFIG_PM
+
+static int hisfc350_driver_suspend(struct platform_device *dev,
+		pm_message_t state)
+{
+	return 0;
+}
+static int hisfc350_driver_resume(struct platform_device *dev)
+{
+	return 0;
+}
+
+#endif
+
+static const struct of_device_id hisi_spi_nor_dt_ids[] = {
+	{ .compatible = "hisilicon,hisi-spi-nor"},
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, hisi_spi_nor_dt_ids);
+
+static struct platform_driver hisi_spi_nor_driver = {
+	.driver = {
+		.name   = "hisilicon,hisfc350",
+		.of_match_table = hisi_spi_nor_dt_ids,
+	},
+	.probe		= hisfc350_spi_nor_probe,
+	.remove		= hisfc350_spi_nor_remove,
+	.shutdown   = hisfc350_spi_nor_shutdown,
+#ifdef CONFIG_PM
+	.suspend	= hisfc350_driver_suspend,
+	.resume		= hisfc350_driver_resume,
+#endif
+};
+module_platform_driver(hisi_spi_nor_driver);
+
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("Hisfc350 Device Driver, Version 1.00");
diff --git a/drivers/mtd/spi-nor/hisfc350/hisfc350.h b/drivers/mtd/spi-nor/hisfc350/hisfc350.h
new file mode 100644
index 0000000..92ad588
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/hisfc350.h
@@ -0,0 +1,325 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef HISFC350H
+#define HISFC350H
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/mtd/mtd.h>
+#include <linux/pm.h>
+#include <mach/io.h>
+#include <linux/clk.h>
+
+/*****************************************************************************/
+#ifndef CONFIG_HISFC350_CHIP_NUM
+#define CONFIG_HISFC350_CHIP_NUM			(2)
+#  warning NOT config CONFIG_HISFC350_CHIP_NUM,\
+	used default value, maybe invalid.
+#endif /* CONFIG_HISFC350_CHIP_NUM */
+
+#define HISFC350_SYSCTRL_LENGTH				(0x100)
+/*****************************************************************************/
+#define HISFC350_MAX_READY_WAIT_JIFFIES			(40 * HZ)
+
+/*****************************************************************************/
+#define HISFC350_REG_BASE_LEN			(0x500)
+#define HISFC350_DMA_ALIGN_SIZE			(256)
+#define HISFC350_DMA_ALIGN_MASK			(HISFC350_DMA_ALIGN_SIZE-1)
+#define HISFC350_DMA_MAX_SIZE			(4096)
+#define HISFC350_DMA_MAX_MASK			(HISFC350_DMA_MAX_SIZE-1)
+#define HISFC350_BUFFER_BASE_LEN		(0x4000000) /* 64MB */
+
+/*****************************************************************************/
+
+/* These macroes are for debug only,reg read is slower then dma read */
+#undef HISFCV350_SUPPORT_REG_READ
+/* #define HISFCV350_SUPPORT_REG_READ */
+#undef HISFCV350_SUPPORT_REG_WRITE
+/* #define HISFCV350_SUPPORT_REG_WRITE */
+#undef HISFCV350_SUPPORT_BUS_READ
+/* #define HISFCV350_SUPPORT_BUS_READ */
+#undef HISFCV350_SUPPORT_BUS_WRITE
+/* #define HISFCV350_SUPPORT_BUS_WRITE */
+
+#ifdef CONFIG_HISFC350_ENABLE_INTR_DMA
+#define SFC_IRQ_NUM 49
+#define SFC_WAIT_FLAG_R 1
+#define SFC_WAIT_FLAG_W 2
+#define SFC_INTMASK		0x128
+#define SFC_MINTSTS		0x124
+#define SFC_RINTSTS		0x120
+#define SFC_INTCLR		0x12c
+#define SFC_DMA_INT_STATUS	(1<<1)
+#define SFC_CMD_INT_STATUS	(1<<0)
+#define SFC_DMA_INT_MASK	(1<<1)
+#define SFC_CMD_INT_MASK	(1<<0)
+#define ALL_INT_CLR		0x2
+#endif
+
+#define HISFC350_GLOBAL_CONFIG				0x0100
+#define HISFC350_GLOBAL_CONFIG_READ_DELAY(_n)		(((_n) & 0x03) << 3)
+#define HISFC350_GLOBAL_CONFIG_ADDR_MODE_4B		(1 << 2)
+#define HISFC350_GLOBAL_CONFIG_ADDR_MODE_DIS_4B		(0 << 2)
+#define HISFC350_GLOBAL_CONFIG_WRITE_PROTECT		(1 << 1)
+#define HISFC350_GLOBAL_CONFIG_SPI_MODE3		(1 << 0)
+
+#define HISFC350_TIMING					0x0110
+#define HISFC350_TIMING_TSHSL(_n)			((_n) & 0xF)
+#define HISFC350_TIMING_TCSS(_n)			(((_n) & 0x7) << 8)
+#define HISFC350_TIMING_TCSH(_n)			(((_n) & 0x7) << 12)
+
+#define HISFC350_INT_RAW_STATUS				0x0120
+#define HISFC350_INT_RAW_STATUS_DMA_DONE		(1<<1)
+#define HISFC350_INT_STATUS				0x0124
+#define HISFC350_INT_MASK				0x0128
+#define HISFC350_INT_CLEAR				0x012C
+#define HISFC350_INT_CLEAR_DMA_DONE			(1<<1)
+
+#define HISFC350_BUS_CONFIG1				0x0200
+#define HISFC350_BUS_CONFIG1_READ_EN			(1<<31)
+#define HISFC350_BUS_CONFIG1_WRITE_EN			(1<<30)
+#define HISFC350_BUS_CONFIG1_WRITE_INS(_n)		((_n & 0xFF) << 22)
+#define HISFC350_BUS_CONFIG1_WRITE_DUMMY_CNT(_n)	((_n & 0x7) << 19)
+#define HISFC350_BUS_CONFIG1_WRITE_IF_TYPE(_n)		((_n & 0x7) << 16)
+#define HISFC350_BUS_CONFIG1_READ_INS(_n)		((_n & 0xFF) << 8)
+#define HISFC350_BUS_CONFIG1_READ_PREF_CNT(_n)		((_n & 0x3) << 6)
+#define HISFC350_BUS_CONFIG1_READ_DUMMY_CNT(_n)		((_n & 0x7) << 3)
+#define HISFC350_BUS_CONFIG1_READ_IF_TYPE(_n)		(_n & 0x7)
+
+#define HISFC350_BUS_CONFIG2				0x0204
+#define HISFC350_BUS_CONFIG2_WIP_LOCATE(_n)		(_n & 0x7)
+
+#define HISFC350_BUS_FLASH_SIZE				0x0210
+#define HISFC350_BUS_FLASH_SIZE_CS0_MASK		0x0F
+#define HISFC350_BUS_FLASH_SIZE_CS1_MASK		(0x0F << 8)
+#define HISFC350_BUS_BASE_ADDR_CS0			0x0214
+#define HISFC350_BUS_BASE_ADDR_CS1			0x0218
+#define HISFC350_BUS_ALIAS_ADDR				0x021C
+#define HISFC350_BUS_ALIAS_CS				0x0220
+#define HISFC350_BUS_DMA_CTRL				0x0240
+#define HISFC350_BUS_DMA_CTRL_START			(1 << 0)
+#define HISFC350_BUS_DMA_CTRL_RW(_rw)			((_rw)<<1)
+#define HISFC350_BUS_DMA_CTRL_CS(_cs)			(((_cs) & 0x01) << 4)
+
+#define HISFC350_BUS_DMA_MEM_SADDR			0x0244
+#define HISFC350_BUS_DMA_FLASH_SADDR			0x0248
+#define HISFC350_BUS_DMA_LEN				0x024C
+#define HISFC350_BUS_DMA_LEN_DATA_CNT(_n)		((_n - 1) & 0x0FFFFFFF)
+#define HISFC350_BUS_DMA_AHB_CTRL			0x0250
+#define HISFC350_BUS_DMA_AHB_CTRL_INCR4_EN		(1<<0)
+#define HISFC350_BUS_DMA_AHB_CTRL_INCR8_EN		(1<<1)
+#define HISFC350_BUS_DMA_AHB_CTRL_INCR16_EN		(1<<2)
+
+#define HISFC350_CMD_CONFIG				0x0300
+#define HISFC350_CMD_CONFIG_MEM_IF_TYPE(_n)		(((_n) & 0x07) << 17)
+#define HISFC350_CMD_CONFIG_DATA_CNT(_n)		(((_n-1) & 0x3F) << 9)
+#define HISFC350_CMD_CONFIG_RW_READ			(1<<8)
+#define HISFC350_CMD_CONFIG_DATA_EN			(1<<7)
+#define HISFC350_CMD_CONFIG_DUMMY_CNT(_n)		(((_n) & 0x07) << 4)
+#define HISFC350_CMD_CONFIG_ADDR_EN			(1<<3)
+#define HISFC350_CMD_CONFIG_SEL_CS(_cs)			(((_cs) & 0x01) << 1)
+#define HISFC350_CMD_CONFIG_START			(1<<0)
+
+#define HISFC350_CMD_INS				0x0308
+#define HISFC350_CMD_ADDR				0x030C
+#define HISFC350_CMD_ADDR_MASK				0x3FFFFFFF
+#define HISFC350_CMD_DATABUF0				0x0400
+#define HISFC350_CMD_DATABUF15				0x043C
+
+#define HISFC350_IFCYCLE_STD				0
+#define HISFC350_IFCYCLE_DUAL				1
+#define HISFC350_IFCYCLE_DUAL_ADDR			2
+#define HISFC350_IFCYCLE_DUAL_CMD			3
+#define HISFC350_IFCYCLE_QUAD				5
+#define HISFC350_IFCYCLE_QUAD_ADDR			6
+#define HISFC350_IFCYCLE_QUAD_CMD			7
+
+#define HISFC350_REG_BUF_SIZE \
+	(HISFC350_CMD_DATABUF15 - HISFC350_CMD_DATABUF0 + 0x04)
+#define HISFC350_REG_BUF_MASK                 (HISFC350_REG_BUF_SIZE - 1)
+
+#undef  READ
+#define READ		1
+
+#undef  WRITE
+#define WRITE		0
+
+#undef  FALSE
+#define FALSE		0
+
+#undef  TRUE
+#define TRUE		1
+
+#define SPI_NOR_SR_LEN		1	/* Status Register length(byte) */
+#define SPI_NOR_CR_LEN		1	/* Config Register length(byte) */
+
+#define SPI_NOR_CR_SHIFT	8	/* Config Register shift(bit) */
+
+#define SPI_NOR_CR_QE_SHIFT	1
+#define SPI_NOR_CR_QE_MASK	(1 << SPI_NOR_CR_QE_SHIFT)
+
+#ifdef CONFIG_CMD_SPI_BLOCK_PROTECTION
+#define DEBUG_SPI_NOR_BP	0
+
+#define SPI_NOR_SR_SRWD_SHIFT	7
+#define SPI_NOR_SR_SRWD_MASK	(1 << SPI_NOR_SR_SRWD_SHIFT)
+
+#define SPI_NOR_SR_BP0_SHIFT	2
+#define SPI_NOR_SR_BP_WIDTH	0xf
+#define SPI_NOR_SR_BP_MASK	(SPI_NOR_SR_BP_WIDTH << SPI_NOR_SR_BP0_SHIFT)
+
+#define SPI_NOR_SR_TB_SHIFT	3
+#define SPI_NOR_SR_TB_MASK	(1 << SPI_NOR_SR_TB_SHIFT)
+
+#define SPI_NOR_SR_WIP_MASK	(1 << 0)
+
+#define BP_OP_SET		0
+#define BP_OP_GET		1
+
+#define BP_CMP_TOP		0
+#define BP_CMP_BOTTOM		1
+
+enum block_protection_level {
+	BP_LEVEL_0	= 0,
+	BP_LEVEL_1	= 1,
+	BP_LEVEL_2	= 2,
+	BP_LEVEL_3	= 3,
+	BP_LEVEL_4	= 4,
+	BP_LEVEL_5	= 5,
+	BP_LEVEL_6	= 6,
+	BP_LEVEL_7	= 7,
+	BP_LEVEL_8	= 8,
+	BP_LEVEL_9	= 9,
+	BP_LEVEL_10	= 10,
+	BP_LEVEL_END,
+};
+
+#define BP_LEVEL_MAX    (BP_LEVEL_END - 1)
+#endif /* CONFIG_CMD_SPI_BLOCK_PROTECTION */
+
+/*****************************************************************************/
+struct hisfc_spi;
+
+struct spi_driver {
+	int (*wait_ready)(struct hisfc_spi *spi);
+	int (*write_enable)(struct hisfc_spi *spi);
+	int (*entry_4addr)(struct hisfc_spi *spi, int enable);
+	int (*bus_prepare)(struct hisfc_spi *spi, int op);
+	int (*qe_enable)(struct hisfc_spi *spi);
+};
+
+struct hisfc_spi {
+	char *name;
+	int chipselect;
+	unsigned long long chipsize;
+	unsigned int erasesize;
+	void __iomem *iobase;
+
+	unsigned int addrcycle;
+	struct spi_operation  read[1];
+	struct spi_operation  write[1];
+	struct spi_operation  erase[MAX_SPI_OP];
+	void *host;
+	struct spi_driver *driver;
+};
+
+struct hisfc_host {
+	struct mtd_info	mtd[1];
+	void __iomem	*iobase;
+	void __iomem	*regbase;
+	struct device	*dev;
+	struct mutex	lock;
+	void __iomem	*sysreg;
+	struct clk *clk;
+#ifdef CONFIG_HISFC350_ENABLE_INTR_DMA
+	wait_queue_head_t       intr_wait;
+	unsigned int wait_fg;
+#endif
+	void (*set_system_clock)(struct hisfc_host *host,
+		struct spi_operation *op, int clk_en);
+
+	void (*set_host_addr_mode)(struct hisfc_host *host, int enable);
+	char *buffer;
+	unsigned int dma_buffer;
+	int add_partition;
+	int num_chip;
+	struct hisfc_spi spi[CONFIG_HISFC350_CHIP_NUM+1];
+	char reg_buffer[HISFC350_REG_BUF_SIZE];
+
+	int (*suspend)(struct platform_device *pltdev, pm_message_t state);
+	int (*resume)(struct platform_device *pltdev);
+#ifdef CONFIG_CMD_SPI_BLOCK_PROTECTION
+	unsigned int start_addr;
+	unsigned int end_addr;
+	unsigned char cmp;
+	unsigned char level;
+#endif
+};
+
+#ifdef CONFIG_CMD_SPI_BLOCK_PROTECTION
+void hisfc350_spi_lock_init(struct hisfc_host *host);
+extern u_char spi_general_get_flash_register(struct hisfc_spi *spi, u_char cmd);
+#endif
+
+#define MTD_TO_HOST(_mtd)		((struct hisfc_host *)(_mtd))
+/*****************************************************************************/
+#define hisfc_read(_host, _reg) \
+	readl(_host->regbase + (_reg))
+
+#define hisfc_write(_host, _reg, _value) \
+	writel((_value), _host->regbase + (_reg))
+
+#define HISFC350_CMD_WAIT_CPU_FINISH(_host) do {\
+	unsigned int timeout = 0x10000000; \
+	while (((hisfc_read((_host), HISFC350_CMD_CONFIG) \
+		& HISFC350_CMD_CONFIG_START)) && timeout) \
+		--timeout; \
+	if (!timeout) \
+		DBG_BUG("cmd wait cpu finish timeout\n"); \
+} while (0)
+
+#define HISFC350_DMA_WAIT_CPU_FINISH(_host) do {\
+	unsigned int timeout = 0x10000000; \
+	while (((hisfc_read((_host), HISFC350_BUS_DMA_CTRL) \
+		& HISFC350_BUS_DMA_CTRL_START)) && timeout) { \
+		--timeout; cond_resched(); } \
+	if (!timeout) \
+		DBG_BUG("dma wait cpu finish timeout\n"); \
+} while (0)
+
+/*****************************************************************************/
+#if 0
+#  define DBG_MSG(_fmt, arg...)
+#else
+#  define DBG_MSG(_fmt, arg...) \
+	printk(KERN_INFO "%s(%d): " _fmt, __FILE__, __LINE__, ##arg);
+#endif
+
+#define DBG_WARN(_fmt, arg...) \
+	printk(KERN_INFO "%s(%d): " _fmt, __FILE__, __LINE__, ##arg);
+
+#define DBG_BUG(fmt, args...) do { \
+	printk(KERN_ERR "%s(%d): BUG: " fmt, __FILE__, __LINE__, ##args); \
+	asm("b ."); \
+} while (0)
+/*****************************************************************************/
+#ifndef NULL
+#  define NULL		(void *)0
+#endif
+/*****************************************************************************/
+#endif /* HISFC350H */
diff --git a/drivers/mtd/spi-nor/hisfc350/hisfc350_hi3516a.c b/drivers/mtd/spi-nor/hisfc350/hisfc350_hi3516a.c
new file mode 100644
index 0000000..c2847a1
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/hisfc350_hi3516a.c
@@ -0,0 +1,102 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/io.h>
+#include "../spi_ids.h"
+#include "hisfc350.h"
+
+#define HISFC350_CRG48				(0x00C0)
+#define HISFC350_CRG48_RST			(1 << 0)
+#define HISFC350_CRG48_CLKEN			(1 << 1)
+#define HISFC350_CRG48_CLK_24M			(0 << 2)
+#define HISFC350_CRG48_CLK_75M			((0 << 3) | (1 << 2))
+#define HISFC350_CRG48_CLK_125M			((1 << 2) | (1 << 3))
+#define SYS_CTRL_BASE				(0x20050000)
+#define SFC_ADDR_MODE_REG			(0x8C)
+#define SFC_ADDR_MODE_MASK			(0x80)
+#define SFC_CLSEL_MASK				(0xC)
+#define SFC_PERI_CLKDIV1_SHIFT			(28)
+#define SFC_PERI_CLKDIV1_MASK			(0xF)
+/*****************************************************************************/
+#define GET_SFC_ADDR_MODE ({\
+	int start_up_mode = 0;\
+	start_up_mode = readl((void *)IO_ADDRESS(SYS_CTRL_BASE + SFC_ADDR_MODE_REG));\
+	start_up_mode &= SFC_ADDR_MODE_MASK;\
+	start_up_mode; })
+/*****************************************************************************/
+void hisfc350_set_system_clock(struct hisfc_host *host,
+	struct spi_operation *op, int clk_en)
+{
+	unsigned int regval = readl(host->sysreg + HISFC350_CRG48);
+
+	regval = regval & (~SFC_CLSEL_MASK);
+
+	if (op && op->clock) {
+		regval &= ~SFC_CLSEL_MASK;
+		regval |= op->clock & SFC_CLSEL_MASK;
+	} else {
+		regval &= ~SFC_CLSEL_MASK;
+		regval |= HISFC350_CRG48_CLK_24M; /* Default Clock */
+	}
+
+	if (clk_en)
+		regval |= HISFC350_CRG48_CLKEN;
+
+	if (regval != readl(host->sysreg + HISFC350_CRG48))
+		writel(regval, (host->sysreg + HISFC350_CRG48));
+}
+
+/*****************************************************************************/
+void hisfc350_get_best_clock(unsigned int *clock)
+{
+	int ix;
+	int clk_reg;
+
+#define CLK_2X(_clk)	(((_clk) + 1) >> 1)
+	unsigned int sysclk[] = {
+		CLK_2X(24),	HISFC350_CRG48_CLK_24M,
+		CLK_2X(75),	HISFC350_CRG48_CLK_75M,
+		CLK_2X(125),	HISFC350_CRG48_CLK_125M,
+		0, 0,
+	};
+#undef CLK_2X
+
+	clk_reg = HISFC350_CRG48_CLK_24M;
+	for (ix = 0; sysclk[ix]; ix += 2) {
+		if (*clock < sysclk[ix])
+			break;
+		clk_reg = sysclk[ix + 1];
+	}
+
+	*clock = clk_reg;
+}
+
+/*****************************************************************************/
+#ifdef CONFIG_HISFC350_SHOW_CYCLE_TIMING
+char *hisfc350_get_clock_str(unsigned int clk_reg)
+{
+	static char buffer[40];
+
+	/* calculate reference PERI_CLKDIV1[31:28] */
+	clk_reg = 216 / ((clk_reg >> SFC_PERI_CLKDIV1_SHIFT)
+				& SFC_PERI_CLKDIV1_MASK);
+	sprintf(buffer, "%dM", clk_reg);
+
+	return buffer;
+}
+#endif /* CONFIG_HISFC350_SHOW_CYCLE_TIMING */
diff --git a/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_en25q64.c b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_en25q64.c
new file mode 100644
index 0000000..0db4bc8
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_en25q64.c
@@ -0,0 +1,29 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/io.h>
+#include <linux/mtd/mtd.h>
+#include <linux/errno.h>
+#include <linux/sched.h>
+#include "../spi_ids.h"
+#include "hisfc350.h"
+
+static int spi_en25q64_qe_enable(struct hisfc_spi *spi)
+{
+	return 0;
+}
diff --git a/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_gd25qxxx.c b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_gd25qxxx.c
new file mode 100644
index 0000000..65b5a0d
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_gd25qxxx.c
@@ -0,0 +1,110 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/io.h>
+#include <linux/mtd/mtd.h>
+#include <linux/errno.h>
+
+#include "../spi_ids.h"
+#include "hisfc350.h"
+
+#define SPI_BRWR	0x17
+#define SPI_EN4B	0x80
+#define SPI_EX4B	0x00
+
+#define GD_SPI_CMD_SR_QE   (0x2)
+#define GD_SPI_CMD_SR_DISQE   (0x0)
+#define SPI_CMD_WRSR1      (0x1)
+
+static int spi_gd25qxxx_qe_enable(struct hisfc_spi *spi)
+{
+	struct hisfc_host *host = (struct hisfc_host *)spi->host;
+	unsigned int regval = 0;
+	unsigned int qe_op1 = 0;
+	unsigned int qe_op2 = 0;
+
+	if (hisfc350_is_quad(spi)) {
+		qe_op1 = SPI_CMD_SR_QE;
+		qe_op2 = GD_SPI_CMD_SR_QE;
+	} else {
+		qe_op1 = SPI_CMD_SR_XQE;
+		qe_op2 = GD_SPI_CMD_SR_DISQE;
+	}
+
+	spi->driver->write_enable(spi);
+
+	/* First, we enable QE(4bit r&w) for 16pin gd flash */
+	hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_WRSR1);
+	hisfc_write(host, HISFC350_CMD_DATABUF0, qe_op1);
+
+	hisfc_write(host, HISFC350_CMD_CONFIG,
+			HISFC350_CMD_CONFIG_MEM_IF_TYPE(spi->
+				write->iftype)
+			| HISFC350_CMD_CONFIG_DATA_CNT(2)
+			| HISFC350_CMD_CONFIG_DATA_EN
+			| HISFC350_CMD_CONFIG_DUMMY_CNT(spi->
+				write->dummy)
+			| HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+			| HISFC350_CMD_CONFIG_START);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	spi->driver->wait_ready(spi);
+
+	/* Second, we enable QE for 8 pin gd flash. This will not affect
+	   16pin gd spi, if the QE bit has been set 1.
+	 */
+	spi->driver->write_enable(spi);
+
+	hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_WRSR2);
+	hisfc_write(host, HISFC350_CMD_DATABUF0, qe_op2);
+
+	hisfc_write(host, HISFC350_CMD_CONFIG,
+			HISFC350_CMD_CONFIG_MEM_IF_TYPE(spi->
+				write->iftype)
+			| HISFC350_CMD_CONFIG_DATA_CNT(1)
+			| HISFC350_CMD_CONFIG_DATA_EN
+			| HISFC350_CMD_CONFIG_DUMMY_CNT(spi->
+				write->dummy)
+			| HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+			| HISFC350_CMD_CONFIG_START);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	spi->driver->wait_ready(spi);
+
+	if (DEBUG_SPI) {
+		hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_RDSR2);
+
+		hisfc_write(host, HISFC350_CMD_CONFIG,
+				HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+				| HISFC350_CMD_CONFIG_DATA_CNT(1)
+				| HISFC350_CMD_CONFIG_DATA_EN
+				| HISFC350_CMD_CONFIG_RW_READ
+				| HISFC350_CMD_CONFIG_START);
+		HISFC350_CMD_WAIT_CPU_FINISH(host);
+		regval = hisfc_read(host, HISFC350_CMD_DATABUF0);
+		printk(KERN_INFO "QEbit = 0x2? : 0x%x\n", regval);
+		if ((regval & GD_SPI_CMD_SR_QE))
+			printk(KERN_INFO "QE bit enable success\n");
+		else
+			printk(KERN_INFO "QE bit enable failed\n");
+	}
+	return 0;
+}
+
diff --git a/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_general.c b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_general.c
new file mode 100644
index 0000000..8ad3545
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_general.c
@@ -0,0 +1,266 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/io.h>
+#include <linux/delay.h>
+#include <linux/mtd/mtd.h>
+#include <linux/errno.h>
+#include <linux/sched.h>
+#include "../spi_ids.h"
+#include "hisfc350.h"
+
+#define DEBUG_SPI 0
+#define DEBUG_GET_SR 0
+#define DEBUG_SPI_QE 0
+
+/*****************************************************************************/
+u_char spi_general_get_flash_register(struct hisfc_spi *spi, u_char cmd)
+{
+	unsigned char status;
+	unsigned int regval;
+	struct hisfc_host *host = (struct hisfc_host *)spi->host;
+
+	if (DEBUG_GET_SR)
+		printk(KERN_INFO "* Start get flash Register %#x.\n", cmd);
+
+	hisfc_write(host, HISFC350_CMD_INS, cmd);
+	if (DEBUG_GET_SR)
+		printk(KERN_INFO "  Set INS[%#x]%#x\n", HISFC350_CMD_INS, cmd);
+
+	regval = HISFC350_CMD_CONFIG_DATA_CNT(SPI_NOR_SR_LEN)
+		| HISFC350_CMD_CONFIG_RW_READ
+		| HISFC350_CMD_CONFIG_DATA_EN
+		| HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+		| HISFC350_CMD_CONFIG_START;
+
+	hisfc_write(host, HISFC350_CMD_CONFIG, regval);
+	if (DEBUG_GET_SR)
+		printk(KERN_INFO "  Set CONFIG[%#x]%#x\n", HISFC350_CMD_CONFIG,
+				regval);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	status = hisfc_read(host, HISFC350_CMD_DATABUF0);
+	if (DEBUG_GET_SR)
+		printk(KERN_INFO "* Get flash Register %#x, val[%#x]\n", cmd,
+				status);
+
+	return status;
+}
+
+/*****************************************************************************/
+static int spi_general_wait_ready(struct hisfc_spi *spi)
+{
+	unsigned long status;
+	unsigned long deadline = jiffies + HISFC350_MAX_READY_WAIT_JIFFIES;
+
+	do {
+		status = spi_general_get_flash_register(spi, SPI_CMD_RDSR);
+		if (!(status & SPI_CMD_SR_WIP))
+			return 0;
+
+		cond_resched();
+
+	} while (!time_after_eq(jiffies, deadline));
+
+	printk(KERN_ERR "Wait spi flash ready timeout.\n");
+
+	return 1;
+}
+
+/*****************************************************************************/
+static int spi_general_write_enable(struct hisfc_spi *spi)
+{
+	struct hisfc_host *host = (struct hisfc_host *)spi->host;
+
+	spi->driver->wait_ready(spi);
+
+	hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_WREN);
+
+	hisfc_write(host, HISFC350_CMD_CONFIG,
+			HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+			| HISFC350_CMD_CONFIG_START);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	return 0;
+}
+
+/*****************************************************************************/
+/*
+  enable 4byte adress for SPI which memory more than 16M
+*/
+static int spi_general_entry_4addr(struct hisfc_spi *spi, int enable)
+{
+	struct hisfc_host *host = (struct hisfc_host *)spi->host;
+
+	spi->driver->wait_ready(spi);
+
+	if (spi->addrcycle != SPI_4BYTE_ADDR_LEN)
+		return 0;
+
+	if (enable)
+		hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_EN4B);
+	else
+		hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_EX4B);
+
+	hisfc_write(host, HISFC350_CMD_CONFIG,
+			HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+			| HISFC350_CMD_CONFIG_START);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	host->set_host_addr_mode(host, enable);
+
+	return 0;
+}
+
+/*****************************************************************************/
+/*
+  configure prepared for dma or bus read or write mode
+*/
+static int spi_general_bus_prepare(struct hisfc_spi *spi, int op)
+{
+	unsigned int regval = 0;
+	struct hisfc_host *host = (struct hisfc_host *)spi->host;
+
+#ifdef HISFCV350_SUPPORT_BUS_WRITE
+	regval |= HISFC350_BUS_CONFIG1_WRITE_EN;
+#endif
+	regval |= HISFC350_BUS_CONFIG1_WRITE_INS(spi->write->cmd);
+	regval |= HISFC350_BUS_CONFIG1_WRITE_DUMMY_CNT(spi->write->dummy);
+	regval |= HISFC350_BUS_CONFIG1_WRITE_IF_TYPE(spi->write->iftype);
+
+#ifdef HISFCV350_SUPPORT_BUS_READ
+	regval |= HISFC350_BUS_CONFIG1_READ_EN;
+#endif
+	regval |= HISFC350_BUS_CONFIG1_READ_PREF_CNT(0);
+	regval |= HISFC350_BUS_CONFIG1_READ_INS(spi->read->cmd);
+	regval |= HISFC350_BUS_CONFIG1_READ_DUMMY_CNT(spi->read->dummy);
+	regval |= HISFC350_BUS_CONFIG1_READ_IF_TYPE(spi->read->iftype);
+
+	hisfc_write(host, HISFC350_BUS_CONFIG1, regval);
+	hisfc_write(host, HISFC350_BUS_CONFIG2,
+		HISFC350_BUS_CONFIG2_WIP_LOCATE(0));
+	if (op == READ)
+		host->set_system_clock(host, spi->read, TRUE);
+	else if (op == WRITE)
+		host->set_system_clock(host, spi->write, TRUE);
+
+	return 0;
+}
+
+/*****************************************************************************/
+/*
+  judge whether SPI support QUAD read write or not
+*/
+static int hisfc350_is_quad(struct hisfc_spi *spi)
+{
+	if (DEBUG_SPI_QE)
+		printk(KERN_INFO "SPI read if[%d] write if[%d]\n",
+			spi->read->iftype, spi->write->iftype);
+
+	if (spi->write->iftype == 5 || spi->write->iftype == 6
+		|| spi->write->iftype == 7 || spi->read->iftype == 5
+		|| spi->read->iftype == 6 || spi->read->iftype == 7)
+		return 1;
+
+	return 0;
+}
+
+/*****************************************************************************/
+/*
+   enable QE bit if QUAD read write is supported by SPI
+*/
+static int spi_general_qe_enable(struct hisfc_spi *spi)
+{
+	unsigned char status, config, op;
+	unsigned int reg;
+	const char *str[] = {"Disable", "Enable"};
+	struct hisfc_host *host = (struct hisfc_host *)spi->host;
+
+	op = hisfc350_is_quad(spi);
+
+	if (DEBUG_SPI_QE)
+		printk(KERN_INFO "* Start SPI Nor %s Quad.\n", str[op]);
+
+	config = spi_general_get_flash_register(spi, SPI_CMD_RDCR);
+	if (DEBUG_SPI_QE)
+		printk(KERN_INFO "  Read config %#x, val[%#x]\n", SPI_CMD_RDCR,
+				config);
+	if (((config & SPI_NOR_CR_QE_MASK) >> SPI_NOR_CR_QE_SHIFT) == op) {
+		if (DEBUG_SPI_QE)
+			printk(KERN_INFO "* Quad was %sd!\n", str[op]);
+		return op;
+	}
+
+	status = spi_general_get_flash_register(spi, SPI_CMD_RDSR);
+	reg = (config << SPI_NOR_CR_SHIFT) | status;
+	if (DEBUG_SPI_QE)
+		printk(KERN_INFO "  Read CR/SR[%#x]\n", reg);
+
+	spi->driver->write_enable(spi);
+
+	if (op)
+		reg |= (SPI_NOR_CR_QE_MASK << SPI_NOR_CR_SHIFT);
+	else
+		reg &= ~(SPI_NOR_CR_QE_MASK << SPI_NOR_CR_SHIFT);
+	hisfc_write(host, HISFC350_CMD_DATABUF0, reg);
+	if (DEBUG_SPI_QE)
+		printk(KERN_INFO "  Set DATA[%#x]%#x\n", HISFC350_CMD_DATABUF0,
+				reg);
+
+	hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_WRSR);
+	if (DEBUG_SPI_QE)
+		printk(KERN_INFO "  Set INS[%#x]%#x\n", HISFC350_CMD_INS,
+				SPI_CMD_WRSR);
+
+	reg = HISFC350_CMD_CONFIG_DATA_CNT(SPI_NOR_SR_LEN + SPI_NOR_CR_LEN)
+		| HISFC350_CMD_CONFIG_DATA_EN
+		| HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+		| HISFC350_CMD_CONFIG_START;
+	hisfc_write(host, HISFC350_CMD_CONFIG, reg);
+	if (DEBUG_SPI_QE)
+		printk(KERN_INFO "  Set CONFIG[%#x]%#x\n", HISFC350_CMD_CONFIG,
+				reg);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	if (DEBUG_SPI_QE) {
+		spi->driver->wait_ready(spi);
+
+		config = spi_general_get_flash_register(spi, SPI_CMD_RDCR);
+		if (((config & SPI_NOR_CR_QE_MASK) >> SPI_NOR_CR_QE_SHIFT)
+				== op)
+			printk(KERN_INFO "* SPI Quad %s succeed. [%#x]\n",
+					str[op], config);
+		else
+			DBG_MSG("%s Quad failed! [%#x]\n", str[op], config);
+	}
+
+	return op;
+}
+
+/*****************************************************************************/
+/*
+  some chip don't QUAD enable
+*/
+static int spi_do_not_qe_enable(struct hisfc_spi *spi)
+{
+	return 0;
+}
\ No newline at end of file
diff --git a/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_ids.c b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_ids.c
new file mode 100644
index 0000000..a08e40f
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_ids.c
@@ -0,0 +1,2208 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include "../spi_ids.h"
+
+/*****************************************************************************/
+
+#define SET_READ_STD(_dummy_, _size_, _clk_) \
+	static struct spi_operation read_std_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_STD, SPI_CMD_READ, _dummy_, _size_, _clk_ }
+
+#define READ_STD(_dummy_, _size_, _clk_) read_std_##_dummy_##_size_##_clk_
+
+#define SET_READ_FAST(_dummy_, _size_, _clk_) \
+	static struct spi_operation read_fast_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_FAST, SPI_CMD_FAST_READ, _dummy_, _size_, _clk_ }
+
+#define READ_FAST(_dummy_, _size_, _clk_) read_fast_##_dummy_##_size_##_clk_
+
+#define SET_READ_DUAL(_dummy_, _size_, _clk_) \
+	static struct spi_operation read_dual_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_DUAL, SPI_CMD_READ_DUAL, _dummy_, _size_, _clk_ }
+
+#define READ_DUAL(_dummy_, _size_, _clk_) read_dual_##_dummy_##_size_##_clk_
+
+#define SET_READ_QUAD(_dummy_, _size_, _clk_) \
+	static struct spi_operation read_quad_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_QUAD, SPI_CMD_READ_QUAD, _dummy_, _size_, _clk_ }
+
+#define READ_QUAD(_dummy_, _size_, _clk_) read_quad_##_dummy_##_size_##_clk_
+
+#define SET_READ_DUAL_ADDR(_dummy_, _size_, _clk_) \
+	static struct spi_operation \
+	read_dual_addr_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_DUAL_ADDR, SPI_CMD_READ_DUAL_ADDR, _dummy_, _size_, _clk_ }
+
+#define READ_DUAL_ADDR(_dummy_, _size_, _clk_) \
+	read_dual_addr_##_dummy_##_size_##_clk_
+
+#define SET_READ_QUAD_ADDR(_dummy_, _size_, _clk_) \
+	static struct spi_operation \
+	read_quad_addr_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_READ_QUAD_ADDR, SPI_CMD_READ_QUAD_ADDR, _dummy_, _size_, _clk_ }
+
+#define READ_QUAD_ADDR(_dummy_, _size_, _clk_) \
+	read_quad_addr_##_dummy_##_size_##_clk_
+
+#define SET_WRITE_STD(_dummy_, _size_, _clk_) \
+	static struct spi_operation write_std_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_WRITE_STD, SPI_CMD_PP, _dummy_, _size_, _clk_ }
+
+#define WRITE_STD(_dummy_, _size_, _clk_) write_std_##_dummy_##_size_##_clk_
+
+#define SET_WRITE_DUAL(_dummy_, _size_, _clk_) \
+	static struct spi_operation write_dual_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_WRITE_DUAL, SPI_CMD_WRITE_DUAL, _dummy_, _size_, _clk_ }
+
+#define WRITE_DUAL(_dummy_, _size_, _clk_) write_dual_##_dummy_##_size_##_clk_
+
+#define SET_WRITE_QUAD(_dummy_, _size_, _clk_) \
+	static struct spi_operation write_quad_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_WRITE_QUAD, SPI_CMD_WRITE_QUAD, _dummy_, _size_, _clk_ }
+
+#define WRITE_QUAD(_dummy_, _size_, _clk_) \
+	write_quad_##_dummy_##_size_##_clk_
+
+#define SET_WRITE_DUAL_ADDR(_dummy_, _size_, _clk_) \
+	static struct spi_operation \
+	write_dual_addr_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_WRITE_DUAL_ADDR, SPI_CMD_WRITE_DUAL_ADDR,\
+		_dummy_, _size_, _clk_ }
+
+#define WRITE_DUAL_ADDR(_dummy_, _size_, _clk_) \
+	write_dual_addr_##_dummy_##_size_##_clk_
+
+#define SET_WRITE_QUAD_ADDR(_dummy_, _size_, _clk_) \
+	static struct spi_operation \
+	write_quad_addr_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_WRITE_QUAD_ADDR, SPI_CMD_WRITE_QUAD_ADDR, \
+		_dummy_, _size_, _clk_ }
+
+#define WRITE_QUAD_ADDR(_dummy_, _size_, _clk_) \
+	write_quad_addr_##_dummy_##_size_##_clk_
+
+#define SET_ERASE_SECTOR_4K(_dummy_, _size_, _clk_) \
+	static struct spi_operation \
+		erase_sector_4k_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_ERASE_SECTOR_4K, SPI_CMD_SE_4K, _dummy_, _size_, _clk_ }
+
+#define ERASE_SECTOR_4K(_dummy_, _size_, _clk_) \
+	erase_sector_4k_##_dummy_##_size_##_clk_
+/*****************************************************************************/
+
+#define SET_ERASE_SECTOR_32K(_dummy_, _size_, _clk_) \
+	static struct spi_operation \
+		erase_sector_32k_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_ERASE_SECTOR_32K, SPI_CMD_SE_32K, _dummy_, _size_, _clk_ }
+
+#define ERASE_SECTOR_32K(_dummy_, _size_, _clk_) \
+	erase_sector_32k_##_dummy_##_size_##_clk_
+/*****************************************************************************/
+
+#define SET_ERASE_SECTOR_64K(_dummy_, _size_, _clk_) \
+	static struct spi_operation \
+		erase_sector_64k_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_ERASE_SECTOR_64K, SPI_CMD_SE_64K, _dummy_, _size_, _clk_ }
+
+#define ERASE_SECTOR_64K(_dummy_, _size_, _clk_) \
+	erase_sector_64k_##_dummy_##_size_##_clk_
+
+/*****************************************************************************/
+
+#define SET_ERASE_SECTOR_256K(_dummy_, _size_, _clk_) \
+	static struct spi_operation \
+		erase_sector_256k_##_dummy_##_size_##_clk_ = { \
+	SPI_IF_ERASE_SECTOR_256K, SPI_CMD_SE_256K, _dummy_, _size_, _clk_ }
+
+#define ERASE_SECTOR_256K(_dummy_, _size_, _clk_) \
+	erase_sector_256k_##_dummy_##_size_##_clk_
+/*****************************************************************************/
+SET_READ_STD(0, INFINITE, 0);
+SET_READ_STD(0, INFINITE, 20);
+SET_READ_STD(0, INFINITE, 32);
+SET_READ_STD(0, INFINITE, 33);
+SET_READ_STD(0, INFINITE, 40);
+SET_READ_STD(0, INFINITE, 50);
+SET_READ_STD(0, INFINITE, 54);
+SET_READ_STD(0, INFINITE, 55);
+SET_READ_STD(0, INFINITE, 66);
+
+SET_READ_FAST(1, INFINITE, 50);
+SET_READ_FAST(1, INFINITE, 64);
+SET_READ_FAST(1, INFINITE, 66);
+SET_READ_FAST(1, INFINITE, 75);
+SET_READ_FAST(1, INFINITE, 80);
+SET_READ_FAST(1, INFINITE, 86);
+SET_READ_FAST(1, INFINITE, 100);
+SET_READ_FAST(1, INFINITE, 104);
+SET_READ_FAST(1, INFINITE, 108);
+SET_READ_FAST(1, INFINITE, 133);
+
+SET_READ_DUAL(1, INFINITE, 64);
+SET_READ_DUAL(1, INFINITE, 75);
+SET_READ_DUAL(1, INFINITE, 80);
+SET_READ_DUAL(1, INFINITE, 84);
+SET_READ_DUAL(1, INFINITE, 104);
+SET_READ_DUAL(2, INFINITE, 104);
+SET_READ_DUAL(1, INFINITE, 108);
+SET_READ_DUAL(1, INFINITE, 133);
+
+SET_READ_DUAL_ADDR(2, INFINITE, 64);
+SET_READ_DUAL_ADDR(0, INFINITE, 80);
+SET_READ_DUAL_ADDR(1, INFINITE, 80);
+SET_READ_DUAL_ADDR(1, INFINITE, 84);
+SET_READ_DUAL_ADDR(2, INFINITE, 84);
+SET_READ_DUAL_ADDR(1, INFINITE, 104);
+SET_READ_DUAL_ADDR(1, INFINITE, 108);
+SET_READ_DUAL_ADDR(2, INFINITE, 133);
+
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+SET_READ_QUAD(1, INFINITE, 64);
+SET_READ_QUAD(1, INFINITE, 80);
+SET_READ_QUAD(1, INFINITE, 84);
+SET_READ_QUAD(1, INFINITE, 104);
+SET_READ_QUAD(1, INFINITE, 108);
+SET_READ_QUAD(1, INFINITE, 133);
+
+SET_READ_QUAD_ADDR(2, INFINITE, 80);
+/* SET_READ_QUAD_ADDR(3, INFINITE, 50); */
+SET_READ_QUAD_ADDR(3, INFINITE, 75);
+SET_READ_QUAD_ADDR(3, INFINITE, 80);
+SET_READ_QUAD_ADDR(5, INFINITE, 64);
+SET_READ_QUAD_ADDR(5, INFINITE, 84);
+SET_READ_QUAD_ADDR(3, INFINITE, 104);
+SET_READ_QUAD_ADDR(3, INFINITE, 108);
+SET_READ_QUAD_ADDR(5, INFINITE, 125);
+#endif
+/*****************************************************************************/
+SET_WRITE_STD(0, 256, 0);
+SET_WRITE_STD(0, 256, 33);
+SET_WRITE_STD(0, 256, 50);
+SET_WRITE_STD(0, 256, 64);
+SET_WRITE_STD(0, 256, 66);
+SET_WRITE_STD(0, 256, 75);
+SET_WRITE_STD(0, 256, 80);
+SET_WRITE_STD(0, 256, 86);
+SET_WRITE_STD(0, 256, 100);
+SET_WRITE_STD(0, 256, 104);
+SET_WRITE_STD(0, 256, 108);
+SET_WRITE_STD(0, 256, 133);
+
+SET_WRITE_DUAL(0, 256, 64);
+SET_WRITE_DUAL(0, 256, 75);
+SET_WRITE_DUAL(0, 256, 108);
+SET_WRITE_DUAL(0, 256, 133);
+
+SET_WRITE_DUAL_ADDR(0, 256, 64);
+SET_WRITE_DUAL_ADDR(0, 256, 75);
+SET_WRITE_DUAL_ADDR(0, 256, 108);
+SET_WRITE_DUAL_ADDR(0, 256, 133);
+
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+SET_WRITE_QUAD(0, 256, 64);
+SET_WRITE_QUAD(0, 256, 80);
+SET_WRITE_QUAD(0, 256, 108);
+SET_WRITE_QUAD(0, 256, 133);
+
+/* FIXME: As Micron MT25Q(and MIXC) and N25Q have different QUAD I/O write code,
+ * but they have the same ID, so we cannot compatiable it. User can open
+ * by theirselves. */
+SET_WRITE_QUAD_ADDR(0, 256, 33);
+/* SET_WRITE_QUAD_ADDR(0, 256, 64); */
+SET_WRITE_QUAD_ADDR(0, 256, 104);
+/* SET_WRITE_QUAD_ADDR(0, 256, 133); */
+#endif
+/*****************************************************************************/
+SET_ERASE_SECTOR_32K(0, _32K, 0);
+
+SET_ERASE_SECTOR_64K(0, _64K, 0);
+SET_ERASE_SECTOR_64K(0, _64K, 33);
+SET_ERASE_SECTOR_64K(0, _64K, 50);
+SET_ERASE_SECTOR_64K(0, _64K, 64);
+SET_ERASE_SECTOR_64K(0, _64K, 66);
+SET_ERASE_SECTOR_64K(0, _64K, 75);
+SET_ERASE_SECTOR_64K(0, _64K, 80);
+SET_ERASE_SECTOR_64K(0, _64K, 86);
+SET_ERASE_SECTOR_64K(0, _64K, 100);
+SET_ERASE_SECTOR_64K(0, _64K, 104);
+SET_ERASE_SECTOR_64K(0, _64K, 108);
+SET_ERASE_SECTOR_64K(0, _64K, 133);
+
+SET_ERASE_SECTOR_256K(0, _256K, 50);
+SET_ERASE_SECTOR_256K(0, _256K, 104);
+
+/*****************************************************************************/
+#include "hisfc350_spi_general.c"
+static struct spi_driver  spi_driver_general = {
+	.wait_ready   = spi_general_wait_ready,
+	.write_enable = spi_general_write_enable,
+	.entry_4addr  = spi_general_entry_4addr,
+	.bus_prepare  = spi_general_bus_prepare,
+	.qe_enable = spi_general_qe_enable,
+};
+
+static struct spi_driver spi_driver_no_qe = {
+	.wait_ready = spi_general_wait_ready,
+	.write_enable = spi_general_write_enable,
+	.entry_4addr = spi_general_entry_4addr,
+	.bus_prepare  = spi_general_bus_prepare,
+	.qe_enable = spi_do_not_qe_enable,
+};
+
+#include "hisfc350_spi_s25fl256s.c"
+static struct spi_driver  spi_driver_s25fl256s = {
+	.wait_ready   = spi_general_wait_ready,
+	.write_enable = spi_general_write_enable,
+	.entry_4addr  = spi_s25fl256s_entry_4addr,
+	.bus_prepare  = spi_general_bus_prepare,
+	.qe_enable = spi_general_qe_enable,
+};
+
+#include "hisfc350_spi_w25q256fv.c"
+static struct spi_driver  spi_driver_w25q256fv = {
+	.wait_ready   = spi_general_wait_ready,
+	.write_enable = spi_general_write_enable,
+	.entry_4addr  = spi_w25q256fv_entry_4addr,
+	.bus_prepare  = spi_general_bus_prepare,
+	.qe_enable = spi_general_qe_enable,
+};
+
+#include "hisfc350_spi_mx25l25635e.c"
+static struct spi_driver  spi_driver_mx25l25635e = {
+	.wait_ready   = spi_general_wait_ready,
+	.write_enable = spi_general_write_enable,
+	.entry_4addr  = spi_general_entry_4addr,
+	.bus_prepare  = spi_general_bus_prepare,
+	.qe_enable = spi_mx25l25635e_qe_enable,
+};
+
+static struct spi_driver  spi_driver_f25l64q = {
+	.wait_ready   = spi_general_wait_ready,
+	.write_enable = spi_general_write_enable,
+	.entry_4addr  = spi_general_entry_4addr,
+	.bus_prepare  = spi_general_bus_prepare,
+	.qe_enable = spi_mx25l25635e_qe_enable,
+};
+
+#include "hisfc350_spi_gd25qxxx.c"
+static struct spi_driver  spi_driver_gd25qxxx = {
+	.wait_ready   = spi_general_wait_ready,
+	.write_enable = spi_general_write_enable,
+	.entry_4addr  = spi_general_entry_4addr,
+	.bus_prepare  = spi_general_bus_prepare,
+	.qe_enable = spi_gd25qxxx_qe_enable,
+};
+
+#include "hisfc350_spi_micron.c"
+static struct spi_driver spi_driver_micron = {
+	.wait_ready = spi_general_wait_ready,
+	.write_enable = spi_general_write_enable,
+	.entry_4addr = spi_micron_entry_4addr,
+	.bus_prepare  = spi_general_bus_prepare,
+	.qe_enable = spi_do_not_qe_enable,
+};
+
+/*****************************************************************************/
+struct spi_info spi_info_table[] = {
+	/* name        id                id_len chipsize(Bytes) erasesize */
+	{
+		"at25fs010",  {0x1f, 0x66, 0x01}, 3,  _128K,  _32K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_32K(0, _32K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"at25fs040",  {0x1f, 0x66, 0x04}, 3,  _512K,  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"at25df041a", {0x1f, 0x44, 0x01}, 3,  _512K,  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"at25df641",  {0x1f, 0x48, 0x00}, 3,  _8M,    _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"at26f004",   {0x1f, 0x04, 0x00}, 3,  _512K,  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"at26df081a", {0x1f, 0x45, 0x01}, 3,  _1M,    _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"at26df161a", {0x1f, 0x46, 0x01}, 3,  _2M,    _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"at26df321",  {0x1f, 0x47, 0x01}, 3,  _4M,    _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	/* Macronix/MXIC */
+	{
+		"mx25l4005a",  {0xc2, 0x20, 0x13}, 3, _512K,  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"MX25L8006E",  {0xc2, 0x20, 0x14}, 3, _1M,    _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 33),
+			&READ_FAST(1, INFINITE, 86),
+			&READ_DUAL(1, INFINITE, 80),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 86),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 86),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"MX25L1606E",  {0xc2, 0x20, 0x15}, 3, _2M,    _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 33),
+			&READ_FAST(1, INFINITE, 86),
+			&READ_DUAL(1, INFINITE, 80),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 86),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 86),
+			0
+		},
+		&spi_driver_no_qe,
+	},
+
+	{
+		"mx25l3205d",  {0xc2, 0x20, 0x16}, 3, _4M,    _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	/* MX25L6406E and MX25L6436F have the same ID, but different I/O wire */
+	{
+		"MX25L6406E",  {0xc2, 0x20, 0x17}, 3, _8M,    _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 86),
+			&READ_DUAL(1, INFINITE, 80),
+/*
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 133),
+			&READ_QUAD_ADDR(3, INFINITE, 133),
+#endif
+*/
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 86),
+/*
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD_ADDR(0, 256, 133),
+#endif
+*/
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 86),
+			0
+		},
+		&spi_driver_mx25l25635e,
+	},
+
+	/* MX25R6435F Wide Voltage Range 1.65~3.6V */
+	{
+		"MX25R6435F", {0xc2, 0x28, 0x17}, 3, _8M, _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 33),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(3, INFINITE, 80),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 33),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD_ADDR(0, 256, 33),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 33),
+			0
+		},
+		&spi_driver_mx25l25635e,
+	},
+
+	{
+		"MX25L128XX", {0xc2, 0x20, 0x18}, 3, _16M, _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_DUAL_ADDR(1, INFINITE, 104),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 104),
+			&READ_QUAD_ADDR(3, INFINITE, 104),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 104),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD_ADDR(0, 256, 104),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 104),
+			0
+		},
+		&spi_driver_mx25l25635e,
+	},
+	/*
+	 The follow chips have the same chipid, but command have some difference
+
+	{"MX25L12836E", {0xc2, 0x20, 0x18}, 3, _16M,   _64K, 3,
+		{&READ_STD(0, INFINITE, 50), &READ_FAST(1, INFINITE, 108), 0},
+		{&WRITE_STD(0, 256, 108), 0},
+		{&ERASE_SECTOR_64K(0, _64K, 108), 0}},
+
+	{"MX25L12845E", {0xc2, 0x20, 0x18}, 3, _16M,   _64K, 3,
+		{&READ_STD(0, INFINITE, 50), &READ_FAST(1, INFINITE, 108), 0},
+		{&WRITE_STD(0, 256, 108), 0},
+		{&ERASE_SECTOR_64K(0, _64K, 108), 0}},
+
+	{"MX25L12835F", {0xc2, 0x20, 0x18}, 3, _16M,   _64K, 3,
+		{&READ_STD(0, INFINITE, 50), &READ_FAST(1, INFINITE, 108), 0},
+		{&WRITE_STD(0, 256, 108), 0},
+		{&ERASE_SECTOR_64K(0, _64K, 108), 0}},
+	*/
+
+	{
+		"MX25L(256/257)XX",
+		{0xc2, 0x20, 0x19}, 3, _32M, _64K, 4,
+		{
+			&READ_STD(0, INFINITE, 40/*50*/),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(2, INFINITE, 104),
+			&READ_DUAL_ADDR(1, INFINITE, 84),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD_ADDR(3, INFINITE, 75),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 75),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD_ADDR(0, 256, 104),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 80),
+			0
+		},
+		&spi_driver_mx25l25635e,
+	},
+
+	{
+		"mx25l1655d",  {0xc2, 0x26, 0x15}, 3, _2M,    _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"mx25l12855e", {0xc2, 0x26, 0x18}, 3, _16M,   _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"s25sl004a", {0x01, 0x02, 0x12}, 3, (_64K * 8),   _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"s25sl008a", {0x01, 0x02, 0x13}, 3, (_64K * 16),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"s25sl016a", {0x01, 0x02, 0x14}, 3, (_64K * 32),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"S25FL064P", {0x01, 0x02, 0x16, 0x4d}, 4, (_64K * 128), _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 40),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 104),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 104),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"s25sl064a", {0x01, 0x02, 0x16}, 3, (_64K * 128), _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	/* Spansion */
+
+	{
+		"S25FL032P", {0x01, 0x02, 0x15, 0x4d}, 4, (_64K * 64),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 40),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(0, INFINITE, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(2, INFINITE, 80),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 104),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 104),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"S25FL032A", {0x01, 0x02, 0x15}, 3, (_64K * 64),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 33),
+			&READ_FAST(1, INFINITE, 50),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 50),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 50),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"S25FL128P-0",
+		{0x01, 0x20, 0x18, 0x03, 0x00}, 5, (_256K * 64),  _256K, 3,
+		{
+			&READ_STD(0, INFINITE, 40),
+			&READ_FAST(1, INFINITE, 104),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 104),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_256K(0, _256K, 104),
+			0
+		},
+		&spi_driver_no_qe,
+	},
+
+	{
+		"S25FL128P-1",
+		{0x01, 0x20, 0x18, 0x03, 0x01}, 5, (_64K * 256),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 40),
+			&READ_FAST(1, INFINITE, 104),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 104), 0},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 104),
+			0
+		},
+		&spi_driver_no_qe,
+	},
+
+	{
+		"S25FL129P0",
+		{0x01, 0x20, 0x18, 0x4d, 0x00}, 5, (_256K * 64),  _256K, 3,
+		{
+			&READ_STD(0, INFINITE, 40),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(0, INFINITE, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(2, INFINITE, 80),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 104),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_256K(0, _256K, 104),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"S25FL129P1/127S",
+		{0x01, 0x20, 0x18, 0x4d, 0x01}, 5, (_64K * 256),  _64K,  3,
+		{
+			&READ_STD(0, INFINITE, 40),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 64),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(3, INFINITE, 80),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 104),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 104),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"S25FL256S", {0x01, 0x02, 0x19, 0x4d, 0x01}, 5, _32M,  _64K,  4,
+		{
+			&READ_STD(0, INFINITE, 40),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 64),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(3, INFINITE, 80),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 104),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 104),
+			0
+		},
+		&spi_driver_s25fl256s,
+	},
+
+	/*
+	The chip and chip W25Q16B have the same chipid,
+	but clock frequency have some difference
+
+	{"S25FL016K", {0xef, 0x40, 0x15}, 3, (_64K * 32),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+			&READ_QUAD(1, INFINITE, 104),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 104),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 104),
+			0
+		}
+	},
+	*/
+
+	/* SST -- large erase sizes are "overlays", "sectors" are 4K */
+	{
+		"sst25vf040b", {0xbf, 0x25, 0x8d}, 3, (_64K * 8),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"sst25vf080b", {0xbf, 0x25, 0x8e}, 3, (_64K * 16), _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"sst25vf016b", {0xbf, 0x25, 0x41}, 3, (_64K * 32), _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"sst25vf032b", {0xbf, 0x25, 0x4a}, 3, (_64K * 64), _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"sst25wf512",  {0xbf, 0x25, 0x01}, 3, (_64K * 1),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"sst25wf010",  {0xbf, 0x25, 0x02}, 3, (_64K * 2),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"sst25wf020",  {0xbf, 0x25, 0x03}, 3, (_64K * 4),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"sst25wf040",  {0xbf, 0x25, 0x04}, 3, (_64K * 8),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	/* ST Microelectronics -- newer production may have feature updates */
+	{
+		"m25p05",  {0x20, 0x20, 0x10}, 3, (_32K * 2), _32K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_32K(0, _32K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"m25p10",  {0x20, 0x20, 0x11}, 3, (_32K * 4), _32K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_32K(0, _32K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"m25p20",  {0x20, 0x20, 0x12}, 3, (_64K * 4),   _64K,  3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"m25p40",  {0x20, 0x20, 0x13}, 3, (_64K * 8),   _64K,  3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"m25p80",  {0x20, 0x20, 0x14}, 3, (_64K * 16),  _64K,  3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"m25p16",  {0x20, 0x20, 0x15}, 3, (_64K * 32),  _64K,  3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"M25P32",  {0x20, 0x20, 0x16, 0x10}, 4, _4M, _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 33),
+			&READ_FAST(1, INFINITE, 75),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 75),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 75),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"m25p64",  {0x20, 0x20, 0x17}, 3, (_64K * 128), _64K,  3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"M25P128", {0x20, 0x20, 0x18}, 3, _16M, _256K, 3,
+		{
+			&READ_STD(0, INFINITE, 20),
+			&READ_FAST(1, INFINITE, 50),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 50),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_256K(0, _256K, 50),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"m45pe10", {0x20, 0x40, 0x11}, 3, (_64K * 2),   _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"m45pe80", {0x20, 0x40, 0x14}, 3, (_64K * 16),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"m45pe16", {0x20, 0x40, 0x15}, 3, (_64K * 32),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"m25pe80", {0x20, 0x80, 0x14}, 3, (_64K * 16), _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"m25pe16", {0x20, 0x80, 0x15}, 3, (_64K * 32), _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"N25Q032", {0x20, 0xba, 0x16}, 3, (_64K * 64), _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 32/*54*/),
+			&READ_FAST(1, INFINITE, 64/*108*/),
+			&READ_DUAL(1, INFINITE, 64/*108*/),
+			&READ_DUAL_ADDR(2, INFINITE, 64/*108*/),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 64/*108*/),
+			&READ_QUAD_ADDR(5, INFINITE, 64/*108*/),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 64/*108*/),
+			&WRITE_DUAL(0, 256, 64/*108*/),
+			&WRITE_DUAL_ADDR(0, 256, 64/*108*/),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 64/*108*/),
+			/* &WRITE_QUAD_ADDR(0, 256, 64), */
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 64/*108*/),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	/* Micron  N25QL064A 3.3V */
+	{
+		"N25QL064A",   {0x20, 0xba, 0x17}, 3, (_64K * 128), _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 54),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(2, INFINITE, 84),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+			&READ_QUAD_ADDR(5, INFINITE, 84),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 80),
+			&WRITE_DUAL(0, 256, 75),
+			&WRITE_DUAL_ADDR(0, 256, 75),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 50),
+			0
+		},
+		&spi_driver_micron,
+	},
+
+	/* Micron  MT(N)25QL128A 3.3V */
+	{
+		"N25QL128A",   {0x20, 0xba, 0x18}, 3, (_64K * 256), _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 54),
+			&READ_FAST(1, INFINITE, 108),
+			&READ_DUAL(1, INFINITE, 84),
+			&READ_DUAL_ADDR(2, INFINITE, 84),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 84),
+			&READ_QUAD_ADDR(5, INFINITE, 84),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 108),
+			&WRITE_DUAL(0, 256, 108),
+			&WRITE_DUAL_ADDR(0, 256, 108),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 108),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 108),
+			0
+		},
+		&spi_driver_micron,
+	},
+
+	/* Micron MT25QL256A 3.3V */
+	{
+		"MT25QL256A",   {0x20, 0xba, 0x19}, 3, (_64K * 512), _64K, 4,
+		{
+			&READ_STD(0, INFINITE, 54),
+			&READ_FAST(1, INFINITE, 133),
+			&READ_DUAL(1, INFINITE, 133),
+			&READ_DUAL_ADDR(2, INFINITE, 133),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 133),
+			&READ_QUAD_ADDR(5, INFINITE, 125),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 133),
+			&WRITE_DUAL(0, 256, 133),
+			&WRITE_DUAL_ADDR(0, 256, 133),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 133),
+			/* &WRITE_QUAD_ADDR(0, 256, 133), */
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 133),
+			0
+		},
+		&spi_driver_micron,
+	},
+
+	{
+		"M25PX16",  {0x20, 0x71, 0x15}, 3, (_64K * 32),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 33),
+			&READ_FAST(1, INFINITE, 75),
+			&READ_DUAL(1, INFINITE, 75),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 75),
+			&WRITE_DUAL(0, 256, 75),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 75),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"M25PX32", {0x20, 0x71, 0x16}, 3, (_64K * 64),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 33),
+			&READ_FAST(1, INFINITE, 75),
+			&READ_DUAL(1, INFINITE, 75),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 75),
+			&WRITE_DUAL(0, 256, 75),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 75),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"m25px64",  {0x20, 0x71, 0x17}, 3, (_64K * 128), _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	/* Winbond -- w25x "blocks" are 64K, "sectors" are 4KiB */
+	{
+		"w25x10",  {0xef, 0x30, 0x11}, 3, (_64K * 2),    _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"w25x20",  {0xef, 0x30, 0x12}, 3, (_64K * 4),    _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+			{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"w25x40",  {0xef, 0x30, 0x13}, 3, (_64K * 8),    _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"w25x80",  {0xef, 0x30, 0x14}, 3, (_64K * 16),   _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+			{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"w25x16",  {0xef, 0x30, 0x15}, 3, (_64K * 32),   _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"w25x32",  {0xef, 0x30, 0x16}, 3, (_64K * 64),   _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0), 0},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"w25x64",  {0xef, 0x30, 0x17}, 3, (_64K * 128),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 0),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 0),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 0),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"W25Q80BV",  {0xef, 0x40, 0x14}, 3, (_64K * 16),   _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 80),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"W25Q16(B/C)V/S25FL016K",
+		{0xef, 0x40, 0x15}, 3, (_64K * 32), _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 80),
+			0
+		},
+		&spi_driver_general,
+	},
+	/*
+	 The follow chips have the same chipid, but command have some difference
+	{
+		"W25Q16BV",  {0xef, 0x40, 0x15}, 3, (_64K * 32),   _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_QUAD(1, INFINITE, 80),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 80),
+			&WRITE_QUAD(0, 256, 80),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 80),
+			0
+		}
+	},
+
+	{
+		"W25Q16CV",  {0xef, 0x40, 0x15}, 3, (_64K * 32),   _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_QUAD(1, INFINITE, 80),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 80),
+			&WRITE_QUAD(0, 256, 80),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 80),
+			0
+		}
+	},
+
+	*/
+	{
+		"W25Q32BV",  {0xef, 0x40, 0x16}, 3, (_64K * 64),   _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 80),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"W25Q64FV",  {0xef, 0x40, 0x17}, 3, _8M,   _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 80),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"W25Q128(B/F)V", {0xEF, 0x40, 0x18}, 3, _16M, _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 33),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 104),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, /*70*/80),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 104),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, /*70*/80),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 104),
+			0
+		},
+		&spi_driver_w25q256fv,
+	},
+
+	{
+		"W25Q256FV", {0xEF, 0x40, 0x19}, 3, _32M, _64K, 4,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 80),
+			&READ_DUAL(1, INFINITE, 80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+#endif
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 104),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 104),
+			0
+		},
+		&spi_driver_w25q256fv,
+	},
+
+	/* Eon -- fit clock frequency of RDSR instruction*/
+	{
+		"EN25F80", {0x1c, 0x31, 0x14}, 3, (_64K * 16),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 66),
+			&READ_FAST(1, INFINITE, 66/*100*/),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 66/*100*/),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 66/*100*/),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"EN25F16", {0x1c, 0x31, 0x15}, 3, _2M,  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 66),
+			&READ_FAST(1, INFINITE, 66/*100*/),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 66/*100*/),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 66/*100*/),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"EN25Q32B", {0x1c, 0x30, 0x16}, 3, (_64K * 64),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 80/*104*/),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+			/*&READ_QUAD(3, INFINITE, 80), */
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 80/*104*/),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 80/*104*/),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"EN25Q64", {0x1c, 0x30, 0x17}, 3, (_64K * 128),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 100),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 80),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 104),
+			0
+		},
+		&spi_driver_no_qe,
+	},
+
+	{
+		"EN25Q128", {0x1c, 0x30, 0x18}, 3, (_64K * 256),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 50),
+			&READ_FAST(1, INFINITE, 104),
+			&READ_DUAL(1, INFINITE, 80),
+			&READ_DUAL_ADDR(1, INFINITE, 80),
+			0
+		},
+
+		{
+			&WRITE_STD(0, 256, 104),
+			0
+		},
+
+		{
+			&ERASE_SECTOR_64K(0, _64K, 104),
+			0
+		},
+		&spi_driver_no_qe,
+	},
+
+	/* ESMT */
+	{
+		"F25L64QA", {0x8C, 0x41, 0x17}, 3, (_64K * 128),  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 66),
+			&READ_FAST(1, INFINITE, /*66*/100),
+			&READ_DUAL(1, INFINITE, /*66*/80),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+#endif
+			0
+		},
+		{
+			&WRITE_STD(0, 256, /*66*/100),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, /*66*/100),
+			0
+		},
+		&spi_driver_f25l64q,
+	},
+
+	{
+		"GD25Q128", {0xC8, 0x40, 0x18}, 3, _16M,  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 66),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+#endif
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 100),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 100),
+			0
+		},
+		&spi_driver_gd25qxxx,
+	},
+
+	{
+		"GD25Q64", {0xC8, 0x40, 0x17}, 3, _8M,  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 66),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+#endif
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 100),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 100),
+			0
+		},
+		&spi_driver_gd25qxxx,
+	},
+	{
+		"GD25Q32", {0xC8, 0x40, 0x16}, 3, _4M,  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 66),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 80),
+#endif
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 100),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&WRITE_QUAD(0, 256, 80),
+#endif
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 100),
+			0
+		},
+		&spi_driver_gd25qxxx,
+	},
+
+	/* Paragon 3.3V */
+	{
+		"PN25F16S", {0xe0, 0x40, 0x15}, 3, _2M,  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 55),
+			&READ_FAST(1, INFINITE, 108),
+			&READ_DUAL(1, INFINITE, 108),
+			&READ_DUAL_ADDR(1, INFINITE, 108),
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 108),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 108),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{
+		"PN25F32S", {0xe0, 0x40, 0x16}, 3, _4M,  _64K, 3,
+		{
+			&READ_STD(0, INFINITE, 55),
+			&READ_FAST(1, INFINITE, 108),
+			&READ_DUAL(1, INFINITE, 108),
+			&READ_DUAL_ADDR(1, INFINITE, 108),
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+			&READ_QUAD(1, INFINITE, 108),
+			&READ_QUAD_ADDR(3, INFINITE, 108),
+#endif
+			0
+		},
+		{
+			&WRITE_STD(0, 256, 108),
+			0
+		},
+		{
+			&ERASE_SECTOR_64K(0, _64K, 108),
+			0
+		},
+		&spi_driver_general,
+	},
+
+	{0, {0}, 0, 0, 0, 0, {0}, {0}, {0}, NULL},
+};
diff --git a/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_micron.c b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_micron.c
new file mode 100644
index 0000000..70ff1b6
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_micron.c
@@ -0,0 +1,98 @@
+/*
+ * The SPI NOR Controller v350 Device Driver for hisilicon
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+/*****************************************************************************/
+#define SPI_CMD_FIRST_RESET_4ADDR  (0x66)
+#define SPI_CMD_SECOND_RESET_4ADDR (0x99)
+
+#define SPI_CMD_FLAG_SR_MICRON  0x70  /* READ FLAG STATUS REGISTER */
+#define SPI_CMD_RD_RDCR_MICRON	0xB5  /* READ NONVOLATILE CONFIGURATION
+					 REGISTER*/
+#define SPI_CMD_WR_RDCR_MICRON	0xB1 /* WRITE NONVOLATILE CONFIGURATION
+					 REGISTER*/
+#define SPI_NOR_ADS_MASK	0x1
+#define SPI_NOR_GET_4BYTE_BY_FLAG_SR(sr)     ((sr) & SPI_NOR_ADS_MASK)
+
+#define SPI_NOR_ADS_SET_4BYTE(cr)	     ((cr) & (~SPI_NOR_ADS_MASK))
+#define SPI_NOR_ADS_GET_4BYTE(cr)	     ((cr) & SPI_NOR_ADS_MASK)
+/****************************************************************************/
+static int spi_micron_entry_4addr(struct hisfc_spi *spi, int enable)
+{
+	unsigned char status;
+	unsigned int reg;
+	const char *str[] = {"Disable", "Enable"};
+	struct hisfc_host *host = (struct hisfc_host *)spi->host;
+
+	if (spi->addrcycle != SPI_4BYTE_ADDR_LEN)
+		return 0;
+
+	status = spi_general_get_flash_register(spi, SPI_CMD_FLAG_SR_MICRON);
+	if (DEBUG_SPI)
+		printk(KERN_INFO"\t Read flag status register[%#x]:%#x\n",
+				SPI_CMD_FLAG_SR_MICRON, status);
+
+	if (SPI_NOR_GET_4BYTE_BY_FLAG_SR(status) == enable) {
+		if (DEBUG_SPI)
+			printk(KERN_INFO"\t* 4-byte was %sd, reg:%#x\n", str[enable],
+					status);
+		return 0;
+	}
+
+	spi->driver->write_enable(spi);
+
+	if (enable)
+		reg = SPI_CMD_EN4B;
+	else
+		reg = SPI_CMD_EX4B;
+
+	hisfc_write(host, HISFC350_CMD_INS, reg);
+	if (DEBUG_SPI)
+		printk(KERN_INFO"\t  Set CMD[%#x]%#x\n", HISFC350_CMD_INS, reg);
+
+	reg =  HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+	   	| HISFC350_CMD_CONFIG_START;
+	hisfc_write(host, HISFC350_CMD_CONFIG, reg);
+
+	if (DEBUG_SPI)
+		printk(KERN_INFO"\t  Set OP_CFG[%#x]%#x\n", HISFC350_CMD_CONFIG, reg);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	host->set_host_addr_mode(host, enable);
+
+	spi->driver->wait_ready(spi);
+
+	status = spi_general_get_flash_register(spi,
+			SPI_CMD_FLAG_SR_MICRON);
+	if (DEBUG_SPI)
+		printk(KERN_INFO"\t Read flag status register[%#x]:%#x\n",
+				SPI_CMD_FLAG_SR_MICRON, status);
+	if (SPI_NOR_GET_4BYTE_BY_FLAG_SR(status) != enable) {
+		printk(KERN_INFO"Error: %s 4-byte failed! SR3:%#x\n",
+				str[enable], status);
+		return status;
+	}
+
+	if (DEBUG_SPI) {
+		printk(KERN_INFO"\t  %s 4-byte success, SR3:%#x\n", str[enable], status);
+		printk(KERN_INFO"\t* End SPI Nor flash %s 4-byte mode.\n", str[enable]);
+	}
+	return 0;
+}
diff --git a/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_mx25l25635e.c b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_mx25l25635e.c
new file mode 100644
index 0000000..0ba254a
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_mx25l25635e.c
@@ -0,0 +1,99 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+ 
+#include <linux/io.h>
+#include <linux/mtd/mtd.h>
+#include <linux/errno.h>
+
+#include "../spi_ids.h"
+#include "hisfc350.h"
+
+/* MXIC QE(bit) include in Status Register */
+#define MX_SPI_NOR_SR_QE_SHIFT	6
+#define MX_SPI_NOR_SR_QE_MASK	(1 << MX_SPI_NOR_SR_QE_SHIFT)
+
+/*****************************************************************************/
+/*
+   enable QE bit if QUAD read write is supported by SPI
+*/
+static int spi_mx25l25635e_qe_enable(struct hisfc_spi *spi)
+{
+	unsigned char status, op;
+	unsigned int reg;
+	const char *str[] = {"Disable", "Enable"};
+	struct hisfc_host *host = (struct hisfc_host *)spi->host;
+
+	op = hisfc350_is_quad(spi);
+
+	if (DEBUG_SPI_QE)
+		printk(KERN_INFO "* Start SPI Nor %s Quad.\n", str[op]);
+
+	spi->driver->wait_ready(spi);
+
+	status = spi_general_get_flash_register(spi, SPI_CMD_RDSR);
+	if (DEBUG_SPI_QE)
+		printk(KERN_INFO "  Read status %#x, val[%#x]\n", SPI_CMD_RDSR,
+				status);
+	if (((status & MX_SPI_NOR_SR_QE_MASK) >> MX_SPI_NOR_SR_QE_SHIFT)
+			== op) {
+		if (DEBUG_SPI_QE)
+			printk(KERN_INFO "* Quad was %sd!\n", str[op]);
+		return op;
+	}
+
+	spi->driver->write_enable(spi);
+
+	if (op)
+		status |= MX_SPI_NOR_SR_QE_MASK;
+	else
+		status &= ~MX_SPI_NOR_SR_QE_MASK;
+	hisfc_write(host, HISFC350_CMD_DATABUF0, status);
+	if (DEBUG_SPI_QE)
+		printk(KERN_INFO "  Set DATA[%#x]%#x\n", HISFC350_CMD_DATABUF0,
+				status);
+
+	hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_WRSR);
+	if (DEBUG_SPI_QE)
+		printk(KERN_INFO "  Set INS[%#x]%#x\n", HISFC350_CMD_INS,
+				SPI_CMD_WRSR);
+
+	reg = HISFC350_CMD_CONFIG_DATA_CNT(SPI_NOR_SR_LEN)
+		| HISFC350_CMD_CONFIG_DATA_EN
+		| HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+		| HISFC350_CMD_CONFIG_START;
+	hisfc_write(host, HISFC350_CMD_CONFIG, reg);
+	if (DEBUG_SPI_QE)
+		printk(KERN_INFO "  Set CONFIG[%#x]%#x\n", HISFC350_CMD_CONFIG,
+				reg);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	if (DEBUG_SPI_QE) {
+		spi->driver->wait_ready(spi);
+
+		status = spi_general_get_flash_register(spi, SPI_CMD_RDSR);
+		if (((status & MX_SPI_NOR_SR_QE_MASK) >> MX_SPI_NOR_SR_QE_SHIFT)
+				== op)
+			printk(KERN_INFO "* SPI %s Quad succeed.\n", str[op]);
+		else
+			DBG_MSG("%s Quad failed! [%#x]\n", str[op], status);
+	}
+
+	return op;
+}
+
diff --git a/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_n25q256a.c b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_n25q256a.c
new file mode 100644
index 0000000..b5a7d28
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_n25q256a.c
@@ -0,0 +1,53 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+ 
+#include <linux/io.h>
+#include <linux/mtd/mtd.h>
+#include <linux/errno.h>
+#include <linux/sched.h>
+#include "../spi_ids.h"
+#include "hisfc350.h"
+
+static int spi_n25q256a_entry_4addr(struct hisfc_spi *spi, int enable)
+{
+	struct hisfc_host *host = (struct hisfc_host *)spi->host;
+
+	if (spi->addrcycle != 4)
+		return 0;
+
+	spi->driver->wait_ready(spi);
+
+	if (enable) {
+		spi->driver->write_enable(spi);
+		hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_EN4B);
+	} else {
+		spi->driver->write_enable(spi);
+		hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_EX4B);
+	}
+
+	hisfc_write(host, HISFC350_CMD_CONFIG,
+		HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+		| HISFC350_CMD_CONFIG_START);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+	host->set_host_addr_mode(host, enable);
+
+	return 0;
+}
+
diff --git a/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_s25fl256s.c b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_s25fl256s.c
new file mode 100644
index 0000000..bec3f23
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_s25fl256s.c
@@ -0,0 +1,68 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+ 
+#include <linux/io.h>
+#include <linux/mtd/mtd.h>
+#include <linux/errno.h>
+#include <linux/sched.h>
+#include "../spi_ids.h"
+#include "hisfc350.h"
+
+#define SPI_BRWR	0x17
+#define SPI_EN4B	0x80
+#define SPI_EX4B	0x00
+
+static int spi_s25fl256s_entry_4addr(struct hisfc_spi *spi, int enable)
+{
+	struct hisfc_host *host = (struct hisfc_host *)spi->host;
+	unsigned int regval = 0;
+
+	if (spi->addrcycle != SPI_4BYTE_ADDR_LEN)
+		return 0;
+
+	spi->driver->wait_ready(spi);
+
+	if (enable) {
+		hisfc_write(host, HISFC350_CMD_INS, SPI_BRWR);
+		hisfc_write(host, HISFC350_CMD_DATABUF0, SPI_EN4B);
+	} else {
+		hisfc_write(host, HISFC350_CMD_INS, SPI_BRWR);
+		hisfc_write(host, HISFC350_CMD_DATABUF0, SPI_EX4B);
+	}
+
+	hisfc_write(host, HISFC350_CMD_CONFIG,
+		HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+		| HISFC350_CMD_CONFIG_DATA_CNT(1)
+		| HISFC350_CMD_CONFIG_DATA_EN
+		| HISFC350_CMD_CONFIG_START);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+	if (DEBUG_SPI) {
+		regval = hisfc_read(host, HISFC350_CMD_DATABUF0);
+		if (!(regval & SPI_EN4B)) {
+			printk(KERN_INFO "now is 3-byte address mode\n");
+			printk(KERN_INFO "regval_read_SPI : 0x%x\n", regval);
+		} else
+			printk(KERN_INFO "now is 4-byte address mode\n");
+
+	}
+	host->set_host_addr_mode(host, enable);
+
+	return 0;
+}
+
diff --git a/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_w25q256fv.c b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_w25q256fv.c
new file mode 100644
index 0000000..ce1f368
--- /dev/null
+++ b/drivers/mtd/spi-nor/hisfc350/hisfc350_spi_w25q256fv.c
@@ -0,0 +1,82 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+ 
+#include <linux/io.h>
+#include <linux/mtd/mtd.h>
+#include <linux/errno.h>
+
+#include "../spi_ids.h"
+#include "hisfc350.h"
+
+#define SPI_CMD_FIRST_RESET_4ADDR  (0x66)
+#define SPI_CMD_SECOND_RESET_4ADDR (0x99)
+
+static int spi_w25q256fv_entry_4addr(struct hisfc_spi *spi, int enable)
+{
+	struct hisfc_host *host = (struct hisfc_host *)spi->host;
+
+	if (spi->addrcycle != SPI_4BYTE_ADDR_LEN)
+		return 0;
+
+	spi->driver->wait_ready(spi);
+	/* This chip should not enable write here,
+	 * we have confirmed with the WINBOND */
+	/* spi->driver->write_enable(spi); */
+	if (enable) {
+		hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_EN4B);
+		if (DEBUG_SPI)
+			printk(KERN_INFO "now w25q256fv is 4-byte address mode\n");
+
+		hisfc_write(host, HISFC350_CMD_CONFIG,
+			HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+			| HISFC350_CMD_CONFIG_START);
+
+		HISFC350_CMD_WAIT_CPU_FINISH(host);
+	} else {
+		hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_FIRST_RESET_4ADDR);
+		hisfc_write(host, HISFC350_CMD_CONFIG,
+			HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+			| HISFC350_CMD_CONFIG_START);
+
+
+		HISFC350_CMD_WAIT_CPU_FINISH(host);
+
+
+		hisfc_write(host, HISFC350_CMD_INS, SPI_CMD_SECOND_RESET_4ADDR);
+		hisfc_write(host, HISFC350_CMD_CONFIG,
+			HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+			| HISFC350_CMD_CONFIG_START);
+
+		HISFC350_CMD_WAIT_CPU_FINISH(host);
+		if (DEBUG_SPI)
+			printk(KERN_INFO "now W25Q256FV 6699 cmd\n");
+	}
+/*
+	hisfc_write(host, HISFC350_CMD_CONFIG,
+		HISFC350_CMD_CONFIG_SEL_CS(spi->chipselect)
+		| HISFC350_CMD_CONFIG_DATA_CNT(1)
+		| HISFC350_CMD_CONFIG_DATA_EN
+		| HISFC350_CMD_CONFIG_START);
+
+	HISFC350_CMD_WAIT_CPU_FINISH(host);
+*/
+	host->set_host_addr_mode(host, enable);
+
+	return 0;
+}
+
diff --git a/drivers/mtd/spi-nor/hisi-sfc.c b/drivers/mtd/spi-nor/hisi-sfc.c
index 20378b0..d8cf89c 100644
--- a/drivers/mtd/spi-nor/hisi-sfc.c
+++ b/drivers/mtd/spi-nor/hisi-sfc.c
@@ -16,80 +16,21 @@
  * You should have received a copy of the GNU General Public License
  * along with this program. If not, see <http://www.gnu.org/licenses/>.
  */
-#include <linux/bitops.h>
 #include <linux/clk.h>
 #include <linux/dma-mapping.h>
 #include <linux/iopoll.h>
 #include <linux/module.h>
+#include <linux/mfd/hisi_fmc.h>
 #include <linux/mtd/mtd.h>
 #include <linux/mtd/spi-nor.h>
+#include <linux/mtd/partitions.h>
 #include <linux/of.h>
 #include <linux/platform_device.h>
 #include <linux/slab.h>
 
-/* Hardware register offsets and field definitions */
-#define FMC_CFG				0x00
-#define FMC_CFG_OP_MODE_MASK		BIT_MASK(0)
-#define FMC_CFG_OP_MODE_BOOT		0
-#define FMC_CFG_OP_MODE_NORMAL		1
-#define FMC_CFG_FLASH_SEL(type)		(((type) & 0x3) << 1)
-#define FMC_CFG_FLASH_SEL_MASK		0x6
-#define FMC_ECC_TYPE(type)		(((type) & 0x7) << 5)
-#define FMC_ECC_TYPE_MASK		GENMASK(7, 5)
-#define SPI_NOR_ADDR_MODE_MASK		BIT_MASK(10)
-#define SPI_NOR_ADDR_MODE_3BYTES	(0x0 << 10)
-#define SPI_NOR_ADDR_MODE_4BYTES	(0x1 << 10)
-#define FMC_GLOBAL_CFG			0x04
-#define FMC_GLOBAL_CFG_WP_ENABLE	BIT(6)
-#define FMC_SPI_TIMING_CFG		0x08
-#define TIMING_CFG_TCSH(nr)		(((nr) & 0xf) << 8)
-#define TIMING_CFG_TCSS(nr)		(((nr) & 0xf) << 4)
-#define TIMING_CFG_TSHSL(nr)		((nr) & 0xf)
-#define CS_HOLD_TIME			0x6
-#define CS_SETUP_TIME			0x6
-#define CS_DESELECT_TIME		0xf
-#define FMC_INT				0x18
-#define FMC_INT_OP_DONE			BIT(0)
-#define FMC_INT_CLR			0x20
-#define FMC_CMD				0x24
-#define FMC_CMD_CMD1(cmd)		((cmd) & 0xff)
-#define FMC_ADDRL			0x2c
-#define FMC_OP_CFG			0x30
-#define OP_CFG_FM_CS(cs)		((cs) << 11)
-#define OP_CFG_MEM_IF_TYPE(type)	(((type) & 0x7) << 7)
-#define OP_CFG_ADDR_NUM(addr)		(((addr) & 0x7) << 4)
-#define OP_CFG_DUMMY_NUM(dummy)		((dummy) & 0xf)
-#define FMC_DATA_NUM			0x38
-#define FMC_DATA_NUM_CNT(cnt)		((cnt) & GENMASK(13, 0))
-#define FMC_OP				0x3c
-#define FMC_OP_DUMMY_EN			BIT(8)
-#define FMC_OP_CMD1_EN			BIT(7)
-#define FMC_OP_ADDR_EN			BIT(6)
-#define FMC_OP_WRITE_DATA_EN		BIT(5)
-#define FMC_OP_READ_DATA_EN		BIT(2)
-#define FMC_OP_READ_STATUS_EN		BIT(1)
-#define FMC_OP_REG_OP_START		BIT(0)
-#define FMC_DMA_LEN			0x40
-#define FMC_DMA_LEN_SET(len)		((len) & GENMASK(27, 0))
-#define FMC_DMA_SADDR_D0		0x4c
-#define HIFMC_DMA_MAX_LEN		(4096)
-#define HIFMC_DMA_MASK			(HIFMC_DMA_MAX_LEN - 1)
+#include "../mtdcore.h"
+
 #define FMC_OP_DMA			0x68
-#define OP_CTRL_RD_OPCODE(code)		(((code) & 0xff) << 16)
-#define OP_CTRL_WR_OPCODE(code)		(((code) & 0xff) << 8)
-#define OP_CTRL_RW_OP(op)		((op) << 1)
-#define OP_CTRL_DMA_OP_READY		BIT(0)
-#define FMC_OP_READ			0x0
-#define FMC_OP_WRITE			0x1
-#define FMC_WAIT_TIMEOUT		1000000
-
-enum hifmc_iftype {
-	IF_TYPE_STD,
-	IF_TYPE_DUAL,
-	IF_TYPE_DIO,
-	IF_TYPE_QUAD,
-	IF_TYPE_QIO,
-};
 
 struct hifmc_priv {
 	u32 chipselect;
@@ -97,10 +38,9 @@ struct hifmc_priv {
 	struct hifmc_host *host;
 };
 
-#define HIFMC_MAX_CHIP_NUM		2
 struct hifmc_host {
 	struct device *dev;
-	struct mutex lock;
+	struct mutex *lock;
 
 	void __iomem *regbase;
 	void __iomem *iobase;
@@ -109,9 +49,11 @@ struct hifmc_host {
 	dma_addr_t dma_buffer;
 
 	struct spi_nor	*nor[HIFMC_MAX_CHIP_NUM];
+	struct hifmc_priv priv[HIFMC_MAX_CHIP_NUM];
 	u32 num_chip;
 };
 
+/******************************************************************************/
 static inline int wait_op_finish(struct hifmc_host *host)
 {
 	u32 reg;
@@ -120,19 +62,24 @@ static inline int wait_op_finish(struct hifmc_host *host)
 		(reg & FMC_INT_OP_DONE), 0, FMC_WAIT_TIMEOUT);
 }
 
-static int get_if_type(enum read_mode flash_read)
+static int get_if_type(enum spi_nor_protocol mode)
 {
 	enum hifmc_iftype if_type;
 
-	switch (flash_read) {
-	case SPI_NOR_DUAL:
+	switch (mode) {
+	case SNOR_PROTO_1_1_2:
 		if_type = IF_TYPE_DUAL;
 		break;
-	case SPI_NOR_QUAD:
+	case SNOR_PROTO_1_2_2:
+		if_type = IF_TYPE_DIO;
+		break;
+	case SNOR_PROTO_1_1_4:
 		if_type = IF_TYPE_QUAD;
 		break;
-	case SPI_NOR_NORMAL:
-	case SPI_NOR_FAST:
+	case SNOR_PROTO_1_4_4:
+		if_type = IF_TYPE_QIO;
+		break;
+	case SNOR_PROTO_1_1_1:
 	default:
 		if_type = IF_TYPE_STD;
 		break;
@@ -141,23 +88,47 @@ static int get_if_type(enum read_mode flash_read)
 	return if_type;
 }
 
+/******************************************************************************/
+static void spi_nor_switch_spi_type(struct hifmc_host *host)
+{
+	unsigned int reg;
+
+	reg = hifmc_readl(host, FMC_CFG);
+	reg &= ~FLASH_TYPE_SEL_MASK;
+	reg |= FMC_CFG_FLASH_SEL(0);
+	hifmc_writel(host, FMC_CFG, reg);
+}
+
+/******************************************************************************/
 static void hisi_spi_nor_init(struct hifmc_host *host)
 {
-	u32 reg;
+	unsigned int reg;
+
+	/* switch the flash type to spi nor */
+	spi_nor_switch_spi_type(host);
 
+	/* set the boot mode to normal */
+	reg = hifmc_readl(host, FMC_CFG);
+	if ((reg & FMC_CFG_OP_MODE_MASK) == FMC_CFG_OP_MODE_BOOT) {
+		reg |= FMC_CFG_OP_MODE(FMC_CFG_OP_MODE_NORMAL);
+		hifmc_writel(host, FMC_CFG, reg);
+	}
+
+	/* set timming */
 	reg = TIMING_CFG_TCSH(CS_HOLD_TIME)
 		| TIMING_CFG_TCSS(CS_SETUP_TIME)
 		| TIMING_CFG_TSHSL(CS_DESELECT_TIME);
-	writel(reg, host->regbase + FMC_SPI_TIMING_CFG);
+	hifmc_writel(host, FMC_SPI_TIMING_CFG, reg);
 }
 
+/******************************************************************************/
 static int hisi_spi_nor_prep(struct spi_nor *nor, enum spi_nor_ops ops)
 {
 	struct hifmc_priv *priv = nor->priv;
 	struct hifmc_host *host = priv->host;
 	int ret;
 
-	mutex_lock(&host->lock);
+	mutex_lock(host->lock);
 
 	ret = clk_set_rate(host->clk, priv->clkrate);
 	if (ret)
@@ -167,22 +138,26 @@ static int hisi_spi_nor_prep(struct spi_nor *nor, enum spi_nor_ops ops)
 	if (ret)
 		goto out;
 
+	spi_nor_switch_spi_type(host);
+
 	return 0;
 
 out:
-	mutex_unlock(&host->lock);
+	mutex_unlock(host->lock);
 	return ret;
 }
 
+/******************************************************************************/
 static void hisi_spi_nor_unprep(struct spi_nor *nor, enum spi_nor_ops ops)
 {
 	struct hifmc_priv *priv = nor->priv;
 	struct hifmc_host *host = priv->host;
 
 	clk_disable_unprepare(host->clk);
-	mutex_unlock(&host->lock);
+	mutex_unlock(host->lock);
 }
 
+/******************************************************************************/
 static int hisi_spi_nor_op_reg(struct spi_nor *nor,
 				u8 opcode, int len, u8 optype)
 {
@@ -191,21 +166,22 @@ static int hisi_spi_nor_op_reg(struct spi_nor *nor,
 	u32 reg;
 
 	reg = FMC_CMD_CMD1(opcode);
-	writel(reg, host->regbase + FMC_CMD);
+	hifmc_writel(host, FMC_CMD, reg);
 
 	reg = FMC_DATA_NUM_CNT(len);
-	writel(reg, host->regbase + FMC_DATA_NUM);
+	hifmc_writel(host, FMC_DATA_NUM, reg);
 
 	reg = OP_CFG_FM_CS(priv->chipselect);
-	writel(reg, host->regbase + FMC_OP_CFG);
+	hifmc_writel(host, FMC_OP_CFG, reg);
 
-	writel(0xff, host->regbase + FMC_INT_CLR);
+	hifmc_writel(host, FMC_INT_CLR, 0xff);
 	reg = FMC_OP_CMD1_EN | FMC_OP_REG_OP_START | optype;
-	writel(reg, host->regbase + FMC_OP);
+	hifmc_writel(host, FMC_OP, reg);
 
 	return wait_op_finish(host);
 }
 
+/******************************************************************************/
 static int hisi_spi_nor_read_reg(struct spi_nor *nor, u8 opcode, u8 *buf,
 		int len)
 {
@@ -221,6 +197,7 @@ static int hisi_spi_nor_read_reg(struct spi_nor *nor, u8 opcode, u8 *buf,
 	return 0;
 }
 
+/******************************************************************************/
 static int hisi_spi_nor_write_reg(struct spi_nor *nor, u8 opcode,
 				u8 *buf, int len)
 {
@@ -233,38 +210,51 @@ static int hisi_spi_nor_write_reg(struct spi_nor *nor, u8 opcode,
 	return hisi_spi_nor_op_reg(nor, opcode, len, FMC_OP_WRITE_DATA_EN);
 }
 
+/******************************************************************************/
 static int hisi_spi_nor_dma_transfer(struct spi_nor *nor, loff_t start_off,
 		dma_addr_t dma_buf, size_t len, u8 op_type)
 {
 	struct hifmc_priv *priv = nor->priv;
 	struct hifmc_host *host = priv->host;
-	u8 if_type = 0;
+	u8 if_type = 0, dummy = 0;
 	u32 reg;
 
-	reg = readl(host->regbase + FMC_CFG);
+	reg = hifmc_readl(host, FMC_CFG);
 	reg &= ~(FMC_CFG_OP_MODE_MASK | SPI_NOR_ADDR_MODE_MASK);
 	reg |= FMC_CFG_OP_MODE_NORMAL;
 	reg |= (nor->addr_width == 4) ? SPI_NOR_ADDR_MODE_4BYTES
 		: SPI_NOR_ADDR_MODE_3BYTES;
-	writel(reg, host->regbase + FMC_CFG);
+	hifmc_writel(host, FMC_CFG, reg);
+
+	hifmc_writel(host, FMC_ADDRL, start_off);
+
+	reg = (unsigned int)dma_buf;
+	hifmc_writel(host, FMC_DMA_SADDR_D0, reg);
 
-	writel(start_off, host->regbase + FMC_ADDRL);
-	writel(dma_buf, host->regbase + FMC_DMA_SADDR_D0);
-	writel(FMC_DMA_LEN_SET(len), host->regbase + FMC_DMA_LEN);
+#ifdef CONFIG_64BIT
+	reg = (dma_buf & FMC_DMA_SADDRH_MASK) >> 32;
+	hifmc_writel(host, FMC_DMA_SADDRH_D0, reg);
+#endif
+
+	hifmc_writel(host, FMC_DMA_LEN, FMC_DMA_LEN_SET(len));
 
 	reg = OP_CFG_FM_CS(priv->chipselect);
-	if_type = get_if_type(nor->flash_read);
-	reg |= OP_CFG_MEM_IF_TYPE(if_type);
-	if (op_type == FMC_OP_READ)
-		reg |= OP_CFG_DUMMY_NUM(nor->read_dummy >> 3);
-	writel(reg, host->regbase + FMC_OP_CFG);
+	if (op_type == FMC_OP_READ) {
+		if_type = get_if_type(nor->read_proto);
+		dummy = nor->read_dummy >> 3;
+	} else {
+		if_type = get_if_type(nor->write_proto);
+	}
+	reg |= OP_CFG_MEM_IF_TYPE(if_type)
+		| OP_CFG_DUMMY_NUM(dummy);
+	hifmc_writel(host, FMC_OP_CFG, reg);
 
-	writel(0xff, host->regbase + FMC_INT_CLR);
+	hifmc_writel(host, FMC_INT_CLR, 0xff);
 	reg = OP_CTRL_RW_OP(op_type) | OP_CTRL_DMA_OP_READY;
 	reg |= (op_type == FMC_OP_READ)
 		? OP_CTRL_RD_OPCODE(nor->read_opcode)
 		: OP_CTRL_WR_OPCODE(nor->program_opcode);
-	writel(reg, host->regbase + FMC_OP_DMA);
+	hifmc_writel(host, FMC_OP_DMA, reg);
 
 	return wait_op_finish(host);
 }
@@ -316,6 +306,26 @@ static ssize_t hisi_spi_nor_write(struct spi_nor *nor, loff_t to,
 }
 
 /**
+ * parse partitions info and register spi flash device as mtd device.
+ */
+static int hisi_snor_device_register(struct mtd_info *mtd)
+{
+	int ret;
+	struct mtd_partitions parsed;
+
+	/*
+	 * We do not add the whole spi flash as a mtdblock device,
+	 * To avoid the number of nand partition +1.
+	 */
+	memset(&parsed, 0, sizeof(parsed));
+	ret = parse_mtd_partitions(mtd, NULL, &parsed, NULL);
+	if (ret)
+		return ret;
+
+	return parsed.nr_parts ? mtd_device_register(mtd, NULL, 0) : parsed.nr_parts;
+}
+
+/**
  * Get spi flash device information and register it as a mtd device.
  */
 static int hisi_spi_nor_register(struct device_node *np,
@@ -323,9 +333,13 @@ static int hisi_spi_nor_register(struct device_node *np,
 {
 	struct device *dev = host->dev;
 	struct spi_nor *nor;
-	struct hifmc_priv *priv;
+	struct hifmc_priv *priv = &host->priv[host->num_chip];
 	struct mtd_info *mtd;
 	int ret;
+	struct spi_nor_modes modes = {
+		.rd_modes = SNOR_MODE_SLOW,
+		.wr_modes = SNOR_MODE_1_1_1,
+	};
 
 	nor = devm_kzalloc(dev, sizeof(*nor), GFP_KERNEL);
 	if (!nor)
@@ -345,6 +359,13 @@ static int hisi_spi_nor_register(struct device_node *np,
 		return ret;
 	}
 
+	if (priv->chipselect != host->num_chip) {
+		dev_warn(dev, " The CS: %d states in device trees isn't real " \
+				"chipselect on board\n, using CS: %d instead. ",
+				priv->chipselect, host->num_chip);
+		priv->chipselect = host->num_chip;
+	}
+
 	ret = of_property_read_u32(np, "spi-max-frequency",
 			&priv->clkrate);
 	if (ret) {
@@ -361,19 +382,27 @@ static int hisi_spi_nor_register(struct device_node *np,
 	nor->write_reg = hisi_spi_nor_write_reg;
 	nor->read = hisi_spi_nor_read;
 	nor->write = hisi_spi_nor_write;
-	nor->erase = NULL;
-	ret = spi_nor_scan(nor, NULL, SPI_NOR_QUAD);
+
+	modes.rd_modes |= SNOR_MODE_1_1_1
+			| SNOR_MODE_1_1_2
+			| SNOR_MODE_1_2_2;
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+	modes.rd_modes |= SNOR_MODE_1_1_4 | SNOR_MODE_1_4_4;
+	modes.wr_modes |= SNOR_MODE_1_1_4 | SNOR_MODE_1_4_4;
+#endif
+	ret = spi_nor_scan(nor, NULL, &modes);
 	if (ret)
 		return ret;
 
 	mtd = &nor->mtd;
 	mtd->name = np->name;
-	ret = mtd_device_register(mtd, NULL, 0);
+	ret = hisi_snor_device_register(mtd);
 	if (ret)
 		return ret;
 
+	/* current chipselect has scanned, to detect next chipselect */
+	hifmc_cs_user[host->num_chip]++;
 	host->nor[host->num_chip] = nor;
-	host->num_chip++;
 	return 0;
 }
 
@@ -388,18 +417,27 @@ static void hisi_spi_nor_unregister_all(struct hifmc_host *host)
 static int hisi_spi_nor_register_all(struct hifmc_host *host)
 {
 	struct device *dev = host->dev;
-	struct device_node *np;
+	struct device_node *np = NULL;
 	int ret;
 
 	for_each_available_child_of_node(dev->of_node, np) {
+		if (hifmc_cs_user[host->num_chip]) {
+			dev_warn(dev, "Current CS(%d) is occupied.\n",
+					host->num_chip);
+			continue;
+		}
 		ret = hisi_spi_nor_register(np, host);
 		if (ret)
 			goto fail;
 
 		if (host->num_chip == HIFMC_MAX_CHIP_NUM) {
-			dev_warn(dev, "Flash device number exceeds the maximum chipselect number\n");
+			dev_warn(dev, "Flash device number exceeds the "
+					"maximum chipselect number\n");
 			break;
 		}
+
+		host->num_chip++;
+
 	}
 
 	return 0;
@@ -409,10 +447,11 @@ static int hisi_spi_nor_register_all(struct hifmc_host *host)
 	return ret;
 }
 
+/******************************************************************************/
 static int hisi_spi_nor_probe(struct platform_device *pdev)
 {
 	struct device *dev = &pdev->dev;
-	struct resource *res;
+	struct hisi_fmc *fmc = dev_get_drvdata(dev->parent);
 	struct hifmc_host *host;
 	int ret;
 
@@ -423,19 +462,10 @@ static int hisi_spi_nor_probe(struct platform_device *pdev)
 	platform_set_drvdata(pdev, host);
 	host->dev = dev;
 
-	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "control");
-	host->regbase = devm_ioremap_resource(dev, res);
-	if (IS_ERR(host->regbase))
-		return PTR_ERR(host->regbase);
-
-	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "memory");
-	host->iobase = devm_ioremap_resource(dev, res);
-	if (IS_ERR(host->iobase))
-		return PTR_ERR(host->iobase);
-
-	host->clk = devm_clk_get(dev, NULL);
-	if (IS_ERR(host->clk))
-		return PTR_ERR(host->clk);
+	host->regbase = fmc->regbase;
+	host->iobase = fmc->iobase;
+	host->clk = fmc->clk;
+	host->lock = &fmc->lock;
 
 	ret = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(32));
 	if (ret) {
@@ -448,40 +478,116 @@ static int hisi_spi_nor_probe(struct platform_device *pdev)
 	if (!host->buffer)
 		return -ENOMEM;
 
-	mutex_init(&host->lock);
 	clk_prepare_enable(host->clk);
 	hisi_spi_nor_init(host);
 	ret = hisi_spi_nor_register_all(host);
 	if (ret)
-		mutex_destroy(&host->lock);
+		dev_warn(dev, "spi nor register fail!\n");
 
 	clk_disable_unprepare(host->clk);
+
 	return ret;
 }
 
+/******************************************************************************/
 static int hisi_spi_nor_remove(struct platform_device *pdev)
 {
 	struct hifmc_host *host = platform_get_drvdata(pdev);
 
 	hisi_spi_nor_unregister_all(host);
-	mutex_destroy(&host->lock);
 	clk_disable_unprepare(host->clk);
 	return 0;
 }
 
+/******************************************************************************/
+static void hisi_spi_nor_driver_shutdown(struct platform_device *pdev)
+{
+	int i;
+	struct hifmc_host *host = platform_get_drvdata(pdev);
+
+	if (!host)
+		return;
+
+	mutex_lock(host->lock);
+	clk_prepare_enable(host->clk);
+
+	spi_nor_switch_spi_type(host);
+	for (i = 0; i < host->num_chip; i++)
+		spi_nor_driver_shutdown(host->nor[i]);
+
+	clk_disable_unprepare(host->clk);
+	mutex_unlock(host->lock);
+	dev_dbg(host->dev, "End of driver shutdown\n");
+}
+
+#ifdef CONFIG_PM
+/******************************************************************************/
+static int hisi_spi_nor_driver_suspend(struct platform_device *pdev,
+		pm_message_t state)
+{
+	int i;
+	struct hifmc_host *host = platform_get_drvdata(pdev);
+
+	if (!host)
+		return 0;
+
+	mutex_lock(host->lock);
+	clk_prepare_enable(host->clk);
+
+	spi_nor_switch_spi_type(host);
+	for (i = 0; i < host->num_chip; i++)
+		spi_nor_suspend(host->nor[i], state);
+
+	clk_disable_unprepare(host->clk);
+	mutex_unlock(host->lock);
+	dev_dbg(host->dev, "End of suspend\n");
+
+	return 0;
+}
+
+/******************************************************************************/
+static int hisi_spi_nor_driver_resume(struct platform_device *pdev)
+{
+	int i;
+	struct hifmc_host *host = platform_get_drvdata(pdev);
+
+	if (!host)
+		return 0;
+
+	mutex_lock(host->lock);
+	clk_prepare_enable(host->clk);
+
+	spi_nor_switch_spi_type(host);
+	for (i = 0; i < host->num_chip; i++)
+		spi_nor_resume(host->nor[i]);
+
+	mutex_unlock(host->lock);
+	dev_dbg(host->dev, "End of resume\n");
+
+	return 0;
+}
+#endif /* End of CONFIG_PM */
+
+/******************************************************************************/
 static const struct of_device_id hisi_spi_nor_dt_ids[] = {
 	{ .compatible = "hisilicon,fmc-spi-nor"},
 	{ /* sentinel */ }
 };
 MODULE_DEVICE_TABLE(of, hisi_spi_nor_dt_ids);
 
+/******************************************************************************/
 static struct platform_driver hisi_spi_nor_driver = {
 	.driver = {
 		.name	= "hisi-sfc",
 		.of_match_table = hisi_spi_nor_dt_ids,
 	},
-	.probe	= hisi_spi_nor_probe,
-	.remove	= hisi_spi_nor_remove,
+	.probe		= hisi_spi_nor_probe,
+	.remove		= hisi_spi_nor_remove,
+	.shutdown	= hisi_spi_nor_driver_shutdown,
+#ifdef CONFIG_PM
+	.suspend	= hisi_spi_nor_driver_suspend,
+	.resume		= hisi_spi_nor_driver_resume,
+#endif
 };
 module_platform_driver(hisi_spi_nor_driver);
 
diff --git a/drivers/mtd/spi-nor/spi-nor.c b/drivers/mtd/spi-nor/spi-nor.c
index 21dde52..d9b3e50 100644
--- a/drivers/mtd/spi-nor/spi-nor.c
+++ b/drivers/mtd/spi-nor/spi-nor.c
@@ -75,6 +75,12 @@ struct flash_info {
 					 * bit. Must be used with
 					 * SPI_NOR_HAS_LOCK.
 					 */
+#define SPI_NOR_4B_OPCODES	BIT(10)	/*
+					 * Use dedicated 4byte address op codes
+					 * to support memory size above 128Mib.
+					 */
+
+	const struct spi_nor_basic_flash_parameter *params;
 };
 
 #define JEDEC_MFR(info)	((info)->id[0])
@@ -139,24 +145,6 @@ static int read_cr(struct spi_nor *nor)
 }
 
 /*
- * Dummy Cycle calculation for different type of read.
- * It can be used to support more commands with
- * different dummy cycle requirements.
- */
-static inline int spi_nor_read_dummy_cycles(struct spi_nor *nor)
-{
-	switch (nor->flash_read) {
-	case SPI_NOR_FAST:
-	case SPI_NOR_DUAL:
-	case SPI_NOR_QUAD:
-		return 8;
-	case SPI_NOR_NORMAL:
-		return 0;
-	}
-	return 0;
-}
-
-/*
  * Write status register 1 byte
  * Returns negative if error occurred.
  */
@@ -188,6 +176,80 @@ static inline struct spi_nor *mtd_to_spi_nor(struct mtd_info *mtd)
 	return mtd->priv;
 }
 
+struct spi_nor_address_entry {
+	u8	src_opcode;
+	u8	dst_opcode;
+};
+
+static u8 spi_nor_convert_opcode(u8 opcode,
+				 const struct spi_nor_address_entry *entries,
+				 size_t num_entries)
+{
+	int min, max;
+
+	min = 0;
+	max = num_entries - 1;
+	while (min <= max) {
+		int mid = (min + max) >> 1;
+		const struct spi_nor_address_entry *entry = &entries[mid];
+
+		if (opcode == entry->src_opcode)
+			return entry->dst_opcode;
+
+		if (opcode < entry->src_opcode)
+			max = mid - 1;
+		else
+			min = mid + 1;
+	}
+
+	/* No conversion found */
+	return opcode;
+}
+
+static u8 spi_nor_3to4_opcode(u8 opcode)
+{
+	/* MUST be sorted by 3byte opcode */
+#define ENTRY_3TO4(_opcode)	{ _opcode, _opcode##_4B }
+	static const struct spi_nor_address_entry spi_nor_3to4_table[] = {
+		ENTRY_3TO4(SPINOR_OP_PP),		/* 0x02 */
+		ENTRY_3TO4(SPINOR_OP_READ),		/* 0x03 */
+		ENTRY_3TO4(SPINOR_OP_READ_FAST),	/* 0x0b */
+		ENTRY_3TO4(SPINOR_OP_BE_4K),		/* 0x20 */
+		ENTRY_3TO4(SPINOR_OP_PP_1_1_4),		/* 0x32 */
+		ENTRY_3TO4(SPINOR_OP_PP_1_4_4),		/* 0x38 */
+		ENTRY_3TO4(SPINOR_OP_READ_1_1_2),	/* 0x3b */
+		ENTRY_3TO4(SPINOR_OP_BE_32K),		/* 0x52 */
+		ENTRY_3TO4(SPINOR_OP_READ_1_1_4),	/* 0x6b */
+		ENTRY_3TO4(SPINOR_OP_READ_1_2_2),	/* 0xbb */
+		ENTRY_3TO4(SPINOR_OP_SE),		/* 0xd8 */
+		ENTRY_3TO4(SPINOR_OP_READ_1_4_4),	/* 0xeb */
+	};
+#undef ENTRY_3TO4
+
+	return spi_nor_convert_opcode(opcode, spi_nor_3to4_table,
+				      ARRAY_SIZE(spi_nor_3to4_table));
+}
+
+static void spi_nor_set_4byte_opcodes(struct spi_nor *nor,
+				      const struct flash_info *info)
+{
+	/* Do some manufacturer fixups first */
+	switch (JEDEC_MFR(info)) {
+	case SNOR_MFR_SPANSION:
+		/* No small sector erase for 4-byte command set */
+		nor->erase_opcode = SPINOR_OP_SE;
+		nor->mtd.erasesize = info->sector_size;
+		break;
+
+	default:
+		break;
+	}
+
+	nor->read_opcode	= spi_nor_3to4_opcode(nor->read_opcode);
+	nor->program_opcode	= spi_nor_3to4_opcode(nor->program_opcode);
+	nor->erase_opcode	= spi_nor_3to4_opcode(nor->erase_opcode);
+}
+
 /* Enable/disable 4-byte addressing mode. */
 static inline int set_4byte(struct spi_nor *nor, const struct flash_info *info,
 			    int enable)
@@ -201,16 +263,26 @@ static inline int set_4byte(struct spi_nor *nor, const struct flash_info *info,
 		/* Some Micron need WREN command; all will accept it */
 		need_wren = true;
 	case SNOR_MFR_MACRONIX:
-	case SNOR_MFR_WINBOND:
 		if (need_wren)
 			write_enable(nor);
 
 		cmd = enable ? SPINOR_OP_EN4B : SPINOR_OP_EX4B;
 		status = nor->write_reg(nor, cmd, NULL, 0);
+
 		if (need_wren)
 			write_disable(nor);
 
 		return status;
+	case SNOR_MFR_WINBOND:
+		if (enable)
+			return nor->write_reg(nor, SPINOR_OP_EN4B, NULL, 0);
+		else {
+			/* w25q256fvfg must send reset to disable 4 byte mode */
+			nor->write_reg(nor, SPINOR_ENABLE_RESET, NULL, 0);
+			nor->write_reg(nor, SPINOR_OP_RESET, NULL, 0);
+			udelay(30);
+		}
+		return 0;
 	default:
 		/* Spansion style */
 		nor->cmd_buf[0] = enable << 7;
@@ -220,6 +292,7 @@ static inline int set_4byte(struct spi_nor *nor, const struct flash_info *info,
 static inline int spi_nor_sr_ready(struct spi_nor *nor)
 {
 	int sr = read_sr(nor);
+
 	if (sr < 0)
 		return sr;
 	else
@@ -229,6 +302,7 @@ static inline int spi_nor_sr_ready(struct spi_nor *nor)
 static inline int spi_nor_fsr_ready(struct spi_nor *nor)
 {
 	int fsr = read_fsr(nor);
+
 	if (fsr < 0)
 		return fsr;
 	else
@@ -238,6 +312,7 @@ static inline int spi_nor_fsr_ready(struct spi_nor *nor)
 static int spi_nor_ready(struct spi_nor *nor)
 {
 	int sr, fsr;
+
 	sr = spi_nor_sr_ready(nor);
 	if (sr < 0)
 		return sr;
@@ -367,6 +442,12 @@ static int spi_nor_erase(struct mtd_info *mtd, struct erase_info *instr)
 	if (ret)
 		return ret;
 
+#ifdef CONFIG_HISI_SPI_BLOCK_PROTECT
+	if ((nor->level) && (addr < nor->end_addr)) {
+		dev_err(nor->dev, "Error: The erase area was locked\n");
+		return -EINVAL;
+	}
+#endif
 	/* whole-chip erase? */
 	if (len == mtd->size) {
 		unsigned long timeout;
@@ -745,6 +826,203 @@ static int spi_nor_is_locked(struct mtd_info *mtd, loff_t ofs, uint64_t len)
 	return ret;
 }
 
+#define SNOR_RD_MODES			\
+	(SNOR_MODE_SLOW |			\
+	 SNOR_MODE_1_1_1 |			\
+	 SNOR_MODE_1_1_2 |			\
+	 SNOR_MODE_1_2_2 |			\
+	 SNOR_MODE_1_1_4 |			\
+	 SNOR_MODE_1_4_4)
+
+#define SNOR_WR_MODES			\
+	(SNOR_MODE_1_1_1 |			\
+	 SNOR_MODE_1_1_4)
+
+static int spansion_quad_enable(struct spi_nor *nor);
+static int macronix_quad_enable(struct spi_nor *nor);
+static int gd_quad_enable(struct spi_nor *nor);
+
+#define SNOR_EON_RD_MODES			\
+	(SNOR_MODE_SLOW |			\
+	 SNOR_MODE_1_1_1 |			\
+	 SNOR_MODE_1_1_2 |			\
+	 SNOR_MODE_1_2_2)
+
+#define SNOR_EON_WR_MODES			\
+	(SNOR_MODE_1_1_1)
+
+static const struct spi_nor_basic_flash_parameter eon_params = {
+	.rd_modes		= SNOR_EON_RD_MODES,
+	.reads[SNOR_MIDX_SLOW]	= SNOR_OP_READ(0, 0, SPINOR_OP_READ),
+	.reads[SNOR_MIDX_1_1_1]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_FAST),
+	.reads[SNOR_MIDX_1_1_2]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_2),
+	.reads[SNOR_MIDX_1_2_2]	= SNOR_OP_READ(8, 0, SPINOR_OP_READ_1_2_2),
+	.reads[SNOR_MIDX_1_1_4]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_4),
+	.reads[SNOR_MIDX_1_4_4]	= SNOR_OP_READ(8, 16, SPINOR_OP_READ_1_4_4),
+
+	.wr_modes		= SNOR_EON_WR_MODES,
+	.page_programs[SNOR_MIDX_1_1_1]	= SPINOR_OP_PP,
+
+	.erase_types[0]		= SNOR_OP_ERASE_64K(SPINOR_OP_SE),
+
+};
+
+static const struct spi_nor_basic_flash_parameter esmt_params = {
+	.rd_modes		= SNOR_RD_MODES,
+	.reads[SNOR_MIDX_SLOW]	= SNOR_OP_READ(0, 0, SPINOR_OP_READ),
+	.reads[SNOR_MIDX_1_1_1]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_FAST),
+	.reads[SNOR_MIDX_1_1_2]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_2),
+	.reads[SNOR_MIDX_1_2_2]	= SNOR_OP_READ(8, 0, SPINOR_OP_READ_1_2_2),
+	.reads[SNOR_MIDX_1_1_4]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_4),
+	.reads[SNOR_MIDX_1_4_4]	= SNOR_OP_READ(8, 16, SPINOR_OP_READ_1_4_4),
+
+	.wr_modes		= SNOR_WR_MODES,
+	.page_programs[SNOR_MIDX_1_1_1]	= SPINOR_OP_PP,
+	.page_programs[SNOR_MIDX_1_1_4]	= SPINOR_OP_PP_1_1_4,
+
+	.erase_types[0]		= SNOR_OP_ERASE_64K(SPINOR_OP_SE),
+
+	.enable_quad_io         = macronix_quad_enable,
+
+};
+
+#define SNOR_PARAGON_WR_MODES			\
+	(SNOR_MODE_1_1_1)
+
+static const struct spi_nor_basic_flash_parameter paragon_params = {
+	.rd_modes		= SNOR_RD_MODES,
+	.reads[SNOR_MIDX_SLOW]	= SNOR_OP_READ(0, 0, SPINOR_OP_READ),
+	.reads[SNOR_MIDX_1_1_1]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_FAST),
+	.reads[SNOR_MIDX_1_1_2]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_2),
+	.reads[SNOR_MIDX_1_2_2]	= SNOR_OP_READ(8, 0, SPINOR_OP_READ_1_2_2),
+	.reads[SNOR_MIDX_1_1_4]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_4),
+	.reads[SNOR_MIDX_1_4_4]	= SNOR_OP_READ(8, 16, SPINOR_OP_READ_1_4_4),
+
+	.wr_modes		= SNOR_PARAGON_WR_MODES,
+	.page_programs[SNOR_MIDX_1_1_1]	= SPINOR_OP_PP,
+
+	.erase_types[0]		= SNOR_OP_ERASE_64K(SPINOR_OP_SE),
+
+	.enable_quad_io         = spansion_quad_enable,
+
+};
+
+static const struct spi_nor_basic_flash_parameter gd_params = {
+	.rd_modes		= SNOR_RD_MODES,
+	.reads[SNOR_MIDX_SLOW]	= SNOR_OP_READ(0, 0, SPINOR_OP_READ),
+	.reads[SNOR_MIDX_1_1_1]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_FAST),
+	.reads[SNOR_MIDX_1_1_2]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_2),
+	.reads[SNOR_MIDX_1_2_2]	= SNOR_OP_READ(8, 0, SPINOR_OP_READ_1_2_2),
+	.reads[SNOR_MIDX_1_1_4]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_4),
+	.reads[SNOR_MIDX_1_4_4]	= SNOR_OP_READ(8, 16, SPINOR_OP_READ_1_4_4),
+
+	.wr_modes		= SNOR_WR_MODES,
+	.page_programs[SNOR_MIDX_1_1_1]	= SPINOR_OP_PP,
+	.page_programs[SNOR_MIDX_1_1_4]	= SPINOR_OP_PP_1_1_4,
+
+	.erase_types[0]		= SNOR_OP_ERASE_64K(SPINOR_OP_SE),
+
+	.enable_quad_io         = gd_quad_enable,
+
+};
+
+static const struct spi_nor_basic_flash_parameter winbond_params = {
+	.rd_modes		= SNOR_RD_MODES,
+	.reads[SNOR_MIDX_SLOW]	= SNOR_OP_READ(0, 0, SPINOR_OP_READ),
+	.reads[SNOR_MIDX_1_1_1]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_FAST),
+	.reads[SNOR_MIDX_1_1_2]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_2),
+	.reads[SNOR_MIDX_1_2_2]	= SNOR_OP_READ(8, 0, SPINOR_OP_READ_1_2_2),
+	.reads[SNOR_MIDX_1_1_4]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_4),
+	.reads[SNOR_MIDX_1_4_4]	= SNOR_OP_READ(8, 16, SPINOR_OP_READ_1_4_4),
+
+	.wr_modes		= SNOR_WR_MODES,
+	.page_programs[SNOR_MIDX_1_1_1]	= SPINOR_OP_PP,
+	.page_programs[SNOR_MIDX_1_1_4]	= SPINOR_OP_PP_1_1_4,
+
+	.erase_types[0]		= SNOR_OP_ERASE_64K(SPINOR_OP_SE),
+
+	.enable_quad_io         = spansion_quad_enable,
+
+};
+
+static const struct spi_nor_basic_flash_parameter spansion_params = {
+	.rd_modes		= SNOR_RD_MODES,
+	.reads[SNOR_MIDX_SLOW]	= SNOR_OP_READ(0, 0, SPINOR_OP_READ),
+	.reads[SNOR_MIDX_1_1_1]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_FAST),
+	.reads[SNOR_MIDX_1_1_2]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_2),
+	.reads[SNOR_MIDX_1_2_2]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_2_2),
+	.reads[SNOR_MIDX_1_1_4]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_4),
+	.reads[SNOR_MIDX_1_4_4]	= SNOR_OP_READ(8, 16, SPINOR_OP_READ_1_4_4),
+
+	.wr_modes		= SNOR_WR_MODES,
+	.page_programs[SNOR_MIDX_1_1_1]	= SPINOR_OP_PP,
+	.page_programs[SNOR_MIDX_1_1_4]	= SPINOR_OP_PP_1_1_4,
+
+	.erase_types[0]		= SNOR_OP_ERASE_64K(SPINOR_OP_SE),
+
+	.enable_quad_io         = spansion_quad_enable,
+
+};
+
+#define SNOR_MXIC_WR_MODES			\
+	(SNOR_MODE_1_1_1 |			\
+	 SNOR_MODE_1_4_4)
+
+static const struct spi_nor_basic_flash_parameter mxic_params = {
+	.rd_modes		= SNOR_RD_MODES,
+	.reads[SNOR_MIDX_SLOW]	= SNOR_OP_READ(0, 0, SPINOR_OP_READ),
+	.reads[SNOR_MIDX_1_1_1]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_FAST),
+	.reads[SNOR_MIDX_1_1_2]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_2),
+	.reads[SNOR_MIDX_1_2_2]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_2_2),
+	.reads[SNOR_MIDX_1_1_4]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_4),
+	.reads[SNOR_MIDX_1_4_4]	= SNOR_OP_READ(8, 16, SPINOR_OP_READ_1_4_4),
+
+	.wr_modes		= SNOR_MXIC_WR_MODES,
+	.page_programs[SNOR_MIDX_1_1_1]	= SPINOR_OP_PP,
+	.page_programs[SNOR_MIDX_1_4_4]	= SPINOR_OP_PP_1_4_4,
+
+	.erase_types[0]		= SNOR_OP_ERASE_64K(SPINOR_OP_SE),
+
+	.enable_quad_io         = macronix_quad_enable,
+
+};
+
+static const struct spi_nor_basic_flash_parameter micron_params = {
+	.rd_modes		= SNOR_RD_MODES,
+	.reads[SNOR_MIDX_SLOW]	= SNOR_OP_READ(0, 0, SPINOR_OP_READ),
+	.reads[SNOR_MIDX_1_1_1]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_FAST),
+	.reads[SNOR_MIDX_1_1_2]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_2),
+	.reads[SNOR_MIDX_1_2_2]	= SNOR_OP_READ(8, 8, SPINOR_OP_READ_1_2_2),
+	.reads[SNOR_MIDX_1_1_4]	= SNOR_OP_READ(1, 7, SPINOR_OP_READ_1_1_4),
+	.reads[SNOR_MIDX_1_4_4]	= SNOR_OP_READ(0, 40, SPINOR_OP_READ_1_4_4),
+
+	.wr_modes		= SNOR_WR_MODES,
+	.page_programs[SNOR_MIDX_1_1_1]	= SPINOR_OP_PP,
+	.page_programs[SNOR_MIDX_1_1_4]	= SPINOR_OP_PP_1_1_4,
+
+	.erase_types[0]		= SNOR_OP_ERASE_64K(SPINOR_OP_SE),
+
+};
+
+static const struct spi_nor_basic_flash_parameter micron_4k_params = {
+	.rd_modes		= SNOR_RD_MODES,
+	.reads[SNOR_MIDX_SLOW]	= SNOR_OP_READ(0, 0, SPINOR_OP_READ),
+	.reads[SNOR_MIDX_1_1_1]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_FAST),
+	.reads[SNOR_MIDX_1_1_2]	= SNOR_OP_READ(0, 8, SPINOR_OP_READ_1_1_2),
+	.reads[SNOR_MIDX_1_2_2]	= SNOR_OP_READ(1, 7, SPINOR_OP_READ_1_2_2),
+	.reads[SNOR_MIDX_1_1_4]	= SNOR_OP_READ(1, 7, SPINOR_OP_READ_1_1_4),
+	.reads[SNOR_MIDX_1_4_4]	= SNOR_OP_READ(1, 9, SPINOR_OP_READ_1_4_4),
+
+	.wr_modes		= SNOR_WR_MODES,
+	.page_programs[SNOR_MIDX_1_1_1]	= SPINOR_OP_PP,
+	.page_programs[SNOR_MIDX_1_1_4]	= SPINOR_OP_PP_1_1_4,
+
+	.erase_types[0]		= SNOR_OP_ERASE_64K(SPINOR_OP_SE),
+	.erase_types[1]		= SNOR_OP_ERASE_4K(SPINOR_OP_BE_4K),
+};
+
+#define PARAMS(_name) .params = &_name##_params
+
 /* Used when the "_ext_id" is two bytes at most */
 #define INFO(_jedec_id, _ext_id, _sector_size, _n_sectors, _flags)	\
 		.id = {							\
@@ -758,7 +1036,7 @@ static int spi_nor_is_locked(struct mtd_info *mtd, loff_t ofs, uint64_t len)
 		.sector_size = (_sector_size),				\
 		.n_sectors = (_n_sectors),				\
 		.page_size = 256,					\
-		.flags = (_flags),
+		.flags = (_flags)
 
 #define INFO6(_jedec_id, _ext_id, _sector_size, _n_sectors, _flags)	\
 		.id = {							\
@@ -812,44 +1090,36 @@ static const struct flash_info spi_nor_ids[] = {
 	/* EON -- en25xxx */
 	{ "en25f32",    INFO(0x1c3116, 0, 64 * 1024,   64, SECT_4K) },
 	{ "en25p32",    INFO(0x1c2016, 0, 64 * 1024,   64, 0) },
-	{ "en25q32b",   INFO(0x1c3016, 0, 64 * 1024,   64, 0) },
+	{ "en25q32b",   INFO(0x1c3016, 0, 64 * 1024,   64, 0), PARAMS(eon) },
 	{ "en25p64",    INFO(0x1c2017, 0, 64 * 1024,  128, 0) },
-	{ "en25q64",    INFO(0x1c3017, 0, 64 * 1024,  128, SECT_4K) },
+	{ "en25q64",    INFO(0x1c3017, 0, 64 * 1024,  128, SECT_4K),
+		PARAMS(eon) },
+	{ "en25q128",   INFO(0x1c3018, 0, 64 * 1024,  256, 0), PARAMS(eon) },
 	{ "en25qh128",  INFO(0x1c7018, 0, 64 * 1024,  256, 0) },
 	{ "en25qh256",  INFO(0x1c7019, 0, 64 * 1024,  512, 0) },
 	{ "en25s64",	INFO(0x1c3817, 0, 64 * 1024,  128, SECT_4K) },
 
 	/* ESMT */
 	{ "f25l32pa", INFO(0x8c2016, 0, 64 * 1024, 64, SECT_4K) },
+	{ "f25l64qa", INFO(0x8c4117, 0, 64 * 1024, 128, 0), PARAMS(esmt) },
 
 	/* Everspin */
-	{ "mr25h256", CAT25_INFO( 32 * 1024, 1, 256, 2, SPI_NOR_NO_ERASE | SPI_NOR_NO_FR) },
-	{ "mr25h10",  CAT25_INFO(128 * 1024, 1, 256, 3, SPI_NOR_NO_ERASE | SPI_NOR_NO_FR) },
+	{ "mr25h256", CAT25_INFO(32 * 1024, 1, 256, 2, SPI_NOR_NO_ERASE
+			| SPI_NOR_NO_FR) },
+	{ "mr25h10",  CAT25_INFO(128 * 1024, 1, 256, 3, SPI_NOR_NO_ERASE
+			| SPI_NOR_NO_FR) },
 
 	/* Fujitsu */
 	{ "mb85rs1mt", INFO(0x047f27, 0, 128 * 1024, 1, SPI_NOR_NO_ERASE) },
 
-	/* GigaDevice */
-	{
-		"gd25q32", INFO(0xc84016, 0, 64 * 1024,  64,
-			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB)
-	},
-	{
-		"gd25q64", INFO(0xc84017, 0, 64 * 1024, 128,
-			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB)
-	},
-	{
-		"gd25lq64c", INFO(0xc86017, 0, 64 * 1024, 128,
-			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB)
-	},
-	{
-		"gd25q128", INFO(0xc84018, 0, 64 * 1024, 256,
-			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB)
-	},
+	/* GigaDevice 3.3V */
+	{ "gd25q16c", INFO(0xc84015, 0, 64 * 1024, 32, SECT_4K), PARAMS(gd) },
+	{ "gd25q32", INFO(0xc84016, 0, 64 * 1024,  64, SECT_4K), PARAMS(gd) },
+	{ "gd25q64", INFO(0xc84017, 0, 64 * 1024, 128, SECT_4K), PARAMS(gd) },
+	{ "gd25q128", INFO(0xc84018, 0, 64 * 1024, 256, SECT_4K), PARAMS(gd) },
+	/* GigaDevice 1.8V */
+	{ "gd25lq64", INFO(0xc86017, 0, 64 * 1024, 128, SECT_4K), PARAMS(gd) },
+	{ "gd25lq128", INFO(0xc86018, 0, 64 * 1024, 256, SECT_4K), PARAMS(gd) },
 
 	/* Intel/Numonyx -- xxxs33b */
 	{ "160s33b",  INFO(0x898911, 0, 64 * 1024,  32, 0) },
@@ -859,68 +1129,104 @@ static const struct flash_info spi_nor_ids[] = {
 	/* ISSI */
 	{ "is25cd512", INFO(0x7f9d20, 0, 32 * 1024,   2, SECT_4K) },
 
-	/* Macronix */
+	/* Macronix/MXIC 3.3V */
 	{ "mx25l512e",   INFO(0xc22010, 0, 64 * 1024,   1, SECT_4K) },
 	{ "mx25l2005a",  INFO(0xc22012, 0, 64 * 1024,   4, SECT_4K) },
 	{ "mx25l4005a",  INFO(0xc22013, 0, 64 * 1024,   8, SECT_4K) },
 	{ "mx25l8005",   INFO(0xc22014, 0, 64 * 1024,  16, 0) },
-	{ "mx25l1606e",  INFO(0xc22015, 0, 64 * 1024,  32, SECT_4K) },
-	{ "mx25l3205d",  INFO(0xc22016, 0, 64 * 1024,  64, SECT_4K) },
+	{ "mx25l1606e",  INFO(0xc22015, 0, 64 * 1024,  32, SECT_4K
+			| SPI_NOR_DUAL_READ) },
+	{ "mx25l3205d",  INFO(0xc22016, 0, 64 * 1024,  64, 0) },
 	{ "mx25l3255e",  INFO(0xc29e16, 0, 64 * 1024,  64, SECT_4K) },
-	{ "mx25l6405d",  INFO(0xc22017, 0, 64 * 1024, 128, SECT_4K) },
-	{ "mx25u6435f",  INFO(0xc22537, 0, 64 * 1024, 128, SECT_4K) },
-	{ "mx25l12805d", INFO(0xc22018, 0, 64 * 1024, 256, 0) },
+	{ "mx25l6436f",  INFO(0xc22017, 0, 64 * 1024, 128, 0), PARAMS(mxic) },
+	{ "mx25l12835f", INFO(0xc22018, 0, 64 * 1024, 256, 0), PARAMS(mxic) },
 	{ "mx25l12855e", INFO(0xc22618, 0, 64 * 1024, 256, 0) },
-	{ "mx25l25635e", INFO(0xc22019, 0, 64 * 1024, 512, 0) },
+	{ "mx25l25635f", INFO(0xc22019, 0, 64 * 1024, 512, 0), PARAMS(mxic) },
+	{ "mx25l25673g", INFO(0xc22019, 0, 64 * 1024, 512, SPI_NOR_QUAD_READ
+			| SPI_NOR_4B_OPCODES) },
 	{ "mx25l25655e", INFO(0xc22619, 0, 64 * 1024, 512, 0) },
-	{ "mx66l51235l", INFO(0xc2201a, 0, 64 * 1024, 1024, SPI_NOR_QUAD_READ) },
-	{ "mx66l1g55g",  INFO(0xc2261b, 0, 64 * 1024, 2048, SPI_NOR_QUAD_READ) },
-
-	/* Micron */
-	{ "n25q032",	 INFO(0x20ba16, 0, 64 * 1024,   64, SPI_NOR_QUAD_READ) },
-	{ "n25q032a",	 INFO(0x20bb16, 0, 64 * 1024,   64, SPI_NOR_QUAD_READ) },
-	{ "n25q064",     INFO(0x20ba17, 0, 64 * 1024,  128, SECT_4K | SPI_NOR_QUAD_READ) },
-	{ "n25q064a",    INFO(0x20bb17, 0, 64 * 1024,  128, SECT_4K | SPI_NOR_QUAD_READ) },
-	{ "n25q128a11",  INFO(0x20bb18, 0, 64 * 1024,  256, SECT_4K | SPI_NOR_QUAD_READ) },
-	{ "n25q128a13",  INFO(0x20ba18, 0, 64 * 1024,  256, SECT_4K | SPI_NOR_QUAD_READ) },
-	{ "n25q256a",    INFO(0x20ba19, 0, 64 * 1024,  512, SECT_4K | SPI_NOR_QUAD_READ) },
-	{ "n25q512a",    INFO(0x20bb20, 0, 64 * 1024, 1024, SECT_4K | USE_FSR | SPI_NOR_QUAD_READ) },
-	{ "n25q512ax3",  INFO(0x20ba20, 0, 64 * 1024, 1024, SECT_4K | USE_FSR | SPI_NOR_QUAD_READ) },
-	{ "n25q00",      INFO(0x20ba21, 0, 64 * 1024, 2048, SECT_4K | USE_FSR | SPI_NOR_QUAD_READ) },
-	{ "n25q00a",     INFO(0x20bb21, 0, 64 * 1024, 2048, SECT_4K | USE_FSR | SPI_NOR_QUAD_READ) },
+	{ "mx66l51235l", INFO(0xc2201a, 0, 64 * 1024, 1024, SPI_NOR_QUAD_READ)},
+	{ "mx66l1g55g",  INFO(0xc2261b, 0, 64 * 1024, 2048, SPI_NOR_QUAD_READ)},
+	{ "mx25v1635f",  INFO(0xc22315, 0, 64 * 1024, 32 , 0), PARAMS(mxic) },
+	/* Macronix/MXIC Wide Voltage Range 1.65~3.6V */
+	{ "mx25r6435f",  INFO(0xc22817, 0, 64 * 1024, 128, SPI_NOR_DUAL_READ
+			| SPI_NOR_QUAD_READ) },
+	/* Macronix/MXIC 1.8V */
+	{ "mx25u6435f",  INFO(0xc22537, 0, 64 * 1024, 128,
+			SECT_4K), PARAMS(mxic) },
+	{ "mx25u12835f", INFO(0xc22538, 0, 64 * 1024, 256, 0), PARAMS(mxic) },
+	{ "mx25u25635f", INFO(0xc22539, 0, 64 * 1024, 512, 0), PARAMS(mxic) },
+
+	/* Micron 3.3V */
+	{ "n25q032",     INFO(0x20ba16, 0, 64 * 1024,   64, 0),
+			PARAMS(micron) },
+	{ "n25q064",     INFO(0x20ba17, 0, 64 * 1024,  128, 0),
+			PARAMS(micron_4k) },
+	{ "n25q128a13",  INFO(0x20ba18, 0, 64 * 1024,  256, 0),
+			PARAMS(micron) },
+	{ "mt25ql256a/n25q256a",  INFO(0x20ba19, 0, 64 * 1024,  512, 0),
+			PARAMS(micron) },
+	{ "n25q512ax3",  INFO(0x20ba20, 0, 64 * 1024, 1024, USE_FSR),
+			PARAMS(micron_4k) },
+	{ "n25q00",      INFO(0x20ba21, 0, 64 * 1024, 2048, USE_FSR),
+			PARAMS(micron_4k) },
+	/* Micron 1.8V */
+	{ "n25q032a",    INFO(0x20bb16, 0, 64 * 1024,   64, 0),
+			PARAMS(micron) },
+	{ "n25q064a",    INFO(0x20bb17, 0, 64 * 1024,  128, 0),
+			PARAMS(micron) },
+	{ "mt25qu128a/n25q128a11",  INFO(0x20bb18, 0, 64 * 1024,  256, 0),
+			PARAMS(micron) },
+	{ "mt25qu256a",  INFO(0x20bb19, 0, 64 * 1024,  512, 0),
+			PARAMS(micron) },
+	{ "n25q512a",    INFO(0x20bb20, 0, 64 * 1024, 1024, USE_FSR),
+			PARAMS(micron_4k) },
 
 	/* PMC */
-	{ "pm25lv512",   INFO(0,        0, 32 * 1024,    2, SECT_4K_PMC) },
-	{ "pm25lv010",   INFO(0,        0, 32 * 1024,    4, SECT_4K_PMC) },
-	{ "pm25lq032",   INFO(0x7f9d46, 0, 64 * 1024,   64, SECT_4K) },
+	{ "pm25lv512",	INFO(0,        0, 32 * 1024,    2, SECT_4K_PMC) },
+	{ "pm25lv010",	INFO(0,        0, 32 * 1024,    4, SECT_4K_PMC) },
+	{ "pm25lq032",	INFO(0x7f9d46, 0, 64 * 1024,   64, SECT_4K) },
 
 	/* Spansion -- single (large) sector size only, at least
 	 * for the chips listed here (without boot sectors).
 	 */
-	{ "s25sl032p",  INFO(0x010215, 0x4d00,  64 * 1024,  64, SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
-	{ "s25sl064p",  INFO(0x010216, 0x4d00,  64 * 1024, 128, SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "s25sl032p",  INFO(0x010215, 0x4d00,  64 * 1024,  64,
+			SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "s25sl064p",  INFO(0x010216, 0x4d00,  64 * 1024, 128,
+			SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 	{ "s25fl256s0", INFO(0x010219, 0x4d00, 256 * 1024, 128, 0) },
-	{ "s25fl256s1", INFO(0x010219, 0x4d01,  64 * 1024, 512, SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
-	{ "s25fl512s",  INFO(0x010220, 0x4d00, 256 * 1024, 256, SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
-	{ "s70fl01gs",  INFO(0x010221, 0x4d00, 256 * 1024, 256, 0) },
+	{ "s25fl256s1", INFO(0x010219, 0x4d01,  64 * 1024, 512,
+			SPI_NOR_4B_OPCODES), PARAMS(spansion) },
+	{ "s25fl512s",	INFO(0x010220, 0x4d00, 256 * 1024, 256,
+			SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "s70fl01gs",	INFO(0x010221, 0x4d00, 256 * 1024, 256, 0) },
+	{ "s25fl127s/129p1", INFO(0x012018, 0x4d01, 64 * 1024, 256,
+			SECT_4K), PARAMS(spansion) },
 	{ "s25sl12800", INFO(0x012018, 0x0300, 256 * 1024,  64, 0) },
 	{ "s25sl12801", INFO(0x012018, 0x0301,  64 * 1024, 256, 0) },
-	{ "s25fl128s",	INFO6(0x012018, 0x4d0180, 64 * 1024, 256, SECT_4K | SPI_NOR_QUAD_READ) },
-	{ "s25fl129p0", INFO(0x012018, 0x4d00, 256 * 1024,  64, SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
-	{ "s25fl129p1", INFO(0x012018, 0x4d01,  64 * 1024, 256, SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
-	{ "s25sl004a",  INFO(0x010212,      0,  64 * 1024,   8, 0) },
-	{ "s25sl008a",  INFO(0x010213,      0,  64 * 1024,  16, 0) },
-	{ "s25sl016a",  INFO(0x010214,      0,  64 * 1024,  32, 0) },
-	{ "s25sl032a",  INFO(0x010215,      0,  64 * 1024,  64, 0) },
-	{ "s25sl064a",  INFO(0x010216,      0,  64 * 1024, 128, 0) },
-	{ "s25fl004k",  INFO(0xef4013,      0,  64 * 1024,   8, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
-	{ "s25fl008k",  INFO(0xef4014,      0,  64 * 1024,  16, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
-	{ "s25fl016k",  INFO(0xef4015,      0,  64 * 1024,  32, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
-	{ "s25fl064k",  INFO(0xef4017,      0,  64 * 1024, 128, SECT_4K) },
-	{ "s25fl116k",  INFO(0x014015,      0,  64 * 1024,  32, SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
-	{ "s25fl132k",  INFO(0x014016,      0,  64 * 1024,  64, SECT_4K) },
-	{ "s25fl164k",  INFO(0x014017,      0,  64 * 1024, 128, SECT_4K) },
-	{ "s25fl204k",  INFO(0x014013,      0,  64 * 1024,   8, SECT_4K | SPI_NOR_DUAL_READ) },
+	{ "s25fl128s",	INFO6(0x012018, 0x4d0180, 64 * 1024, 256, SECT_4K
+			|SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "s25fl129p0", INFO(0x012018, 0x4d00, 256 * 1024,  64,
+			SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "s25fl129p1", INFO(0x012018, 0x4d01,  64 * 1024, 256,
+			SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "s25sl004a",	INFO(0x010212,      0,  64 * 1024,   8, 0) },
+	{ "s25sl008a",	INFO(0x010213,      0,  64 * 1024,  16, 0) },
+	{ "s25sl016a",	INFO(0x010214,      0,  64 * 1024,  32, 0) },
+	{ "s25sl032a",	INFO(0x010215,      0,  64 * 1024,  64, 0) },
+	{ "s25sl064a",	INFO(0x010216,      0,  64 * 1024, 128, 0) },
+	{ "s25fl004k",	INFO(0xef4013,      0,  64 * 1024,   8, SECT_4K
+			| SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "s25fl008k",	INFO(0xef4014,      0,  64 * 1024,  16, SECT_4K
+			| SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+	{ "w25x16/s25fl016k",	INFO(0xef4015,      0,  64 * 1024,  32,
+			SECT_4K), PARAMS(winbond) },
+	/* { "s25fl064k",	INFO(0xef4017,      0,  64 * 1024, 128, SECT_4K
+			| SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) }, */
+	{ "s25fl132k",	INFO(0x014016,      0,  64 * 1024,  64, SECT_4K) },
+	{ "s25fl164k",	INFO(0x014017,      0,  64 * 1024, 128, SECT_4K) },
+	{ "s25fl204k",	INFO(0x014013,      0,  64 * 1024,   8, SECT_4K
+			| SPI_NOR_DUAL_READ) },
 
 	/* SST -- large erase sizes are "overlays", "sectors" are 4K */
 	{ "sst25vf040b", INFO(0xbf258d, 0, 64 * 1024,  8, SECT_4K | SST_WRITE) },
@@ -972,43 +1278,52 @@ static const struct flash_info spi_nor_ids[] = {
 	{ "m25px64",    INFO(0x207117,  0, 64 * 1024, 128, 0) },
 	{ "m25px80",    INFO(0x207114,  0, 64 * 1024, 16, 0) },
 
-	/* Winbond -- w25x "blocks" are 64K, "sectors" are 4KiB */
+	/* Winbond 3.3V-- w25x "blocks" are 64K, "sectors" are 4KiB */
 	{ "w25x05", INFO(0xef3010, 0, 64 * 1024,  1,  SECT_4K) },
 	{ "w25x10", INFO(0xef3011, 0, 64 * 1024,  2,  SECT_4K) },
 	{ "w25x20", INFO(0xef3012, 0, 64 * 1024,  4,  SECT_4K) },
 	{ "w25x40", INFO(0xef3013, 0, 64 * 1024,  8,  SECT_4K) },
 	{ "w25x80", INFO(0xef3014, 0, 64 * 1024,  16, SECT_4K) },
-	{ "w25x16", INFO(0xef3015, 0, 64 * 1024,  32, SECT_4K) },
+	{ "w25x16", INFO(0xef3015, 0, 64 * 1024,  32, SECT_4K
+			| SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 	{ "w25x32", INFO(0xef3016, 0, 64 * 1024,  64, SECT_4K) },
-	{ "w25q32", INFO(0xef4016, 0, 64 * 1024,  64, SECT_4K) },
-	{
-		"w25q32dw", INFO(0xef6016, 0, 64 * 1024,  64,
-			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB)
-	},
+	{ "w25q32", INFO(0xef4016, 0, 64 * 1024,  64,
+			SECT_4K), PARAMS(winbond) },
 	{ "w25x64", INFO(0xef3017, 0, 64 * 1024, 128, SECT_4K) },
-	{ "w25q64", INFO(0xef4017, 0, 64 * 1024, 128, SECT_4K) },
-	{
-		"w25q64dw", INFO(0xef6017, 0, 64 * 1024, 128,
-			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB)
-	},
-	{
-		"w25q128fw", INFO(0xef6018, 0, 64 * 1024, 256,
-			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB)
-	},
+	{ "w25q64/s25fl064k", INFO(0xef4017, 0, 64 * 1024, 128,
+			SECT_4K), PARAMS(winbond) },
 	{ "w25q80", INFO(0xef5014, 0, 64 * 1024,  16, SECT_4K) },
 	{ "w25q80bl", INFO(0xef4014, 0, 64 * 1024,  16, SECT_4K) },
-	{ "w25q128", INFO(0xef4018, 0, 64 * 1024, 256, SECT_4K) },
-	{ "w25q256", INFO(0xef4019, 0, 64 * 1024, 512, SECT_4K) },
+	{ "w25q128", INFO(0xef4018, 0, 64 * 1024, 256,
+			SECT_4K), PARAMS(winbond) },
+	{ "w25q256", INFO(0xef4019, 0, 64 * 1024, 512,
+			SECT_4K), PARAMS(winbond) },
+	/* Winbond 1.8V */
+	{ "w25q32dw", INFO(0xef6016, 0, 64 * 1024,  64,
+			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+			SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB) },
+	{ "w25q64dw", INFO(0xef6017, 0, 64 * 1024, 128,
+			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+			SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB), PARAMS(winbond) },
+	{ "w25q128fw", INFO(0xef6018, 0, 64 * 1024, 256,
+			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+			SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB), PARAMS(winbond) },
 
 	/* Catalyst / On Semiconductor -- non-JEDEC */
-	{ "cat25c11", CAT25_INFO(  16, 8, 16, 1, SPI_NOR_NO_ERASE | SPI_NOR_NO_FR) },
-	{ "cat25c03", CAT25_INFO(  32, 8, 16, 2, SPI_NOR_NO_ERASE | SPI_NOR_NO_FR) },
-	{ "cat25c09", CAT25_INFO( 128, 8, 32, 2, SPI_NOR_NO_ERASE | SPI_NOR_NO_FR) },
-	{ "cat25c17", CAT25_INFO( 256, 8, 32, 2, SPI_NOR_NO_ERASE | SPI_NOR_NO_FR) },
-	{ "cat25128", CAT25_INFO(2048, 8, 64, 2, SPI_NOR_NO_ERASE | SPI_NOR_NO_FR) },
+	{ "cat25c11", CAT25_INFO(16, 8, 16, 1, SPI_NOR_NO_ERASE
+			| SPI_NOR_NO_FR) },
+	{ "cat25c03", CAT25_INFO(32, 8, 16, 2, SPI_NOR_NO_ERASE
+			| SPI_NOR_NO_FR) },
+	{ "cat25c09", CAT25_INFO(28, 8, 32, 2, SPI_NOR_NO_ERASE
+			| SPI_NOR_NO_FR) },
+	{ "cat25c17", CAT25_INFO(256, 8, 32, 2, SPI_NOR_NO_ERASE
+			| SPI_NOR_NO_FR) },
+	{ "cat25128", CAT25_INFO(2048, 8, 64, 2, SPI_NOR_NO_ERASE
+			| SPI_NOR_NO_FR) },
+	/* Paragon 3.3V */
+	{ "pn25f16s", INFO(0xe04015, 0, 64 * 1024,  32, 0), PARAMS(paragon) },
+	{ "pn25f32s", INFO(0xe04016, 0, 64 * 1024,  64, 0), PARAMS(paragon) },
+
 	{ },
 };
 
@@ -1167,14 +1482,22 @@ static int spi_nor_write(struct mtd_info *mtd, loff_t to, size_t len,
 	ret = spi_nor_lock_and_prep(nor, SPI_NOR_OPS_WRITE);
 	if (ret)
 		return ret;
+#ifdef CONFIG_HISI_SPI_BLOCK_PROTECT
+	if (nor->level && (to < nor->end_addr)) {
+		dev_err(nor->dev, "Error: The DMA write area was locked\n");
+		return -EINVAL;
+	}
+#endif
 
 	for (i = 0; i < len; ) {
 		ssize_t written;
 
 		page_offset = (to + i) & (nor->page_size - 1);
+#ifndef CONFIG_SPI_HISI_SFC 
 		WARN_ONCE(page_offset,
 			  "Writing at offset %zu into a NOR page. Writing partial pages may decrease reliability and increase wear of NOR flash.",
 			  page_offset);
+#endif
 		/* the size of data remaining on the first page */
 		page_remain = min_t(size_t,
 				    nor->page_size - page_offset, len - i);
@@ -1211,15 +1534,22 @@ static int macronix_quad_enable(struct spi_nor *nor)
 	val = read_sr(nor);
 	if (val < 0)
 		return val;
+
+	if ((unsigned int)val & SR_QUAD_EN_MX)
+		return 0;
+
+	/* Update the Quad Enable bit. */
+	dev_info(nor->dev, "setting Macronix Quad Enable (non-volatile) bit\n");
+
 	write_enable(nor);
 
-	write_sr(nor, val | SR_QUAD_EN_MX);
+	write_sr(nor, (u8)val | SR_QUAD_EN_MX);
 
 	if (spi_nor_wait_till_ready(nor))
 		return 1;
 
 	ret = read_sr(nor);
-	if (!(ret > 0 && (ret & SR_QUAD_EN_MX))) {
+	if (!(ret > 0 && ((unsigned int)ret & SR_QUAD_EN_MX))) {
 		dev_err(nor->dev, "Macronix Quad bit not set\n");
 		return -EINVAL;
 	}
@@ -1244,28 +1574,131 @@ static int write_sr_cr(struct spi_nor *nor, u16 val)
 static int spansion_quad_enable(struct spi_nor *nor)
 {
 	int ret;
-	int quad_en = CR_QUAD_EN_SPAN << 8;
+	u16 val;
+
+	ret = read_cr(nor);
+	if (ret & CR_QUAD_EN_SPAN)
+		return 0;
+
+	/* Update the Quad Enable bit. */
+	dev_info(nor->dev, "setting Quad Enable (non-volatile) bit\n");
+
+	val = ((ret & 0xff) | CR_QUAD_EN_SPAN) << 8;
+
+	ret = read_sr(nor);
+	val |= (ret & 0xff);
 
 	write_enable(nor);
 
-	ret = write_sr_cr(nor, quad_en);
+	ret = write_sr_cr(nor, val);
 	if (ret < 0) {
 		dev_err(nor->dev,
 			"error while writing configuration register\n");
 		return -EINVAL;
 	}
 
+	if (spi_nor_wait_till_ready(nor))
+		return 1;
+
+	/* read back and check it */
+	ret = read_cr(nor);
+	if (!(ret > 0 && (ret & CR_QUAD_EN_SPAN))) {
+		dev_err(nor->dev, "Spansion Quad bit not set\n");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int micron_quad_enable(struct spi_nor *nor)
+{
+	int ret;
+	u8 val;
+
+	ret = nor->read_reg(nor, SPINOR_OP_RD_EVCR, &val, 1);
+	if (ret < 0) {
+		dev_err(nor->dev, "error %d reading EVCR\n", ret);
+		return ret;
+	}
+
+	write_enable(nor);
+
+	/* set EVCR, enable quad I/O */
+	nor->cmd_buf[0] = val & ~EVCR_QUAD_EN_MICRON;
+	ret = nor->write_reg(nor, SPINOR_OP_WD_EVCR, nor->cmd_buf, 1);
+	if (ret < 0) {
+		dev_err(nor->dev, "error while writing EVCR register\n");
+		return ret;
+	}
+
 	ret = spi_nor_wait_till_ready(nor);
-	if (ret) {
+	if (ret)
+		return ret;
+
+	/* read EVCR and check it */
+	ret = nor->read_reg(nor, SPINOR_OP_RD_EVCR, &val, 1);
+	if (ret < 0) {
+		dev_err(nor->dev, "error %d reading EVCR\n", ret);
+		return ret;
+	}
+	if (val & EVCR_QUAD_EN_MICRON) {
+		dev_err(nor->dev, "Micron EVCR Quad bit not clear\n");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int gd_quad_enable(struct spi_nor *nor)
+{
+	int ret;
+	u16 val;
+
+	/* First, Quad Enable for 16-Pin GD flash, use WRSR[01h] cmd */
+	ret = read_cr(nor);
+	val = ((ret & 0xff) | CR_QUAD_EN_SPAN) << 8;
+
+	ret = read_sr(nor);
+	val |= (ret & 0xff);
+
+	write_enable(nor);
+
+	ret = write_sr_cr(nor, val);
+	if (ret < 0) {
 		dev_err(nor->dev,
-			"timeout while writing configuration register\n");
+			"error while writing config and status register\n");
+		return -EINVAL;
+	}
+
+	if (spi_nor_wait_till_ready(nor))
+		return 1;
+
+	/* read back and check it */
+	ret = read_cr(nor);
+	if (ret & CR_QUAD_EN_SPAN)
+		return 0;
+
+	/* Second, Quad Enable for 8-Pin GD flash, use WRCR[31h] cmd */
+	ret = read_sr(nor);
+	if (!(ret & SR_WEL))
+		write_enable(nor);
+
+	ret = read_cr(nor);
+	nor->cmd_buf[0] = (ret & 0xff) | CR_QUAD_EN_SPAN;
+
+	ret = nor->write_reg(nor, SPINOR_OP_WRCR, nor->cmd_buf, 1);
+	if (ret < 0) {
+		dev_err(nor->dev, "error while writing config register\n");
 		return ret;
 	}
 
+	if (spi_nor_wait_till_ready(nor))
+		return 1;
+
 	/* read back and check it */
 	ret = read_cr(nor);
 	if (!(ret > 0 && (ret & CR_QUAD_EN_SPAN))) {
-		dev_err(nor->dev, "Spansion Quad bit not set\n");
+		dev_err(nor->dev, "GigaDevice Quad bit not set\n");
 		return -EINVAL;
 	}
 
@@ -1277,6 +1710,7 @@ static int set_quad_mode(struct spi_nor *nor, const struct flash_info *info)
 	int status;
 
 	switch (JEDEC_MFR(info)) {
+	case SNOR_MFR_ESMT:
 	case SNOR_MFR_MACRONIX:
 		status = macronix_quad_enable(nor);
 		if (status) {
@@ -1285,7 +1719,19 @@ static int set_quad_mode(struct spi_nor *nor, const struct flash_info *info)
 		}
 		return status;
 	case SNOR_MFR_MICRON:
-		return 0;
+		status = micron_quad_enable(nor);
+		if (status) {
+			dev_err(nor->dev, "Micron quad-read not enabled\n");
+			return -EINVAL;
+		}
+		return status;
+	case SNOR_MFR_GD:
+		status = gd_quad_enable(nor);
+		if (status) {
+			dev_err(nor->dev, "GD quad-read not enabled\n");
+			return -EINVAL;
+		}
+		return status;
 	default:
 		status = spansion_quad_enable(nor);
 		if (status) {
@@ -1307,8 +1753,350 @@ static int spi_nor_check(struct spi_nor *nor)
 	return 0;
 }
 
-int spi_nor_scan(struct spi_nor *nor, const char *name, enum read_mode mode)
+#ifdef CONFIG_HISI_SPI_BLOCK_PROTECT
+static void spi_lock_update_address(struct spi_nor *nor, const struct flash_info *info)
+{
+	unsigned int lock_level_max, sectorsize, chipsize;
+
+	if (!nor->level) {
+		nor->end_addr = 0;
+		dev_warn(nor->dev, "all blocks is unlocked.\n");
+		return;
+	}
+
+	sectorsize = info->sector_size;
+	chipsize = sectorsize * info->n_sectors;
+	lock_level_max = nor->lock_level_max;
+
+	switch (JEDEC_MFR(info)) {
+	case SNOR_MFR_MACRONIX:
+		if (chipsize == _2M) {
+			if ((nor->level != lock_level_max)
+					&& (nor->level != 1))
+				nor->end_addr = chipsize - (sectorsize <<
+					(lock_level_max - nor->level - 1));
+			else
+				nor->end_addr = chipsize;
+			return;
+		}
+
+		if (chipsize != _8M)
+			break;
+	case SNOR_MFR_ESMT:
+		/* this case is for ESMT and MXIC 8M devices */
+		if (nor->level != lock_level_max)
+			nor->end_addr = chipsize - (sectorsize
+					<< (lock_level_max - nor->level));
+		else
+			nor->end_addr = chipsize;
+		return;
+	case SNOR_MFR_EON:
+		if (nor->level != lock_level_max)
+			nor->end_addr = chipsize - (sectorsize
+					<< (nor->level - 1));
+		else
+			nor->end_addr = chipsize;
+		return;
+	default:
+		break;
+	}
+
+	/* general case */
+	nor->end_addr = chipsize >> (lock_level_max - nor->level);
+}
+
+static unsigned char hisi_bp_to_level(struct spi_nor *nor,
+		const struct flash_info *info, unsigned int bp_num)
+{
+	int ret;
+	unsigned char val;
+	unsigned char level;
+	unsigned int chipsize;
+
+	ret = spi_nor_wait_till_ready(nor);
+	BUG_ON(ret);
+
+	ret = nor->read_reg(nor, SPINOR_OP_RDSR, &val, 1);
+	if (ret < 0) {
+		dev_err(nor->dev, "error %d reading SR\n", ret);
+		return ret;
+	}
+
+	if (bp_num == BP_NUM_3)
+		level = (val & SPI_NOR_SR_BP_MASK_3) >> SPI_NOR_SR_BP0_SHIFT;
+	else
+		level = (val & SPI_NOR_SR_BP_MASK_4) >> SPI_NOR_SR_BP0_SHIFT;
+
+	/* dev_info(nor->dev, "the current level[%d]\n", level); */
+
+	if (bp_num == BP_NUM_4) {
+		nor->lock_level_max = LOCK_LEVEL_MAX(bp_num) - 5;
+		chipsize = info->sector_size * info->n_sectors;
+		if ((JEDEC_MFR(info) == SNOR_MFR_MACRONIX)
+				&& (chipsize == _16M))
+			nor->lock_level_max--;
+	} else
+		nor->lock_level_max = LOCK_LEVEL_MAX(bp_num);
+	/* dev_info(nor->dev, "Get the max bp level: [%d]\n",
+	*   nor->lock_level_max); */
+
+	return level;
+}
+
+static void hisi_get_spi_lock_info(struct spi_nor *nor, const struct flash_info *info)
+{
+	unsigned int chipsize;
+	struct device *dev = nor->dev;
+
+	chipsize = info->sector_size * info->n_sectors;
+
+	/* read the BP bit in RDSR to check whether nor is lock or not */
+	switch (JEDEC_MFR(info)) {
+	case SNOR_MFR_GD:
+	case SNOR_MFR_ESMT:
+	case SNOR_MFR_EON:
+	case SNOR_MFR_SPANSION:
+		/* BP bit convert to lock level */
+		nor->level = hisi_bp_to_level(nor, info, BP_NUM_3);
+		break;
+	case SNOR_MFR_WINBOND:
+		/* BP bit convert to lock level */
+		if (chipsize <= _16M)
+			nor->level = hisi_bp_to_level(nor, info, BP_NUM_3);
+		else
+			nor->level = hisi_bp_to_level(nor, info, BP_NUM_4);
+		break;
+	case SNOR_MFR_MACRONIX:
+		/* BP bit convert to lock level */
+		if (chipsize <= _8M)
+			nor->level = hisi_bp_to_level(nor, info, BP_NUM_3);
+		else
+			nor->level = hisi_bp_to_level(nor, info, BP_NUM_4);
+		break;
+	default:
+		goto usage;
+	}
+
+	spi_lock_update_address(nor, info);
+	if (nor->end_addr)
+		dev_info(dev, "Address range [0 => %#x] is locked.\n",
+		nor->end_addr);
+	return;
+usage:
+	dev_err(dev, "The ID: %#x isn't in the BP table,"
+			" Current device can't not protect\n",
+			JEDEC_MFR(info));
+}
+#endif/* CONFIG_HISI_SPI_BLOCK_PROTECT */
+
+static int spi_nor_midx2proto(int midx, enum spi_nor_protocol *proto)
+{
+	switch (midx) {
+	case SNOR_MIDX_SLOW:
+	case SNOR_MIDX_1_1_1:
+		*proto = SNOR_PROTO_1_1_1;
+		break;
+
+	case SNOR_MIDX_1_1_2:
+		*proto = SNOR_PROTO_1_1_2;
+		break;
+
+	case SNOR_MIDX_1_2_2:
+		*proto = SNOR_PROTO_1_2_2;
+		break;
+	case SNOR_MIDX_1_1_4:
+		*proto = SNOR_PROTO_1_1_4;
+		break;
+
+	case SNOR_MIDX_1_4_4:
+		*proto = SNOR_PROTO_1_4_4;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int spi_nor_sr3_to_reset(struct spi_nor *nor)
+{
+	int ret;
+	unsigned char val;
+
+	ret = nor->read_reg(nor, SPINOR_OP_RDSR3, &val, 1);
+	if (ret < 0) {
+		dev_err(nor->dev, "error %d reading Status Reg 3.\n", ret);
+		return ret;
+	}
+
+	if (SPI_NOR_GET_RST(val)) {
+		dev_dbg(nor->dev, "Device has worked on RESET#.\n");
+		return 0;
+	}
+
+	dev_dbg(nor->dev, "Start to enable RESET# function.\n");
+	val = SPI_NOR_SET_RST(val);
+
+	nor->write_reg(nor, SPINOR_OP_WRSR3, &val, 1);
+	if (ret < 0) {
+		dev_err(nor->dev, "error while writing Status Reg 3.\n");
+		return ret;
+	}
+
+	dev_dbg(nor->dev, "Enable RESET# function success.\n");
+
+	return 0;
+}
+
+static int spi_nor_reset_pin_enable(struct spi_nor *nor,
+		const struct flash_info *info)
+{
+	switch (JEDEC_MFR(info)) {
+	case SNOR_MFR_WINBOND:
+	case SNOR_MFR_GD:
+		return spi_nor_sr3_to_reset(nor);
+	default:
+		return 0;
+	}
+}
+
+static int spi_nor_setup(struct spi_nor *nor, const struct flash_info *info,
+			 const struct spi_nor_basic_flash_parameter *params,
+			 const struct spi_nor_modes *modes)
+{
+	bool enable_quad_io;
+	u32 rd_modes, wr_modes;
+	const struct spi_nor_erase_type *erase_type;
+	const struct spi_nor_read_op *read;
+	int rd_midx, wr_midx, err = 0;
+
+	rd_modes = modes->rd_modes;
+	wr_modes = modes->wr_modes;
+
+	/* Setup read operation. */
+	rd_midx = fls(params->rd_modes & rd_modes) - 1;
+	if (spi_nor_midx2proto(rd_midx, &nor->read_proto)) {
+		dev_err(nor->dev, "invalid (fast) read\n");
+		return -EINVAL;
+	}
+	read = &params->reads[rd_midx];
+	nor->read_opcode = read->opcode;
+	nor->read_dummy = read->num_mode_clocks + read->num_wait_states;
+
+	/* Set page program op code and protocol. */
+	wr_midx = fls(params->wr_modes & wr_modes) - 1;
+	if (spi_nor_midx2proto(wr_midx, &nor->write_proto)) {
+		dev_err(nor->dev, "invalid page program\n");
+		return -EINVAL;
+	}
+	nor->program_opcode = params->page_programs[wr_midx];
+
+	/* Set sector erase op code and size. */
+	erase_type = &params->erase_types[0];
+#ifdef CONFIG_MTD_SPI_NOR_USE_4K_SECTORS
+	for (i = 1; i < SNOR_MAX_ERASE_TYPES; ++i)
+		if (params->erase_types[i].size == 0x0c)
+			erase_type = &params->erase_types[i];
+#endif
+	nor->erase_opcode = erase_type->opcode;
+	nor->mtd.erasesize = (1 << erase_type->size);
+
+	enable_quad_io = (SNOR_PROTO_DATA_FROM_PROTO(nor->read_proto) == 4 ||
+			  SNOR_PROTO_DATA_FROM_PROTO(nor->write_proto) == 4);
+
+	/* Enable Quad I/O if needed. */
+	if (enable_quad_io && params->enable_quad_io) {
+		err = params->enable_quad_io(nor);
+		if (err) {
+			dev_err(nor->dev,
+				"failed to enable the Quad I/O mode\n");
+			return err;
+		}
+	}
+
+	/*
+	 * Fix erase protocol if needed, read and write protocols should
+	 * already be valid.
+	 */
+	nor->erase_proto = SNOR_PROTO_1_1_1;
+
+	dev_dbg(nor->dev,
+		"(Fast) Read:  opcode=%02Xh, protocol=%03x, mode=%u, wait=%u\n",
+		nor->read_opcode, nor->read_proto,
+		read->num_mode_clocks, read->num_wait_states);
+	dev_dbg(nor->dev,
+		"Page Program: opcode=%02Xh, protocol=%03x\n",
+		nor->program_opcode, nor->write_proto);
+	dev_dbg(nor->dev,
+		"Sector Erase: opcode=%02Xh, protocol=%03x, sector size=%zu\n",
+		nor->erase_opcode, nor->erase_proto, nor->mtd.erasesize);
+
+	return 0;
+}
+
+static int spi_nor_config(struct spi_nor *nor, const struct flash_info *info,
+			 const struct spi_nor_basic_flash_parameter *params,
+			 struct spi_nor_modes *modes)
+{
+	int ret;
+
+	if (params) {
+		ret = spi_nor_setup(nor, info, params, modes);
+		if (ret)
+			return ret;
+	} else if (modes->rd_modes & SNOR_MODE_1_1_4 &&
+				info->flags & SPI_NOR_QUAD_READ) {
+		/*
+		 * This branch is spcially for some devices which can
+		 * not be stated by params, but only SPI_NOR_QUAD_READ,
+		 * it just supports the protocol 1_1_4.
+		 */
+			if (spi_nor_wait_till_ready(nor))
+				return 1;
+
+			ret = set_quad_mode(nor, info);
+			if (ret) {
+				dev_err(nor->dev, "quad mode not supported\n");
+				return ret;
+			}
+			nor->read_proto = SNOR_PROTO_1_1_4;
+			nor->read_opcode = SPINOR_OP_READ_1_1_4;
+			nor->read_dummy = 8;
+	} else if (modes->rd_modes & SNOR_MODE_1_1_2 &&
+			info->flags & SPI_NOR_DUAL_READ) {
+		/*
+		 * This branch is spcially for some devices which can
+		 * not be stated by params, but only SPI_NOR_DUAL_READ,
+		 * it just supports the protocol 1_1_2.
+		 */
+			nor->read_proto = SNOR_PROTO_1_1_2;
+			nor->read_opcode = SPINOR_OP_READ_1_1_2;
+			nor->read_dummy = 8;
+	} else {
+		if (modes->rd_modes & SNOR_MODE_1_1_1) {
+			nor->read_opcode = SPINOR_OP_READ_FAST;
+			nor->read_dummy = 8;
+		} else {
+			nor->read_opcode = SPINOR_OP_READ;
+			nor->read_dummy = 0;
+		}
+	}
+
+	if (!(modes->rd_modes & (SNOR_MODE_1_1_4 | SNOR_MODE_1_4_4))) {
+		ret = spi_nor_reset_pin_enable(nor, info);
+		if (ret < 0) {
+			dev_err(nor->dev, "Enable RESET# fail.\n");
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+int spi_nor_scan(struct spi_nor *nor, const char *name,
+		 struct spi_nor_modes *modes)
 {
+	const struct spi_nor_basic_flash_parameter *params = NULL;
 	const struct flash_info *info = NULL;
 	struct device *dev = nor->dev;
 	struct mtd_info *mtd = &nor->mtd;
@@ -1320,6 +2108,11 @@ int spi_nor_scan(struct spi_nor *nor, const char *name, enum read_mode mode)
 	if (ret)
 		return ret;
 
+	/* Reset SPI protocol for all commands */
+	nor->erase_proto = SNOR_PROTO_1_1_1;
+	nor->read_proto = SNOR_PROTO_1_1_1;
+	nor->write_proto = SNOR_PROTO_1_1_1;
+
 	if (name)
 		info = spi_nor_match_id(name);
 	/* Try to auto-detect if chip name wasn't specified or not found */
@@ -1351,9 +2144,15 @@ int spi_nor_scan(struct spi_nor *nor, const char *name, enum read_mode mode)
 			info = jinfo;
 		}
 	}
+	if (info->params)
+		params = info->params;
 
 	mutex_init(&nor->lock);
 
+#ifdef CONFIG_HISI_SPI_BLOCK_PROTECT
+	/* NOR block protection support */
+	hisi_get_spi_lock_info(nor, info);
+#else
 	/*
 	 * Atmel, SST, Intel/Numonyx, and others serial NOR tend to power up
 	 * with the software protection bits set
@@ -1367,6 +2166,7 @@ int spi_nor_scan(struct spi_nor *nor, const char *name, enum read_mode mode)
 		write_sr(nor, 0);
 		spi_nor_wait_till_ready(nor);
 	}
+#endif
 
 	if (!mtd->name)
 		mtd->name = dev_name(dev);
@@ -1380,7 +2180,8 @@ int spi_nor_scan(struct spi_nor *nor, const char *name, enum read_mode mode)
 
 	/* NOR protection support for STmicro/Micron chips and similar */
 	if (JEDEC_MFR(info) == SNOR_MFR_MICRON ||
-			info->flags & SPI_NOR_HAS_LOCK) {
+	    JEDEC_MFR(info) == SNOR_MFR_WINBOND ||
+		info->flags & SPI_NOR_HAS_LOCK) {
 		nor->flash_lock = stm_lock;
 		nor->flash_unlock = stm_unlock;
 		nor->flash_is_locked = stm_is_locked;
@@ -1428,77 +2229,40 @@ int spi_nor_scan(struct spi_nor *nor, const char *name, enum read_mode mode)
 	if (np) {
 		/* If we were instantiated by DT, use it */
 		if (of_property_read_bool(np, "m25p,fast-read"))
-			nor->flash_read = SPI_NOR_FAST;
+			modes->rd_modes |= SNOR_MODE_1_1_1;
 		else
-			nor->flash_read = SPI_NOR_NORMAL;
+			modes->rd_modes &= ~SNOR_MODE_1_1_1;
 	} else {
 		/* If we weren't instantiated by DT, default to fast-read */
-		nor->flash_read = SPI_NOR_FAST;
+		modes->rd_modes |= SNOR_MODE_1_1_1;
 	}
 
 	/* Some devices cannot do fast-read, no matter what DT tells us */
 	if (info->flags & SPI_NOR_NO_FR)
-		nor->flash_read = SPI_NOR_NORMAL;
-
-	/* Quad/Dual-read mode takes precedence over fast/normal */
-	if (mode == SPI_NOR_QUAD && info->flags & SPI_NOR_QUAD_READ) {
-		ret = set_quad_mode(nor, info);
-		if (ret) {
-			dev_err(dev, "quad mode not supported\n");
-			return ret;
-		}
-		nor->flash_read = SPI_NOR_QUAD;
-	} else if (mode == SPI_NOR_DUAL && info->flags & SPI_NOR_DUAL_READ) {
-		nor->flash_read = SPI_NOR_DUAL;
-	}
-
-	/* Default commands */
-	switch (nor->flash_read) {
-	case SPI_NOR_QUAD:
-		nor->read_opcode = SPINOR_OP_READ_1_1_4;
-		break;
-	case SPI_NOR_DUAL:
-		nor->read_opcode = SPINOR_OP_READ_1_1_2;
-		break;
-	case SPI_NOR_FAST:
-		nor->read_opcode = SPINOR_OP_READ_FAST;
-		break;
-	case SPI_NOR_NORMAL:
-		nor->read_opcode = SPINOR_OP_READ;
-		break;
-	default:
-		dev_err(dev, "No Read opcode defined\n");
-		return -EINVAL;
-	}
+		modes->rd_modes &= ~SNOR_MODE_1_1_1;
 
 	nor->program_opcode = SPINOR_OP_PP;
 
+	/*
+	 * Configure the SPI memory:
+	 * - select op codes for (Fast) Read, Page Program and Sector Erase.
+	 * - set the number of dummy cycles (mode cycles + wait states).
+	 * - set the SPI protocols for register and memory accesses.
+	 * - set the Quad Enable bit if needed (required by SPI x-y-4 protos).
+	 */
+	ret = spi_nor_config(nor, info, params, modes);
+	if (ret)
+		return ret;
+
 	if (info->addr_width)
 		nor->addr_width = info->addr_width;
 	else if (mtd->size > 0x1000000) {
 		/* enable 4-byte addressing if the device exceeds 16MiB */
 		nor->addr_width = 4;
-		if (JEDEC_MFR(info) == SNOR_MFR_SPANSION) {
-			/* Dedicated 4-byte command set */
-			switch (nor->flash_read) {
-			case SPI_NOR_QUAD:
-				nor->read_opcode = SPINOR_OP_READ4_1_1_4;
-				break;
-			case SPI_NOR_DUAL:
-				nor->read_opcode = SPINOR_OP_READ4_1_1_2;
-				break;
-			case SPI_NOR_FAST:
-				nor->read_opcode = SPINOR_OP_READ4_FAST;
-				break;
-			case SPI_NOR_NORMAL:
-				nor->read_opcode = SPINOR_OP_READ4;
-				break;
-			}
-			nor->program_opcode = SPINOR_OP_PP_4B;
-			/* No small sector erase for 4-byte command set */
-			nor->erase_opcode = SPINOR_OP_SE_4B;
-			mtd->erasesize = info->sector_size;
-		} else
+		if (JEDEC_MFR(info) == SNOR_MFR_SPANSION ||
+		    info->flags & SPI_NOR_4B_OPCODES)
+			spi_nor_set_4byte_opcodes(nor, info);
+		else
 			set_4byte(nor, info, 1);
 	} else {
 		nor->addr_width = 3;
@@ -1510,8 +2274,6 @@ int spi_nor_scan(struct spi_nor *nor, const char *name, enum read_mode mode)
 		return -EINVAL;
 	}
 
-	nor->read_dummy = spi_nor_read_dummy_cycles(nor);
-
 	dev_info(dev, "%s (%lld Kbytes)\n", info->name,
 			(long long)mtd->size >> 10);
 
@@ -1547,6 +2309,64 @@ static const struct flash_info *spi_nor_match_id(const char *name)
 	return NULL;
 }
 
+/******************************************************************************/
+void spi_nor_driver_shutdown(struct spi_nor *nor)
+{
+	/* disable 4-byte addressing if the device exceeds 16MiB */
+	if (nor->addr_width == 4) {
+		const struct flash_info *info = NULL;
+
+		info = spi_nor_read_id(nor);
+		set_4byte(nor, info, 0);
+	}
+	return;
+}
+
+#ifdef CONFIG_PM
+/******************************************************************************/
+int spi_nor_suspend(struct spi_nor *nor, pm_message_t state)
+{
+	return spi_nor_wait_till_ready(nor);
+}
+
+/******************************************************************************/
+int spi_nor_resume(struct spi_nor *nor)
+{
+	int ret;
+	const struct flash_info *info = NULL;
+	const struct spi_nor_basic_flash_parameter *params = NULL;
+	struct spi_nor_modes modes = {
+		.rd_modes = SNOR_MODE_SLOW,
+		.wr_modes = SNOR_MODE_1_1_1,
+	};
+
+	modes.rd_modes |= SNOR_MODE_1_1_1
+			| SNOR_MODE_1_1_2
+			| SNOR_MODE_1_2_2;
+#ifndef CONFIG_CLOSE_SPI_8PIN_4IO
+	modes.rd_modes |= SNOR_MODE_1_1_4 | SNOR_MODE_1_4_4;
+	modes.wr_modes |= SNOR_MODE_1_1_4 | SNOR_MODE_1_4_4;
+#endif
+
+	if (!info)
+		info = spi_nor_read_id(nor);
+
+	/* Quad mode takes precedence over fast/normal */
+	if (info->params)
+		params = info->params;
+
+	ret = spi_nor_config(nor, info, params, &modes);
+	if (ret)
+		return ret;
+
+	/* enable 4-byte addressing if the device exceeds 16MiB */
+	if (nor->addr_width == 4 && JEDEC_MFR(info) != SNOR_MFR_SPANSION)
+		set_4byte(nor, info, 1);
+
+	return 0;
+}
+#endif /* End of CONFIG_PM */
+
 MODULE_LICENSE("GPL");
 MODULE_AUTHOR("Huang Shijie <shijie8@gmail.com>");
 MODULE_AUTHOR("Mike Lavender");
diff --git a/drivers/mtd/spi-nor/spi_ids.c b/drivers/mtd/spi-nor/spi_ids.c
new file mode 100644
index 0000000..de56dab
--- /dev/null
+++ b/drivers/mtd/spi-nor/spi_ids.c
@@ -0,0 +1,254 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <asm/setup.h>
+
+#include "spi_ids.h"
+
+#define SPI_DRV_VERSION       "1.22"
+/*****************************************************************************/
+
+#if 1
+#  define DBG_MSG(_fmt, arg...)
+#else
+#  define DBG_MSG(_fmt, arg...)   \
+	printk(KERN_DEBUG "%s(%d): " _fmt, __FILE__, __LINE__, ##arg);
+#endif
+
+#define DBG_BUG(fmt, args...) do {\
+	printk(KERN_DEBUG "%s(%d): BUG !!! " fmt, __FILE__, __LINE__, ##args); \
+	while (1)\
+		;\
+} while (0)
+
+/*****************************************************************************/
+static char *int_to_size(unsigned long long size)
+{
+	int ix;
+	static char buffer[20];
+	char *fmt[] = {"%u", "%uK", "%uM", "%uG", "%uT", "%uT"};
+
+	for (ix = 0; (ix < 5) && !(size & 0x3FF) && size; ix++)
+		size = (size >> 10);
+
+	sprintf(buffer, fmt[ix], size);
+	return buffer;
+}
+/*****************************************************************************/
+
+struct spi_info *spi_serach_ids(unsigned char ids[8])
+{
+	struct spi_info *info;
+	struct spi_info *fit_info = NULL;
+
+	for (info = spi_info_table; info->name; info++) {
+		if (memcmp(info->id, ids, info->id_len))
+			continue;
+
+		if ((fit_info == NULL) || (fit_info->id_len < info->id_len))
+			fit_info = info;
+	}
+	return fit_info;
+}
+/*****************************************************************************/
+
+void spi_search_rw(struct spi_info *spiinfo, struct spi_operation *spiop_rw,
+	unsigned int iftype, unsigned int max_dummy, int is_read)
+{
+	int ix = 0;
+	struct spi_operation **spiop, **fitspiop;
+
+	for (fitspiop = spiop = (is_read ? spiinfo->read : spiinfo->write);
+		(*spiop) && ix < MAX_SPI_OP; spiop++, ix++) {
+		DBG_MSG("dump[%d] %s iftype:0x%02X\n", ix,
+			(is_read ? "read" : "write"),
+			(*spiop)->iftype);
+
+		if (((*spiop)->iftype & iftype)
+			&& ((*spiop)->dummy <= max_dummy)
+			&& (*fitspiop)->iftype < (*spiop)->iftype) {
+			fitspiop = spiop;
+		}
+	}
+	memcpy(spiop_rw, (*fitspiop), sizeof(struct spi_operation));
+}
+/*****************************************************************************/
+#ifndef CONFIG_MTD_HISFC300
+void spi_get_erase(struct spi_info *spiinfo, struct spi_operation *spiop_erase)
+{
+	int ix;
+
+	spiop_erase->size = 0;
+	for (ix = 0; ix < MAX_SPI_OP; ix++) {
+		if (spiinfo->erase[ix] == NULL)
+			break;
+		if (spiinfo->erasesize == spiinfo->erase[ix]->size) {
+			memcpy(&spiop_erase[ix], spiinfo->erase[ix],
+			sizeof(struct spi_operation));
+
+			break;
+		}
+	}
+}
+#endif
+/*****************************************************************************/
+
+struct spi_tag {
+	char name[16];
+
+	unsigned char  id[8];
+	unsigned int   id_len;
+
+	unsigned long  chipsize;
+	unsigned int   erasesize;
+	unsigned int   addrcycle;
+
+	struct spi_operation read[MAX_SPI_OP];
+	struct spi_operation write[MAX_SPI_OP];
+	struct spi_operation erase[MAX_SPI_OP];
+};
+/*****************************************************************************/
+
+static int __init parse_spi_id(const struct tag *tag)
+{
+	int ix;
+	static struct spi_tag spitag[1];
+	struct spi_info *spiinfo = spi_info_table;
+
+	if (tag->hdr.size < ((sizeof(struct tag_header) +
+					sizeof(struct spi_tag)) >> 2)) {
+		printk(KERN_ERR "%s(%d):tag->hdr.size(%d) too small.\n",
+			__func__, __LINE__, tag->hdr.size);
+		return 0;
+	}
+	memset(spiinfo, 0, sizeof(struct spi_info));
+	memcpy(spitag, &tag->u, sizeof(struct spi_tag));
+
+	spiinfo->name = spitag->name;
+
+	memcpy(spiinfo->id, spitag->id, 8);
+	spiinfo->id_len = spitag->id_len;
+
+	spiinfo->chipsize = spitag->chipsize;
+	spiinfo->erasesize = spitag->erasesize;
+	spiinfo->addrcycle = spitag->addrcycle;
+
+	for (ix = 0; ix < MAX_SPI_OP; ix++) {
+		if (spitag->read[ix].iftype)
+			spiinfo->read[ix] = &spitag->read[ix];
+	}
+	for (ix = 0; ix < MAX_SPI_OP; ix++) {
+		if (spitag->write[ix].iftype)
+			spiinfo->write[ix] = &spitag->write[ix];
+	}
+	for (ix = 0; ix < MAX_SPI_OP; ix++) {
+		if (spitag->erase[ix].iftype)
+			spiinfo->erase[ix] = &spitag->erase[ix];
+	}
+
+	printk(KERN_NOTICE "SPI TAG: hdr.tag: 0x%08X, hdr.size: %d\n",
+		tag->hdr.tag, tag->hdr.size);
+	printk(KERN_NOTICE "(%dByte): 0x%02X 0x%02X 0x%02X 0x%02X "
+			"0x%02X 0x%02X 0x%02X 0x%02X\n",
+		spitag->id_len,
+		spitag->id[0], spitag->id[1], spitag->id[2], spitag->id[3],
+		spitag->id[4], spitag->id[5], spitag->id[6], spitag->id[7]);
+	printk(KERN_NOTICE "Block:%sB ",     int_to_size(spitag->erasesize));
+	printk(KERN_NOTICE "Chip:%sB ",      int_to_size(spitag->chipsize));
+	printk(KERN_NOTICE "AddrCycle:%d ",  spitag->addrcycle);
+	printk(KERN_NOTICE "Name:(%s)",      spitag->name);
+	printk(KERN_NOTICE "\n");
+	for (ix = 0; ix < MAX_SPI_OP; ix++) {
+		if (spitag->read[ix].iftype) {
+			printk(KERN_NOTICE "R %d: ", ix + 1);
+			printk(KERN_NOTICE "IF Type:0x%02X ",
+					spitag->read[ix].iftype);
+			printk(KERN_NOTICE "CMD:0x%02X ",
+					spitag->read[ix].cmd);
+			printk(KERN_NOTICE "Dummy:%d ",
+					spitag->read[ix].dummy);
+			if (spitag->read[ix].size == INFINITE)
+				printk(KERN_NOTICE "Size:-1      ");
+			else
+				printk(KERN_NOTICE "Size:%6sB ",
+					int_to_size(spitag->read[ix].size));
+			printk(KERN_NOTICE "Clock:%dMHz ",
+					spitag->read[ix].clock);
+			printk(KERN_NOTICE "\n");
+		}
+	}
+	for (ix = 0; ix < MAX_SPI_OP; ix++) {
+		if (spitag->write[ix].iftype) {
+			printk(KERN_NOTICE "W %d: ", ix + 1);
+			printk(KERN_NOTICE "IF Type:0x%02X ",
+					spitag->write[ix].iftype);
+			printk(KERN_NOTICE "CMD:0x%02X ",
+					spitag->write[ix].cmd);
+			printk(KERN_NOTICE "Dummy:%d ",
+					spitag->write[ix].dummy);
+			printk(KERN_NOTICE "Size:%6sB ",
+					int_to_size(spitag->write[ix].size));
+			printk(KERN_NOTICE "Clock:%dMHz ",
+					spitag->write[ix].clock);
+			printk(KERN_NOTICE "\n");
+		}
+	}
+	for (ix = 0; ix < MAX_SPI_OP; ix++) {
+		if (spitag->erase[ix].iftype) {
+			printk(KERN_NOTICE "E %d: ", ix + 1);
+			printk(KERN_NOTICE "IF Type:0x%02X ",
+					spitag->erase[ix].iftype);
+			printk(KERN_NOTICE "CMD:0x%02X ",
+					spitag->erase[ix].cmd);
+			printk(KERN_NOTICE "Dummy:%d ",
+					spitag->erase[ix].dummy);
+			printk(KERN_NOTICE "Size:0x%02X ",
+					spitag->erase[ix].size);
+			printk(KERN_NOTICE "Clock:%dMHz ",
+					spitag->erase[ix].clock);
+			printk(KERN_NOTICE "\n");
+		}
+	}
+
+	return 0;
+}
+
+/* turn to ascii is "S_ID" */
+__tagtable(0x535F4944, parse_spi_id);
+/*****************************************************************************/
+
+static int __init spi_ids_init(void)
+{
+	printk(KERN_INFO "Spi id table Version %s\n", SPI_DRV_VERSION);
+	return 0;
+}
+/*****************************************************************************/
+
+static void __exit spi_ids_exit(void)
+{
+}
+/*****************************************************************************/
+
+module_init(spi_ids_init);
+module_exit(spi_ids_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Spi id table");
diff --git a/drivers/mtd/spi-nor/spi_ids.h b/drivers/mtd/spi-nor/spi_ids.h
new file mode 100644
index 0000000..89fd8d9
--- /dev/null
+++ b/drivers/mtd/spi-nor/spi_ids.h
@@ -0,0 +1,171 @@
+/*
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef SPI_IDSH
+#define SPI_IDSH
+
+/*****************************************************************************/
+
+#define _1K		(0x400)
+#define _2K		(0x800)
+
+#define _4K		(0x1000)
+#define _8K		(0x2000)
+#define _16K		(0x4000)
+#define _32K		(0x8000)
+
+#define _64K		(0x10000)
+#define _128K		(0x20000)
+#define _256K		(0x40000)
+#define _512K		(0x80000)
+
+#define _1M		(0x100000)
+#define _2M		(0x200000)
+#define _4M		(0x400000)
+#define _8M		(0x800000)
+
+#define _16M		(0x1000000)
+#define _32M		(0x2000000)
+#define _64M		(0x4000000)
+
+#define INFINITE	(0xFFFFFFFF)
+/*****************************************************************************/
+
+#define SPI_IF_READ_STD			(0x01)
+#define SPI_IF_READ_FAST		(0x02)
+#define SPI_IF_READ_DUAL		(0x04)
+#define SPI_IF_READ_DUAL_ADDR		(0x08)
+#define SPI_IF_READ_QUAD		(0x10)
+#define SPI_IF_READ_QUAD_ADDR		(0x20)
+
+#define SPI_IF_WRITE_STD		(0x01)
+#define SPI_IF_WRITE_DUAL		(0x02)
+#define SPI_IF_WRITE_DUAL_ADDR		(0x04)
+#define SPI_IF_WRITE_QUAD		(0x08)
+#define SPI_IF_WRITE_QUAD_ADDR		(0x10)
+
+#define SPI_IF_ERASE_SECTOR		(0x01)	/* sector erase, 64K */
+#define SPI_IF_ERASE_CHIP		(0x02)	/* chip erase */
+#define SPI_IF_ERASE_4K			(0x04)	/* 4K */
+#define SPI_IF_ERASE_8K			(0x08)	/* 8K */
+
+#define SPI_IF_ERASE_SECTOR_4K		(0x01)	/* 4K */
+#define SPI_IF_ERASE_SECTOR_32K		(0x02)	/* 32K */
+#define SPI_IF_ERASE_SECTOR_64K		(0x04)	/* 64K */
+#define SPI_IF_ERASE_SECTOR_128K	(0x08)  /* 128K */
+#define SPI_IF_ERASE_SECTOR_256K	(0x10)  /* 256K */
+/*****************************************************************************/
+#define SPI_CMD_BRWR           (0x17)  /*write value to BAR*/
+#define SPI_EN4B_VALUE         (0x80)  /*the enable 4Byte addr len value*/
+#define SPI_EX4B_VALUE         (0x00)  /*the disable 4Byte addr len value*/
+#define SPI_4BYTE_ADDR_LEN     (4)     /*address len 4Byte*/
+/*****************************************************************************/
+
+#define SPI_CMD_WREN			0x06   /* Write Enable */
+#define SPI_CMD_WRDI			0x04   /* Write Disable */
+/*****************************************************************************/
+#define SPI_CMD_SE_4K			0x20	/* 4KB sector Erase */
+#define SPI_CMD_SE_32K			0x52	/* 32KB sector Erase */
+
+#define SPI_CMD_SE_64K			0xD8	/* 64KB sector Erase */
+#define SPI_CMD_SE_128K			0xD8   /* 128KB sector Erase */
+#define SPI_CMD_SE_256K			0xD8	/* 256KB sector Erase */
+
+#define SPI_CMD_SE			0xD8	/* 64KB Sector Erase */
+#define SPI_CMD_BE			0xC7	/* chip erase */
+/*****************************************************************************/
+#define SPI_CMD_WRSR			0x01	/* Write Status Register */
+#define SPI_CMD_WRSR2			0x31	/* Write Status Register-2 */
+#define SPI_CMD_WRSR3			0x11	/* Write Status Register-3 */
+
+#define SPI_CMD_RDSR			0x05	/* Read Status Register */
+#define SPI_CMD_RDSR2			0x35	/* Read Status Register-2 */
+#define SPI_CMD_RDSR3			0x15	/* Read Status Register-3 */
+
+#define SPI_CMD_RDCR			0x35	/* Read Config Register */
+
+#define SPI_CMD_RDID			0x9F	/* Read Identification */
+/*****************************************************************************/
+#define SPI_CMD_PP			0x02	/* Page Programming */
+#define SPI_CMD_WRITE_DUAL		0xA2	/* fast program dual input */
+#define SPI_CMD_WRITE_QUAD		0x32	/* fast program quad input */
+#define SPI_CMD_WRITE_DUAL_ADDR	0xD2	/* Dual I/O High Performance Write */
+#define SPI_CMD_WRITE_QUAD_ADDR	0x38	/* Quad I/O High Performance Write */
+/* #define SPI_CMD_WRITE_QUAD_ADDR	0x12	Quad I/O High Performance Write */
+/*****************************************************************************/
+#define SPI_CMD_READ			0x03	/* Read Data bytes */
+#define SPI_CMD_FAST_READ	0x0B	/* Read Data Bytes at Higher Speed */
+#define SPI_CMD_READ_DUAL		0x3B	/* fast read dual output */
+#define SPI_CMD_READ_QUAD		0x6B	/* fast read quad output */
+#define SPI_CMD_READ_DUAL_ADDR	0xBB	/* Dual I/O High Performance Read */
+#define SPI_CMD_READ_QUAD_ADDR	0xEB	/* Quad I/O High Performance Read */
+/*****************************************************************************/
+#define SPI_CMD_SR_WIP			1	/* Write in Progress */
+#define SPI_CMD_SR_WEL			2	/* Write Enable Latch */
+
+#define SPI_CMD_SR_QE			(1 << 9)	/* quad enable */
+#define SPI_CMD_SR_XQE			(0 << 9)	/* quad disable */
+/*****************************************************************************/
+#define SPI_CMD_EN4B			0xB7	/* enter to 4 bytes mode and
+							set 4 byte bit as '1' */
+#define SPI_CMD_EX4B			0xE9	/* exit 4 bytes mode and
+						clear 4 byte bit as '0' */
+
+/*****************************************************************************/
+
+struct spi_operation {
+	unsigned char	iftype;
+	unsigned char	cmd;
+	unsigned char	dummy;
+	unsigned int	size;
+	unsigned int	clock;
+};
+
+struct spi_info {
+	char *name;
+
+	unsigned char	id[8];
+	unsigned int	id_len;
+
+	unsigned long	chipsize;
+	unsigned int	erasesize;
+	unsigned int	addrcycle;
+
+#define MAX_SPI_OP                       (8)
+	struct spi_operation *read[8];
+	struct spi_operation *write[8];
+	struct spi_operation *erase[8];
+#ifndef CONFIG_MTD_HISFC300
+	struct spi_driver *driver;
+#endif
+};
+/*****************************************************************************/
+
+struct spi_info *spi_serach_ids(unsigned char ids[8]);
+
+void spi_search_rw(struct spi_info *spiinfo, struct spi_operation *spiop_rw,
+		unsigned int iftype, unsigned int max_dummy, int is_read);
+
+#ifndef CONFIG_MTD_HISFC300
+void spi_get_erase(struct spi_info *spiinfo, struct spi_operation *spiop_erase);
+#endif
+/******************************************************************************/
+
+extern struct spi_info spi_info_table[];
+/******************************************************************************/
+#endif /* SPI_IDSH */
diff --git a/drivers/net/ethernet/hisilicon/Kconfig b/drivers/net/ethernet/hisilicon/Kconfig
index d11287e..59133db 100644
--- a/drivers/net/ethernet/hisilicon/Kconfig
+++ b/drivers/net/ethernet/hisilicon/Kconfig
@@ -76,4 +76,6 @@ config HNS_ENET
 	  This selects the general ethernet driver for HNS.  This module make
 	  use of any HNS AE driver, such as HNS_DSAF
 
+source "drivers/net/ethernet/hisilicon/higmac/Kconfig"
+
 endif # NET_VENDOR_HISILICON
diff --git a/drivers/net/ethernet/hisilicon/Makefile b/drivers/net/ethernet/hisilicon/Makefile
index 8661695..44e0c6b 100644
--- a/drivers/net/ethernet/hisilicon/Makefile
+++ b/drivers/net/ethernet/hisilicon/Makefile
@@ -6,4 +6,5 @@ obj-$(CONFIG_HIX5HD2_GMAC) += hix5hd2_gmac.o
 obj-$(CONFIG_HIP04_ETH) += hip04_eth.o
 obj-$(CONFIG_HNS_MDIO) += hns_mdio.o
 obj-$(CONFIG_HNS) += hns/
-obj-$(CONFIG_HISI_FEMAC) += hisi_femac.o
+obj-$(CONFIG_HISI_FEMAC) += hisi-femac/
+obj-$(CONFIG_HIETH_GMAC) += higmac/
diff --git a/drivers/net/ethernet/hisilicon/higmac/Kconfig b/drivers/net/ethernet/hisilicon/higmac/Kconfig
new file mode 100644
index 0000000..bda6f74
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/Kconfig
@@ -0,0 +1,96 @@
+#
+# higmac family network device configuration
+#
+
+menuconfig HIETH_GMAC
+	tristate "hieth gmac family network device support"
+	select PHYLIB
+	select RESET_CONTROLLER
+	help
+	  This selects the hieth gmac family network device.
+	  The gigabit switch fabric (GSF) receives and transmits data over Ethernet
+	  ports at 10/100/1000 Mbit/s in full-duplex or half-duplex mode.
+	  The Ethernet port exchanges data with the CPU port, and supports
+	  the energy efficient Ethernet (EEE) and wake on LAN (WoL) functions.
+
+if HIETH_GMAC
+
+config HIGMAC_DESC_4WORD
+        bool "higmac descriptor size is 4 words"
+        default y
+        help
+	  This define the size of higmac descriptor structure.
+	  In the newest version, descriptor size is 4 words.
+	  But in some old version, the size is 8 words.
+	  The default value is true.
+
+config HIGMAC_RXCSUM
+        bool "higmac Receive checksumming offload supported"
+        default y
+        help
+	  This indicate MAC support Receive checksumming offload.
+	  Support IPv4 and IPv6, tcp and udp.
+	  The default value is enabled.
+	  If old version MAC does not support, disable this option please.
+
+config RX_FLOW_CTRL_SUPPORT
+	bool "rx flow ctrl supported"
+	default y
+	help
+	  Rx flow ctrl supported, default is enabled.
+	  When we received pause frame,
+	  we will stop transmiting data frame for some time.
+	  The stopping time is the time filled in pause frame.
+
+config TX_FLOW_CTRL_SUPPORT
+	bool "tx flow ctrl supported"
+	default y
+	help
+	  Tx flow ctrl supported, default is enabled.
+	  When we has no buffer to receive packet,
+	  we will send pause frame.
+	  When buffer is available, we will send zero-quanta pause frame.
+
+config TX_FLOW_CTRL_PAUSE_TIME
+	hex "tx flow ctrl pause time"
+	default "0xFFFF"
+	help
+	  The pause time filled in the sending pause frame.
+	  The unit is the time for transmiting 512 bit data.
+	  This value is 16 bit, so its value is 0x0000~0xFFFF.
+	  The default value is 0xFFFF.
+
+config TX_FLOW_CTRL_PAUSE_INTERVAL
+	hex "tx flow ctrl pause interval"
+	default "0xFFFF"
+	help
+	  The interval time for sending pause frame.
+	  When the remainint amount of receive queue is below tx flow ctrl active threshold,
+	  we will wait this time to transmiting pause frame.
+	  The unit is the time for transmiting 512 bit data.
+	  This value is 16 bit, so its value is 0x0000~0xFFFF.
+	  The default value is 0xFFFF.
+
+config TX_FLOW_CTRL_ACTIVE_THRESHOLD
+	int "tx flow ctrl active threshold"
+	default "16"
+	range 1 127
+	help
+	  The threshold for activing tx flow ctrl.
+	  When the left amount of receive queue descriptors is below this threshold,
+	  hardware will send pause frame immediately.
+	  We advise this value is set smaller than 64. Too bigger is not a good choice.
+	  This value must be smaller than tx flow ctrl deactive threshold.
+
+config TX_FLOW_CTRL_DEACTIVE_THRESHOLD
+	int "tx flow ctrl deactive threshold"
+	default "32"
+	range 1 127
+	help
+	  The threshold for deactiving tx flow ctrl.
+	  When the left amount of receive queue descriptors is above or equal with this threshold,
+	  hardware will exit flow control state.
+	  We advise this value is set smaller than 64. Too bigger is not a good choice.
+	  This value must be larger than tx flow ctrl active threshold.
+
+endif # HIETH_GMAC
diff --git a/drivers/net/ethernet/hisilicon/higmac/Makefile b/drivers/net/ethernet/hisilicon/higmac/Makefile
new file mode 100644
index 0000000..e3d9c53
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/Makefile
@@ -0,0 +1,2 @@
+obj-$(CONFIG_HIETH_GMAC) += hieth-gmac.o
+hieth-gmac-objs := board.o higmac.o autoeee/autoeee.o autoeee/phy_id_table.o
diff --git a/drivers/net/ethernet/hisilicon/higmac/autoeee/autoeee.c b/drivers/net/ethernet/hisilicon/higmac/autoeee/autoeee.c
new file mode 100644
index 0000000..be12244
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/autoeee/autoeee.c
@@ -0,0 +1,125 @@
+#include <linux/phy.h>
+#include <linux/micrel_phy.h>
+#include "../higmac.h"
+#include "autoeee.h"
+
+void init_autoeee(struct higmac_netdev_local *ld)
+{
+	int phy_id = ld->phy->phy_id;
+	struct phy_info *phy_info;
+
+	if (ld->eee_init)
+		goto eee_init;
+
+	phy_info = phy_search_ids(phy_id);
+	if (phy_info) {
+		int eee_available, lp_eee_capable, v;
+		u32 link_stat = 0;
+
+		eee_available = phy_info->eee_available;
+		if (netif_msg_wol(ld))
+			pr_info("fit phy_id:0x%x, phy_name:%s, eee:%d\n",
+				phy_info->phy_id, phy_info->name,
+				eee_available);
+
+		if (!eee_available)
+			goto not_support;
+
+		if (eee_available == PHY_EEE) {
+			if (netif_msg_wol(ld))
+				pr_info("enter phy-EEE mode\n");
+
+			v = readl(ld->gmac_iobase + EEE_ENABLE);
+			v &= ~BIT_EEE_ENABLE;	/* disable auto-EEE */
+			writel(v, ld->gmac_iobase + EEE_ENABLE);
+			return;
+		}
+
+		ld->eee_init = phy_info->eee_init;
+eee_init:
+		switch (ld->phy->speed) {
+		case SPEED_10:
+			link_stat |= HIGMAC_SPD_10M;
+			break;
+		case SPEED_100:
+			link_stat |= HIGMAC_SPD_100M;
+			break;
+		case SPEED_1000:
+			link_stat |= HIGMAC_SPD_1000M;
+			break;
+		default:
+			break;
+		}
+
+		lp_eee_capable = ld->eee_init(ld->phy);
+		if (lp_eee_capable < 0)
+			return;
+
+		if (ld->phy->link) {
+			if (((u32)lp_eee_capable) & link_stat) {
+				if ((phy_id & REALTEK_PHY_MASK) ==
+				    REALTEK_PHY_ID_8211E) {
+					v = readl(ld->gmac_iobase + EEE_CLK);
+					v &= ~MASK_EEE_CLK;
+					v |= BIT_DISABLE_TX_CLK;
+					writel(v, ld->gmac_iobase + EEE_CLK);
+				} else if ((phy_id & MICREL_PHY_ID_MASK) ==
+					   PHY_ID_KSZ9031) {
+					v = readl(ld->gmac_iobase + EEE_CLK);
+					v &= ~MASK_EEE_CLK;
+					v |= (BIT_DISABLE_TX_CLK |
+						BIT_PHY_KSZ9031);
+					writel(v, ld->gmac_iobase + EEE_CLK);
+				}
+
+				/* EEE_1us: 0x7c for 125M */
+				writel(0x7c, ld->gmac_iobase +
+				       EEE_TIME_CLK_CNT);
+				writel(0x1e0400, ld->gmac_iobase +
+				       EEE_TIMER);/* FIXME */
+
+				v = readl(ld->gmac_iobase + EEE_LINK_STATUS);
+				v |= 0x3 << 1;	/* auto EEE and ... */
+				v |= BIT_PHY_LINK_STATUS;	/* phy linkup */
+				writel(v, ld->gmac_iobase + EEE_LINK_STATUS);
+
+				v = readl(ld->gmac_iobase + EEE_ENABLE);
+				v |= BIT_EEE_ENABLE;	/* enable EEE */
+				writel(v, ld->gmac_iobase + EEE_ENABLE);
+
+				if (netif_msg_wol(ld))
+					pr_info("enter auto-EEE mode\n");
+			} else {
+				if (netif_msg_wol(ld))
+					pr_info("link partner not support EEE\n");
+			}
+		} else {
+			v = readl(ld->gmac_iobase + EEE_LINK_STATUS);
+			v &= ~(BIT_PHY_LINK_STATUS);	/* phy linkdown */
+			writel(v, ld->gmac_iobase + EEE_LINK_STATUS);
+		}
+
+		return;
+	}
+
+not_support:
+	ld->eee_init = NULL;
+	if (netif_msg_wol(ld))
+		pr_info("non-EEE mode\n");
+}
+
+void eee_phy_linkdown(struct higmac_netdev_local *ld)
+{
+	int v = readl(ld->gmac_iobase + EEE_LINK_STATUS);
+	/* update phy link state */
+	v &= ~BIT_PHY_LINK_STATUS;
+	writel(v, ld->gmac_iobase + EEE_LINK_STATUS);
+}
+
+void eee_phy_linkup(struct higmac_netdev_local *ld)
+{
+	int v = readl(ld->gmac_iobase + EEE_LINK_STATUS);
+	/* update phy link state */
+	v |= BIT_PHY_LINK_STATUS;
+	writel(v, ld->gmac_iobase + EEE_LINK_STATUS);
+}
diff --git a/drivers/net/ethernet/hisilicon/higmac/autoeee/autoeee.h b/drivers/net/ethernet/hisilicon/higmac/autoeee/autoeee.h
new file mode 100644
index 0000000..8f75a7a
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/autoeee/autoeee.h
@@ -0,0 +1,42 @@
+#ifndef	_AUTO_EEE_H
+
+#define NO_EEE          0
+#define MAC_EEE         1
+#define PHY_EEE         2
+#define PARTNER_EEE     2
+
+struct phy_info {
+	char *name;
+	int phy_id;
+	char eee_available;	/* eee support by this phy */
+	int (*eee_init)(struct phy_device *phy_dev);
+};
+
+/* GMAC register definition */
+#define EEE_CLK			0x800
+#define MASK_EEE_CLK		(0x3 << 20)
+#define BIT_DISABLE_TX_CLK	BIT(21)
+#define BIT_PHY_KSZ9031		BIT(20)
+#define EEE_ENABLE		0x808
+#define BIT_EEE_ENABLE		BIT(0)
+#define EEE_TIMER		0x80C
+#define EEE_LINK_STATUS		0x810
+#define BIT_PHY_LINK_STATUS	BIT(0)
+#define EEE_TIME_CLK_CNT	0x814
+
+/* ----------------------------phy register-------------------------------*/
+/* MMD: MDIO Manageable Device */
+#define MACR		0x0D
+#define MAADR		0x0E
+#define EEE_DEV		0x3
+#define EEE_CAPABILITY	0x14
+#define	EEELPAR_DEV	0x7
+#define EEELPAR		0x3D	/* EEE link partner ability register */
+#define EEE_ADVERTISE	0x3c
+#define LP_1000BASE_EEE	BIT(2)
+#define LP_100BASE_EEE	BIT(1)
+
+struct phy_info *phy_search_ids(int phy_id);
+void init_autoeee(struct higmac_netdev_local *ld);
+
+#endif
diff --git a/drivers/net/ethernet/hisilicon/higmac/autoeee/phy_id_table.c b/drivers/net/ethernet/hisilicon/higmac/autoeee/phy_id_table.c
new file mode 100644
index 0000000..8ffaf2a
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/autoeee/phy_id_table.c
@@ -0,0 +1,177 @@
+#include <linux/delay.h>
+#include <linux/kernel.h>
+#include <linux/phy.h>
+#include "../higmac.h"
+#include "autoeee.h"
+
+struct phy_info phy_info_table[];
+
+struct phy_info *phy_search_ids(int phy_id)
+{
+	int i;
+	struct phy_info *fit_info = NULL;
+
+	for (i = 0; phy_info_table[i].name; i++) {
+		if (phy_id == phy_info_table[i].phy_id)
+			fit_info = &phy_info_table[i];
+	}
+
+	return fit_info;
+}
+
+static inline int phy_mmd_read(struct phy_device *phy_dev,
+			       u32 mmd_device, u32 regnum)
+{
+	phy_write(phy_dev, MACR, mmd_device);	/* function = 00 address */
+	phy_write(phy_dev, MAADR, regnum);
+	phy_write(phy_dev, MACR, 0x4000 | mmd_device);	/* function = 01 data */
+
+	return phy_read(phy_dev, MAADR);
+}
+
+static inline int phy_mmd_write(struct phy_device *phy_dev, u32 mmd_device,
+				u32 regnum, u16 val)
+{
+	phy_write(phy_dev, MACR, mmd_device);	/* function = 00 address */
+	phy_write(phy_dev, MAADR, regnum);
+	phy_write(phy_dev, MACR, 0x4000 | mmd_device);	/* function = 01 data */
+
+	return phy_write(phy_dev, MAADR, val);
+}
+
+static int smsc_lan8740_init(struct phy_device *phy_dev)
+{
+	static int first_time;
+	int v, eee_type = 0;
+
+	if (!first_time) {
+		/* Realtek LAN 8740 start to enable eee */
+		int eee_lan;
+
+		eee_lan = phy_read(phy_dev, 0x10);
+		if (eee_lan < 0)
+			return eee_lan;
+		eee_lan |= 0x4;
+		phy_write(phy_dev, 0x10, eee_lan);
+		eee_lan = phy_read(phy_dev, 0x10);
+		if (eee_lan < 0)
+			return eee_lan;
+		/* auto negotiate after enable eee */
+		eee_lan = phy_read(phy_dev, 0x0);
+		if (eee_lan < 0)
+			return eee_lan;
+		eee_lan |= 0x200;
+		phy_write(phy_dev, 0x0, eee_lan);
+		first_time = 1;
+	}
+
+	v = phy_mmd_read(phy_dev, EEELPAR_DEV, EEELPAR);
+
+	if (v & LP_1000BASE_EEE)
+		eee_type |= HIGMAC_SPD_1000M;
+	if (v & LP_100BASE_EEE)
+		eee_type |= HIGMAC_SPD_100M;
+
+	return eee_type;
+}
+
+#define RTL8211EG_MAC	0
+#if RTL8211EG_MAC
+static int rtl8211EG_mac_init(struct phy_device *phy_dev)
+{
+	static int first_time;
+	/* Realtek 8211EG start reset to change eee to mac */
+	int v, eee_type = 0;
+
+	if (!first_time) {
+		int tmp = 0;
+
+		phy_write(phy_dev, 0x1f, 0x0);
+		phy_write(phy_dev, MII_BMCR, BMCR_RESET);	/* reset phy */
+		do {		/* wait phy restart over */
+			udelay(1);
+			tmp = phy_read(phy_dev, MII_BMSR);
+			/* no need to wait AN finished */
+			tmp &= (BMSR_ANEGCOMPLETE | BMSR_ANEGCAPABLE);
+		} while (!tmp);
+
+		phy_write(phy_dev, 0x1f, 0x7);
+		phy_write(phy_dev, 0x1e, 0x20);
+		phy_write(phy_dev, 0x1b, 0xa03a);
+		phy_write(phy_dev, 0x1f, 0x0);
+
+		first_time = 1;
+	}
+
+	v = phy_mmd_read(phy_dev, EEELPAR_DEV, EEELPAR);
+
+	if (v & LP_1000BASE_EEE)
+		eee_type |= HIGMAC_SPD_1000M;
+	if (v & LP_100BASE_EEE)
+		eee_type |= HIGMAC_SPD_100M;
+
+	return eee_type;
+}
+#else
+static int rtl8211EG_init(struct phy_device *phy_dev)
+{
+	int eee_type = 0, v;
+
+	v = phy_mmd_read(phy_dev, EEELPAR_DEV, EEELPAR);
+
+	if (v & LP_1000BASE_EEE)
+		eee_type |= HIGMAC_SPD_1000M;
+	if (v & LP_100BASE_EEE)
+		eee_type |= HIGMAC_SPD_100M;
+
+	return eee_type;
+}
+#endif
+
+static int festa_v200_init(struct phy_device *phy_dev)
+{
+	static int first_time_init;
+	int v, eee_type = 0;
+
+	if (!first_time_init) {
+		/* EEE_CAPABILITY register: support 100M-BaseT */
+		v = phy_mmd_read(phy_dev, EEE_DEV, EEE_CAPABILITY);
+		phy_mmd_write(phy_dev, EEE_DEV, EEE_CAPABILITY,
+			      ((u32)v) | BIT(1));
+
+		/* EEE_ADVERTISEMENT register: advertising 100M-BaseT */
+		v = phy_mmd_read(phy_dev, EEELPAR_DEV, EEE_ADVERTISE);
+		phy_mmd_write(phy_dev, EEELPAR_DEV, EEE_ADVERTISE,
+			      ((u32)v) | BIT(1));
+
+		v = phy_read(phy_dev, MII_BMCR);
+		if (v < 0)
+			return v;
+		v |= (BMCR_ANENABLE | BMCR_ANRESTART);
+		phy_write(phy_dev, MII_BMCR, v);	/* auto-neg restart */
+
+		first_time_init = 1;
+	}
+
+	v = phy_mmd_read(phy_dev, EEELPAR_DEV, EEELPAR);
+
+	if (v & LP_1000BASE_EEE)
+		eee_type |= HIGMAC_SPD_1000M;
+	if (v & LP_100BASE_EEE)
+		eee_type |= HIGMAC_SPD_100M;
+
+	return eee_type;
+}
+
+struct phy_info phy_info_table[] = {
+	/* phy_name             phy_id  eee_available   phy_driver */
+/* SMSC */
+	{"SMSC LAN8740", 0x0007c110, MAC_EEE, &smsc_lan8740_init},
+/* Realtek */
+#if RTL8211EG_MAC
+	{"Realtek 8211EG", 0x001cc915, MAC_EEE, &rtl8211EG_mac_init},
+#else
+	{"Realtek 8211EG", 0x001cc915, PHY_EEE, &rtl8211EG_init},
+#endif
+	{"Festa V200", HISILICON_PHY_ID_FESTAV200, MAC_EEE, &festa_v200_init},
+};
diff --git a/drivers/net/ethernet/hisilicon/higmac/board.c b/drivers/net/ethernet/hisilicon/higmac/board.c
new file mode 100644
index 0000000..89b9d16
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/board.c
@@ -0,0 +1,96 @@
+#include <linux/clk.h>
+#include <linux/kernel.h>
+#include <linux/reset.h>
+#include "higmac.h"
+
+void higmac_mac_core_reset(struct higmac_netdev_local *priv)
+{
+	/* undo reset */
+	reset_control_deassert(priv->port_rst);
+	usleep_range(50, 60);
+
+	/* soft reset mac port */
+	reset_control_assert(priv->port_rst);
+	usleep_range(50, 60);
+	/* undo reset */
+	reset_control_deassert(priv->port_rst);
+}
+
+void higmac_hw_internal_phy_reset(struct higmac_netdev_local *priv)
+{
+}
+
+void higmac_hw_phy_reset(struct higmac_netdev_local *priv)
+{
+	if (priv->internal_phy)
+		higmac_hw_internal_phy_reset(priv);
+	else
+		higmac_hw_external_phy_reset(priv);
+}
+
+void higmac_hw_external_phy_reset(struct higmac_netdev_local *priv)
+{
+	if (priv->phy_rst) {
+		/* write 0 to cancel reset */
+		reset_control_deassert(priv->phy_rst);
+		msleep(50);
+
+		/* HIFONE or 98cv200 use CRG register to reset phy */
+		/* RST_BIT, write 0 to reset phy, write 1 to cancel reset */
+		reset_control_assert(priv->phy_rst);
+
+		/* delay some time to ensure reset ok,
+		 * this depends on PHY hardware feature
+		 */
+		msleep(50);
+
+		/* write 0 to cancel reset */
+		reset_control_deassert(priv->phy_rst);
+		/* delay some time to ensure later MDIO access */
+		msleep(50);
+	}
+}
+
+void higmac_internal_phy_clk_disable(struct higmac_netdev_local *priv)
+{
+}
+
+void higmac_internal_phy_clk_enable(struct higmac_netdev_local *priv)
+{
+}
+
+void higmac_hw_all_clk_disable(struct higmac_netdev_local *priv)
+{
+	/* If macif clock is enabled when suspend, we should
+	 * disable it here.
+	 * Because when resume, PHY will link up again and
+	 * macif clock will be enabled too. If we don't disable
+	 * macif clock in suspend, macif clock will be enabled twice.
+	 */
+	if (priv->netdev->flags & IFF_UP)
+		clk_disable_unprepare(priv->macif_clk);
+
+	/* This is called in suspend, when net device is down,
+	 * MAC clk is disabled.
+	 * So we need to judge whether MAC clk is enabled,
+	 * otherwise kernel will WARNING if clk disable twice.
+	 */
+	if (priv->netdev->flags & IFF_UP)
+		clk_disable_unprepare(priv->clk);
+
+	if (priv->internal_phy)
+		higmac_internal_phy_clk_disable(priv);
+}
+
+void higmac_hw_all_clk_enable(struct higmac_netdev_local *priv)
+{
+	if (priv->internal_phy)
+		higmac_internal_phy_clk_enable(priv);
+
+	if (priv->netdev->flags & IFF_UP)
+		clk_prepare_enable(priv->macif_clk);
+
+	/* If net device is down when suspend, we should not enable MAC clk. */
+	if (priv->netdev->flags & IFF_UP)
+		clk_prepare_enable(priv->clk);
+}
diff --git a/drivers/net/ethernet/hisilicon/higmac/higmac.c b/drivers/net/ethernet/hisilicon/higmac/higmac.c
new file mode 100644
index 0000000..f0bbe92
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/higmac.c
@@ -0,0 +1,3021 @@
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/unistd.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/mii.h>
+#include <linux/ethtool.h>
+#include <linux/phy.h>
+#include <linux/dma-mapping.h>
+#include <linux/workqueue.h>
+#include <linux/device.h>
+#include <linux/atomic.h>
+#include <linux/platform_device.h>
+#include <linux/capability.h>
+#include <linux/time.h>
+#include <asm/setup.h>
+#include <linux/proc_fs.h>
+#include <linux/module.h>
+
+#include <linux/circ_buf.h>
+#include <linux/if_vlan.h>
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+#include <net/ipv6.h>
+
+#include <linux/of_net.h>
+#include <linux/of_mdio.h>
+#include <linux/clk.h>
+#include <linux/reset.h>
+
+#include "util.h"
+#include "higmac.h"
+#include "autoeee/autoeee.h"
+#include "sockioctl.h"
+
+#define HAS_TSO_CAP(hw_cap)		((((hw_cap) >> 28) & 0x3) == VER_TSO)
+#define HAS_RXHASH_CAP(hw_cap)		((hw_cap) & BIT(30))
+#define HAS_RSS_CAP(hw_cap)		((hw_cap) & BIT(31))
+
+#define RGMII_SPEED_1000		0x2c
+#define RGMII_SPEED_100			0x2f
+#define RGMII_SPEED_10			0x2d
+#define MII_SPEED_100			0x0f
+#define MII_SPEED_10			0x0d
+#define RMII_SPEED_100			0x8f
+#define RMII_SPEED_10			0x8d
+#define GMAC_FULL_DUPLEX		BIT(4)
+
+static unsigned int flow_ctrl_en = FLOW_OFF;
+static int tx_flow_ctrl_pause_time = CONFIG_TX_FLOW_CTRL_PAUSE_TIME;
+static int tx_flow_ctrl_pause_interval = CONFIG_TX_FLOW_CTRL_PAUSE_INTERVAL;
+static int tx_flow_ctrl_active_threshold = CONFIG_TX_FLOW_CTRL_ACTIVE_THRESHOLD;
+static int tx_flow_ctrl_deactive_threshold =
+				CONFIG_TX_FLOW_CTRL_DEACTIVE_THRESHOLD;
+
+#define DEFAULT_MSG_ENABLE (NETIF_MSG_DRV | NETIF_MSG_PROBE | NETIF_MSG_LINK)
+static int debug = -1;
+module_param(debug, int, 0000);
+MODULE_PARM_DESC(debug, "Debug level (0=none,...,16=all)");
+
+static void higmac_config_port(struct net_device *dev, u32 speed, u32 duplex)
+{
+	struct higmac_netdev_local *priv = netdev_priv(dev);
+	u32 val;
+
+	switch (priv->phy_mode) {
+	case PHY_INTERFACE_MODE_RGMII:
+		if (speed == SPEED_1000)
+			val = RGMII_SPEED_1000;
+		else if (speed == SPEED_100)
+			val = RGMII_SPEED_100;
+		else
+			val = RGMII_SPEED_10;
+		break;
+	case PHY_INTERFACE_MODE_MII:
+		if (speed == SPEED_100)
+			val = MII_SPEED_100;
+		else
+			val = MII_SPEED_10;
+		break;
+	case PHY_INTERFACE_MODE_RMII:
+		if (speed == SPEED_100)
+			val = RMII_SPEED_100;
+		else
+			val = RMII_SPEED_10;
+		break;
+	default:
+		netdev_warn(dev, "not supported mode\n");
+		val = MII_SPEED_10;
+		break;
+	}
+
+	if (duplex)
+		val |= GMAC_FULL_DUPLEX;
+
+	reset_control_assert(priv->macif_rst);
+	writel_relaxed(val, priv->macif_base);
+	reset_control_deassert(priv->macif_rst);
+
+	writel_relaxed(BIT_MODE_CHANGE_EN, priv->gmac_iobase + MODE_CHANGE_EN);
+	if (speed == SPEED_1000)
+		val = GMAC_SPEED_1000;
+	else if (speed == SPEED_100)
+		val = GMAC_SPEED_100;
+	else
+		val = GMAC_SPEED_10;
+	writel_relaxed(val, priv->gmac_iobase + PORT_MODE);
+	writel_relaxed(0, priv->gmac_iobase + MODE_CHANGE_EN);
+	writel_relaxed(duplex, priv->gmac_iobase + MAC_DUPLEX_HALF_CTRL);
+}
+
+static void higmac_set_desc_depth(struct higmac_netdev_local *priv,
+				  u32 rx, u32 tx)
+{
+	u32 reg;
+	int i;
+
+	writel(BITS_RX_FQ_DEPTH_EN, priv->gmac_iobase + RX_FQ_REG_EN);
+	writel(rx << DESC_WORD_SHIFT, priv->gmac_iobase + RX_FQ_DEPTH);
+	writel(0, priv->gmac_iobase + RX_FQ_REG_EN);
+
+	writel(BITS_RX_BQ_DEPTH_EN, priv->gmac_iobase + RX_BQ_REG_EN);
+	writel(rx << DESC_WORD_SHIFT, priv->gmac_iobase + RX_BQ_DEPTH);
+	for (i = 1; i < priv->num_rxqs; i++) {
+		reg = RX_BQ_DEPTH_QUEUE(i);
+		writel(rx << DESC_WORD_SHIFT, priv->gmac_iobase + reg);
+	}
+	writel(0, priv->gmac_iobase + RX_BQ_REG_EN);
+
+	writel(BITS_TX_BQ_DEPTH_EN, priv->gmac_iobase + TX_BQ_REG_EN);
+	writel(tx << DESC_WORD_SHIFT, priv->gmac_iobase + TX_BQ_DEPTH);
+	writel(0, priv->gmac_iobase + TX_BQ_REG_EN);
+
+	writel(BITS_TX_RQ_DEPTH_EN, priv->gmac_iobase + TX_RQ_REG_EN);
+	writel(tx << DESC_WORD_SHIFT, priv->gmac_iobase + TX_RQ_DEPTH);
+	writel(0, priv->gmac_iobase + TX_RQ_REG_EN);
+}
+
+static void higmac_set_rx_fq(struct higmac_netdev_local *priv,
+			     dma_addr_t phy_addr)
+{
+	writel(BITS_RX_FQ_START_ADDR_EN, priv->gmac_iobase + RX_FQ_REG_EN);
+	writel(phy_addr, priv->gmac_iobase + RX_FQ_START_ADDR);
+	writel(0, priv->gmac_iobase + RX_FQ_REG_EN);
+}
+
+static void higmac_set_rx_bq(struct higmac_netdev_local *priv,
+			     dma_addr_t phy_addr)
+{
+	writel(BITS_RX_BQ_START_ADDR_EN, priv->gmac_iobase + RX_BQ_REG_EN);
+	writel(phy_addr, priv->gmac_iobase + RX_BQ_START_ADDR);
+	writel(0, priv->gmac_iobase + RX_BQ_REG_EN);
+}
+
+static void higmac_set_tx_bq(struct higmac_netdev_local *priv,
+			     dma_addr_t phy_addr)
+{
+	writel(BITS_TX_BQ_START_ADDR_EN, priv->gmac_iobase + TX_BQ_REG_EN);
+	writel(phy_addr, priv->gmac_iobase + TX_BQ_START_ADDR);
+	writel(0, priv->gmac_iobase + TX_BQ_REG_EN);
+}
+
+static void higmac_set_tx_rq(struct higmac_netdev_local *priv,
+			     dma_addr_t phy_addr)
+{
+	writel(BITS_TX_RQ_START_ADDR_EN, priv->gmac_iobase + TX_RQ_REG_EN);
+	writel(phy_addr, priv->gmac_iobase + TX_RQ_START_ADDR);
+	writel(0, priv->gmac_iobase + TX_RQ_REG_EN);
+}
+
+static void higmac_hw_set_desc_addr(struct higmac_netdev_local *priv)
+{
+	u32 reg;
+	int i;
+
+	higmac_set_rx_fq(priv, priv->rx_fq.phys_addr);
+	higmac_set_rx_bq(priv, priv->rx_bq.phys_addr);
+	higmac_set_tx_rq(priv, priv->tx_rq.phys_addr);
+	higmac_set_tx_bq(priv, priv->tx_bq.phys_addr);
+
+	for (i = 1; i < priv->num_rxqs; i++) {
+		reg = RX_BQ_START_ADDR_QUEUE(i);
+		writel(BITS_RX_BQ_START_ADDR_EN,
+		       priv->gmac_iobase + RX_BQ_REG_EN);
+		writel(priv->pool[3 + i].phys_addr, priv->gmac_iobase + reg);
+		writel(0, priv->gmac_iobase + RX_BQ_REG_EN);
+	}
+}
+
+static void higmac_set_rss_cap(struct higmac_netdev_local *priv)
+{
+	u32 val = 0;
+
+	if (priv->has_rxhash_cap)
+		val |= BIT_RXHASH_CAP;
+	if (priv->has_rss_cap)
+		val |= BIT_RSS_CAP;
+	writel(val, priv->gmac_iobase + HW_CAP_EN);
+}
+
+static void higmac_hw_init(struct higmac_netdev_local *priv)
+{
+	u32 val;
+	u32 reg;
+	int i;
+
+#if defined(CONFIG_ARCH_HI3519) || defined(CONFIG_ARCH_HI3519V101) || \
+	defined(CONFIG_ARCH_HI3559) || defined(CONFIG_ARCH_HI3556) || \
+	defined(CONFIG_ARCH_HI3516AV200)
+	/* config AXI parameter for better performance. */
+	val = readl(priv->gmac_iobase + BURST_OUTSTANDING_REG);
+	val >>= BURST_OUTSTANDING_OFFSET;
+	if (!val)
+		writel(BURST4_OUTSTANDING1, priv->gmac_iobase +
+			BURST_OUTSTANDING_REG);
+#endif
+
+	/* disable and clear all interrupts */
+	writel(0, priv->gmac_iobase + ENA_PMU_INT);
+	writel(~0, priv->gmac_iobase + RAW_PMU_INT);
+
+	for (i = 1; i < priv->num_rxqs; i++) {
+		reg = RSS_ENA_INT_QUEUE(i);
+		writel(0, priv->gmac_iobase + reg);
+	}
+	writel(~0, priv->gmac_iobase + RSS_RAW_PMU_INT);
+
+	/* enable CRC erro packets filter */
+	val = readl(priv->gmac_iobase + REC_FILT_CONTROL);
+	val |= BIT_CRC_ERR_PASS;
+	writel(val, priv->gmac_iobase + REC_FILT_CONTROL);
+
+	/* set tx min packet length */
+	val = readl(priv->gmac_iobase + CRF_MIN_PACKET);
+	val &= ~BIT_MASK_TX_MIN_LEN;
+	val |= ETH_HLEN << BIT_OFFSET_TX_MIN_LEN;
+	writel(val, priv->gmac_iobase + CRF_MIN_PACKET);
+
+	/* fix bug for udp and ip error check */
+	writel(CONTROL_WORD_CONFIG, priv->gmac_iobase + CONTROL_WORD);
+
+	writel(0, priv->gmac_iobase + COL_SLOT_TIME);
+
+	writel(DUPLEX_HALF, priv->gmac_iobase + MAC_DUPLEX_HALF_CTRL);
+
+	/* FIXME: interrupt when rcv packets >= RX_BQ_INT_THRESHOLD */
+	val = RX_BQ_INT_THRESHOLD |
+		(TX_RQ_INT_THRESHOLD << BITS_OFFSET_TX_RQ_IN_TH);
+	writel(val, priv->gmac_iobase + IN_QUEUE_TH);
+
+	/* FIXME: rx_bq/tx_rq in timeout threshold */
+	writel(0x10000, priv->gmac_iobase + RX_BQ_IN_TIMEOUT_TH);
+
+	writel(0x18000, priv->gmac_iobase + TX_RQ_IN_TIMEOUT_TH);
+
+	higmac_set_desc_depth(priv, RX_DESC_NUM, TX_DESC_NUM);
+}
+
+static inline void higmac_irq_enable(struct higmac_netdev_local *ld)
+{
+	writel(RX_BQ_IN_INT | RX_BQ_IN_TIMEOUT_INT
+		| TX_RQ_IN_INT | TX_RQ_IN_TIMEOUT_INT,
+		ld->gmac_iobase + ENA_PMU_INT);
+}
+
+static inline void higmac_irq_enable_queue(struct higmac_netdev_local *ld,
+					   int rxq_id)
+{
+	if (rxq_id) {
+		u32 reg;
+
+		reg = RSS_ENA_INT_QUEUE(rxq_id);
+		writel(~0, ld->gmac_iobase + reg);
+	} else {
+		higmac_irq_enable(ld);
+	}
+}
+
+static inline void higmac_irq_enable_all_queue(struct higmac_netdev_local *ld)
+{
+	int i;
+
+	for (i = 0; i < ld->num_rxqs; i++)
+		higmac_irq_enable_queue(ld, i);
+}
+
+static inline void higmac_irq_disable(struct higmac_netdev_local *ld)
+{
+	writel(0, ld->gmac_iobase + ENA_PMU_INT);
+}
+
+static inline void higmac_irq_disable_queue(struct higmac_netdev_local *ld,
+					    int rxq_id)
+{
+	if (rxq_id) {
+		u32 reg;
+
+		reg = RSS_ENA_INT_QUEUE(rxq_id);
+		writel(0, ld->gmac_iobase + reg);
+	} else {
+		higmac_irq_disable(ld);
+	}
+}
+
+static inline void higmac_irq_disable_all_queue(struct higmac_netdev_local *ld)
+{
+	int i;
+
+	for (i = 0; i < ld->num_rxqs; i++)
+		higmac_irq_disable_queue(ld, i);
+}
+
+static inline bool higmac_queue_irq_disabled(struct higmac_netdev_local *ld,
+					     int rxq_id)
+{
+	u32 reg, val;
+
+	if (rxq_id)
+		reg = RSS_ENA_INT_QUEUE(rxq_id);
+	else
+		reg = ENA_PMU_INT;
+	val = readl(ld->gmac_iobase + reg);
+
+	return !val;
+}
+
+static inline void higmac_hw_desc_enable(struct higmac_netdev_local *ld)
+{
+	writel(0xF, ld->gmac_iobase + DESC_WR_RD_ENA);
+}
+
+static inline void higmac_hw_desc_disable(struct higmac_netdev_local *ld)
+{
+	writel(0, ld->gmac_iobase + DESC_WR_RD_ENA);
+}
+
+static inline void higmac_port_enable(struct higmac_netdev_local *ld)
+{
+	writel(BITS_TX_EN | BITS_RX_EN, ld->gmac_iobase + PORT_EN);
+}
+
+static inline void higmac_port_disable(struct higmac_netdev_local *ld)
+{
+	writel(0, ld->gmac_iobase + PORT_EN);
+}
+
+void higmac_set_flow_ctrl_params(struct higmac_netdev_local *ld)
+{
+	unsigned int rx_fq_empty_th;
+	unsigned int rx_fq_full_th;
+	unsigned int rx_bq_empty_th;
+	unsigned int rx_bq_full_th;
+	unsigned int rec_filter;
+
+	writel(ld->pause, ld->gmac_iobase + FC_TX_TIMER);
+	writel(ld->pause_interval, ld->gmac_iobase + PAUSE_THR);
+
+	rx_fq_empty_th = readl(ld->gmac_iobase + RX_FQ_ALEMPTY_TH);
+	rx_fq_empty_th &= ~(BITS_Q_PAUSE_TH_MASK << BITS_Q_PAUSE_TH_OFFSET);
+	rx_fq_empty_th |= (ld->flow_ctrl_active_threshold <<
+			BITS_Q_PAUSE_TH_OFFSET);
+	writel(rx_fq_empty_th, ld->gmac_iobase + RX_FQ_ALEMPTY_TH);
+
+	rx_fq_full_th = readl(ld->gmac_iobase + RX_FQ_ALFULL_TH);
+	rx_fq_full_th &= ~(BITS_Q_PAUSE_TH_MASK << BITS_Q_PAUSE_TH_OFFSET);
+	rx_fq_full_th |= (ld->flow_ctrl_deactive_threshold <<
+			BITS_Q_PAUSE_TH_OFFSET);
+	writel(rx_fq_full_th, ld->gmac_iobase + RX_FQ_ALFULL_TH);
+
+	rx_bq_empty_th = readl(ld->gmac_iobase + RX_BQ_ALEMPTY_TH);
+	rx_bq_empty_th &= ~(BITS_Q_PAUSE_TH_MASK << BITS_Q_PAUSE_TH_OFFSET);
+	rx_bq_empty_th |= (ld->flow_ctrl_active_threshold <<
+			BITS_Q_PAUSE_TH_OFFSET);
+	writel(rx_bq_empty_th, ld->gmac_iobase + RX_BQ_ALEMPTY_TH);
+
+	rx_bq_full_th = readl(ld->gmac_iobase + RX_BQ_ALFULL_TH);
+	rx_bq_full_th &= ~(BITS_Q_PAUSE_TH_MASK << BITS_Q_PAUSE_TH_OFFSET);
+	rx_bq_full_th |= (ld->flow_ctrl_deactive_threshold <<
+			BITS_Q_PAUSE_TH_OFFSET);
+	writel(rx_bq_full_th, ld->gmac_iobase + RX_BQ_ALFULL_TH);
+
+	writel(0, ld->gmac_iobase + CRF_TX_PAUSE);
+
+	rec_filter = readl(ld->gmac_iobase + REC_FILT_CONTROL);
+	rec_filter |= BIT_PAUSE_FRM_PASS;
+	writel(rec_filter, ld->gmac_iobase + REC_FILT_CONTROL);
+}
+
+void higmac_set_flow_ctrl_state(struct higmac_netdev_local *ld, int pause)
+{
+	unsigned int flow_rx_q_en;
+	unsigned int flow;
+
+	flow_rx_q_en = readl(ld->gmac_iobase + RX_PAUSE_EN);
+	flow_rx_q_en &= ~(BIT_RX_FQ_PAUSE_EN | BIT_RX_BQ_PAUSE_EN);
+	if (pause && (ld->flow_ctrl & FLOW_TX))
+		flow_rx_q_en |= (BIT_RX_FQ_PAUSE_EN | BIT_RX_BQ_PAUSE_EN);
+	writel(flow_rx_q_en, ld->gmac_iobase + RX_PAUSE_EN);
+
+	flow = readl(ld->gmac_iobase + PAUSE_EN);
+	flow &= ~(BIT_RX_FDFC | BIT_TX_FDFC);
+	if (pause) {
+		if (ld->flow_ctrl & FLOW_RX)
+			flow |= BIT_RX_FDFC;
+		if (ld->flow_ctrl & FLOW_TX)
+			flow |= BIT_TX_FDFC;
+	}
+	writel(flow, ld->gmac_iobase + PAUSE_EN);
+}
+
+static void higmac_set_flow_ctrl_args(struct higmac_netdev_local *ld)
+{
+	ld->flow_ctrl = flow_ctrl_en;
+	ld->pause = tx_flow_ctrl_pause_time;
+	ld->pause_interval = tx_flow_ctrl_pause_interval;
+	ld->flow_ctrl_active_threshold = tx_flow_ctrl_active_threshold;
+	ld->flow_ctrl_deactive_threshold = tx_flow_ctrl_deactive_threshold;
+}
+
+/* set gmac's multicast list, here we setup gmac's mc filter */
+static void higmac_gmac_multicast_list(struct net_device *dev)
+{
+	struct higmac_netdev_local *ld = netdev_priv(dev);
+	unsigned int rec_filter;
+
+	rec_filter = readl(ld->gmac_iobase + REC_FILT_CONTROL);
+	/* when set gmac in promisc mode
+	 * a. dev in IFF_PROMISC mode
+	 */
+	if ((dev->flags & IFF_PROMISC)) {
+		/* promisc mode.received all pkgs. */
+		rec_filter &= ~(BIT_BC_DROP_EN | BIT_MC_MATCH_EN |
+				BIT_UC_MATCH_EN);
+	} else {
+		/* drop uc pkgs with field 'DA' not match our's */
+		rec_filter |= BIT_UC_MATCH_EN;
+
+		if (dev->flags & IFF_BROADCAST)	/* no broadcast */
+			rec_filter &= ~BIT_BC_DROP_EN;
+		else
+			rec_filter |= BIT_BC_DROP_EN;
+
+		if (netdev_mc_empty(dev) || !(dev->flags & IFF_MULTICAST)) {
+			/* haven't join any mc group */
+			writel(0, ld->gmac_iobase + PORT_MC_ADDR_LOW);
+			writel(0, ld->gmac_iobase + PORT_MC_ADDR_HIGH);
+			rec_filter |= BIT_MC_MATCH_EN;
+		} else if (netdev_mc_count(dev) == 1 &&
+			(dev->flags & IFF_MULTICAST)) {
+			struct netdev_hw_addr *ha;
+			unsigned int d = 0;
+
+			netdev_for_each_mc_addr(ha, dev) {
+				d = (ha->addr[0] << 8) | (ha->addr[1]);
+				writel(d, ld->gmac_iobase + PORT_MC_ADDR_HIGH);
+
+				d = (ha->addr[2] << 24) | (ha->addr[3] << 16)
+					| (ha->addr[4] << 8) | (ha->addr[5]);
+				writel(d, ld->gmac_iobase + PORT_MC_ADDR_LOW);
+			}
+			rec_filter |= BIT_MC_MATCH_EN;
+		} else {
+			rec_filter &= ~BIT_MC_MATCH_EN;
+		}
+	}
+	writel(rec_filter, ld->gmac_iobase + REC_FILT_CONTROL);
+}
+
+/* the func stop the hw desc and relaim the software skb resource
+ * before reusing the gmac, you'd better reset the gmac
+ */
+void higmac_reclaim_rx_tx_resource(struct higmac_netdev_local *ld)
+{
+	unsigned long rxflags, txflags;
+	int rd_offset, wr_offset;
+	int i;
+
+	higmac_irq_disable_all_queue(ld);
+	higmac_hw_desc_disable(ld);
+	writel(STOP_RX_TX, ld->gmac_iobase + STOP_CMD);
+
+	spin_lock_irqsave(&ld->rxlock, rxflags);
+	/* rx_bq: logic write pointer */
+	wr_offset = readl(ld->gmac_iobase + RX_BQ_WR_ADDR);
+	/* rx_bq: software read pointer */
+	rd_offset = readl(ld->gmac_iobase + RX_BQ_RD_ADDR);
+	/* FIXME: prevent to reclaim skb in rx bottom half */
+	writel(wr_offset, ld->gmac_iobase + RX_BQ_RD_ADDR);
+
+	for (i = 1; i < ld->num_rxqs; i++) {
+		u32 rx_bq_wr_reg, rx_bq_rd_reg;
+
+		rx_bq_wr_reg = RX_BQ_WR_ADDR_QUEUE(i);
+		rx_bq_rd_reg = RX_BQ_RD_ADDR_QUEUE(i);
+
+		wr_offset = readl(ld->gmac_iobase + rx_bq_wr_reg);
+		writel(wr_offset, ld->gmac_iobase + rx_bq_rd_reg);
+	}
+
+	/* rx_fq: software write pointer */
+	wr_offset = readl(ld->gmac_iobase + RX_FQ_WR_ADDR);
+	/* rx_fq: logic read pointer */
+	rd_offset = readl(ld->gmac_iobase + RX_FQ_RD_ADDR);
+	if (!rd_offset)
+		rd_offset = (RX_DESC_NUM - 1) << DESC_BYTE_SHIFT;
+	else
+		rd_offset -= DESC_SIZE;
+	/* FIXME: stop to feed hw desc */
+	writel(rd_offset, ld->gmac_iobase + RX_FQ_WR_ADDR);
+
+	for (i = 0; i < ld->rx_fq.count; i++) {
+		if (!ld->rx_fq.skb[i])
+			ld->rx_fq.skb[i] = SKB_MAGIC;
+	}
+	spin_unlock_irqrestore(&ld->rxlock, rxflags);
+
+	/* no need to wait pkts in tx_rq finish to free all skb,
+	 * because higmac_xmit_reclaim is in the tx_lock,
+	 */
+	spin_lock_irqsave(&ld->txlock, txflags);
+	/* tx_rq: logic write */
+	wr_offset = readl(ld->gmac_iobase + TX_RQ_WR_ADDR);
+	/* tx_rq: software read */
+	rd_offset = readl(ld->gmac_iobase + TX_RQ_RD_ADDR);
+	/* FIXME: stop to reclaim tx skb */
+	writel(wr_offset, ld->gmac_iobase + TX_RQ_RD_ADDR);
+
+	/* tx_bq: logic read */
+	rd_offset = readl(ld->gmac_iobase + TX_BQ_RD_ADDR);
+	if (!rd_offset)
+		rd_offset = (TX_DESC_NUM - 1) << DESC_BYTE_SHIFT;
+	else
+		rd_offset -= DESC_SIZE;
+	/* FIXME: stop software tx skb */
+	writel(rd_offset, ld->gmac_iobase + TX_BQ_WR_ADDR);
+
+	for (i = 0; i < ld->tx_bq.count; i++) {
+		if (!ld->tx_bq.skb[i])
+			ld->tx_bq.skb[i] = SKB_MAGIC;
+	}
+	spin_unlock_irqrestore(&ld->txlock, txflags);
+}
+
+static void higmac_monitor_func(unsigned long arg);
+static void higmac_set_multicast_list(struct net_device *dev);
+
+static void higmac_hw_set_mac_addr(struct net_device *dev)
+{
+	struct higmac_netdev_local *priv = netdev_priv(dev);
+	unsigned char *mac = dev->dev_addr;
+	u32 val;
+
+	val = mac[1] | (mac[0] << 8);
+	writel(val, priv->gmac_iobase + STATION_ADDR_HIGH);
+
+	val = mac[5] | (mac[4] << 8) | (mac[3] << 16) | (mac[2] << 24);
+	writel(val, priv->gmac_iobase + STATION_ADDR_LOW);
+}
+
+static void higmac_rx_refill(struct higmac_netdev_local *priv);
+
+static void higmac_free_rx_skb(struct higmac_netdev_local *ld)
+{
+	struct sk_buff *skb = NULL;
+	int i;
+
+	for (i = 0; i < ld->rx_fq.count; i++) {
+		skb = ld->rx_fq.skb[i];
+		if (skb) {
+			ld->rx_skb[i] = NULL;
+			ld->rx_fq.skb[i] = NULL;
+			if (skb == SKB_MAGIC)
+				continue;
+			dev_kfree_skb_any(skb);
+			/* TODO: need to unmap the skb here
+			 * but there is no way to get the dma_addr here,
+			 * and unmap(TO_DEVICE) ops do nothing in fact,
+			 * so we ignore to call
+			 * dma_unmap_single(dev, dma_addr, skb->len,
+			 *      DMA_TO_DEVICE)
+			 */
+		}
+	}
+}
+
+static void higmac_free_tx_skb(struct higmac_netdev_local *ld)
+{
+	struct sk_buff *skb = NULL;
+	int i;
+
+	for (i = 0; i < ld->tx_bq.count; i++) {
+		skb = ld->tx_bq.skb[i];
+		if (skb) {
+			ld->tx_skb[i] = NULL;
+			ld->tx_bq.skb[i] = NULL;
+			if (skb == SKB_MAGIC)
+				continue;
+			dev_kfree_skb_any(skb);
+			/* TODO: unmap the skb */
+		}
+	}
+}
+
+/* reset and re-config gmac */
+void higmac_restart(struct higmac_netdev_local *ld)
+{
+	unsigned long rxflags, txflags;
+
+	/* restart hw engine now */
+	higmac_mac_core_reset(ld);
+
+	spin_lock_irqsave(&ld->rxlock, rxflags);
+	spin_lock_irqsave(&ld->txlock, txflags);
+
+	higmac_free_rx_skb(ld);
+	higmac_free_tx_skb(ld);
+
+	pmt_reg_restore(ld);
+	higmac_hw_init(ld);
+	higmac_hw_set_mac_addr(ld->netdev);
+	higmac_hw_set_desc_addr(ld);
+
+	/* we don't set macif here, it will be set in adjust_link */
+	if (ld->netdev->flags & IFF_UP) {
+		/* when resume, only do the following operations
+		 * when dev is up before suspend.
+		 */
+		higmac_rx_refill(ld);
+		higmac_set_multicast_list(ld->netdev);
+
+		higmac_hw_desc_enable(ld);
+		higmac_port_enable(ld);
+		higmac_irq_enable_all_queue(ld);
+	}
+	spin_unlock_irqrestore(&ld->txlock, txflags);
+	spin_unlock_irqrestore(&ld->rxlock, rxflags);
+}
+
+static int higmac_net_set_mac_address(struct net_device *dev, void *p)
+{
+	int ret;
+
+	ret = eth_mac_addr(dev, p);
+	if (!ret)
+		higmac_hw_set_mac_addr(dev);
+
+	return ret;
+}
+
+static void higmac_adjust_link(struct net_device *dev)
+{
+	struct higmac_netdev_local *priv = netdev_priv(dev);
+	struct phy_device *phy = priv->phy;
+	bool link_status_changed = false;
+
+	if (phy->link) {
+		if ((priv->old_speed != phy->speed) ||
+		    (priv->old_duplex != phy->duplex)) {
+			higmac_config_port(dev, phy->speed, phy->duplex);
+			higmac_set_flow_ctrl_state(priv, phy->pause);
+
+			if (priv->autoeee)
+				init_autoeee(priv);
+
+			link_status_changed = true;
+			priv->old_link = 1;
+			priv->old_speed = phy->speed;
+			priv->old_duplex = phy->duplex;
+		}
+	} else if (priv->old_link) {
+		link_status_changed = true;
+		priv->old_link = 0;
+		priv->old_speed = SPEED_UNKNOWN;
+		priv->old_duplex = DUPLEX_UNKNOWN;
+	}
+
+	if (link_status_changed && netif_msg_link(priv))
+		phy_print_status(phy);
+}
+
+int higmac_tx_avail(struct higmac_netdev_local *ld)
+{
+	int tx_bq_wr_offset, tx_bq_rd_offset;
+
+	tx_bq_wr_offset = readl(ld->gmac_iobase + TX_BQ_WR_ADDR);
+	tx_bq_rd_offset = readl(ld->gmac_iobase + TX_BQ_RD_ADDR);
+
+	return (tx_bq_rd_offset >> DESC_BYTE_SHIFT) + TX_DESC_NUM
+		- (tx_bq_wr_offset >> DESC_BYTE_SHIFT) - 1;
+}
+
+static int higmac_init_sg_desc_queue(struct higmac_netdev_local *ld)
+{
+	ld->sg_count = ld->tx_bq.count + HIGMAC_SG_DESC_ADD;
+	if (HAS_CAP_CCI(ld->hw_cap)) {
+		ld->dma_sg_desc = kmalloc_array(ld->sg_count,
+				sizeof(struct sg_desc),
+				GFP_KERNEL);
+		if (ld->dma_sg_desc)
+			ld->dma_sg_phy = virt_to_phys(ld->dma_sg_desc);
+	} else {
+		ld->dma_sg_desc = (struct sg_desc *)dma_alloc_coherent(ld->dev,
+				ld->sg_count * sizeof(struct sg_desc),
+				&ld->dma_sg_phy, GFP_KERNEL);
+	}
+
+	if (!ld->dma_sg_desc) {
+		pr_err("alloc sg desc dma error!\n");
+		return -ENOMEM;
+	}
+#ifdef HIGMAC_TSO_DEBUG
+	pr_info("Higmac dma_sg_phy: 0x%p\n", (void *)ld->dma_sg_phy);
+#endif
+
+	ld->sg_head = 0;
+	ld->sg_tail = 0;
+
+	return 0;
+}
+
+static void higmac_destroy_sg_desc_queue(struct higmac_netdev_local *ld)
+{
+	if (ld->dma_sg_desc) {
+		if (HAS_CAP_CCI(ld->hw_cap))
+			kfree(ld->dma_sg_desc);
+		else
+			dma_free_coherent(ld->dev,
+					  ld->sg_count * sizeof(struct sg_desc),
+					  ld->dma_sg_desc, ld->dma_sg_phy);
+		ld->dma_sg_desc = NULL;
+	}
+}
+
+static void higmac_monitor_func(unsigned long arg)
+{
+	struct net_device *dev = (struct net_device *)arg;
+	struct higmac_netdev_local *ld = netdev_priv(dev);
+
+	if (!ld || !netif_running(dev)) {
+		higmac_trace(7, "network driver is stopped.");
+		return;
+	}
+
+	spin_lock(&ld->rxlock);
+	higmac_rx_refill(ld);
+	spin_unlock(&ld->rxlock);
+
+	ld->monitor.expires = jiffies + HIGMAC_MONITOR_TIMER;
+	mod_timer(&ld->monitor, ld->monitor.expires);
+}
+
+static void higmac_rx_refill(struct higmac_netdev_local *priv)
+{
+	struct higmac_desc *desc;
+	struct sk_buff *skb;
+	u32 start, end, num, pos, i;
+	u32 len = HIETH_MAX_FRAME_SIZE;
+	dma_addr_t addr;
+
+	/* software write pointer */
+	start = dma_cnt(readl(priv->gmac_iobase + RX_FQ_WR_ADDR));
+	/* logic read pointer */
+	end = dma_cnt(readl(priv->gmac_iobase + RX_FQ_RD_ADDR));
+	num = CIRC_SPACE(start, end, RX_DESC_NUM);
+
+	for (i = 0, pos = start; i < num; i++) {
+		if (priv->rx_fq.skb[pos] || priv->rx_skb[pos])
+			break;
+
+		skb = netdev_alloc_skb_ip_align(priv->netdev, len);
+		if (unlikely(!skb))
+			break;
+
+		if (!HAS_CAP_CCI(priv->hw_cap)) {
+			addr = dma_map_single(priv->dev, skb->data, len,
+					      DMA_FROM_DEVICE);
+			if (dma_mapping_error(priv->dev, addr)) {
+				dev_kfree_skb_any(skb);
+				break;
+			}
+		} else {
+			addr = virt_to_phys(skb->data);
+		}
+
+		desc = priv->rx_fq.desc + pos;
+		desc->data_buff_addr = addr;
+		priv->rx_fq.skb[pos] = skb;
+		priv->rx_skb[pos] = skb;
+
+		desc->buffer_len = len - 1;
+		desc->data_len = 0;
+		desc->fl = 0;
+		desc->descvid = DESC_VLD_FREE;
+		desc->skb_id = pos;
+
+		pos = dma_ring_incr(pos, RX_DESC_NUM);
+	}
+
+	/* This barrier is important here.  It is required to ensure
+	 * the ARM CPU flushes it's DMA write buffers before proceeding
+	 * to the next instruction, to ensure that GMAC will see
+	 * our descriptor changes in memory
+	 */
+	HIGMAC_SYNC_BARRIER();
+
+	if (pos != start)
+		writel(dma_byte(pos), priv->gmac_iobase + RX_FQ_WR_ADDR);
+}
+
+static int higmac_rx(struct net_device *dev, int limit, int rxq_id)
+{
+	struct higmac_netdev_local *ld = netdev_priv(dev);
+	struct sk_buff *skb;
+	struct higmac_desc *desc;
+	dma_addr_t addr;
+	u32 start, end, num, pos, i, len;
+	u32 rx_bq_rd_reg, rx_bq_wr_reg;
+	u16 skb_id;
+
+	rx_bq_rd_reg = RX_BQ_RD_ADDR_QUEUE(rxq_id);
+	rx_bq_wr_reg = RX_BQ_WR_ADDR_QUEUE(rxq_id);
+
+	/* software read pointer */
+	start = dma_cnt(readl(ld->gmac_iobase + rx_bq_rd_reg));
+	/* logic write pointer */
+	end = dma_cnt(readl(ld->gmac_iobase + rx_bq_wr_reg));
+	num = CIRC_CNT(end, start, RX_DESC_NUM);
+	if (num > limit)
+		num = limit;
+
+	/* ensure get updated desc */
+	rmb();
+	for (i = 0, pos = start; i < num; i++) {
+		if (rxq_id)
+			desc = ld->pool[3 + rxq_id].desc + pos;
+		else
+			desc = ld->rx_bq.desc + pos;
+		skb_id = desc->skb_id;
+
+		spin_lock(&ld->rxlock);
+		skb = ld->rx_skb[skb_id];
+		if (unlikely(!skb)) {
+			spin_unlock(&ld->rxlock);
+			netdev_err(dev, "inconsistent rx_skb\n");
+			break;
+		}
+
+		/* data consistent check */
+		if (unlikely(skb != ld->rx_fq.skb[skb_id])) {
+			netdev_err(dev, "desc->skb(0x%p),rx_fq.skb[%d](0x%p)\n",
+				   skb, skb_id, ld->rx_fq.skb[skb_id]);
+			if (ld->rx_fq.skb[skb_id] == SKB_MAGIC) {
+				spin_unlock(&ld->rxlock);
+				goto next;
+			}
+			WARN_ON(1);
+		} else {
+			ld->rx_fq.skb[skb_id] = NULL;
+		}
+		spin_unlock(&ld->rxlock);
+
+		len = desc->data_len;
+
+		if (!HAS_CAP_CCI(ld->hw_cap)) {
+			addr = desc->data_buff_addr;
+			dma_unmap_single(ld->dev, addr, HIETH_MAX_FRAME_SIZE,
+					 DMA_FROM_DEVICE);
+		}
+
+		skb_put(skb, len);
+		if (skb->len > HIETH_MAX_FRAME_SIZE) {
+			netdev_err(dev, "rcv len err, len = %d\n", skb->len);
+			dev->stats.rx_errors++;
+			dev->stats.rx_length_errors++;
+			dev_kfree_skb_any(skb);
+			goto next;
+		}
+
+		skb->protocol = eth_type_trans(skb, dev);
+		skb->ip_summed = CHECKSUM_NONE;
+#if defined(CONFIG_HIGMAC_RXCSUM)
+		if (dev->features & NETIF_F_RXCSUM) {
+			int hdr_csum_done =
+				desc->header_csum_done;
+			int payload_csum_done =
+				desc->payload_csum_done;
+			int hdr_csum_err =
+				desc->header_csum_err;
+			int payload_csum_err =
+				desc->payload_csum_err;
+
+			if (hdr_csum_done && payload_csum_done) {
+				if (unlikely(hdr_csum_err ||
+					     payload_csum_err)) {
+					dev->stats.rx_errors++;
+					dev->stats.rx_crc_errors++;
+					dev_kfree_skb_any(skb);
+					goto next;
+				} else {
+					skb->ip_summed = CHECKSUM_UNNECESSARY;
+				}
+			}
+		}
+#endif
+		if ((dev->features & NETIF_F_RXHASH) && desc->has_hash)
+			skb_set_hash(skb, desc->rxhash, desc->l3_hash ?
+				     PKT_HASH_TYPE_L3 : PKT_HASH_TYPE_L4);
+
+		skb_record_rx_queue(skb, rxq_id);
+
+		napi_gro_receive(&ld->q_napi[rxq_id].napi, skb);
+		dev->stats.rx_packets++;
+		dev->stats.rx_bytes += skb->len;
+		dev->last_rx = jiffies;
+next:
+		spin_lock(&ld->rxlock);
+		ld->rx_skb[skb_id] = NULL;
+		spin_unlock(&ld->rxlock);
+		pos = dma_ring_incr(pos, RX_DESC_NUM);
+	}
+
+	if (pos != start)
+		writel(dma_byte(pos), ld->gmac_iobase + rx_bq_rd_reg);
+
+	spin_lock(&ld->rxlock);
+	higmac_rx_refill(ld);
+	spin_unlock(&ld->rxlock);
+
+	return num;
+}
+
+#ifdef HIGMAC_TSO_DEBUG
+unsigned int id_send;
+unsigned int id_free;
+struct send_pkt_info pkt_rec[MAX_RECORD];
+#endif
+
+static int higmac_check_tx_err(struct higmac_netdev_local *ld,
+			       struct higmac_tso_desc *tx_bq_desc,
+			       unsigned int desc_pos)
+{
+	unsigned int tx_err = tx_bq_desc->tx_err;
+
+	if (unlikely(tx_err & ERR_ALL)) {
+		struct sg_desc *desc_cur;
+		int *sg_word;
+		int i;
+
+		WARN((tx_err & ERR_ALL),
+		     "TX ERR: desc1=0x%x, desc2=0x%x, desc5=0x%x\n",
+		     tx_bq_desc->data_buff_addr,
+		     tx_bq_desc->desc1.val, tx_bq_desc->tx_err);
+
+		desc_cur = ld->dma_sg_desc + ld->tx_bq.sg_desc_offset[desc_pos];
+		sg_word = (int *)desc_cur;
+		for (i = 0; i < sizeof(struct sg_desc) / sizeof(int); i++)
+			pr_err("%s,%d: sg_desc word[%d]=0x%x\n",
+			       __func__, __LINE__, i, sg_word[i]);
+
+		return -1;
+	}
+
+	return 0;
+}
+
+static int higmac_xmit_release_gso(struct higmac_netdev_local *ld,
+				   struct higmac_tso_desc *tx_rq_desc,
+				   unsigned int desc_pos)
+{
+	int pkt_type;
+	int nfrags = tx_rq_desc->desc1.tx.nfrags_num;
+	dma_addr_t addr;
+	size_t len;
+
+	if (unlikely(higmac_check_tx_err(ld, tx_rq_desc, desc_pos) < 0)) {
+		/* dev_close */
+		higmac_irq_disable_all_queue(ld);
+		higmac_hw_desc_disable(ld);
+
+		netif_carrier_off(ld->netdev);
+		netif_stop_queue(ld->netdev);
+
+		phy_stop(ld->phy);
+		del_timer_sync(&ld->monitor);
+		return -1;
+	}
+
+	if (tx_rq_desc->desc1.tx.tso_flag || nfrags)
+		pkt_type = PKT_SG;
+	else
+		pkt_type = PKT_NORMAL;
+
+	if (pkt_type == PKT_NORMAL) {
+		if (!HAS_CAP_CCI(ld->hw_cap)) {
+			addr = tx_rq_desc->data_buff_addr;
+			len = tx_rq_desc->desc1.tx.data_len;
+			dma_unmap_single(ld->dev, addr, len, DMA_TO_DEVICE);
+		}
+	} else {
+		if (!HAS_CAP_CCI(ld->hw_cap)) {
+			struct sg_desc *desc_cur;
+			unsigned int desc_offset;
+			int i;
+
+			desc_offset = ld->tx_bq.sg_desc_offset[desc_pos];
+			WARN_ON(desc_offset != ld->sg_tail);
+			desc_cur = ld->dma_sg_desc + desc_offset;
+
+			addr = desc_cur->linear_addr;
+			len = desc_cur->linear_len;
+			dma_unmap_single(ld->dev, addr, len, DMA_TO_DEVICE);
+			for (i = 0; i < nfrags; i++) {
+				addr = desc_cur->frags[i].addr;
+				len = desc_cur->frags[i].size;
+				dma_unmap_page(ld->dev, addr, len,
+					       DMA_TO_DEVICE);
+			}
+		}
+
+		ld->sg_tail = (ld->sg_tail + 1) % ld->sg_count;
+	}
+
+#ifdef HIGMAC_TSO_DEBUG
+	pkt_rec[id_free].status = 0;
+	id_free++;
+	if (id_free == MAX_RECORD)
+		id_free = 0;
+#endif
+
+	return 0;
+}
+
+static void higmac_xmit_reclaim(struct net_device *dev)
+{
+	struct sk_buff *skb;
+	struct higmac_desc *desc;
+	struct higmac_tso_desc *tso_desc;
+	struct higmac_netdev_local *priv = netdev_priv(dev);
+	unsigned int bytes_compl = 0, pkts_compl = 0;
+	u32 start, end, num, pos, i;
+	dma_addr_t addr;
+	int ret;
+
+	spin_lock(&priv->txlock);
+
+	/* software read */
+	start = dma_cnt(readl(priv->gmac_iobase + TX_RQ_RD_ADDR));
+	/* logic write */
+	end = dma_cnt(readl(priv->gmac_iobase + TX_RQ_WR_ADDR));
+	num = CIRC_CNT(end, start, TX_DESC_NUM);
+
+	for (i = 0, pos = start; i < num; i++) {
+		skb = priv->tx_skb[pos];
+		if (unlikely(!skb)) {
+			netdev_err(dev, "inconsistent tx_skb\n");
+			break;
+		}
+
+		if (skb != priv->tx_bq.skb[pos]) {
+			netdev_err(dev, "wired, tx skb[%d](%p) != skb(%p)\n",
+				   pos, priv->tx_bq.skb[pos], skb);
+			if (priv->tx_bq.skb[pos] == SKB_MAGIC)
+				goto next;
+		}
+
+		pkts_compl++;
+		bytes_compl += skb->len;
+		desc = priv->tx_rq.desc + pos;
+		if (priv->tso_supported) {
+			tso_desc = (struct higmac_tso_desc *)desc;
+			ret = higmac_xmit_release_gso(priv, tso_desc, pos);
+			if (ret < 0)
+				break;
+		} else if (!HAS_CAP_CCI(priv->hw_cap)) {
+			addr = desc->data_buff_addr;
+			dma_unmap_single(priv->dev, addr, skb->len,
+					 DMA_TO_DEVICE);
+		}
+		priv->tx_bq.skb[pos] = NULL;
+next:
+		priv->tx_skb[pos] = NULL;
+		dev_consume_skb_any(skb);
+		pos = dma_ring_incr(pos, TX_DESC_NUM);
+	}
+
+	if (pos != start)
+		writel(dma_byte(pos), priv->gmac_iobase + TX_RQ_RD_ADDR);
+
+	if (pkts_compl || bytes_compl)
+		netdev_completed_queue(dev, pkts_compl, bytes_compl);
+
+	if (unlikely(netif_queue_stopped(priv->netdev)) && pkts_compl)
+		netif_wake_queue(priv->netdev);
+
+	spin_unlock(&priv->txlock);
+}
+
+static int higmac_poll(struct napi_struct *napi, int budget)
+{
+	struct higmac_napi *q_napi = container_of(napi,
+					struct higmac_napi, napi);
+	struct higmac_netdev_local *priv = q_napi->ndev_priv;
+	struct net_device *dev = priv->netdev;
+	int work_done = 0, task = budget;
+	u32 ints, num;
+	u32 raw_int_reg, raw_int_mask;
+
+	if (q_napi->rxq_id) {
+		raw_int_reg = RSS_RAW_PMU_INT;
+		raw_int_mask = DEF_INT_MASK_QUEUE(q_napi->rxq_id);
+	} else {
+		raw_int_reg = RAW_PMU_INT;
+		raw_int_mask = DEF_INT_MASK;
+	}
+
+	do {
+		if (!q_napi->rxq_id)
+			higmac_xmit_reclaim(dev);
+		num = higmac_rx(dev, task, q_napi->rxq_id);
+		work_done += num;
+		task -= num;
+		if (work_done >= budget)
+			break;
+
+		ints = readl(priv->gmac_iobase + raw_int_reg);
+		ints &= raw_int_mask;
+		writel(ints, priv->gmac_iobase + raw_int_reg);
+	} while (ints);
+
+	if (work_done < budget) {
+		napi_complete(napi);
+		higmac_irq_enable_queue(priv, q_napi->rxq_id);
+	}
+
+	return work_done;
+}
+
+static irqreturn_t higmac_interrupt(int irq, void *dev_id)
+{
+	struct higmac_napi *q_napi = (struct higmac_napi *)dev_id;
+	struct higmac_netdev_local *ld = q_napi->ndev_priv;
+	u32 ints;
+	u32 raw_int_reg, raw_int_mask;
+
+	if (higmac_queue_irq_disabled(ld, q_napi->rxq_id))
+		return IRQ_NONE;
+
+	if (q_napi->rxq_id) {
+		raw_int_reg = RSS_RAW_PMU_INT;
+		raw_int_mask = DEF_INT_MASK_QUEUE(q_napi->rxq_id);
+	} else {
+		raw_int_reg = RAW_PMU_INT;
+		raw_int_mask = DEF_INT_MASK;
+	}
+
+	ints = readl(ld->gmac_iobase + raw_int_reg);
+	ints &= raw_int_mask;
+	writel(ints, ld->gmac_iobase + raw_int_reg);
+
+	if (likely(ints)) {
+		higmac_irq_disable_queue(ld, q_napi->rxq_id);
+		napi_schedule(&q_napi->napi);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static inline __be16 higmac_get_l3_proto(struct sk_buff *skb)
+{
+	__be16 l3_proto;
+
+	l3_proto = skb->protocol;
+	if (skb->protocol == htons(ETH_P_8021Q))
+		l3_proto = vlan_get_protocol(skb);
+
+	return l3_proto;
+}
+
+static inline unsigned int higmac_get_l4_proto(struct sk_buff *skb)
+{
+	__be16 l3_proto;
+	unsigned int l4_proto = IPPROTO_MAX;
+
+	l3_proto = higmac_get_l3_proto(skb);
+	if (l3_proto == htons(ETH_P_IP))
+		l4_proto = ip_hdr(skb)->protocol;
+	else if (l3_proto == htons(ETH_P_IPV6))
+		l4_proto = ipv6_hdr(skb)->nexthdr;
+
+	return l4_proto;
+}
+
+static inline bool higmac_skb_is_ipv6(struct sk_buff *skb)
+{
+	return (higmac_get_l3_proto(skb) == htons(ETH_P_IPV6));
+}
+
+static inline bool higmac_skb_is_udp(struct sk_buff *skb)
+{
+	return (higmac_get_l4_proto(skb) == IPPROTO_UDP);
+}
+
+static int higmac_check_hw_capability_for_udp(struct sk_buff *skb)
+{
+	struct ethhdr *eth;
+
+	/* hardware can't dea with UFO broadcast packet */
+	eth = (struct ethhdr *)(skb->data);
+	if (skb_is_gso(skb) && is_broadcast_ether_addr(eth->h_dest))
+		return -ENOTSUPP;
+
+	return 0;
+}
+
+static int higmac_check_hw_capability_for_ipv6(struct sk_buff *skb)
+{
+	unsigned int l4_proto = IPPROTO_MAX;
+
+	l4_proto = ipv6_hdr(skb)->nexthdr;
+
+	if ((l4_proto != IPPROTO_TCP) && (l4_proto != IPPROTO_UDP)) {
+		/* when IPv6 next header is not tcp or udp,
+		 * it means that IPv6 next header is extension header.
+		 * Hardware can't deal with this case,
+		 * so do checksumming by software or do GSO by software.
+		 */
+		if (skb_is_gso(skb))
+			return -ENOTSUPP;
+
+		if (skb->ip_summed == CHECKSUM_PARTIAL &&
+		    skb_checksum_help(skb))
+			return -EFAULT;
+	}
+
+	return 0;
+}
+
+static inline bool higmac_skb_is_ipv4_with_options(struct sk_buff *skb)
+{
+	return ((higmac_get_l3_proto(skb) == htons(ETH_P_IP)) &&
+		(ip_hdr(skb)->ihl > 5));
+}
+
+static int higmac_check_hw_capability(struct sk_buff *skb)
+{
+	int ret = 0;
+
+	/* if tcp_mtu_probe() use (2 * tp->mss_cache) as probe_size,
+	 * the linear data length will be larger than 2048,
+	 * the MAC can't handle it, so let the software do it.
+	 */
+	if (skb_is_gso(skb) && (skb_headlen(skb) > 2048))
+		return -ENOTSUPP;
+
+	if (higmac_skb_is_ipv6(skb)) {
+		ret = higmac_check_hw_capability_for_ipv6(skb);
+		if (ret)
+			return ret;
+	}
+
+	if (higmac_skb_is_udp(skb)) {
+		ret = higmac_check_hw_capability_for_udp(skb);
+		if (ret)
+			return ret;
+	}
+
+	if (((skb->ip_summed == CHECKSUM_PARTIAL) || skb_is_gso(skb)) &&
+	    higmac_skb_is_ipv4_with_options(skb))
+		return -ENOTSUPP;
+
+	return 0;
+}
+
+static void higmac_do_udp_checksum(struct sk_buff *skb)
+{
+	int offset;
+	__wsum csum;
+	__sum16 udp_csum;
+
+	offset = skb_checksum_start_offset(skb);
+	WARN_ON(offset >= skb_headlen(skb));
+	csum = skb_checksum(skb, offset, skb->len - offset, 0);
+
+	offset += skb->csum_offset;
+	WARN_ON(offset + sizeof(__sum16) > skb_headlen(skb));
+	udp_csum = csum_fold(csum);
+	if (udp_csum == 0)
+		udp_csum = CSUM_MANGLED_0;
+
+	*(__sum16 *)(skb->data + offset) = udp_csum;
+
+	skb->ip_summed = CHECKSUM_NONE;
+}
+
+static void higmac_get_pkt_info(struct higmac_netdev_local *ld,
+				struct sk_buff *skb,
+				struct higmac_tso_desc *tx_bq_desc)
+{
+	int nfrags = skb_shinfo(skb)->nr_frags;
+
+	__be16 l3_proto;	/* level 3 protocol */
+	unsigned int l4_proto = IPPROTO_MAX;
+	unsigned int max_mss = ETH_DATA_LEN;
+	unsigned char coe_enable = 0;
+	int max_data_len = skb->len - ETH_HLEN;
+
+	if (likely(skb->ip_summed == CHECKSUM_PARTIAL))
+		coe_enable = 1;
+
+	tx_bq_desc->desc1.val = 0;
+
+	if (skb_is_gso(skb)) {
+		tx_bq_desc->desc1.tx.tso_flag = 1;
+		tx_bq_desc->desc1.tx.sg_flag = 1;
+	} else if (nfrags) {
+		tx_bq_desc->desc1.tx.sg_flag = 1;
+	}
+
+	l3_proto = skb->protocol;
+	if (skb->protocol == htons(ETH_P_8021Q)) {
+		l3_proto = vlan_get_protocol(skb);
+		tx_bq_desc->desc1.tx.vlan_flag = 1;
+		max_data_len -= VLAN_HLEN;
+	}
+
+	if (l3_proto == htons(ETH_P_IP)) {
+		struct iphdr *iph;
+
+		iph = ip_hdr(skb);
+		tx_bq_desc->desc1.tx.ip_ver = PKT_IPV4;
+		tx_bq_desc->desc1.tx.ip_hdr_len = iph->ihl;
+
+		if ((max_data_len >= GSO_MAX_SIZE) &&
+		    (ntohs(iph->tot_len) <= (iph->ihl << 2)))
+			iph->tot_len = htons(GSO_MAX_SIZE - 1);
+
+		max_mss -= iph->ihl * WORD_TO_BYTE;
+		l4_proto = iph->protocol;
+	} else if (l3_proto == htons(ETH_P_IPV6)) {
+		tx_bq_desc->desc1.tx.ip_ver = PKT_IPV6;
+		tx_bq_desc->desc1.tx.ip_hdr_len = PKT_IPV6_HDR_LEN;
+		max_mss -= PKT_IPV6_HDR_LEN * WORD_TO_BYTE;
+		l4_proto = ipv6_hdr(skb)->nexthdr;
+	} else {
+		coe_enable = 0;
+	}
+
+	if (l4_proto == IPPROTO_TCP) {
+		tx_bq_desc->desc1.tx.prot_type = PKT_TCP;
+		tx_bq_desc->desc1.tx.prot_hdr_len = tcp_hdr(skb)->doff;
+		max_mss -= tcp_hdr(skb)->doff * WORD_TO_BYTE;
+	} else if (l4_proto == IPPROTO_UDP) {
+		tx_bq_desc->desc1.tx.prot_type = PKT_UDP;
+		tx_bq_desc->desc1.tx.prot_hdr_len = PKT_UDP_HDR_LEN;
+		if (l3_proto == htons(ETH_P_IPV6))
+			max_mss -= sizeof(struct frag_hdr);
+	} else {
+		coe_enable = 0;
+	}
+
+	if (skb_is_gso(skb))
+		tx_bq_desc->desc1.tx.data_len =
+			(skb_shinfo(skb)->gso_size > max_mss) ? max_mss :
+					skb_shinfo(skb)->gso_size;
+	else
+		tx_bq_desc->desc1.tx.data_len = skb->len;
+
+	if (coe_enable && skb_is_gso(skb) && (l4_proto == IPPROTO_UDP))
+		higmac_do_udp_checksum(skb);
+
+	if (coe_enable)
+		tx_bq_desc->desc1.tx.coe_flag = 1;
+
+	tx_bq_desc->desc1.tx.nfrags_num = nfrags;
+
+	tx_bq_desc->desc1.tx.hw_own = DESC_VLD_BUSY;
+}
+
+static int higmac_xmit_gso(struct higmac_netdev_local *ld, struct sk_buff *skb,
+			   struct higmac_tso_desc *tx_bq_desc,
+			   unsigned int desc_pos)
+{
+	int pkt_type = PKT_NORMAL;
+	int nfrags = skb_shinfo(skb)->nr_frags;
+	dma_addr_t addr;
+	int ret;
+
+	if (skb_is_gso(skb) || nfrags) {
+		/* TSO pkt or SG pkt */
+		pkt_type = PKT_SG;
+	} else {		/* Normal pkt */
+		pkt_type = PKT_NORMAL;
+	}
+
+	ret = higmac_check_hw_capability(skb);
+	if (unlikely(ret))
+		return ret;
+
+	higmac_get_pkt_info(ld, skb, tx_bq_desc);
+
+	if (pkt_type == PKT_NORMAL) {
+		if (!HAS_CAP_CCI(ld->hw_cap)) {
+			addr = dma_map_single(ld->dev, skb->data, skb->len,
+					      DMA_TO_DEVICE);
+			ret = dma_mapping_error(ld->dev, addr);
+			if (unlikely(ret)) {
+				pr_err("Normal Packet DMA Mapping fail.\n");
+				return -EFAULT;
+			}
+			tx_bq_desc->data_buff_addr = addr;
+		} else {
+			tx_bq_desc->data_buff_addr = virt_to_phys(skb->data);
+		}
+	} else {
+		struct sg_desc *desc_cur;
+		int i;
+
+		if (unlikely(((ld->sg_head + 1) % ld->sg_count) ==
+			ld->sg_tail)) {
+			/* SG pkt, but sg desc all used */
+			pr_err("WARNING: sg desc all used.\n");
+			return -EBUSY;
+		}
+
+		desc_cur = ld->dma_sg_desc + ld->sg_head;
+
+		/* TODO: deal with ipv6_id */
+		if (tx_bq_desc->desc1.tx.tso_flag &&
+		    tx_bq_desc->desc1.tx.ip_ver == PKT_IPV6 &&
+		    tx_bq_desc->desc1.tx.prot_type == PKT_UDP) {
+			desc_cur->ipv6_id = ntohl(skb_shinfo(skb)->ip6_frag_id);
+		}
+
+		desc_cur->total_len = skb->len;
+		desc_cur->linear_len = skb_headlen(skb);
+		if (!HAS_CAP_CCI(ld->hw_cap)) {
+			addr = dma_map_single(ld->dev, skb->data,
+					      desc_cur->linear_len,
+					      DMA_TO_DEVICE);
+			ret = dma_mapping_error(ld->dev, addr);
+			if (unlikely(ret)) {
+				pr_err("DMA Mapping fail.");
+				return -EFAULT;
+			}
+			desc_cur->linear_addr = addr;
+		} else {
+			desc_cur->linear_addr = virt_to_phys(skb->data);
+		}
+
+		for (i = 0; i < nfrags; i++) {
+			skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
+			int len = frag->size;
+
+			if (!HAS_CAP_CCI(ld->hw_cap)) {
+				addr = skb_frag_dma_map(ld->dev, frag, 0, len,
+							DMA_TO_DEVICE);
+				ret = dma_mapping_error(ld->dev, addr);
+				if (unlikely(ret)) {
+					pr_err("skb frag DMA Mapping fail.");
+					return -EFAULT;
+				}
+				desc_cur->frags[i].addr = addr;
+			} else {
+				desc_cur->frags[i].addr =
+					page_to_phys(skb_frag_page(frag)) +
+					frag->page_offset;
+			}
+			desc_cur->frags[i].size = len;
+		}
+		tx_bq_desc->data_buff_addr = ld->dma_sg_phy +
+			ld->sg_head * sizeof(struct sg_desc);
+		ld->tx_bq.sg_desc_offset[desc_pos] = ld->sg_head;
+
+		ld->sg_head = (ld->sg_head + 1) % ld->sg_count;
+	}
+
+#ifdef HIGMAC_TSO_DEBUG
+	memcpy(&pkt_rec[id_send].desc, tx_bq_desc,
+	       sizeof(struct higmac_tso_desc));
+	pkt_rec[id_send].status = 1;
+	id_send++;
+	if (id_send == MAX_RECORD)
+		id_send = 0;
+#endif
+	return 0;
+}
+
+static netdev_tx_t higmac_net_xmit(struct sk_buff *skb, struct net_device *dev);
+
+static netdev_tx_t higmac_sw_gso(struct higmac_netdev_local *ld,
+				 struct sk_buff *skb)
+{
+	struct sk_buff *segs, *curr_skb;
+	int gso_segs = skb_shinfo(skb)->gso_segs;
+
+	if (gso_segs == 0 && skb_shinfo(skb)->gso_size != 0)
+		gso_segs = DIV_ROUND_UP(skb->len, skb_shinfo(skb)->gso_size);
+
+	/* Estimate the number of fragments in the worst case */
+	if (unlikely(higmac_tx_avail(ld) < gso_segs)) {
+		netif_stop_queue(ld->netdev);
+		if (higmac_tx_avail(ld) < gso_segs) {
+			ld->netdev->stats.tx_dropped++;
+			ld->netdev->stats.tx_fifo_errors++;
+			return NETDEV_TX_BUSY;
+		}
+
+		netif_wake_queue(ld->netdev);
+	}
+
+	segs = skb_gso_segment(skb, ld->netdev->features & ~(NETIF_F_CSUM_MASK |
+					NETIF_F_SG | NETIF_F_GSO_SOFTWARE));
+
+	if (IS_ERR_OR_NULL(segs))
+		goto drop;
+
+	do {
+		curr_skb = segs;
+		segs = segs->next;
+		curr_skb->next = NULL;
+		higmac_net_xmit(curr_skb, ld->netdev);
+	} while (segs);
+
+	dev_kfree_skb_any(skb);
+	return NETDEV_TX_OK;
+
+drop:
+	dev_kfree_skb_any(skb);
+	ld->netdev->stats.tx_dropped++;
+	return NETDEV_TX_OK;
+}
+
+static netdev_tx_t higmac_net_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct higmac_netdev_local *ld = netdev_priv(dev);
+	struct higmac_desc *desc;
+	dma_addr_t addr;
+	unsigned long txflags;
+	int ret;
+	u32 pos;
+
+	if (skb->len < ETH_HLEN) {
+		dev_kfree_skb_any(skb);
+		dev->stats.tx_errors++;
+		dev->stats.tx_dropped++;
+		return NETDEV_TX_OK;
+	}
+
+	/* if adding higmac_xmit_reclaim here, iperf tcp client
+	 * performance will be affected, from 550M(avg) to 513M~300M
+	 */
+
+	/* software write pointer */
+	pos = dma_cnt(readl(ld->gmac_iobase + TX_BQ_WR_ADDR));
+
+	spin_lock_irqsave(&ld->txlock, txflags);
+
+	if (unlikely(ld->tx_skb[pos] || ld->tx_bq.skb[pos])) {
+		dev->stats.tx_dropped++;
+		dev->stats.tx_fifo_errors++;
+		netif_stop_queue(dev);
+		spin_unlock_irqrestore(&ld->txlock, txflags);
+
+		return NETDEV_TX_BUSY;
+	}
+
+	ld->tx_bq.skb[pos] = skb;
+	ld->tx_skb[pos] = skb;
+
+	desc = ld->tx_bq.desc + pos;
+
+	if (ld->tso_supported) {
+		ret = higmac_xmit_gso(ld, skb,
+				      (struct higmac_tso_desc *)desc,
+				      pos);
+		if (unlikely(ret < 0)) {
+			ld->tx_skb[pos] = NULL;
+			ld->tx_bq.skb[pos] = NULL;
+			spin_unlock_irqrestore(&ld->txlock, txflags);
+
+			if (ret == -ENOTSUPP)
+				return higmac_sw_gso(ld, skb);
+
+			dev_kfree_skb_any(skb);
+			dev->stats.tx_dropped++;
+			return NETDEV_TX_OK;
+		}
+	} else {
+		if (!HAS_CAP_CCI(ld->hw_cap)) {
+			addr = dma_map_single(ld->dev, skb->data, skb->len,
+					      DMA_TO_DEVICE);
+			if (unlikely(dma_mapping_error(ld->dev, addr))) {
+				dev_kfree_skb_any(skb);
+				dev->stats.tx_dropped++;
+				ld->tx_skb[pos] = NULL;
+				ld->tx_bq.skb[pos] = NULL;
+				spin_unlock_irqrestore(&ld->txlock, txflags);
+				return NETDEV_TX_OK;
+			}
+			desc->data_buff_addr = addr;
+		} else {
+			desc->data_buff_addr = virt_to_phys(skb->data);
+		}
+		desc->buffer_len = HIETH_MAX_FRAME_SIZE - 1;
+		desc->data_len = skb->len;
+		desc->fl = DESC_FL_FULL;
+		desc->descvid = DESC_VLD_BUSY;
+	}
+
+	/* This barrier is important here.  It is required to ensure
+	 * the ARM CPU flushes it's DMA write buffers before proceeding
+	 * to the next instruction, to ensure that GMAC will see
+	 * our descriptor changes in memory
+	 */
+	HIGMAC_SYNC_BARRIER();
+
+	pos = dma_ring_incr(pos, TX_DESC_NUM);
+	writel(dma_byte(pos), ld->gmac_iobase + TX_BQ_WR_ADDR);
+
+	netif_trans_update(dev);
+	dev->stats.tx_packets++;
+	dev->stats.tx_bytes += skb->len;
+	netdev_sent_queue(dev, skb->len);
+
+	spin_unlock_irqrestore(&ld->txlock, txflags);
+
+	return NETDEV_TX_OK;
+}
+
+void higmac_enable_napi(struct higmac_netdev_local *priv)
+{
+	struct higmac_napi *q_napi;
+	int i;
+
+	for (i = 0; i < priv->num_rxqs; i++) {
+		q_napi = &priv->q_napi[i];
+		napi_enable(&q_napi->napi);
+	}
+}
+
+void higmac_disable_napi(struct higmac_netdev_local *priv)
+{
+	struct higmac_napi *q_napi;
+	int i;
+
+	for (i = 0; i < priv->num_rxqs; i++) {
+		q_napi = &priv->q_napi[i];
+		napi_disable(&q_napi->napi);
+	}
+}
+
+static int higmac_net_open(struct net_device *dev)
+{
+	struct higmac_netdev_local *ld = netdev_priv(dev);
+	unsigned long flags;
+
+	clk_prepare_enable(ld->macif_clk);
+	clk_prepare_enable(ld->clk);
+
+	/* If we configure mac address by
+	 * "ifconfig ethX hw ether XX:XX:XX:XX:XX:XX",
+	 * the ethX must be down state and mac core clock is disabled
+	 * which results the mac address has not been configured
+	 * in mac core register.
+	 * So we must set mac address again here,
+	 * because mac core clock is enabled at this time
+	 * and we can configure mac address to mac core register.
+	 */
+	higmac_hw_set_mac_addr(dev);
+
+	/* We should use netif_carrier_off() here,
+	 * because the default state should be off.
+	 * And this call should before phy_start().
+	 */
+	netif_carrier_off(dev);
+	higmac_enable_napi(ld);
+	phy_start(ld->phy);
+
+	higmac_hw_desc_enable(ld);
+	higmac_port_enable(ld);
+	higmac_irq_enable_all_queue(ld);
+
+	spin_lock_irqsave(&ld->rxlock, flags);
+	higmac_rx_refill(ld);
+	spin_unlock_irqrestore(&ld->rxlock, flags);
+
+	ld->monitor.expires = jiffies + HIGMAC_MONITOR_TIMER;
+	mod_timer(&ld->monitor, ld->monitor.expires);
+
+	netif_start_queue(dev);
+
+	return 0;
+}
+
+static int higmac_net_close(struct net_device *dev)
+{
+	struct higmac_netdev_local *ld = netdev_priv(dev);
+
+	higmac_irq_disable_all_queue(ld);
+	higmac_hw_desc_disable(ld);
+
+	higmac_disable_napi(ld);
+
+	netif_carrier_off(dev);
+	netif_stop_queue(dev);
+
+	phy_stop(ld->phy);
+	del_timer_sync(&ld->monitor);
+
+	clk_disable_unprepare(ld->clk);
+	clk_disable_unprepare(ld->macif_clk);
+
+	return 0;
+}
+
+static void higmac_net_timeout(struct net_device *dev)
+{
+	dev->stats.tx_errors++;
+
+	pr_err("tx timeout!\n");
+}
+
+static void higmac_set_multicast_list(struct net_device *dev)
+{
+	higmac_gmac_multicast_list(dev);
+}
+
+static inline void higmac_enable_rxcsum_drop(struct higmac_netdev_local *ld,
+					     bool drop)
+{
+	unsigned int v;
+
+	v = readl(ld->gmac_iobase + TSO_COE_CTRL);
+	if (drop)
+		v |= COE_ERR_DROP;
+	else
+		v &= ~COE_ERR_DROP;
+	writel(v, ld->gmac_iobase + TSO_COE_CTRL);
+}
+
+static int higmac_set_features(struct net_device *dev,
+			       netdev_features_t features)
+{
+	struct higmac_netdev_local *ld = netdev_priv(dev);
+	netdev_features_t changed = dev->features ^ features;
+
+	if (changed & NETIF_F_RXCSUM) {
+		if (features & NETIF_F_RXCSUM)
+			higmac_enable_rxcsum_drop(ld, true);
+		else
+			higmac_enable_rxcsum_drop(ld, false);
+	}
+
+	return 0;
+}
+
+static struct net_device_stats *higmac_net_get_stats(struct net_device *dev)
+{
+	return &dev->stats;
+}
+
+static void higmac_get_drvinfo(struct net_device *net_dev,
+			       struct ethtool_drvinfo *info)
+{
+	strncpy(info->driver, "higmac driver", 15);
+	strncpy(info->version, "higmac v200", 15);
+	strncpy(info->bus_info, "platform", 15);
+}
+
+static unsigned int higmac_get_link(struct net_device *net_dev)
+{
+	struct higmac_netdev_local *ld = netdev_priv(net_dev);
+
+	return ld->phy->link ? HIGMAC_LINKED : 0;
+}
+
+static int higmac_get_settings(struct net_device *net_dev,
+			       struct ethtool_cmd *cmd)
+{
+	struct higmac_netdev_local *ld = netdev_priv(net_dev);
+
+	if (ld->phy)
+		return phy_ethtool_gset(ld->phy, cmd);
+
+	return -EINVAL;
+}
+
+static int higmac_set_settings(struct net_device *net_dev,
+			       struct ethtool_cmd *cmd)
+{
+	struct higmac_netdev_local *ld = netdev_priv(net_dev);
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (ld->phy)
+		return phy_ethtool_sset(ld->phy, cmd);
+
+	return -EINVAL;
+}
+
+static void higmac_get_pauseparam(struct net_device *net_dev,
+				  struct ethtool_pauseparam *pause)
+{
+	struct higmac_netdev_local *ld = netdev_priv(net_dev);
+
+	pause->rx_pause = 0;
+	pause->tx_pause = 0;
+	pause->autoneg = ld->phy->autoneg;
+
+	if (ld->flow_ctrl & FLOW_RX)
+		pause->rx_pause = 1;
+	if (ld->flow_ctrl & FLOW_TX)
+		pause->tx_pause = 1;
+}
+
+static int higmac_set_pauseparam(struct net_device *net_dev,
+				 struct ethtool_pauseparam *pause)
+{
+	struct higmac_netdev_local *ld = netdev_priv(net_dev);
+	struct phy_device *phy = ld->phy;
+	int new_pause = FLOW_OFF;
+	int ret = 0;
+
+	if (pause->rx_pause)
+		new_pause |= FLOW_RX;
+	if (pause->tx_pause)
+		new_pause |= FLOW_TX;
+
+	if (new_pause != ld->flow_ctrl)
+		ld->flow_ctrl = new_pause;
+
+	higmac_set_flow_ctrl_state(ld, phy->pause);
+	phy->advertising &= ~SUPPORTED_Pause;
+	if (ld->flow_ctrl)
+		phy->advertising |= SUPPORTED_Pause;
+
+	if (phy->autoneg) {
+		if (netif_running(net_dev))
+			return phy_start_aneg(phy);
+	}
+
+	return ret;
+}
+
+static u32 higmac_ethtool_getmsglevel(struct net_device *ndev)
+{
+	struct higmac_netdev_local *priv = netdev_priv(ndev);
+
+	return priv->msg_enable;
+}
+
+static void higmac_ethtool_setmsglevel(struct net_device *ndev, u32 level)
+{
+	struct higmac_netdev_local *priv = netdev_priv(ndev);
+
+	priv->msg_enable = level;
+}
+
+static u32 higmac_get_rxfh_key_size(struct net_device *ndev)
+{
+	return RSS_HASH_KEY_SIZE;
+}
+
+static u32 higmac_get_rxfh_indir_size(struct net_device *ndev)
+{
+	struct higmac_netdev_local *priv = netdev_priv(ndev);
+
+	return priv->rss_info.ind_tbl_size;
+}
+
+static int higmac_get_rxfh(struct net_device *ndev, u32 *indir, u8 *hkey,
+			   u8 *hfunc)
+{
+	struct higmac_netdev_local *priv = netdev_priv(ndev);
+	struct higmac_rss_info *rss = &priv->rss_info;
+
+	if (hfunc)
+		*hfunc = ETH_RSS_HASH_TOP;
+
+	if (hkey)
+		memcpy(hkey, rss->key, RSS_HASH_KEY_SIZE);
+
+	if (indir) {
+		int i;
+
+		for (i = 0; i < rss->ind_tbl_size; i++)
+			indir[i] = rss->ind_tbl[i];
+	}
+
+	return 0;
+}
+
+static void higmac_get_rss_key(struct higmac_netdev_local *priv)
+{
+	struct higmac_rss_info *rss = &priv->rss_info;
+	u32 hkey;
+
+	hkey = readl(priv->gmac_iobase + RSS_HASH_KEY);
+	*((u32 *)rss->key) = hkey;
+}
+
+static void higmac_set_rss_key(struct higmac_netdev_local *priv)
+{
+	struct higmac_rss_info *rss = &priv->rss_info;
+
+	writel(*((u32 *)rss->key), priv->gmac_iobase + RSS_HASH_KEY);
+}
+
+static int higmac_wait_rss_ready(struct higmac_netdev_local *priv)
+{
+	void __iomem *base = priv->gmac_iobase;
+	int i, timeout = 10000;
+
+	for (i = 0; !(readl(base + RSS_IND_TBL) & BIT_IND_TBL_READY); i++) {
+		if (i == timeout) {
+			netdev_err(priv->netdev, "wait rss ready timeout!\n");
+			return -ETIMEDOUT;
+		}
+		usleep_range(10, 20);
+	}
+
+	return 0;
+}
+
+static void higmac_config_rss(struct higmac_netdev_local *priv)
+{
+	struct higmac_rss_info *rss = &priv->rss_info;
+	u32 rss_val;
+	int i;
+
+	for (i = 0; i < rss->ind_tbl_size; i++) {
+		if (higmac_wait_rss_ready(priv))
+			break;
+		rss_val = BIT_IND_TLB_WR | (rss->ind_tbl[i] << 8) | i;
+		writel(rss_val, priv->gmac_iobase + RSS_IND_TBL);
+	}
+}
+
+static void higmac_get_rss(struct higmac_netdev_local *priv)
+{
+	struct higmac_rss_info *rss = &priv->rss_info;
+	u32 rss_val;
+	int i;
+
+	for (i = 0; i < rss->ind_tbl_size; i++) {
+		if (higmac_wait_rss_ready(priv))
+			break;
+		writel(i, priv->gmac_iobase + RSS_IND_TBL);
+		if (higmac_wait_rss_ready(priv))
+			break;
+		rss_val = readl(priv->gmac_iobase + RSS_IND_TBL);
+		rss->ind_tbl[i] = (rss_val >> 10) & 0x3;
+	}
+}
+
+static int higmac_set_rxfh(struct net_device *ndev, const u32 *indir,
+			   const u8 *hkey, const u8 hfunc)
+{
+	struct higmac_netdev_local *priv = netdev_priv(ndev);
+	struct higmac_rss_info *rss = &priv->rss_info;
+
+	if (hfunc != ETH_RSS_HASH_NO_CHANGE && hfunc != ETH_RSS_HASH_TOP)
+		return -EOPNOTSUPP;
+
+	if (indir) {
+		int i;
+
+		for (i = 0; i < rss->ind_tbl_size; i++)
+			rss->ind_tbl[i] = indir[i];
+	}
+
+	if (hkey) {
+		memcpy(rss->key, hkey, RSS_HASH_KEY_SIZE);
+		higmac_set_rss_key(priv);
+	}
+
+	higmac_config_rss(priv);
+
+	return 0;
+}
+
+static int higmac_get_rss_hash_opts(struct higmac_netdev_local *priv,
+				    struct ethtool_rxnfc *info)
+{
+	u32 hash_cfg = priv->rss_info.hash_cfg;
+
+	info->data = 0;
+
+	switch (info->flow_type) {
+	case TCP_V4_FLOW:
+		if (hash_cfg & TCPV4_L3_HASH_EN)
+			info->data |= RXH_IP_SRC | RXH_IP_DST;
+		if (hash_cfg & TCPV4_L4_HASH_EN)
+			info->data |= RXH_L4_B_0_1 | RXH_L4_B_2_3;
+		if (hash_cfg & TCPV4_VLAN_HASH_EN)
+			info->data |= RXH_VLAN;
+		break;
+	case TCP_V6_FLOW:
+		if (hash_cfg & TCPV6_L3_HASH_EN)
+			info->data |= RXH_IP_SRC | RXH_IP_DST;
+		if (hash_cfg & TCPV6_L4_HASH_EN)
+			info->data |= RXH_L4_B_0_1 | RXH_L4_B_2_3;
+		if (hash_cfg & TCPV6_VLAN_HASH_EN)
+			info->data |= RXH_VLAN;
+		break;
+	case UDP_V4_FLOW:
+		if (hash_cfg & UDPV4_L3_HASH_EN)
+			info->data |= RXH_IP_SRC | RXH_IP_DST;
+		if (hash_cfg & UDPV4_L4_HASH_EN)
+			info->data |= RXH_L4_B_0_1 | RXH_L4_B_2_3;
+		if (hash_cfg & UDPV4_VLAN_HASH_EN)
+			info->data |= RXH_VLAN;
+		break;
+	case UDP_V6_FLOW:
+		if (hash_cfg & UDPV6_L3_HASH_EN)
+			info->data |= RXH_IP_SRC | RXH_IP_DST;
+		if (hash_cfg & UDPV6_L4_HASH_EN)
+			info->data |= RXH_L4_B_0_1 | RXH_L4_B_2_3;
+		if (hash_cfg & UDPV6_VLAN_HASH_EN)
+			info->data |= RXH_VLAN;
+		break;
+	case IPV4_FLOW:
+		if (hash_cfg & IPV4_L3_HASH_EN)
+			info->data |= RXH_IP_SRC | RXH_IP_DST;
+		if (hash_cfg & IPV4_VLAN_HASH_EN)
+			info->data |= RXH_VLAN;
+		break;
+	case IPV6_FLOW:
+		if (hash_cfg & IPV6_L3_HASH_EN)
+			info->data |= RXH_IP_SRC | RXH_IP_DST;
+		if (hash_cfg & IPV6_VLAN_HASH_EN)
+			info->data |= RXH_VLAN;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int higmac_get_rxnfc(struct net_device *ndev,
+			    struct ethtool_rxnfc *info, u32 *rules)
+{
+	struct higmac_netdev_local *priv = netdev_priv(ndev);
+	int ret = -EOPNOTSUPP;
+
+	switch (info->cmd) {
+	case ETHTOOL_GRXRINGS:
+		info->data = priv->num_rxqs;
+		ret = 0;
+		break;
+	case ETHTOOL_GRXFH:
+		return higmac_get_rss_hash_opts(priv, info);
+	default:
+		break;
+	}
+	return ret;
+}
+
+static void higmac_config_hash_policy(struct higmac_netdev_local *priv)
+{
+	writel(priv->rss_info.hash_cfg, priv->gmac_iobase + RSS_HASH_CONFIG);
+}
+
+static int higmac_set_rss_hash_opts(struct higmac_netdev_local *priv,
+				    struct ethtool_rxnfc *info)
+{
+	u32 hash_cfg = priv->rss_info.hash_cfg;
+
+	netdev_info(priv->netdev, "Set RSS flow type = %d, data = %lld\n",
+		    info->flow_type, info->data);
+
+	if (!(info->data & RXH_IP_SRC) || !(info->data & RXH_IP_DST))
+		return -EINVAL;
+
+	switch (info->flow_type) {
+	case TCP_V4_FLOW:
+		switch (info->data & (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {
+		case 0:
+			hash_cfg &= ~TCPV4_L4_HASH_EN;
+			break;
+		case (RXH_L4_B_0_1 | RXH_L4_B_2_3):
+			hash_cfg |= TCPV4_L4_HASH_EN;
+			break;
+		default:
+			return -EINVAL;
+		}
+		if (info->data & RXH_VLAN)
+			hash_cfg |= TCPV4_VLAN_HASH_EN;
+		else
+			hash_cfg &= ~TCPV4_VLAN_HASH_EN;
+		break;
+	case TCP_V6_FLOW:
+		switch (info->data & (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {
+		case 0:
+			hash_cfg &= ~TCPV6_L4_HASH_EN;
+			break;
+		case (RXH_L4_B_0_1 | RXH_L4_B_2_3):
+			hash_cfg |= TCPV6_L4_HASH_EN;
+			break;
+		default:
+			return -EINVAL;
+		}
+		if (info->data & RXH_VLAN)
+			hash_cfg |= TCPV6_VLAN_HASH_EN;
+		else
+			hash_cfg &= ~TCPV6_VLAN_HASH_EN;
+		break;
+	case UDP_V4_FLOW:
+		switch (info->data & (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {
+		case 0:
+			hash_cfg &= ~UDPV4_L4_HASH_EN;
+			break;
+		case (RXH_L4_B_0_1 | RXH_L4_B_2_3):
+			hash_cfg |= UDPV4_L4_HASH_EN;
+			break;
+		default:
+			return -EINVAL;
+		}
+		if (info->data & RXH_VLAN)
+			hash_cfg |= UDPV4_VLAN_HASH_EN;
+		else
+			hash_cfg &= ~UDPV4_VLAN_HASH_EN;
+		break;
+	case UDP_V6_FLOW:
+		switch (info->data & (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {
+		case 0:
+			hash_cfg &= ~UDPV6_L4_HASH_EN;
+			break;
+		case (RXH_L4_B_0_1 | RXH_L4_B_2_3):
+			hash_cfg |= UDPV6_L4_HASH_EN;
+			break;
+		default:
+			return -EINVAL;
+		}
+		if (info->data & RXH_VLAN)
+			hash_cfg |= UDPV6_VLAN_HASH_EN;
+		else
+			hash_cfg &= ~UDPV6_VLAN_HASH_EN;
+		break;
+	case IPV4_FLOW:
+		if (info->data & (RXH_L4_B_0_1 | RXH_L4_B_2_3))
+			return -EINVAL;
+		if (info->data & RXH_VLAN)
+			hash_cfg |= IPV4_VLAN_HASH_EN;
+		else
+			hash_cfg &= ~IPV4_VLAN_HASH_EN;
+		break;
+	case IPV6_FLOW:
+		if (info->data & (RXH_L4_B_0_1 | RXH_L4_B_2_3))
+			return -EINVAL;
+		if (info->data & RXH_VLAN)
+			hash_cfg |= IPV6_VLAN_HASH_EN;
+		else
+			hash_cfg &= ~IPV6_VLAN_HASH_EN;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	priv->rss_info.hash_cfg = hash_cfg;
+	higmac_config_hash_policy(priv);
+
+	return 0;
+}
+
+static int higmac_set_rxnfc(struct net_device *ndev, struct ethtool_rxnfc *info)
+{
+	struct higmac_netdev_local *priv = netdev_priv(ndev);
+
+	switch (info->cmd) {
+	case ETHTOOL_SRXFH:
+		return higmac_set_rss_hash_opts(priv, info);
+	default:
+		break;
+	}
+	return -EOPNOTSUPP;
+}
+
+static const struct ethtool_ops hieth_ethtools_ops = {
+	.get_drvinfo = higmac_get_drvinfo,
+	.get_link = higmac_get_link,
+	.get_settings = higmac_get_settings,
+	.set_settings = higmac_set_settings,
+	.get_pauseparam = higmac_get_pauseparam,
+	.set_pauseparam = higmac_set_pauseparam,
+	.get_msglevel = higmac_ethtool_getmsglevel,
+	.set_msglevel = higmac_ethtool_setmsglevel,
+	.get_rxfh_key_size = higmac_get_rxfh_key_size,
+	.get_rxfh_indir_size = higmac_get_rxfh_indir_size,
+	.get_rxfh = higmac_get_rxfh,
+	.set_rxfh = higmac_set_rxfh,
+	.get_rxnfc = higmac_get_rxnfc,
+	.set_rxnfc = higmac_set_rxnfc,
+};
+
+static const struct net_device_ops hieth_netdev_ops = {
+	.ndo_open = higmac_net_open,
+	.ndo_stop = higmac_net_close,
+	.ndo_start_xmit = higmac_net_xmit,
+	.ndo_tx_timeout = higmac_net_timeout,
+	.ndo_set_rx_mode = higmac_set_multicast_list,
+	.ndo_set_features = higmac_set_features,
+	.ndo_do_ioctl = higmac_ioctl,
+	.ndo_set_mac_address = higmac_net_set_mac_address,
+	.ndo_change_mtu = eth_change_mtu,
+	.ndo_get_stats = higmac_net_get_stats,
+};
+
+static int higmac_of_get_param(struct higmac_netdev_local *ld,
+			       struct device_node *node)
+{
+	/* get auto eee */
+	ld->autoeee = of_property_read_bool(node, "autoeee");
+	/* get internal flag */
+	ld->internal_phy =
+		of_property_read_bool(node, "internal-phy");
+
+	return 0;
+}
+
+static int KSZ8051MNL_phy_fix(struct phy_device *phy_dev)
+{
+	u32 v;
+	int ret;
+
+	if (phy_dev->interface != PHY_INTERFACE_MODE_RMII)
+		return 0;
+
+	ret = phy_read(phy_dev, 0x1F);
+	if (ret < 0)
+		return ret;
+	v = ret;
+	v |= (1 << 7);		/* set phy RMII 50MHz clk; */
+	phy_write(phy_dev, 0x1F, v);
+
+	ret = phy_read(phy_dev, 0x16);
+	if (ret < 0)
+		return ret;
+	v = ret;
+	v |= (1 << 1);		/* set phy RMII override; */
+	phy_write(phy_dev, 0x16, v);
+
+	return 0;
+}
+
+static int KSZ8081RNB_phy_fix(struct phy_device *phy_dev)
+{
+	u32 v;
+	int ret;
+
+	if (phy_dev->interface != PHY_INTERFACE_MODE_RMII)
+		return 0;
+
+	ret = phy_read(phy_dev, 0x1F);
+	if (ret < 0)
+		return ret;
+	v = ret;
+	v |= (1 << 7);		/* set phy RMII 50MHz clk; */
+	phy_write(phy_dev, 0x1F, v);
+
+	return 0;
+}
+
+static int rtl8211e_phy_fix(struct phy_device *phy_dev)
+{
+	u32 v;
+	int ret;
+
+	/* select Extension page */
+	phy_write(phy_dev, 0x1f, 0x7);
+	/* switch ExtPage 164 */
+	phy_write(phy_dev, 0x1e, 0xa4);
+
+	/* config RGMII rx pin io driver max */
+	ret = phy_read(phy_dev, 0x1c);
+	if (ret < 0)
+		return ret;
+	v = ret;
+	v = (v & 0xff03) | 0xfc;
+	phy_write(phy_dev, 0x1c, v);
+
+	/* select to page 0 */
+	phy_write(phy_dev, 0x1f, 0);
+
+	return 0;
+}
+
+static void phy_register_fixups(void)
+{
+	phy_register_fixup_for_uid(PHY_ID_KSZ8051MNL, DEFAULT_PHY_MASK,
+				   KSZ8051MNL_phy_fix);
+	phy_register_fixup_for_uid(PHY_ID_KSZ8081RNB, DEFAULT_PHY_MASK,
+				   KSZ8081RNB_phy_fix);
+	phy_register_fixup_for_uid(REALTEK_PHY_ID_8211E, REALTEK_PHY_MASK,
+				   rtl8211e_phy_fix);
+}
+
+static void phy_unregister_fixups(void)
+{
+	phy_unregister_fixup_for_uid(PHY_ID_KSZ8051MNL, DEFAULT_PHY_MASK);
+	phy_unregister_fixup_for_uid(PHY_ID_KSZ8081RNB, DEFAULT_PHY_MASK);
+	phy_unregister_fixup_for_uid(REALTEK_PHY_ID_8211E, REALTEK_PHY_MASK);
+}
+
+static void higmac_verify_flow_ctrl_args(void)
+{
+#if defined(CONFIG_TX_FLOW_CTRL_SUPPORT)
+	flow_ctrl_en |= FLOW_TX;
+#endif
+#if defined(CONFIG_RX_FLOW_CTRL_SUPPORT)
+	flow_ctrl_en |= FLOW_RX;
+#endif
+	if (tx_flow_ctrl_active_threshold < FC_ACTIVE_MIN ||
+	    tx_flow_ctrl_active_threshold > FC_ACTIVE_MAX)
+		tx_flow_ctrl_active_threshold = FC_ACTIVE_DEFAULT;
+
+	if (tx_flow_ctrl_deactive_threshold < FC_DEACTIVE_MIN ||
+	    tx_flow_ctrl_deactive_threshold > FC_DEACTIVE_MAX)
+		tx_flow_ctrl_deactive_threshold = FC_DEACTIVE_DEFAULT;
+
+	if (tx_flow_ctrl_active_threshold >= tx_flow_ctrl_deactive_threshold) {
+		tx_flow_ctrl_active_threshold = FC_ACTIVE_DEFAULT;
+		tx_flow_ctrl_deactive_threshold = FC_DEACTIVE_DEFAULT;
+	}
+
+	if (tx_flow_ctrl_pause_time < 0 ||
+	    tx_flow_ctrl_pause_time > FC_PAUSE_TIME_MAX)
+		tx_flow_ctrl_pause_time = FC_PAUSE_TIME_DEFAULT;
+
+	if (tx_flow_ctrl_pause_interval < 0 ||
+	    tx_flow_ctrl_pause_interval > FC_PAUSE_TIME_MAX)
+		tx_flow_ctrl_pause_interval = FC_PAUSE_INTERVAL_DEFAULT;
+
+	/* pause interval should not bigger than pause time,
+	 * but should not too smaller to avoid sending too many pause frame.
+	 */
+	if ((tx_flow_ctrl_pause_interval > tx_flow_ctrl_pause_time) ||
+	    (tx_flow_ctrl_pause_interval < (tx_flow_ctrl_pause_time >> 1)))
+		tx_flow_ctrl_pause_interval = tx_flow_ctrl_pause_time;
+}
+
+static void higmac_destroy_hw_desc_queue(struct higmac_netdev_local *priv)
+{
+	int i;
+
+	for (i = 0; i < QUEUE_NUMS + RSS_NUM_RXQS - 1; i++) {
+		if (priv->pool[i].desc) {
+			if (HAS_CAP_CCI(priv->hw_cap))
+				kfree(priv->pool[i].desc);
+			else
+				dma_free_coherent(priv->dev, priv->pool[i].size,
+						  priv->pool[i].desc,
+						  priv->pool[i].phys_addr);
+			priv->pool[i].desc = NULL;
+		}
+	}
+
+	kfree(priv->rx_fq.skb);
+	kfree(priv->tx_bq.skb);
+	priv->rx_fq.skb = NULL;
+	priv->tx_bq.skb = NULL;
+
+	if (priv->tso_supported) {
+		kfree(priv->tx_bq.sg_desc_offset);
+		priv->tx_bq.sg_desc_offset = NULL;
+	}
+
+	kfree(priv->tx_skb);
+	priv->tx_skb = NULL;
+
+	kfree(priv->rx_skb);
+	priv->rx_skb = NULL;
+}
+
+static int higmac_init_hw_desc_queue(struct higmac_netdev_local *priv)
+{
+	struct device *dev = priv->dev;
+	struct higmac_desc *virt_addr;
+	dma_addr_t phys_addr = 0;
+	int size, i;
+
+	priv->rx_fq.count = RX_DESC_NUM;
+	priv->rx_bq.count = RX_DESC_NUM;
+	priv->tx_bq.count = TX_DESC_NUM;
+	priv->tx_rq.count = TX_DESC_NUM;
+
+	for (i = 1; i < RSS_NUM_RXQS; i++)
+		priv->pool[3 + i].count = RX_DESC_NUM;
+
+	for (i = 0; i < (QUEUE_NUMS + RSS_NUM_RXQS - 1); i++) {
+		size = priv->pool[i].count * sizeof(struct higmac_desc);
+		if (HAS_CAP_CCI(priv->hw_cap)) {
+			virt_addr = kmalloc(size, GFP_KERNEL);
+			if (virt_addr)
+				phys_addr = virt_to_phys(virt_addr);
+		} else {
+			virt_addr = dma_alloc_coherent(dev, size, &phys_addr,
+						       GFP_KERNEL);
+		}
+		if (!virt_addr)
+			goto error_free_pool;
+
+		memset(virt_addr, 0, size);
+		priv->pool[i].size = size;
+		priv->pool[i].desc = virt_addr;
+		priv->pool[i].phys_addr = phys_addr;
+	}
+	priv->rx_fq.skb = kzalloc(priv->rx_fq.count
+				* sizeof(struct sk_buff *), GFP_KERNEL);
+	if (!priv->rx_fq.skb)
+		goto error_free_pool;
+
+	priv->rx_skb = kzalloc(priv->rx_fq.count
+			     * sizeof(struct sk_buff *), GFP_KERNEL);
+	if (!priv->rx_skb)
+		goto error_free_pool;
+
+	priv->tx_bq.skb = kzalloc(priv->tx_bq.count
+				* sizeof(struct sk_buff *), GFP_KERNEL);
+	if (!priv->tx_bq.skb)
+		goto error_free_pool;
+
+	priv->tx_skb = kzalloc(priv->tx_bq.count
+			     * sizeof(struct sk_buff *), GFP_KERNEL);
+	if (!priv->tx_skb)
+		goto error_free_pool;
+
+	if (priv->tso_supported) {
+		priv->tx_bq.sg_desc_offset = kzalloc(priv->tx_bq.count
+						   * sizeof(int), GFP_KERNEL);
+		if (!priv->tx_bq.sg_desc_offset)
+			goto error_free_pool;
+	}
+
+	higmac_hw_set_desc_addr(priv);
+	if (HAS_CAP_CCI(priv->hw_cap))
+		pr_info("higmac: ETH MAC supporte CCI.\n");
+
+	return 0;
+
+error_free_pool:
+	higmac_destroy_hw_desc_queue(priv);
+
+	return -ENOMEM;
+}
+
+void higmac_init_napi(struct higmac_netdev_local *priv)
+{
+	struct higmac_napi *q_napi;
+	int i;
+
+	for (i = 0; i < priv->num_rxqs; i++) {
+		q_napi = &priv->q_napi[i];
+		q_napi->rxq_id = i;
+		q_napi->ndev_priv = priv;
+		netif_napi_add(priv->netdev, &q_napi->napi, higmac_poll,
+			       NAPI_POLL_WEIGHT);
+	}
+}
+
+void higmac_destroy_napi(struct higmac_netdev_local *priv)
+{
+	struct higmac_napi *q_napi;
+	int i;
+
+	for (i = 0; i < priv->num_rxqs; i++) {
+		q_napi = &priv->q_napi[i];
+		netif_napi_del(&q_napi->napi);
+	}
+}
+
+int higmac_request_irqs(struct platform_device *pdev,
+			struct higmac_netdev_local *priv)
+{
+	struct device *dev = priv->dev;
+	int ret;
+	int i;
+
+	for (i = 0; i < priv->num_rxqs; i++) {
+		ret = platform_get_irq(pdev, i);
+		if (ret < 0) {
+			dev_err(dev, "No irq[%d] resource, ret=%d\n", i, ret);
+			return ret;
+		}
+		priv->irq[i] = ret;
+
+		ret = devm_request_irq(dev, priv->irq[i], higmac_interrupt,
+				       IRQF_SHARED, pdev->name,
+				       &priv->q_napi[i]);
+		if (ret) {
+			dev_err(dev, "devm_request_irq failed, ret=%d\n", ret);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int higmac_dev_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct device_node *node = dev->of_node;
+	struct net_device *ndev;
+	struct higmac_netdev_local *priv;
+	struct resource *res;
+	const char *mac_addr;
+	unsigned int hw_cap;
+	int ret;
+	int num_rxqs;
+
+	higmac_verify_flow_ctrl_args();
+
+	if (of_device_is_compatible(node, "hisilicon,higmac-v5"))
+		num_rxqs = RSS_NUM_RXQS;
+	else
+		num_rxqs = 1;
+
+	ndev = alloc_etherdev_mqs(sizeof(struct higmac_netdev_local), 1,
+				  num_rxqs);
+	if (!ndev)
+		return -ENOMEM;
+
+	platform_set_drvdata(pdev, ndev);
+	SET_NETDEV_DEV(ndev, dev);
+
+	priv = netdev_priv(ndev);
+	priv->dev = dev;
+	priv->netdev = ndev;
+	priv->num_rxqs = num_rxqs;
+
+	if (of_device_is_compatible(node, "hisilicon,higmac-v3"))
+		priv->hw_cap |= HW_CAP_CCI;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, MEM_GMAC_IOBASE);
+	priv->gmac_iobase = devm_ioremap_resource(dev, res);
+	if (IS_ERR(priv->gmac_iobase)) {
+		ret = PTR_ERR(priv->gmac_iobase);
+		goto out_free_netdev;
+	}
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM,
+				    MEM_MACIF_IOBASE);
+	priv->macif_base = devm_ioremap_resource(dev, res);
+	if (IS_ERR(priv->macif_base)) {
+		ret = PTR_ERR(priv->macif_base);
+		goto out_free_netdev;
+	}
+
+	priv->port_rst = devm_reset_control_get(dev, HIGMAC_PORT_RST_NAME);
+	if (IS_ERR(priv->port_rst)) {
+		ret = PTR_ERR(priv->port_rst);
+		goto out_free_netdev;
+	}
+
+	priv->macif_rst = devm_reset_control_get(dev, HIGMAC_MACIF_RST_NAME);
+	if (IS_ERR(priv->macif_rst)) {
+		ret = PTR_ERR(priv->macif_rst);
+		goto out_free_netdev;
+	}
+
+	priv->phy_rst = devm_reset_control_get(dev, HIGMAC_PHY_RST_NAME);
+	if (IS_ERR(priv->phy_rst))
+		priv->phy_rst = NULL;
+
+	priv->clk = devm_clk_get(&pdev->dev, HIGMAC_MAC_CLK_NAME);
+	if (IS_ERR(priv->clk)) {
+		netdev_err(ndev, "failed to get clk\n");
+		ret = -ENODEV;
+		goto out_free_netdev;
+	}
+
+	ret = clk_prepare_enable(priv->clk);
+	if (ret < 0) {
+		netdev_err(ndev, "failed to enable clk %d\n", ret);
+		goto out_free_netdev;
+	}
+
+	priv->macif_clk = devm_clk_get(&pdev->dev, HIGMAC_MACIF_CLK_NAME);
+	if (IS_ERR(priv->macif_clk))
+		priv->macif_clk = NULL;
+
+	if (priv->macif_clk) {
+		ret = clk_prepare_enable(priv->macif_clk);
+		if (ret < 0) {
+			netdev_err(ndev, "failed enable macif_clk %d\n", ret);
+			goto out_clk_disable;
+		}
+	}
+
+	higmac_mac_core_reset(priv);
+
+	/* phy reset, should be early than "of_mdiobus_register".
+	 * becausue "of_mdiobus_register" will read PHY register by MDIO.
+	 */
+	higmac_hw_phy_reset(priv);
+
+	higmac_of_get_param(priv, node);
+
+	ret = of_get_phy_mode(node);
+	if (ret < 0) {
+		netdev_err(ndev, "not find phy-mode\n");
+		goto out_macif_clk_disable;
+	}
+	priv->phy_mode = ret;
+
+	priv->phy_node = of_parse_phandle(node, "phy-handle", 0);
+	if (!priv->phy_node) {
+		netdev_err(ndev, "not find phy-handle\n");
+		ret = -EINVAL;
+		goto out_macif_clk_disable;
+	}
+
+	mac_addr = of_get_mac_address(node);
+	if (mac_addr)
+		ether_addr_copy(ndev->dev_addr, mac_addr);
+	if (!is_valid_ether_addr(ndev->dev_addr)) {
+		eth_hw_addr_random(ndev);
+		netdev_warn(ndev, "using random MAC address %pM\n",
+			    ndev->dev_addr);
+	}
+
+	higmac_hw_set_mac_addr(ndev);
+
+	hw_cap = readl(priv->gmac_iobase + CRF_MIN_PACKET);
+	priv->tso_supported = HAS_TSO_CAP(hw_cap);
+	priv->has_rxhash_cap = HAS_RXHASH_CAP(hw_cap);
+	priv->has_rss_cap = HAS_RSS_CAP(hw_cap);
+
+	higmac_set_rss_cap(priv);
+	higmac_get_rss_key(priv);
+	if (priv->has_rss_cap) {
+		priv->rss_info.ind_tbl_size = RSS_INDIRECTION_TABLE_SIZE;
+		higmac_get_rss(priv);
+	}
+
+	if (priv->has_rxhash_cap) {
+		priv->rss_info.hash_cfg = DEF_HASH_CFG;
+		higmac_config_hash_policy(priv);
+	}
+
+	/* init hw controller */
+	higmac_hw_init(priv);
+
+	/* TODO: phy fix here?? other way ??? */
+	phy_register_fixups();
+
+	priv->phy = of_phy_connect(ndev, priv->phy_node,
+				   &higmac_adjust_link, 0, priv->phy_mode);
+	if (!priv->phy) {
+		ret = -ENODEV;
+		goto out_phy_node;
+	}
+
+	/* If the phy_id is mostly Fs, there is no device there */
+	if ((priv->phy->phy_id & 0x1fffffff) == 0x1fffffff ||
+	    priv->phy->phy_id == 0) {
+		pr_info("phy %d not found\n", priv->phy->mdio.addr);
+		ret = -ENODEV;
+		goto out_phy_disconnect;
+	}
+
+	pr_info("attached PHY %d to driver %s, PHY_ID=0x%x\n",
+		priv->phy->mdio.addr, priv->phy->drv->name, priv->phy->phy_id);
+
+	/* Stop Advertising 1000BASE Capability if interface is not RGMII */
+	if ((priv->phy_mode == PHY_INTERFACE_MODE_MII) ||
+	    (priv->phy_mode == PHY_INTERFACE_MODE_RMII)) {
+		priv->phy->advertising &= ~(SUPPORTED_1000baseT_Half |
+					    SUPPORTED_1000baseT_Full);
+
+		/* Internal FE phy's reg BMSR bit8 is wrong, make the kernel
+		 * believe it has the 1000base Capability, so fix it here
+		 */
+		if (priv->phy->phy_id == HISILICON_PHY_ID_FESTAV200)
+			priv->phy->supported &= ~(ADVERTISED_1000baseT_Full |
+						  ADVERTISED_1000baseT_Half);
+	}
+
+	higmac_set_flow_ctrl_args(priv);
+	higmac_set_flow_ctrl_params(priv);
+	priv->phy->supported |= SUPPORTED_Pause;
+	if (priv->flow_ctrl)
+		priv->phy->advertising |= SUPPORTED_Pause;
+
+	if (priv->autoeee)
+		init_autoeee(priv);
+
+	ret = higmac_request_irqs(pdev, priv);
+	if (ret)
+		goto out_phy_disconnect;
+
+	higmac_init_napi(priv);
+	spin_lock_init(&priv->rxlock);
+	spin_lock_init(&priv->txlock);
+	spin_lock_init(&priv->pmtlock);
+
+	/* init netdevice */
+	ndev->irq = priv->irq[0];
+	ndev->watchdog_timeo = 3 * HZ;
+	ndev->netdev_ops = &hieth_netdev_ops;
+	ndev->ethtool_ops = &hieth_ethtools_ops;
+
+	if (priv->has_rxhash_cap)
+		ndev->hw_features |= NETIF_F_RXHASH;
+	if (priv->has_rss_cap)
+		ndev->hw_features |= NETIF_F_NTUPLE;
+	if (priv->tso_supported) {
+		ndev->hw_features |= NETIF_F_SG |
+			NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM |
+			NETIF_F_TSO | NETIF_F_TSO6 | NETIF_F_UFO;
+	}
+#if defined(CONFIG_HIGMAC_RXCSUM)
+	ndev->hw_features |= NETIF_F_RXCSUM;
+	higmac_enable_rxcsum_drop(priv, true);
+#endif
+
+	ndev->features |= ndev->hw_features;
+	ndev->features |= NETIF_F_HIGHDMA | NETIF_F_GSO;
+	ndev->vlan_features |= ndev->features;
+
+	init_timer(&priv->monitor);
+	priv->monitor.function = higmac_monitor_func;
+	priv->monitor.data = (unsigned long)ndev;
+	priv->monitor.expires = jiffies + HIGMAC_MONITOR_TIMER;
+
+	device_set_wakeup_capable(priv->dev, 1);
+	/* TODO: when we can let phy powerdown?
+	 * In some mode, we don't want phy powerdown,
+	 * so I set wakeup enable all the time
+	 */
+	device_set_wakeup_enable(priv->dev, 1);
+
+	priv->wol_enable = false;
+
+	priv->msg_enable = netif_msg_init(debug, DEFAULT_MSG_ENABLE);
+
+	/* init hw desc queue */
+	ret = higmac_init_hw_desc_queue(priv);
+	if (ret)
+		goto _error_hw_desc_queue;
+
+	if (priv->tso_supported) {
+		ret = higmac_init_sg_desc_queue(priv);
+		if (ret)
+			goto _error_sg_desc_queue;
+	}
+
+	/* register netdevice */
+	ret = register_netdev(priv->netdev);
+	if (ret) {
+		pr_err("register_ndev failed!");
+		goto _error_sg_desc_queue;
+	}
+
+	/* reset queue here to make BQL only reset once.
+	 * if we put netdev_reset_queue() in higmac_net_open(),
+	 * the BQL will be reset when ifconfig eth0 down and up,
+	 * but the tx ring is not cleared before.
+	 * As a result, the NAPI poll will call netdev_completed_queue()
+	 * and BQL throw a bug.
+	 */
+	netdev_reset_queue(ndev);
+
+	clk_disable_unprepare(priv->clk);
+	if (priv->macif_clk)
+		clk_disable_unprepare(priv->macif_clk);
+
+	pr_info("ETH: %s, phy_addr=%d\n",
+		phy_modes(priv->phy_mode), priv->phy->mdio.addr);
+
+	return ret;
+
+_error_sg_desc_queue:
+	if (priv->tso_supported)
+		higmac_destroy_sg_desc_queue(priv);
+
+_error_hw_desc_queue:
+	higmac_destroy_hw_desc_queue(priv);
+	higmac_destroy_napi(priv);
+out_phy_disconnect:
+	phy_disconnect(priv->phy);
+out_phy_node:
+	of_node_put(priv->phy_node);
+out_macif_clk_disable:
+	if (priv->macif_clk)
+		clk_disable_unprepare(priv->macif_clk);
+out_clk_disable:
+	clk_disable_unprepare(priv->clk);
+out_free_netdev:
+	free_netdev(ndev);
+
+	return ret;
+}
+
+static int higmac_dev_remove(struct platform_device *pdev)
+{
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct higmac_netdev_local *priv = netdev_priv(ndev);
+
+	/* TODO: stop the gmac and free all resource */
+	del_timer_sync(&priv->monitor);
+	higmac_destroy_napi(priv);
+
+	unregister_netdev(ndev);
+
+	higmac_reclaim_rx_tx_resource(priv);
+	higmac_free_rx_skb(priv);
+	higmac_free_tx_skb(priv);
+
+	if (priv->tso_supported)
+		higmac_destroy_sg_desc_queue(priv);
+	higmac_destroy_hw_desc_queue(priv);
+
+	phy_disconnect(priv->phy);
+	of_node_put(priv->phy_node);
+
+	free_netdev(ndev);
+
+	phy_unregister_fixups();
+
+	return 0;
+}
+
+#include "pm.c"
+#ifdef CONFIG_PM
+
+static void higmac_disable_irq(struct higmac_netdev_local *priv)
+{
+	int i;
+
+	for (i = 0; i < priv->num_rxqs; i++)
+		disable_irq(priv->irq[i]);
+}
+
+static void higmac_enable_irq(struct higmac_netdev_local *priv)
+{
+	int i;
+
+	for (i = 0; i < priv->num_rxqs; i++)
+		enable_irq(priv->irq[i]);
+}
+
+int higmac_dev_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct higmac_netdev_local *priv = netdev_priv(ndev);
+
+	higmac_disable_irq(priv);
+	/* If support Wake on LAN, we should not disconnect phy
+	 * because it will call phy_suspend to power down phy.
+	 */
+	if (!priv->wol_enable)
+		phy_disconnect(priv->phy);
+	del_timer_sync(&priv->monitor);
+	/* If suspend when netif is not up, the napi_disable will run into
+	 * dead loop and dpm_drv_timeout will give warning.
+	 */
+	if (netif_running(ndev))
+		higmac_disable_napi(priv);
+	netif_device_detach(ndev);
+
+	netif_carrier_off(ndev);
+
+	/* If netdev is down, MAC clock is disabled.
+	 * So if we want to reclaim MAC rx and tx resource,
+	 * we must first enable MAC clock and then disable it.
+	 */
+	if (!(ndev->flags & IFF_UP))
+		clk_prepare_enable(priv->clk);
+
+	higmac_reclaim_rx_tx_resource(priv);
+
+	if (!(ndev->flags & IFF_UP))
+		clk_disable_unprepare(priv->clk);
+
+	pmt_enter(priv);
+
+	if (!priv->wol_enable) {	/* if no WOL, then poweroff */
+		/* pr_info("power off gmac.\n"); */
+		/* no need to call genphy_resume() in resume,
+		 * because we reset everything
+		 */
+		genphy_suspend(priv->phy);	/* power down phy */
+		msleep(20);
+		higmac_hw_all_clk_disable(priv);
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(higmac_dev_suspend);
+
+int higmac_dev_resume(struct platform_device *pdev)
+{
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct higmac_netdev_local *priv = netdev_priv(ndev);
+	int ret = 0;
+
+	/* If we support Wake on LAN, we doesn't call clk_disable.
+	 * But when we resume, the uboot may off mac clock and reset phy
+	 * by re-write the mac CRG register.
+	 * So we first call clk_disable, and then clk_enable.
+	 */
+	if (priv->wol_enable)
+		higmac_hw_all_clk_disable(priv);
+
+	higmac_hw_all_clk_enable(priv);
+	/* internal FE_PHY: enable clk and reset  */
+	higmac_hw_phy_reset(priv);
+
+	/* If netdev is down, MAC clock is disabled.
+	 * So if we want to restart MAC and re-initialize it,
+	 * we must first enable MAC clock and then disable it.
+	 */
+	if (!(ndev->flags & IFF_UP))
+		clk_prepare_enable(priv->clk);
+
+	/* power on gmac */
+	higmac_restart(priv);
+
+	/* If support WoL, we didn't disconnect phy.
+	 * But when we resume, we reset PHY, so we want to
+	 * call phy_connect to make phy_fixup excuted.
+	 * This is important for internal PHY fix.
+	 */
+	if (priv->wol_enable)
+		phy_disconnect(priv->phy);
+
+	ret = phy_connect_direct(ndev, priv->phy, higmac_adjust_link,
+				 priv->phy_mode);
+	if (ret)
+		return ret;
+
+	/* If we suspend and resume when net device is down,
+	 * some operations are unnecessary.
+	 */
+	if (ndev->flags & IFF_UP) {
+		priv->monitor.expires = jiffies + HIGMAC_MONITOR_TIMER;
+		mod_timer(&priv->monitor, priv->monitor.expires);
+		priv->old_link = 0;
+		priv->old_speed = SPEED_UNKNOWN;
+		priv->old_duplex = DUPLEX_UNKNOWN;
+	}
+	if (netif_running(ndev))
+		higmac_enable_napi(priv);
+	netif_device_attach(ndev);
+	if (ndev->flags & IFF_UP)
+		phy_start(priv->phy);
+	higmac_enable_irq(priv);
+
+	pmt_exit(priv);
+
+	if (!(ndev->flags & IFF_UP))
+		clk_disable_unprepare(priv->clk);
+
+	return 0;
+}
+EXPORT_SYMBOL(higmac_dev_resume);
+#else
+#define higmac_dev_suspend	NULL
+#define higmac_dev_resume	NULL
+#endif
+
+static const struct of_device_id higmac_of_match[] = {
+	{.compatible = "hisilicon,higmac",},
+	{.compatible = "hisilicon,higmac-v1",},
+	{.compatible = "hisilicon,higmac-v2",},
+	{.compatible = "hisilicon,higmac-v3",},
+	{.compatible = "hisilicon,higmac-v4",},
+	{.compatible = "hisilicon,higmac-v5",},
+	{ },
+};
+
+MODULE_DEVICE_TABLE(of, higmac_of_match);
+
+static struct platform_driver higmac_dev_driver = {
+	.probe = higmac_dev_probe,
+	.remove = higmac_dev_remove,
+	.suspend = higmac_dev_suspend,
+	.resume = higmac_dev_resume,
+	.driver = {
+		   .owner = THIS_MODULE,
+		   .name = HIGMAC_DRIVER_NAME,
+		   .of_match_table = higmac_of_match,
+		   },
+};
+
+#include "proc-dev.c"
+
+static int __init higmac_init(void)
+{
+	int ret = 0;
+
+	ret = platform_driver_register(&higmac_dev_driver);
+	if (ret)
+		return ret;
+
+	higmac_proc_create();
+
+	return ret;
+}
+
+static void __exit higmac_exit(void)
+{
+	platform_driver_unregister(&higmac_dev_driver);
+
+	higmac_proc_destroy();
+}
+
+module_init(higmac_init);
+module_exit(higmac_exit);
+
+MODULE_AUTHOR("ZMJUN");
+MODULE_DESCRIPTION("Hisilicon double GMAC driver, base on driver higmacv200 by CHH");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/net/ethernet/hisilicon/higmac/higmac.h b/drivers/net/ethernet/hisilicon/higmac/higmac.h
new file mode 100644
index 0000000..2458e0d
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/higmac.h
@@ -0,0 +1,613 @@
+#ifndef __HIGMAC_H__
+#define __HIGMAC_H__
+
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/netdevice.h>
+#include <linux/list.h>
+#include <linux/phy.h>
+#include <linux/io.h>
+#include <linux/interrupt.h>
+
+#define STATION_ADDR_LOW		0x0000
+#define STATION_ADDR_HIGH		0x0004
+#define MAC_DUPLEX_HALF_CTRL		0x0008
+
+#define PORT_MODE			0x0040
+
+#define PORT_EN				0x0044
+#define BITS_TX_EN			BIT(2)
+#define BITS_RX_EN			BIT(1)
+
+#define FC_TX_TIMER			0x001C
+
+#define PAUSE_THR			0x0038
+
+#define PAUSE_EN			0x0048
+#define BIT_RX_FDFC			BIT(0)
+#define BIT_TX_FDFC			BIT(1)
+
+#define RX_PAUSE_EN			0x02A4
+#define BIT_RX_FQ_PAUSE_EN		BIT(0)
+#define BIT_RX_BQ_PAUSE_EN		BIT(1)
+
+#define CRF_TX_PAUSE			0x0340
+
+#define BITS_Q_PAUSE_TH_OFFSET		16
+#define BITS_Q_PAUSE_TH_MASK		0xFFFF
+
+#define REC_FILT_CONTROL		0x0064
+#define BIT_CRC_ERR_PASS		BIT(5)
+#define BIT_PAUSE_FRM_PASS		BIT(4)
+#define BIT_VLAN_DROP_EN		BIT(3)
+#define BIT_BC_DROP_EN			BIT(2)
+#define BIT_MC_MATCH_EN			BIT(1)
+#define BIT_UC_MATCH_EN			BIT(0)
+
+#define	PORT_MC_ADDR_LOW		0x0068
+#define	PORT_MC_ADDR_HIGH		0x006C
+
+#define MODE_CHANGE_EN			0x01b4
+#define BIT_MODE_CHANGE_EN		BIT(0)
+
+#define COL_SLOT_TIME			0x01c0
+
+#define CRF_MIN_PACKET			0x0210
+#define BIT_OFFSET_TX_MIN_LEN		8
+#define BIT_MASK_TX_MIN_LEN		GENMASK(13, 8)
+
+#define CONTROL_WORD			0x0214
+#define CONTROL_WORD_CONFIG		0x640
+
+#define TSO_COE_CTRL			0x02e8
+#define BIT_COE_IPHDR_DROP		BIT(4)
+#define BIT_COE_PAYLOAD_DROP		BIT(5)
+#define BIT_COE_IPV6_UDP_ZERO_DROP	BIT(6)
+#define COE_ERR_DROP			(BIT_COE_IPHDR_DROP | \
+					BIT_COE_PAYLOAD_DROP | \
+					BIT_COE_IPV6_UDP_ZERO_DROP)
+
+#define RX_FQ_START_ADDR		0x0500
+#define RX_FQ_DEPTH			0x0504
+#define RX_FQ_WR_ADDR			0x0508
+#define BITS_RX_FQ_WR_ADDR		MK_BITS(0, 21)
+#define RX_FQ_RD_ADDR			0x050c
+#define BITS_RX_FQ_RD_ADDR		MK_BITS(0, 21)
+#define RX_FQ_VLDDESC_CNT		0x0510
+#define BITS_RX_FQ_VLDDESC_CNT		MK_BITS(0, 16)
+#define RX_FQ_ALEMPTY_TH		0x0514
+#define BITS_RX_FQ_ALEMPTY_TH		MK_BITS(0, 16)
+#define RX_FQ_REG_EN			0x0518
+#define BITS_RX_FQ_START_ADDR_EN	BIT(2)
+#define BITS_RX_FQ_DEPTH_EN		BIT(1)
+#define BITS_RX_FQ_RD_ADDR_EN		MK_BITS(0, 1)
+#define RX_FQ_ALFULL_TH			0x051c
+#define BITS_RX_FQ_ALFULL_TH		MK_BITS(0, 16)
+
+#define RX_BQ_START_ADDR		0x0520
+#define RX_BQ_DEPTH			0x0524
+#define RX_BQ_WR_ADDR			0x0528
+#define RX_BQ_RD_ADDR			0x052c
+#define RX_BQ_FREE_DESC_CNT		0x0530
+#define BITS_RX_BQ_FREE_DESC_CNT	MK_BITS(0, 16)
+#define RX_BQ_ALEMPTY_TH		0x0534
+#define BITS_RX_BQ_ALEMPTY_TH		MK_BITS(0, 16)
+#define RX_BQ_REG_EN			0x0538
+#define BITS_RX_BQ_START_ADDR_EN	BIT(2)
+#define BITS_RX_BQ_DEPTH_EN		BIT(1)
+#define BITS_RX_BQ_WR_ADDR_EN		MK_BITS(0, 1)
+#define RX_BQ_ALFULL_TH			0x053c
+#define BITS_RX_BQ_ALFULL_TH		MK_BITS(0, 16)
+
+#define TX_BQ_START_ADDR		0x0580
+#define TX_BQ_DEPTH			0x0584
+#define TX_BQ_WR_ADDR			0x0588
+#define BITS_TX_BQ_WR_ADDR		MK_BITS(0, 21)
+#define TX_BQ_RD_ADDR			0x058c
+#define BITS_TX_BQ_RD_ADDR		MK_BITS(0, 21)
+#define TX_BQ_VLDDESC_CNT		0x0590
+#define BITS_TX_BQ_VLDDESC_CNT		MK_BITS(0, 16)
+#define TX_BQ_ALEMPTY_TH		0x0594
+#define BITS_TX_BQ_ALEMPTY_TH		MK_BITS(0, 16)
+#define TX_BQ_REG_EN			0x0598
+#define BITS_TX_BQ_START_ADDR_EN	BIT(2)
+#define BITS_TX_BQ_DEPTH_EN		BIT(1)
+#define BITS_TX_BQ_RD_ADDR_EN		MK_BITS(0, 1)
+#define TX_BQ_ALFULL_TH			0x059c
+#define BITS_TX_BQ_ALFULL_TH		MK_BITS(0, 16)
+
+#define TX_RQ_START_ADDR		0x05a0
+#define TX_RQ_DEPTH			0x05a4
+#define TX_RQ_WR_ADDR			0x05a8
+#define BITS_TX_RQ_WR_ADDR		MK_BITS(0, 21)
+#define TX_RQ_RD_ADDR			0x05ac
+#define BITS_TX_RQ_RD_ADDR		MK_BITS(0, 21)
+#define TX_RQ_FREE_DESC_CNT		0x05b0
+#define BITS_TX_RQ_FREE_DESC_CNT	MK_BITS(0, 16)
+#define TX_RQ_ALEMPTY_TH		0x05b4
+#define BITS_TX_RQ_ALEMPTY_TH		MK_BITS(0, 16)
+#define TX_RQ_REG_EN			0x05b8
+#define BITS_TX_RQ_START_ADDR_EN	BIT(2)
+#define BITS_TX_RQ_DEPTH_EN		BIT(1)
+#define BITS_TX_RQ_WR_ADDR_EN		MK_BITS(0, 1)
+#define TX_RQ_ALFULL_TH			0x05bc
+#define BITS_TX_RQ_ALFULL_TH		MK_BITS(0, 16)
+
+#define RAW_PMU_INT			0x05c0
+#define ENA_PMU_INT			0x05c4
+
+#define DESC_WR_RD_ENA					0x05CC
+
+#define IN_QUEUE_TH					0x05d8
+#define BITS_OFFSET_TX_RQ_IN_TH				16
+
+#define RX_BQ_IN_TIMEOUT_TH				0x05E0
+
+#define TX_RQ_IN_TIMEOUT_TH				0x05e4
+
+#define STOP_CMD			0x05e8
+#define BITS_TX_STOP_EN			BIT(1)
+#define BITS_RX_STOP_EN			BIT(0)
+#define	STOP_RX_TX			(BITS_TX_STOP_EN | BITS_RX_STOP_EN)
+
+#define HW_CAP_EN			0x0c00
+#define BIT_RSS_CAP			BIT(0)
+#define BIT_RXHASH_CAP			BIT(1)
+#define RSS_HASH_KEY			0x0c04
+#define RSS_HASH_CONFIG			0x0c08
+#define TCPV4_L3_HASH_EN		BIT(0)
+#define TCPV4_L4_HASH_EN		BIT(1)
+#define TCPV4_VLAN_HASH_EN		BIT(2)
+#define UDPV4_L3_HASH_EN		BIT(4)
+#define UDPV4_L4_HASH_EN		BIT(5)
+#define UDPV4_VLAN_HASH_EN		BIT(6)
+#define IPV4_L3_HASH_EN			BIT(8)
+#define IPV4_VLAN_HASH_EN		BIT(9)
+#define TCPV6_L3_HASH_EN		BIT(12)
+#define TCPV6_L4_HASH_EN		BIT(13)
+#define TCPV6_VLAN_HASH_EN		BIT(14)
+#define UDPV6_L3_HASH_EN		BIT(16)
+#define UDPV6_L4_HASH_EN		BIT(17)
+#define UDPV6_VLAN_HASH_EN		BIT(18)
+#define IPV6_L3_HASH_EN			BIT(20)
+#define IPV6_VLAN_HASH_EN		BIT(21)
+#define DEF_HASH_CFG			0x377377
+
+#define RSS_IND_TBL			0x0c0c
+#define BIT_IND_TBL_READY		BIT(13)
+#define BIT_IND_TLB_WR			BIT(12)
+#define RSS_RAW_PMU_INT			0x0c10
+#define RSS_QUEUE1_START_ADDR		0x0c20
+#define RX_BQ_START_ADDR_QUEUE(i)	(RSS_QUEUE1_START_ADDR + \
+					((i) - 1) * 0x10)
+#define RSS_QUEUE1_DEPTH		0x0c24
+#define RX_BQ_WR_ADDR_QUEUE1		0x0c28
+#define RX_BQ_RD_ADDR_QUEUE1		0x0c2c
+#define RSS_QUEUE1_ENA_INT		0x0c90
+#define RSS_ENA_INT_QUEUE(i)		(RSS_QUEUE1_ENA_INT + ((i) - 1) * 0x4)
+#define RX_BQ_DEPTH_QUEUE(i)		(RSS_QUEUE1_DEPTH + ((i) - 1) * 0x10)
+#define RX_BQ_WR_ADDR_QUEUE(i)		((i) ? (RX_BQ_WR_ADDR_QUEUE1 + \
+					((i) - 1) * 0x10) : RX_BQ_WR_ADDR)
+#define RX_BQ_RD_ADDR_QUEUE(i)		((i) ? (RX_BQ_RD_ADDR_QUEUE1 + \
+					((i) - 1) * 0x10) : RX_BQ_RD_ADDR)
+
+#define DEF_INT_MASK_QUEUE(i)		(0x3 << (2 * ((i) - 1)))
+
+/* AXI burst and outstanding config */
+#define BURST_OUTSTANDING_REG		0x3014
+#define BURST4_OUTSTANDING1		0x81ff
+#define BURST_OUTSTANDING_OFFSET	16
+
+#define GMAC_SPEED_1000			0x05
+#define GMAC_SPEED_100			0x01
+#define GMAC_SPEED_10			0x00
+
+enum higmac_tx_err {
+	ERR_NONE = 0,
+	ERR_DESC_CFG = (1 << 0),
+	ERR_DATA_LEN = (1 << 1),
+	ERR_DESC_NFRAG_NUM = (1 << 2),
+	ERR_DESC_IP_HDR_LEN = (1 << 3),
+	ERR_DESC_PROT_HDR_LEN = (1 << 4),
+	ERR_DESC_MTU = (1 << 5),
+	ERR_LINK_SGPKT_LEN = (1 << 8),
+	ERR_LINK_TSOPKT_LINEAR = (1 << 9),
+	ERR_LINK_NFRAG_LEN = (1 << 10),
+	ERR_LINK_TOTAL_LEN = (1 << 11),
+	ERR_HDR_TCP_BCMC = (1 << 12),
+	ERR_HDR_UDP_BC = (1 << 13),
+	ERR_HDR_VLAN_IP_TYPE = (1 << 14),
+	ERR_HDR_IP_TYPE = (1 << 15),
+	ERR_HDR_IP_VERSION = (1 << 16),
+	ERR_HDR_IP_HDR_LEN = (1 << 17),
+	ERR_HDR_IP_TOTAL_LEN = (1 << 18),
+	ERR_HDR_IPV6_TTL_PROT = (1 << 19),
+	ERR_HDR_IPV4_OFFSET = (1 << 20),
+	ERR_HDR_IPV4_TTL_PROT = (1 << 21),
+	ERR_HDR_UDP_LEN = (1 << 22),
+	ERR_HDR_TCP_LEN = (1 << 23),
+	ERR_DESC = (ERR_DESC_CFG | ERR_DATA_LEN |
+			ERR_DESC_NFRAG_NUM | ERR_DESC_IP_HDR_LEN |
+			ERR_DESC_PROT_HDR_LEN | ERR_DESC_MTU),
+	ERR_LINK = (ERR_LINK_SGPKT_LEN | ERR_LINK_TSOPKT_LINEAR |
+			ERR_LINK_NFRAG_LEN | ERR_LINK_TOTAL_LEN),
+	ERR_HDR = (ERR_HDR_TCP_BCMC | ERR_HDR_UDP_BC |
+			ERR_HDR_VLAN_IP_TYPE | ERR_HDR_IP_TYPE |
+			ERR_HDR_IP_VERSION | ERR_HDR_IP_HDR_LEN |
+			ERR_HDR_IP_TOTAL_LEN | ERR_HDR_IPV6_TTL_PROT |
+			ERR_HDR_IPV4_OFFSET | ERR_HDR_IPV4_TTL_PROT |
+			ERR_HDR_UDP_LEN | ERR_HDR_TCP_LEN),
+	ERR_ALL = (ERR_DESC | ERR_LINK | ERR_HDR),
+};
+
+#define HIGMAC_DRIVER_NAME	"hi_gmac_v200"
+
+#define HIGMAC_MAC_CLK_NAME	"higmac_clk"
+#define HIGMAC_MACIF_CLK_NAME	"macif_clk"
+
+#define HIGMAC_PORT_RST_NAME	"port_reset"
+#define HIGMAC_MACIF_RST_NAME	"macif_reset"
+#define HIGMAC_PHY_RST_NAME	"phy_reset"
+
+#define HIGMAC_TSO_DEBUG
+
+#include "tso.h"
+
+#if defined(CONFIG_ARCH_HI3519) || defined(CONFIG_ARCH_HI3519V101) || \
+	defined(CONFIG_ARCH_HI3516AV200)
+#ifdef readl
+#undef readl
+#undef readl_relaxed
+#undef writel
+#undef writel_relaxed
+#define readl		hi_readl
+#define readl_relaxed	hi_readl_relaxed
+#define writel		hi_writel
+#define writel_relaxed	hi_writel_relaxed
+#endif /* readl */
+#endif /* defined(CONFIG_ARCH_HI3519) || defined(CONFIG_HI3519V101) */
+
+#define HIGMAC_IOSIZE			(0x1000)
+#define HIGMAC_OFFSET			(HIGMAC_IOSIZE)
+
+#define RX_BQ_IN_INT			BIT(17)
+#define TX_RQ_IN_INT			BIT(19)
+#define RX_BQ_IN_TIMEOUT_INT		BIT(28)
+#define TX_RQ_IN_TIMEOUT_INT		BIT(29)
+
+#define DEF_INT_MASK			(RX_BQ_IN_INT | RX_BQ_IN_TIMEOUT_INT | \
+					TX_RQ_IN_INT | TX_RQ_IN_TIMEOUT_INT)
+
+/* write or read descriptor need memory barrier */
+#define HIGMAC_SYNC_BARRIER() do { isb(); smp_mb(); } while (0)
+
+#define HISILICON_PHY_ID_FESTAV200	(0x20669823)
+#define PHY_ID_KSZ8051MNL               (0x00221550)
+#define PHY_ID_KSZ8081RNB               (0x00221560)
+#define DEFAULT_PHY_MASK                (0xfffffff0)
+#define REALTEK_PHY_ID_8211E		(0x001cc915)
+#define REALTEK_PHY_MASK		(0x001fffff)
+
+enum {
+	GMAC_PORT0,
+	GMAC_PORT1,
+	GMAC_MAX_PORT,
+};
+
+enum {
+	MEM_GMAC_IOBASE,
+	MEM_MACIF_IOBASE,
+	MEM_FWD_IOBASE,
+	MEM_CTRL_IOBASE,
+};
+
+#define HIGMAC_LINKED		BIT(0)
+#define HIGMAC_DUP_FULL		BIT(1)
+#define HIGMAC_SPD_10M		BIT(2)
+#define HIGMAC_SPD_100M		BIT(3)
+#define HIGMAC_SPD_1000M	BIT(4)
+/* Flow Control defines */
+#define FLOW_OFF        0
+#define FLOW_RX         1
+#define FLOW_TX         2
+#define FLOW_AUTO       (FLOW_TX | FLOW_RX)
+
+#define FC_ACTIVE_MIN		1
+#define FC_ACTIVE_DEFAULT	16
+#define FC_ACTIVE_MAX		127
+#define FC_DEACTIVE_MIN		1
+#define FC_DEACTIVE_DEFAULT	32
+#define FC_DEACTIVE_MAX		127
+
+#define FC_PAUSE_TIME_DEFAULT		0xFFFF
+#define FC_PAUSE_INTERVAL_DEFAULT	0xFFFF
+#define FC_PAUSE_TIME_MAX		0xFFFF
+
+#define RX_BQ_INT_THRESHOLD	0x40	/* TODO: */
+#define TX_RQ_INT_THRESHOLD	0x20	/* TODO: */
+
+#define HIGMAC_MONITOR_TIMER	(msecs_to_jiffies(200))
+
+#define HIETH_MAX_FRAME_SIZE	(1600 + 128)
+#define SKB_SIZE		(HIETH_MAX_FRAME_SIZE)
+
+#define DESC_VLD_FREE		0
+#define DESC_VLD_BUSY		1
+
+#define DESC_FL_FIRST		2
+#define DESC_FL_MID		0
+#define DESC_FL_LAST		1
+#define DESC_FL_FULL		3
+
+#if defined(CONFIG_HIGMAC_DESC_4WORD)
+#define DESC_WORD_SHIFT		2
+#else
+#define DESC_WORD_SHIFT		3
+#endif
+#define DESC_BYTE_SHIFT		(DESC_WORD_SHIFT + 2)
+#define DESC_WORD_CNT		(1 << DESC_WORD_SHIFT)
+#define DESC_SIZE		(1 << DESC_BYTE_SHIFT)
+
+#define RX_DESC_NUM			1024
+#define TX_DESC_NUM			1024
+
+/* DMA descriptor ring helpers */
+#define dma_ring_incr(n, s)		(((n) + 1) & ((s) - 1))
+#define dma_cnt(n)			((n) >> DESC_BYTE_SHIFT)
+#define dma_byte(n)			((n) << DESC_BYTE_SHIFT)
+
+#define RSS_HASH_KEY_SIZE		4
+#define RSS_INDIRECTION_TABLE_SIZE	128
+#define RSS_NUM_RXQS		4
+
+#define HW_CAP_TSO			BIT(0)
+#define HW_CAP_RXCSUM			BIT(1)
+#define HW_CAP_CCI			BIT(2)
+#define HAS_CAP_TSO(hw_cap)		((hw_cap) & HW_CAP_TSO)
+#define HAS_CAP_RXCSUM(hw_cap)		((hw_cap) & HW_CAP_RXCSUM)
+#define HAS_CAP_CCI(hw_cap)		((hw_cap) & HW_CAP_CCI)
+
+#if defined(CONFIG_HIGMAC_DESC_4WORD)
+struct higmac_desc {
+	unsigned int data_buff_addr;
+
+	unsigned int buffer_len:11;
+#if defined(CONFIG_HIGMAC_RXCSUM)
+	unsigned int reserve2:1;
+	unsigned int payload_csum_err:1;
+	unsigned int header_csum_err:1;
+	unsigned int payload_csum_done:1;
+	unsigned int header_csum_done:1;
+#else
+	unsigned int reserve2:5;
+#endif
+	unsigned int data_len:11;
+	unsigned int reserve1:2;
+	unsigned int fl:2;
+	unsigned int descvid:1;
+
+	unsigned int rxhash;
+	unsigned int reserve3:8;
+	unsigned int l3_hash:1;
+	unsigned int has_hash:1;
+	unsigned int skb_id:14;
+	unsigned int reserve31:8;
+};
+
+struct higmac_tso_desc {
+	unsigned int data_buff_addr;
+	union {
+		struct {
+			unsigned int prot_hdr_len:4;
+			unsigned int ip_hdr_len:4;
+			unsigned int prot_type:1;
+			unsigned int ip_ver:1;
+			unsigned int vlan_flag:1;
+			unsigned int nfrags_num:5;
+			unsigned int data_len:11;
+			unsigned int reservel:1;
+			unsigned int tso_flag:1;
+			unsigned int coe_flag:1;
+			unsigned int sg_flag:1;
+			unsigned int hw_own:1;
+		} tx;
+		unsigned int val;
+	} desc1;
+	unsigned int reserve_desc2;
+	unsigned int tx_err;
+};
+#else
+struct higmac_desc {
+	unsigned int data_buff_addr;
+
+	unsigned int buffer_len:11;
+#if defined(CONFIG_HIGMAC_RXCSUM)
+	unsigned int reserve2:1;
+	unsigned int payload_csum_err:1;
+	unsigned int header_csum_err:1;
+	unsigned int payload_csum_done:1;
+#else
+	unsigned int reserve2:5;
+#endif
+	unsigned int data_len:11;
+	unsigned int reserve1:2;
+	unsigned int fl:2;
+	unsigned int descvid:1;
+
+	unsigned int rxhash;
+	unsigned int reserve3:8;
+	unsigned int l3_hash:1;
+	unsigned int has_hash:1;
+	unsigned int skb_id:14;
+	unsigned int reserve31:8;
+
+	unsigned int reserve4;
+	unsigned int reserve5;
+	unsigned int reserve6;
+	unsigned int reserve7;
+};
+
+struct higmac_tso_desc {
+	unsigned int data_buff_addr;
+	union {
+		struct {
+			unsigned int prot_hdr_len:4;
+			unsigned int ip_hdr_len:4;
+			unsigned int prot_type:1;
+			unsigned int ip_ver:1;
+			unsigned int vlan_flag:1;
+			unsigned int nfrags_num:5;
+			unsigned int data_len:11;
+			unsigned int reservel:1;
+			unsigned int tso_flag:1;
+			unsigned int coe_flag:1;
+			unsigned int sg_flag:1;
+			unsigned int hw_own:1;
+		} tx;
+		unsigned int val;
+	} desc1;
+	unsigned int reserve_desc2;
+	unsigned int reserve3;
+
+	unsigned int tx_err;
+	unsigned int reserve5;
+	unsigned int reserve6;
+	unsigned int reserve7;
+};
+#endif
+
+#define SKB_MAGIC	((struct sk_buff *)0x5a)
+
+struct higmac_napi {
+	struct napi_struct napi;
+	struct higmac_netdev_local *ndev_priv;
+	int rxq_id;
+};
+
+struct higmac_rss_info {
+	u32 hash_cfg;
+	u32 ind_tbl_size;
+	u8 ind_tbl[RSS_INDIRECTION_TABLE_SIZE];
+	u8 key[RSS_HASH_KEY_SIZE];
+};
+
+#define QUEUE_NUMS	(4)
+struct higmac_netdev_local {
+#define HIGMAC_SG_DESC_ADD	(64U)
+	struct sg_desc *dma_sg_desc ____cacheline_aligned;
+	dma_addr_t dma_sg_phy;
+	unsigned int sg_head;
+	unsigned int sg_tail;
+	unsigned int sg_count;
+
+	void __iomem *gmac_iobase;
+	void __iomem *macif_base;
+	int index;		/* 0 -- mac0, 1 -- mac1 */
+
+	u32 hw_cap;
+	bool tso_supported;
+	bool has_rxhash_cap;
+	bool has_rss_cap;
+	int num_rxqs;
+	struct higmac_napi q_napi[RSS_NUM_RXQS];
+	int irq[RSS_NUM_RXQS];
+	struct higmac_rss_info rss_info;
+
+	struct reset_control *port_rst;
+	struct reset_control *macif_rst;
+	struct reset_control *phy_rst;
+
+	struct {
+		struct higmac_desc *desc;
+		dma_addr_t phys_addr;
+		int *sg_desc_offset;
+
+		/* how many desc in the desc pool */
+		unsigned int count;
+		struct sk_buff **skb;
+
+		/* sizeof(desc) * count */
+		unsigned int size;
+	} pool[QUEUE_NUMS + RSS_NUM_RXQS - 1];
+#define rx_fq		pool[0]
+#define rx_bq		pool[1]
+#define tx_bq		pool[2]
+#define tx_rq		pool[3]
+
+	struct sk_buff **tx_skb;
+	struct sk_buff **rx_skb;
+
+	struct device *dev;
+	struct net_device *netdev;
+	struct clk *clk;
+	struct clk *macif_clk;
+
+	struct higmac_adapter *adapter;
+
+	struct timer_list monitor;
+
+	char phy_name[MII_BUS_ID_SIZE];
+	struct phy_device *phy;
+	struct device_node *phy_node;
+	phy_interface_t phy_mode;
+	bool autoeee;
+	bool internal_phy;
+	int (*eee_init)(struct phy_device *phy_dev);
+
+	unsigned int flow_ctrl;
+	unsigned int pause;
+	unsigned int pause_interval;
+	unsigned int flow_ctrl_active_threshold;
+	unsigned int flow_ctrl_deactive_threshold;
+
+	int old_link;
+	int old_speed;
+	int old_duplex;
+
+	/* receive packet lock */
+	spinlock_t rxlock;
+	/* transmit packet lock */
+	spinlock_t txlock;
+	/* power management lock */
+	spinlock_t pmtlock;
+
+	int dev_state;		/* INIT/OPEN/CLOSE */
+	char pm_state;
+	bool wol_enable;
+	u32 msg_enable;
+#define INIT			(0)	/* power off gmac */
+#define OPEN			(1)	/* power on gmac */
+#define CLOSE			(2)	/* power off gmac */
+};
+
+enum tso_version {
+	VER_NO_TSO = 0x0,
+	VER_BYTE_SPLICE = 0x1,
+	VER_SG_COE = 0x2,
+	VER_TSO = 0x3,
+};
+
+#ifdef HIGMAC_TSO_DEBUG
+#define MAX_RECORD	(100)
+struct send_pkt_info {
+	struct higmac_tso_desc desc;
+	int status;
+};
+#endif
+
+int higmac_tx_avail(struct higmac_netdev_local *ld);
+
+/* board related func */
+void higmac_mac_core_reset(struct higmac_netdev_local *priv);
+void higmac_hw_internal_phy_reset(struct higmac_netdev_local *priv);
+void higmac_hw_external_phy_reset(struct higmac_netdev_local *priv);
+void higmac_internal_phy_clk_disable(struct higmac_netdev_local *priv);
+void higmac_internal_phy_clk_enable(struct higmac_netdev_local *priv);
+void higmac_hw_all_clk_disable(struct higmac_netdev_local *priv);
+void higmac_hw_all_clk_enable(struct higmac_netdev_local *priv);
+
+/* board independent func */
+void higmac_hw_phy_reset(struct higmac_netdev_local *priv);
+
+void pmt_reg_restore(struct higmac_netdev_local *ld);
+#endif
diff --git a/drivers/net/ethernet/hisilicon/higmac/pm.c b/drivers/net/ethernet/hisilicon/higmac/pm.c
new file mode 100644
index 0000000..7620abe
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/pm.c
@@ -0,0 +1,359 @@
+#include <linux/crc16.h>
+#include "higmac.h"
+
+#define N			(31)
+#define FILTERS			(4)
+struct pm_config {
+	unsigned char index;	/* bit0--eth0 bit1--eth1 */
+	unsigned char uc_pkts_enable;
+	unsigned char magic_pkts_enable;
+	unsigned char wakeup_pkts_enable;
+	struct {
+		unsigned int mask_bytes:N;
+		unsigned int reserved:1;	/* userspace ignore this bit */
+		unsigned char offset;	/* >= 12 */
+		unsigned char value[N];	/* byte string */
+		unsigned char valid;	/* valid filter */
+	} filter[FILTERS];
+};
+
+struct pm_reg_config {
+	unsigned int pmt_ctrl;
+	unsigned int pmt_mask0;
+	unsigned int pmt_mask1;
+	unsigned int pmt_mask2;
+	unsigned int pmt_mask3;
+	unsigned int pmt_cmd;
+	unsigned int pmt_offset;
+	unsigned int pmt_crc1_0;
+	unsigned int pmt_crc3_2;
+};
+
+struct pm_reg_config pm_reg_config_backup;
+
+#define PMT_CTRL		0xa00
+#define PMT_MASK0		0xa04
+#define PMT_MASK1		0xa08
+#define PMT_MASK2		0xa0c
+#define PMT_MASK3		0xa10
+#define PMT_CMD			0xa14
+#define PMT_OFFSET		0xa18
+#define PMT_CRC1_0		0xa1c
+#define PMT_CRC3_2		0xa20
+#define MASK_INVALID_BIT	BIT(31)
+
+static void init_crc_table(void);
+static unsigned short compute_crc(char *message, int nbytes);
+static unsigned short calculate_crc16(char *buf, unsigned int mask)
+{
+	char data[N];
+	int i, len = 0;
+
+	memset(data, 0, sizeof(data));
+
+	for (i = 0; i < N; i++) {
+		if (mask & 0x1)
+			data[len++] = buf[i];
+
+		mask >>= 1;
+	}
+
+	return compute_crc(data, len);
+}
+
+/* use this func in config pm func */
+void _pmt_reg_backup(struct higmac_netdev_local *ld)
+{
+	pm_reg_config_backup.pmt_ctrl = readl(ld->gmac_iobase + PMT_CTRL);
+	pm_reg_config_backup.pmt_mask0 = readl(ld->gmac_iobase + PMT_MASK0);
+	pm_reg_config_backup.pmt_mask1 = readl(ld->gmac_iobase + PMT_MASK1);
+	pm_reg_config_backup.pmt_mask2 = readl(ld->gmac_iobase + PMT_MASK2);
+	pm_reg_config_backup.pmt_mask3 = readl(ld->gmac_iobase + PMT_MASK3);
+	pm_reg_config_backup.pmt_cmd = readl(ld->gmac_iobase + PMT_CMD);
+	pm_reg_config_backup.pmt_offset = readl(ld->gmac_iobase + PMT_OFFSET);
+	pm_reg_config_backup.pmt_crc1_0 = readl(ld->gmac_iobase + PMT_CRC1_0);
+	pm_reg_config_backup.pmt_crc3_2 = readl(ld->gmac_iobase + PMT_CRC3_2);
+}
+
+#define	PM_SET			(1)
+#define PM_CLEAR		(0)
+
+int pmt_config_gmac(struct pm_config *config, struct higmac_netdev_local *ld)
+{
+	unsigned int v = 0, cmd = 0, offset = 0;
+	unsigned short crc[FILTERS] = { 0 };
+	unsigned long flags;
+	int reg_mask = 0;
+	int i;
+
+	if (!ld)
+		return -EINVAL;
+
+	spin_lock_irqsave(&ld->pmtlock, flags);
+	if (config->wakeup_pkts_enable) {
+		/* disable wakeup_pkts_enable before reconfig? */
+		v = readl(ld->gmac_iobase + PMT_CTRL);
+		v &= ~BIT(2);
+		writel(v, ld->gmac_iobase + PMT_CTRL);	/* any side effect? */
+	} else {
+		goto config_ctrl;
+	}
+
+/* filter.valid		mask.valid	mask_bytes	effect
+ *	0		*		*		no use the filter
+ *	1		0		*	all pkts can wake-up(non-exist)
+ *	1		1		0		all pkts can wake-up
+ *	1		1		!0		normal filter
+ */
+	/* setup filter */
+	for (i = 0; i < FILTERS; i++) {
+		if (config->filter[i].valid) {
+			if (config->filter[i].offset < 12)
+				continue;
+			/* offset and valid bit */
+			offset |= config->filter[i].offset << (i * 8);
+			cmd |= BIT(i * 8);	/* valid bit */
+			/* mask */
+			reg_mask = PMT_MASK0 + (i * 4);
+
+			/* for logic, mask valid bit(bit31) must set to 0,
+			 * 0 is enable
+			 */
+			v = config->filter[i].mask_bytes;
+			v &= ~BIT(31);
+			writel(v, ld->gmac_iobase + reg_mask);
+
+			/* crc */
+			crc[i] = calculate_crc16(config->filter[i].value, v);
+			if (i <= 1) {	/* for filter0 and filter 1 */
+				v = readl(ld->gmac_iobase + PMT_CRC1_0);
+				v &= ~(0xFFFF << (16 * i));
+				v |= crc[i] << (16 * i);
+				writel(v, ld->gmac_iobase + PMT_CRC1_0);
+			} else {	/* filter2 and filter3 */
+				v = readl(ld->gmac_iobase + PMT_CRC3_2);
+				v &= ~(0xFFFF << (16 * (i - 2)));
+				v |= crc[i] << (16 * (i - 2));
+				writel(v, ld->gmac_iobase + PMT_CRC3_2);
+			}
+		}
+	}
+
+	if (cmd) {
+		writel(offset, ld->gmac_iobase + PMT_OFFSET);
+		writel(cmd, ld->gmac_iobase + PMT_CMD);
+	}
+
+config_ctrl:
+	v = 0;
+	if (config->uc_pkts_enable)
+		v |= BIT(9);	/* uc pkts wakeup */
+	if (config->wakeup_pkts_enable)
+		v |= BIT(2);	/* use filter framework */
+	if (config->magic_pkts_enable)
+		v |= BIT(1);	/* magic pkts wakeup */
+
+	v |= 3 << 5;		/* clear irq status */
+	writel(v, ld->gmac_iobase + PMT_CTRL);
+
+	_pmt_reg_backup(ld);
+
+	spin_unlock_irqrestore(&ld->pmtlock, flags);
+
+	return 0;
+}
+
+/* pmt_config will overwrite pre-config */
+int pmt_config(struct net_device *ndev, struct pm_config *config)
+{
+	static int init;
+	int ret = -EINVAL;
+	struct higmac_netdev_local *priv = netdev_priv(ndev);
+
+	if (!init)
+		init_crc_table();
+
+	ret = pmt_config_gmac(config, priv);
+	if (ret)
+		return ret;
+
+	priv->pm_state = PM_SET;
+	priv->wol_enable = true;
+	device_set_wakeup_enable(priv->dev, 1);
+
+	return ret;
+}
+
+inline bool pmt_enter(struct higmac_netdev_local *ld)
+{
+	int pm = false;
+	unsigned long flags;
+
+	spin_lock_irqsave(&ld->pmtlock, flags);
+	if (ld->pm_state == PM_SET) {
+		int v;
+
+		v = readl(ld->gmac_iobase + PMT_CTRL);
+		v |= BIT(0);	/* enter power down */
+		v |= BIT(3);	/* enable wakeup irq */
+		v |= 3 << 5;	/* clear irq status */
+		writel(v, ld->gmac_iobase + PMT_CTRL);
+
+		ld->pm_state = PM_CLEAR;
+		pm = true;
+	}
+	spin_unlock_irqrestore(&ld->pmtlock, flags);
+	return pm;
+}
+
+inline void pmt_exit(struct higmac_netdev_local *ld)
+{
+	int v;
+	unsigned long flags;
+
+	/* logic auto exit power down mode */
+	spin_lock_irqsave(&ld->pmtlock, flags);
+
+	v = readl(ld->gmac_iobase + PMT_CTRL);
+	v &= ~BIT(0);		/* enter power down */
+	v &= ~BIT(3);		/* enable wakeup irq */
+
+	v |= 3 << 5;		/* clear irq status */
+	writel(v, ld->gmac_iobase + PMT_CTRL);
+
+	spin_unlock_irqrestore(&ld->pmtlock, flags);
+
+	ld->wol_enable = false;
+	/* device_set_wakeup_enable(ld->dev, 0); */
+}
+
+void pmt_reg_restore(struct higmac_netdev_local *ld)
+{
+	unsigned int v;
+	unsigned long flags;
+
+	spin_lock_irqsave(&ld->pmtlock, flags);
+	v = pm_reg_config_backup.pmt_mask0;
+	writel(v, ld->gmac_iobase + PMT_MASK0);
+
+	v = pm_reg_config_backup.pmt_mask1;
+	writel(v, ld->gmac_iobase + PMT_MASK1);
+
+	v = pm_reg_config_backup.pmt_mask2;
+	writel(v, ld->gmac_iobase + PMT_MASK2);
+
+	v = pm_reg_config_backup.pmt_mask3;
+	writel(v, ld->gmac_iobase + PMT_MASK3);
+
+	v = pm_reg_config_backup.pmt_cmd;
+	writel(v, ld->gmac_iobase + PMT_CMD);
+
+	v = pm_reg_config_backup.pmt_offset;
+	writel(v, ld->gmac_iobase + PMT_OFFSET);
+
+	v = pm_reg_config_backup.pmt_crc1_0;
+	writel(v, ld->gmac_iobase + PMT_CRC1_0);
+
+	v = pm_reg_config_backup.pmt_crc3_2;
+	writel(v, ld->gmac_iobase + PMT_CRC3_2);
+
+	v = pm_reg_config_backup.pmt_ctrl;
+	writel(v, ld->gmac_iobase + PMT_CTRL);
+	spin_unlock_irqrestore(&ld->pmtlock, flags);
+}
+
+/* ========the following code copy from Synopsys DWC_gmac_crc_example.c====== */
+#define CRC16			/* Change it to CRC16 for CRC16 Computation */
+
+#if defined(CRC16)
+#define CRC_NAME		"CRC-16"
+#define POLYNOMIAL		0x8005
+#define INITIAL_REMAINDER	0xFFFF
+#define FINAL_XOR_VALUE		0x0000
+#define REVERSE_DATA
+#undef REVERSE_REMAINDER
+#endif
+
+#define WIDTH    (8 * sizeof(unsigned short))
+#define TOPBIT   BIT(WIDTH - 1)
+
+#ifdef REVERSE_DATA
+#undef  REVERSE_DATA
+#define REVERSE_DATA(X)		((unsigned char)reverse((X), 8))
+#else
+#undef  REVERSE_DATA
+#define REVERSE_DATA(X)		(X)
+#endif
+
+#ifdef REVERSE_REMAINDER
+#undef  REVERSE_REMAINDER
+#define REVERSE_REMAINDER(X)	((unsigned short)reverse((X), WIDTH))
+#else
+#undef  REVERSE_REMAINDER
+#define REVERSE_REMAINDER(X)	(X)
+#endif
+
+static unsigned short crc_table[256];
+
+/* Reverse the data
+ * Input1: Data to be reversed
+ * Input2: number of bits in the data
+ * Output: The reversed data
+ */
+static unsigned int reverse(unsigned int data, unsigned char nbits)
+{
+	unsigned int reversed = 0x00000000;
+	unsigned char bit;
+
+	/* Reverse the data about the center bit. */
+	for (bit = 0; bit < nbits; ++bit) {
+		/* If the LSB bit is set, set the reflection of it. */
+		if (data & 0x01)
+			reversed |= BIT((nbits - 1) - bit);
+
+		data = (data >> 1);
+	}
+	return reversed;
+}
+
+/* This Initializes the partial CRC look up table */
+static void init_crc_table(void)
+{
+	unsigned short remainder;
+	int dividend;
+	unsigned char bit;
+
+	/* Compute the remainder of each possible dividend. */
+	for (dividend = 0; dividend < 256; ++dividend) {
+		/* Start with the dividend followed by zeros. */
+		remainder = (unsigned short)(dividend << (WIDTH - 8));
+
+		/* Perform modulo-2 division, a bit at a time. */
+		for (bit = 8; bit > 0; --bit) {
+			/* Try to divide the current data bit. */
+			if (remainder & TOPBIT)
+				remainder = (remainder << 1) ^ POLYNOMIAL;
+			else
+				remainder = (remainder << 1);
+		}
+
+		/* Store the result into the table. */
+		crc_table[dividend] = remainder;
+	}
+}
+
+static unsigned short compute_crc(char *message, int nbytes)
+{
+	unsigned short remainder = INITIAL_REMAINDER;
+	int byte;
+	unsigned char data;
+
+	/* Divide the message by the polynomial, a byte at a time. */
+	for (byte = 0; byte < nbytes; ++byte) {
+		data = REVERSE_DATA(message[byte]) ^ (remainder >> (WIDTH - 8));
+		remainder = crc_table[data] ^ (remainder << 8);
+	}
+
+	/* The final remainder is the CRC. */
+	return (REVERSE_REMAINDER(remainder) ^ FINAL_XOR_VALUE);
+}
diff --git a/drivers/net/ethernet/hisilicon/higmac/proc-dev.c b/drivers/net/ethernet/hisilicon/higmac/proc-dev.c
new file mode 100644
index 0000000..d522565
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/proc-dev.c
@@ -0,0 +1,111 @@
+#include "sockioctl.h"
+
+/* debug code */
+static int set_suspend(int eth_n)
+{
+	return 0;
+}
+
+/* debug code */
+static int set_resume(int eth_n)
+{
+	/* higmac_dev_driver.resume(&higmac_platform_device); */
+	return 0;
+}
+
+static int hw_states_read(struct seq_file *m, void *v)
+{
+	return 0;
+}
+
+static struct proc_dir_entry *higmac_proc_root;
+
+#define proc_open(name)	\
+static int proc_open_##name(struct inode *inode, struct file *file) \
+{ \
+	return single_open(file, name, PDE_DATA(inode)); \
+} \
+
+proc_open(hw_states_read);
+
+static struct proc_file {
+	char *name;
+	const struct file_operations ops;
+
+} proc_file[] = {
+	{
+		.name = "hw_stats",
+		.ops = {
+			.open           = proc_open_hw_states_read,
+			.read           = seq_read,
+			.llseek         = seq_lseek,
+			.release        = single_release,
+		},
+	}
+};
+
+/* /proc/higmac/
+ *	|---hw_stats
+ *	|---skb_pools
+ */
+void higmac_proc_create(void)
+{
+	int i;
+
+	higmac_proc_root = proc_mkdir("higmac", NULL);
+	if (!higmac_proc_root)
+		return;
+
+	for (i = 0; i < ARRAY_SIZE(proc_file); i++) {
+		struct proc_dir_entry *entry;
+
+		entry = proc_create(proc_file[i].name, 0000, higmac_proc_root,
+				    &proc_file[i].ops);
+		if (!entry)
+			pr_err("failed to create %s\n", proc_file[i].name);
+	}
+}
+
+void higmac_proc_destroy(void)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(proc_file); i++)
+		remove_proc_entry(proc_file[i].name, higmac_proc_root);
+
+	remove_proc_entry("higmac", NULL);
+}
+
+int higmac_ioctl(struct net_device *ndev, struct ifreq *rq, int cmd)
+{
+	struct higmac_netdev_local *priv = netdev_priv(ndev);
+	struct pm_config pm_config;
+	int val = 0;
+
+	switch (cmd) {
+	case SIOCSETPM:
+		if (copy_from_user(&pm_config, rq->ifr_data, sizeof(pm_config)))
+			return -EFAULT;
+		return pmt_config(ndev, &pm_config);
+
+	case SIOCSETSUSPEND:
+		if (copy_from_user(&val, rq->ifr_data, sizeof(val)))
+			return -EFAULT;
+		return set_suspend(val);
+
+	case SIOCSETRESUME:
+		if (copy_from_user(&val, rq->ifr_data, sizeof(val)))
+			return -EFAULT;
+		return set_resume(val);
+
+	default:
+		if (!netif_running(ndev))
+			return -EINVAL;
+
+		if (!priv->phy)
+			return -EINVAL;
+
+		return phy_mii_ioctl(priv->phy, rq, cmd);
+	}
+	return 0;
+}
diff --git a/drivers/net/ethernet/hisilicon/higmac/sockioctl.h b/drivers/net/ethernet/hisilicon/higmac/sockioctl.h
new file mode 100644
index 0000000..571c71a
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/sockioctl.h
@@ -0,0 +1,12 @@
+#ifndef _SOCKIOCTL_H_
+#define _SOCKIOCTL_H_
+
+#include <linux/sockios.h>
+
+#define SIOCSETPM	(SIOCDEVPRIVATE + 4)	/* set pmt wake up config */
+#define SIOCSETSUSPEND	(SIOCDEVPRIVATE + 5)	/* call dev->suspend, debug */
+#define SIOCSETRESUME	(SIOCDEVPRIVATE + 6)	/* call dev->resume, debug */
+
+int higmac_ioctl(struct net_device *net_dev, struct ifreq *rq, int cmd);
+
+#endif
diff --git a/drivers/net/ethernet/hisilicon/higmac/tso.h b/drivers/net/ethernet/hisilicon/higmac/tso.h
new file mode 100644
index 0000000..6416eef
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/tso.h
@@ -0,0 +1,53 @@
+#ifndef __HIETH_TSO_H
+#define __HIETH_TSO_H
+
+#define SG_FLAG		BIT(30)
+#define COE_FLAG	BIT(29)
+#define TSO_FLAG	BIT(28)
+#define VLAN_FLAG	BIT(10)
+#define IPV6_FLAG	BIT(9)
+#define UDP_FLAG	BIT(8)
+
+#define PKT_IPV6_HDR_LEN	10
+#define PKT_UDP_HDR_LEN		2
+#define WORD_TO_BYTE		4
+enum {
+	PKT_NORMAL,
+	PKT_SG
+};
+
+enum {
+	PKT_IPV4,
+	PKT_IPV6
+};
+
+enum {
+	PKT_TCP,
+	PKT_UDP
+};
+
+struct frags_info {
+	/* Word(2*i+2) */
+	u32 addr;
+	/* Word(2*i+3) */
+	u32 size:16;
+	u32 reserved:16;
+};
+
+struct sg_desc {
+	/* Word0 */
+	u32 total_len:17;
+	u32 reserv:15;
+	/* Word1 */
+	u32 ipv6_id;
+	/* Word2 */
+	u32 linear_addr;
+	/* Word3 */
+	u32 linear_len:16;
+	u32 reserv3:16;
+	/* MAX_SKB_FRAGS = 17 */
+	struct frags_info frags[18];
+	/* struct frags_info frags[MAX_SKB_FRAGS]; */
+};
+
+#endif
diff --git a/drivers/net/ethernet/hisilicon/higmac/util.h b/drivers/net/ethernet/hisilicon/higmac/util.h
new file mode 100644
index 0000000..f08cbf6
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/higmac/util.h
@@ -0,0 +1,29 @@
+#ifndef __HIGMAC_UTIL_H__
+#define __HIGMAC_UTIL_H__
+
+#define HIGMAC_TRACE_LEVEL 10
+
+#define higmac_trace(level, msg...) do { \
+	if ((level) >= HIGMAC_TRACE_LEVEL) { \
+		pr_info("higmac_trace:%s:%d: ", __FILE__, __LINE__); \
+		printk(msg); \
+		printk("\n"); \
+	} \
+} while (0)
+
+#define higmac_error(args...) do { \
+	pr_err("higmac:%s:%d: ", __FILE__, __LINE__); \
+	printk(args); \
+	printk("\n"); \
+} while (0)
+
+#define higmac_assert(cond) do { \
+	if (!(cond)) \
+		pr_alert("Assert:higmac:%s:%d\n", \
+			__FILE__, \
+			__LINE__);\
+} while (0)
+
+#define MK_BITS(shift, nbits) ((((shift) & 0x1F) << 16) | ((nbits) & 0x3F))
+
+#endif
diff --git a/drivers/net/ethernet/hisilicon/hisi-femac/Makefile b/drivers/net/ethernet/hisilicon/hisi-femac/Makefile
new file mode 100644
index 0000000..266ca3b
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/hisi-femac/Makefile
@@ -0,0 +1,6 @@
+#
+# Makefile for the HISILICON Fast Ethernet network device drivers.
+#
+
+obj-$(CONFIG_HISI_FEMAC) += hisi-femac.o
+hisi-femac-objs := hisi_femac.o phy_fix.o
diff --git a/drivers/net/ethernet/hisilicon/hisi-femac/festa_v272_2723.h b/drivers/net/ethernet/hisilicon/hisi-femac/festa_v272_2723.h
new file mode 100644
index 0000000..c12bc41
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/hisi-femac/festa_v272_2723.h
@@ -0,0 +1,102 @@
+0x33f9, 0xbd,
+0x33fa, 0x34,
+0x33fb, 0x00,
+0x33fc, 0x39,
+0x3400, 0x39,
+0x3401, 0xCC,
+0x3402, 0x27,
+0x3403, 0x23,
+0x3404, 0xFD,
+0x3405, 0xFF,
+0x3406, 0xF0,
+0x3407, 0x20,
+0x3408, 0x00,
+0x3409, 0x3C,
+0x340A, 0x3C,
+0x340B, 0x30,
+0x340C, 0xF6,
+0x340D, 0x00,
+0x340E, 0x4A,
+0x340F, 0xC4,
+0x3410, 0x7F,
+0x3411, 0xE7,
+0x3412, 0x01,
+0x3413, 0xF6,
+0x3414, 0x01,
+0x3415, 0xBE,
+0x3416, 0xC1,
+0x3417, 0x02,
+0x3418, 0x27,
+0x3419, 0x0E,
+0x341A, 0xE6,
+0x341B, 0x01,
+0x341C, 0xC1,
+0x341D, 0x14,
+0x341E, 0x27,
+0x341F, 0x08,
+0x3420, 0xC1,
+0x3421, 0x18,
+0x3422, 0x25,
+0x3423, 0x09,
+0x3424, 0xC1,
+0x3425, 0x1B,
+0x3426, 0x22,
+0x3427, 0x05,
+0x3428, 0xC6,
+0x3429, 0x5C,
+0x342A, 0xF7,
+0x342B, 0x20,
+0x342C, 0xA1,
+0x342D, 0xF6,
+0x342E, 0x01,
+0x342F, 0xBF,
+0x3430, 0xC1,
+0x3431, 0x01,
+0x3432, 0x26,
+0x3433, 0x29,
+0x3434, 0xF6,
+0x3435, 0x30,
+0x3436, 0x55,
+0x3437, 0xC0,
+0x3438, 0x05,
+0x3439, 0xE7,
+0x343A, 0x01,
+0x343B, 0xC1,
+0x343C, 0x13,
+0x343D, 0x23,
+0x343E, 0x04,
+0x343F, 0xC6,
+0x3440, 0x13,
+0x3441, 0xE7,
+0x3442, 0x01,
+0x3443, 0x18,
+0x3444, 0xFE,
+0x3445, 0x30,
+0x3446, 0x4C,
+0x3447, 0x18,
+0x3448, 0x3A,
+0x3449, 0x18,
+0x344A, 0xE6,
+0x344B, 0x00,
+0x344C, 0x58,
+0x344D, 0x58,
+0x344E, 0x58,
+0x344F, 0x58,
+0x3450, 0x58,
+0x3451, 0xE7,
+0x3452, 0x00,
+0x3453, 0xF6,
+0x3454, 0x20,
+0x3455, 0x04,
+0x3456, 0xC4,
+0x3457, 0x1F,
+0x3458, 0xEA,
+0x3459, 0x00,
+0x345A, 0xF7,
+0x345B, 0x20,
+0x345C, 0x04,
+0x345D, 0x38,
+0x345E, 0x38,
+0x345F, 0x39,
+0x3400, 0x01,
+0x33f8, 0x01
diff --git a/drivers/net/ethernet/hisilicon/hisi-femac/hisi_femac.c b/drivers/net/ethernet/hisilicon/hisi-femac/hisi_femac.c
new file mode 100644
index 0000000..5b3b79e
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/hisi-femac/hisi_femac.c
@@ -0,0 +1,1693 @@
+/*
+ * Hisilicon Fast Ethernet MAC Driver
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program. If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/circ_buf.h>
+#include <linux/clk.h>
+#include <linux/etherdevice.h>
+#include <linux/if_ether.h>
+#include <linux/if_vlan.h>
+#include <linux/ip.h>
+#include <linux/interrupt.h>
+#include <linux/module.h>
+#include <linux/of_mdio.h>
+#include <linux/of_net.h>
+#include <linux/platform_device.h>
+#include <linux/reset.h>
+#include <linux/tcp.h>
+#include <net/ipv6.h>
+#include <net/protocol.h>
+
+#include "phy_fix.h"
+
+/* MAC control register list */
+#define MAC_PORTSEL			0x0200
+#define MAC_PORTSEL_STAT_CPU		BIT(0)
+#define MAC_PORTSEL_RMII		BIT(1)
+#define MAC_PORTSET			0x0208
+#define MAC_PORTSET_DUPLEX_FULL		BIT(0)
+#define MAC_PORTSET_LINKED		BIT(1)
+#define MAC_PORTSET_SPEED_100M		BIT(2)
+#define MAC_SET				0x0210
+#define MAX_FRAME_SIZE			1600
+#define MAX_FRAME_SIZE_MASK		GENMASK(10, 0)
+#define BIT_PAUSE_EN			BIT(18)
+#define RX_COALESCE_SET			0x0340
+#define RX_COALESCED_FRAME_OFFSET	24
+#define RX_COALESCED_FRAMES		8
+#define RX_COALESCED_TIMER		0x74
+#define QLEN_SET			0x0344
+#define RX_DEPTH_OFFSET			8
+#define MAX_HW_FIFO_DEPTH		64
+#define HW_TX_FIFO_DEPTH		12
+#define HW_RX_FIFO_DEPTH		(MAX_HW_FIFO_DEPTH - HW_TX_FIFO_DEPTH)
+#define FC_LEVEL			0x0348
+#define BITS_FC_ACTIVE_THR_OFFSET	8
+#define FC_DEACTIVE_THR_MASK		GENMASK(5, 0)
+#define FC_ACTIVE_THR_MASK		GENMASK(13, 8)
+#define BIT_FC_EN			BIT(14)
+#define IQFRM_DES			0x0354
+#define RX_FRAME_LEN_MASK		GENMASK(11, 0)
+#define BITS_PAYLOAD_ERR_OFFSET		28
+#define BITS_PAYLOAD_ERR_MASK		0x1
+#define BITS_HEADER_ERR_OFFSET		29
+#define BITS_HEADER_ERR_MASK		0x1
+#define BITS_PAYLOAD_DONE_OFFSET	30
+#define BITS_PAYLOAD_DONE_MASK		0x1
+#define BITS_HEADER_DONE_OFFSET		31
+#define BITS_HEADER_DONE_MASK		0x1
+#define IQ_ADDR				0x0358
+#define EQ_ADDR				0x0360
+#define EQFRM_LEN			0x0364
+#define ADDRQ_STAT			0x036C
+#define TX_CNT_INUSE_MASK		GENMASK(5, 0)
+#define BIT_TX_READY			BIT(24)
+#define BIT_RX_READY			BIT(25)
+#define RX_COE_CTRL			0x0380
+#define BIT_COE_IPV6_UDP_ZERO_DROP	BIT(13)
+#define BIT_COE_PAYLOAD_DROP		BIT(14)
+#define BIT_COE_IPHDR_DROP		BIT(15)
+#define COE_ERR_DROP			(BIT_COE_IPHDR_DROP | \
+					BIT_COE_PAYLOAD_DROP | \
+					BIT_COE_IPV6_UDP_ZERO_DROP)
+#define TSO_DBG_EN			0x03A4
+#define BITS_TSO_DBG_EN			BIT(31)
+#define TSO_DBG_STATE			0x03A8
+#define TSO_DBG_ADDR			0x03AC
+#define TSO_DBG_TX_INFO			0x03B0
+#define TSO_DBG_TX_ERR			0x03B4
+/* global control register list */
+#define GLB_HOSTMAC_L32			0x0000
+#define GLB_HOSTMAC_H16			0x0004
+#define GLB_SOFT_RESET			0x0008
+#define SOFT_RESET_ALL			BIT(0)
+#define GLB_FWCTRL			0x0010
+#define FWCTRL_VLAN_ENABLE		BIT(0)
+#define FWCTRL_FW2CPU_ENA		BIT(5)
+#define FWCTRL_FWALL2CPU		BIT(7)
+#define GLB_MACTCTRL			0x0014
+#define MACTCTRL_UNI2CPU		BIT(1)
+#define MACTCTRL_MULTI2CPU		BIT(3)
+#define MACTCTRL_BROAD2CPU		BIT(5)
+#define MACTCTRL_MACT_ENA		BIT(7)
+#define GLB_IRQ_STAT			0x0030
+#define GLB_IRQ_ENA			0x0034
+#define IRQ_ENA_PORT0_MASK		GENMASK(7, 0)
+#define IRQ_ENA_PORT0			BIT(18)
+#define IRQ_ENA_ALL			BIT(19)
+#define GLB_IRQ_RAW			0x0038
+#define IRQ_INT_RX_RDY			BIT(0)
+#define IRQ_INT_TX_PER_PACKET		BIT(1)
+#define IRQ_INT_TX_FIFO_EMPTY		BIT(6)
+#define IRQ_INT_MULTI_RXRDY		BIT(7)
+#define INT_TX_ERR			BIT(8)
+#define DEF_INT_MASK			(IRQ_INT_MULTI_RXRDY | \
+					IRQ_INT_TX_PER_PACKET | \
+					IRQ_INT_TX_FIFO_EMPTY)
+#define GLB_MAC_L32_BASE		0x0100
+#define GLB_MAC_H16_BASE		0x0104
+#define MACFLT_HI16_MASK		GENMASK(15, 0)
+#define BIT_MACFLT_ENA			BIT(17)
+#define BIT_MACFLT_FW2CPU		BIT(21)
+#define GLB_MAC_H16(reg)		(GLB_MAC_H16_BASE + ((reg) * 0x8))
+#define GLB_MAC_L32(reg)		(GLB_MAC_L32_BASE + ((reg) * 0x8))
+#define MAX_MAC_FILTER_NUM		8
+#define MAX_UNICAST_ADDRESSES		2
+#define MAX_MULTICAST_ADDRESSES		(MAX_MAC_FILTER_NUM - \
+					MAX_UNICAST_ADDRESSES)
+/* software tx and rx queue number, should be power of 2 */
+#define TXQ_NUM				64
+#define RXQ_NUM				128
+#define FEMAC_POLL_WEIGHT		16
+#define HW_CAP_TSO			BIT(0)
+#define HW_CAP_RXCSUM			BIT(1)
+#define HAS_TSO_CAP(hw_cap)		((hw_cap) & HW_CAP_TSO)
+#define HAS_RXCSUM_CAP(hw_cap)		((hw_cap) & HW_CAP_RXCSUM)
+#define RXBUF_ADDR_ALIGN_SIZE		64UL
+/* UDP header len is 2 word */
+#define UDP_HDR_LEN			2
+/* IPv6 header len is 10 word */
+#define IPV6_HDR_LEN			10
+#define WORD_TO_BYTE			4
+
+#define BIT_OFFSET_NFRAGS_NUM		11
+#define BIT_OFFSET_PROT_HEADER_LEN	16
+#define BIT_OFFSET_IP_HEADER_LEN	20
+#define BIT_FLAG_SG			BIT(26)
+#define BIT_FLAG_TXCSUM			BIT(27)
+#define BIT_FLAG_UDP			BIT(28)
+#define BIT_FLAG_IPV6			BIT(29)
+#define BIT_FLAG_VLAN			BIT(30)
+#define BIT_FLAG_TSO			BIT(31)
+
+#define PHY_RESET_DELAYS_PROPERTY	"hisilicon,phy-reset-delays-us"
+
+/* The threshold for activing tx flow ctrl.
+ * When the left amount of receive queue descriptors is below this threshold,
+ * hardware will send pause frame immediately.
+ * We advise this value is set between 1 and 10.
+ * Too bigger is not a good choice.
+ * This value must be smaller than tx flow ctrl deactive threshold.
+ */
+#define TX_FLOW_CTRL_ACTIVE_THRESHOLD	3
+/* The threshold for deactiving tx flow ctrl.
+ * When the left amount of receive queue descriptors is
+ * above or equal with this threshold,
+ * hardware will exit flow control state.
+ * We advise this value is set between 1 and 10.
+ * Too bigger is not a good choice.
+ * This value must be larger than tx flow ctrl active threshold.
+ */
+#define TX_FLOW_CTRL_DEACTIVE_THRESHOLD	5
+#define FC_ACTIVE_MIN			1
+#define FC_ACTIVE_DEFAULT		3
+#define FC_ACTIVE_MAX			31
+#define FC_DEACTIVE_MIN			1
+#define FC_DEACTIVE_DEFAULT		5
+#define FC_DEACTIVE_MAX			31
+
+enum phy_reset_delays {
+	PRE_DELAY,
+	PULSE,
+	POST_DELAY,
+	DELAYS_NUM,
+};
+
+struct hisi_femac_queue {
+	struct sk_buff **skb;
+	dma_addr_t *dma_phys;
+	int num;
+	unsigned int head;
+	unsigned int tail;
+};
+
+struct hisi_femac_tx_desc_ring {
+	struct tx_desc *desc;
+	dma_addr_t dma_phys;
+};
+
+struct hisi_femac_priv {
+	void __iomem *port_base;
+	void __iomem *glb_base;
+	struct clk *clk;
+	struct reset_control *mac_rst;
+	struct reset_control *phy_rst;
+	u32 phy_reset_delays[DELAYS_NUM];
+	u32 link_status;
+
+	struct device *dev;
+	struct net_device *ndev;
+
+	u32 hw_cap;
+	struct hisi_femac_queue txq;
+	struct hisi_femac_queue rxq;
+	struct hisi_femac_tx_desc_ring tx_ring;
+	u32 tx_fifo_used_cnt;
+	struct napi_struct napi;
+
+	/* 802.3x flow control */
+	bool tx_pause_en;
+	u32 tx_pause_active_thresh;
+	u32 tx_pause_deactive_thresh;
+};
+
+struct frags_info {
+	/* Word(2*i+2) */
+	u32 addr;
+	/* Word(2*i+3) */
+	u32 size:16;
+	u32 reserved:16;
+};
+
+struct tx_desc {
+	/* Word0 */
+	u32 total_len:17;
+	u32 reserv:15;
+	/* Word1 */
+	u32 ipv6_id;
+	/* Word2 */
+	u32 linear_addr;
+	/* Word3 */
+	u32 linear_len:16;
+	u32 reserv3:16;
+	/* MAX_SKB_FRAGS = 17 */
+	struct frags_info frags[30];
+	/* struct frags_info frags[MAX_SKB_FRAGS]; */
+};
+
+static void hisi_femac_irq_enable(struct hisi_femac_priv *priv, u32 irqs)
+{
+	u32 val;
+
+	val = readl(priv->glb_base + GLB_IRQ_ENA);
+	writel(val | irqs, priv->glb_base + GLB_IRQ_ENA);
+}
+
+static void hisi_femac_irq_disable(struct hisi_femac_priv *priv, u32 irqs)
+{
+	u32 val;
+
+	val = readl(priv->glb_base + GLB_IRQ_ENA);
+	writel(val & (~irqs), priv->glb_base + GLB_IRQ_ENA);
+}
+
+static void hisi_femac_set_flow_ctrl(struct hisi_femac_priv *priv)
+{
+	unsigned int pause_en;
+	unsigned int tx_flow_ctrl;
+
+	tx_flow_ctrl = readl(priv->port_base + FC_LEVEL);
+	tx_flow_ctrl &= ~FC_DEACTIVE_THR_MASK;
+	tx_flow_ctrl |= priv->tx_pause_deactive_thresh;
+	tx_flow_ctrl &= ~FC_ACTIVE_THR_MASK;
+	tx_flow_ctrl |= priv->tx_pause_active_thresh <<
+				BITS_FC_ACTIVE_THR_OFFSET;
+
+	pause_en = readl(priv->port_base + MAC_SET);
+
+	if (priv->tx_pause_en) {
+		tx_flow_ctrl |= BIT_FC_EN;
+		pause_en |= BIT_PAUSE_EN;
+	} else {
+		tx_flow_ctrl &= ~BIT_FC_EN;
+		pause_en &= ~BIT_PAUSE_EN;
+	}
+
+	writel(tx_flow_ctrl, priv->port_base + FC_LEVEL);
+
+	writel(pause_en, priv->port_base + MAC_SET);
+}
+
+static void hisi_femac_tx_sg_dma_unmap(struct hisi_femac_priv *priv,
+				       struct sk_buff *skb, unsigned int pos)
+{
+	struct tx_desc *desc_cur;
+	dma_addr_t addr;
+	u32 len;
+	int i;
+
+	desc_cur = priv->tx_ring.desc + pos;
+
+	addr = desc_cur->linear_addr;
+	len = desc_cur->linear_len;
+	dma_unmap_single(priv->dev, addr, len, DMA_TO_DEVICE);
+
+	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
+		addr = desc_cur->frags[i].addr;
+		len = desc_cur->frags[i].size;
+		dma_unmap_page(priv->dev, addr, len, DMA_TO_DEVICE);
+	}
+}
+
+static void hisi_femac_tx_dma_unmap(struct hisi_femac_priv *priv,
+				    struct sk_buff *skb, unsigned int pos)
+{
+	if (!(skb_is_gso(skb) || skb_shinfo(skb)->nr_frags)) {
+		dma_addr_t dma_addr;
+
+		dma_addr = priv->txq.dma_phys[pos];
+		dma_unmap_single(priv->dev, dma_addr, skb->len, DMA_TO_DEVICE);
+	} else {
+		hisi_femac_tx_sg_dma_unmap(priv, skb, pos);
+	}
+}
+
+static void hisi_femac_xmit_reclaim(struct net_device *dev)
+{
+	struct sk_buff *skb;
+	struct hisi_femac_priv *priv = netdev_priv(dev);
+	struct hisi_femac_queue *txq = &priv->txq;
+	unsigned int bytes_compl = 0, pkts_compl = 0;
+	u32 val;
+
+	netif_tx_lock(dev);
+
+	val = readl(priv->port_base + ADDRQ_STAT) & TX_CNT_INUSE_MASK;
+	while (val < priv->tx_fifo_used_cnt) {
+		skb = txq->skb[txq->tail];
+		if (unlikely(!skb)) {
+			netdev_err(dev, "xmitq_cnt_inuse=%d, tx_fifo_used=%d\n",
+				   val, priv->tx_fifo_used_cnt);
+			break;
+		}
+		hisi_femac_tx_dma_unmap(priv, skb, txq->tail);
+		pkts_compl++;
+		bytes_compl += skb->len;
+		dev_kfree_skb_any(skb);
+
+		priv->tx_fifo_used_cnt--;
+
+		val = readl(priv->port_base + ADDRQ_STAT) & TX_CNT_INUSE_MASK;
+		txq->skb[txq->tail] = NULL;
+		txq->tail = (txq->tail + 1) % txq->num;
+	}
+
+	netdev_completed_queue(dev, pkts_compl, bytes_compl);
+
+	if (unlikely(netif_queue_stopped(dev)) && pkts_compl)
+		netif_wake_queue(dev);
+
+	netif_tx_unlock(dev);
+}
+
+static void hisi_femac_get_tso_err_info(struct hisi_femac_priv *priv)
+{
+	unsigned int reg_addr, reg_tx_info, reg_tx_err;
+	unsigned int sg_index;
+	struct tx_desc *sg_desc;
+	int *sg_word;
+	int i;
+
+	reg_addr = readl(priv->port_base + TSO_DBG_ADDR);
+	reg_tx_info = readl(priv->port_base + TSO_DBG_TX_INFO);
+	reg_tx_err = readl(priv->port_base + TSO_DBG_TX_ERR);
+
+	WARN(1, "tx err=0x%x, tx_info=0x%x, addr=0x%x\n",
+	     reg_tx_err, reg_tx_info, reg_addr);
+
+	sg_index = (reg_addr - priv->tx_ring.dma_phys) / sizeof(struct tx_desc);
+	sg_desc = priv->tx_ring.desc + sg_index;
+	sg_word = (int *)sg_desc;
+	for (i = 0; i < sizeof(struct tx_desc) / sizeof(int); i++)
+		pr_err("%s,%d: sg_desc word[%d]=0x%x\n",
+		       __func__, __LINE__, i, sg_word[i]);
+
+	/* restart MAC to transmit next packet */
+	hisi_femac_irq_disable(priv, INT_TX_ERR);
+	/* The following is recovery code,
+	 * allow netcard transmit packet again.
+	 * But now we disable it for error debug.
+	 *
+	 * readl(priv->port_base + TSO_DBG_STATE));
+	 * hisi_femac_irq_enable(priv, INT_TX_ERR);
+	 */
+}
+
+static netdev_tx_t hisi_femac_net_xmit(struct sk_buff *skb,
+				       struct net_device *dev);
+
+static netdev_tx_t hisi_femac_sw_gso(struct sk_buff *skb,
+				     struct net_device *dev)
+{
+	struct sk_buff *segs, *curr_skb;
+	netdev_features_t features = dev->features;
+
+	features &= ~(NETIF_F_SG | NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM |
+			NETIF_F_TSO | NETIF_F_TSO6 | NETIF_F_UFO);
+	segs = skb_gso_segment(skb, features);
+	if (IS_ERR_OR_NULL(segs))
+		goto drop;
+
+	do {
+		curr_skb = segs;
+		segs = segs->next;
+		curr_skb->next = NULL;
+		if (hisi_femac_net_xmit(curr_skb, dev)) {
+			dev_kfree_skb(curr_skb);
+			while (segs) {
+				curr_skb = segs;
+				segs = segs->next;
+				curr_skb->next = NULL;
+				dev_kfree_skb_any(curr_skb);
+			}
+			goto drop;
+		}
+	} while (segs);
+
+	dev_kfree_skb_any(skb);
+	return NETDEV_TX_OK;
+
+drop:
+	dev_kfree_skb_any(skb);
+	dev->stats.tx_dropped++;
+	return NETDEV_TX_OK;
+}
+
+static void hisi_femac_do_udp_checksum(struct sk_buff *skb)
+{
+	int offset;
+	__wsum csum;
+	__sum16 udp_csum;
+
+	offset = skb_checksum_start_offset(skb);
+	WARN_ON(offset >= skb_headlen(skb));
+	csum = skb_checksum(skb, offset, skb->len - offset, 0);
+
+	offset += skb->csum_offset;
+	WARN_ON(offset + sizeof(__sum16) > skb_headlen(skb));
+
+	udp_csum = csum_fold(csum);
+	if (udp_csum == 0)
+		udp_csum = CSUM_MANGLED_0;
+
+	*(__sum16 *)(skb->data + offset) = udp_csum;
+
+	skb->ip_summed = CHECKSUM_NONE;
+}
+
+static inline __be16 hisi_femac_get_l3_proto(struct sk_buff *skb)
+{
+	__be16 l3_proto;
+
+	l3_proto = skb->protocol;
+	if (skb->protocol == htons(ETH_P_8021Q))
+		l3_proto = vlan_get_protocol(skb);
+
+	return l3_proto;
+}
+
+static inline bool hisi_femac_skb_is_ipv6(struct sk_buff *skb)
+{
+	return (hisi_femac_get_l3_proto(skb) == htons(ETH_P_IPV6));
+}
+
+static int hisi_femac_check_hw_capability_for_ipv6(struct sk_buff *skb)
+{
+	unsigned int l4_proto = IPPROTO_MAX;
+
+	l4_proto = ipv6_hdr(skb)->nexthdr;
+
+	if ((l4_proto != IPPROTO_TCP) && (l4_proto != IPPROTO_UDP)) {
+		/* when IPv6 next header is not tcp or udp,
+		 * it means that IPv6 next header is extension header.
+		 * Hardware can't deal with this case,
+		 * so do checksumming by software or do GSO by software.
+		 */
+		if (skb_is_gso(skb))
+			return -ENOTSUPP;
+
+		if (skb->ip_summed == CHECKSUM_PARTIAL &&
+		    skb_checksum_help(skb))
+			return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int hisi_femac_check_hw_capability(struct sk_buff *skb)
+{
+	/* if tcp_mtu_probe() use (2 * tp->mss_cache) as probe_size,
+	 * the linear data length will be larger than 2048,
+	 * the MAC can't handle it, so let the software do it.
+	 */
+	if (skb_is_gso(skb) && (skb_headlen(skb) > 2048))
+		return -ENOTSUPP;
+
+	if (hisi_femac_skb_is_ipv6(skb))
+		return hisi_femac_check_hw_capability_for_ipv6(skb);
+
+	return 0;
+}
+
+static u32 hisi_femac_get_pkt_info(struct sk_buff *skb)
+{
+	__be16 l3_proto;
+	unsigned int l4_proto = IPPROTO_MAX;
+	bool do_txcsum = false;
+	int max_data_len = skb->len - ETH_HLEN;
+	unsigned int max_mss = ETH_DATA_LEN;
+	u32 pkt_info = 0;
+
+	if (skb->ip_summed == CHECKSUM_PARTIAL)
+		do_txcsum = true;
+
+	l3_proto = skb->protocol;
+	if (skb->protocol == htons(ETH_P_8021Q)) {
+		l3_proto = vlan_get_protocol(skb);
+		max_data_len -= VLAN_HLEN;
+		pkt_info |= BIT_FLAG_VLAN;
+	}
+
+	if (l3_proto == htons(ETH_P_IP)) {
+		struct iphdr *iph = ip_hdr(skb);
+
+		if ((max_data_len >= GSO_MAX_SIZE) &&
+		    (ntohs(iph->tot_len) <= (iph->ihl << 2)))
+			iph->tot_len = htons(GSO_MAX_SIZE - 1);
+
+		max_mss -= iph->ihl * WORD_TO_BYTE;
+		pkt_info |= (iph->ihl << BIT_OFFSET_IP_HEADER_LEN);
+		l4_proto = iph->protocol;
+	} else if (l3_proto == htons(ETH_P_IPV6)) {
+		max_mss -= IPV6_HDR_LEN * WORD_TO_BYTE;
+		pkt_info |= BIT_FLAG_IPV6;
+		pkt_info |= (IPV6_HDR_LEN << BIT_OFFSET_IP_HEADER_LEN);
+		l4_proto = ipv6_hdr(skb)->nexthdr;
+	} else {
+		do_txcsum = false;
+	}
+
+	if (l4_proto == IPPROTO_TCP) {
+		max_mss -= tcp_hdr(skb)->doff * WORD_TO_BYTE;
+		pkt_info |= (tcp_hdr(skb)->doff << BIT_OFFSET_PROT_HEADER_LEN);
+	} else if (l4_proto == IPPROTO_UDP) {
+		if (l3_proto == htons(ETH_P_IPV6))
+			max_mss -= sizeof(struct frag_hdr);
+		pkt_info |= (BIT_FLAG_UDP |
+				(UDP_HDR_LEN << BIT_OFFSET_PROT_HEADER_LEN));
+	} else {
+		do_txcsum = false;
+	}
+
+	/* Although netcard support UFO feature, it can't deal with
+	 * UDP header checksum.
+	 * So the driver will do UDP header checksum and netcard will just
+	 * fragment the packet.
+	 */
+	if (do_txcsum && skb_is_gso(skb) && (l4_proto == IPPROTO_UDP)) {
+		hisi_femac_do_udp_checksum(skb);
+		do_txcsum = false;
+	}
+
+	if (do_txcsum)
+		pkt_info |= BIT_FLAG_TXCSUM;
+
+	if (skb_is_gso(skb))
+		pkt_info |= (BIT_FLAG_SG | BIT_FLAG_TSO);
+	else if (skb_shinfo(skb)->nr_frags)
+		pkt_info |= BIT_FLAG_SG;
+
+	pkt_info |= (skb_shinfo(skb)->nr_frags << BIT_OFFSET_NFRAGS_NUM);
+	pkt_info |= (skb_is_gso(skb) ?
+		((skb_shinfo(skb)->gso_size > max_mss) ? max_mss :
+		skb_shinfo(skb)->gso_size) : (skb->len + ETH_FCS_LEN));
+
+	return pkt_info;
+}
+
+static int hisi_femac_fill_sg_desc(struct hisi_femac_priv *priv,
+				   struct sk_buff *skb, unsigned int pos)
+{
+	struct tx_desc *desc_cur;
+	dma_addr_t addr;
+	int ret;
+	int i;
+
+	desc_cur = priv->tx_ring.desc + pos;
+
+	desc_cur->ipv6_id = ntohl(skb_shinfo(skb)->ip6_frag_id);
+
+	desc_cur->total_len = skb->len;
+	addr = dma_map_single(priv->dev, skb->data, skb_headlen(skb),
+			      DMA_TO_DEVICE);
+	if (unlikely(dma_mapping_error(priv->dev, addr)))
+		return -EINVAL;
+	desc_cur->linear_addr = addr;
+	desc_cur->linear_len = skb_headlen(skb);
+
+	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
+		skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
+		int len = frag->size;
+
+		addr = skb_frag_dma_map(priv->dev, frag, 0, len, DMA_TO_DEVICE);
+		ret = dma_mapping_error(priv->dev, addr);
+		if (unlikely(ret))
+			return -EINVAL;
+		desc_cur->frags[i].addr = addr;
+		desc_cur->frags[i].size = len;
+	}
+
+	return 0;
+}
+
+static void hisi_femac_adjust_link(struct net_device *dev)
+{
+	struct hisi_femac_priv *priv = netdev_priv(dev);
+	struct phy_device *phy = dev->phydev;
+	u32 status = 0;
+
+	if (phy->link)
+		status |= MAC_PORTSET_LINKED;
+	if (phy->duplex == DUPLEX_FULL)
+		status |= MAC_PORTSET_DUPLEX_FULL;
+	if (phy->speed == SPEED_100)
+		status |= MAC_PORTSET_SPEED_100M;
+
+	if ((status != priv->link_status) &&
+	    ((status | priv->link_status) & MAC_PORTSET_LINKED)) {
+		writel(status, priv->port_base + MAC_PORTSET);
+		priv->link_status = status;
+		phy_print_status(phy);
+
+		priv->tx_pause_en = phy->pause;
+		hisi_femac_set_flow_ctrl(priv);
+	}
+}
+
+static void hisi_femac_rx_refill(struct hisi_femac_priv *priv)
+{
+	struct hisi_femac_queue *rxq = &priv->rxq;
+	struct sk_buff *skb;
+	u32 pos;
+	u32 len = MAX_FRAME_SIZE;
+	dma_addr_t addr;
+	u32 alloc_rxbuf_align = 0;
+	int reserve_room = 0;
+
+	pos = rxq->head;
+	while (readl(priv->port_base + ADDRQ_STAT) & BIT_RX_READY) {
+		if (!CIRC_SPACE(pos, rxq->tail, rxq->num))
+			break;
+		if (unlikely(rxq->skb[pos])) {
+			netdev_err(priv->ndev, "err skb[%d]=%p\n",
+				   pos, rxq->skb[pos]);
+			break;
+		}
+		len = MAX_FRAME_SIZE + RXBUF_ADDR_ALIGN_SIZE;
+		skb = netdev_alloc_skb_ip_align(priv->ndev, len);
+		if (unlikely(!skb))
+			break;
+
+		alloc_rxbuf_align = ((unsigned long)skb->data - NET_IP_ALIGN) &
+						(RXBUF_ADDR_ALIGN_SIZE - 1);
+		if (alloc_rxbuf_align) {
+			reserve_room = RXBUF_ADDR_ALIGN_SIZE -
+							alloc_rxbuf_align;
+			len -= reserve_room;
+			skb_reserve(skb, reserve_room);
+		}
+
+		addr = dma_map_single(priv->dev, skb->data, len,
+				      DMA_FROM_DEVICE);
+		if (dma_mapping_error(priv->dev, addr)) {
+			dev_kfree_skb_any(skb);
+			break;
+		}
+		rxq->dma_phys[pos] = addr;
+		rxq->skb[pos] = skb;
+		writel(addr, priv->port_base + IQ_ADDR);
+		pos = (pos + 1) % rxq->num;
+	}
+	rxq->head = pos;
+}
+
+static u32 hisi_femac_rx(struct net_device *dev, int limit)
+{
+	struct hisi_femac_priv *priv = netdev_priv(dev);
+	struct hisi_femac_queue *rxq = &priv->rxq;
+	struct sk_buff *skb;
+	dma_addr_t addr;
+	u32 rx_pkt_info, pos, len, rx_pkts_num = 0;
+	int hdr_csum_done, hdr_csum_err;
+	int payload_csum_done, payload_csum_err;
+
+	pos = rxq->tail;
+	while (readl(priv->glb_base + GLB_IRQ_RAW) & IRQ_INT_RX_RDY) {
+		rx_pkt_info = readl(priv->port_base + IQFRM_DES);
+		len = rx_pkt_info & RX_FRAME_LEN_MASK;
+		len -= ETH_FCS_LEN;
+
+		/* tell hardware we will deal with this packet */
+		writel(IRQ_INT_RX_RDY, priv->glb_base + GLB_IRQ_RAW);
+
+		rx_pkts_num++;
+
+		skb = rxq->skb[pos];
+		if (unlikely(!skb)) {
+			netdev_err(dev, "rx skb NULL. pos=%d\n", pos);
+			break;
+		}
+		rxq->skb[pos] = NULL;
+
+		addr = rxq->dma_phys[pos];
+		dma_unmap_single(priv->dev, addr, MAX_FRAME_SIZE,
+				 DMA_FROM_DEVICE);
+		skb_put(skb, len);
+		if (unlikely(skb->len > MAX_FRAME_SIZE)) {
+			netdev_err(dev, "rcv len err, len = %d\n", skb->len);
+			dev->stats.rx_errors++;
+			dev->stats.rx_length_errors++;
+			dev_kfree_skb_any(skb);
+			goto next;
+		}
+
+		skb->ip_summed = CHECKSUM_NONE;
+		if (dev->features & NETIF_F_RXCSUM) {
+			hdr_csum_done =
+				(rx_pkt_info >> BITS_HEADER_DONE_OFFSET) &
+				BITS_HEADER_DONE_MASK;
+			payload_csum_done =
+				(rx_pkt_info >> BITS_PAYLOAD_DONE_OFFSET) &
+				BITS_PAYLOAD_DONE_MASK;
+			hdr_csum_err =
+				(rx_pkt_info >> BITS_HEADER_ERR_OFFSET) &
+				BITS_HEADER_ERR_MASK;
+			payload_csum_err =
+				(rx_pkt_info >> BITS_PAYLOAD_ERR_OFFSET) &
+				BITS_PAYLOAD_ERR_MASK;
+
+			if (hdr_csum_done && payload_csum_done) {
+				if (unlikely(hdr_csum_err)) {
+					dev->stats.rx_errors++;
+					dev->stats.rx_crc_errors++;
+					dev_kfree_skb_any(skb);
+					goto next;
+				} else if (!payload_csum_err) {
+					skb->ip_summed = CHECKSUM_UNNECESSARY;
+				}
+			}
+		}
+
+		skb->protocol = eth_type_trans(skb, dev);
+		napi_gro_receive(&priv->napi, skb);
+		dev->stats.rx_packets++;
+		dev->stats.rx_bytes += skb->len;
+next:
+		pos = (pos + 1) % rxq->num;
+		if (rx_pkts_num >= limit)
+			break;
+	}
+	rxq->tail = pos;
+
+	hisi_femac_rx_refill(priv);
+
+	return rx_pkts_num;
+}
+
+static int hisi_femac_poll(struct napi_struct *napi, int budget)
+{
+	struct hisi_femac_priv *priv = container_of(napi,
+					struct hisi_femac_priv, napi);
+	struct net_device *dev = priv->ndev;
+	int work_done = 0, task = budget;
+	u32 ints, num;
+
+	do {
+		hisi_femac_xmit_reclaim(dev);
+		num = hisi_femac_rx(dev, task);
+		work_done += num;
+		task -= num;
+		if (work_done >= budget)
+			break;
+
+		ints = readl(priv->glb_base + GLB_IRQ_RAW);
+		writel(ints & DEF_INT_MASK,
+		       priv->glb_base + GLB_IRQ_RAW);
+	} while (ints & DEF_INT_MASK);
+
+	if (work_done < budget) {
+		napi_complete(napi);
+		hisi_femac_irq_enable(priv, DEF_INT_MASK &
+					(~IRQ_INT_TX_PER_PACKET));
+	}
+
+	return work_done;
+}
+
+static irqreturn_t hisi_femac_interrupt(int irq, void *dev_id)
+{
+	u32 ints;
+	struct net_device *dev = (struct net_device *)dev_id;
+	struct hisi_femac_priv *priv = netdev_priv(dev);
+
+	ints = readl(priv->glb_base + GLB_IRQ_RAW);
+
+	if (likely(ints & DEF_INT_MASK)) {
+		writel(ints & DEF_INT_MASK,
+		       priv->glb_base + GLB_IRQ_RAW);
+		hisi_femac_irq_disable(priv, DEF_INT_MASK);
+		napi_schedule(&priv->napi);
+	}
+
+	if (HAS_TSO_CAP(priv->hw_cap) &&
+	    unlikely(ints & INT_TX_ERR))
+		hisi_femac_get_tso_err_info(priv);
+
+	return IRQ_HANDLED;
+}
+
+static int hisi_femac_init_tx_descriptor_ring(struct hisi_femac_priv *priv)
+{
+	priv->tx_ring.desc = (struct tx_desc *)dma_zalloc_coherent(priv->dev,
+			TXQ_NUM * sizeof(struct tx_desc),
+			&priv->tx_ring.dma_phys,
+			GFP_KERNEL);
+	if (!priv->tx_ring.desc)
+		return -ENOMEM;
+
+	return 0;
+}
+
+static void hisi_femac_destroy_tx_descriptor_ring(struct hisi_femac_priv *priv)
+{
+	if (priv->tx_ring.desc)
+		dma_free_coherent(priv->dev,
+				  TXQ_NUM * sizeof(struct tx_desc),
+				  priv->tx_ring.desc, priv->tx_ring.dma_phys);
+	priv->tx_ring.desc = NULL;
+}
+
+static int hisi_femac_init_queue(struct device *dev,
+				 struct hisi_femac_queue *queue,
+				 unsigned int num)
+{
+	queue->skb = devm_kcalloc(dev, num, sizeof(struct sk_buff *),
+				  GFP_KERNEL);
+	if (!queue->skb)
+		return -ENOMEM;
+
+	queue->dma_phys = devm_kcalloc(dev, num, sizeof(dma_addr_t),
+				       GFP_KERNEL);
+	if (!queue->dma_phys)
+		return -ENOMEM;
+
+	queue->num = num;
+	queue->head = 0;
+	queue->tail = 0;
+
+	return 0;
+}
+
+static int hisi_femac_init_tx_and_rx_queues(struct hisi_femac_priv *priv)
+{
+	int ret;
+
+	ret = hisi_femac_init_queue(priv->dev, &priv->txq, TXQ_NUM);
+	if (ret)
+		return ret;
+
+	ret = hisi_femac_init_queue(priv->dev, &priv->rxq, RXQ_NUM);
+	if (ret)
+		return ret;
+
+	priv->tx_fifo_used_cnt = 0;
+
+	return 0;
+}
+
+static void hisi_femac_free_skb_rings(struct hisi_femac_priv *priv)
+{
+	struct hisi_femac_queue *txq = &priv->txq;
+	struct hisi_femac_queue *rxq = &priv->rxq;
+	struct sk_buff *skb;
+	dma_addr_t dma_addr;
+	u32 pos;
+
+	pos = rxq->tail;
+	while (pos != rxq->head) {
+		skb = rxq->skb[pos];
+		if (unlikely(!skb)) {
+			netdev_err(priv->ndev, "NULL rx skb. pos=%d, head=%d\n",
+				   pos, rxq->head);
+			continue;
+		}
+
+		dma_addr = rxq->dma_phys[pos];
+		dma_unmap_single(priv->dev, dma_addr, MAX_FRAME_SIZE,
+				 DMA_FROM_DEVICE);
+
+		dev_kfree_skb_any(skb);
+		rxq->skb[pos] = NULL;
+		pos = (pos + 1) % rxq->num;
+	}
+	rxq->tail = pos;
+
+	pos = txq->tail;
+	while (pos != txq->head) {
+		skb = txq->skb[pos];
+		if (unlikely(!skb)) {
+			netdev_err(priv->ndev, "NULL tx skb. pos=%d, head=%d\n",
+				   pos, txq->head);
+			continue;
+		}
+		hisi_femac_tx_dma_unmap(priv, skb, pos);
+		dev_kfree_skb_any(skb);
+		txq->skb[pos] = NULL;
+		pos = (pos + 1) % txq->num;
+	}
+	txq->tail = pos;
+	priv->tx_fifo_used_cnt = 0;
+}
+
+static int hisi_femac_set_hw_mac_addr(struct hisi_femac_priv *priv,
+				      unsigned char *mac)
+{
+	u32 reg;
+
+	reg = mac[1] | (mac[0] << 8);
+	writel(reg, priv->glb_base + GLB_HOSTMAC_H16);
+
+	reg = mac[5] | (mac[4] << 8) | (mac[3] << 16) | (mac[2] << 24);
+	writel(reg, priv->glb_base + GLB_HOSTMAC_L32);
+
+	return 0;
+}
+
+static int hisi_femac_port_reset(struct hisi_femac_priv *priv)
+{
+	u32 val;
+
+	val = readl(priv->glb_base + GLB_SOFT_RESET);
+	val |= SOFT_RESET_ALL;
+	writel(val, priv->glb_base + GLB_SOFT_RESET);
+
+	usleep_range(500, 800);
+
+	val &= ~SOFT_RESET_ALL;
+	writel(val, priv->glb_base + GLB_SOFT_RESET);
+
+	return 0;
+}
+
+static int hisi_femac_net_open(struct net_device *dev)
+{
+	struct hisi_femac_priv *priv = netdev_priv(dev);
+
+	hisi_femac_set_hw_mac_addr(priv, dev->dev_addr);
+	/* clear interrupts will drop the first packet MAC have received,
+	 * so do it before refill the rx free skbs.
+	 */
+	writel(IRQ_ENA_PORT0_MASK, priv->glb_base + GLB_IRQ_RAW);
+	hisi_femac_rx_refill(priv);
+
+	netif_carrier_off(dev);
+	netdev_reset_queue(dev);
+	netif_start_queue(dev);
+	napi_enable(&priv->napi);
+
+	priv->link_status = 0;
+	if (dev->phydev)
+		phy_start(dev->phydev);
+
+	hisi_femac_irq_enable(priv, IRQ_ENA_ALL | IRQ_ENA_PORT0 | DEF_INT_MASK);
+	if (HAS_TSO_CAP(priv->hw_cap))
+		hisi_femac_irq_enable(priv, INT_TX_ERR);
+
+	return 0;
+}
+
+static void hisi_femac_port_init(struct hisi_femac_priv *priv);
+
+static int hisi_femac_net_close(struct net_device *dev)
+{
+	struct hisi_femac_priv *priv = netdev_priv(dev);
+
+	hisi_femac_irq_disable(priv, IRQ_ENA_PORT0);
+
+	if (dev->phydev)
+		phy_stop(dev->phydev);
+
+	netif_stop_queue(dev);
+	napi_disable(&priv->napi);
+
+	/* reset MAC port first before free skb rings
+	 * to prevent potential risk of use-after-free.
+	 */
+	hisi_femac_port_reset(priv);
+	hisi_femac_port_init(priv);
+
+	priv->tx_pause_en = false;
+	hisi_femac_set_flow_ctrl(priv);
+	hisi_femac_free_skb_rings(priv);
+
+	return 0;
+}
+
+static netdev_tx_t hisi_femac_net_xmit(struct sk_buff *skb,
+				       struct net_device *dev)
+{
+	struct hisi_femac_priv *priv = netdev_priv(dev);
+	struct hisi_femac_queue *txq = &priv->txq;
+	dma_addr_t addr;
+	int ret;
+	u32 pkt_info;
+	u32 val;
+
+	val = readl(priv->port_base + ADDRQ_STAT);
+	val &= BIT_TX_READY;
+	if (!val) {
+		hisi_femac_irq_enable(priv, IRQ_INT_TX_PER_PACKET);
+		dev->stats.tx_dropped++;
+		dev->stats.tx_fifo_errors++;
+		netif_stop_queue(dev);
+		return NETDEV_TX_BUSY;
+	}
+
+	if (unlikely(!CIRC_SPACE(txq->head, txq->tail,
+				 txq->num))) {
+		hisi_femac_irq_enable(priv, IRQ_INT_TX_PER_PACKET);
+		dev->stats.tx_dropped++;
+		dev->stats.tx_fifo_errors++;
+		netif_stop_queue(dev);
+		return NETDEV_TX_BUSY;
+	}
+
+	ret = hisi_femac_check_hw_capability(skb);
+	if (unlikely(ret)) {
+		if (ret == -ENOTSUPP)
+			return hisi_femac_sw_gso(skb, dev);
+
+		dev_kfree_skb_any(skb);
+		dev->stats.tx_dropped++;
+		return NETDEV_TX_OK;
+	}
+
+	pkt_info = hisi_femac_get_pkt_info(skb);
+
+	if (!(skb_is_gso(skb) || skb_shinfo(skb)->nr_frags)) {
+		addr = dma_map_single(priv->dev, skb->data,
+				      skb->len, DMA_TO_DEVICE);
+		if (unlikely(dma_mapping_error(priv->dev, addr))) {
+			dev_kfree_skb_any(skb);
+			dev->stats.tx_dropped++;
+			return NETDEV_TX_OK;
+		}
+	} else {
+		ret = hisi_femac_fill_sg_desc(priv, skb, txq->head);
+		if (unlikely(ret)) {
+			dev_kfree_skb_any(skb);
+			dev->stats.tx_dropped++;
+			return NETDEV_TX_OK;
+		}
+
+		addr = priv->tx_ring.dma_phys +
+			txq->head * sizeof(struct tx_desc);
+
+		/* Ensure desc info writen to memory before config hardware */
+		wmb();
+	}
+	txq->dma_phys[txq->head] = addr;
+
+	txq->skb[txq->head] = skb;
+	txq->head = (txq->head + 1) % txq->num;
+
+	writel(addr, priv->port_base + EQ_ADDR);
+	writel(pkt_info, priv->port_base + EQFRM_LEN);
+
+	priv->tx_fifo_used_cnt++;
+
+	dev->stats.tx_packets++;
+	dev->stats.tx_bytes += skb->len;
+	netdev_sent_queue(dev, skb->len);
+
+	return NETDEV_TX_OK;
+}
+
+static int hisi_femac_set_mac_address(struct net_device *dev, void *p)
+{
+	struct hisi_femac_priv *priv = netdev_priv(dev);
+	struct sockaddr *skaddr = p;
+
+	if (!is_valid_ether_addr(skaddr->sa_data))
+		return -EADDRNOTAVAIL;
+
+	memcpy(dev->dev_addr, skaddr->sa_data, dev->addr_len);
+	dev->addr_assign_type &= ~NET_ADDR_RANDOM;
+
+	hisi_femac_set_hw_mac_addr(priv, dev->dev_addr);
+
+	return 0;
+}
+
+static void hisi_femac_enable_hw_addr_filter(struct hisi_femac_priv *priv,
+					     unsigned int reg_n, bool enable)
+{
+	u32 val;
+
+	val = readl(priv->glb_base + GLB_MAC_H16(reg_n));
+	if (enable)
+		val |= BIT_MACFLT_ENA;
+	else
+		val &= ~BIT_MACFLT_ENA;
+	writel(val, priv->glb_base + GLB_MAC_H16(reg_n));
+}
+
+static void hisi_femac_set_hw_addr_filter(struct hisi_femac_priv *priv,
+					  unsigned char *addr,
+					  unsigned int reg_n)
+{
+	unsigned int high, low;
+	u32 val;
+
+	high = GLB_MAC_H16(reg_n);
+	low = GLB_MAC_L32(reg_n);
+
+	val = (addr[2] << 24) | (addr[3] << 16) | (addr[4] << 8) | addr[5];
+	writel(val, priv->glb_base + low);
+
+	val = readl(priv->glb_base + high);
+	val &= ~MACFLT_HI16_MASK;
+	val |= ((addr[0] << 8) | addr[1]);
+	val |= (BIT_MACFLT_ENA | BIT_MACFLT_FW2CPU);
+	writel(val, priv->glb_base + high);
+}
+
+static void hisi_femac_set_promisc_mode(struct hisi_femac_priv *priv,
+					bool promisc_mode)
+{
+	u32 val;
+
+	val = readl(priv->glb_base + GLB_FWCTRL);
+	if (promisc_mode)
+		val |= FWCTRL_FWALL2CPU;
+	else
+		val &= ~FWCTRL_FWALL2CPU;
+	writel(val, priv->glb_base + GLB_FWCTRL);
+}
+
+/* Handle multiple multicast addresses (perfect filtering)*/
+static void hisi_femac_set_mc_addr_filter(struct hisi_femac_priv *priv)
+{
+	struct net_device *dev = priv->ndev;
+	u32 val;
+
+	val = readl(priv->glb_base + GLB_MACTCTRL);
+	if ((netdev_mc_count(dev) > MAX_MULTICAST_ADDRESSES) ||
+	    (dev->flags & IFF_ALLMULTI)) {
+		val |= MACTCTRL_MULTI2CPU;
+	} else {
+		int reg = MAX_UNICAST_ADDRESSES;
+		int i;
+		struct netdev_hw_addr *ha;
+
+		for (i = reg; i < MAX_MAC_FILTER_NUM; i++)
+			hisi_femac_enable_hw_addr_filter(priv, i, false);
+
+		netdev_for_each_mc_addr(ha, dev) {
+			hisi_femac_set_hw_addr_filter(priv, ha->addr, reg);
+			reg++;
+		}
+		val &= ~MACTCTRL_MULTI2CPU;
+	}
+	writel(val, priv->glb_base + GLB_MACTCTRL);
+}
+
+/* Handle multiple unicast addresses (perfect filtering)*/
+static void hisi_femac_set_uc_addr_filter(struct hisi_femac_priv *priv)
+{
+	struct net_device *dev = priv->ndev;
+	u32 val;
+
+	val = readl(priv->glb_base + GLB_MACTCTRL);
+	if (netdev_uc_count(dev) > MAX_UNICAST_ADDRESSES) {
+		val |= MACTCTRL_UNI2CPU;
+	} else {
+		int reg = 0;
+		int i;
+		struct netdev_hw_addr *ha;
+
+		for (i = reg; i < MAX_UNICAST_ADDRESSES; i++)
+			hisi_femac_enable_hw_addr_filter(priv, i, false);
+
+		netdev_for_each_uc_addr(ha, dev) {
+			hisi_femac_set_hw_addr_filter(priv, ha->addr, reg);
+			reg++;
+		}
+		val &= ~MACTCTRL_UNI2CPU;
+	}
+	writel(val, priv->glb_base + GLB_MACTCTRL);
+}
+
+static void hisi_femac_net_set_rx_mode(struct net_device *dev)
+{
+	struct hisi_femac_priv *priv = netdev_priv(dev);
+
+	if (dev->flags & IFF_PROMISC) {
+		hisi_femac_set_promisc_mode(priv, true);
+	} else {
+		hisi_femac_set_promisc_mode(priv, false);
+		hisi_femac_set_mc_addr_filter(priv);
+		hisi_femac_set_uc_addr_filter(priv);
+	}
+}
+
+static int hisi_femac_net_ioctl(struct net_device *dev,
+				struct ifreq *ifreq, int cmd)
+{
+	if (!netif_running(dev))
+		return -EINVAL;
+
+	if (!dev->phydev)
+		return -EINVAL;
+
+	return phy_mii_ioctl(dev->phydev, ifreq, cmd);
+}
+
+static void hisi_femac_get_pauseparam(struct net_device *dev,
+				      struct ethtool_pauseparam *pause)
+{
+	struct hisi_femac_priv *priv = netdev_priv(dev);
+
+	pause->autoneg = dev->phydev->autoneg;
+	pause->rx_pause = 1;
+	if (priv->tx_pause_en)
+		pause->tx_pause = 1;
+}
+
+static int hisi_femac_set_pauseparam(struct net_device *dev,
+				     struct ethtool_pauseparam *pause)
+{
+	struct hisi_femac_priv *priv = netdev_priv(dev);
+	struct phy_device *phy = dev->phydev;
+	int ret = 0;
+
+	if (pause->rx_pause == 0)
+		return -EINVAL;
+
+	if (pause->tx_pause != priv->tx_pause_en) {
+		priv->tx_pause_en = pause->tx_pause;
+		hisi_femac_set_flow_ctrl(priv);
+	}
+
+	if (phy->autoneg) {
+		if (netif_running(dev)) {
+			struct ethtool_cmd cmd;
+			/* auto-negotiation automatically restarted */
+			cmd.cmd = ETHTOOL_NWAY_RST;
+			cmd.supported = phy->supported;
+			cmd.advertising = phy->advertising;
+			cmd.autoneg = phy->autoneg;
+			cmd.speed = phy->speed;
+			cmd.duplex = phy->duplex;
+			cmd.phy_address = phy->mdio.addr;
+			ret = phy_ethtool_sset(phy, &cmd);
+		}
+	}
+
+	return ret;
+}
+
+static void hisi_femac_enable_rxcsum_drop(struct hisi_femac_priv *priv,
+					  bool drop)
+{
+	unsigned int val;
+
+	val = readl(priv->port_base + RX_COE_CTRL);
+	val &= ~COE_ERR_DROP;
+	if (drop)
+		val |= (BIT_COE_IPHDR_DROP | BIT_COE_IPV6_UDP_ZERO_DROP);
+	writel(val, priv->port_base + RX_COE_CTRL);
+}
+
+static int hisi_femac_set_features(struct net_device *dev,
+				   netdev_features_t features)
+{
+	struct hisi_femac_priv *priv = netdev_priv(dev);
+	netdev_features_t changed = dev->features ^ features;
+
+	if (changed & NETIF_F_RXCSUM) {
+		if (features & NETIF_F_RXCSUM)
+			hisi_femac_enable_rxcsum_drop(priv, true);
+		else
+			hisi_femac_enable_rxcsum_drop(priv, false);
+	}
+
+	return 0;
+}
+
+static const struct ethtool_ops hisi_femac_ethtools_ops = {
+	.get_link		= ethtool_op_get_link,
+	.get_link_ksettings	= phy_ethtool_get_link_ksettings,
+	.set_link_ksettings	= phy_ethtool_set_link_ksettings,
+	.get_pauseparam		= hisi_femac_get_pauseparam,
+	.set_pauseparam		= hisi_femac_set_pauseparam,
+};
+
+static const struct net_device_ops hisi_femac_netdev_ops = {
+	.ndo_open		= hisi_femac_net_open,
+	.ndo_stop		= hisi_femac_net_close,
+	.ndo_start_xmit		= hisi_femac_net_xmit,
+	.ndo_do_ioctl		= hisi_femac_net_ioctl,
+	.ndo_set_mac_address	= hisi_femac_set_mac_address,
+	.ndo_set_rx_mode	= hisi_femac_net_set_rx_mode,
+	.ndo_change_mtu		= eth_change_mtu,
+	.ndo_set_features	= hisi_femac_set_features,
+};
+
+static void hisi_femac_verify_flow_ctrl_args(struct hisi_femac_priv *priv)
+{
+	if (priv->tx_pause_active_thresh < FC_ACTIVE_MIN ||
+	    priv->tx_pause_active_thresh > FC_ACTIVE_MAX)
+		priv->tx_pause_active_thresh = FC_ACTIVE_DEFAULT;
+
+	if (priv->tx_pause_deactive_thresh < FC_DEACTIVE_MIN ||
+	    priv->tx_pause_deactive_thresh > FC_DEACTIVE_MAX)
+		priv->tx_pause_deactive_thresh = FC_DEACTIVE_DEFAULT;
+
+	if (priv->tx_pause_active_thresh >= priv->tx_pause_deactive_thresh) {
+		priv->tx_pause_active_thresh = FC_ACTIVE_DEFAULT;
+		priv->tx_pause_deactive_thresh = FC_DEACTIVE_DEFAULT;
+	}
+}
+
+static void hisi_femac_core_reset(struct hisi_femac_priv *priv)
+{
+	reset_control_assert(priv->mac_rst);
+	reset_control_deassert(priv->mac_rst);
+}
+
+static void hisi_femac_sleep_us(u32 time_us)
+{
+	u32 time_ms;
+
+	if (!time_us)
+		return;
+
+	time_ms = DIV_ROUND_UP(time_us, 1000);
+	if (time_ms < 20)
+		usleep_range(time_us, time_us + 500);
+	else
+		msleep(time_ms);
+}
+
+static void hisi_femac_phy_reset(struct hisi_femac_priv *priv)
+{
+	/* To make sure PHY hardware reset success,
+	 * we must keep PHY in deassert state first and
+	 * then complete the hardware reset operation
+	 */
+	reset_control_deassert(priv->phy_rst);
+	hisi_femac_sleep_us(priv->phy_reset_delays[PRE_DELAY]);
+
+	reset_control_assert(priv->phy_rst);
+	/* delay some time to ensure reset ok,
+	 * this depends on PHY hardware feature
+	 */
+	hisi_femac_sleep_us(priv->phy_reset_delays[PULSE]);
+	reset_control_deassert(priv->phy_rst);
+	/* delay some time to ensure later MDIO access */
+	hisi_femac_sleep_us(priv->phy_reset_delays[POST_DELAY]);
+}
+
+static void hisi_femac_port_init(struct hisi_femac_priv *priv)
+{
+	u32 val;
+
+	/* MAC gets link status info and phy mode by software config */
+	val = MAC_PORTSEL_STAT_CPU;
+	if (priv->ndev->phydev->interface == PHY_INTERFACE_MODE_RMII)
+		val |= MAC_PORTSEL_RMII;
+	writel(val, priv->port_base + MAC_PORTSEL);
+
+	/*clear all interrupt status */
+	writel(IRQ_ENA_PORT0_MASK, priv->glb_base + GLB_IRQ_RAW);
+	hisi_femac_irq_disable(priv, IRQ_ENA_PORT0_MASK | IRQ_ENA_PORT0);
+
+	if (HAS_TSO_CAP(priv->hw_cap)) {
+		/* enable TSO debug for error handle */
+		val = readl(priv->port_base + TSO_DBG_EN);
+		val |= BITS_TSO_DBG_EN;
+		writel(val, priv->port_base + TSO_DBG_EN);
+	}
+
+	val = readl(priv->glb_base + GLB_FWCTRL);
+	val &= ~(FWCTRL_VLAN_ENABLE | FWCTRL_FWALL2CPU);
+	val |= FWCTRL_FW2CPU_ENA;
+	writel(val, priv->glb_base + GLB_FWCTRL);
+
+	val = readl(priv->glb_base + GLB_MACTCTRL);
+	val |= (MACTCTRL_BROAD2CPU | MACTCTRL_MACT_ENA);
+	writel(val, priv->glb_base + GLB_MACTCTRL);
+
+	val = readl(priv->port_base + MAC_SET);
+	val &= ~MAX_FRAME_SIZE_MASK;
+	val |= MAX_FRAME_SIZE;
+	writel(val, priv->port_base + MAC_SET);
+
+	val = RX_COALESCED_TIMER |
+		(RX_COALESCED_FRAMES << RX_COALESCED_FRAME_OFFSET);
+	writel(val, priv->port_base + RX_COALESCE_SET);
+
+	val = (HW_RX_FIFO_DEPTH << RX_DEPTH_OFFSET) | HW_TX_FIFO_DEPTH;
+	writel(val, priv->port_base + QLEN_SET);
+
+	hisi_femac_set_flow_ctrl(priv);
+}
+
+static int hisi_femac_drv_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct device_node *node = dev->of_node;
+	struct resource *res;
+	struct net_device *ndev;
+	struct hisi_femac_priv *priv;
+	struct phy_device *phy;
+	const char *mac_addr;
+	int ret;
+
+	ndev = alloc_etherdev(sizeof(*priv));
+	if (!ndev)
+		return -ENOMEM;
+
+	platform_set_drvdata(pdev, ndev);
+	SET_NETDEV_DEV(ndev, &pdev->dev);
+
+	priv = netdev_priv(ndev);
+	priv->dev = dev;
+	priv->ndev = ndev;
+
+	if (of_device_is_compatible(node, "hisilicon,hisi-femac-v2"))
+		priv->hw_cap |= HW_CAP_TSO | HW_CAP_RXCSUM;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	priv->port_base = devm_ioremap_resource(dev, res);
+	if (IS_ERR(priv->port_base)) {
+		ret = PTR_ERR(priv->port_base);
+		goto out_free_netdev;
+	}
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 1);
+	priv->glb_base = devm_ioremap_resource(dev, res);
+	if (IS_ERR(priv->glb_base)) {
+		ret = PTR_ERR(priv->glb_base);
+		goto out_free_netdev;
+	}
+
+	priv->clk = devm_clk_get(&pdev->dev, NULL);
+	if (IS_ERR(priv->clk)) {
+		dev_err(dev, "failed to get clk\n");
+		ret = -ENODEV;
+		goto out_free_netdev;
+	}
+
+	ret = clk_prepare_enable(priv->clk);
+	if (ret) {
+		dev_err(dev, "failed to enable clk %d\n", ret);
+		goto out_free_netdev;
+	}
+
+	priv->mac_rst = devm_reset_control_get(dev, "mac");
+	if (IS_ERR(priv->mac_rst)) {
+		ret = PTR_ERR(priv->mac_rst);
+		goto out_disable_clk;
+	}
+	hisi_femac_core_reset(priv);
+
+	priv->phy_rst = devm_reset_control_get(dev, "phy");
+	if (IS_ERR(priv->phy_rst)) {
+		priv->phy_rst = NULL;
+	} else {
+		ret = of_property_read_u32_array(node,
+						 PHY_RESET_DELAYS_PROPERTY,
+						 priv->phy_reset_delays,
+						 DELAYS_NUM);
+		if (ret)
+			goto out_disable_clk;
+		hisi_femac_phy_reset(priv);
+	}
+
+	phy_register_fixups();
+
+	phy = of_phy_get_and_connect(ndev, node, hisi_femac_adjust_link);
+	if (!phy) {
+		dev_err(dev, "connect to PHY failed!\n");
+		ret = -ENODEV;
+		goto out_disable_clk;
+	}
+
+	phy->advertising |= ADVERTISED_Pause;
+	phy->supported |= ADVERTISED_Pause;
+
+	phy->advertising &= ~(ADVERTISED_1000baseT_Full |
+			      ADVERTISED_1000baseT_Half);
+
+	phy_attached_print(phy, "phy_id=0x%.8lx, phy_mode=%s\n",
+			   (unsigned long)phy->phy_id,
+			   phy_modes(phy->interface));
+
+	mac_addr = of_get_mac_address(node);
+	if (mac_addr)
+		ether_addr_copy(ndev->dev_addr, mac_addr);
+	if (!is_valid_ether_addr(ndev->dev_addr)) {
+		eth_hw_addr_random(ndev);
+		dev_warn(dev, "using random MAC address %pM\n",
+			 ndev->dev_addr);
+	}
+
+	ndev->watchdog_timeo = 6 * HZ;
+	ndev->priv_flags |= IFF_UNICAST_FLT;
+	ndev->netdev_ops = &hisi_femac_netdev_ops;
+	ndev->ethtool_ops = &hisi_femac_ethtools_ops;
+	netif_napi_add(ndev, &priv->napi, hisi_femac_poll, FEMAC_POLL_WEIGHT);
+
+	if (HAS_TSO_CAP(priv->hw_cap))
+		ndev->hw_features |= NETIF_F_SG |
+			NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM |
+			NETIF_F_TSO | NETIF_F_TSO6 | NETIF_F_UFO;
+
+	if (HAS_RXCSUM_CAP(priv->hw_cap))
+		ndev->hw_features |= NETIF_F_RXCSUM;
+	ndev->features |= ndev->hw_features;
+	ndev->vlan_features |= ndev->features;
+
+	device_set_wakeup_capable(priv->dev, true);
+	device_set_wakeup_enable(priv->dev, true);
+
+	priv->tx_pause_en = true;
+	priv->tx_pause_active_thresh = TX_FLOW_CTRL_ACTIVE_THRESHOLD;
+	priv->tx_pause_deactive_thresh = TX_FLOW_CTRL_DEACTIVE_THRESHOLD;
+
+	hisi_femac_verify_flow_ctrl_args(priv);
+
+	hisi_femac_port_init(priv);
+
+	if (HAS_RXCSUM_CAP(priv->hw_cap))
+		hisi_femac_enable_rxcsum_drop(priv, true);
+
+	ret = hisi_femac_init_tx_and_rx_queues(priv);
+	if (ret)
+		goto out_disconnect_phy;
+
+	if (HAS_TSO_CAP(priv->hw_cap)) {
+		ret = hisi_femac_init_tx_descriptor_ring(priv);
+		if (ret)
+			goto out_disconnect_phy;
+	}
+
+	ndev->irq = platform_get_irq(pdev, 0);
+	if (ndev->irq <= 0) {
+		dev_err(dev, "No irq resource\n");
+		ret = -ENODEV;
+		goto out_destroy_descriptor;
+	}
+
+	ret = devm_request_irq(dev, ndev->irq, hisi_femac_interrupt,
+			       IRQF_SHARED, pdev->name, ndev);
+	if (ret) {
+		dev_err(dev, "devm_request_irq %d failed!\n", ndev->irq);
+		goto out_destroy_descriptor;
+	}
+
+	ret = register_netdev(ndev);
+	if (ret) {
+		dev_err(dev, "register_netdev failed!\n");
+		goto out_destroy_descriptor;
+	}
+
+	return ret;
+
+out_destroy_descriptor:
+	if (HAS_TSO_CAP(priv->hw_cap))
+		hisi_femac_destroy_tx_descriptor_ring(priv);
+out_disconnect_phy:
+	netif_napi_del(&priv->napi);
+	phy_disconnect(phy);
+out_disable_clk:
+	clk_disable_unprepare(priv->clk);
+out_free_netdev:
+	free_netdev(ndev);
+
+	return ret;
+}
+
+static int hisi_femac_drv_remove(struct platform_device *pdev)
+{
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct hisi_femac_priv *priv = netdev_priv(ndev);
+
+	netif_napi_del(&priv->napi);
+	unregister_netdev(ndev);
+	if (HAS_TSO_CAP(priv->hw_cap))
+		hisi_femac_destroy_tx_descriptor_ring(priv);
+
+	phy_disconnect(ndev->phydev);
+	clk_disable_unprepare(priv->clk);
+	free_netdev(ndev);
+
+	phy_unregister_fixups();
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int hisi_femac_drv_suspend(struct platform_device *pdev,
+				  pm_message_t state)
+{
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct hisi_femac_priv *priv = netdev_priv(ndev);
+
+	disable_irq(ndev->irq);
+	if (netif_running(ndev)) {
+		hisi_femac_net_close(ndev);
+		netif_device_detach(ndev);
+	}
+
+	clk_disable_unprepare(priv->clk);
+
+	return 0;
+}
+
+static int hisi_femac_drv_resume(struct platform_device *pdev)
+{
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct hisi_femac_priv *priv = netdev_priv(ndev);
+
+	clk_prepare_enable(priv->clk);
+	if (priv->phy_rst)
+		hisi_femac_phy_reset(priv);
+
+	if (netif_running(ndev)) {
+		hisi_femac_port_init(priv);
+		hisi_femac_net_open(ndev);
+		netif_device_attach(ndev);
+	}
+	enable_irq(ndev->irq);
+
+	return 0;
+}
+#endif
+
+static const struct of_device_id hisi_femac_match[] = {
+	{.compatible = "hisilicon,hisi-femac-v1",},
+	{.compatible = "hisilicon,hisi-femac-v2",},
+	{.compatible = "hisilicon,hi3516cv300-femac",},
+	{.compatible = "hisilicon,hi3536dv100-femac",},
+	{},
+};
+
+MODULE_DEVICE_TABLE(of, hisi_femac_match);
+
+static struct platform_driver hisi_femac_driver = {
+	.driver = {
+		.name = "hisi-femac",
+		.of_match_table = hisi_femac_match,
+	},
+	.probe = hisi_femac_drv_probe,
+	.remove = hisi_femac_drv_remove,
+#ifdef CONFIG_PM
+	.suspend = hisi_femac_drv_suspend,
+	.resume = hisi_femac_drv_resume,
+#endif
+};
+
+module_platform_driver(hisi_femac_driver);
+
+MODULE_DESCRIPTION("Hisilicon Fast Ethernet MAC driver");
+MODULE_AUTHOR("Dongpo Li <lidongpo@hisilicon.com>");
+MODULE_LICENSE("GPL v2");
+MODULE_ALIAS("platform:hisi-femac");
diff --git a/drivers/net/ethernet/hisilicon/hisi-femac/phy_fix.c b/drivers/net/ethernet/hisilicon/hisi-femac/phy_fix.c
new file mode 100644
index 0000000..6a6e246
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/hisi-femac/phy_fix.c
@@ -0,0 +1,58 @@
+#include <linux/phy.h>
+#include "phy_fix.h"
+
+static const u32 phy_v272_fix_param[] = {
+#include "festa_v272_2723.h"
+};
+
+static int phy_expanded_write_bulk(struct phy_device *phy_dev,
+				   const u32 reg_and_val[], int count)
+{
+	int i, v, ret = 0;
+	u32 reg_addr;
+	u16 val;
+
+	v = phy_read(phy_dev, MII_BMCR);
+	v |= BMCR_PDOWN;
+	phy_write(phy_dev, MII_BMCR, v);
+
+	for (i = 0; i < (2 * count); i += 2) {
+		reg_addr = reg_and_val[i];
+		val = (u16)reg_and_val[i + 1];
+		phy_write(phy_dev, MII_EXPMA, reg_addr);
+		ret = phy_write(phy_dev, MII_EXPMD, val);
+	}
+
+	v = phy_read(phy_dev, MII_BMCR);
+	v &= (~BMCR_PDOWN);
+	phy_write(phy_dev, MII_BMCR, v);
+
+	return ret;
+}
+
+static int hisilicon_fephy_v272_fix(struct phy_device *phy_dev)
+{
+	int count;
+
+	count = ARRAY_SIZE(phy_v272_fix_param);
+	if (count % 2)
+		pr_warn("internal FEPHY fix register count is not right.\n");
+	count /= 2;
+
+	phy_expanded_write_bulk(phy_dev, phy_v272_fix_param, count);
+
+	return 0;
+}
+
+void phy_register_fixups(void)
+{
+	phy_register_fixup_for_uid(HISILICON_PHY_ID_FESTAV272,
+				   HISILICON_PHY_MASK,
+				   hisilicon_fephy_v272_fix);
+}
+
+void phy_unregister_fixups(void)
+{
+	phy_unregister_fixup_for_uid(HISILICON_PHY_ID_FESTAV272,
+				     HISILICON_PHY_MASK);
+}
diff --git a/drivers/net/ethernet/hisilicon/hisi-femac/phy_fix.h b/drivers/net/ethernet/hisilicon/hisi-femac/phy_fix.h
new file mode 100644
index 0000000..1e3d59e
--- /dev/null
+++ b/drivers/net/ethernet/hisilicon/hisi-femac/phy_fix.h
@@ -0,0 +1,8 @@
+#define HISILICON_PHY_ID_FESTAV272	0x20669901
+#define HISILICON_PHY_MASK		0xfffffff0
+
+#define MII_EXPMD		0x1d
+#define MII_EXPMA		0x1e
+
+void phy_register_fixups(void);
+void phy_unregister_fixups(void);
diff --git a/drivers/net/ethernet/hisilicon/hisi_femac.c b/drivers/net/ethernet/hisilicon/hisi_femac.c
deleted file mode 100644
index ced1859..0000000
--- a/drivers/net/ethernet/hisilicon/hisi_femac.c
+++ /dev/null
@@ -1,1007 +0,0 @@
-/*
- * Hisilicon Fast Ethernet MAC Driver
- *
- * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program. If not, see <http://www.gnu.org/licenses/>.
- */
-
-#include <linux/circ_buf.h>
-#include <linux/clk.h>
-#include <linux/etherdevice.h>
-#include <linux/interrupt.h>
-#include <linux/module.h>
-#include <linux/of_mdio.h>
-#include <linux/of_net.h>
-#include <linux/platform_device.h>
-#include <linux/reset.h>
-
-/* MAC control register list */
-#define MAC_PORTSEL			0x0200
-#define MAC_PORTSEL_STAT_CPU		BIT(0)
-#define MAC_PORTSEL_RMII		BIT(1)
-#define MAC_PORTSET			0x0208
-#define MAC_PORTSET_DUPLEX_FULL		BIT(0)
-#define MAC_PORTSET_LINKED		BIT(1)
-#define MAC_PORTSET_SPEED_100M		BIT(2)
-#define MAC_SET				0x0210
-#define MAX_FRAME_SIZE			1600
-#define MAX_FRAME_SIZE_MASK		GENMASK(10, 0)
-#define BIT_PAUSE_EN			BIT(18)
-#define RX_COALESCE_SET			0x0340
-#define RX_COALESCED_FRAME_OFFSET	24
-#define RX_COALESCED_FRAMES		8
-#define RX_COALESCED_TIMER		0x74
-#define QLEN_SET			0x0344
-#define RX_DEPTH_OFFSET			8
-#define MAX_HW_FIFO_DEPTH		64
-#define HW_TX_FIFO_DEPTH		12
-#define HW_RX_FIFO_DEPTH		(MAX_HW_FIFO_DEPTH - HW_TX_FIFO_DEPTH)
-#define IQFRM_DES			0x0354
-#define RX_FRAME_LEN_MASK		GENMASK(11, 0)
-#define IQ_ADDR				0x0358
-#define EQ_ADDR				0x0360
-#define EQFRM_LEN			0x0364
-#define ADDRQ_STAT			0x036C
-#define TX_CNT_INUSE_MASK		GENMASK(5, 0)
-#define BIT_TX_READY			BIT(24)
-#define BIT_RX_READY			BIT(25)
-/* global control register list */
-#define GLB_HOSTMAC_L32			0x0000
-#define GLB_HOSTMAC_H16			0x0004
-#define GLB_SOFT_RESET			0x0008
-#define SOFT_RESET_ALL			BIT(0)
-#define GLB_FWCTRL			0x0010
-#define FWCTRL_VLAN_ENABLE		BIT(0)
-#define FWCTRL_FW2CPU_ENA		BIT(5)
-#define FWCTRL_FWALL2CPU		BIT(7)
-#define GLB_MACTCTRL			0x0014
-#define MACTCTRL_UNI2CPU		BIT(1)
-#define MACTCTRL_MULTI2CPU		BIT(3)
-#define MACTCTRL_BROAD2CPU		BIT(5)
-#define MACTCTRL_MACT_ENA		BIT(7)
-#define GLB_IRQ_STAT			0x0030
-#define GLB_IRQ_ENA			0x0034
-#define IRQ_ENA_PORT0_MASK		GENMASK(7, 0)
-#define IRQ_ENA_PORT0			BIT(18)
-#define IRQ_ENA_ALL			BIT(19)
-#define GLB_IRQ_RAW			0x0038
-#define IRQ_INT_RX_RDY			BIT(0)
-#define IRQ_INT_TX_PER_PACKET		BIT(1)
-#define IRQ_INT_TX_FIFO_EMPTY		BIT(6)
-#define IRQ_INT_MULTI_RXRDY		BIT(7)
-#define DEF_INT_MASK			(IRQ_INT_MULTI_RXRDY | \
-					IRQ_INT_TX_PER_PACKET | \
-					IRQ_INT_TX_FIFO_EMPTY)
-#define GLB_MAC_L32_BASE		0x0100
-#define GLB_MAC_H16_BASE		0x0104
-#define MACFLT_HI16_MASK		GENMASK(15, 0)
-#define BIT_MACFLT_ENA			BIT(17)
-#define BIT_MACFLT_FW2CPU		BIT(21)
-#define GLB_MAC_H16(reg)		(GLB_MAC_H16_BASE + ((reg) * 0x8))
-#define GLB_MAC_L32(reg)		(GLB_MAC_L32_BASE + ((reg) * 0x8))
-#define MAX_MAC_FILTER_NUM		8
-#define MAX_UNICAST_ADDRESSES		2
-#define MAX_MULTICAST_ADDRESSES		(MAX_MAC_FILTER_NUM - \
-					MAX_UNICAST_ADDRESSES)
-/* software tx and rx queue number, should be power of 2 */
-#define TXQ_NUM				64
-#define RXQ_NUM				128
-#define FEMAC_POLL_WEIGHT		16
-
-#define PHY_RESET_DELAYS_PROPERTY	"hisilicon,phy-reset-delays-us"
-
-enum phy_reset_delays {
-	PRE_DELAY,
-	PULSE,
-	POST_DELAY,
-	DELAYS_NUM,
-};
-
-struct hisi_femac_queue {
-	struct sk_buff **skb;
-	dma_addr_t *dma_phys;
-	int num;
-	unsigned int head;
-	unsigned int tail;
-};
-
-struct hisi_femac_priv {
-	void __iomem *port_base;
-	void __iomem *glb_base;
-	struct clk *clk;
-	struct reset_control *mac_rst;
-	struct reset_control *phy_rst;
-	u32 phy_reset_delays[DELAYS_NUM];
-	u32 link_status;
-
-	struct device *dev;
-	struct net_device *ndev;
-
-	struct hisi_femac_queue txq;
-	struct hisi_femac_queue rxq;
-	u32 tx_fifo_used_cnt;
-	struct napi_struct napi;
-};
-
-static void hisi_femac_irq_enable(struct hisi_femac_priv *priv, int irqs)
-{
-	u32 val;
-
-	val = readl(priv->glb_base + GLB_IRQ_ENA);
-	writel(val | irqs, priv->glb_base + GLB_IRQ_ENA);
-}
-
-static void hisi_femac_irq_disable(struct hisi_femac_priv *priv, int irqs)
-{
-	u32 val;
-
-	val = readl(priv->glb_base + GLB_IRQ_ENA);
-	writel(val & (~irqs), priv->glb_base + GLB_IRQ_ENA);
-}
-
-static void hisi_femac_tx_dma_unmap(struct hisi_femac_priv *priv,
-				    struct sk_buff *skb, unsigned int pos)
-{
-	dma_addr_t dma_addr;
-
-	dma_addr = priv->txq.dma_phys[pos];
-	dma_unmap_single(priv->dev, dma_addr, skb->len, DMA_TO_DEVICE);
-}
-
-static void hisi_femac_xmit_reclaim(struct net_device *dev)
-{
-	struct sk_buff *skb;
-	struct hisi_femac_priv *priv = netdev_priv(dev);
-	struct hisi_femac_queue *txq = &priv->txq;
-	unsigned int bytes_compl = 0, pkts_compl = 0;
-	u32 val;
-
-	netif_tx_lock(dev);
-
-	val = readl(priv->port_base + ADDRQ_STAT) & TX_CNT_INUSE_MASK;
-	while (val < priv->tx_fifo_used_cnt) {
-		skb = txq->skb[txq->tail];
-		if (unlikely(!skb)) {
-			netdev_err(dev, "xmitq_cnt_inuse=%d, tx_fifo_used=%d\n",
-				   val, priv->tx_fifo_used_cnt);
-			break;
-		}
-		hisi_femac_tx_dma_unmap(priv, skb, txq->tail);
-		pkts_compl++;
-		bytes_compl += skb->len;
-		dev_kfree_skb_any(skb);
-
-		priv->tx_fifo_used_cnt--;
-
-		val = readl(priv->port_base + ADDRQ_STAT) & TX_CNT_INUSE_MASK;
-		txq->skb[txq->tail] = NULL;
-		txq->tail = (txq->tail + 1) % txq->num;
-	}
-
-	netdev_completed_queue(dev, pkts_compl, bytes_compl);
-
-	if (unlikely(netif_queue_stopped(dev)) && pkts_compl)
-		netif_wake_queue(dev);
-
-	netif_tx_unlock(dev);
-}
-
-static void hisi_femac_adjust_link(struct net_device *dev)
-{
-	struct hisi_femac_priv *priv = netdev_priv(dev);
-	struct phy_device *phy = dev->phydev;
-	u32 status = 0;
-
-	if (phy->link)
-		status |= MAC_PORTSET_LINKED;
-	if (phy->duplex == DUPLEX_FULL)
-		status |= MAC_PORTSET_DUPLEX_FULL;
-	if (phy->speed == SPEED_100)
-		status |= MAC_PORTSET_SPEED_100M;
-
-	if ((status != priv->link_status) &&
-	    ((status | priv->link_status) & MAC_PORTSET_LINKED)) {
-		writel(status, priv->port_base + MAC_PORTSET);
-		priv->link_status = status;
-		phy_print_status(phy);
-	}
-}
-
-static void hisi_femac_rx_refill(struct hisi_femac_priv *priv)
-{
-	struct hisi_femac_queue *rxq = &priv->rxq;
-	struct sk_buff *skb;
-	u32 pos;
-	u32 len = MAX_FRAME_SIZE;
-	dma_addr_t addr;
-
-	pos = rxq->head;
-	while (readl(priv->port_base + ADDRQ_STAT) & BIT_RX_READY) {
-		if (!CIRC_SPACE(pos, rxq->tail, rxq->num))
-			break;
-		if (unlikely(rxq->skb[pos])) {
-			netdev_err(priv->ndev, "err skb[%d]=%p\n",
-				   pos, rxq->skb[pos]);
-			break;
-		}
-		skb = netdev_alloc_skb_ip_align(priv->ndev, len);
-		if (unlikely(!skb))
-			break;
-
-		addr = dma_map_single(priv->dev, skb->data, len,
-				      DMA_FROM_DEVICE);
-		if (dma_mapping_error(priv->dev, addr)) {
-			dev_kfree_skb_any(skb);
-			break;
-		}
-		rxq->dma_phys[pos] = addr;
-		rxq->skb[pos] = skb;
-		writel(addr, priv->port_base + IQ_ADDR);
-		pos = (pos + 1) % rxq->num;
-	}
-	rxq->head = pos;
-}
-
-static int hisi_femac_rx(struct net_device *dev, int limit)
-{
-	struct hisi_femac_priv *priv = netdev_priv(dev);
-	struct hisi_femac_queue *rxq = &priv->rxq;
-	struct sk_buff *skb;
-	dma_addr_t addr;
-	u32 rx_pkt_info, pos, len, rx_pkts_num = 0;
-
-	pos = rxq->tail;
-	while (readl(priv->glb_base + GLB_IRQ_RAW) & IRQ_INT_RX_RDY) {
-		rx_pkt_info = readl(priv->port_base + IQFRM_DES);
-		len = rx_pkt_info & RX_FRAME_LEN_MASK;
-		len -= ETH_FCS_LEN;
-
-		/* tell hardware we will deal with this packet */
-		writel(IRQ_INT_RX_RDY, priv->glb_base + GLB_IRQ_RAW);
-
-		rx_pkts_num++;
-
-		skb = rxq->skb[pos];
-		if (unlikely(!skb)) {
-			netdev_err(dev, "rx skb NULL. pos=%d\n", pos);
-			break;
-		}
-		rxq->skb[pos] = NULL;
-
-		addr = rxq->dma_phys[pos];
-		dma_unmap_single(priv->dev, addr, MAX_FRAME_SIZE,
-				 DMA_FROM_DEVICE);
-		skb_put(skb, len);
-		if (unlikely(skb->len > MAX_FRAME_SIZE)) {
-			netdev_err(dev, "rcv len err, len = %d\n", skb->len);
-			dev->stats.rx_errors++;
-			dev->stats.rx_length_errors++;
-			dev_kfree_skb_any(skb);
-			goto next;
-		}
-
-		skb->protocol = eth_type_trans(skb, dev);
-		napi_gro_receive(&priv->napi, skb);
-		dev->stats.rx_packets++;
-		dev->stats.rx_bytes += skb->len;
-next:
-		pos = (pos + 1) % rxq->num;
-		if (rx_pkts_num >= limit)
-			break;
-	}
-	rxq->tail = pos;
-
-	hisi_femac_rx_refill(priv);
-
-	return rx_pkts_num;
-}
-
-static int hisi_femac_poll(struct napi_struct *napi, int budget)
-{
-	struct hisi_femac_priv *priv = container_of(napi,
-					struct hisi_femac_priv, napi);
-	struct net_device *dev = priv->ndev;
-	int work_done = 0, task = budget;
-	int ints, num;
-
-	do {
-		hisi_femac_xmit_reclaim(dev);
-		num = hisi_femac_rx(dev, task);
-		work_done += num;
-		task -= num;
-		if (work_done >= budget)
-			break;
-
-		ints = readl(priv->glb_base + GLB_IRQ_RAW);
-		writel(ints & DEF_INT_MASK,
-		       priv->glb_base + GLB_IRQ_RAW);
-	} while (ints & DEF_INT_MASK);
-
-	if (work_done < budget) {
-		napi_complete(napi);
-		hisi_femac_irq_enable(priv, DEF_INT_MASK &
-					(~IRQ_INT_TX_PER_PACKET));
-	}
-
-	return work_done;
-}
-
-static irqreturn_t hisi_femac_interrupt(int irq, void *dev_id)
-{
-	int ints;
-	struct net_device *dev = (struct net_device *)dev_id;
-	struct hisi_femac_priv *priv = netdev_priv(dev);
-
-	ints = readl(priv->glb_base + GLB_IRQ_RAW);
-
-	if (likely(ints & DEF_INT_MASK)) {
-		writel(ints & DEF_INT_MASK,
-		       priv->glb_base + GLB_IRQ_RAW);
-		hisi_femac_irq_disable(priv, DEF_INT_MASK);
-		napi_schedule(&priv->napi);
-	}
-
-	return IRQ_HANDLED;
-}
-
-static int hisi_femac_init_queue(struct device *dev,
-				 struct hisi_femac_queue *queue,
-				 unsigned int num)
-{
-	queue->skb = devm_kcalloc(dev, num, sizeof(struct sk_buff *),
-				  GFP_KERNEL);
-	if (!queue->skb)
-		return -ENOMEM;
-
-	queue->dma_phys = devm_kcalloc(dev, num, sizeof(dma_addr_t),
-				       GFP_KERNEL);
-	if (!queue->dma_phys)
-		return -ENOMEM;
-
-	queue->num = num;
-	queue->head = 0;
-	queue->tail = 0;
-
-	return 0;
-}
-
-static int hisi_femac_init_tx_and_rx_queues(struct hisi_femac_priv *priv)
-{
-	int ret;
-
-	ret = hisi_femac_init_queue(priv->dev, &priv->txq, TXQ_NUM);
-	if (ret)
-		return ret;
-
-	ret = hisi_femac_init_queue(priv->dev, &priv->rxq, RXQ_NUM);
-	if (ret)
-		return ret;
-
-	priv->tx_fifo_used_cnt = 0;
-
-	return 0;
-}
-
-static void hisi_femac_free_skb_rings(struct hisi_femac_priv *priv)
-{
-	struct hisi_femac_queue *txq = &priv->txq;
-	struct hisi_femac_queue *rxq = &priv->rxq;
-	struct sk_buff *skb;
-	dma_addr_t dma_addr;
-	u32 pos;
-
-	pos = rxq->tail;
-	while (pos != rxq->head) {
-		skb = rxq->skb[pos];
-		if (unlikely(!skb)) {
-			netdev_err(priv->ndev, "NULL rx skb. pos=%d, head=%d\n",
-				   pos, rxq->head);
-			continue;
-		}
-
-		dma_addr = rxq->dma_phys[pos];
-		dma_unmap_single(priv->dev, dma_addr, MAX_FRAME_SIZE,
-				 DMA_FROM_DEVICE);
-
-		dev_kfree_skb_any(skb);
-		rxq->skb[pos] = NULL;
-		pos = (pos + 1) % rxq->num;
-	}
-	rxq->tail = pos;
-
-	pos = txq->tail;
-	while (pos != txq->head) {
-		skb = txq->skb[pos];
-		if (unlikely(!skb)) {
-			netdev_err(priv->ndev, "NULL tx skb. pos=%d, head=%d\n",
-				   pos, txq->head);
-			continue;
-		}
-		hisi_femac_tx_dma_unmap(priv, skb, pos);
-		dev_kfree_skb_any(skb);
-		txq->skb[pos] = NULL;
-		pos = (pos + 1) % txq->num;
-	}
-	txq->tail = pos;
-	priv->tx_fifo_used_cnt = 0;
-}
-
-static int hisi_femac_set_hw_mac_addr(struct hisi_femac_priv *priv,
-				      unsigned char *mac)
-{
-	u32 reg;
-
-	reg = mac[1] | (mac[0] << 8);
-	writel(reg, priv->glb_base + GLB_HOSTMAC_H16);
-
-	reg = mac[5] | (mac[4] << 8) | (mac[3] << 16) | (mac[2] << 24);
-	writel(reg, priv->glb_base + GLB_HOSTMAC_L32);
-
-	return 0;
-}
-
-static int hisi_femac_port_reset(struct hisi_femac_priv *priv)
-{
-	u32 val;
-
-	val = readl(priv->glb_base + GLB_SOFT_RESET);
-	val |= SOFT_RESET_ALL;
-	writel(val, priv->glb_base + GLB_SOFT_RESET);
-
-	usleep_range(500, 800);
-
-	val &= ~SOFT_RESET_ALL;
-	writel(val, priv->glb_base + GLB_SOFT_RESET);
-
-	return 0;
-}
-
-static int hisi_femac_net_open(struct net_device *dev)
-{
-	struct hisi_femac_priv *priv = netdev_priv(dev);
-
-	hisi_femac_port_reset(priv);
-	hisi_femac_set_hw_mac_addr(priv, dev->dev_addr);
-	hisi_femac_rx_refill(priv);
-
-	netif_carrier_off(dev);
-	netdev_reset_queue(dev);
-	netif_start_queue(dev);
-	napi_enable(&priv->napi);
-
-	priv->link_status = 0;
-	if (dev->phydev)
-		phy_start(dev->phydev);
-
-	writel(IRQ_ENA_PORT0_MASK, priv->glb_base + GLB_IRQ_RAW);
-	hisi_femac_irq_enable(priv, IRQ_ENA_ALL | IRQ_ENA_PORT0 | DEF_INT_MASK);
-
-	return 0;
-}
-
-static int hisi_femac_net_close(struct net_device *dev)
-{
-	struct hisi_femac_priv *priv = netdev_priv(dev);
-
-	hisi_femac_irq_disable(priv, IRQ_ENA_PORT0);
-
-	if (dev->phydev)
-		phy_stop(dev->phydev);
-
-	netif_stop_queue(dev);
-	napi_disable(&priv->napi);
-
-	hisi_femac_free_skb_rings(priv);
-
-	return 0;
-}
-
-static netdev_tx_t hisi_femac_net_xmit(struct sk_buff *skb,
-				       struct net_device *dev)
-{
-	struct hisi_femac_priv *priv = netdev_priv(dev);
-	struct hisi_femac_queue *txq = &priv->txq;
-	dma_addr_t addr;
-	u32 val;
-
-	val = readl(priv->port_base + ADDRQ_STAT);
-	val &= BIT_TX_READY;
-	if (!val) {
-		hisi_femac_irq_enable(priv, IRQ_INT_TX_PER_PACKET);
-		dev->stats.tx_dropped++;
-		dev->stats.tx_fifo_errors++;
-		netif_stop_queue(dev);
-		return NETDEV_TX_BUSY;
-	}
-
-	if (unlikely(!CIRC_SPACE(txq->head, txq->tail,
-				 txq->num))) {
-		hisi_femac_irq_enable(priv, IRQ_INT_TX_PER_PACKET);
-		dev->stats.tx_dropped++;
-		dev->stats.tx_fifo_errors++;
-		netif_stop_queue(dev);
-		return NETDEV_TX_BUSY;
-	}
-
-	addr = dma_map_single(priv->dev, skb->data,
-			      skb->len, DMA_TO_DEVICE);
-	if (unlikely(dma_mapping_error(priv->dev, addr))) {
-		dev_kfree_skb_any(skb);
-		dev->stats.tx_dropped++;
-		return NETDEV_TX_OK;
-	}
-	txq->dma_phys[txq->head] = addr;
-
-	txq->skb[txq->head] = skb;
-	txq->head = (txq->head + 1) % txq->num;
-
-	writel(addr, priv->port_base + EQ_ADDR);
-	writel(skb->len + ETH_FCS_LEN, priv->port_base + EQFRM_LEN);
-
-	priv->tx_fifo_used_cnt++;
-
-	dev->stats.tx_packets++;
-	dev->stats.tx_bytes += skb->len;
-	netdev_sent_queue(dev, skb->len);
-
-	return NETDEV_TX_OK;
-}
-
-static int hisi_femac_set_mac_address(struct net_device *dev, void *p)
-{
-	struct hisi_femac_priv *priv = netdev_priv(dev);
-	struct sockaddr *skaddr = p;
-
-	if (!is_valid_ether_addr(skaddr->sa_data))
-		return -EADDRNOTAVAIL;
-
-	memcpy(dev->dev_addr, skaddr->sa_data, dev->addr_len);
-	dev->addr_assign_type &= ~NET_ADDR_RANDOM;
-
-	hisi_femac_set_hw_mac_addr(priv, dev->dev_addr);
-
-	return 0;
-}
-
-static void hisi_femac_enable_hw_addr_filter(struct hisi_femac_priv *priv,
-					     unsigned int reg_n, bool enable)
-{
-	u32 val;
-
-	val = readl(priv->glb_base + GLB_MAC_H16(reg_n));
-	if (enable)
-		val |= BIT_MACFLT_ENA;
-	else
-		val &= ~BIT_MACFLT_ENA;
-	writel(val, priv->glb_base + GLB_MAC_H16(reg_n));
-}
-
-static void hisi_femac_set_hw_addr_filter(struct hisi_femac_priv *priv,
-					  unsigned char *addr,
-					  unsigned int reg_n)
-{
-	unsigned int high, low;
-	u32 val;
-
-	high = GLB_MAC_H16(reg_n);
-	low = GLB_MAC_L32(reg_n);
-
-	val = (addr[2] << 24) | (addr[3] << 16) | (addr[4] << 8) | addr[5];
-	writel(val, priv->glb_base + low);
-
-	val = readl(priv->glb_base + high);
-	val &= ~MACFLT_HI16_MASK;
-	val |= ((addr[0] << 8) | addr[1]);
-	val |= (BIT_MACFLT_ENA | BIT_MACFLT_FW2CPU);
-	writel(val, priv->glb_base + high);
-}
-
-static void hisi_femac_set_promisc_mode(struct hisi_femac_priv *priv,
-					bool promisc_mode)
-{
-	u32 val;
-
-	val = readl(priv->glb_base + GLB_FWCTRL);
-	if (promisc_mode)
-		val |= FWCTRL_FWALL2CPU;
-	else
-		val &= ~FWCTRL_FWALL2CPU;
-	writel(val, priv->glb_base + GLB_FWCTRL);
-}
-
-/* Handle multiple multicast addresses (perfect filtering)*/
-static void hisi_femac_set_mc_addr_filter(struct hisi_femac_priv *priv)
-{
-	struct net_device *dev = priv->ndev;
-	u32 val;
-
-	val = readl(priv->glb_base + GLB_MACTCTRL);
-	if ((netdev_mc_count(dev) > MAX_MULTICAST_ADDRESSES) ||
-	    (dev->flags & IFF_ALLMULTI)) {
-		val |= MACTCTRL_MULTI2CPU;
-	} else {
-		int reg = MAX_UNICAST_ADDRESSES;
-		int i;
-		struct netdev_hw_addr *ha;
-
-		for (i = reg; i < MAX_MAC_FILTER_NUM; i++)
-			hisi_femac_enable_hw_addr_filter(priv, i, false);
-
-		netdev_for_each_mc_addr(ha, dev) {
-			hisi_femac_set_hw_addr_filter(priv, ha->addr, reg);
-			reg++;
-		}
-		val &= ~MACTCTRL_MULTI2CPU;
-	}
-	writel(val, priv->glb_base + GLB_MACTCTRL);
-}
-
-/* Handle multiple unicast addresses (perfect filtering)*/
-static void hisi_femac_set_uc_addr_filter(struct hisi_femac_priv *priv)
-{
-	struct net_device *dev = priv->ndev;
-	u32 val;
-
-	val = readl(priv->glb_base + GLB_MACTCTRL);
-	if (netdev_uc_count(dev) > MAX_UNICAST_ADDRESSES) {
-		val |= MACTCTRL_UNI2CPU;
-	} else {
-		int reg = 0;
-		int i;
-		struct netdev_hw_addr *ha;
-
-		for (i = reg; i < MAX_UNICAST_ADDRESSES; i++)
-			hisi_femac_enable_hw_addr_filter(priv, i, false);
-
-		netdev_for_each_uc_addr(ha, dev) {
-			hisi_femac_set_hw_addr_filter(priv, ha->addr, reg);
-			reg++;
-		}
-		val &= ~MACTCTRL_UNI2CPU;
-	}
-	writel(val, priv->glb_base + GLB_MACTCTRL);
-}
-
-static void hisi_femac_net_set_rx_mode(struct net_device *dev)
-{
-	struct hisi_femac_priv *priv = netdev_priv(dev);
-
-	if (dev->flags & IFF_PROMISC) {
-		hisi_femac_set_promisc_mode(priv, true);
-	} else {
-		hisi_femac_set_promisc_mode(priv, false);
-		hisi_femac_set_mc_addr_filter(priv);
-		hisi_femac_set_uc_addr_filter(priv);
-	}
-}
-
-static int hisi_femac_net_ioctl(struct net_device *dev,
-				struct ifreq *ifreq, int cmd)
-{
-	if (!netif_running(dev))
-		return -EINVAL;
-
-	if (!dev->phydev)
-		return -EINVAL;
-
-	return phy_mii_ioctl(dev->phydev, ifreq, cmd);
-}
-
-static const struct ethtool_ops hisi_femac_ethtools_ops = {
-	.get_link		= ethtool_op_get_link,
-	.get_link_ksettings	= phy_ethtool_get_link_ksettings,
-	.set_link_ksettings	= phy_ethtool_set_link_ksettings,
-};
-
-static const struct net_device_ops hisi_femac_netdev_ops = {
-	.ndo_open		= hisi_femac_net_open,
-	.ndo_stop		= hisi_femac_net_close,
-	.ndo_start_xmit		= hisi_femac_net_xmit,
-	.ndo_do_ioctl		= hisi_femac_net_ioctl,
-	.ndo_set_mac_address	= hisi_femac_set_mac_address,
-	.ndo_set_rx_mode	= hisi_femac_net_set_rx_mode,
-	.ndo_change_mtu		= eth_change_mtu,
-};
-
-static void hisi_femac_core_reset(struct hisi_femac_priv *priv)
-{
-	reset_control_assert(priv->mac_rst);
-	reset_control_deassert(priv->mac_rst);
-}
-
-static void hisi_femac_sleep_us(u32 time_us)
-{
-	u32 time_ms;
-
-	if (!time_us)
-		return;
-
-	time_ms = DIV_ROUND_UP(time_us, 1000);
-	if (time_ms < 20)
-		usleep_range(time_us, time_us + 500);
-	else
-		msleep(time_ms);
-}
-
-static void hisi_femac_phy_reset(struct hisi_femac_priv *priv)
-{
-	/* To make sure PHY hardware reset success,
-	 * we must keep PHY in deassert state first and
-	 * then complete the hardware reset operation
-	 */
-	reset_control_deassert(priv->phy_rst);
-	hisi_femac_sleep_us(priv->phy_reset_delays[PRE_DELAY]);
-
-	reset_control_assert(priv->phy_rst);
-	/* delay some time to ensure reset ok,
-	 * this depends on PHY hardware feature
-	 */
-	hisi_femac_sleep_us(priv->phy_reset_delays[PULSE]);
-	reset_control_deassert(priv->phy_rst);
-	/* delay some time to ensure later MDIO access */
-	hisi_femac_sleep_us(priv->phy_reset_delays[POST_DELAY]);
-}
-
-static void hisi_femac_port_init(struct hisi_femac_priv *priv)
-{
-	u32 val;
-
-	/* MAC gets link status info and phy mode by software config */
-	val = MAC_PORTSEL_STAT_CPU;
-	if (priv->ndev->phydev->interface == PHY_INTERFACE_MODE_RMII)
-		val |= MAC_PORTSEL_RMII;
-	writel(val, priv->port_base + MAC_PORTSEL);
-
-	/*clear all interrupt status */
-	writel(IRQ_ENA_PORT0_MASK, priv->glb_base + GLB_IRQ_RAW);
-	hisi_femac_irq_disable(priv, IRQ_ENA_PORT0_MASK | IRQ_ENA_PORT0);
-
-	val = readl(priv->glb_base + GLB_FWCTRL);
-	val &= ~(FWCTRL_VLAN_ENABLE | FWCTRL_FWALL2CPU);
-	val |= FWCTRL_FW2CPU_ENA;
-	writel(val, priv->glb_base + GLB_FWCTRL);
-
-	val = readl(priv->glb_base + GLB_MACTCTRL);
-	val |= (MACTCTRL_BROAD2CPU | MACTCTRL_MACT_ENA);
-	writel(val, priv->glb_base + GLB_MACTCTRL);
-
-	val = readl(priv->port_base + MAC_SET);
-	val &= ~MAX_FRAME_SIZE_MASK;
-	val |= MAX_FRAME_SIZE;
-	writel(val, priv->port_base + MAC_SET);
-
-	val = RX_COALESCED_TIMER |
-		(RX_COALESCED_FRAMES << RX_COALESCED_FRAME_OFFSET);
-	writel(val, priv->port_base + RX_COALESCE_SET);
-
-	val = (HW_RX_FIFO_DEPTH << RX_DEPTH_OFFSET) | HW_TX_FIFO_DEPTH;
-	writel(val, priv->port_base + QLEN_SET);
-}
-
-static int hisi_femac_drv_probe(struct platform_device *pdev)
-{
-	struct device *dev = &pdev->dev;
-	struct device_node *node = dev->of_node;
-	struct resource *res;
-	struct net_device *ndev;
-	struct hisi_femac_priv *priv;
-	struct phy_device *phy;
-	const char *mac_addr;
-	int ret;
-
-	ndev = alloc_etherdev(sizeof(*priv));
-	if (!ndev)
-		return -ENOMEM;
-
-	platform_set_drvdata(pdev, ndev);
-
-	priv = netdev_priv(ndev);
-	priv->dev = dev;
-	priv->ndev = ndev;
-
-	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
-	priv->port_base = devm_ioremap_resource(dev, res);
-	if (IS_ERR(priv->port_base)) {
-		ret = PTR_ERR(priv->port_base);
-		goto out_free_netdev;
-	}
-
-	res = platform_get_resource(pdev, IORESOURCE_MEM, 1);
-	priv->glb_base = devm_ioremap_resource(dev, res);
-	if (IS_ERR(priv->glb_base)) {
-		ret = PTR_ERR(priv->glb_base);
-		goto out_free_netdev;
-	}
-
-	priv->clk = devm_clk_get(&pdev->dev, NULL);
-	if (IS_ERR(priv->clk)) {
-		dev_err(dev, "failed to get clk\n");
-		ret = -ENODEV;
-		goto out_free_netdev;
-	}
-
-	ret = clk_prepare_enable(priv->clk);
-	if (ret) {
-		dev_err(dev, "failed to enable clk %d\n", ret);
-		goto out_free_netdev;
-	}
-
-	priv->mac_rst = devm_reset_control_get(dev, "mac");
-	if (IS_ERR(priv->mac_rst)) {
-		ret = PTR_ERR(priv->mac_rst);
-		goto out_disable_clk;
-	}
-	hisi_femac_core_reset(priv);
-
-	priv->phy_rst = devm_reset_control_get(dev, "phy");
-	if (IS_ERR(priv->phy_rst)) {
-		priv->phy_rst = NULL;
-	} else {
-		ret = of_property_read_u32_array(node,
-						 PHY_RESET_DELAYS_PROPERTY,
-						 priv->phy_reset_delays,
-						 DELAYS_NUM);
-		if (ret)
-			goto out_disable_clk;
-		hisi_femac_phy_reset(priv);
-	}
-
-	phy = of_phy_get_and_connect(ndev, node, hisi_femac_adjust_link);
-	if (!phy) {
-		dev_err(dev, "connect to PHY failed!\n");
-		ret = -ENODEV;
-		goto out_disable_clk;
-	}
-
-	phy_attached_print(phy, "phy_id=0x%.8lx, phy_mode=%s\n",
-			   (unsigned long)phy->phy_id,
-			   phy_modes(phy->interface));
-
-	mac_addr = of_get_mac_address(node);
-	if (mac_addr)
-		ether_addr_copy(ndev->dev_addr, mac_addr);
-	if (!is_valid_ether_addr(ndev->dev_addr)) {
-		eth_hw_addr_random(ndev);
-		dev_warn(dev, "using random MAC address %pM\n",
-			 ndev->dev_addr);
-	}
-
-	ndev->watchdog_timeo = 6 * HZ;
-	ndev->priv_flags |= IFF_UNICAST_FLT;
-	ndev->netdev_ops = &hisi_femac_netdev_ops;
-	ndev->ethtool_ops = &hisi_femac_ethtools_ops;
-	netif_napi_add(ndev, &priv->napi, hisi_femac_poll, FEMAC_POLL_WEIGHT);
-	SET_NETDEV_DEV(ndev, &pdev->dev);
-
-	hisi_femac_port_init(priv);
-
-	ret = hisi_femac_init_tx_and_rx_queues(priv);
-	if (ret)
-		goto out_disconnect_phy;
-
-	ndev->irq = platform_get_irq(pdev, 0);
-	if (ndev->irq <= 0) {
-		dev_err(dev, "No irq resource\n");
-		ret = -ENODEV;
-		goto out_disconnect_phy;
-	}
-
-	ret = devm_request_irq(dev, ndev->irq, hisi_femac_interrupt,
-			       IRQF_SHARED, pdev->name, ndev);
-	if (ret) {
-		dev_err(dev, "devm_request_irq %d failed!\n", ndev->irq);
-		goto out_disconnect_phy;
-	}
-
-	ret = register_netdev(ndev);
-	if (ret) {
-		dev_err(dev, "register_netdev failed!\n");
-		goto out_disconnect_phy;
-	}
-
-	return ret;
-
-out_disconnect_phy:
-	netif_napi_del(&priv->napi);
-	phy_disconnect(phy);
-out_disable_clk:
-	clk_disable_unprepare(priv->clk);
-out_free_netdev:
-	free_netdev(ndev);
-
-	return ret;
-}
-
-static int hisi_femac_drv_remove(struct platform_device *pdev)
-{
-	struct net_device *ndev = platform_get_drvdata(pdev);
-	struct hisi_femac_priv *priv = netdev_priv(ndev);
-
-	netif_napi_del(&priv->napi);
-	unregister_netdev(ndev);
-
-	phy_disconnect(ndev->phydev);
-	clk_disable_unprepare(priv->clk);
-	free_netdev(ndev);
-
-	return 0;
-}
-
-#ifdef CONFIG_PM
-static int hisi_femac_drv_suspend(struct platform_device *pdev,
-				  pm_message_t state)
-{
-	struct net_device *ndev = platform_get_drvdata(pdev);
-	struct hisi_femac_priv *priv = netdev_priv(ndev);
-
-	disable_irq(ndev->irq);
-	if (netif_running(ndev)) {
-		hisi_femac_net_close(ndev);
-		netif_device_detach(ndev);
-	}
-
-	clk_disable_unprepare(priv->clk);
-
-	return 0;
-}
-
-static int hisi_femac_drv_resume(struct platform_device *pdev)
-{
-	struct net_device *ndev = platform_get_drvdata(pdev);
-	struct hisi_femac_priv *priv = netdev_priv(ndev);
-
-	clk_prepare_enable(priv->clk);
-	if (priv->phy_rst)
-		hisi_femac_phy_reset(priv);
-
-	if (netif_running(ndev)) {
-		hisi_femac_port_init(priv);
-		hisi_femac_net_open(ndev);
-		netif_device_attach(ndev);
-	}
-	enable_irq(ndev->irq);
-
-	return 0;
-}
-#endif
-
-static const struct of_device_id hisi_femac_match[] = {
-	{.compatible = "hisilicon,hisi-femac-v1",},
-	{.compatible = "hisilicon,hisi-femac-v2",},
-	{.compatible = "hisilicon,hi3516cv300-femac",},
-	{},
-};
-
-MODULE_DEVICE_TABLE(of, hisi_femac_match);
-
-static struct platform_driver hisi_femac_driver = {
-	.driver = {
-		.name = "hisi-femac",
-		.of_match_table = hisi_femac_match,
-	},
-	.probe = hisi_femac_drv_probe,
-	.remove = hisi_femac_drv_remove,
-#ifdef CONFIG_PM
-	.suspend = hisi_femac_drv_suspend,
-	.resume = hisi_femac_drv_resume,
-#endif
-};
-
-module_platform_driver(hisi_femac_driver);
-
-MODULE_DESCRIPTION("Hisilicon Fast Ethernet MAC driver");
-MODULE_AUTHOR("Dongpo Li <lidongpo@hisilicon.com>");
-MODULE_LICENSE("GPL v2");
-MODULE_ALIAS("platform:hisi-femac");
diff --git a/drivers/net/phy/Kconfig b/drivers/net/phy/Kconfig
index 2651c8d..0c4b93a 100644
--- a/drivers/net/phy/Kconfig
+++ b/drivers/net/phy/Kconfig
@@ -105,6 +105,13 @@ config MDIO_HISI_FEMAC
 	  This module provides a driver for the MDIO busses found in the
 	  Hisilicon SoC that have an Fast Ethernet MAC.
 
+config MDIO_HISI_GEMAC
+	tristate "Hisilicon GEMAC MDIO bus controller"
+	depends on HAS_IOMEM && OF_MDIO
+	help
+	  This module provides a driver for the MDIO busses found in the
+	  Hisilicon SoC that have an Gigabit Ethernet MAC.
+
 config MDIO_MOXART
         tristate "MOXA ART MDIO interface support"
         depends on ARCH_MOXART
diff --git a/drivers/net/phy/Makefile b/drivers/net/phy/Makefile
index e58667d..a6ae694 100644
--- a/drivers/net/phy/Makefile
+++ b/drivers/net/phy/Makefile
@@ -15,6 +15,7 @@ obj-$(CONFIG_MDIO_BUS_MUX_MMIOREG) += mdio-mux-mmioreg.o
 obj-$(CONFIG_MDIO_CAVIUM)	+= mdio-cavium.o
 obj-$(CONFIG_MDIO_GPIO)		+= mdio-gpio.o
 obj-$(CONFIG_MDIO_HISI_FEMAC)	+= mdio-hisi-femac.o
+obj-$(CONFIG_MDIO_HISI_GEMAC)	+= mdio-hisi-gemac.o
 obj-$(CONFIG_MDIO_MOXART)	+= mdio-moxart.o
 obj-$(CONFIG_MDIO_OCTEON)	+= mdio-octeon.o
 obj-$(CONFIG_MDIO_SUN4I)	+= mdio-sun4i.o
diff --git a/drivers/net/phy/mdio-hisi-femac.c b/drivers/net/phy/mdio-hisi-femac.c
index b03fedd..9035579 100644
--- a/drivers/net/phy/mdio-hisi-femac.c
+++ b/drivers/net/phy/mdio-hisi-femac.c
@@ -24,6 +24,7 @@
 #include <linux/of_address.h>
 #include <linux/of_mdio.h>
 #include <linux/platform_device.h>
+#include <linux/reset.h>
 
 #define MDIO_RWCTRL		0x00
 #define MDIO_RO_DATA		0x04
@@ -32,16 +33,55 @@
 #define BIT_PHY_ADDR_OFFSET	8
 #define BIT_WR_DATA_OFFSET	16
 
+#define BIT_MASK_FEPHY_ADDR	GENMASK(4, 0)
+#define BIT_FEPHY_SEL		BIT(5)
+
+#define BIT_OFFSET_LD_SET	0
+#define BIT_OFFSET_LDO_SET	5
+#define BIT_OFFSET_R_TUNING	8
+
+#define MII_EXPMD		0x1d
+#define MII_EXPMA		0x1e
+
+#define REG_LD_AM		0x3050
+#define BIT_MASK_LD_SET		GENMASK(4, 0)
+#define REG_LDO_AM		0x3051
+#define BIT_MASK_LDO_SET	GENMASK(2, 0)
+#define REG_R_TUNING		0x3052
+#define BIT_MASK_R_TUNING	GENMASK(5, 0)
+#define REG_WR_DONE		0x3053
+#define BIT_CFG_DONE		BIT(0)
+#define BIT_CFG_ACK		BIT(1)
+#define REG_DEF_ATE		0x3057
+#define BIT_AUTOTRIM_DONE	BIT(0)
+
+#define PHY_RESET_DELAYS_PROPERTY	"hisilicon,phy-reset-delays-us"
+
+enum phy_reset_delays {
+	PRE_DELAY,
+	PULSE,
+	POST_DELAY,
+	DELAYS_NUM,
+};
+
 struct hisi_femac_mdio_data {
 	struct clk *clk;
+	struct clk *fephy_clk;
+	struct reset_control *phy_rst;
+	struct reset_control *fephy_rst;
+	u32 phy_reset_delays[DELAYS_NUM];
 	void __iomem *membase;
+	void __iomem *fephy_iobase;
+	void __iomem *fephy_trim_iobase;
+	struct mii_bus *bus;
+	u32 phy_addr;
 };
 
 static int hisi_femac_mdio_wait_ready(struct hisi_femac_mdio_data *data)
 {
 	u32 val;
 
-	return readl_poll_timeout(data->membase + MDIO_RWCTRL,
+	return readl_poll_timeout_atomic(data->membase + MDIO_RWCTRL,
 				  val, val & MDIO_RW_FINISH, 20, 10000);
 }
 
@@ -54,8 +94,8 @@ static int hisi_femac_mdio_read(struct mii_bus *bus, int mii_id, int regnum)
 	if (ret)
 		return ret;
 
-	writel((mii_id << BIT_PHY_ADDR_OFFSET) | regnum,
-	       data->membase + MDIO_RWCTRL);
+	writel((mii_id << BIT_PHY_ADDR_OFFSET) | ((u32)regnum),
+		  data->membase + MDIO_RWCTRL);
 
 	ret = hisi_femac_mdio_wait_ready(data);
 	if (ret)
@@ -75,12 +115,215 @@ static int hisi_femac_mdio_write(struct mii_bus *bus, int mii_id, int regnum,
 		return ret;
 
 	writel(MDIO_WRITE | (value << BIT_WR_DATA_OFFSET) |
-	       (mii_id << BIT_PHY_ADDR_OFFSET) | regnum,
+	       (mii_id << BIT_PHY_ADDR_OFFSET) | ((u32)regnum),
 	       data->membase + MDIO_RWCTRL);
 
 	return hisi_femac_mdio_wait_ready(data);
 }
 
+static void hisi_femac_sleep_us(u32 time_us)
+{
+	u32 time_ms;
+
+	if (!time_us)
+		return;
+
+	time_ms = DIV_ROUND_UP(time_us, 1000);
+	if (time_ms < 20)
+		usleep_range(time_us, time_us + 500);
+	else
+		msleep(time_ms);
+}
+
+static void hisi_femac_phy_reset(struct hisi_femac_mdio_data *data)
+{
+	/* To make sure PHY hardware reset success,
+	 * we must keep PHY in deassert state first and
+	 * then complete the hardware reset operation
+	 */
+	reset_control_deassert(data->phy_rst);
+	hisi_femac_sleep_us(data->phy_reset_delays[PRE_DELAY]);
+
+	reset_control_assert(data->phy_rst);
+	/* delay some time to ensure reset ok,
+	 * this depends on PHY hardware feature
+	 */
+	hisi_femac_sleep_us(data->phy_reset_delays[PULSE]);
+	reset_control_deassert(data->phy_rst);
+	/* delay some time to ensure later MDIO access */
+	hisi_femac_sleep_us(data->phy_reset_delays[POST_DELAY]);
+}
+
+static void hisi_femac_get_phy_addr(struct hisi_femac_mdio_data *data,
+				    struct device_node *np)
+{
+	struct device_node *child = NULL;
+	int addr;
+
+	child = of_get_next_available_child(np, NULL);
+	if (!child) {
+		pr_err("%s: No valid PHY device node!\n", __func__);
+		return;
+	}
+
+	addr = of_mdio_parse_addr(&data->bus->dev, child);
+	if (addr < 0) {
+		pr_err("%s: get PHY address failed!\n", __func__);
+		return;
+	}
+
+	data->phy_addr = addr;
+}
+
+static inline bool hisi_femac_use_fephy(struct hisi_femac_mdio_data *data)
+{
+	/*return false;*/
+	return (data->fephy_iobase ?
+			!(readl(data->fephy_iobase) & BIT_FEPHY_SEL) : false);
+}
+
+static void hisi_femac_fephy_reset(struct hisi_femac_mdio_data *data)
+{
+	u32 val;
+
+	/* disable MDCK clock to make sure FEPHY reset success */
+	clk_disable_unprepare(data->clk);
+
+	val = readl(data->fephy_iobase);
+	val &= ~BIT_MASK_FEPHY_ADDR;
+	val |= data->phy_addr;
+	writel(val, data->fephy_iobase);
+
+	clk_prepare_enable(data->fephy_clk);
+	udelay(10);
+
+	reset_control_assert(data->fephy_rst);
+	udelay(10);
+	reset_control_deassert(data->fephy_rst);
+	/* delay at least 15ms for MDIO operation */
+	msleep(20);
+
+	clk_prepare_enable(data->clk);
+	/* delay 5ms after enable MDCK to make sure FEPHY trim safe */
+	mdelay(5);
+}
+
+static inline int fephy_expanded_read(struct mii_bus *bus, int phy_addr,
+				      u32 reg_addr)
+{
+	int ret;
+
+	hisi_femac_mdio_write(bus, phy_addr, MII_EXPMA, reg_addr);
+	ret = hisi_femac_mdio_read(bus, phy_addr, MII_EXPMD);
+
+	return ret;
+}
+
+static inline int fephy_expanded_write(struct mii_bus *bus, int phy_addr,
+				       u32 reg_addr, u16 val)
+{
+	int ret;
+
+	hisi_femac_mdio_write(bus, phy_addr, MII_EXPMA, reg_addr);
+	ret = hisi_femac_mdio_write(bus, phy_addr, MII_EXPMD, val);
+
+	return ret;
+}
+
+void hisi_femac_fephy_use_default_trim(struct hisi_femac_mdio_data *data)
+{
+	unsigned short val;
+	int timeout = 3;
+
+	pr_info("No OTP data, festa PHY use default ATE parameters!\n");
+
+	do {
+		msleep(250);
+		val = fephy_expanded_read(data->bus, data->phy_addr,
+					  REG_DEF_ATE);
+		val &= BIT_AUTOTRIM_DONE;
+	} while (!val && --timeout);
+
+	if (!timeout)
+		pr_err("festa PHY wait autotrim done timeout!\n");
+
+	mdelay(5);
+}
+
+static void hisi_femac_fephy_trim(struct hisi_femac_mdio_data *data)
+{
+	struct mii_bus *bus = data->bus;
+	u32 phy_addr = data->phy_addr;
+	int timeout = 3000;
+	u32 val;
+	u8 ld_set;
+	u8 ldo_set;
+	u8 r_tuning;
+
+	val = readl(data->fephy_trim_iobase);
+	ld_set = (val >> BIT_OFFSET_LD_SET) & BIT_MASK_LD_SET;
+	ldo_set = (val >> BIT_OFFSET_LDO_SET) & BIT_MASK_LDO_SET;
+	r_tuning = (val >> BIT_OFFSET_R_TUNING) & BIT_MASK_R_TUNING;
+
+	if (!ld_set && !ldo_set && !r_tuning) {
+		hisi_femac_fephy_use_default_trim(data);
+		return;
+	}
+
+	val = fephy_expanded_read(bus, phy_addr, REG_LD_AM);
+	val = (val & ~BIT_MASK_LD_SET) | (ld_set & BIT_MASK_LD_SET);
+	fephy_expanded_write(bus, phy_addr, REG_LD_AM, val);
+
+	val = fephy_expanded_read(bus, phy_addr, REG_LDO_AM);
+	val = (val & ~BIT_MASK_LDO_SET) | (ldo_set & BIT_MASK_LDO_SET);
+	fephy_expanded_write(bus, phy_addr, REG_LDO_AM, val);
+
+	val = fephy_expanded_read(bus, phy_addr, REG_R_TUNING);
+	val = (val & ~BIT_MASK_R_TUNING) | (r_tuning & BIT_MASK_R_TUNING);
+	fephy_expanded_write(bus, phy_addr, REG_R_TUNING, val);
+
+	val = fephy_expanded_read(bus, phy_addr, REG_WR_DONE);
+	if (val & BIT_CFG_ACK)
+		pr_err("festa PHY 0x3053 bit CFG_ACK value: 1\n");
+	val = val | BIT_CFG_DONE;
+	fephy_expanded_write(bus, phy_addr, REG_WR_DONE, val);
+
+	do {
+		usleep_range(100, 150);
+		val = fephy_expanded_read(bus, phy_addr, REG_WR_DONE);
+		val &= BIT_CFG_ACK;
+	} while (!val && --timeout);
+	if (!timeout)
+		pr_err("festa PHY 0x3053 wait bit CFG_ACK timeout!\n");
+
+	mdelay(5);
+
+	pr_info("FEPHY:addr=%d, la_am=0x%x, ldo_am=0x%x, r_tuning=0x%x\n",
+		phy_addr,
+		fephy_expanded_read(bus, phy_addr, REG_LD_AM),
+		fephy_expanded_read(bus, phy_addr, REG_LDO_AM),
+		fephy_expanded_read(bus, phy_addr, REG_R_TUNING));
+}
+
+static void hisi_femac_fephy_reset_and_trim(struct hisi_femac_mdio_data *data)
+{
+	hisi_femac_fephy_reset(data);
+	hisi_femac_fephy_trim(data);
+}
+
+static void hisi_femac_fephy_set_phy_addr(struct hisi_femac_mdio_data *data)
+{
+	u32 val;
+
+	if (!data->fephy_iobase)
+		return;
+
+	val = readl(data->fephy_iobase);
+	val &= ~BIT_MASK_FEPHY_ADDR;
+	val |= (data->phy_addr + 1);
+	writel(val, data->fephy_iobase);
+}
+
 static int hisi_femac_mdio_probe(struct platform_device *pdev)
 {
 	struct device_node *np = pdev->dev.of_node;
@@ -100,6 +343,7 @@ static int hisi_femac_mdio_probe(struct platform_device *pdev)
 	bus->parent = &pdev->dev;
 
 	data = bus->priv;
+	data->bus = bus;
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	data->membase = devm_ioremap_resource(&pdev->dev, res);
 	if (IS_ERR(data->membase)) {
@@ -107,16 +351,66 @@ static int hisi_femac_mdio_probe(struct platform_device *pdev)
 		goto err_out_free_mdiobus;
 	}
 
-	data->clk = devm_clk_get(&pdev->dev, NULL);
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 1);
+	if (res) {
+		data->fephy_iobase = devm_ioremap_resource(&pdev->dev, res);
+		if (IS_ERR(data->fephy_iobase)) {
+			ret = PTR_ERR(data->fephy_iobase);
+			goto err_out_free_mdiobus;
+		}
+	} else {
+		data->fephy_iobase = NULL;
+	}
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 2);
+	if (res) {
+		data->fephy_trim_iobase = devm_ioremap_resource(&pdev->dev,
+								res);
+		if (IS_ERR(data->fephy_trim_iobase)) {
+			ret = PTR_ERR(data->fephy_trim_iobase);
+			goto err_out_free_mdiobus;
+		}
+	} else {
+		data->fephy_trim_iobase = NULL;
+	}
+
+	data->clk = devm_clk_get(&pdev->dev, "mdio");
 	if (IS_ERR(data->clk)) {
 		ret = PTR_ERR(data->clk);
 		goto err_out_free_mdiobus;
 	}
 
+	data->fephy_clk = devm_clk_get(&pdev->dev, "phy");
+	if (IS_ERR(data->fephy_clk))
+		data->fephy_clk = NULL;
+
 	ret = clk_prepare_enable(data->clk);
 	if (ret)
 		goto err_out_free_mdiobus;
 
+	data->phy_rst = devm_reset_control_get(&pdev->dev, "external-phy");
+	if (IS_ERR(data->phy_rst)) {
+		data->phy_rst = NULL;
+	} else {
+		ret = of_property_read_u32_array(np,
+						 PHY_RESET_DELAYS_PROPERTY,
+						 data->phy_reset_delays,
+						 DELAYS_NUM);
+		if (ret)
+			goto err_out_disable_clk;
+		hisi_femac_phy_reset(data);
+	}
+
+	data->fephy_rst = devm_reset_control_get(&pdev->dev, "internal-phy");
+	if (IS_ERR(data->fephy_rst))
+		data->fephy_rst = NULL;
+
+	hisi_femac_get_phy_addr(data, np);
+	if (hisi_femac_use_fephy(data))
+		hisi_femac_fephy_reset_and_trim(data);
+	else
+		hisi_femac_fephy_set_phy_addr(data);
+
 	ret = of_mdiobus_register(bus, np);
 	if (ret)
 		goto err_out_disable_clk;
@@ -126,6 +420,7 @@ static int hisi_femac_mdio_probe(struct platform_device *pdev)
 	return 0;
 
 err_out_disable_clk:
+	clk_disable_unprepare(data->fephy_clk);
 	clk_disable_unprepare(data->clk);
 err_out_free_mdiobus:
 	mdiobus_free(bus);
diff --git a/drivers/net/phy/mdio-hisi-gemac.c b/drivers/net/phy/mdio-hisi-gemac.c
new file mode 100644
index 0000000..e34941d5e
--- /dev/null
+++ b/drivers/net/phy/mdio-hisi-gemac.c
@@ -0,0 +1,249 @@
+/*
+ * Hisilicon Gigabit Ethernet MDIO Bus Driver
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program. If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/clk.h>
+#include <linux/iopoll.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of_address.h>
+#include <linux/of_mdio.h>
+#include <linux/platform_device.h>
+#include <linux/reset.h>
+
+#if defined(CONFIG_ARCH_HI3519) || defined(CONFIG_ARCH_HI3519V101) || \
+	defined(CONFIG_ARCH_HI3516AV200)
+#ifdef readl
+#undef readl
+#undef writel
+#define readl		hi_readl
+#define writel		hi_writel
+#endif
+#endif
+
+#define MDIO_SINGLE_CMD		0x00
+#define MDIO_SINGLE_DATA	0x04
+#define MDIO_RDATA_STATUS	0x10
+#define BIT_PHY_ADDR_OFFSET	8
+#define MDIO_WRITE		BIT(16)
+#define MDIO_READ		BIT(17)
+#define MDIO_START		BIT(20)
+#define MDIO_START_READ		(MDIO_START | MDIO_READ)
+#define MDIO_START_WRITE	(MDIO_START | MDIO_WRITE)
+
+struct hisi_gemac_mdio_data {
+	struct clk *clk;
+	struct reset_control *phy_rst;
+	void __iomem *membase;
+};
+
+static int hisi_gemac_mdio_wait_ready(struct hisi_gemac_mdio_data *data)
+{
+	u32 val;
+
+	return readl_poll_timeout(data->membase + MDIO_SINGLE_CMD,
+				  val, !(val & MDIO_START), 20, 10000);
+}
+
+static int hisi_gemac_mdio_read(struct mii_bus *bus, int mii_id, int regnum)
+{
+	struct hisi_gemac_mdio_data *data = bus->priv;
+	int ret;
+
+	ret = hisi_gemac_mdio_wait_ready(data);
+	if (ret)
+		return ret;
+
+	writel(MDIO_START_READ | ((u32)mii_id << BIT_PHY_ADDR_OFFSET) |
+		((u32)regnum),
+	       data->membase + MDIO_SINGLE_CMD);
+
+	ret = hisi_gemac_mdio_wait_ready(data);
+	if (ret)
+		return ret;
+
+	/* if read data is invalid, we just return 0 instead of -EAGAIN.
+	 * This can make MDIO more robust when reading PHY status.
+	 */
+	if (readl(data->membase + MDIO_RDATA_STATUS))
+		return 0;
+
+	return readl(data->membase + MDIO_SINGLE_DATA) >> 16;
+}
+
+static int hisi_gemac_mdio_write(struct mii_bus *bus, int mii_id, int regnum,
+				 u16 value)
+{
+	struct hisi_gemac_mdio_data *data = bus->priv;
+	int ret;
+
+	ret = hisi_gemac_mdio_wait_ready(data);
+	if (ret)
+		return ret;
+
+	writel(value, data->membase + MDIO_SINGLE_DATA);
+	writel(MDIO_START_WRITE | ((u32)mii_id << BIT_PHY_ADDR_OFFSET) |
+		((u32)regnum),
+	       data->membase + MDIO_SINGLE_CMD);
+
+	return hisi_gemac_mdio_wait_ready(data);
+}
+
+static void hisi_gemac_external_phy_reset(struct hisi_gemac_mdio_data *data)
+{
+	if (data->phy_rst) {
+		/* write 0 to cancel reset */
+		reset_control_deassert(data->phy_rst);
+		msleep(50);
+
+		/* HIFONE or 98cv200 use CRG register to reset phy */
+		/* RST_BIT, write 0 to reset phy, write 1 to cancel reset */
+		reset_control_assert(data->phy_rst);
+
+		/* delay some time to ensure reset ok,
+		 * this depends on PHY hardware feature
+		 */
+		msleep(50);
+
+		/* write 0 to cancel reset */
+		reset_control_deassert(data->phy_rst);
+		/* delay some time to ensure later MDIO access */
+		msleep(50);
+	} else {
+#if defined(CONFIG_ARCH_HI3516A)
+#include <mach/hi3516a_io.h>
+#define GPIO_BASE_ETH_PHY_RESET		0x20140000
+#define GPIO_BIT_ETH_PHY_RESET		1
+		void __iomem *gpio_base;
+		u32 val;
+
+		gpio_base = (void __iomem *)IO_ADDRESS(GPIO_BASE_ETH_PHY_RESET);
+		/* use GPIO to do hardware PHY reset */
+		/* set direction */
+		val = readl(gpio_base + 0x400);
+		val |= (1 << GPIO_BIT_ETH_PHY_RESET);
+		writel(val, gpio_base + 0x400);
+
+		/* Firstly, set to 1 regardless of the value of this pin */
+		writel(0xFF, gpio_base + (4 << GPIO_BIT_ETH_PHY_RESET));
+		msleep(20);
+
+		/* Set to 0 to reset, then sleep 200ms */
+		writel(0x0, gpio_base + (4 << GPIO_BIT_ETH_PHY_RESET));
+		msleep(20);
+
+		/* then, cancel reset, and should sleep 50ms */
+		writel(0xFF, gpio_base + (4 << GPIO_BIT_ETH_PHY_RESET));
+		msleep(200);
+#endif
+	}
+}
+
+static int hisi_gemac_mdio_probe(struct platform_device *pdev)
+{
+	struct device_node *np = pdev->dev.of_node;
+	struct mii_bus *bus;
+	struct hisi_gemac_mdio_data *data;
+	struct resource *res;
+	int ret;
+
+	bus = mdiobus_alloc_size(sizeof(*data));
+	if (!bus)
+		return -ENOMEM;
+
+	bus->name = "hisi_gemac_mii_bus";
+	bus->read = &hisi_gemac_mdio_read;
+	bus->write = &hisi_gemac_mdio_write;
+	snprintf(bus->id, MII_BUS_ID_SIZE, "%s", pdev->name);
+	bus->parent = &pdev->dev;
+
+	data = bus->priv;
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		ret = -ENXIO;
+		goto err_out_free_mdiobus;
+	}
+	data->membase = devm_ioremap(&pdev->dev, res->start,
+				     resource_size(res));
+	if (!data->membase) {
+		ret = -ENOMEM;
+		goto err_out_free_mdiobus;
+	}
+
+	data->clk = devm_clk_get(&pdev->dev, NULL);
+	if (IS_ERR(data->clk)) {
+		ret = PTR_ERR(data->clk);
+		goto err_out_free_mdiobus;
+	}
+
+	ret = clk_prepare_enable(data->clk);
+	if (ret)
+		goto err_out_free_mdiobus;
+
+	data->phy_rst = devm_reset_control_get(&pdev->dev, "phy_reset");
+	if (IS_ERR(data->phy_rst))
+		data->phy_rst = NULL;
+	hisi_gemac_external_phy_reset(data);
+
+	ret = of_mdiobus_register(bus, np);
+	if (ret)
+		goto err_out_disable_clk;
+
+	platform_set_drvdata(pdev, bus);
+
+	return 0;
+
+err_out_disable_clk:
+	clk_disable_unprepare(data->clk);
+err_out_free_mdiobus:
+	mdiobus_free(bus);
+	return ret;
+}
+
+static int hisi_gemac_mdio_remove(struct platform_device *pdev)
+{
+	struct mii_bus *bus = platform_get_drvdata(pdev);
+	struct hisi_gemac_mdio_data *data = bus->priv;
+
+	mdiobus_unregister(bus);
+	clk_disable_unprepare(data->clk);
+	mdiobus_free(bus);
+
+	return 0;
+}
+
+static const struct of_device_id hisi_gemac_mdio_dt_ids[] = {
+	{ .compatible = "hisilicon,hisi-gemac-mdio" },
+	{ }
+};
+MODULE_DEVICE_TABLE(of, hisi_gemac_mdio_dt_ids);
+
+static struct platform_driver hisi_gemac_mdio_driver = {
+	.probe = hisi_gemac_mdio_probe,
+	.remove = hisi_gemac_mdio_remove,
+	.driver = {
+		.name = "hisi-gemac-mdio",
+		.of_match_table = hisi_gemac_mdio_dt_ids,
+	},
+};
+
+module_platform_driver(hisi_gemac_mdio_driver);
+
+MODULE_DESCRIPTION("Hisilicon Gigabit Ethernet MAC MDIO interface driver");
+MODULE_AUTHOR("Dongpo Li <lidongpo@hisilicon.com>");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/net/phy/phy_device.c b/drivers/net/phy/phy_device.c
index 32b555a..f02a86e 100644
--- a/drivers/net/phy/phy_device.c
+++ b/drivers/net/phy/phy_device.c
@@ -234,6 +234,53 @@ int phy_register_fixup_for_id(const char *bus_id,
 }
 EXPORT_SYMBOL(phy_register_fixup_for_id);
 
+/**
+ * phy_unregister_fixup - remove a phy_fixup from the list
+ * @bus_id: A string matches fixup->bus_id (or PHY_ANY_ID) in phy_fixup_list
+ * @phy_uid: A phy id matches fixup->phy_id (or PHY_ANY_UID) in phy_fixup_list
+ * @phy_uid_mask: Applied to phy_uid and fixup->phy_uid before comparison
+ */
+int phy_unregister_fixup(const char *bus_id, u32 phy_uid, u32 phy_uid_mask)
+{
+	struct list_head *pos, *n;
+	struct phy_fixup *fixup;
+	int ret;
+
+	ret = -ENODEV;
+
+	mutex_lock(&phy_fixup_lock);
+	list_for_each_safe(pos, n, &phy_fixup_list) {
+		fixup = list_entry(pos, struct phy_fixup, list);
+
+		if ((!strcmp(fixup->bus_id, bus_id)) &&
+		    ((fixup->phy_uid & phy_uid_mask) ==
+		     (phy_uid & phy_uid_mask))) {
+			list_del(&fixup->list);
+			kfree(fixup);
+			ret = 0;
+			break;
+		}
+	}
+	mutex_unlock(&phy_fixup_lock);
+
+	return ret;
+}
+EXPORT_SYMBOL(phy_unregister_fixup);
+
+/* Unregisters a fixup of any PHY with the UID in phy_uid */
+int phy_unregister_fixup_for_uid(u32 phy_uid, u32 phy_uid_mask)
+{
+	return phy_unregister_fixup(PHY_ANY_ID, phy_uid, phy_uid_mask);
+}
+EXPORT_SYMBOL(phy_unregister_fixup_for_uid);
+
+/* Unregisters a fixup of the PHY with id string bus_id */
+int phy_unregister_fixup_for_id(const char *bus_id)
+{
+	return phy_unregister_fixup(bus_id, PHY_ANY_UID, 0xffffffff);
+}
+EXPORT_SYMBOL(phy_unregister_fixup_for_id);
+
 /* Returns 1 if fixup matches phydev in bus_id and phy_uid.
  * Fixups can be set to match any in one or more fields.
  */
diff --git a/drivers/phy/Kconfig b/drivers/phy/Kconfig
index 7dc726d..17bc054 100644
--- a/drivers/phy/Kconfig
+++ b/drivers/phy/Kconfig
@@ -481,6 +481,7 @@ config PHY_CYGNUS_PCIE
 	  If unsure, say N.
 
 source "drivers/phy/tegra/Kconfig"
+source "drivers/phy/hibvt/Kconfig"
 
 config PHY_NS2_PCIE
 	tristate "Broadcom Northstar2 PCIe PHY driver"
diff --git a/drivers/phy/Makefile b/drivers/phy/Makefile
index a534cf5..b69cc4b 100644
--- a/drivers/phy/Makefile
+++ b/drivers/phy/Makefile
@@ -59,4 +59,5 @@ obj-$(CONFIG_PHY_BRCM_SATA)		+= phy-brcm-sata.o
 obj-$(CONFIG_PHY_PISTACHIO_USB)		+= phy-pistachio-usb.o
 obj-$(CONFIG_PHY_CYGNUS_PCIE)		+= phy-bcm-cygnus-pcie.o
 obj-$(CONFIG_ARCH_TEGRA) += tegra/
+obj-$(CONFIG_ARCH_HISI_BVT) += hibvt/
 obj-$(CONFIG_PHY_NS2_PCIE)		+= phy-bcm-ns2-pcie.o
diff --git a/drivers/phy/hibvt/Kconfig b/drivers/phy/hibvt/Kconfig
new file mode 100644
index 0000000..d9f72be
--- /dev/null
+++ b/drivers/phy/hibvt/Kconfig
@@ -0,0 +1,26 @@
+config PHY_HISI_SATA
+	tristate "Hisilicon sata nano phy support"
+	depends on (ARCH_HI3536DV100 && OF && HAS_IOMEM)
+	default y if ARCH_HI3536DV100
+	select GENERIC_PHY
+	help
+	  Enable this to support the sata phy that is part of
+	  sata driver for hisilicon
+
+config HISI_SATA_MODE
+	int "Hisi sata interworking speed mode(1.5G:0/3G:1/6G:2)"
+	depends on PHY_HISI_SATA
+	range 0 1 if ARCH_HI3536DV100
+	default "1" if ARCH_HI3536DV100
+	help
+	  Hisilicon sata interworking speed mode
+
+config PHY_HISI_USB2
+	tristate "HISI USB2 PHY Driver"
+	default y
+	select GENERIC_PHY
+	help
+	Support for PHY on Hisilicon Socs. This Phy supports
+	USB 1.5Mb/s, USB 12Mb/s, USB 480Mb/s speeds. It suppots one
+	USB host port to accept one USB device. Support init the phy
+	and adjust phy Eye Diagram.
diff --git a/drivers/phy/hibvt/Makefile b/drivers/phy/hibvt/Makefile
new file mode 100644
index 0000000..63ff999
--- /dev/null
+++ b/drivers/phy/hibvt/Makefile
@@ -0,0 +1,4 @@
+obj-$(CONFIG_PHY_HISI_SATA)			+= phy-hisi-sata.o
+obj-$(CONFIG_PHY_HISI_USB2)			+= phy-hisi-usb.o
+obj-$(CONFIG_ARCH_HI3516A)			+= phy-hi3516a-usb.o
+obj-$(CONFIG_ARCH_HI3536DV100)		+= phy-hi3536d-usb.o
diff --git a/drivers/phy/hibvt/phy-hi3516a-usb.c b/drivers/phy/hibvt/phy-hi3516a-usb.c
new file mode 100644
index 0000000..6683b64
--- /dev/null
+++ b/drivers/phy/hibvt/phy-hi3516a-usb.c
@@ -0,0 +1,133 @@
+#include <linux/delay.h>
+#include <linux/io.h>
+#include <linux/phy/phy.h>
+#include "phy-hisi-usb.h"
+
+#define USB2_SWITCH_OFFSET	0x130
+#define PERI_CRG46		0xb8
+#define USB_CKEN		(1 << 7)
+#define USB_CTRL_UTMI0_REG	(1 << 5)
+#define USB_CTRL_HUB_REG	(1 << 4)
+#define USBPHY_PORT0_TREQ	(1 << 2)
+#define USBPHY_REQ		(1 << 1)
+#define USB_AHB_SRST_REQ	(1 << 0)
+
+#define PERI_USB                0x78
+#define WORDINTERFACE           (1 << 0)
+#define SS_BURST4_EN            (1 << 7)
+#define SS_BURST8_EN            (1 << 8)
+#define SS_BURST16_EN           (1 << 9)
+#define USBOVR_P_CTRL           (1 << 17)
+#define MISC_USB                0x80
+
+static int *usb2_switch_base;
+
+void hisi_switch_func(int otg)
+{
+	int reg;
+
+	reg = readl(usb2_switch_base);
+	if (otg) {
+		reg |= 0x1;
+		writel(reg, usb2_switch_base);
+	} else {
+		reg &= ~(0x1);
+		writel(reg, usb2_switch_base);
+	}
+}
+EXPORT_SYMBOL(hisi_switch_func);
+
+void hisi_usb_phy_on(struct phy *phy)
+{
+	int reg;
+	struct hisi_priv *priv = phy_get_drvdata(phy);
+
+	usb2_switch_base = priv->switch_base + USB2_SWITCH_OFFSET;
+	/* enable phy ref clk to enable phy */
+	reg = readl(priv->peri_ctrl + PERI_CRG46);
+	reg |= USB_CKEN;
+	writel(reg, priv->peri_ctrl + PERI_CRG46);
+	udelay(100);
+
+	/* config controller */
+	reg = readl(priv->misc_ctrl + PERI_USB);
+	reg &= ~(WORDINTERFACE); /* 8bit */
+	/* disable ehci burst16 mode*/
+	reg &= ~(SS_BURST16_EN);
+	reg |= USBOVR_P_CTRL;
+	writel(reg, priv->misc_ctrl + PERI_USB);
+	udelay(100);
+
+	/* de-assert phy port */
+	reg = readl(priv->peri_ctrl + PERI_CRG46);
+	reg &= ~(USBPHY_REQ);
+	writel(reg, priv->peri_ctrl + PERI_CRG46);
+	udelay(100);
+
+	/* open phy clk */
+	writel(0xc06, priv->misc_ctrl + MISC_USB);
+	udelay(10);
+	writel(0xc26, priv->misc_ctrl + MISC_USB);
+	mdelay(5);
+
+	/* usb2.0 phy eye pattern */
+	writel(0x1c00, priv->misc_ctrl + MISC_USB);
+	udelay(10);
+	writel(0x1c20, priv->misc_ctrl + MISC_USB);
+	mdelay(5);
+
+	writel(0x0c09, priv->misc_ctrl + MISC_USB);
+	udelay(10);
+	writel(0x0c29, priv->misc_ctrl + MISC_USB);
+	mdelay(5);
+
+	writel(0x1a0a, priv->misc_ctrl + MISC_USB);
+	udelay(10);
+	writel(0x1a2a, priv->misc_ctrl + MISC_USB);
+	mdelay(5);
+
+	/* cancel phy utmi reset */
+	reg = readl(priv->peri_ctrl + PERI_CRG46);
+	reg &= ~(USBPHY_PORT0_TREQ);
+	writel(reg, priv->peri_ctrl + PERI_CRG46);
+	udelay(300);
+
+	/* de-assert all the rsts of ctrl */
+	reg = readl(priv->peri_ctrl + PERI_CRG46);
+	reg &= ~(USB_CTRL_UTMI0_REG);
+	reg &= ~(USB_CTRL_HUB_REG);
+	reg &= ~(USB_AHB_SRST_REQ);
+	writel(reg, priv->peri_ctrl + PERI_CRG46);
+	udelay(200);
+
+	/* decrease the threshold value from 650 to 550*/
+	writel(0xa, priv->misc_ctrl + MISC_USB);
+	udelay(10);
+	writel(0x092a, priv->misc_ctrl + MISC_USB);
+	mdelay(5);
+}
+EXPORT_SYMBOL(hisi_usb_phy_on);
+
+void hisi_usb_phy_off(struct phy *phy)
+{
+	int reg;
+	struct hisi_priv *priv = phy_get_drvdata(phy);
+
+	reg = readl(priv->peri_ctrl + PERI_CRG46);
+	reg &= ~(USB_CKEN);
+	reg |= (USB_CTRL_UTMI0_REG);
+	reg |= (USB_CTRL_HUB_REG);
+	reg |= (USBPHY_PORT0_TREQ);
+	reg |= (USBPHY_REQ);
+	reg |= (USB_AHB_SRST_REQ);
+	writel(reg, priv->peri_ctrl + PERI_CRG46);
+	udelay(100);
+
+	/* enable phy */
+	reg = readl(priv->misc_ctrl + PERI_USB);
+	reg |= (WORDINTERFACE);
+	reg |= (SS_BURST16_EN);
+	reg |= (USBOVR_P_CTRL);
+	writel(reg, priv->misc_ctrl + PERI_USB);
+}
+EXPORT_SYMBOL(hisi_usb_phy_off);
diff --git a/drivers/phy/hibvt/phy-hi3536d-usb.c b/drivers/phy/hibvt/phy-hi3536d-usb.c
new file mode 100644
index 0000000..ffd1b58
--- /dev/null
+++ b/drivers/phy/hibvt/phy-hi3536d-usb.c
@@ -0,0 +1,210 @@
+#include <linux/delay.h>
+#include <linux/phy/phy.h>
+#include <linux/of_address.h>
+#include "phy-hisi-usb.h"
+
+#define USB2_CTRL		0xb8
+#define USB2_BUS_CKEN		(1 << 0)
+#define USB2_OHCI48M_CKEN	(1 << 1)
+#define USB2_OHCI12M_CKEN	(1 << 2)
+#define USB2_HST_PHY_CKEN	(1 << 4)
+#define USB2_UTMI0_CKEN		(1 << 5)
+#define USB2_UTMI1_CKEN		(1 << 6)
+#define USB2_BUS_SRST_REQ	(1 << 12)
+#define USB2_UTMI0_SRST_REQ	(1 << 13)
+#define USB2_UTMI1_SRST_REQ	(1 << 14)
+#define USB2_HST_PHY_SYST_REQ	(1 << 16)
+
+#define REG_USB2_PHY0		0xbc
+#define USB_PHY0_REF_CKEN	(1 << 0)
+#define USB_PHY0_SRST_REQ	(1 << 1)
+#define USB_PHY0_SRST_TREQ	(1 << 2)
+#define USB_PHY1_SRST_TREQ	(1 << 3)
+#define USB_PHY0_TEST_SRST_REQ	(1 << 4)
+
+#define MISC_CTRL_TRIM		0x50
+#define USB_R_TUNING_1		0x800c
+#define USB_R_TUNING_2		0x840c
+#define MISC_CTRL20_23		(1 << 23)
+#define MISC_CTRL20_24		(1 << 24)
+#define MISC_CTRL20_25		(1 << 25)
+#define MISC_CTRL20_26		(1 << 26)
+#define MISC_CTRL20_27		(1 << 27)
+#define TRIM_CONFIG_2		(1 << 2)
+#define TRIM_CONFIG_3		(1 << 3)
+#define TRIM_CONFIG_4		(1 << 4)
+#define TRIM_CONFIG_5		(1 << 5)
+#define TRIM_CONFIG_6		(1 << 6)
+
+#define MISC_CTRL			(1 << 22)
+#define REG_USB2_CFG		0x8018
+#define USB2_CFG_VAL		0x05
+#define USB2_PHY0_CTLL		0x54
+
+/* param config */
+#define EYE_HEIGHT_CFG		0x8008
+#define EYE_HEIGHT_RECFG	0x8408
+#define EYE_HEIGHT_VAL		0x5c
+
+#define PRE_OPEN_CFG		0x8000
+#define PRE_OPEN_RECFG		0x8400
+#define PRE_OPEN_VAL		0x1c
+
+#define PRE_IMP_CFG			0x8014
+#define PRE_IMP_RECFG		0x8414
+#define PRE_IMP_VAL			0x80
+
+#define DISC_CFG			0x8010
+#define DISC_RECFG			0x8410
+#define DISC_CFG_VAL		0x17
+
+
+void hisi_usb_phy_on(struct phy *phy)
+{
+	int reg, trim_reg;
+	struct hisi_priv *priv = phy_get_drvdata(phy);
+
+	/* misc ctrl */
+	reg = readl(priv->misc_ctrl + USB2_PHY0_CTLL);
+	reg |= MISC_CTRL;
+	writel_relaxed(reg, priv->misc_ctrl + USB2_PHY0_CTLL);
+	udelay(200);
+
+	/* reset enable */
+	reg = readl(priv->peri_ctrl + USB2_CTRL);
+	reg |= (USB2_BUS_SRST_REQ
+		| USB2_UTMI0_SRST_REQ
+		| USB2_HST_PHY_SYST_REQ
+		| USB2_UTMI1_SRST_REQ);
+	writel(reg, priv->peri_ctrl + USB2_CTRL);
+	udelay(200);
+
+	reg = readl(priv->peri_ctrl + REG_USB2_PHY0);
+	reg |= (USB_PHY0_SRST_REQ
+		| USB_PHY0_SRST_TREQ
+		| USB_PHY1_SRST_TREQ);
+	writel(reg, priv->peri_ctrl + REG_USB2_PHY0);
+	udelay(200);
+
+	/* open ref clock */
+	reg = readl(priv->peri_ctrl + REG_USB2_PHY0);
+	reg |= (USB_PHY0_REF_CKEN);
+	writel(reg, priv->peri_ctrl + REG_USB2_PHY0);
+	udelay(100);
+
+	/* cancel power on reset */
+	reg = readl(priv->peri_ctrl + REG_USB2_PHY0);
+	reg &= ~(USB_PHY0_SRST_REQ);
+	reg &= ~(USB_PHY0_TEST_SRST_REQ);
+	writel(reg, priv->peri_ctrl + REG_USB2_PHY0);
+	udelay(300);
+
+	writel(USB2_CFG_VAL, priv->misc_ctrl + REG_USB2_CFG);
+	udelay(200);
+
+	/* cancel port reset */
+	reg = readl(priv->peri_ctrl + REG_USB2_PHY0);
+	reg &= ~(USB_PHY0_SRST_TREQ);
+	reg &= ~(USB_PHY1_SRST_TREQ);
+	writel(reg, priv->peri_ctrl + REG_USB2_PHY0);
+	udelay(300);
+
+	/* cancel control reset */
+	reg = readl(priv->peri_ctrl + USB2_CTRL);
+	reg &= ~(USB2_BUS_SRST_REQ
+		| USB2_UTMI0_SRST_REQ
+		| USB2_HST_PHY_SYST_REQ
+		| USB2_UTMI1_SRST_REQ);
+	reg |= (USB2_BUS_CKEN
+		| USB2_OHCI48M_CKEN
+		| USB2_OHCI12M_CKEN
+		| USB2_HST_PHY_CKEN
+		| USB2_UTMI0_CKEN
+		| USB2_UTMI1_CKEN);
+	writel(reg, priv->peri_ctrl + USB2_CTRL);
+	udelay(200);
+
+	/* Trim config */
+	reg = readl(priv->misc_ctrl + MISC_CTRL_TRIM);
+	reg &= (MISC_CTRL20_23
+			| MISC_CTRL20_24
+			| MISC_CTRL20_25
+			| MISC_CTRL20_26
+			| MISC_CTRL20_27);
+	reg = reg >> 21;
+	if(reg){
+		trim_reg = readl(priv->misc_ctrl + USB_R_TUNING_1);
+		trim_reg &= ~(TRIM_CONFIG_2
+				| TRIM_CONFIG_3
+				| TRIM_CONFIG_4
+				| TRIM_CONFIG_5
+				| TRIM_CONFIG_6);
+		trim_reg |= reg;
+		writel(trim_reg, priv->misc_ctrl + USB_R_TUNING_1);
+
+		trim_reg = readl(priv->misc_ctrl + USB_R_TUNING_2);
+		trim_reg &= ~(TRIM_CONFIG_2
+				| TRIM_CONFIG_3
+				| TRIM_CONFIG_4
+				| TRIM_CONFIG_5
+				| TRIM_CONFIG_6);
+		trim_reg |= reg;
+		writel(trim_reg, priv->misc_ctrl + USB_R_TUNING_2);
+	}
+
+	/* eye height config */
+	writel_relaxed(EYE_HEIGHT_VAL, priv->misc_ctrl + EYE_HEIGHT_CFG);
+	udelay(100);
+	writel_relaxed(EYE_HEIGHT_VAL, priv->misc_ctrl + EYE_HEIGHT_RECFG);
+	udelay(100);
+
+	/* pre open */
+	writel_relaxed(PRE_OPEN_VAL, priv->misc_ctrl + PRE_OPEN_CFG);
+	udelay(100);
+	writel_relaxed(PRE_OPEN_VAL, priv->misc_ctrl + PRE_OPEN_RECFG);
+	udelay(100);
+
+	/* pre improve */
+	writel_relaxed(PRE_IMP_VAL, priv->misc_ctrl + PRE_IMP_CFG);
+	udelay(100);
+	writel_relaxed(PRE_IMP_VAL, priv->misc_ctrl + PRE_IMP_RECFG);
+	udelay(100);
+
+	/* disconnects */
+	writel_relaxed(DISC_CFG_VAL, priv->misc_ctrl + DISC_CFG);
+	udelay(100);
+	writel_relaxed(DISC_CFG_VAL, priv->misc_ctrl + DISC_RECFG);
+	udelay(100);
+}
+EXPORT_SYMBOL(hisi_usb_phy_on);
+
+void hisi_usb_phy_off(struct phy *phy)
+{
+	int reg;
+	struct hisi_priv *priv = phy_get_drvdata(phy);
+
+	reg = readl(priv->peri_ctrl + REG_USB2_PHY0);
+	reg |= (USB_PHY0_SRST_REQ
+		| USB_PHY0_SRST_TREQ
+		| USB_PHY1_SRST_TREQ);
+	writel(reg, priv->peri_ctrl + REG_USB2_PHY0);
+	udelay(100);
+
+	/* close clock */
+	reg = readl(priv->peri_ctrl + REG_USB2_PHY0);
+	reg &= ~USB_PHY0_REF_CKEN;
+	writel(reg, priv->peri_ctrl + REG_USB2_PHY0);
+	udelay(300);
+
+	/* close clock */
+	reg = readl(priv->peri_ctrl + USB2_CTRL);
+	reg &= ~(USB2_BUS_CKEN
+		| USB2_OHCI48M_CKEN
+		| USB2_OHCI12M_CKEN
+		| USB2_HST_PHY_CKEN
+		| USB2_UTMI0_CKEN
+		| USB2_UTMI1_CKEN);
+	writel(reg, priv->peri_ctrl + USB2_CTRL);
+	udelay(200);
+}
+EXPORT_SYMBOL(hisi_usb_phy_off);
diff --git a/drivers/phy/hibvt/phy-hi3536dv100-sata.c b/drivers/phy/hibvt/phy-hi3536dv100-sata.c
new file mode 100644
index 0000000..91b8f0a
--- /dev/null
+++ b/drivers/phy/hibvt/phy-hi3536dv100-sata.c
@@ -0,0 +1,208 @@
+/*
+ * Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/io.h>
+#include <mach/io.h>
+#include <mach/platform.h>
+
+#include "phy-hisi-sata.h"
+
+enum {
+	HISI_SATA_PERI_CTRL		= IO_ADDRESS(REG_CRG_BASE),
+	HISI_SATA_PERI_CRG44	= (HISI_SATA_PERI_CTRL + 0xB0),
+	HISI_SATA_PERI_CRG45	= (HISI_SATA_PERI_CTRL + 0xB4),
+	HISI_SATAPHY_MISC_CTRL	= IO_ADDRESS(REG_MISC_CTRL_BASE),
+	HISI_SATAPHY_MISC_CTRL22 = (HISI_SATAPHY_MISC_CTRL + 0x58),
+
+	HISI_SATA_PHY0_CLK_EN	= (1 << 0),
+	HISI_SATA_PHY0_RST		= (1 << 1),
+	HISI_SATA_PHY0_REFCLK_SEL_MASK = (0x3 << 2),
+	HISI_SATA_PHY0_REFCLK_SEL = (0x2 << 2),
+
+	HISI_SATA_BUS_CKEN		= (1 << 0),
+	HISI_SATA_RX0_CKEN		= (1 << 1),
+	HISI_SATA_CKO_ALIVE_CKEN	= (1 << 2),
+	HISI_SATA_TX0_CKEN		= (1 << 3),
+	HISI_SATA_BUS_SRST_REQ	= (1 << 8),
+	HISI_SATA_CKO_ALIVE_SRST_REQ	= (1 << 9),
+	HISI_SATA_RX0_SRST_REQ	= (1 << 10),
+	HISI_SATA0_SRST_REQ		= (1 << 11),
+
+	FIFOTH_VALUE    = 0xFEED9F24,
+	PHY_CONFIG_1_5G = 0x0e180000,
+	PHY_CONFIG_3G   = 0x0e390000,
+
+	PHY_SG_1_5G = 0x50438,
+	PHY_SG_3G   = 0x50438,
+};
+
+static void hisi_sata_poweron(void)
+{
+}
+
+static void hisi_sata_poweroff(void)
+{
+}
+
+void hisi_sata_reset_rxtx_assert(void)
+{
+	unsigned int tmp_val;
+
+	tmp_val = readl((void *)HISI_SATA_PERI_CRG45);
+
+	tmp_val |= HISI_SATA_RX0_SRST_REQ | HISI_SATA0_SRST_REQ;
+	writel(tmp_val, (void *)HISI_SATA_PERI_CRG45);
+}
+EXPORT_SYMBOL(hisi_sata_reset_rxtx_assert);
+
+void hisi_sata_reset_rxtx_deassert(void)
+{
+	unsigned int tmp_val;
+
+	tmp_val = readl((void *)HISI_SATA_PERI_CRG45);
+
+	tmp_val &= ~(HISI_SATA_RX0_SRST_REQ | HISI_SATA0_SRST_REQ);
+
+	writel(tmp_val, (void *)HISI_SATA_PERI_CRG45);
+}
+EXPORT_SYMBOL(hisi_sata_reset_rxtx_deassert);
+
+static void hisi_sata_reset(void)
+{
+	unsigned int tmp_val;
+
+	tmp_val = readl((void *)HISI_SATA_PERI_CRG45);
+
+	tmp_val |= HISI_SATA_BUS_SRST_REQ | HISI_SATA_CKO_ALIVE_SRST_REQ
+		| HISI_SATA_RX0_SRST_REQ | HISI_SATA0_SRST_REQ;
+	writel(tmp_val, (void *)HISI_SATA_PERI_CRG45);
+}
+
+static void hisi_sata_unreset(void)
+{
+	unsigned int tmp_val;
+
+	tmp_val = readl((void *)HISI_SATA_PERI_CRG45);
+
+	tmp_val &= ~(HISI_SATA_BUS_SRST_REQ | HISI_SATA_CKO_ALIVE_SRST_REQ
+		| HISI_SATA_RX0_SRST_REQ | HISI_SATA0_SRST_REQ);
+
+	writel(tmp_val, (void *)HISI_SATA_PERI_CRG45);
+}
+
+static void hisi_sata_phy_reset(void)
+{
+	unsigned int tmp_val;
+
+	tmp_val = readl((void *)HISI_SATA_PERI_CRG44);
+	tmp_val |= HISI_SATA_PHY0_RST;
+	writel(tmp_val, (void *)HISI_SATA_PERI_CRG44);
+}
+
+static void hisi_sata_phy_unreset(void)
+{
+	unsigned int tmp_val;
+
+	tmp_val = readl((void *)HISI_SATA_PERI_CRG44);
+	tmp_val &= ~HISI_SATA_PHY0_RST;
+	writel(tmp_val, (void *)HISI_SATA_PERI_CRG44);
+}
+
+static void hisi_sata_clk_enable(void)
+{
+	unsigned int tmp_val, tmp_reg;
+
+	tmp_val = readl((void *)HISI_SATA_PERI_CRG44);
+	tmp_reg = readl((void *)HISI_SATA_PERI_CRG45);
+	tmp_val |= HISI_SATA_PHY0_CLK_EN;
+	tmp_reg |= HISI_SATA_RX0_CKEN | HISI_SATA_TX0_CKEN;
+	writel(tmp_val, (void *)HISI_SATA_PERI_CRG44);
+	writel(tmp_reg, (void *)HISI_SATA_PERI_CRG45);
+
+}
+
+static void hisi_sata_clk_disable(void)
+{
+}
+
+static void hisi_sata_clk_reset(void)
+{
+}
+
+static void hisi_sata_phy_clk_sel(void)
+{
+	unsigned int tmp_val;
+
+	tmp_val = readl((void *)HISI_SATA_PERI_CRG44);
+	tmp_val &= ~HISI_SATA_PHY0_REFCLK_SEL_MASK;
+	tmp_val |= HISI_SATA_PHY0_REFCLK_SEL;
+	writel(tmp_val, (void *)HISI_SATA_PERI_CRG44);
+}
+
+void hisi_sata_set_fifoth(void *mmio)
+{
+	writel(FIFOTH_VALUE, (mmio + 0x100 + PORT_FIFOTH));
+}
+EXPORT_SYMBOL(hisi_sata_set_fifoth);
+
+static void hisi_sata_phy_config(void *mmio, int phy_mode)
+{
+	unsigned int tmp_val, phy_config = PHY_CONFIG_3G;
+	unsigned int phy_sg = PHY_SG_3G;
+
+	hisi_sata_set_fifoth(mmio);
+
+	tmp_val = readl(mmio + PHY_CTL1);
+	tmp_val |= PHY_DATA_INVERT;
+	writel(tmp_val, (mmio + PHY_CTL1));
+	tmp_val = readl(mmio + PHY_CTL2);
+	tmp_val |= PHY_DATA_INVERT;
+	writel(tmp_val, (mmio + PHY_CTL2));
+
+	tmp_val = readl(mmio + PHY_RST_BACK_MASK);
+	tmp_val |= PHY_RST_MASK_ALL;
+	tmp_val &= ~PHY0_RST_MASK;
+	writel(tmp_val, (mmio + PHY_RST_BACK_MASK));
+
+	if (phy_mode == PHY_MODE_1_5G) {
+		phy_config = PHY_CONFIG_1_5G;
+		phy_sg = PHY_SG_1_5G;
+	}
+
+	if (phy_mode == PHY_MODE_3G) {
+		phy_config = PHY_CONFIG_3G;
+		phy_sg = PHY_SG_3G;
+	}
+
+	writel(phy_config, (mmio + 0x100 + PORT_PHYCTL));
+	writel(phy_sg, (mmio + 0x100 + PORT_PHYCTL1));
+
+	/* force pll always work at 6Gbps, force cdr at 3Gbps
+	 * for gen1 and at 6Gbps for gen2
+	 */
+	writel(0x70f, (void *)HISI_SATAPHY_MISC_CTRL22);
+	writel(0x74f, (void *)HISI_SATAPHY_MISC_CTRL22);
+	writel(0x70f, (void *)HISI_SATAPHY_MISC_CTRL22);
+	writel(0x0, (void *)HISI_SATAPHY_MISC_CTRL22);
+
+	/* disable SSC*/
+	writel(0x802, (void *)HISI_SATAPHY_MISC_CTRL22);
+	writel(0x842, (void *)HISI_SATAPHY_MISC_CTRL22);
+	writel(0x802, (void *)HISI_SATAPHY_MISC_CTRL22);
+	writel(0x0, (void *)HISI_SATAPHY_MISC_CTRL22);
+}
diff --git a/drivers/phy/hibvt/phy-hisi-sata.c b/drivers/phy/hibvt/phy-hisi-sata.c
new file mode 100644
index 0000000..2d6cbf5
--- /dev/null
+++ b/drivers/phy/hibvt/phy-hisi-sata.c
@@ -0,0 +1,151 @@
+/*
+ * Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#include <linux/delay.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/phy/phy.h>
+#include <linux/platform_device.h>
+#include <mach/io.h>
+
+static unsigned int phy_mode = CONFIG_HISI_SATA_MODE;
+
+#ifdef MODULE
+module_param(mode_3g, uint, 0600);
+MODULE_PARM_DESC(phy_mode, "sata phy mode (0:1.5G;1:3G(default);2:6G)");
+#endif
+
+#ifdef CONFIG_ARCH_HI3536DV100
+#include "phy-hi3536dv100-sata.c"
+#endif
+
+static int hisi_sata_phy_init(struct phy *phy)
+{
+	void __iomem *mmio = phy_get_drvdata(phy);
+
+	hisi_sata_poweron();
+	hisi_sata_reset();
+	hisi_sata_phy_reset();
+	hisi_sata_phy_clk_sel();
+	hisi_sata_clk_enable();
+	msleep(20);
+	hisi_sata_phy_unreset();
+	msleep(20);
+	hisi_sata_unreset();
+	msleep(20);
+	hisi_sata_phy_config(mmio, phy_mode);
+
+	return 0;
+}
+
+static int hisi_sata_phy_exit(struct phy *phy)
+{
+	hisi_sata_phy_reset();
+	msleep(20);
+	hisi_sata_reset();
+	msleep(20);
+	hisi_sata_clk_reset();
+	msleep(20);
+	hisi_sata_clk_disable();
+	hisi_sata_poweroff();
+	msleep(20);
+
+	return 0;
+}
+
+static struct phy_ops hisi_sata_phy_ops = {
+	.init		= hisi_sata_phy_init,
+	.exit		= hisi_sata_phy_exit,
+	.owner		= THIS_MODULE,
+};
+
+static int hisi_sata_phy_probe(struct platform_device *pdev)
+{
+	struct phy_provider *phy_provider;
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	struct phy *phy;
+	void __iomem *mmio;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(dev, "failed to get reg base\n");
+		return -ENOENT;
+	}
+
+	mmio = devm_ioremap(dev, res->start, resource_size(res));
+	if (!mmio)
+		return -ENOMEM;
+
+	phy = devm_phy_create(dev, NULL, &hisi_sata_phy_ops);
+	if (IS_ERR(phy)) {
+		dev_err(dev, "failed to create PHY\n");
+		return PTR_ERR(phy);
+	}
+
+	phy_set_drvdata(phy, mmio);
+
+	phy_provider = devm_of_phy_provider_register(dev, of_phy_simple_xlate);
+	if (IS_ERR(phy_provider))
+		return PTR_ERR(phy_provider);
+
+	return 0;
+}
+
+static int hisi_sata_phy_suspend(struct platform_device *pdev,
+		pm_message_t state)
+{
+	struct device *dev = &pdev->dev;
+	struct phy *phy = to_phy(dev);
+
+	hisi_sata_phy_exit(phy);
+
+	return 0;
+}
+
+static int hisi_sata_phy_resume(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct phy *phy = to_phy(dev);
+
+	hisi_sata_phy_init(phy);
+
+	return 0;
+}
+
+static const struct of_device_id hisi_sata_phy_of_match[] = {
+	{.compatible = "hisilicon,hisi-sata-phy",},
+	{ },
+};
+MODULE_DEVICE_TABLE(of, hisi_sata_phy_of_match);
+
+static struct platform_driver hisi_sata_phy_driver = {
+	.probe	= hisi_sata_phy_probe,
+	.suspend = hisi_sata_phy_suspend,
+	.resume  = hisi_sata_phy_resume,
+	.driver = {
+		.name	= "hisi-sata-phy",
+		.of_match_table	= hisi_sata_phy_of_match,
+	}
+};
+module_platform_driver(hisi_sata_phy_driver);
+
+MODULE_AUTHOR("HiSilicon BVT");
+MODULE_DESCRIPTION("HISILICON SATA PHY driver");
+MODULE_ALIAS("platform:hisi-sata-phy");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/phy/hibvt/phy-hisi-sata.h b/drivers/phy/hibvt/phy-hisi-sata.h
new file mode 100644
index 0000000..a767c68
--- /dev/null
+++ b/drivers/phy/hibvt/phy-hisi-sata.h
@@ -0,0 +1,38 @@
+/*
+ * Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+enum {
+	/* hisi extended global controller registers */
+	PHY_CTL0    = 0xA0,
+	PHY_CTL1    = 0xA4,
+	PHY_RST_BACK_MASK	= 0xAC,
+	PHY_CTL2	= 0xB0,
+
+#define PHY_DATA_INVERT     (0x1 << 3)
+#define PHY0_RST_MASK		(0x1 << 4)
+#define PHY_RST_MASK_ALL	(0xF << 4)
+
+	/* hisi extended registers for each SATA port */
+	PORT_FIFOTH		= 0x44,
+	PORT_PHYCTL1    = 0x48,
+	PORT_PHYCTL     = 0x74,
+
+#define PHY_MODE_1_5G   0
+#define PHY_MODE_3G     1
+#define PHY_MODE_6G     2
+};
diff --git a/drivers/phy/hibvt/phy-hisi-usb.c b/drivers/phy/hibvt/phy-hisi-usb.c
new file mode 100644
index 0000000..fa67598
--- /dev/null
+++ b/drivers/phy/hibvt/phy-hisi-usb.c
@@ -0,0 +1,108 @@
+/*
+ * Copyright (c) 2015 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program. If not, see <http://www.gnu.org/licenses/>.
+ */
+
+#include <linux/module.h>
+#include <linux/phy/phy.h>
+#include <linux/platform_device.h>
+#include <linux/of_address.h>
+
+#include "phy-hisi-usb.h"
+
+static int hisi_usb_phy_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct phy *phy;
+	struct hisi_priv *priv;
+	struct device_node *np = pdev->dev.of_node;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	priv->peri_ctrl = of_iomap(np, 0);
+	if (IS_ERR(priv->peri_ctrl))
+		priv->peri_ctrl = NULL;
+
+	priv->misc_ctrl = of_iomap(np, 1);
+	if (IS_ERR(priv->misc_ctrl))
+		priv->misc_ctrl = NULL;
+
+	priv->switch_base = of_iomap(np, 2);
+	if (IS_ERR(priv->switch_base))
+		priv->switch_base = NULL;
+
+	phy = devm_kzalloc(dev, sizeof(*phy), GFP_KERNEL);
+	if (!phy)
+		return -ENOMEM;
+
+	platform_set_drvdata(pdev, phy);
+	phy_set_drvdata(phy, priv);
+	hisi_usb_phy_on(phy);
+
+	return 0;
+}
+
+static int hisi_usb_phy_remove(struct platform_device *pdev)
+{
+	struct phy *phy = dev_get_drvdata(&pdev->dev);
+
+	hisi_usb_phy_off(phy);
+	return 0;
+}
+
+static const struct of_device_id hisi_usb_phy_of_match[] = {
+	{.compatible = "hisilicon,hisi-usb-phy",},
+	{ },
+};
+MODULE_DEVICE_TABLE(of, hisi_usb_phy_of_match);
+
+#ifdef CONFIG_PM_SLEEP
+static int hisi_usb_phy_suspend(struct device *dev)
+{
+	struct phy *phy = dev_get_drvdata(dev);
+
+	hisi_usb_phy_off(phy);
+	return 0;
+}
+
+static int hisi_usb_phy_resume(struct device *dev)
+{
+	struct phy *phy = dev_get_drvdata(dev);
+
+	hisi_usb_phy_on(phy);
+	return 0;
+}
+#endif /* CONFIG_PM_SLEEP */
+
+static SIMPLE_DEV_PM_OPS(hisi_usb2_pm_ops, hisi_usb_phy_suspend,
+		       hisi_usb_phy_resume);
+
+static struct platform_driver hisi_usb_phy_driver = {
+	.probe	= hisi_usb_phy_probe,
+	.remove = hisi_usb_phy_remove,
+	.driver = {
+		.name	= "hisi-usb-phy",
+		.pm	= &hisi_usb2_pm_ops,
+		.of_match_table	= hisi_usb_phy_of_match,
+	}
+};
+module_platform_driver(hisi_usb_phy_driver);
+
+MODULE_AUTHOR("Pengcheng Li <lpc.li@hisilicon.com>");
+MODULE_DESCRIPTION("HISILICON USB PHY driver");
+MODULE_ALIAS("platform:hisi-usb-phy");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/phy/hibvt/phy-hisi-usb.h b/drivers/phy/hibvt/phy-hisi-usb.h
new file mode 100644
index 0000000..28b9b08
--- /dev/null
+++ b/drivers/phy/hibvt/phy-hisi-usb.h
@@ -0,0 +1,8 @@
+extern void hisi_usb_phy_on(struct phy *phy);
+extern void hisi_usb_phy_off(struct phy *phy);
+struct hisi_priv {
+	void __iomem	*base;
+	void __iomem	*peri_ctrl;
+	void __iomem	*misc_ctrl;
+	void __iomem	*switch_base;
+};
diff --git a/drivers/power/reset/Kconfig b/drivers/power/reset/Kconfig
index 02e46bb..cf3e643 100644
--- a/drivers/power/reset/Kconfig
+++ b/drivers/power/reset/Kconfig
@@ -85,7 +85,7 @@ config POWER_RESET_GPIO_RESTART
 
 config POWER_RESET_HISI
 	bool "Hisilicon power-off driver"
-	depends on ARCH_HISI
+	depends on ARCH_HISI || ARCH_HISI_BVT
 	help
 	  Reboot support for Hisilicon boards.
 
diff --git a/drivers/rtc/Kconfig b/drivers/rtc/Kconfig
index 0723c97..bc4f1c0 100644
--- a/drivers/rtc/Kconfig
+++ b/drivers/rtc/Kconfig
@@ -824,6 +824,14 @@ comment "Platform RTC drivers"
 # requires <asm/mc146818rtc.h> defining CMOS_READ/CMOS_WRITE, and a
 # global rtc_lock ... it's not yet just another platform_device.
 
+config RTC_DRV_HIBVT
+	tristate "HiSilicon BVT RTC support"
+	help
+	  Generic RTC framework driver for HiSilicon BVT SoCs.
+
+	  To compile this driver as a module, choose M here: the module
+	  will be called rtc-hibvt.
+
 config RTC_DRV_CMOS
 	tristate "PC-style 'CMOS'"
 	depends on X86 || ARM || M32R || PPC || MIPS || SPARC64 || MN10300
diff --git a/drivers/rtc/Makefile b/drivers/rtc/Makefile
index 1ac694a..c308468 100644
--- a/drivers/rtc/Makefile
+++ b/drivers/rtc/Makefile
@@ -21,6 +21,7 @@ rtc-core-$(CONFIG_RTC_INTF_SYSFS)	+= rtc-sysfs.o
 
 # Keep the list ordered.
 
+obj-$(CONFIG_RTC_DRV_HIBVT)	+= rtc-hibvt.o
 obj-$(CONFIG_RTC_DRV_88PM80X)	+= rtc-88pm80x.o
 obj-$(CONFIG_RTC_DRV_88PM860X)	+= rtc-88pm860x.o
 obj-$(CONFIG_RTC_DRV_AB3100)	+= rtc-ab3100.o
diff --git a/drivers/rtc/rtc-hibvt.c b/drivers/rtc/rtc-hibvt.c
new file mode 100644
index 0000000..28d0bae
--- /dev/null
+++ b/drivers/rtc/rtc-hibvt.c
@@ -0,0 +1,581 @@
+/*
+ * RTC driver for Hisilicon BVT
+ * Copyright (C) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/bcd.h>
+#include <linux/bitops.h>
+#include <linux/log2.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/rtc.h>
+#include <linux/version.h>
+#include <linux/io.h>
+#include <linux/delay.h>
+
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+
+union u_spi_rw {
+	struct {
+		unsigned int spi_wdata		: 8; /* [7:0] */
+		unsigned int spi_rdata		: 8; /* [15:8] */
+		unsigned int spi_addr		: 7; /* [22:16] */
+		unsigned int spi_rw		    : 1; /* [23] */
+		unsigned int spi_start		: 1; /* [24] */
+		unsigned int reserved		: 6; /* [30:25] */
+		unsigned int spi_busy		: 1; /* [31] */
+	} bits;
+	unsigned int u32;
+};
+
+#define SPI_CLK_DIV			(0x000)
+#define SPI_RW				(0x004)
+
+#define SPI_WRITE		(0)
+#define SPI_READ		(1)
+
+/* RTC REG */
+#define RTC_10MS_COUN	0x00
+#define RTC_S_COUNT		0x01
+#define RTC_M_COUNT		0x02
+#define RTC_H_COUNT		0x03
+#define RTC_D_COUNT_L	0x04
+#define RTC_D_COUNT_H	0x05
+
+#define RTC_MR_10MS		0x06
+#define RTC_MR_S		0x07
+#define RTC_MR_M		0x08
+#define RTC_MR_H		0x09
+#define RTC_MR_D_L		0x0A
+#define RTC_MR_D_H		0x0B
+
+#define RTC_LR_10MS		0x0C
+#define RTC_LR_S		0x0D
+#define RTC_LR_M		0x0E
+#define RTC_LR_H		0x0F
+#define RTC_LR_D_L		0x10
+#define RTC_LR_D_H		0x11
+
+#define RTC_LORD		0x12
+
+#define RTC_IMSC		0x13
+#define RTC_INT_CLR		0x14
+#define RTC_INT			0x15
+#define RTC_INT_RAW		0x16
+
+#define RTC_CLK			0x17
+#define RTC_POR_N		0x18
+#define RTC_SAR_CTRL	0x1A
+#define RTC_CLK_CFG	    0x1B
+
+#define RTC_FREQ_H		0x51
+#define RTC_FREQ_L		0x52
+
+#define FREQ_H_DEFAULT  0x8
+#define FREQ_L_DEFAULT  0x1B
+
+#define LV_CTL_DEFAULT  0x01
+#define CLK_DIV_DEFAULT 0x4
+#define INT_RST_DEFAULT 0x0
+#define INT_MSK_DEFAULT 0x4
+
+#define AIE_INT_MASK       BIT(0)
+#define LV_INT_MASK        BIT(1)
+#define REG_LOAD_STAT      BIT(0)
+#define REG_LOCK_STAT      BIT(1)
+#define REG_LOCK_BYPASS    BIT(2)
+
+#define RETRY_CNT 500
+
+#define DATE_TO_SEC(d, h, m, s)     (s + m*60 + h*60*60 + d*24*60*60)
+#define SEC_TO_DAY(s)            (s/(60*60*24))
+
+struct hibvt_rtc {
+	struct rtc_device	*rtc_dev;
+	void __iomem		*regs;
+	int                  rtc_irq;
+};
+
+static int hibvt_spi_write(void *spi_reg, unsigned char reg,
+	unsigned char val)
+{
+	union u_spi_rw w_data, r_data;
+	int cnt = RETRY_CNT;
+
+	r_data.u32 = 0;
+	w_data.u32 = 0;
+
+	w_data.bits.spi_wdata = val;
+	w_data.bits.spi_addr = reg;
+	w_data.bits.spi_rw = SPI_WRITE;
+	w_data.bits.spi_start = 0x1;
+
+	writel(w_data.u32, (spi_reg+SPI_RW));
+
+	do
+		r_data.u32 = readl(spi_reg+SPI_RW);
+	while (r_data.bits.spi_busy && (--cnt));
+
+	if (r_data.bits.spi_busy)
+		return -EIO;
+
+	return 0;
+}
+
+
+static int hibvt_spi_rtc_write(void *spi_reg, unsigned char reg,
+	unsigned char val)
+{
+	return hibvt_spi_write(spi_reg, reg, val);
+}
+
+static int hibvt_spi_read(void *spi_reg, unsigned char reg,
+	unsigned char *val)
+{
+	union u_spi_rw w_data, r_data;
+	int cnt = RETRY_CNT;
+
+	r_data.u32 = 0;
+	w_data.u32 = 0;
+	w_data.bits.spi_addr = reg;
+	w_data.bits.spi_rw = SPI_READ;
+	w_data.bits.spi_start = 0x1;
+
+	writel(w_data.u32, (spi_reg+SPI_RW));
+
+	do
+		r_data.u32 = readl(spi_reg+SPI_RW);
+	while (r_data.bits.spi_busy && (--cnt));
+
+	if (r_data.bits.spi_busy)
+		return -EIO;
+
+	*val = r_data.bits.spi_rdata;
+
+	return 0;
+}
+
+static int hibvt_spi_rtc_read(void *spi_reg, unsigned char reg,
+	unsigned char *val)
+{
+	return hibvt_spi_read(spi_reg, reg, val);
+}
+
+static int hibvt_rtc_read_time(struct device *dev, struct rtc_time *time)
+{
+	struct hibvt_rtc *rtc = dev_get_drvdata(dev);
+	unsigned char dayl, dayh;
+	unsigned char second, minute, hour;
+	unsigned long seconds = 0;
+	unsigned int day;
+	unsigned char raw_value;
+	int cnt = RETRY_CNT;
+	int ret = 0;
+
+	ret = hibvt_spi_rtc_read(rtc->regs, RTC_INT_RAW, &raw_value);
+	if (ret) {
+		dev_err(dev, "IO err.\n");
+		return ret;
+	}
+
+	if (raw_value & LV_INT_MASK) {
+		dev_err(dev,
+			"low voltage detected, date/time is not reliable.\n");
+		hibvt_spi_write(rtc->regs, RTC_INT_CLR, 1);
+		return -EINVAL;
+	}
+
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_LORD, &raw_value);
+	if (raw_value & REG_LOCK_BYPASS)
+		ret |= hibvt_spi_rtc_write(rtc->regs, RTC_LORD,
+		(~(REG_LOCK_BYPASS)) & raw_value);
+
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_LORD, &raw_value);
+	/* lock the time */
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_LORD,
+	(REG_LOCK_STAT) | raw_value);
+	/* wait rtc load flag */
+	do {
+		ret |= hibvt_spi_rtc_read(rtc->regs, RTC_LORD, &raw_value);
+		msleep(20);
+	} while ((ret || (raw_value & REG_LOCK_STAT)) && (--cnt));
+
+	if (!ret && (raw_value & REG_LOCK_STAT))
+		return -EBUSY;
+
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_S_COUNT, &second);
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_M_COUNT, &minute);
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_H_COUNT, &hour);
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_D_COUNT_L, &dayl);
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_D_COUNT_H, &dayh);
+
+	if (ret) {
+		dev_err(dev, "IO err.\n");
+		return ret;
+	}
+
+	day = (dayl | (dayh << 8));
+	seconds = DATE_TO_SEC(day, hour, minute, second);
+
+	rtc_time_to_tm(seconds, time);
+
+	return rtc_valid_tm(time);
+}
+
+static int hibvt_rtc_set_time(struct device *dev, struct rtc_time *time)
+{
+	struct hibvt_rtc	*rtc = dev_get_drvdata(dev);
+	unsigned char ret = 0;
+	unsigned int days;
+	unsigned long seconds = 0;
+	unsigned int cnt = RETRY_CNT;
+	unsigned char raw_value = 0;
+
+	ret = rtc_tm_to_time(time, &seconds);
+	if (ret)
+		return ret;
+	days = SEC_TO_DAY(seconds);
+
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_LR_10MS, 0);
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_LR_S, time->tm_sec);
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_LR_M, time->tm_min);
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_LR_H, time->tm_hour);
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_LR_D_L, (days & 0xFF));
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_LR_D_H, (days >> 8));
+
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_LORD,
+		(raw_value | REG_LOAD_STAT));
+	/* wait rtc load flag */
+	do {
+		ret |= hibvt_spi_rtc_read(rtc->regs, RTC_LORD, &raw_value);
+		msleep(20);
+	} while ((ret || (raw_value & REG_LOAD_STAT)) && (--cnt));
+
+	if (!ret && (raw_value & REG_LOAD_STAT))
+		return -EBUSY;
+
+	if (ret)
+		dev_err(dev, "IO err.\n");
+
+	return ret;
+}
+
+static int hibvt_rtc_read_alarm(struct device *dev,
+	struct rtc_wkalrm *alrm)
+{
+	struct hibvt_rtc *rtc = dev_get_drvdata(dev);
+	unsigned char dayl, dayh;
+	unsigned char second, minute, hour;
+	unsigned long seconds = 0;
+	unsigned int day;
+	unsigned char int_state = 0;
+	int ret = 0;
+
+	memset(alrm, 0, sizeof(struct rtc_wkalrm));
+
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_MR_S, &second);
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_MR_M, &minute);
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_MR_H, &hour);
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_MR_D_L, &dayl);
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_MR_D_H, &dayh);
+
+	day = (unsigned int)(dayl | (dayh << 8));
+	seconds = DATE_TO_SEC(day, hour, minute, second);
+
+	rtc_time_to_tm(seconds, &alrm->time);
+
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_IMSC, &int_state);
+	if (ret) {
+		dev_err(dev, "IO err.\n");
+		return ret;
+	}
+
+	alrm->enabled = !!(int_state & AIE_INT_MASK);
+	alrm->pending = alrm->enabled;
+
+	return 0;
+}
+
+static int hibvt_rtc_set_alarm(struct device *dev, struct rtc_wkalrm *alrm)
+{
+	struct hibvt_rtc	*rtc = dev_get_drvdata(dev);
+	unsigned int days;
+	unsigned long seconds = 0;
+	unsigned char val = 0;
+	int ret = 0;
+
+	rtc_tm_to_time(&alrm->time, &seconds);
+
+	days = SEC_TO_DAY(seconds);
+
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_MR_10MS, 0);
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_MR_S, alrm->time.tm_sec);
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_MR_M, alrm->time.tm_min);
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_MR_H, alrm->time.tm_hour);
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_MR_D_L, (days & 0xFF));
+	ret |= hibvt_spi_rtc_write(rtc->regs, RTC_MR_D_H, (days >> 8));
+
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_IMSC, &val);
+	if (alrm->enabled)
+		ret |= hibvt_spi_rtc_write(rtc->regs, RTC_IMSC,
+		val | AIE_INT_MASK);
+	else
+		ret |= hibvt_spi_rtc_write(rtc->regs, RTC_IMSC,
+		val & ~AIE_INT_MASK);
+
+	if (ret) {
+		dev_err(dev, "IO err.\n");
+		return ret;
+	}
+
+	return 0;
+}
+
+static int hibvt_rtc_alarm_irq_enable(struct device *dev,
+	unsigned int enabled)
+{
+	struct hibvt_rtc	*rtc = dev_get_drvdata(dev);
+	unsigned char val = 0;
+	int ret = 0;
+
+	ret |= hibvt_spi_rtc_read(rtc->regs, RTC_IMSC, &val);
+	if (enabled)
+		ret |= hibvt_spi_rtc_write(rtc->regs, RTC_IMSC,
+		val | AIE_INT_MASK);
+	else
+		ret |= hibvt_spi_rtc_write(rtc->regs, RTC_IMSC,
+		val & ~AIE_INT_MASK);
+
+	if (ret) {
+		dev_err(dev, "IO err.\n");
+		return ret;
+	}
+
+	return 0;
+}
+
+
+/*
+ * interrupt function
+ * do nothing. left for future
+ */
+static irqreturn_t hibvt_rtc_alm_interrupt(int irq, void *data)
+{
+	struct hibvt_rtc *rtc = (struct hibvt_rtc *)data;
+	unsigned char val = 0;
+	int ret = 0;
+
+	ret |= hibvt_spi_read(rtc->regs, RTC_INT, &val);
+	ret |= hibvt_spi_write(rtc->regs, RTC_INT_CLR, AIE_INT_MASK);
+
+	if (ret) {
+		dev_err(&rtc->rtc_dev->dev, "IO err.\n");
+		return ret;
+	}
+
+	if (val & AIE_INT_MASK)
+		rtc_update_irq(rtc->rtc_dev, 1, RTC_AF | RTC_IRQF);
+
+	return IRQ_HANDLED;
+}
+
+#define FREQ_MAX_VAL	    3277000
+#define FREQ_MIN_VAL	    3276000
+
+static int hibvt_rtc_ioctl(struct device *dev,
+	unsigned int cmd, unsigned long arg)
+{
+	struct hibvt_rtc	*rtc = dev_get_drvdata(dev);
+	int ret = 0;
+
+	switch (cmd) {
+	case RTC_PLL_SET:
+	{
+		char freq_l, freq_h;
+		struct rtc_pll_info pll_info;
+
+		if (copy_from_user(&pll_info, (struct rtc_pll_info *)arg,
+			sizeof(struct rtc_pll_info)))
+			return -EFAULT;
+
+		/* freq = 32700 + (freq /3052)*100 */
+		if (pll_info.pll_value > FREQ_MAX_VAL
+			|| pll_info.pll_value < FREQ_MIN_VAL)
+			return -EINVAL;
+
+		pll_info.pll_value = (pll_info.pll_value - 3270000)
+			* 3052 / 10000;
+
+		freq_l = (char)(pll_info.pll_value & 0xff);
+		freq_h = (char)((pll_info.pll_value >> 8) & 0xf);
+
+		ret |= hibvt_spi_rtc_write(rtc->regs, RTC_FREQ_H, freq_h);
+		ret |= hibvt_spi_rtc_write(rtc->regs, RTC_FREQ_L, freq_l);
+
+		if (ret) {
+			dev_err(dev, "IO err.\n");
+			return ret;
+		}
+
+		return 0;
+	}
+	case RTC_PLL_GET:
+	{
+		char freq_l, freq_h;
+		struct rtc_pll_info pll_info;
+
+		ret |= hibvt_spi_rtc_read(rtc->regs, RTC_FREQ_H, &freq_h);
+		ret |= hibvt_spi_rtc_read(rtc->regs, RTC_FREQ_L, &freq_l);
+
+		if (ret) {
+			dev_err(dev, "IO err.\n");
+			return ret;
+		}
+
+		pll_info.pll_value = ((freq_h & 0xf) << 8) + freq_l;
+		pll_info.pll_value = 3270000
+			+ (pll_info.pll_value * 10000) / 3052;
+
+		pll_info.pll_max = FREQ_MAX_VAL;
+		pll_info.pll_min = FREQ_MIN_VAL;
+
+		if (copy_to_user((void __user *)arg,
+			&pll_info, sizeof(struct rtc_pll_info)))
+			return -EFAULT;
+
+		return 0;
+	}
+	default:
+		return -ENOIOCTLCMD;
+	}
+}
+
+static const struct rtc_class_ops hibvt_rtc_ops = {
+	.read_time		= hibvt_rtc_read_time,
+	.set_time		= hibvt_rtc_set_time,
+	.read_alarm		= hibvt_rtc_read_alarm,
+	.set_alarm		= hibvt_rtc_set_alarm,
+	.alarm_irq_enable	= hibvt_rtc_alarm_irq_enable,
+	.ioctl          = hibvt_rtc_ioctl,
+};
+
+static int hibvt_rtc_init(struct hibvt_rtc *rtc)
+{
+	void *spi_reg = rtc->regs;
+	int ret = 0;
+	unsigned char val = 0;
+	/*
+	 * clk div value = (apb_clk/spi_clk)/2-1,
+	 *	apb clk = 100MHz, spi_clk = 10MHz,so value= 0x4
+	 */
+	writel(CLK_DIV_DEFAULT, (spi_reg+SPI_CLK_DIV));
+
+	ret |= hibvt_spi_rtc_write(spi_reg, RTC_IMSC, INT_MSK_DEFAULT);
+	ret |= hibvt_spi_rtc_write(spi_reg, RTC_SAR_CTRL, LV_CTL_DEFAULT);
+
+   
+	ret |= hibvt_spi_rtc_write(spi_reg, RTC_CLK_CFG, 0x01);
+
+    /* default FREQ COEF */
+	ret |= hibvt_spi_rtc_write(spi_reg, RTC_FREQ_H, FREQ_H_DEFAULT);
+	ret |= hibvt_spi_rtc_write(spi_reg, RTC_FREQ_L, FREQ_L_DEFAULT);
+
+	ret |= hibvt_spi_rtc_read(spi_reg, RTC_INT_RAW, &val);
+    //ret |= hibvt_spi_rtc_read(spi_reg, RTC_CLK_CFG, &val2);
+	if (ret) {
+		dev_err(&rtc->rtc_dev->dev, "IO err.\n");
+		return ret;
+	}
+ 
+	if (val & LV_INT_MASK) {
+		dev_err(&rtc->rtc_dev->dev,
+			"low voltage detected, date/time is not reliable.\n");
+		hibvt_spi_write(rtc->regs, RTC_INT_CLR, 1);
+	}
+
+	return ret;
+}
+
+static int hibvt_rtc_probe(struct platform_device *pdev)
+{
+	struct resource  *mem;
+	struct hibvt_rtc *rtc;
+	int    ret;
+
+	rtc = devm_kzalloc(&pdev->dev, sizeof(*rtc), GFP_KERNEL);
+	if (!rtc)
+		return -ENOMEM;
+
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	rtc->regs = devm_ioremap_resource(&pdev->dev, mem);
+	if (IS_ERR((const void *)rtc->regs)) {
+		dev_err(&pdev->dev, "could not map I/O memory\n");
+		return PTR_ERR((const void *)rtc->regs);
+	}
+
+	rtc->rtc_irq = platform_get_irq(pdev, 0);
+	ret = devm_request_irq(&pdev->dev, rtc->rtc_irq,
+		hibvt_rtc_alm_interrupt, 0, pdev->name, rtc);
+	if (ret) {
+		dev_err(&pdev->dev, "could not request irq %d\n", rtc->rtc_irq);
+		return ret;
+	}
+
+	platform_set_drvdata(pdev, rtc);
+	rtc->rtc_dev = devm_rtc_device_register(&pdev->dev, pdev->name,
+						&hibvt_rtc_ops, THIS_MODULE);
+	if (IS_ERR(rtc->rtc_dev)) {
+		dev_err(&pdev->dev, "could not register rtc device\n");
+		return PTR_ERR(rtc->rtc_dev);
+	}
+
+	if (hibvt_rtc_init(rtc)) {
+		dev_err(&pdev->dev, "hibvt_rtc_init failed.\n");
+		return -EIO;
+	}
+
+	dev_info(&pdev->dev, "RTC driver for hibvt enabled\n");
+
+	return 0;
+}
+
+static int hibvt_rtc_remove(struct platform_device *pdev)
+{
+	return 0;
+}
+
+static const struct of_device_id hibvt_rtc_match[] = {
+	{ .compatible = "hisilicon,hi35xx-rtc" },
+	{},
+};
+
+static struct platform_driver hibvt_rtc_driver = {
+	.probe  = hibvt_rtc_probe,
+	.remove = hibvt_rtc_remove,
+	.driver =  { .name = "hibvt_rtc",
+				.of_match_table = hibvt_rtc_match,
+				},
+};
+
+module_platform_driver(hibvt_rtc_driver);
+
+#define OSDRV_MODULE_VERSION_STRING "HISI_rtc @HiMPP"
+
+MODULE_AUTHOR("Hisilicon");
+MODULE_DESCRIPTION("Hisilicon RTC driver");
+MODULE_LICENSE("GPL v2");
+MODULE_VERSION("HI_VERSION=" OSDRV_MODULE_VERSION_STRING);
+
diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c
index d8099c7..62bb8ad 100644
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@ -1420,7 +1420,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 	if (scsi_host_in_recovery(shost))
 		return 0;
 
-	busy = atomic_inc_return(&shost->host_busy) - 1;
+	busy = atomic_read(&shost->host_busy);
 	if (atomic_read(&shost->host_blocked) > 0) {
 		if (busy)
 			goto starved;
@@ -1429,7 +1429,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 		 * unblock after host_blocked iterates to zero
 		 */
 		if (atomic_dec_return(&shost->host_blocked) > 0)
-			goto out_dec;
+			goto out;
 
 		SCSI_LOG_MLQUEUE(3,
 			shost_printk(KERN_INFO, shost,
@@ -1449,6 +1449,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 		spin_unlock_irq(shost->host_lock);
 	}
 
+	atomic_inc(&shost->host_busy);
 	return 1;
 
 starved:
@@ -1456,8 +1457,7 @@ static inline int scsi_host_queue_ready(struct request_queue *q,
 	if (list_empty(&sdev->starved_entry))
 		list_add_tail(&sdev->starved_entry, &shost->starved_list);
 	spin_unlock_irq(shost->host_lock);
-out_dec:
-	atomic_dec(&shost->host_busy);
+out:
 	return 0;
 }
 
diff --git a/drivers/spi/spi-pl022.c b/drivers/spi/spi-pl022.c
index f7f7ba1..a34db8c 100644
--- a/drivers/spi/spi-pl022.c
+++ b/drivers/spi/spi-pl022.c
@@ -43,6 +43,7 @@
 #include <linux/gpio.h>
 #include <linux/of_gpio.h>
 #include <linux/pinctrl/consumer.h>
+#include <linux/of_address.h>
 
 /*
  * This macro is used to define some register default values.
@@ -137,6 +138,13 @@
 #define SSP_CR1_MASK_FBCLKDEL_ST (0x7UL << 13)
 
 /*
+ * The Hisilicon version of this block adds some bits
+ * in SSP_CR1
+ */
+#define SSP_CR1_MASK_BIGEND_HISI	(0x1UL << 4)
+#define SSP_CR1_MASK_ALTASENS_HISI	(0x1UL << 6)
+
+/*
  * SSP Status Register - SSP_SR
  */
 #define SSP_SR_MASK_TFE		(0x1UL << 0) /* Transmit FIFO empty */
@@ -296,6 +304,8 @@
 
 #define SPI_POLLING_TIMEOUT 1000
 
+#define PL022_IDS_INDEX_HISI		4
+
 /*
  * The type of reading going on on this chip
  */
@@ -337,6 +347,13 @@ struct vendor_data {
 	bool internal_cs_ctrl;
 };
 
+struct cs_data {
+	struct resource		res;
+	void __iomem		*virt_addr;
+	unsigned int		cs_sb;
+	unsigned int		cs_mask_bit;
+};
+
 /**
  * struct pl022 - This is the private SSP driver data structure
  * @adev: AMBA device model hookup
@@ -346,6 +363,13 @@ struct vendor_data {
  * @clk: outgoing clock "SPICLK" for the SPI bus
  * @master: SPI framework hookup
  * @master_info: controller-specific data from machine setup
+ * @kworker: thread struct for message pump
+ * @kworker_task: pointer to task for message pump kworker thread
+ * @pump_messages: work struct for scheduling work to the message pump
+ * @queue_lock: spinlock to syncronise access to message queue
+ * @queue: message queue
+ * @busy: message pump is busy
+ * @running: message pump is running
  * @pump_transfers: Tasklet used in Interrupt Transfer mode
  * @cur_msg: Pointer to current spi_message being processed
  * @cur_transfer: Pointer to current spi_transfer
@@ -403,6 +427,7 @@ struct pl022 {
 #endif
 	int cur_cs;
 	int *chipselects;
+	struct cs_data		*cs_data;
 };
 
 /**
@@ -459,13 +484,37 @@ static void null_cs_control(u32 command)
 static void internal_cs_control(struct pl022 *pl022, u32 command)
 {
 	u32 tmp;
+	struct amba_device *adev = pl022->adev;
+	struct amba_driver *adrv = container_of(adev->dev.driver,
+			struct amba_driver, drv);
+
+	if (pl022->vendor->extended_cr && (adev->periphid ==
+				adrv->id_table[PL022_IDS_INDEX_HISI].id)) {
+		if (pl022->cs_data) {
+			tmp = readl(pl022->cs_data->virt_addr);
+			tmp &= ~(pl022->cs_data->cs_mask_bit);
+			tmp |= ((u32)pl022->cur_cs) << pl022->cs_data->cs_sb;
+			writel(tmp, pl022->cs_data->virt_addr);
+		}
 
-	tmp = readw(SSP_CSR(pl022->virtbase));
-	if (command == SSP_CHIP_SELECT)
-		tmp &= ~BIT(pl022->cur_cs);
-	else
-		tmp |= BIT(pl022->cur_cs);
-	writew(tmp, SSP_CSR(pl022->virtbase));
+		if (command == SSP_CHIP_SELECT)
+			/* Enable SSP */
+			writew((readw(SSP_CR1(pl022->virtbase)) |
+						SSP_CR1_MASK_SSE),
+					SSP_CR1(pl022->virtbase));
+		else
+			/* disable SSP */
+			writew((readw(SSP_CR1(pl022->virtbase)) &
+						(~SSP_CR1_MASK_SSE)),
+					SSP_CR1(pl022->virtbase));
+	} else {
+		tmp = readw(SSP_CSR(pl022->virtbase));
+		if (command == SSP_CHIP_SELECT)
+			tmp &= ~BIT((u32)pl022->cur_cs);
+		else
+			tmp |= BIT((u32)pl022->cur_cs);
+		writew(tmp, SSP_CSR(pl022->virtbase));
+	}
 }
 
 static void pl022_cs_control(struct pl022 *pl022, u32 command)
@@ -566,8 +615,12 @@ static int flush(struct pl022 *pl022)
 static void restore_state(struct pl022 *pl022)
 {
 	struct chip_data *chip = pl022->cur_chip;
+	struct amba_device *adev = pl022->adev;
+	struct amba_driver *adrv = container_of(adev->dev.driver,
+			struct amba_driver, drv);
 
-	if (pl022->vendor->extended_cr)
+	if (pl022->vendor->extended_cr && (adev->periphid !=
+				adrv->id_table[PL022_IDS_INDEX_HISI].id))
 		writel(chip->cr0, SSP_CR0(pl022->virtbase));
 	else
 		writew(chip->cr0, SSP_CR0(pl022->virtbase));
@@ -640,6 +693,13 @@ static void restore_state(struct pl022 *pl022)
 	GEN_MASK_BITS(SSP_FEEDBACK_CLK_DELAY_NONE, SSP_CR1_MASK_FBCLKDEL_ST, 13) \
 )
 
+/* Hisilicon versions extend this register to use all 16 bits */
+#define DEFAULT_SSP_REG_CR1_HISI ( \
+	DEFAULT_SSP_REG_CR1 | \
+	GEN_MASK_BITS(SSP_RX_MSB, SSP_CR1_MASK_BIGEND_HISI, 4) | \
+	GEN_MASK_BITS(0x1, SSP_CR1_MASK_ALTASENS_HISI, 6) \
+)
+
 #define DEFAULT_SSP_REG_CPSR ( \
 	GEN_MASK_BITS(SSP_DEFAULT_PRESCALE, SSP_CPSR_MASK_CPSDVSR, 0) \
 )
@@ -655,12 +715,24 @@ static void restore_state(struct pl022 *pl022)
  */
 static void load_ssp_default_config(struct pl022 *pl022)
 {
+	struct amba_device *adev = pl022->adev;
+	struct amba_driver *adrv = container_of(adev->dev.driver,
+			struct amba_driver, drv);
+
 	if (pl022->vendor->pl023) {
 		writel(DEFAULT_SSP_REG_CR0_ST_PL023, SSP_CR0(pl022->virtbase));
 		writew(DEFAULT_SSP_REG_CR1_ST_PL023, SSP_CR1(pl022->virtbase));
 	} else if (pl022->vendor->extended_cr) {
-		writel(DEFAULT_SSP_REG_CR0_ST, SSP_CR0(pl022->virtbase));
-		writew(DEFAULT_SSP_REG_CR1_ST, SSP_CR1(pl022->virtbase));
+		if (adev->periphid == adrv->id_table[PL022_IDS_INDEX_HISI].id) {
+			writew(DEFAULT_SSP_REG_CR0, SSP_CR0(pl022->virtbase));
+			writew(DEFAULT_SSP_REG_CR1_HISI,
+					SSP_CR1(pl022->virtbase));
+		} else {
+			writel(DEFAULT_SSP_REG_CR0_ST,
+					SSP_CR0(pl022->virtbase));
+			writew(DEFAULT_SSP_REG_CR1_ST,
+					SSP_CR1(pl022->virtbase));
+		}
 	} else {
 		writew(DEFAULT_SSP_REG_CR0, SSP_CR0(pl022->virtbase));
 		writew(DEFAULT_SSP_REG_CR1, SSP_CR1(pl022->virtbase));
@@ -1835,6 +1907,10 @@ static int pl022_setup(struct spi_device *spi)
 	unsigned int bits = spi->bits_per_word;
 	u32 tmp;
 	struct device_node *np = spi->dev.of_node;
+	struct amba_device *adev = pl022->adev;
+	struct amba_driver *adrv = container_of(adev->dev.driver,
+			struct amba_driver, drv);
+
 
 	if (!spi->max_speed_hz)
 		return -EINVAL;
@@ -1977,7 +2053,8 @@ static int pl022_setup(struct spi_device *spi)
 	chip->cpsr = clk_freq.cpsdvsr;
 
 	/* Special setup for the ST micro extended control registers */
-	if (pl022->vendor->extended_cr) {
+	if (pl022->vendor->extended_cr && (adev->periphid !=
+				adrv->id_table[PL022_IDS_INDEX_HISI].id)) {
 		u32 etx;
 
 		if (pl022->vendor->pl023) {
@@ -2011,6 +2088,20 @@ static int pl022_setup(struct spi_device *spi)
 			       SSP_CR1_MASK_RXIFLSEL_ST, 7);
 		SSP_WRITE_BITS(chip->cr1, chip_info->tx_lev_trig,
 			       SSP_CR1_MASK_TXIFLSEL_ST, 10);
+	} else if (pl022->vendor->extended_cr && (adev->periphid ==
+				adrv->id_table[PL022_IDS_INDEX_HISI].id)) {
+		SSP_WRITE_BITS(chip->cr0, bits - 1,
+			       SSP_CR0_MASK_DSS, 0);
+		SSP_WRITE_BITS(chip->cr0, chip_info->iface,
+			       SSP_CR0_MASK_FRF, 4);
+
+		if (spi->mode & SPI_LSB_FIRST)
+			tmp = !!SPI_LSB_FIRST;
+		else
+			tmp = !SPI_LSB_FIRST;
+
+		SSP_WRITE_BITS(chip->cr1, tmp, SSP_CR1_MASK_BIGEND_HISI, 4);
+		SSP_WRITE_BITS(chip->cr1, 0x1, SSP_CR1_MASK_ALTASENS_HISI, 6);
 	} else {
 		SSP_WRITE_BITS(chip->cr0, bits - 1,
 			       SSP_CR0_MASK_DSS, 0);
@@ -2042,7 +2133,7 @@ static int pl022_setup(struct spi_device *spi)
 	}
 	SSP_WRITE_BITS(chip->cr1, SSP_DISABLED, SSP_CR1_MASK_SSE, 1);
 	SSP_WRITE_BITS(chip->cr1, chip_info->hierarchy, SSP_CR1_MASK_MS, 2);
-	SSP_WRITE_BITS(chip->cr1, chip_info->slave_tx_disable, SSP_CR1_MASK_SOD,
+	SSP_WRITE_BITS(chip->cr1, (unsigned int)chip_info->slave_tx_disable, SSP_CR1_MASK_SOD,
 		3);
 
 	/* Save controller_state */
@@ -2074,7 +2165,7 @@ pl022_platform_data_dt_get(struct device *dev)
 {
 	struct device_node *np = dev->of_node;
 	struct pl022_ssp_controller *pd;
-	u32 tmp;
+	u32 tmp = 0;
 
 	if (!np) {
 		dev_err(dev, "no dt node defined\n");
@@ -2099,6 +2190,8 @@ pl022_platform_data_dt_get(struct device *dev)
 static int pl022_probe(struct amba_device *adev, const struct amba_id *id)
 {
 	struct device *dev = &adev->dev;
+	struct amba_driver *adrv = container_of(adev->dev.driver,
+			struct amba_driver, drv);
 	struct pl022_ssp_controller *platform_info =
 			dev_get_platdata(&adev->dev);
 	struct spi_master *master;
@@ -2162,6 +2255,41 @@ static int pl022_probe(struct amba_device *adev, const struct amba_id *id)
 	} else if (pl022->vendor->internal_cs_ctrl) {
 		for (i = 0; i < num_cs; i++)
 			pl022->chipselects[i] = i;
+
+		if ((adev->periphid == adrv->id_table[PL022_IDS_INDEX_HISI].id)
+				&& pl022->vendor->extended_cr
+				&& (num_cs > 1)) {
+			pl022->cs_data = devm_kzalloc(dev,
+					sizeof(struct cs_data),
+					GFP_KERNEL);
+			if (!pl022->cs_data) {
+				status = -ENOMEM;
+				goto err_no_mem;
+			}
+
+			if (of_address_to_resource(np, 1,
+						&pl022->cs_data->res)) {
+				status = -EPROBE_DEFER;
+				goto err_no_gpio;
+			}
+
+			if (of_property_read_u32(np, "hisi,spi_cs_sb",
+						&pl022->cs_data->cs_sb)) {
+				status = -EPROBE_DEFER;
+				goto err_no_gpio;
+			}
+
+			if (of_property_read_u32(np, "hisi,spi_cs_mask_bit",
+						&pl022->cs_data->cs_mask_bit)) {
+				status = -EPROBE_DEFER;
+				goto err_no_gpio;
+			}
+
+			pl022->cs_data->virt_addr = devm_ioremap(dev,
+					pl022->cs_data->res.start,
+					resource_size(&adev->res));
+		} else
+				pl022->cs_data = NULL;
 	} else if (IS_ENABLED(CONFIG_OF)) {
 		for (i = 0; i < num_cs; i++) {
 			int cs_gpio = of_get_named_gpio(np, "cs-gpios", i);
@@ -2288,6 +2416,10 @@ static int pl022_probe(struct amba_device *adev, const struct amba_id *id)
  err_no_ioremap:
 	amba_release_regions(adev);
  err_no_ioregion:
+	if (pl022->cs_data)
+		release_mem_region(pl022->cs_data->res.start,
+				resource_size(&pl022->cs_data->res));
+
  err_no_gpio:
  err_no_mem:
 	spi_master_put(master);
@@ -2314,6 +2446,10 @@ pl022_remove(struct amba_device *adev)
 
 	clk_disable_unprepare(pl022->clk);
 	amba_release_regions(adev);
+	if (pl022->cs_data)
+		release_mem_region(pl022->cs_data->res.start,
+				resource_size(&pl022->cs_data->res));
+
 	tasklet_disable(&pl022->pump_transfers);
 	return 0;
 }
@@ -2429,6 +2565,16 @@ static struct vendor_data vendor_lsi = {
 	.internal_cs_ctrl = true,
 };
 
+static struct vendor_data vendor_hisi = {
+	.fifodepth = 256,
+	.max_bpw = 16,
+	.unidir = false,
+	.extended_cr = true,
+	.pl023 = false,
+	.loopback = true,
+	.internal_cs_ctrl = true,
+};
+
 static struct amba_id pl022_ids[] = {
 	{
 		/*
@@ -2469,6 +2615,15 @@ static struct amba_id pl022_ids[] = {
 		.mask	= 0x000fffff,
 		.data	= &vendor_lsi,
 	},
+	{
+		/*
+		 * Hisilicon derivative, this has a 16bit wide
+		 * and 256 locations deep TX/RX FIFO
+		 */
+		.id	= 0x00800022,
+		.mask	= 0xffffffff,
+		.data	= &vendor_hisi,
+	},
 	{ 0, 0 },
 };
 
diff --git a/drivers/spi/spi.c b/drivers/spi/spi.c
index 6db8063..ce94584 100644
--- a/drivers/spi/spi.c
+++ b/drivers/spi/spi.c
@@ -323,11 +323,125 @@ static int spi_uevent(struct device *dev, struct kobj_uevent_env *env)
 	return 0;
 }
 
+#ifdef CONFIG_PM_SLEEP
+static int spi_legacy_suspend(struct device *dev, pm_message_t message)
+{
+	int			value = 0;
+	struct spi_driver	*drv = to_spi_driver(dev->driver);
+
+	/* suspend will stop irqs and dma; no more i/o */
+	if (drv) {
+		if (drv->suspend)
+			value = drv->suspend(to_spi_device(dev), message);
+		else
+			dev_dbg(dev, "... can't suspend\n");
+	}
+	return value;
+}
+
+static int spi_legacy_resume(struct device *dev)
+{
+	int			value = 0;
+	struct spi_driver	*drv = to_spi_driver(dev->driver);
+
+	/* resume may restart the i/o queue */
+	if (drv) {
+		if (drv->resume)
+			value = drv->resume(to_spi_device(dev));
+		else
+			dev_dbg(dev, "... can't resume\n");
+	}
+	return value;
+}
+
+static int spi_pm_suspend(struct device *dev)
+{
+	const struct dev_pm_ops *pm = dev->driver ? dev->driver->pm : NULL;
+
+	if (pm)
+		return pm_generic_suspend(dev);
+	else
+		return spi_legacy_suspend(dev, PMSG_SUSPEND);
+}
+
+static int spi_pm_resume(struct device *dev)
+{
+	const struct dev_pm_ops *pm = dev->driver ? dev->driver->pm : NULL;
+
+	if (pm)
+		return pm_generic_resume(dev);
+	else
+		return spi_legacy_resume(dev);
+}
+
+static int spi_pm_freeze(struct device *dev)
+{
+	const struct dev_pm_ops *pm = dev->driver ? dev->driver->pm : NULL;
+
+	if (pm)
+		return pm_generic_freeze(dev);
+	else
+		return spi_legacy_suspend(dev, PMSG_FREEZE);
+}
+
+static int spi_pm_thaw(struct device *dev)
+{
+	const struct dev_pm_ops *pm = dev->driver ? dev->driver->pm : NULL;
+
+	if (pm)
+		return pm_generic_thaw(dev);
+	else
+		return spi_legacy_resume(dev);
+}
+
+static int spi_pm_poweroff(struct device *dev)
+{
+	const struct dev_pm_ops *pm = dev->driver ? dev->driver->pm : NULL;
+
+	if (pm)
+		return pm_generic_poweroff(dev);
+	else
+		return spi_legacy_suspend(dev, PMSG_HIBERNATE);
+}
+
+static int spi_pm_restore(struct device *dev)
+{
+	const struct dev_pm_ops *pm = dev->driver ? dev->driver->pm : NULL;
+
+	if (pm)
+		return pm_generic_restore(dev);
+	else
+		return spi_legacy_resume(dev);
+}
+#else
+#define spi_pm_suspend	NULL
+#define spi_pm_resume	NULL
+#define spi_pm_freeze	NULL
+#define spi_pm_thaw	NULL
+#define spi_pm_poweroff	NULL
+#define spi_pm_restore	NULL
+#endif
+
+static const struct dev_pm_ops spi_pm = {
+	.suspend = spi_pm_suspend,
+	.resume = spi_pm_resume,
+	.freeze = spi_pm_freeze,
+	.thaw = spi_pm_thaw,
+	.poweroff = spi_pm_poweroff,
+	.restore = spi_pm_restore,
+	SET_RUNTIME_PM_OPS(
+		pm_generic_runtime_suspend,
+		pm_generic_runtime_resume,
+		NULL
+	)
+};
+
 struct bus_type spi_bus_type = {
 	.name		= "spi",
 	.dev_groups	= spi_dev_groups,
 	.match		= spi_match_device,
 	.uevent		= spi_uevent,
+	.pm		= &spi_pm,
 };
 EXPORT_SYMBOL_GPL(spi_bus_type);
 
diff --git a/drivers/usb/gadget/composite.c b/drivers/usb/gadget/composite.c
index baa7cdc..00a2776 100644
--- a/drivers/usb/gadget/composite.c
+++ b/drivers/usb/gadget/composite.c
@@ -24,6 +24,13 @@
 
 #include "u_os_desc.h"
 
+#if CONFIG_ARCH_HI3516A
+#define USB2_BASE_REG           0x20120000
+#define DWC_OTG_EN              (1 << 31)
+#define USB2_PHY_DPPULL_DOWN    (0x3 << 26)
+#define USB2_OTG_BASE           0x78
+#endif
+
 /**
  * struct usb_os_string - represents OS String to be reported by a gadget
  * @bLength: total length of the entire descritor, always 0x12
@@ -2189,6 +2196,11 @@ static int composite_bind(struct usb_gadget *gadget,
 	struct usb_composite_driver	*composite = to_cdriver(gdriver);
 	int				status = -ENOMEM;
 
+#ifdef CONFIG_ARCH_HI3516A
+	void __iomem *usb2_base_reg = ioremap_nocache(USB2_BASE_REG, 0x1000);
+        int usb2_reg;
+#endif
+
 	cdev = kzalloc(sizeof *cdev, GFP_KERNEL);
 	if (!cdev)
 		return status;
@@ -2223,6 +2235,13 @@ static int composite_bind(struct usb_gadget *gadget,
 	if (composite->needs_serial && !cdev->desc.iSerialNumber)
 		WARNING(cdev, "userspace failed to provide iSerialNumber\n");
 
+#ifdef CONFIG_ARCH_HI3516A
+        usb2_reg = readl(usb2_base_reg + USB2_OTG_BASE);
+        usb2_reg &= ~(USB2_PHY_DPPULL_DOWN);
+        usb2_reg |= DWC_OTG_EN;
+        writel(usb2_reg, usb2_base_reg + USB2_OTG_BASE);
+        iounmap(usb2_base_reg);
+#endif
 	INFO(cdev, "%s ready\n", composite->name);
 	return 0;
 
@@ -2347,6 +2366,16 @@ EXPORT_SYMBOL_GPL(usb_composite_probe);
  */
 void usb_composite_unregister(struct usb_composite_driver *driver)
 {
+#if CONFIG_ARCH_HI3516A
+        void __iomem *usb2_base_reg = ioremap_nocache(USB2_BASE_REG, 0x1000);
+        int usb2_reg;
+
+        usb2_reg = readl(usb2_base_reg + USB2_OTG_BASE);
+        usb2_reg |= USB2_PHY_DPPULL_DOWN;
+        usb2_reg &= ~DWC_OTG_EN;
+        writel(usb2_reg, usb2_base_reg + USB2_OTG_BASE);
+        iounmap(usb2_base_reg);
+#endif
 	usb_gadget_unregister_driver(&driver->gadget_driver);
 }
 EXPORT_SYMBOL_GPL(usb_composite_unregister);
diff --git a/drivers/usb/gadget/function/f_mass_storage.c b/drivers/usb/gadget/function/f_mass_storage.c
index ccd93c9..64d9728 100644
--- a/drivers/usb/gadget/function/f_mass_storage.c
+++ b/drivers/usb/gadget/function/f_mass_storage.c
@@ -253,6 +253,7 @@ static struct usb_gadget_strings *fsg_strings_array[] = {
 
 struct fsg_dev;
 struct fsg_common;
+extern void hisi_switch_func(int otg);
 
 /* Data shared by all the FSG instances. */
 struct fsg_common {
@@ -1954,6 +1955,9 @@ static int do_scsi_command(struct fsg_common *common)
 				      "READ CAPACITY");
 		if (reply == 0)
 			reply = do_read_capacity(common, bh);
+
+		hisi_switch_func(1);
+
 		break;
 
 	case READ_HEADER:
@@ -1997,6 +2001,9 @@ static int do_scsi_command(struct fsg_common *common)
 				      "REQUEST SENSE");
 		if (reply == 0)
 			reply = do_request_sense(common, bh);
+
+		hisi_switch_func(1);
+
 		break;
 
 	case START_STOP:
diff --git a/drivers/usb/gadget/udc/Kconfig b/drivers/usb/gadget/udc/Kconfig
index 658b8da..66c7431 100644
--- a/drivers/usb/gadget/udc/Kconfig
+++ b/drivers/usb/gadget/udc/Kconfig
@@ -232,6 +232,26 @@ config USB_MV_UDC
 	  USB2.0 OTG controller, which can be configured as high speed or
 	  full speed USB peripheral.
 
+menuconfig HIUSB_DEVICE2_0
+          bool "Hisilicon USB2.0 Device Controller SUPPORT"
+          help
+          This selects the usb(ehci/ohci) family usb device.
+          Say Y to enable hisi usb2.0 controller driver.
+          IF you do not use usb2.0 device in your board,
+          say N to get a smaller uImage. Mostly you need it.
+
+if HIUSB_DEVICE2_0
+          config USB_HISI_UDC
+          tristate "hisilicon highspeed device controller version 3.00a driver"
+          help
+          You can select device mode by the option.
+          Enable hisi ehci controller driver.
+          Say Y to enable hisi usb2.0 ehci controller driver.
+          IF you do not use usb2.0 ehci device in your board, say N to get a
+          smaller uImage. Mostly you need it.
+
+endif
+
 config USB_MV_U3D
 	depends on HAS_DMA
 	tristate "MARVELL PXA2128 USB 3.0 controller"
diff --git a/drivers/usb/gadget/udc/Makefile b/drivers/usb/gadget/udc/Makefile
index 98e74ed..ecd9036 100644
--- a/drivers/usb/gadget/udc/Makefile
+++ b/drivers/usb/gadget/udc/Makefile
@@ -1,8 +1,10 @@
 # define_trace.h needs to know how to find our header
 CFLAGS_trace.o			:= -I$(src)
+#ifndef CONFIG_USB_HISI_UDC
 
 udc-core-y			:= core.o trace.o
 
+#endif
 #
 # USB peripheral controller drivers
 #
@@ -37,3 +39,4 @@ obj-$(CONFIG_USB_MV_U3D)	+= mv_u3d_core.o
 obj-$(CONFIG_USB_GR_UDC)	+= gr_udc.o
 obj-$(CONFIG_USB_GADGET_XILINX)	+= udc-xilinx.o
 obj-$(CONFIG_USB_BDC_UDC)	+= bdc/
+obj-$(CONFIG_USB_HISI_UDC)      += hiudc/
diff --git a/drivers/usb/gadget/udc/core.c b/drivers/usb/gadget/udc/core.c
index d685d82..a849216 100644
--- a/drivers/usb/gadget/udc/core.c
+++ b/drivers/usb/gadget/udc/core.c
@@ -904,11 +904,6 @@ int usb_gadget_ep_match_desc(struct usb_gadget *gadget,
 	type = usb_endpoint_type(desc);
 	max = 0x7ff & usb_endpoint_maxp(desc);
 
-	if (usb_endpoint_dir_in(desc) && !ep->caps.dir_in)
-		return 0;
-	if (usb_endpoint_dir_out(desc) && !ep->caps.dir_out)
-		return 0;
-
 	if (max > ep->maxpacket_limit)
 		return 0;
 
@@ -928,8 +923,6 @@ int usb_gadget_ep_match_desc(struct usb_gadget *gadget,
 			return 0;
 		break;
 	case USB_ENDPOINT_XFER_BULK:
-		if (!ep->caps.type_bulk)
-			return 0;
 		if (ep_comp && gadget_is_superspeed(gadget)) {
 			/* Get the number of required streams from the
 			 * EP companion descriptor and see if the EP
@@ -966,15 +959,6 @@ static void usb_gadget_state_work(struct work_struct *work)
 	if (udc)
 		sysfs_notify(&udc->dev.kobj, NULL, "state");
 }
-
-void usb_gadget_set_state(struct usb_gadget *gadget,
-		enum usb_device_state state)
-{
-	gadget->state = state;
-	schedule_work(&gadget->work);
-}
-EXPORT_SYMBOL_GPL(usb_gadget_set_state);
-
 /* ------------------------------------------------------------------------- */
 
 static void usb_udc_connect_control(struct usb_udc *udc)
@@ -985,6 +969,24 @@ static void usb_udc_connect_control(struct usb_udc *udc)
 		usb_gadget_disconnect(udc->gadget);
 }
 
+/* should be called with udc_lock held */
+static int check_pending_gadget_drivers(struct usb_udc *udc)
+{
+       struct usb_gadget_driver *driver;
+       int ret = 0;
+
+       list_for_each_entry(driver, &gadget_driver_pending_list, pending)
+               if (!driver->udc_name || strcmp(driver->udc_name,
+                                               dev_name(&udc->dev)) == 0) {
+                       ret = udc_bind_to_driver(udc, driver);
+                       if (ret != -EPROBE_DEFER)
+                               list_del(&driver->pending);
+                       break;
+               }
+
+       return ret;
+}
+
 /**
  * usb_udc_vbus_handler - updates the udc core vbus status, and try to
  * connect or disconnect gadget
@@ -1005,6 +1007,15 @@ void usb_udc_vbus_handler(struct usb_gadget *gadget, bool status)
 }
 EXPORT_SYMBOL_GPL(usb_udc_vbus_handler);
 
+/* ------------------------------------------------------------------------- */
+void usb_gadget_set_state(struct usb_gadget *gadget,
+                enum usb_device_state state)
+{
+        gadget->state = state;
+}
+EXPORT_SYMBOL_GPL(usb_gadget_set_state);
+/* ------------------------------------------------------------------------- */
+
 /**
  * usb_gadget_udc_reset - notifies the udc core that bus reset occurs
  * @gadget: The gadget which bus reset occurs
@@ -1080,24 +1091,6 @@ static void usb_udc_nop_release(struct device *dev)
 	dev_vdbg(dev, "%s\n", __func__);
 }
 
-/* should be called with udc_lock held */
-static int check_pending_gadget_drivers(struct usb_udc *udc)
-{
-	struct usb_gadget_driver *driver;
-	int ret = 0;
-
-	list_for_each_entry(driver, &gadget_driver_pending_list, pending)
-		if (!driver->udc_name || strcmp(driver->udc_name,
-						dev_name(&udc->dev)) == 0) {
-			ret = udc_bind_to_driver(udc, driver);
-			if (ret != -EPROBE_DEFER)
-				list_del(&driver->pending);
-			break;
-		}
-
-	return ret;
-}
-
 /**
  * usb_add_gadget_udc_release - adds a new gadget to the udc class driver list
  * @parent: the parent device to this udc. Usually the controller driver's
@@ -1310,87 +1303,6 @@ static int udc_bind_to_driver(struct usb_udc *udc, struct usb_gadget_driver *dri
 	udc->gadget->dev.driver = NULL;
 	return ret;
 }
-
-int usb_gadget_probe_driver(struct usb_gadget_driver *driver)
-{
-	struct usb_udc		*udc = NULL;
-	int			ret = -ENODEV;
-
-	if (!driver || !driver->bind || !driver->setup)
-		return -EINVAL;
-
-	mutex_lock(&udc_lock);
-	if (driver->udc_name) {
-		list_for_each_entry(udc, &udc_list, list) {
-			ret = strcmp(driver->udc_name, dev_name(&udc->dev));
-			if (!ret)
-				break;
-		}
-		if (ret)
-			ret = -ENODEV;
-		else if (udc->driver)
-			ret = -EBUSY;
-		else
-			goto found;
-	} else {
-		list_for_each_entry(udc, &udc_list, list) {
-			/* For now we take the first one */
-			if (!udc->driver)
-				goto found;
-		}
-	}
-
-	if (!driver->match_existing_only) {
-		list_add_tail(&driver->pending, &gadget_driver_pending_list);
-		pr_info("udc-core: couldn't find an available UDC - added [%s] to list of pending drivers\n",
-			driver->function);
-		ret = 0;
-	}
-
-	mutex_unlock(&udc_lock);
-	return ret;
-found:
-	ret = udc_bind_to_driver(udc, driver);
-	mutex_unlock(&udc_lock);
-	return ret;
-}
-EXPORT_SYMBOL_GPL(usb_gadget_probe_driver);
-
-int usb_gadget_unregister_driver(struct usb_gadget_driver *driver)
-{
-	struct usb_udc		*udc = NULL;
-	int			ret = -ENODEV;
-
-	if (!driver || !driver->unbind)
-		return -EINVAL;
-
-	mutex_lock(&udc_lock);
-	list_for_each_entry(udc, &udc_list, list) {
-		if (udc->driver == driver) {
-			usb_gadget_remove_driver(udc);
-			usb_gadget_set_state(udc->gadget,
-					     USB_STATE_NOTATTACHED);
-
-			/* Maybe there is someone waiting for this UDC? */
-			check_pending_gadget_drivers(udc);
-			/*
-			 * For now we ignore bind errors as probably it's
-			 * not a valid reason to fail other's gadget unbind
-			 */
-			ret = 0;
-			break;
-		}
-	}
-
-	if (ret) {
-		list_del(&driver->pending);
-		ret = 0;
-	}
-	mutex_unlock(&udc_lock);
-	return ret;
-}
-EXPORT_SYMBOL_GPL(usb_gadget_unregister_driver);
-
 /* ------------------------------------------------------------------------- */
 
 static ssize_t usb_udc_srp_store(struct device *dev,
diff --git a/drivers/usb/gadget/udc/hiudc/Makefile b/drivers/usb/gadget/udc/hiudc/Makefile
new file mode 100644
index 0000000..28dd23c
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/Makefile
@@ -0,0 +1,21 @@
+#
+# USB peripheral controller drivers
+#
+# Use the BUS_INTERFACE variable to compile the software for either
+# PCI(PCI_INTERFACE) or LM(LM_INTERFACE) bus.
+# Use one of the following flags to compile the software in host-only or
+# device-only mode.
+EXTRA_CFLAGS        += -DDWC_DEVICE_ONLY
+EXTRA_CFLAGS		+= -DDWC_LINUX
+EXTRA_CFLAGS		+= -DLM_INTERFACE
+
+obj-$(CONFIG_USB_HISI_UDC)      += udc-hisi.o
+#obj-y	+= udc-hisi.o
+udc-hisi-objs	:= dwc_otg_driver.o dwc_otg_attr.o
+udc-hisi-objs	+= dwc_otg_cil.o dwc_otg_cil_intr.o
+udc-hisi-objs	+= dwc_otg_pcd_linux.o dwc_otg_pcd.o dwc_otg_pcd_intr.o
+udc-hisi-objs	+= dwc_otg_hcd.o dwc_otg_hcd_linux.o dwc_otg_hcd_intr.o dwc_otg_hcd_queue.o dwc_otg_hcd_ddma.o
+udc-hisi-objs	+= dwc_otg_adp.o
+udc-hisi-objs	+= dwc_cc.o dwc_modpow.o dwc_dh.o \
+			    dwc_crypto.o dwc_notifier.o \
+			    dwc_common_linux.o dwc_mem.o
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_cc.c b/drivers/usb/gadget/udc/hiudc/dwc_cc.c
new file mode 100644
index 0000000..a757f4f
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_cc.c
@@ -0,0 +1,532 @@
+/* =========================================================================
+ * $File: //dwh/usb_iip/dev/software/dwc_common_port_2/dwc_cc.c $
+ * $Revision: #4 $
+ * $Date: 2010/11/04 $
+ * $Change: 1621692 $
+ *
+ * Synopsys Portability Library Software and documentation
+ * (hereinafter, "Software") is an Unsupported proprietary work of
+ * Synopsys, Inc. unless otherwise expressly agreed to in writing
+ * between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product
+ * under any End User Software License Agreement or Agreement for
+ * Licensed Product with Synopsys or any supplement thereto. You are
+ * permitted to use and redistribute this Software in source and binary
+ * forms, with or without modification, provided that redistributions
+ * of source code must retain this notice. You may not view, use,
+ * disclose, copy or distribute this file or any information contained
+ * herein except pursuant to this license grant from Synopsys. If you
+ * do not agree with this notice, including the disclaimer below, then
+ * you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS"
+ * BASIS AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+ * FOR A PARTICULAR PURPOSE ARE HEREBY DISCLAIMED. IN NO EVENT SHALL
+ * SYNOPSYS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ * USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================= */
+#ifdef DWC_CCLIB
+
+#include "dwc_cc.h"
+
+typedef struct dwc_cc
+{
+	uint32_t uid;
+	uint8_t chid[16];
+	uint8_t cdid[16];
+	uint8_t ck[16];
+	uint8_t *name;
+	uint8_t length;
+        DWC_CIRCLEQ_ENTRY(dwc_cc) list_entry;
+} dwc_cc_t;
+
+DWC_CIRCLEQ_HEAD(context_list, dwc_cc);
+
+/** The main structure for CC management.  */
+struct dwc_cc_if
+{
+	dwc_mutex_t *mutex;
+	char *filename;
+
+	unsigned is_host:1;
+
+	dwc_notifier_t *notifier;
+
+	struct context_list list;
+};
+
+#ifdef DEBUG
+static inline void dump_bytes(char *name, uint8_t *bytes, int len)
+{
+	int i;
+	DWC_PRINTF("%s: ", name);
+	for (i=0; i<len; i++) {
+		DWC_PRINTF("%02x ", bytes[i]);
+	}
+	DWC_PRINTF("\n");
+}
+#else
+#define dump_bytes(x...)
+#endif
+
+static dwc_cc_t *alloc_cc(void *mem_ctx, uint8_t *name, uint32_t length)
+{
+	dwc_cc_t *cc = dwc_alloc(mem_ctx, sizeof(dwc_cc_t));
+	if (!cc) {
+		return NULL;
+	}
+	DWC_MEMSET(cc, 0, sizeof(dwc_cc_t));
+
+	if (name) {
+		cc->length = length;
+		cc->name = dwc_alloc(mem_ctx, length);
+		if (!cc->name) {
+			dwc_free(mem_ctx, cc);
+			return NULL;
+		}
+
+		DWC_MEMCPY(cc->name, name, length);
+	}
+
+	return cc;
+}
+
+static void free_cc(void *mem_ctx, dwc_cc_t *cc)
+{
+	if (cc->name) {
+		dwc_free(mem_ctx, cc->name);
+	}
+	dwc_free(mem_ctx, cc);
+}
+
+static uint32_t next_uid(dwc_cc_if_t *cc_if)
+{
+	uint32_t uid = 0;
+	dwc_cc_t *cc;
+	DWC_CIRCLEQ_FOREACH(cc, &cc_if->list, list_entry) {
+		if (cc->uid > uid) {
+			uid = cc->uid;
+		}
+	}
+
+	if (uid == 0) {
+		uid = 255;
+	}
+
+	return uid + 1;
+}
+
+static dwc_cc_t *cc_find(dwc_cc_if_t *cc_if, uint32_t uid)
+{
+	dwc_cc_t *cc;
+	DWC_CIRCLEQ_FOREACH(cc, &cc_if->list, list_entry) {
+		if (cc->uid == uid) {
+			return cc;
+		}
+	}
+	return NULL;
+}
+
+static unsigned int cc_data_size(dwc_cc_if_t *cc_if)
+{
+	unsigned int size = 0;
+	dwc_cc_t *cc;
+	DWC_CIRCLEQ_FOREACH(cc, &cc_if->list, list_entry) {
+		size += (48 + 1);
+		if (cc->name) {
+			size += cc->length;
+		}
+	}
+	return size;
+}
+
+static uint32_t cc_match_chid(dwc_cc_if_t *cc_if, uint8_t *chid)
+{
+	uint32_t uid = 0;
+	dwc_cc_t *cc;
+
+	DWC_CIRCLEQ_FOREACH(cc, &cc_if->list, list_entry) {
+		if (DWC_MEMCMP(cc->chid, chid, 16) == 0) {
+			uid = cc->uid;
+			break;
+		}
+	}
+	return uid;
+}
+static uint32_t cc_match_cdid(dwc_cc_if_t *cc_if, uint8_t *cdid)
+{
+	uint32_t uid = 0;
+	dwc_cc_t *cc;
+
+	DWC_CIRCLEQ_FOREACH(cc, &cc_if->list, list_entry) {
+		if (DWC_MEMCMP(cc->cdid, cdid, 16) == 0) {
+			uid = cc->uid;
+			break;
+		}
+	}
+	return uid;
+}
+
+/* Internal cc_add */
+static int32_t cc_add(void *mem_ctx, dwc_cc_if_t *cc_if, uint8_t *chid,
+		      uint8_t *cdid, uint8_t *ck, uint8_t *name, uint8_t length)
+{
+	dwc_cc_t *cc;
+	uint32_t uid;
+
+	if (cc_if->is_host) {
+		uid = cc_match_cdid(cc_if, cdid);
+	}
+	else {
+		uid = cc_match_chid(cc_if, chid);
+	}
+
+	if (uid) {
+		DWC_DEBUG("Replacing previous connection context id=%d name=%p name_len=%d", uid, name, length);
+		cc = cc_find(cc_if, uid);
+	}
+	else {
+		cc = alloc_cc(mem_ctx, name, length);
+		cc->uid = next_uid(cc_if);
+		DWC_CIRCLEQ_INSERT_TAIL(&cc_if->list, cc, list_entry);
+	}
+
+	DWC_MEMCPY(&(cc->chid[0]), chid, 16);
+	DWC_MEMCPY(&(cc->cdid[0]), cdid, 16);
+	DWC_MEMCPY(&(cc->ck[0]), ck, 16);
+
+	DWC_DEBUG("Added connection context id=%d name=%p name_len=%d", cc->uid, name, length);
+	dump_bytes("CHID", cc->chid, 16);
+	dump_bytes("CDID", cc->cdid, 16);
+	dump_bytes("CK", cc->ck, 16);
+	return cc->uid;
+}
+
+/* Internal cc_clear */
+static void cc_clear(void *mem_ctx, dwc_cc_if_t *cc_if)
+{
+	while (!DWC_CIRCLEQ_EMPTY(&cc_if->list)) {
+		dwc_cc_t *cc = DWC_CIRCLEQ_FIRST(&cc_if->list);
+		DWC_CIRCLEQ_REMOVE_INIT(&cc_if->list, cc, list_entry);
+		free_cc(mem_ctx, cc);
+	}
+}
+
+dwc_cc_if_t *dwc_cc_if_alloc(void *mem_ctx, void *mtx_ctx,
+			     dwc_notifier_t *notifier, unsigned is_host)
+{
+	dwc_cc_if_t *cc_if = NULL;
+
+	/* Allocate a common_cc_if structure */
+	cc_if = dwc_alloc(mem_ctx, sizeof(dwc_cc_if_t));
+
+	if (!cc_if)
+		return NULL;
+
+#if (defined(DWC_LINUX) && defined(CONFIG_DEBUG_MUTEXES))
+	DWC_MUTEX_ALLOC_LINUX_DEBUG(cc_if->mutex);
+#else
+	cc_if->mutex = dwc_mutex_alloc(mtx_ctx);
+#endif
+	if (!cc_if->mutex) {
+		dwc_free(mem_ctx, cc_if);
+		return NULL;
+	}
+
+	DWC_CIRCLEQ_INIT(&cc_if->list);
+	cc_if->is_host = is_host;
+	cc_if->notifier = notifier;
+	return cc_if;
+}
+
+void dwc_cc_if_free(void *mem_ctx, void *mtx_ctx, dwc_cc_if_t *cc_if)
+{
+#if (defined(DWC_LINUX) && defined(CONFIG_DEBUG_MUTEXES))
+	DWC_MUTEX_FREE(cc_if->mutex);
+#else
+	dwc_mutex_free(mtx_ctx, cc_if->mutex);
+#endif
+	cc_clear(mem_ctx, cc_if);
+	dwc_free(mem_ctx, cc_if);
+}
+
+static void cc_changed(dwc_cc_if_t *cc_if)
+{
+	if (cc_if->notifier) {
+		dwc_notify(cc_if->notifier, DWC_CC_LIST_CHANGED_NOTIFICATION, cc_if);
+	}
+}
+
+void dwc_cc_clear(void *mem_ctx, dwc_cc_if_t *cc_if)
+{
+	DWC_MUTEX_LOCK(cc_if->mutex);
+	cc_clear(mem_ctx, cc_if);
+	DWC_MUTEX_UNLOCK(cc_if->mutex);
+	cc_changed(cc_if);
+}
+
+int32_t dwc_cc_add(void *mem_ctx, dwc_cc_if_t *cc_if, uint8_t *chid,
+		   uint8_t *cdid, uint8_t *ck, uint8_t *name, uint8_t length)
+{
+	uint32_t uid;
+
+	DWC_MUTEX_LOCK(cc_if->mutex);
+	uid = cc_add(mem_ctx, cc_if, chid, cdid, ck, name, length);
+	DWC_MUTEX_UNLOCK(cc_if->mutex);
+	cc_changed(cc_if);
+
+	return uid;
+}
+
+void dwc_cc_change(void *mem_ctx, dwc_cc_if_t *cc_if, int32_t id, uint8_t *chid,
+		   uint8_t *cdid, uint8_t *ck, uint8_t *name, uint8_t length)
+{
+	dwc_cc_t* cc;
+
+	DWC_DEBUG("Change connection context %d", id);
+
+	DWC_MUTEX_LOCK(cc_if->mutex);
+	cc = cc_find(cc_if, id);
+	if (!cc) {
+		DWC_ERROR("Uid %d not found in cc list\n", id);
+		DWC_MUTEX_UNLOCK(cc_if->mutex);
+		return;
+	}
+
+	if (chid) {
+		DWC_MEMCPY(&(cc->chid[0]), chid, 16);
+	}
+	if (cdid) {
+		DWC_MEMCPY(&(cc->cdid[0]), cdid, 16);
+	}
+	if (ck) {
+		DWC_MEMCPY(&(cc->ck[0]), ck, 16);
+	}
+
+	if (name) {
+		if (cc->name) {
+			dwc_free(mem_ctx, cc->name);
+		}
+		cc->name = dwc_alloc(mem_ctx, length);
+		if (!cc->name) {
+			DWC_ERROR("Out of memory in dwc_cc_change()\n");
+			DWC_MUTEX_UNLOCK(cc_if->mutex);
+			return;
+		}
+		cc->length = length;
+		DWC_MEMCPY(cc->name, name, length);
+	}
+
+	DWC_MUTEX_UNLOCK(cc_if->mutex);
+
+	cc_changed(cc_if);
+
+	DWC_DEBUG("Changed connection context id=%d\n", id);
+	dump_bytes("New CHID", cc->chid, 16);
+	dump_bytes("New CDID", cc->cdid, 16);
+	dump_bytes("New CK", cc->ck, 16);
+}
+
+void dwc_cc_remove(void *mem_ctx, dwc_cc_if_t *cc_if, int32_t id)
+{
+	dwc_cc_t *cc;
+
+	DWC_DEBUG("Removing connection context %d", id);
+
+	DWC_MUTEX_LOCK(cc_if->mutex);
+	cc = cc_find(cc_if, id);
+	if (!cc) {
+		DWC_ERROR("Uid %d not found in cc list\n", id);
+		DWC_MUTEX_UNLOCK(cc_if->mutex);
+		return;
+	}
+
+	DWC_CIRCLEQ_REMOVE_INIT(&cc_if->list, cc, list_entry);
+	DWC_MUTEX_UNLOCK(cc_if->mutex);
+	free_cc(mem_ctx, cc);
+
+	cc_changed(cc_if);
+}
+
+uint8_t *dwc_cc_data_for_save(void *mem_ctx, dwc_cc_if_t *cc_if, unsigned int *length)
+{
+	uint8_t *buf, *x;
+	uint8_t zero = 0;
+	dwc_cc_t *cc;
+
+	DWC_MUTEX_LOCK(cc_if->mutex);
+	*length = cc_data_size(cc_if);
+	if (!(*length)) {
+		DWC_MUTEX_UNLOCK(cc_if->mutex);
+		return NULL;
+	}
+
+	DWC_DEBUG("Creating data for saving (length=%d)", *length);
+
+	buf = dwc_alloc(mem_ctx, *length);
+	if (!buf) {
+		*length = 0;
+		DWC_MUTEX_UNLOCK(cc_if->mutex);
+		return NULL;
+	}
+
+	x = buf;
+	DWC_CIRCLEQ_FOREACH(cc, &cc_if->list, list_entry) {
+		DWC_MEMCPY(x, cc->chid, 16);
+		x += 16;
+		DWC_MEMCPY(x, cc->cdid, 16);
+		x += 16;
+		DWC_MEMCPY(x, cc->ck, 16);
+		x += 16;
+		if (cc->name) {
+			DWC_MEMCPY(x, &cc->length, 1);
+			x += 1;
+			DWC_MEMCPY(x, cc->name, cc->length);
+			x += cc->length;
+		}
+		else {
+			DWC_MEMCPY(x, &zero, 1);
+			x += 1;
+		}
+	}
+	DWC_MUTEX_UNLOCK(cc_if->mutex);
+
+	return buf;
+}
+
+void dwc_cc_restore_from_data(void *mem_ctx, dwc_cc_if_t *cc_if, uint8_t *data, uint32_t length)
+{
+	uint8_t name_length;
+	uint8_t *name;
+	uint8_t *chid;
+	uint8_t *cdid;
+	uint8_t *ck;
+	uint32_t i = 0;
+
+	DWC_MUTEX_LOCK(cc_if->mutex);
+	cc_clear(mem_ctx, cc_if);
+
+	while (i < length) {
+		chid = &data[i];
+		i += 16;
+		cdid = &data[i];
+		i += 16;
+		ck = &data[i];
+		i += 16;
+
+		name_length = data[i];
+		i ++;
+
+		if (name_length) {
+			name = &data[i];
+			i += name_length;
+		}
+		else {
+			name = NULL;
+		}
+
+		/* check to see if we haven't overflown the buffer */
+		if (i > length) {
+			DWC_ERROR("Data format error while attempting to load CCs "
+				  "(nlen=%d, iter=%d, buflen=%d).\n", name_length, i, length);
+			break;
+		}
+
+		cc_add(mem_ctx, cc_if, chid, cdid, ck, name, name_length);
+	}
+	DWC_MUTEX_UNLOCK(cc_if->mutex);
+
+	cc_changed(cc_if);
+}
+
+uint32_t dwc_cc_match_chid(dwc_cc_if_t *cc_if, uint8_t *chid)
+{
+	uint32_t uid = 0;
+
+	DWC_MUTEX_LOCK(cc_if->mutex);
+	uid = cc_match_chid(cc_if, chid);
+	DWC_MUTEX_UNLOCK(cc_if->mutex);
+	return uid;
+}
+uint32_t dwc_cc_match_cdid(dwc_cc_if_t *cc_if, uint8_t *cdid)
+{
+	uint32_t uid = 0;
+
+	DWC_MUTEX_LOCK(cc_if->mutex);
+	uid = cc_match_cdid(cc_if, cdid);
+	DWC_MUTEX_UNLOCK(cc_if->mutex);
+	return uid;
+}
+
+uint8_t *dwc_cc_ck(dwc_cc_if_t *cc_if, int32_t id)
+{
+	uint8_t *ck = NULL;
+	dwc_cc_t *cc;
+
+	DWC_MUTEX_LOCK(cc_if->mutex);
+	cc = cc_find(cc_if, id);
+	if (cc) {
+		ck = cc->ck;
+	}
+	DWC_MUTEX_UNLOCK(cc_if->mutex);
+
+	return ck;
+
+}
+
+uint8_t *dwc_cc_chid(dwc_cc_if_t *cc_if, int32_t id)
+{
+	uint8_t *retval = NULL;
+	dwc_cc_t *cc;
+
+	DWC_MUTEX_LOCK(cc_if->mutex);
+	cc = cc_find(cc_if, id);
+	if (cc) {
+		retval = cc->chid;
+	}
+	DWC_MUTEX_UNLOCK(cc_if->mutex);
+
+	return retval;
+}
+
+uint8_t *dwc_cc_cdid(dwc_cc_if_t *cc_if, int32_t id)
+{
+	uint8_t *retval = NULL;
+	dwc_cc_t *cc;
+
+	DWC_MUTEX_LOCK(cc_if->mutex);
+	cc = cc_find(cc_if, id);
+	if (cc) {
+		retval = cc->cdid;
+	}
+	DWC_MUTEX_UNLOCK(cc_if->mutex);
+
+	return retval;
+}
+
+uint8_t *dwc_cc_name(dwc_cc_if_t *cc_if, int32_t id, uint8_t *length)
+{
+	uint8_t *retval = NULL;
+	dwc_cc_t *cc;
+
+	DWC_MUTEX_LOCK(cc_if->mutex);
+	*length = 0;
+	cc = cc_find(cc_if, id);
+	if (cc) {
+		*length = cc->length;
+		retval = cc->name;
+	}
+	DWC_MUTEX_UNLOCK(cc_if->mutex);
+
+	return retval;
+}
+
+#endif	/* DWC_CCLIB */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_cc.h b/drivers/usb/gadget/udc/hiudc/dwc_cc.h
new file mode 100644
index 0000000..f86e6f2
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_cc.h
@@ -0,0 +1,224 @@
+/* =========================================================================
+ * $File: //dwh/usb_iip/dev/software/dwc_common_port_2/dwc_cc.h $
+ * $Revision: #4 $
+ * $Date: 2010/09/28 $
+ * $Change: 1596182 $
+ *
+ * Synopsys Portability Library Software and documentation
+ * (hereinafter, "Software") is an Unsupported proprietary work of
+ * Synopsys, Inc. unless otherwise expressly agreed to in writing
+ * between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product
+ * under any End User Software License Agreement or Agreement for
+ * Licensed Product with Synopsys or any supplement thereto. You are
+ * permitted to use and redistribute this Software in source and binary
+ * forms, with or without modification, provided that redistributions
+ * of source code must retain this notice. You may not view, use,
+ * disclose, copy or distribute this file or any information contained
+ * herein except pursuant to this license grant from Synopsys. If you
+ * do not agree with this notice, including the disclaimer below, then
+ * you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS"
+ * BASIS AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+ * FOR A PARTICULAR PURPOSE ARE HEREBY DISCLAIMED. IN NO EVENT SHALL
+ * SYNOPSYS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ * USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================= */
+#ifndef _DWC_CC_H_
+#define _DWC_CC_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/** @file
+ *
+ * This file defines the Context Context library.
+ *
+ * The main data structure is dwc_cc_if_t which is returned by either the
+ * dwc_cc_if_alloc function or returned by the module to the user via a provided
+ * function. The data structure is opaque and should only be manipulated via the
+ * functions provied in this API.
+ *
+ * It manages a list of connection contexts and operations can be performed to
+ * add, remove, query, search, and change, those contexts.  Additionally,
+ * a dwc_notifier_t object can be requested from the manager so that
+ * the user can be notified whenever the context list has changed.
+ */
+
+#include "dwc_os.h"
+#include "dwc_list.h"
+#include "dwc_notifier.h"
+
+
+/* Notifications */
+#define DWC_CC_LIST_CHANGED_NOTIFICATION "DWC_CC_LIST_CHANGED_NOTIFICATION"
+
+struct dwc_cc_if;
+typedef struct dwc_cc_if dwc_cc_if_t;
+
+
+/** @name Connection Context Operations */
+/** @{ */
+
+/** This function allocates memory for a dwc_cc_if_t structure, initializes
+ * fields to default values, and returns a pointer to the structure or NULL on
+ * error. */
+extern dwc_cc_if_t *dwc_cc_if_alloc(void *mem_ctx, void *mtx_ctx,
+				    dwc_notifier_t *notifier, unsigned is_host);
+
+/** Frees the memory for the specified CC structure allocated from
+ * dwc_cc_if_alloc(). */
+extern void dwc_cc_if_free(void *mem_ctx, void *mtx_ctx, dwc_cc_if_t *cc_if);
+
+/** Removes all contexts from the connection context list */
+extern void dwc_cc_clear(void *mem_ctx, dwc_cc_if_t *cc_if);
+
+/** Adds a connection context (CHID, CK, CDID, Name) to the connection context list.
+ * If a CHID already exists, the CK and name are overwritten.  Statistics are
+ * not overwritten.
+ *
+ * @param cc_if The cc_if structure.
+ * @param chid A pointer to the 16-byte CHID.  This value will be copied.
+ * @param ck A pointer to the 16-byte CK.  This value will be copied.
+ * @param cdid A pointer to the 16-byte CDID.  This value will be copied.
+ * @param name An optional host friendly name as defined in the association model
+ * spec.  Must be a UTF16-LE unicode string.  Can be NULL to indicated no name.
+ * @param length The length othe unicode string.
+ * @return A unique identifier used to refer to this context that is valid for
+ * as long as this context is still in the list. */
+extern int32_t dwc_cc_add(void *mem_ctx, dwc_cc_if_t *cc_if, uint8_t *chid,
+			  uint8_t *cdid, uint8_t *ck, uint8_t *name,
+			  uint8_t length);
+
+/** Changes the CHID, CK, CDID, or Name values of a connection context in the
+ * list, preserving any accumulated statistics.  This would typically be called
+ * if the host decideds to change the context with a SET_CONNECTION request.
+ *
+ * @param cc_if The cc_if structure.
+ * @param id The identifier of the connection context.
+ * @param chid A pointer to the 16-byte CHID.  This value will be copied.  NULL
+ * indicates no change.
+ * @param cdid A pointer to the 16-byte CDID.  This value will be copied.  NULL
+ * indicates no change.
+ * @param ck A pointer to the 16-byte CK.  This value will be copied.  NULL
+ * indicates no change.
+ * @param name Host friendly name UTF16-LE.  NULL indicates no change.
+ * @param length Length of name. */
+extern void dwc_cc_change(void *mem_ctx, dwc_cc_if_t *cc_if, int32_t id,
+			  uint8_t *chid, uint8_t *cdid, uint8_t *ck,
+			  uint8_t *name, uint8_t length);
+
+/** Remove the specified connection context.
+ * @param cc_if The cc_if structure.
+ * @param id The identifier of the connection context to remove. */
+extern void dwc_cc_remove(void *mem_ctx, dwc_cc_if_t *cc_if, int32_t id);
+
+/** Get a binary block of data for the connection context list and attributes.
+ * This data can be used by the OS specific driver to save the connection
+ * context list into non-volatile memory.
+ *
+ * @param cc_if The cc_if structure.
+ * @param length Return the length of the data buffer.
+ * @return A pointer to the data buffer.  The memory for this buffer should be
+ * freed with DWC_FREE() after use. */
+extern uint8_t *dwc_cc_data_for_save(void *mem_ctx, dwc_cc_if_t *cc_if,
+				     unsigned int *length);
+
+/** Restore the connection context list from the binary data that was previously
+ * returned from a call to dwc_cc_data_for_save.  This can be used by the OS specific
+ * driver to load a connection context list from non-volatile memory.
+ *
+ * @param cc_if The cc_if structure.
+ * @param data The data bytes as returned from dwc_cc_data_for_save.
+ * @param length The length of the data. */
+extern void dwc_cc_restore_from_data(void *mem_ctx, dwc_cc_if_t *cc_if,
+				     uint8_t *data, unsigned int length);
+
+/** Find the connection context from the specified CHID.
+ *
+ * @param cc_if The cc_if structure.
+ * @param chid A pointer to the CHID data.
+ * @return A non-zero identifier of the connection context if the CHID matches.
+ * Otherwise returns 0. */
+extern uint32_t dwc_cc_match_chid(dwc_cc_if_t *cc_if, uint8_t *chid);
+
+/** Find the connection context from the specified CDID.
+ *
+ * @param cc_if The cc_if structure.
+ * @param cdid A pointer to the CDID data.
+ * @return A non-zero identifier of the connection context if the CHID matches.
+ * Otherwise returns 0. */
+extern uint32_t dwc_cc_match_cdid(dwc_cc_if_t *cc_if, uint8_t *cdid);
+
+/** Retrieve the CK from the specified connection context.
+ *
+ * @param cc_if The cc_if structure.
+ * @param id The identifier of the connection context.
+ * @return A pointer to the CK data.  The memory does not need to be freed. */
+extern uint8_t *dwc_cc_ck(dwc_cc_if_t *cc_if, int32_t id);
+
+/** Retrieve the CHID from the specified connection context.
+ *
+ * @param cc_if The cc_if structure.
+ * @param id The identifier of the connection context.
+ * @return A pointer to the CHID data.  The memory does not need to be freed. */
+extern uint8_t *dwc_cc_chid(dwc_cc_if_t *cc_if, int32_t id);
+
+/** Retrieve the CDID from the specified connection context.
+ *
+ * @param cc_if The cc_if structure.
+ * @param id The identifier of the connection context.
+ * @return A pointer to the CDID data.  The memory does not need to be freed. */
+extern uint8_t *dwc_cc_cdid(dwc_cc_if_t *cc_if, int32_t id);
+
+extern uint8_t *dwc_cc_name(dwc_cc_if_t *cc_if, int32_t id, uint8_t *length);
+
+/** Checks a buffer for non-zero.
+ * @param id A pointer to a 16 byte buffer.
+ * @return true if the 16 byte value is non-zero. */
+static inline unsigned dwc_assoc_is_not_zero_id(uint8_t *id) {
+	int i;
+	for (i=0; i<16; i++) {
+		if (id[i]) return 1;
+	}
+	return 0;
+}
+
+/** Checks a buffer for zero.
+ * @param id A pointer to a 16 byte buffer.
+ * @return true if the 16 byte value is zero. */
+static inline unsigned dwc_assoc_is_zero_id(uint8_t *id) {
+	return !dwc_assoc_is_not_zero_id(id);
+}
+
+/** Prints an ASCII representation for the 16-byte chid, cdid, or ck, into
+ * buffer. */
+static inline int dwc_print_id_string(char *buffer, uint8_t *id) {
+	char *ptr = buffer;
+	int i;
+	for (i=0; i<16; i++) {
+		ptr += DWC_SPRINTF(ptr, "%02x", id[i]);
+		if (i < 15) {
+			ptr += DWC_SPRINTF(ptr, " ");
+		}
+	}
+	return ptr - buffer;
+}
+
+/** @} */
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _DWC_CC_H_ */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_common_linux.c b/drivers/usb/gadget/udc/hiudc/dwc_common_linux.c
new file mode 100644
index 0000000..426a2ca
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_common_linux.c
@@ -0,0 +1,1307 @@
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/kthread.h>
+
+#ifdef DWC_CCLIB
+# include "dwc_cc.h"
+#endif
+
+#ifdef DWC_CRYPTOLIB
+# include "dwc_modpow.h"
+# include "dwc_dh.h"
+# include "dwc_crypto.h"
+#endif
+
+#ifdef DWC_NOTIFYLIB
+# include "dwc_notifier.h"
+#endif
+
+/* OS-Level Implementations */
+
+/* This is the Linux kernel implementation of the DWC platform library. */
+#include <linux/moduleparam.h>
+#include <linux/ctype.h>
+#include <linux/crypto.h>
+#include <linux/delay.h>
+#include <linux/device.h>
+#include <linux/dma-mapping.h>
+#include <linux/cdev.h>
+#include <linux/errno.h>
+#include <linux/interrupt.h>
+#include <linux/jiffies.h>
+#include <linux/list.h>
+#include <linux/pci.h>
+#include <linux/random.h>
+#include <linux/scatterlist.h>
+#include <linux/slab.h>
+#include <linux/stat.h>
+#include <linux/string.h>
+#include <linux/timer.h>
+#include <linux/usb.h>
+
+#include <linux/version.h>
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,24)
+# include <linux/usb/gadget.h>
+#else
+# include <linux/usb_gadget.h>
+#endif
+
+#include <asm/io.h>
+#include <asm/page.h>
+#include <asm/uaccess.h>
+#include <asm/unaligned.h>
+
+#include "dwc_os.h"
+#include "dwc_list.h"
+
+
+/* MISC */
+
+void *DWC_MEMSET(void *dest, uint8_t byte, uint32_t size)
+{
+	return memset(dest, byte, size);
+}
+
+void *DWC_MEMCPY(void *dest, void const *src, uint32_t size)
+{
+	return memcpy(dest, src, size);
+}
+
+void *DWC_MEMMOVE(void *dest, void *src, uint32_t size)
+{
+	return memmove(dest, src, size);
+}
+
+int DWC_MEMCMP(void *m1, void *m2, uint32_t size)
+{
+	return memcmp(m1, m2, size);
+}
+
+int DWC_STRNCMP(void *s1, void *s2, uint32_t size)
+{
+	return strncmp(s1, s2, size);
+}
+
+int DWC_STRCMP(void *s1, void *s2)
+{
+	return strcmp(s1, s2);
+}
+
+int DWC_STRLEN(char const *str)
+{
+	return strlen(str);
+}
+
+char *DWC_STRCPY(char *to, char const *from)
+{
+	return strcpy(to, from);
+}
+
+char *DWC_STRDUP(char const *str)
+{
+	int len = DWC_STRLEN(str) + 1;
+	char *new = DWC_ALLOC_ATOMIC(len);
+
+	if (!new) {
+		return NULL;
+	}
+
+	DWC_MEMCPY(new, str, len);
+	return new;
+}
+
+int DWC_ATOI(const char *str, int32_t *value)
+{
+	char *end = NULL;
+
+	*value = simple_strtol(str, &end, 0);
+	if (*end == '\0') {
+		return 0;
+	}
+
+	return -1;
+}
+
+int DWC_ATOUI(const char *str, uint32_t *value)
+{
+	char *end = NULL;
+
+	*value = simple_strtoul(str, &end, 0);
+	if (*end == '\0') {
+		return 0;
+	}
+
+	return -1;
+}
+
+
+#ifdef DWC_UTFLIB
+/* From usbstring.c */
+
+int DWC_UTF8_TO_UTF16LE(uint8_t const *s, uint16_t *cp, unsigned len)
+{
+	int	count = 0;
+	u8	c;
+	u16	uchar;
+
+	/* this insists on correct encodings, though not minimal ones.
+	 * BUT it currently rejects legit 4-byte UTF-8 code points,
+	 * which need surrogate pairs.  (Unicode 3.1 can use them.)
+	 */
+	while (len != 0 && (c = (u8) *s++) != 0) {
+		if (unlikely(c & 0x80)) {
+			// 2-byte sequence:
+			// 00000yyyyyxxxxxx = 110yyyyy 10xxxxxx
+			if ((c & 0xe0) == 0xc0) {
+				uchar = (c & 0x1f) << 6;
+
+				c = (u8) *s++;
+				if ((c & 0xc0) != 0xc0)
+					goto fail;
+				c &= 0x3f;
+				uchar |= c;
+
+			// 3-byte sequence (most CJKV characters):
+			// zzzzyyyyyyxxxxxx = 1110zzzz 10yyyyyy 10xxxxxx
+			} else if ((c & 0xf0) == 0xe0) {
+				uchar = (c & 0x0f) << 12;
+
+				c = (u8) *s++;
+				if ((c & 0xc0) != 0xc0)
+					goto fail;
+				c &= 0x3f;
+				uchar |= c << 6;
+
+				c = (u8) *s++;
+				if ((c & 0xc0) != 0xc0)
+					goto fail;
+				c &= 0x3f;
+				uchar |= c;
+
+				/* no bogus surrogates */
+				if (0xd800 <= uchar && uchar <= 0xdfff)
+					goto fail;
+
+			// 4-byte sequence (surrogate pairs, currently rare):
+			// 11101110wwwwzzzzyy + 110111yyyyxxxxxx
+			//     = 11110uuu 10uuzzzz 10yyyyyy 10xxxxxx
+			// (uuuuu = wwww + 1)
+			// FIXME accept the surrogate code points (only)
+			} else
+				goto fail;
+		} else
+			uchar = c;
+		put_unaligned (cpu_to_le16 (uchar), cp++);
+		count++;
+		len--;
+	}
+	return count;
+fail:
+	return -1;
+}
+#endif	/* DWC_UTFLIB */
+
+
+/* dwc_debug.h */
+
+dwc_bool_t DWC_IN_IRQ(void)
+{
+	return in_irq();
+}
+
+dwc_bool_t DWC_IN_BH(void)
+{
+	return in_softirq();
+}
+
+void DWC_VPRINTF(char *format, va_list args)
+{
+	vprintk(format, args);
+}
+
+int DWC_VSNPRINTF(char *str, int size, char *format, va_list args)
+{
+	return vsnprintf(str, size, format, args);
+}
+
+void DWC_PRINTF(char *format, ...)
+{
+	va_list args;
+
+	va_start(args, format);
+	DWC_VPRINTF(format, args);
+	va_end(args);
+}
+
+int DWC_SPRINTF(char *buffer, char *format, ...)
+{
+	int retval;
+	va_list args;
+
+	va_start(args, format);
+	retval = vsprintf(buffer, format, args);
+	va_end(args);
+	return retval;
+}
+
+int DWC_SNPRINTF(char *buffer, int size, char *format, ...)
+{
+	int retval;
+	va_list args;
+
+	va_start(args, format);
+	retval = vsnprintf(buffer, size, format, args);
+	va_end(args);
+	return retval;
+}
+
+void __DWC_WARN(char *format, ...)
+{
+	va_list args;
+
+	va_start(args, format);
+	DWC_PRINTF(KERN_WARNING);
+	DWC_VPRINTF(format, args);
+	va_end(args);
+}
+
+void __DWC_ERROR(char *format, ...)
+{
+	va_list args;
+
+	va_start(args, format);
+	DWC_PRINTF(KERN_ERR);
+	DWC_VPRINTF(format, args);
+	va_end(args);
+}
+
+void DWC_EXCEPTION(char *format, ...)
+{
+	va_list args;
+
+	va_start(args, format);
+	DWC_PRINTF(KERN_ERR);
+	DWC_VPRINTF(format, args);
+	va_end(args);
+	BUG_ON(1);
+}
+
+#ifdef DEBUG
+void __DWC_DEBUG(char *format, ...)
+{
+	va_list args;
+
+	va_start(args, format);
+	DWC_PRINTF(KERN_DEBUG);
+	DWC_VPRINTF(format, args);
+	va_end(args);
+}
+#endif
+
+void *__DWC_DMA_ALLOC(void *dma_ctx, uint32_t size, dwc_dma_t *dma_addr)
+{
+#ifdef xxCOSIM /* Only works for 32-bit cosim */
+	void *buf = dma_alloc_coherent(dma_ctx, (size_t)size, dma_addr, GFP_KERNEL);
+#else
+//	void *buf = dma_alloc_coherent(dma_ctx, (size_t)size, dma_addr, GFP_KERNEL | GFP_DMA32);
+	void *buf = dma_alloc_coherent(NULL, (size_t)size, dma_addr, GFP_ATOMIC);
+#endif
+	if (!buf) {
+		return NULL;
+	}
+
+	memset(buf, 0, (size_t)size);
+	return buf;
+}
+
+void *__DWC_DMA_ALLOC_ATOMIC(void *dma_ctx, uint32_t size, dwc_dma_t *dma_addr)
+{
+	void *buf = dma_alloc_coherent(NULL, (size_t)size, dma_addr, GFP_ATOMIC);
+	if (!buf) {
+		return NULL;
+	}
+	memset(buf, 0, (size_t)size);
+	return buf;
+}
+
+void __DWC_DMA_FREE(void *dma_ctx, uint32_t size, void *virt_addr, dwc_dma_t dma_addr)
+{
+	dma_free_coherent(dma_ctx, size, virt_addr, dma_addr);
+}
+
+void *__DWC_ALLOC(void *mem_ctx, uint32_t size)
+{
+	return kzalloc(size, GFP_KERNEL);
+}
+
+void *__DWC_ALLOC_ATOMIC(void *mem_ctx, uint32_t size)
+{
+	return kzalloc(size, GFP_ATOMIC);
+}
+
+void __DWC_FREE(void *mem_ctx, void *addr)
+{
+	kfree(addr);
+}
+
+
+#ifdef DWC_CRYPTOLIB
+/* dwc_crypto.h */
+
+void DWC_RANDOM_BYTES(uint8_t *buffer, uint32_t length)
+{
+	get_random_bytes(buffer, length);
+}
+
+int DWC_AES_CBC(uint8_t *message, uint32_t messagelen, uint8_t *key, uint32_t keylen, uint8_t iv[16], uint8_t *out)
+{
+	struct crypto_blkcipher *tfm;
+	struct blkcipher_desc desc;
+	struct scatterlist sgd;
+	struct scatterlist sgs;
+
+	tfm = crypto_alloc_blkcipher("cbc(aes)", 0, CRYPTO_ALG_ASYNC);
+	if (tfm == NULL) {
+		printk("failed to load transform for aes CBC\n");
+		return -1;
+	}
+
+	crypto_blkcipher_setkey(tfm, key, keylen);
+	crypto_blkcipher_set_iv(tfm, iv, 16);
+
+	sg_init_one(&sgd, out, messagelen);
+	sg_init_one(&sgs, message, messagelen);
+
+	desc.tfm = tfm;
+	desc.flags = 0;
+
+	if (crypto_blkcipher_encrypt(&desc, &sgd, &sgs, messagelen)) {
+		crypto_free_blkcipher(tfm);
+		DWC_ERROR("AES CBC encryption failed");
+		return -1;
+	}
+
+	crypto_free_blkcipher(tfm);
+	return 0;
+}
+
+int DWC_SHA256(uint8_t *message, uint32_t len, uint8_t *out)
+{
+	struct crypto_hash *tfm;
+	struct hash_desc desc;
+	struct scatterlist sg;
+
+	tfm = crypto_alloc_hash("sha256", 0, CRYPTO_ALG_ASYNC);
+	if (IS_ERR(tfm)) {
+		DWC_ERROR("Failed to load transform for sha256: %ld\n", PTR_ERR(tfm));
+		return 0;
+	}
+	desc.tfm = tfm;
+	desc.flags = 0;
+
+	sg_init_one(&sg, message, len);
+	crypto_hash_digest(&desc, &sg, len, out);
+	crypto_free_hash(tfm);
+
+	return 1;
+}
+
+int DWC_HMAC_SHA256(uint8_t *message, uint32_t messagelen,
+		    uint8_t *key, uint32_t keylen, uint8_t *out)
+{
+	struct crypto_hash *tfm;
+	struct hash_desc desc;
+	struct scatterlist sg;
+
+	tfm = crypto_alloc_hash("hmac(sha256)", 0, CRYPTO_ALG_ASYNC);
+	if (IS_ERR(tfm)) {
+		DWC_ERROR("Failed to load transform for hmac(sha256): %ld\n", PTR_ERR(tfm));
+		return 0;
+	}
+	desc.tfm = tfm;
+	desc.flags = 0;
+
+	sg_init_one(&sg, message, messagelen);
+	crypto_hash_setkey(tfm, key, keylen);
+	crypto_hash_digest(&desc, &sg, messagelen, out);
+	crypto_free_hash(tfm);
+
+	return 1;
+}
+#endif	/* DWC_CRYPTOLIB */
+
+
+/* Byte Ordering Conversions */
+
+uint32_t DWC_CPU_TO_LE32(uint32_t *p)
+{
+#ifdef __LITTLE_ENDIAN
+	return *p;
+#else
+	uint8_t *u_p = (uint8_t *)p;
+
+	return (u_p[3] | (u_p[2] << 8) | (u_p[1] << 16) | (u_p[0] << 24));
+#endif
+}
+
+uint32_t DWC_CPU_TO_BE32(uint32_t *p)
+{
+#ifdef __BIG_ENDIAN
+	return *p;
+#else
+	uint8_t *u_p = (uint8_t *)p;
+
+	return (u_p[3] | (u_p[2] << 8) | (u_p[1] << 16) | (u_p[0] << 24));
+#endif
+}
+
+uint32_t DWC_LE32_TO_CPU(uint32_t *p)
+{
+#ifdef __LITTLE_ENDIAN
+	return *p;
+#else
+	uint8_t *u_p = (uint8_t *)p;
+
+	return (u_p[3] | (u_p[2] << 8) | (u_p[1] << 16) | (u_p[0] << 24));
+#endif
+}
+
+uint32_t DWC_BE32_TO_CPU(uint32_t *p)
+{
+#ifdef __BIG_ENDIAN
+	return *p;
+#else
+	uint8_t *u_p = (uint8_t *)p;
+
+	return (u_p[3] | (u_p[2] << 8) | (u_p[1] << 16) | (u_p[0] << 24));
+#endif
+}
+
+uint16_t DWC_CPU_TO_LE16(uint16_t *p)
+{
+#ifdef __LITTLE_ENDIAN
+	return *p;
+#else
+	uint8_t *u_p = (uint8_t *)p;
+	return (u_p[1] | (u_p[0] << 8));
+#endif
+}
+
+uint16_t DWC_CPU_TO_BE16(uint16_t *p)
+{
+#ifdef __BIG_ENDIAN
+	return *p;
+#else
+	uint8_t *u_p = (uint8_t *)p;
+	return (u_p[1] | (u_p[0] << 8));
+#endif
+}
+
+uint16_t DWC_LE16_TO_CPU(uint16_t *p)
+{
+#ifdef __LITTLE_ENDIAN
+	return *p;
+#else
+	uint8_t *u_p = (uint8_t *)p;
+	return (u_p[1] | (u_p[0] << 8));
+#endif
+}
+
+uint16_t DWC_BE16_TO_CPU(uint16_t *p)
+{
+#ifdef __BIG_ENDIAN
+	return *p;
+#else
+	uint8_t *u_p = (uint8_t *)p;
+	return (u_p[1] | (u_p[0] << 8));
+#endif
+}
+
+
+/* Registers */
+
+uint32_t DWC_READ_REG32(uint32_t volatile *reg)
+{
+	return readl(reg);
+}
+
+void DWC_WRITE_REG32(uint32_t volatile *reg, uint32_t value)
+{
+	writel(value, reg);
+}
+
+void DWC_MODIFY_REG32(uint32_t volatile *reg, uint32_t clear_mask, uint32_t set_mask)
+{
+	writel((readl(reg) & ~clear_mask) | set_mask, reg);
+}
+
+/* Locking */
+
+dwc_spinlock_t *DWC_SPINLOCK_ALLOC(void)
+{
+	spinlock_t *sl = (spinlock_t *)1;
+
+#if defined(CONFIG_PREEMPT) || defined(CONFIG_SMP)
+	sl = DWC_ALLOC(sizeof(*sl));
+	if (!sl) {
+		DWC_ERROR("Cannot allocate memory for spinlock\n");
+		return NULL;
+	}
+
+	spin_lock_init(sl);
+#endif
+	return (dwc_spinlock_t *)sl;
+}
+
+void DWC_SPINLOCK_FREE(dwc_spinlock_t *lock)
+{
+#if defined(CONFIG_PREEMPT) || defined(CONFIG_SMP)
+	DWC_FREE(lock);
+#endif
+}
+
+void DWC_SPINLOCK(dwc_spinlock_t *lock)
+{
+#if defined(CONFIG_PREEMPT) || defined(CONFIG_SMP)
+	spin_lock((spinlock_t *)lock);
+#endif
+}
+
+void DWC_SPINUNLOCK(dwc_spinlock_t *lock)
+{
+#if defined(CONFIG_PREEMPT) || defined(CONFIG_SMP)
+	spin_unlock((spinlock_t *)lock);
+#endif
+}
+
+void DWC_SPINLOCK_IRQSAVE(dwc_spinlock_t *lock, dwc_irqflags_t *flags)
+{
+	dwc_irqflags_t f;
+
+#if defined(CONFIG_PREEMPT) || defined(CONFIG_SMP)
+	spin_lock_irqsave((spinlock_t *)lock, f);
+#else
+	local_irq_save(f);
+#endif
+	*flags = f;
+}
+
+void DWC_SPINUNLOCK_IRQRESTORE(dwc_spinlock_t *lock, dwc_irqflags_t flags)
+{
+#if defined(CONFIG_PREEMPT) || defined(CONFIG_SMP)
+	spin_unlock_irqrestore((spinlock_t *)lock, flags);
+#else
+	local_irq_restore(flags);
+#endif
+}
+
+dwc_mutex_t *DWC_MUTEX_ALLOC(void)
+{
+	struct mutex *m;
+	dwc_mutex_t *mutex = (dwc_mutex_t *)DWC_ALLOC(sizeof(struct mutex));
+
+	if (!mutex) {
+		DWC_ERROR("Cannot allocate memory for mutex\n");
+		return NULL;
+	}
+
+	m = (struct mutex *)mutex;
+	mutex_init(m);
+	return mutex;
+}
+
+#if (defined(DWC_LINUX) && defined(CONFIG_DEBUG_MUTEXES))
+#else
+void DWC_MUTEX_FREE(dwc_mutex_t *mutex)
+{
+	mutex_destroy((struct mutex *)mutex);
+	DWC_FREE(mutex);
+}
+#endif
+
+void DWC_MUTEX_LOCK(dwc_mutex_t *mutex)
+{
+	struct mutex *m = (struct mutex *)mutex;
+	mutex_lock(m);
+}
+
+int DWC_MUTEX_TRYLOCK(dwc_mutex_t *mutex)
+{
+	struct mutex *m = (struct mutex *)mutex;
+	return mutex_trylock(m);
+}
+
+void DWC_MUTEX_UNLOCK(dwc_mutex_t *mutex)
+{
+	struct mutex *m = (struct mutex *)mutex;
+	mutex_unlock(m);
+}
+
+
+/* Timing */
+
+void DWC_UDELAY(uint32_t usecs)
+{
+	udelay(usecs);
+}
+
+void DWC_MDELAY(uint32_t msecs)
+{
+	if (in_interrupt())
+		mdelay(msecs);
+	else
+		msleep(msecs);
+}
+
+void DWC_MSLEEP(uint32_t msecs)
+{
+	msleep(msecs);
+}
+
+uint32_t DWC_TIME(void)
+{
+	return jiffies_to_msecs(jiffies);
+}
+
+
+/* Timers */
+
+struct dwc_timer {
+	struct timer_list *t;
+	char *name;
+	dwc_timer_callback_t cb;
+	void *data;
+	uint8_t scheduled;
+	dwc_spinlock_t *lock;
+};
+
+void DWC_TIMER_FREE(dwc_timer_t *timer)
+{
+	dwc_irqflags_t flags;
+
+	DWC_SPINLOCK_IRQSAVE(timer->lock, &flags);
+
+	if (timer->scheduled) {
+		del_timer(timer->t);
+		timer->scheduled = 0;
+	}
+
+	DWC_SPINUNLOCK_IRQRESTORE(timer->lock, flags);
+	DWC_SPINLOCK_FREE(timer->lock);
+	DWC_FREE(timer->t);
+	DWC_FREE(timer->name);
+	DWC_FREE(timer);
+}
+
+void DWC_TIMER_SCHEDULE(dwc_timer_t *timer, uint32_t time)
+{
+	dwc_irqflags_t flags;
+
+	DWC_SPINLOCK_IRQSAVE(timer->lock, &flags);
+
+	if (!timer->scheduled) {
+		timer->scheduled = 1;
+		DWC_DEBUG("Scheduling timer %s to expire in +%d msec", timer->name, time);
+		timer->t->expires = jiffies + msecs_to_jiffies(time);
+		add_timer(timer->t);
+	} else {
+		DWC_DEBUG("Modifying timer %s to expire in +%d msec", timer->name, time);
+		mod_timer(timer->t, jiffies + msecs_to_jiffies(time));
+	}
+
+	DWC_SPINUNLOCK_IRQRESTORE(timer->lock, flags);
+}
+
+void DWC_TIMER_CANCEL(dwc_timer_t *timer)
+{
+	del_timer(timer->t);
+}
+
+
+/* Wait Queues */
+
+struct dwc_waitq {
+	wait_queue_head_t queue;
+	int abort;
+};
+
+dwc_waitq_t *DWC_WAITQ_ALLOC(void)
+{
+	dwc_waitq_t *wq = DWC_ALLOC(sizeof(*wq));
+
+	if (!wq) {
+		DWC_ERROR("Cannot allocate memory for waitqueue\n");
+		return NULL;
+	}
+
+	init_waitqueue_head(&wq->queue);
+	wq->abort = 0;
+	return wq;
+}
+
+void DWC_WAITQ_FREE(dwc_waitq_t *wq)
+{
+	DWC_FREE(wq);
+}
+
+int32_t DWC_WAITQ_WAIT(dwc_waitq_t *wq, dwc_waitq_condition_t cond, void *data)
+{
+	int result = wait_event_interruptible(wq->queue,
+					      cond(data) || wq->abort);
+	if (result == -ERESTARTSYS) {
+		wq->abort = 0;
+		return -DWC_E_RESTART;
+	}
+
+	if (wq->abort == 1) {
+		wq->abort = 0;
+		return -DWC_E_ABORT;
+	}
+
+	wq->abort = 0;
+
+	if (result == 0) {
+		return 0;
+	}
+
+	return -DWC_E_UNKNOWN;
+}
+
+int32_t DWC_WAITQ_WAIT_TIMEOUT(dwc_waitq_t *wq, dwc_waitq_condition_t cond,
+			       void *data, int32_t msecs)
+{
+	int32_t tmsecs;
+	int result = wait_event_interruptible_timeout(wq->queue,
+						      cond(data) || wq->abort,
+						      msecs_to_jiffies(msecs));
+	if (result == -ERESTARTSYS) {
+		wq->abort = 0;
+		return -DWC_E_RESTART;
+	}
+
+	if (wq->abort == 1) {
+		wq->abort = 0;
+		return -DWC_E_ABORT;
+	}
+
+	wq->abort = 0;
+
+	if (result > 0) {
+		tmsecs = jiffies_to_msecs(result);
+		if (!tmsecs) {
+			return 1;
+		}
+
+		return tmsecs;
+	}
+
+	if (result == 0) {
+		return -DWC_E_TIMEOUT;
+	}
+
+	return -DWC_E_UNKNOWN;
+}
+
+void DWC_WAITQ_TRIGGER(dwc_waitq_t *wq)
+{
+	wq->abort = 0;
+	wake_up_interruptible(&wq->queue);
+}
+
+void DWC_WAITQ_ABORT(dwc_waitq_t *wq)
+{
+	wq->abort = 1;
+	wake_up_interruptible(&wq->queue);
+}
+
+
+/* Threading */
+
+dwc_thread_t *DWC_THREAD_RUN(dwc_thread_function_t func, char *name, void *data)
+{
+	struct task_struct *thread = kthread_run(func, data, name);
+
+	if (thread == ERR_PTR(-ENOMEM)) {
+		return NULL;
+	}
+
+	return (dwc_thread_t *)thread;
+}
+
+int DWC_THREAD_STOP(dwc_thread_t *thread)
+{
+	return kthread_stop((struct task_struct *)thread);
+}
+
+dwc_bool_t DWC_THREAD_SHOULD_STOP(void)
+{
+	return kthread_should_stop();
+}
+
+
+/* tasklets
+ - run in interrupt context (cannot sleep)
+ - each tasklet runs on a single CPU
+ - different tasklets can be running simultaneously on different CPUs
+ */
+struct dwc_tasklet {
+	struct tasklet_struct t;
+	dwc_tasklet_callback_t cb;
+	void *data;
+};
+
+static void tasklet_callback(unsigned long data)
+{
+	dwc_tasklet_t *t = (dwc_tasklet_t *)data;
+	t->cb(t->data);
+}
+
+dwc_tasklet_t *DWC_TASK_ALLOC(char *name, dwc_tasklet_callback_t cb, void *data)
+{
+	dwc_tasklet_t *t = DWC_ALLOC(sizeof(*t));
+
+	if (t) {
+		t->cb = cb;
+		t->data = data;
+		tasklet_init(&t->t, tasklet_callback, (unsigned long)t);
+	} else {
+		DWC_ERROR("Cannot allocate memory for tasklet\n");
+	}
+
+	return t;
+}
+
+void DWC_TASK_FREE(dwc_tasklet_t *task)
+{
+	DWC_FREE(task);
+}
+
+void DWC_TASK_SCHEDULE(dwc_tasklet_t *task)
+{
+	tasklet_schedule(&task->t);
+}
+
+
+/* workqueues
+ - run in process context (can sleep)
+ */
+typedef struct work_container {
+	dwc_work_callback_t cb;
+	void *data;
+	dwc_workq_t *wq;
+	char *name;
+
+#ifdef DEBUG
+	DWC_CIRCLEQ_ENTRY(work_container) entry;
+#endif
+	struct delayed_work work;
+} work_container_t;
+
+#ifdef DEBUG
+DWC_CIRCLEQ_HEAD(work_container_queue, work_container);
+#endif
+
+struct dwc_workq {
+	struct workqueue_struct *wq;
+	dwc_spinlock_t *lock;
+	dwc_waitq_t *waitq;
+	int pending;
+
+#ifdef DEBUG
+	struct work_container_queue entries;
+#endif
+};
+
+static void do_work(struct work_struct *work)
+{
+	dwc_irqflags_t flags;
+	struct delayed_work *dw = container_of(work, struct delayed_work, work);
+	work_container_t *container = container_of(dw, struct work_container, work);
+	dwc_workq_t *wq = container->wq;
+
+	container->cb(container->data);
+
+#ifdef DEBUG
+	DWC_CIRCLEQ_REMOVE(&wq->entries, container, entry);
+#endif
+	DWC_DEBUG("Work done: %s, container=%p", container->name, container);
+	if (container->name) {
+		DWC_FREE(container->name);
+	}
+	DWC_FREE(container);
+
+	DWC_SPINLOCK_IRQSAVE(wq->lock, &flags);
+	wq->pending--;
+	DWC_SPINUNLOCK_IRQRESTORE(wq->lock, flags);
+	DWC_WAITQ_TRIGGER(wq->waitq);
+}
+
+static int work_done(void *data)
+{
+	dwc_workq_t *workq = (dwc_workq_t *)data;
+	return workq->pending == 0;
+}
+
+int DWC_WORKQ_WAIT_WORK_DONE(dwc_workq_t *workq, int timeout)
+{
+	return DWC_WAITQ_WAIT_TIMEOUT(workq->waitq, work_done, workq, timeout);
+}
+
+dwc_workq_t *DWC_WORKQ_ALLOC(char *name)
+{
+	dwc_workq_t *wq = DWC_ALLOC(sizeof(*wq));
+
+	if (!wq) {
+		return NULL;
+	}
+
+	wq->wq = create_singlethread_workqueue(name);
+	if (!wq->wq) {
+		goto no_wq;
+	}
+
+	wq->pending = 0;
+
+	wq->lock = DWC_SPINLOCK_ALLOC();
+	if (!wq->lock) {
+		goto no_lock;
+	}
+
+	wq->waitq = DWC_WAITQ_ALLOC();
+	if (!wq->waitq) {
+		goto no_waitq;
+	}
+
+#ifdef DEBUG
+	DWC_CIRCLEQ_INIT(&wq->entries);
+#endif
+	return wq;
+
+ no_waitq:
+	DWC_SPINLOCK_FREE(wq->lock);
+ no_lock:
+	destroy_workqueue(wq->wq);
+ no_wq:
+	DWC_FREE(wq);
+
+	return NULL;
+}
+
+void DWC_WORKQ_FREE(dwc_workq_t *wq)
+{
+#ifdef DEBUG
+	if (wq->pending != 0) {
+		struct work_container *wc;
+		DWC_ERROR("Destroying work queue with pending work");
+		DWC_CIRCLEQ_FOREACH(wc, &wq->entries, entry) {
+			DWC_ERROR("Work %s still pending", wc->name);
+		}
+	}
+#endif
+	destroy_workqueue(wq->wq);
+	DWC_SPINLOCK_FREE(wq->lock);
+	DWC_WAITQ_FREE(wq->waitq);
+	DWC_FREE(wq);
+}
+
+void DWC_WORKQ_SCHEDULE(dwc_workq_t *wq, dwc_work_callback_t cb, void *data,
+			char *format, ...)
+{
+	dwc_irqflags_t flags;
+	work_container_t *container;
+	static char name[128];
+	va_list args;
+
+	va_start(args, format);
+	DWC_VSNPRINTF(name, 128, format, args);
+	va_end(args);
+
+	DWC_SPINLOCK_IRQSAVE(wq->lock, &flags);
+	wq->pending++;
+	DWC_SPINUNLOCK_IRQRESTORE(wq->lock, flags);
+	DWC_WAITQ_TRIGGER(wq->waitq);
+
+	container = DWC_ALLOC_ATOMIC(sizeof(*container));
+	if (!container) {
+		DWC_ERROR("Cannot allocate memory for container\n");
+		return;
+	}
+
+	container->name = DWC_STRDUP(name);
+	if (!container->name) {
+		DWC_ERROR("Cannot allocate memory for container->name\n");
+		DWC_FREE(container);
+		return;
+	}
+
+	container->cb = cb;
+	container->data = data;
+	container->wq = wq;
+	DWC_DEBUG("Queueing work: %s, container=%p", container->name, container);
+	INIT_WORK(&container->work.work, do_work);
+
+#ifdef DEBUG
+	DWC_CIRCLEQ_INSERT_TAIL(&wq->entries, container, entry);
+#endif
+	queue_work(wq->wq, &container->work.work);
+}
+
+void DWC_WORKQ_SCHEDULE_DELAYED(dwc_workq_t *wq, dwc_work_callback_t cb,
+				void *data, uint32_t time, char *format, ...)
+{
+	dwc_irqflags_t flags;
+	work_container_t *container;
+	static char name[128];
+	va_list args;
+
+	va_start(args, format);
+	DWC_VSNPRINTF(name, 128, format, args);
+	va_end(args);
+
+	DWC_SPINLOCK_IRQSAVE(wq->lock, &flags);
+	wq->pending++;
+	DWC_SPINUNLOCK_IRQRESTORE(wq->lock, flags);
+	DWC_WAITQ_TRIGGER(wq->waitq);
+
+	container = DWC_ALLOC_ATOMIC(sizeof(*container));
+	if (!container) {
+		DWC_ERROR("Cannot allocate memory for container\n");
+		return;
+	}
+
+	container->name = DWC_STRDUP(name);
+	if (!container->name) {
+		DWC_ERROR("Cannot allocate memory for container->name\n");
+		DWC_FREE(container);
+		return;
+	}
+
+	container->cb = cb;
+	container->data = data;
+	container->wq = wq;
+	DWC_DEBUG("Queueing work: %s, container=%p", container->name, container);
+	INIT_DELAYED_WORK(&container->work, do_work);
+
+#ifdef DEBUG
+	DWC_CIRCLEQ_INSERT_TAIL(&wq->entries, container, entry);
+#endif
+	queue_delayed_work(wq->wq, &container->work, msecs_to_jiffies(time));
+}
+
+int DWC_WORKQ_PENDING(dwc_workq_t *wq)
+{
+	return wq->pending;
+}
+
+
+#ifdef DWC_LIBMODULE
+
+#ifdef DWC_CCLIB
+/* CC */
+EXPORT_SYMBOL(dwc_cc_if_alloc);
+EXPORT_SYMBOL(dwc_cc_if_free);
+EXPORT_SYMBOL(dwc_cc_clear);
+EXPORT_SYMBOL(dwc_cc_add);
+EXPORT_SYMBOL(dwc_cc_remove);
+EXPORT_SYMBOL(dwc_cc_change);
+EXPORT_SYMBOL(dwc_cc_data_for_save);
+EXPORT_SYMBOL(dwc_cc_restore_from_data);
+EXPORT_SYMBOL(dwc_cc_match_chid);
+EXPORT_SYMBOL(dwc_cc_match_cdid);
+EXPORT_SYMBOL(dwc_cc_ck);
+EXPORT_SYMBOL(dwc_cc_chid);
+EXPORT_SYMBOL(dwc_cc_cdid);
+EXPORT_SYMBOL(dwc_cc_name);
+#endif	/* DWC_CCLIB */
+
+#ifdef DWC_CRYPTOLIB
+# ifndef CONFIG_MACH_IPMATE
+/* Modpow */
+EXPORT_SYMBOL(dwc_modpow);
+
+/* DH */
+EXPORT_SYMBOL(dwc_dh_modpow);
+EXPORT_SYMBOL(dwc_dh_derive_keys);
+EXPORT_SYMBOL(dwc_dh_pk);
+# endif	/* CONFIG_MACH_IPMATE */
+
+/* Crypto */
+EXPORT_SYMBOL(dwc_wusb_aes_encrypt);
+EXPORT_SYMBOL(dwc_wusb_cmf);
+EXPORT_SYMBOL(dwc_wusb_prf);
+EXPORT_SYMBOL(dwc_wusb_fill_ccm_nonce);
+EXPORT_SYMBOL(dwc_wusb_gen_nonce);
+EXPORT_SYMBOL(dwc_wusb_gen_key);
+EXPORT_SYMBOL(dwc_wusb_gen_mic);
+#endif	/* DWC_CRYPTOLIB */
+
+/* Notification */
+#ifdef DWC_NOTIFYLIB
+EXPORT_SYMBOL(dwc_alloc_notification_manager);
+EXPORT_SYMBOL(dwc_free_notification_manager);
+EXPORT_SYMBOL(dwc_register_notifier);
+EXPORT_SYMBOL(dwc_unregister_notifier);
+EXPORT_SYMBOL(dwc_add_observer);
+EXPORT_SYMBOL(dwc_remove_observer);
+EXPORT_SYMBOL(dwc_notify);
+#endif
+
+/* Memory Debugging Routines */
+#ifdef DWC_DEBUG_MEMORY
+EXPORT_SYMBOL(dwc_alloc_debug);
+EXPORT_SYMBOL(dwc_alloc_atomic_debug);
+EXPORT_SYMBOL(dwc_free_debug);
+EXPORT_SYMBOL(dwc_dma_alloc_debug);
+EXPORT_SYMBOL(dwc_dma_free_debug);
+#endif
+
+EXPORT_SYMBOL(DWC_MEMSET);
+EXPORT_SYMBOL(DWC_MEMCPY);
+EXPORT_SYMBOL(DWC_MEMMOVE);
+EXPORT_SYMBOL(DWC_MEMCMP);
+EXPORT_SYMBOL(DWC_STRNCMP);
+EXPORT_SYMBOL(DWC_STRCMP);
+EXPORT_SYMBOL(DWC_STRLEN);
+EXPORT_SYMBOL(DWC_STRCPY);
+EXPORT_SYMBOL(DWC_STRDUP);
+EXPORT_SYMBOL(DWC_ATOI);
+EXPORT_SYMBOL(DWC_ATOUI);
+
+#ifdef DWC_UTFLIB
+EXPORT_SYMBOL(DWC_UTF8_TO_UTF16LE);
+#endif	/* DWC_UTFLIB */
+
+EXPORT_SYMBOL(DWC_IN_IRQ);
+EXPORT_SYMBOL(DWC_IN_BH);
+EXPORT_SYMBOL(DWC_VPRINTF);
+EXPORT_SYMBOL(DWC_VSNPRINTF);
+EXPORT_SYMBOL(DWC_PRINTF);
+EXPORT_SYMBOL(DWC_SPRINTF);
+EXPORT_SYMBOL(DWC_SNPRINTF);
+EXPORT_SYMBOL(__DWC_WARN);
+EXPORT_SYMBOL(__DWC_ERROR);
+EXPORT_SYMBOL(DWC_EXCEPTION);
+
+#ifdef DEBUG
+EXPORT_SYMBOL(__DWC_DEBUG);
+#endif
+
+EXPORT_SYMBOL(__DWC_DMA_ALLOC);
+EXPORT_SYMBOL(__DWC_DMA_ALLOC_ATOMIC);
+EXPORT_SYMBOL(__DWC_DMA_FREE);
+EXPORT_SYMBOL(__DWC_ALLOC);
+EXPORT_SYMBOL(__DWC_ALLOC_ATOMIC);
+EXPORT_SYMBOL(__DWC_FREE);
+
+#ifdef DWC_CRYPTOLIB
+EXPORT_SYMBOL(DWC_RANDOM_BYTES);
+EXPORT_SYMBOL(DWC_AES_CBC);
+EXPORT_SYMBOL(DWC_SHA256);
+EXPORT_SYMBOL(DWC_HMAC_SHA256);
+#endif
+
+EXPORT_SYMBOL(DWC_CPU_TO_LE32);
+EXPORT_SYMBOL(DWC_CPU_TO_BE32);
+EXPORT_SYMBOL(DWC_LE32_TO_CPU);
+EXPORT_SYMBOL(DWC_BE32_TO_CPU);
+EXPORT_SYMBOL(DWC_CPU_TO_LE16);
+EXPORT_SYMBOL(DWC_CPU_TO_BE16);
+EXPORT_SYMBOL(DWC_LE16_TO_CPU);
+EXPORT_SYMBOL(DWC_BE16_TO_CPU);
+EXPORT_SYMBOL(DWC_READ_REG32);
+EXPORT_SYMBOL(DWC_WRITE_REG32);
+EXPORT_SYMBOL(DWC_MODIFY_REG32);
+
+EXPORT_SYMBOL(DWC_SPINLOCK_ALLOC);
+EXPORT_SYMBOL(DWC_SPINLOCK_FREE);
+EXPORT_SYMBOL(DWC_SPINLOCK);
+EXPORT_SYMBOL(DWC_SPINUNLOCK);
+EXPORT_SYMBOL(DWC_SPINLOCK_IRQSAVE);
+EXPORT_SYMBOL(DWC_SPINUNLOCK_IRQRESTORE);
+EXPORT_SYMBOL(DWC_MUTEX_ALLOC);
+
+#if (!defined(DWC_LINUX) || !defined(CONFIG_DEBUG_MUTEXES))
+EXPORT_SYMBOL(DWC_MUTEX_FREE);
+#endif
+
+EXPORT_SYMBOL(DWC_MUTEX_LOCK);
+EXPORT_SYMBOL(DWC_MUTEX_TRYLOCK);
+EXPORT_SYMBOL(DWC_MUTEX_UNLOCK);
+EXPORT_SYMBOL(DWC_UDELAY);
+EXPORT_SYMBOL(DWC_MDELAY);
+EXPORT_SYMBOL(DWC_MSLEEP);
+EXPORT_SYMBOL(DWC_TIME);
+EXPORT_SYMBOL(DWC_TIMER_ALLOC);
+EXPORT_SYMBOL(DWC_TIMER_FREE);
+EXPORT_SYMBOL(DWC_TIMER_SCHEDULE);
+EXPORT_SYMBOL(DWC_TIMER_CANCEL);
+EXPORT_SYMBOL(DWC_WAITQ_ALLOC);
+EXPORT_SYMBOL(DWC_WAITQ_FREE);
+EXPORT_SYMBOL(DWC_WAITQ_WAIT);
+EXPORT_SYMBOL(DWC_WAITQ_WAIT_TIMEOUT);
+EXPORT_SYMBOL(DWC_WAITQ_TRIGGER);
+EXPORT_SYMBOL(DWC_WAITQ_ABORT);
+EXPORT_SYMBOL(DWC_THREAD_RUN);
+EXPORT_SYMBOL(DWC_THREAD_STOP);
+EXPORT_SYMBOL(DWC_THREAD_SHOULD_STOP);
+EXPORT_SYMBOL(DWC_TASK_ALLOC);
+EXPORT_SYMBOL(DWC_TASK_FREE);
+EXPORT_SYMBOL(DWC_TASK_SCHEDULE);
+EXPORT_SYMBOL(DWC_WORKQ_WAIT_WORK_DONE);
+EXPORT_SYMBOL(DWC_WORKQ_ALLOC);
+EXPORT_SYMBOL(DWC_WORKQ_FREE);
+EXPORT_SYMBOL(DWC_WORKQ_SCHEDULE);
+EXPORT_SYMBOL(DWC_WORKQ_SCHEDULE_DELAYED);
+EXPORT_SYMBOL(DWC_WORKQ_PENDING);
+
+static int dwc_common_port_init_module(void)
+{
+	int result = 0;
+
+	printk(KERN_DEBUG "Module dwc_common_port init\n" );
+
+#ifdef DWC_DEBUG_MEMORY
+	result = dwc_memory_debug_start(NULL);
+	if (result) {
+		printk(KERN_ERR
+		       "dwc_memory_debug_start() failed with error %d\n",
+		       result);
+		return result;
+	}
+#endif
+
+#ifdef DWC_NOTIFYLIB
+	result = dwc_alloc_notification_manager(NULL, NULL);
+	if (result) {
+		printk(KERN_ERR
+		       "dwc_alloc_notification_manager() failed with error %d\n",
+		       result);
+		return result;
+	}
+#endif
+	return result;
+}
+
+static void dwc_common_port_exit_module(void)
+{
+	printk(KERN_DEBUG "Module dwc_common_port exit\n" );
+
+#ifdef DWC_NOTIFYLIB
+	dwc_free_notification_manager();
+#endif
+
+#ifdef DWC_DEBUG_MEMORY
+	dwc_memory_debug_stop();
+#endif
+}
+
+module_init(dwc_common_port_init_module);
+module_exit(dwc_common_port_exit_module);
+
+MODULE_DESCRIPTION("DWC Common Library - Portable version");
+MODULE_AUTHOR("Synopsys Inc.");
+MODULE_LICENSE ("GPL");
+
+#endif	/* DWC_LIBMODULE */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_crypto.c b/drivers/usb/gadget/udc/hiudc/dwc_crypto.c
new file mode 100644
index 0000000..3b03532
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_crypto.c
@@ -0,0 +1,308 @@
+/* =========================================================================
+ * $File: //dwh/usb_iip/dev/software/dwc_common_port_2/dwc_crypto.c $
+ * $Revision: #5 $
+ * $Date: 2010/09/28 $
+ * $Change: 1596182 $
+ *
+ * Synopsys Portability Library Software and documentation
+ * (hereinafter, "Software") is an Unsupported proprietary work of
+ * Synopsys, Inc. unless otherwise expressly agreed to in writing
+ * between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product
+ * under any End User Software License Agreement or Agreement for
+ * Licensed Product with Synopsys or any supplement thereto. You are
+ * permitted to use and redistribute this Software in source and binary
+ * forms, with or without modification, provided that redistributions
+ * of source code must retain this notice. You may not view, use,
+ * disclose, copy or distribute this file or any information contained
+ * herein except pursuant to this license grant from Synopsys. If you
+ * do not agree with this notice, including the disclaimer below, then
+ * you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS"
+ * BASIS AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+ * FOR A PARTICULAR PURPOSE ARE HEREBY DISCLAIMED. IN NO EVENT SHALL
+ * SYNOPSYS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ * USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================= */
+
+/** @file
+ * This file contains the WUSB cryptographic routines.
+ */
+
+#ifdef DWC_CRYPTOLIB
+
+#include "dwc_crypto.h"
+#include "usb.h"
+
+#ifdef DEBUG
+static inline void dump_bytes(char *name, uint8_t *bytes, int len)
+{
+	int i;
+	DWC_PRINTF("%s: ", name);
+	for (i=0; i<len; i++) {
+		DWC_PRINTF("%02x ", bytes[i]);
+	}
+	DWC_PRINTF("\n");
+}
+#else
+#define dump_bytes(x...)
+#endif
+
+/* Display a block */
+void show_block(const u8 *blk, const char *prefix, const char *suffix, int a)
+{
+#ifdef DWC_DEBUG_CRYPTO
+	int i, blksize = 16;
+
+	DWC_DEBUG("%s", prefix);
+
+	if (suffix == NULL) {
+		suffix = "\n";
+		blksize = a;
+	}
+
+	for (i = 0; i < blksize; i++)
+		DWC_PRINT("%02x%s", *blk++, ((i & 3) == 3) ? "  " : " ");
+	DWC_PRINT(suffix);
+#endif
+}
+
+/**
+ * Encrypts an array of bytes using the AES encryption engine.
+ * If <code>dst</code> == <code>src</code>, then the bytes will be encrypted
+ * in-place.
+ *
+ * @return  0 on success, negative error code on error.
+ */
+int dwc_wusb_aes_encrypt(u8 *src, u8 *key, u8 *dst)
+{
+	u8 block_t[16];
+	DWC_MEMSET(block_t, 0, 16);
+
+	return DWC_AES_CBC(src, 16, key, 16, block_t, dst);
+}
+
+/**
+ * The CCM-MAC-FUNCTION described in section 6.5 of the WUSB spec.
+ * This function takes a data string and returns the encrypted CBC
+ * Counter-mode MIC.
+ *
+ * @param key     The 128-bit symmetric key.
+ * @param nonce   The CCM nonce.
+ * @param label   The unique 14-byte ASCII text label.
+ * @param bytes   The byte array to be encrypted.
+ * @param len     Length of the byte array.
+ * @param result  Byte array to receive the 8-byte encrypted MIC.
+ */
+void dwc_wusb_cmf(u8 *key, u8 *nonce,
+		  char *label, u8 *bytes, int len, u8 *result)
+{
+	u8 block_m[16];
+	u8 block_x[16];
+	u8 block_t[8];
+	int idx, blkNum;
+	u16 la = (u16)(len + 14);
+
+	/* Set the AES-128 key */
+	//dwc_aes_setkey(tfm, key, 16);
+
+	/* Fill block B0 from flags = 0x59, N, and l(m) = 0 */
+	block_m[0] = 0x59;
+	for (idx = 0; idx < 13; idx++)
+		block_m[idx + 1] = nonce[idx];
+	block_m[14] = 0;
+	block_m[15] = 0;
+
+	/* Produce the CBC IV */
+	dwc_wusb_aes_encrypt(block_m, key, block_x);
+	show_block(block_m, "CBC IV in: ", "\n", 0);
+	show_block(block_x, "CBC IV out:", "\n", 0);
+
+	/* Fill block B1 from l(a) = Blen + 14, and A */
+	block_x[0] ^= (u8)(la >> 8);
+	block_x[1] ^= (u8)la;
+	for (idx = 0; idx < 14; idx++)
+		block_x[idx + 2] ^= label[idx];
+	show_block(block_x, "After xor: ", "b1\n", 16);
+
+	dwc_wusb_aes_encrypt(block_x, key, block_x);
+	show_block(block_x, "After AES: ", "b1\n", 16);
+
+	idx = 0;
+	blkNum = 0;
+
+	/* Fill remaining blocks with B */
+	while (len-- > 0) {
+		block_x[idx] ^= *bytes++;
+		if (++idx >= 16) {
+			idx = 0;
+			show_block(block_x, "After xor: ", "\n", blkNum);
+			dwc_wusb_aes_encrypt(block_x, key, block_x);
+			show_block(block_x, "After AES: ", "\n", blkNum);
+			blkNum++;
+		}
+	}
+
+	/* Handle partial last block */
+	if (idx > 0) {
+		show_block(block_x, "After xor: ", "\n", blkNum);
+		dwc_wusb_aes_encrypt(block_x, key, block_x);
+		show_block(block_x, "After AES: ", "\n", blkNum);
+	}
+
+	/* Save the MIC tag */
+	DWC_MEMCPY(block_t, block_x, 8);
+	show_block(block_t, "MIC tag  : ", NULL, 8);
+
+	/* Fill block A0 from flags = 0x01, N, and counter = 0 */
+	block_m[0] = 0x01;
+	block_m[14] = 0;
+	block_m[15] = 0;
+
+	/* Encrypt the counter */
+	dwc_wusb_aes_encrypt(block_m, key, block_x);
+	show_block(block_x, "CTR[MIC] : ", NULL, 8);
+
+	/* XOR with MIC tag */
+	for (idx = 0; idx < 8; idx++) {
+		block_t[idx] ^= block_x[idx];
+	}
+
+	/* Return result to caller */
+	DWC_MEMCPY(result, block_t, 8);
+	show_block(result, "CCM-MIC  : ", NULL, 8);
+
+}
+
+/**
+ * The PRF function described in section 6.5 of the WUSB spec. This function
+ * concatenates MIC values returned from dwc_cmf() to create a value of
+ * the requested length.
+ *
+ * @param prf_len  Length of the PRF function in bits (64, 128, or 256).
+ * @param key, nonce, label, bytes, len  Same as for dwc_cmf().
+ * @param result   Byte array to receive the result.
+ */
+void dwc_wusb_prf(int prf_len, u8 *key,
+		  u8 *nonce, char *label, u8 *bytes, int len, u8 *result)
+{
+	int i;
+
+	nonce[0] = 0;
+	for (i = 0; i < prf_len >> 6; i++, nonce[0]++) {
+		dwc_wusb_cmf(key, nonce, label, bytes, len, result);
+		result += 8;
+	}
+}
+
+/**
+ * Fills in CCM Nonce per the WUSB spec.
+ *
+ * @param[in] haddr Host address.
+ * @param[in] daddr Device address.
+ * @param[in] tkid Session Key(PTK) identifier.
+ * @param[out] nonce Pointer to where the CCM Nonce output is to be written.
+ */
+void dwc_wusb_fill_ccm_nonce(uint16_t haddr, uint16_t daddr, uint8_t *tkid,
+			     uint8_t *nonce)
+{
+
+	DWC_DEBUG("%s %x %x\n", __func__, daddr, haddr);
+
+	DWC_MEMSET(&nonce[0], 0, 16);
+
+	DWC_MEMCPY(&nonce[6], tkid, 3);
+	nonce[9] = daddr & 0xFF;
+	nonce[10] = (daddr >> 8) & 0xFF;
+	nonce[11] = haddr & 0xFF;
+	nonce[12] = (haddr >> 8) & 0xFF;
+
+	dump_bytes("CCM nonce", nonce, 16);
+}
+
+/**
+ * Generates a 16-byte cryptographic-grade random number for the Host/Device
+ * Nonce.
+ */
+void dwc_wusb_gen_nonce(uint16_t addr, uint8_t *nonce)
+{
+	uint8_t inonce[16];
+	uint32_t temp[4];
+
+	/* Fill in the Nonce */
+	DWC_MEMSET(&inonce[0], 0, sizeof(inonce));
+	inonce[9] = addr & 0xFF;
+	inonce[10] = (addr >> 8) & 0xFF;
+	inonce[11] = inonce[9];
+	inonce[12] = inonce[10];
+
+	/* Collect "randomness samples" */
+	DWC_RANDOM_BYTES((uint8_t *)temp, 16);
+
+	dwc_wusb_prf_128((uint8_t *)temp, nonce,
+			 "Random Numbers", (uint8_t *)temp, sizeof(temp),
+			 nonce);
+}
+
+/**
+ * Generates the Session Key (PTK) and Key Confirmation Key (KCK) per the
+ * WUSB spec.
+ *
+ * @param[in] ccm_nonce Pointer to CCM Nonce.
+ * @param[in] mk Master Key to derive the session from
+ * @param[in] hnonce Pointer to Host Nonce.
+ * @param[in] dnonce Pointer to Device Nonce.
+ * @param[out] kck Pointer to where the KCK output is to be written.
+ * @param[out] ptk Pointer to where the PTK output is to be written.
+ */
+void dwc_wusb_gen_key(uint8_t *ccm_nonce, uint8_t *mk, uint8_t *hnonce,
+		      uint8_t *dnonce, uint8_t *kck, uint8_t *ptk)
+{
+	uint8_t idata[32];
+	uint8_t odata[32];
+
+	dump_bytes("ck", mk, 16);
+	dump_bytes("hnonce", hnonce, 16);
+	dump_bytes("dnonce", dnonce, 16);
+
+	/* The data is the HNonce and DNonce concatenated */
+	DWC_MEMCPY(&idata[0], hnonce, 16);
+	DWC_MEMCPY(&idata[16], dnonce, 16);
+
+	dwc_wusb_prf_256(mk, ccm_nonce, "Pair-wise keys", idata, 32, odata);
+
+	/* Low 16 bytes of the result is the KCK, high 16 is the PTK */
+	DWC_MEMCPY(kck, &odata[0], 16);
+	DWC_MEMCPY(ptk, &odata[16], 16);
+
+	dump_bytes("kck", kck, 16);
+	dump_bytes("ptk", ptk, 16);
+}
+
+/**
+ * Generates the Message Integrity Code over the Handshake data per the
+ * WUSB spec.
+ *
+ * @param ccm_nonce Pointer to CCM Nonce.
+ * @param kck   Pointer to Key Confirmation Key.
+ * @param data  Pointer to Handshake data to be checked.
+ * @param mic   Pointer to where the MIC output is to be written.
+ */
+void dwc_wusb_gen_mic(uint8_t *ccm_nonce, uint8_t *kck,
+		      uint8_t *data, uint8_t *mic)
+{
+
+	dwc_wusb_prf_64(kck, ccm_nonce, "out-of-bandMIC",
+			data, WUSB_HANDSHAKE_LEN_FOR_MIC, mic);
+}
+
+#endif	/* DWC_CRYPTOLIB */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_crypto.h b/drivers/usb/gadget/udc/hiudc/dwc_crypto.h
new file mode 100644
index 0000000..26fcddc
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_crypto.h
@@ -0,0 +1,111 @@
+/* =========================================================================
+ * $File: //dwh/usb_iip/dev/software/dwc_common_port_2/dwc_crypto.h $
+ * $Revision: #3 $
+ * $Date: 2010/09/28 $
+ * $Change: 1596182 $
+ *
+ * Synopsys Portability Library Software and documentation
+ * (hereinafter, "Software") is an Unsupported proprietary work of
+ * Synopsys, Inc. unless otherwise expressly agreed to in writing
+ * between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product
+ * under any End User Software License Agreement or Agreement for
+ * Licensed Product with Synopsys or any supplement thereto. You are
+ * permitted to use and redistribute this Software in source and binary
+ * forms, with or without modification, provided that redistributions
+ * of source code must retain this notice. You may not view, use,
+ * disclose, copy or distribute this file or any information contained
+ * herein except pursuant to this license grant from Synopsys. If you
+ * do not agree with this notice, including the disclaimer below, then
+ * you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS"
+ * BASIS AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+ * FOR A PARTICULAR PURPOSE ARE HEREBY DISCLAIMED. IN NO EVENT SHALL
+ * SYNOPSYS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ * USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================= */
+
+#ifndef _DWC_CRYPTO_H_
+#define _DWC_CRYPTO_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/** @file
+ *
+ * This file contains declarations for the WUSB Cryptographic routines as
+ * defined in the WUSB spec.  They are only to be used internally by the DWC UWB
+ * modules.
+ */
+
+#include "dwc_os.h"
+
+int dwc_wusb_aes_encrypt(u8 *src, u8 *key, u8 *dst);
+
+void dwc_wusb_cmf(u8 *key, u8 *nonce,
+		  char *label, u8 *bytes, int len, u8 *result);
+void dwc_wusb_prf(int prf_len, u8 *key,
+		  u8 *nonce, char *label, u8 *bytes, int len, u8 *result);
+
+/**
+ * The PRF-64 function described in section 6.5 of the WUSB spec.
+ *
+ * @param key, nonce, label, bytes, len, result  Same as for dwc_prf().
+ */
+static inline void dwc_wusb_prf_64(u8 *key, u8 *nonce,
+				   char *label, u8 *bytes, int len, u8 *result)
+{
+	dwc_wusb_prf(64, key, nonce, label, bytes, len, result);
+}
+
+/**
+ * The PRF-128 function described in section 6.5 of the WUSB spec.
+ *
+ * @param key, nonce, label, bytes, len, result  Same as for dwc_prf().
+ */
+static inline void dwc_wusb_prf_128(u8 *key, u8 *nonce,
+				    char *label, u8 *bytes, int len, u8 *result)
+{
+	dwc_wusb_prf(128, key, nonce, label, bytes, len, result);
+}
+
+/**
+ * The PRF-256 function described in section 6.5 of the WUSB spec.
+ *
+ * @param key, nonce, label, bytes, len, result  Same as for dwc_prf().
+ */
+static inline void dwc_wusb_prf_256(u8 *key, u8 *nonce,
+				    char *label, u8 *bytes, int len, u8 *result)
+{
+	dwc_wusb_prf(256, key, nonce, label, bytes, len, result);
+}
+
+
+void dwc_wusb_fill_ccm_nonce(uint16_t haddr, uint16_t daddr, uint8_t *tkid,
+			       uint8_t *nonce);
+void dwc_wusb_gen_nonce(uint16_t addr,
+			  uint8_t *nonce);
+
+void dwc_wusb_gen_key(uint8_t *ccm_nonce, uint8_t *mk,
+			uint8_t *hnonce, uint8_t *dnonce,
+			uint8_t *kck, uint8_t *ptk);
+
+
+void dwc_wusb_gen_mic(uint8_t *ccm_nonce, uint8_t
+			*kck, uint8_t *data, uint8_t *mic);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _DWC_CRYPTO_H_ */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_dh.c b/drivers/usb/gadget/udc/hiudc/dwc_dh.c
new file mode 100644
index 0000000..2b429a3
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_dh.c
@@ -0,0 +1,291 @@
+/* =========================================================================
+ * $File: //dwh/usb_iip/dev/software/dwc_common_port_2/dwc_dh.c $
+ * $Revision: #3 $
+ * $Date: 2010/09/28 $
+ * $Change: 1596182 $
+ *
+ * Synopsys Portability Library Software and documentation
+ * (hereinafter, "Software") is an Unsupported proprietary work of
+ * Synopsys, Inc. unless otherwise expressly agreed to in writing
+ * between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product
+ * under any End User Software License Agreement or Agreement for
+ * Licensed Product with Synopsys or any supplement thereto. You are
+ * permitted to use and redistribute this Software in source and binary
+ * forms, with or without modification, provided that redistributions
+ * of source code must retain this notice. You may not view, use,
+ * disclose, copy or distribute this file or any information contained
+ * herein except pursuant to this license grant from Synopsys. If you
+ * do not agree with this notice, including the disclaimer below, then
+ * you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS"
+ * BASIS AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+ * FOR A PARTICULAR PURPOSE ARE HEREBY DISCLAIMED. IN NO EVENT SHALL
+ * SYNOPSYS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ * USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================= */
+#ifdef DWC_CRYPTOLIB
+
+#ifndef CONFIG_MACH_IPMATE
+
+#include "dwc_dh.h"
+#include "dwc_modpow.h"
+
+#ifdef DEBUG
+/* This function prints out a buffer in the format described in the Association
+ * Model specification. */
+static void dh_dump(char *str, void *_num, int len)
+{
+	uint8_t *num = _num;
+	int i;
+	DWC_PRINTF("%s\n", str);
+	for (i = 0; i < len; i ++) {
+		DWC_PRINTF("%02x", num[i]);
+		if (((i + 1) % 2) == 0) DWC_PRINTF(" ");
+		if (((i + 1) % 26) == 0) DWC_PRINTF("\n");
+	}
+
+	DWC_PRINTF("\n");
+}
+#else
+#define dh_dump(_x...) do {; } while(0)
+#endif
+
+/* Constant g value */
+static __u32 dh_g[] = {
+	0x02000000,
+};
+
+/* Constant p value */
+static __u32 dh_p[] = {
+	0xFFFFFFFF, 0xFFFFFFFF, 0xA2DA0FC9, 0x34C26821, 0x8B62C6C4, 0xD11CDC80, 0x084E0229, 0x74CC678A,
+	0xA6BE0B02, 0x229B133B, 0x79084A51, 0xDD04348E, 0xB31995EF, 0x1B433ACD, 0x6D0A2B30, 0x37145FF2,
+	0x6D35E14F, 0x45C2516D, 0x76B585E4, 0xC67E5E62, 0xE9424CF4, 0x6BED37A6, 0xB65CFF0B, 0xEDB706F4,
+	0xFB6B38EE, 0xA59F895A, 0x11249FAE, 0xE61F4B7C, 0x51662849, 0x3D5BE4EC, 0xB87C00C2, 0x05BF63A1,
+	0x3648DA98, 0x9AD3551C, 0xA83F1669, 0x5FCF24FD, 0x235D6583, 0x96ADA3DC, 0x56F3621C, 0xBB528520,
+	0x0729D59E, 0x6D969670, 0x4E350C67, 0x0498BC4A, 0x086C74F1, 0x7C2118CA, 0x465E9032, 0x3BCE362E,
+	0x2C779EE3, 0x03860E18, 0xA283279B, 0x8FA207EC, 0xF05DC5B5, 0xC9524C6F, 0xF6CB2BDE, 0x18175895,
+	0x7C499539, 0xE56A95EA, 0x1826D215, 0x1005FA98, 0x5A8E7215, 0x2DC4AA8A, 0x0D1733AD, 0x337A5004,
+	0xAB2155A8, 0x64BA1CDF, 0x0485FBEC, 0x0AEFDB58, 0x5771EA8A, 0x7D0C065D, 0x850F97B3, 0xC7E4E1A6,
+	0x8CAEF5AB, 0xD73309DB, 0xE0948C1E, 0x9D61254A, 0x26D2E3CE, 0x6BEED21A, 0x06FA2FF1, 0x64088AD9,
+	0x730276D8, 0x646AC83E, 0x182B1F52, 0x0C207B17, 0x5717E1BB, 0x6C5D617A, 0xC0880977, 0xE246D9BA,
+	0xA04FE208, 0x31ABE574, 0xFC5BDB43, 0x8E10FDE0, 0x20D1824B, 0xCAD23AA9, 0xFFFFFFFF, 0xFFFFFFFF,
+};
+
+static void dh_swap_bytes(void *_in, void *_out, uint32_t len)
+{
+	uint8_t *in = _in;
+	uint8_t *out = _out;
+	int i;
+	for (i=0; i<len; i++) {
+		out[i] = in[len-1-i];
+	}
+}
+
+/* Computes the modular exponentiation (num^exp % mod).  num, exp, and mod are
+ * big endian numbers of size len, in bytes.  Each len value must be a multiple
+ * of 4. */
+int dwc_dh_modpow(void *mem_ctx, void *num, uint32_t num_len,
+		  void *exp, uint32_t exp_len,
+		  void *mod, uint32_t mod_len,
+		  void *out)
+{
+	/* modpow() takes little endian numbers.  AM uses big-endian.  This
+	 * function swaps bytes of numbers before passing onto modpow. */
+
+	int retval = 0;
+	uint32_t *result;
+
+	uint32_t *bignum_num = dwc_alloc(mem_ctx, num_len + 4);
+	uint32_t *bignum_exp = dwc_alloc(mem_ctx, exp_len + 4);
+	uint32_t *bignum_mod = dwc_alloc(mem_ctx, mod_len + 4);
+
+	dh_swap_bytes(num, &bignum_num[1], num_len);
+	bignum_num[0] = num_len / 4;
+
+	dh_swap_bytes(exp, &bignum_exp[1], exp_len);
+	bignum_exp[0] = exp_len / 4;
+
+	dh_swap_bytes(mod, &bignum_mod[1], mod_len);
+	bignum_mod[0] = mod_len / 4;
+
+	result = dwc_modpow(mem_ctx, bignum_num, bignum_exp, bignum_mod);
+	if (!result) {
+		retval = -1;
+		goto dh_modpow_nomem;
+	}
+
+	dh_swap_bytes(&result[1], out, result[0] * 4);
+	dwc_free(mem_ctx, result);
+
+ dh_modpow_nomem:
+	dwc_free(mem_ctx, bignum_num);
+	dwc_free(mem_ctx, bignum_exp);
+	dwc_free(mem_ctx, bignum_mod);
+	return retval;
+}
+
+
+int dwc_dh_pk(void *mem_ctx, uint8_t nd, uint8_t *exp, uint8_t *pk, uint8_t *hash)
+{
+	int retval;
+	uint8_t m3[385];
+
+#ifndef DH_TEST_VECTORS
+	DWC_RANDOM_BYTES(exp, 32);
+#endif
+
+	/* Compute the pkd */
+	if ((retval = dwc_dh_modpow(mem_ctx, dh_g, 4,
+				    exp, 32,
+				    dh_p, 384, pk))) {
+		return retval;
+	}
+
+	m3[384] = nd;
+	DWC_MEMCPY(&m3[0], pk, 384);
+	DWC_SHA256(m3, 385, hash);
+
+	dh_dump("PK", pk, 384);
+	dh_dump("SHA-256(M3)", hash, 32);
+	return 0;
+}
+
+int dwc_dh_derive_keys(void *mem_ctx, uint8_t nd, uint8_t *pkh, uint8_t *pkd,
+		       uint8_t *exp, int is_host,
+		       char *dd, uint8_t *ck, uint8_t *kdk)
+{
+	int retval;
+	uint8_t mv[784];
+	uint8_t sha_result[32];
+	uint8_t dhkey[384];
+	uint8_t shared_secret[384];
+	char *message;
+	uint32_t vd;
+
+	uint8_t *pk;
+
+	if (is_host) {
+		pk = pkd;
+	}
+	else {
+		pk = pkh;
+	}
+
+	if ((retval = dwc_dh_modpow(mem_ctx, pk, 384,
+				    exp, 32,
+				    dh_p, 384, shared_secret))) {
+		return retval;
+	}
+	dh_dump("Shared Secret", shared_secret, 384);
+
+	DWC_SHA256(shared_secret, 384, dhkey);
+	dh_dump("DHKEY", dhkey, 384);
+
+	DWC_MEMCPY(&mv[0], pkd, 384);
+	DWC_MEMCPY(&mv[384], pkh, 384);
+	DWC_MEMCPY(&mv[768], "displayed digest", 16);
+	dh_dump("MV", mv, 784);
+
+	DWC_SHA256(mv, 784, sha_result);
+	dh_dump("SHA-256(MV)", sha_result, 32);
+	dh_dump("First 32-bits of SHA-256(MV)", sha_result, 4);
+
+	dh_swap_bytes(sha_result, &vd, 4);
+#ifdef DEBUG
+	DWC_PRINTF("Vd (decimal) = %d\n", vd);
+#endif
+
+	switch (nd) {
+	case 2:
+		vd = vd % 100;
+		DWC_SPRINTF(dd, "%02d", vd);
+		break;
+	case 3:
+		vd = vd % 1000;
+		DWC_SPRINTF(dd, "%03d", vd);
+		break;
+	case 4:
+		vd = vd % 10000;
+		DWC_SPRINTF(dd, "%04d", vd);
+		break;
+	}
+#ifdef DEBUG
+	DWC_PRINTF("Display Digits: %s\n", dd);
+#endif
+
+	message = "connection key";
+	DWC_HMAC_SHA256(message, DWC_STRLEN(message), dhkey, 32, sha_result);
+	dh_dump("HMAC(SHA-256, DHKey, connection key)", sha_result, 32);
+	DWC_MEMCPY(ck, sha_result, 16);
+
+	message = "key derivation key";
+	DWC_HMAC_SHA256(message, DWC_STRLEN(message), dhkey, 32, sha_result);
+	dh_dump("HMAC(SHA-256, DHKey, key derivation key)", sha_result, 32);
+	DWC_MEMCPY(kdk, sha_result, 32);
+
+	return 0;
+}
+
+
+#ifdef DH_TEST_VECTORS
+
+static __u8 dh_a[] = {
+	0x44, 0x00, 0x51, 0xd6,
+	0xf0, 0xb5, 0x5e, 0xa9,
+	0x67, 0xab, 0x31, 0xc6,
+	0x8a, 0x8b, 0x5e, 0x37,
+	0xd9, 0x10, 0xda, 0xe0,
+	0xe2, 0xd4, 0x59, 0xa4,
+	0x86, 0x45, 0x9c, 0xaa,
+	0xdf, 0x36, 0x75, 0x16,
+};
+
+static __u8 dh_b[] = {
+	0x5d, 0xae, 0xc7, 0x86,
+	0x79, 0x80, 0xa3, 0x24,
+	0x8c, 0xe3, 0x57, 0x8f,
+	0xc7, 0x5f, 0x1b, 0x0f,
+	0x2d, 0xf8, 0x9d, 0x30,
+	0x6f, 0xa4, 0x52, 0xcd,
+	0xe0, 0x7a, 0x04, 0x8a,
+	0xde, 0xd9, 0x26, 0x56,
+};
+
+void dwc_run_dh_test_vectors(void *mem_ctx)
+{
+	uint8_t pkd[384];
+	uint8_t pkh[384];
+	uint8_t hashd[32];
+	uint8_t hashh[32];
+	uint8_t ck[16];
+	uint8_t kdk[32];
+	char dd[5];
+
+	DWC_PRINTF("\n\n\nDH_TEST_VECTORS\n\n");
+
+	/* compute the PKd and SHA-256(PKd || Nd) */
+	DWC_PRINTF("Computing PKd\n");
+	dwc_dh_pk(mem_ctx, 2, dh_a, pkd, hashd);
+
+	/* compute the PKd and SHA-256(PKh || Nd) */
+	DWC_PRINTF("Computing PKh\n");
+	dwc_dh_pk(mem_ctx, 2, dh_b, pkh, hashh);
+
+	/* compute the dhkey */
+	dwc_dh_derive_keys(mem_ctx, 2, pkh, pkd, dh_a, 0, dd, ck, kdk);
+}
+#endif /* DH_TEST_VECTORS */
+
+#endif /* !CONFIG_MACH_IPMATE */
+
+#endif /* DWC_CRYPTOLIB */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_dh.h b/drivers/usb/gadget/udc/hiudc/dwc_dh.h
new file mode 100644
index 0000000..25c1cc0
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_dh.h
@@ -0,0 +1,106 @@
+/* =========================================================================
+ * $File: //dwh/usb_iip/dev/software/dwc_common_port_2/dwc_dh.h $
+ * $Revision: #4 $
+ * $Date: 2010/09/28 $
+ * $Change: 1596182 $
+ *
+ * Synopsys Portability Library Software and documentation
+ * (hereinafter, "Software") is an Unsupported proprietary work of
+ * Synopsys, Inc. unless otherwise expressly agreed to in writing
+ * between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product
+ * under any End User Software License Agreement or Agreement for
+ * Licensed Product with Synopsys or any supplement thereto. You are
+ * permitted to use and redistribute this Software in source and binary
+ * forms, with or without modification, provided that redistributions
+ * of source code must retain this notice. You may not view, use,
+ * disclose, copy or distribute this file or any information contained
+ * herein except pursuant to this license grant from Synopsys. If you
+ * do not agree with this notice, including the disclaimer below, then
+ * you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS"
+ * BASIS AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+ * FOR A PARTICULAR PURPOSE ARE HEREBY DISCLAIMED. IN NO EVENT SHALL
+ * SYNOPSYS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ * USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================= */
+#ifndef _DWC_DH_H_
+#define _DWC_DH_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "dwc_os.h"
+
+/** @file
+ *
+ * This file defines the common functions on device and host for performing
+ * numeric association as defined in the WUSB spec.  They are only to be
+ * used internally by the DWC UWB modules. */
+
+extern int dwc_dh_sha256(uint8_t *message, uint32_t len, uint8_t *out);
+extern int dwc_dh_hmac_sha256(uint8_t *message, uint32_t messagelen,
+			      uint8_t *key, uint32_t keylen,
+			      uint8_t *out);
+extern int dwc_dh_modpow(void *mem_ctx, void *num, uint32_t num_len,
+			 void *exp, uint32_t exp_len,
+			 void *mod, uint32_t mod_len,
+			 void *out);
+
+/** Computes PKD or PKH, and SHA-256(PKd || Nd)
+ *
+ * PK = g^exp mod p.
+ *
+ * Input:
+ * Nd = Number of digits on the device.
+ *
+ * Output:
+ * exp = A 32-byte buffer to be filled with a randomly generated number.
+ *       used as either A or B.
+ * pk = A 384-byte buffer to be filled with the PKH or PKD.
+ * hash = A 32-byte buffer to be filled with SHA-256(PK || ND).
+ */
+extern int dwc_dh_pk(void *mem_ctx, uint8_t nd, uint8_t *exp, uint8_t *pkd, uint8_t *hash);
+
+/** Computes the DHKEY, and VD.
+ *
+ * If called from host, then it will comput DHKEY=PKD^exp % p.
+ * If called from device, then it will comput DHKEY=PKH^exp % p.
+ *
+ * Input:
+ * pkd = The PKD value.
+ * pkh = The PKH value.
+ * exp = The A value (if device) or B value (if host) generated in dwc_wudev_dh_pk.
+ * is_host = Set to non zero if a WUSB host is calling this function.
+ *
+ * Output:
+
+ * dd = A pointer to an buffer to be set to the displayed digits string to be shown
+ *      to the user.  This buffer should be at 5 bytes long to hold 4 digits plus a
+ *      null termination character.  This buffer can be used directly for display.
+ * ck = A 16-byte buffer to be filled with the CK.
+ * kdk = A 32-byte buffer to be filled with the KDK.
+ */
+extern int dwc_dh_derive_keys(void *mem_ctx, uint8_t nd, uint8_t *pkh, uint8_t *pkd,
+			      uint8_t *exp, int is_host,
+			      char *dd, uint8_t *ck, uint8_t *kdk);
+
+#ifdef DH_TEST_VECTORS
+extern void dwc_run_dh_test_vectors(void);
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _DWC_DH_H_ */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_list.h b/drivers/usb/gadget/udc/hiudc/dwc_list.h
new file mode 100644
index 0000000..f2ac846
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_list.h
@@ -0,0 +1,543 @@
+/*	$OpenBSD: queue.h,v 1.26 2004/05/04 16:59:32 grange Exp $	*/
+/*	$NetBSD: queue.h,v 1.11 1996/05/16 05:17:14 mycroft Exp $	*/
+
+/*
+ * Copyright (c) 1991, 1993
+ *	The Regents of the University of California.  All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. Neither the name of the University nor the names of its contributors
+ *    may be used to endorse or promote products derived from this software
+ *    without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ *	@(#)queue.h	8.5 (Berkeley) 8/20/94
+ */
+
+#ifndef _DWC_LIST_H_
+#define _DWC_LIST_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/** @file
+ *
+ * This file defines linked list operations.  It is derived from BSD with
+ * only the MACRO names being prefixed with DWC_.  This is because a few of
+ * these names conflict with those on Linux.  For documentation on use, see the
+ * inline comments in the source code.  The original license for this source
+ * code applies and is preserved in the dwc_list.h source file.
+ */
+
+/*
+ * This file defines five types of data structures: singly-linked lists,
+ * lists, simple queues, tail queues, and circular queues.
+ *
+ *
+ * A singly-linked list is headed by a single forward pointer. The elements
+ * are singly linked for minimum space and pointer manipulation overhead at
+ * the expense of O(n) removal for arbitrary elements. New elements can be
+ * added to the list after an existing element or at the head of the list.
+ * Elements being removed from the head of the list should use the explicit
+ * macro for this purpose for optimum efficiency. A singly-linked list may
+ * only be traversed in the forward direction.  Singly-linked lists are ideal
+ * for applications with large datasets and few or no removals or for
+ * implementing a LIFO queue.
+ *
+ * A list is headed by a single forward pointer (or an array of forward
+ * pointers for a hash table header). The elements are doubly linked
+ * so that an arbitrary element can be removed without a need to
+ * traverse the list. New elements can be added to the list before
+ * or after an existing element or at the head of the list. A list
+ * may only be traversed in the forward direction.
+ *
+ * A simple queue is headed by a pair of pointers, one the head of the
+ * list and the other to the tail of the list. The elements are singly
+ * linked to save space, so elements can only be removed from the
+ * head of the list. New elements can be added to the list before or after
+ * an existing element, at the head of the list, or at the end of the
+ * list. A simple queue may only be traversed in the forward direction.
+ *
+ * A tail queue is headed by a pair of pointers, one to the head of the
+ * list and the other to the tail of the list. The elements are doubly
+ * linked so that an arbitrary element can be removed without a need to
+ * traverse the list. New elements can be added to the list before or
+ * after an existing element, at the head of the list, or at the end of
+ * the list. A tail queue may be traversed in either direction.
+ *
+ * A circle queue is headed by a pair of pointers, one to the head of the
+ * list and the other to the tail of the list. The elements are doubly
+ * linked so that an arbitrary element can be removed without a need to
+ * traverse the list. New elements can be added to the list before or after
+ * an existing element, at the head of the list, or at the end of the list.
+ * A circle queue may be traversed in either direction, but has a more
+ * complex end of list detection.
+ *
+ * For details on the use of these macros, see the queue(3) manual page.
+ */
+
+/*
+ * Double-linked List.
+ */
+
+typedef struct dwc_list_link {
+	struct dwc_list_link *next;
+	struct dwc_list_link *prev;
+} dwc_list_link_t;
+
+#define DWC_LIST_INIT(link) do {	\
+	(link)->next = (link);		\
+	(link)->prev = (link);		\
+} while (0)
+
+#define DWC_LIST_FIRST(link)	((link)->next)
+#define DWC_LIST_LAST(link)	((link)->prev)
+#define DWC_LIST_END(link)	(link)
+#define DWC_LIST_NEXT(link)	((link)->next)
+#define DWC_LIST_PREV(link)	((link)->prev)
+#define DWC_LIST_EMPTY(link)	\
+	(DWC_LIST_FIRST(link) == DWC_LIST_END(link))
+#define DWC_LIST_ENTRY(link, type, field)			\
+	(type *)((uint8_t *)(link) - (size_t)(&((type *)0)->field))
+
+#define DWC_LIST_INSERT_HEAD(list, link) do {			\
+	dwc_list_link_t *__next__ = (list)->next;		\
+	__next__->prev = (link);				\
+	(link)->next = __next__;				\
+	(link)->prev = (list);					\
+	(list)->next = (link);					\
+} while (0)
+
+#define DWC_LIST_INSERT_TAIL(list, link) do {			\
+	dwc_list_link_t *__prev__ = (list)->prev;		\
+	(list)->prev = (link);					\
+	(link)->next = (list);					\
+	(link)->prev = __prev__;				\
+	__prev__->next = (link);				\
+} while (0)
+
+#define DWC_LIST_REMOVE(link) do {				\
+	(link)->next->prev = (link)->prev;			\
+	(link)->prev->next = (link)->next;			\
+} while (0)
+
+#define DWC_LIST_REMOVE_INIT(link) do {				\
+	DWC_LIST_REMOVE(link);					\
+	DWC_LIST_INIT(link);					\
+} while (0)
+
+#define DWC_LIST_MOVE_HEAD(list, link) do {			\
+	DWC_LIST_REMOVE(link);					\
+	DWC_LIST_INSERT_HEAD(list, link);			\
+} while (0)
+
+#define DWC_LIST_MOVE_TAIL(list, link) do {			\
+	DWC_LIST_REMOVE(link);					\
+	DWC_LIST_INSERT_TAIL(list, link);			\
+} while (0)
+
+#define DWC_LIST_FOREACH(var, list)				\
+	for((var) = DWC_LIST_FIRST(list);			\
+	    (var) != DWC_LIST_END(list);			\
+	    (var) = DWC_LIST_NEXT(var))
+
+#define DWC_LIST_FOREACH_SAFE(var, var2, list)			\
+	for((var) = DWC_LIST_FIRST(list), (var2) = DWC_LIST_NEXT(var);	\
+	    (var) != DWC_LIST_END(list);			\
+	    (var) = (var2), (var2) = DWC_LIST_NEXT(var2))
+
+#define DWC_LIST_FOREACH_REVERSE(var, list)			\
+	for((var) = DWC_LIST_LAST(list);			\
+	    (var) != DWC_LIST_END(list);			\
+	    (var) = DWC_LIST_PREV(var))
+
+/*
+ * Singly-linked List definitions.
+ */
+#define DWC_SLIST_HEAD(name, type)					\
+struct name {								\
+	struct type *slh_first;	/* first element */			\
+}
+
+#define DWC_SLIST_HEAD_INITIALIZER(head)				\
+	{ NULL }
+
+#define DWC_SLIST_ENTRY(type)						\
+struct {								\
+	struct type *sle_next;	/* next element */			\
+}
+
+/*
+ * Singly-linked List access methods.
+ */
+#define DWC_SLIST_FIRST(head)	((head)->slh_first)
+#define DWC_SLIST_END(head)		NULL
+#define DWC_SLIST_EMPTY(head)	(SLIST_FIRST(head) == SLIST_END(head))
+#define DWC_SLIST_NEXT(elm, field)	((elm)->field.sle_next)
+
+#define DWC_SLIST_FOREACH(var, head, field)				\
+	for((var) = SLIST_FIRST(head);					\
+	    (var) != SLIST_END(head);					\
+	    (var) = SLIST_NEXT(var, field))
+
+#define DWC_SLIST_FOREACH_PREVPTR(var, varp, head, field)		\
+	for((varp) = &SLIST_FIRST((head));				\
+	    ((var) = *(varp)) != SLIST_END(head);			\
+	    (varp) = &SLIST_NEXT((var), field))
+
+/*
+ * Singly-linked List functions.
+ */
+#define DWC_SLIST_INIT(head) {						\
+	SLIST_FIRST(head) = SLIST_END(head);				\
+}
+
+#define DWC_SLIST_INSERT_AFTER(slistelm, elm, field) do {		\
+	(elm)->field.sle_next = (slistelm)->field.sle_next;		\
+	(slistelm)->field.sle_next = (elm);				\
+} while (0)
+
+#define DWC_SLIST_INSERT_HEAD(head, elm, field) do {			\
+	(elm)->field.sle_next = (head)->slh_first;			\
+	(head)->slh_first = (elm);					\
+} while (0)
+
+#define DWC_SLIST_REMOVE_NEXT(head, elm, field) do {			\
+	(elm)->field.sle_next = (elm)->field.sle_next->field.sle_next;	\
+} while (0)
+
+#define DWC_SLIST_REMOVE_HEAD(head, field) do {				\
+	(head)->slh_first = (head)->slh_first->field.sle_next;		\
+} while (0)
+
+#define DWC_SLIST_REMOVE(head, elm, type, field) do {			\
+	if ((head)->slh_first == (elm)) {				\
+		SLIST_REMOVE_HEAD((head), field);			\
+	}								\
+	else {								\
+		struct type *curelm = (head)->slh_first;		\
+		while( curelm->field.sle_next != (elm) )		\
+			curelm = curelm->field.sle_next;		\
+		curelm->field.sle_next =				\
+		    curelm->field.sle_next->field.sle_next;		\
+	}								\
+} while (0)
+
+/*
+ * Simple queue definitions.
+ */
+#define DWC_SIMPLEQ_HEAD(name, type)					\
+struct name {								\
+	struct type *sqh_first;	/* first element */			\
+	struct type **sqh_last;	/* addr of last next element */		\
+}
+
+#define DWC_SIMPLEQ_HEAD_INITIALIZER(head)				\
+	{ NULL, &(head).sqh_first }
+
+#define DWC_SIMPLEQ_ENTRY(type)						\
+struct {								\
+	struct type *sqe_next;	/* next element */			\
+}
+
+/*
+ * Simple queue access methods.
+ */
+#define DWC_SIMPLEQ_FIRST(head)	    ((head)->sqh_first)
+#define DWC_SIMPLEQ_END(head)	    NULL
+#define DWC_SIMPLEQ_EMPTY(head)	    (SIMPLEQ_FIRST(head) == SIMPLEQ_END(head))
+#define DWC_SIMPLEQ_NEXT(elm, field)    ((elm)->field.sqe_next)
+
+#define DWC_SIMPLEQ_FOREACH(var, head, field)				\
+	for((var) = SIMPLEQ_FIRST(head);				\
+	    (var) != SIMPLEQ_END(head);					\
+	    (var) = SIMPLEQ_NEXT(var, field))
+
+/*
+ * Simple queue functions.
+ */
+#define DWC_SIMPLEQ_INIT(head) do {					\
+	(head)->sqh_first = NULL;					\
+	(head)->sqh_last = &(head)->sqh_first;				\
+} while (0)
+
+#define DWC_SIMPLEQ_INSERT_HEAD(head, elm, field) do {			\
+	if (((elm)->field.sqe_next = (head)->sqh_first) == NULL)	\
+		(head)->sqh_last = &(elm)->field.sqe_next;		\
+	(head)->sqh_first = (elm);					\
+} while (0)
+
+#define DWC_SIMPLEQ_INSERT_TAIL(head, elm, field) do {			\
+	(elm)->field.sqe_next = NULL;					\
+	*(head)->sqh_last = (elm);					\
+	(head)->sqh_last = &(elm)->field.sqe_next;			\
+} while (0)
+
+#define DWC_SIMPLEQ_INSERT_AFTER(head, listelm, elm, field) do {	\
+	if (((elm)->field.sqe_next = (listelm)->field.sqe_next) == NULL)\
+		(head)->sqh_last = &(elm)->field.sqe_next;		\
+	(listelm)->field.sqe_next = (elm);				\
+} while (0)
+
+#define DWC_SIMPLEQ_REMOVE_HEAD(head, field) do {			\
+	if (((head)->sqh_first = (head)->sqh_first->field.sqe_next) == NULL) \
+		(head)->sqh_last = &(head)->sqh_first;			\
+} while (0)
+
+/*
+ * Tail queue definitions.
+ */
+#define DWC_TAILQ_HEAD(name, type)					\
+struct name {								\
+	struct type *tqh_first;	/* first element */			\
+	struct type **tqh_last;	/* addr of last next element */		\
+}
+
+#define DWC_TAILQ_HEAD_INITIALIZER(head)				\
+	{ NULL, &(head).tqh_first }
+
+#define DWC_TAILQ_ENTRY(type)						\
+struct {								\
+	struct type *tqe_next;	/* next element */			\
+	struct type **tqe_prev;	/* address of previous next element */	\
+}
+
+/*
+ * tail queue access methods
+ */
+#define DWC_TAILQ_FIRST(head)		((head)->tqh_first)
+#define DWC_TAILQ_END(head)		NULL
+#define DWC_TAILQ_NEXT(elm, field)	((elm)->field.tqe_next)
+#define DWC_TAILQ_LAST(head, headname)					\
+	(*(((struct headname *)((head)->tqh_last))->tqh_last))
+/* XXX */
+#define DWC_TAILQ_PREV(elm, headname, field)				\
+	(*(((struct headname *)((elm)->field.tqe_prev))->tqh_last))
+#define DWC_TAILQ_EMPTY(head)						\
+	(TAILQ_FIRST(head) == TAILQ_END(head))
+
+#define DWC_TAILQ_FOREACH(var, head, field)				\
+	for((var) = TAILQ_FIRST(head);					\
+	    (var) != TAILQ_END(head);					\
+	    (var) = TAILQ_NEXT(var, field))
+
+#define DWC_TAILQ_FOREACH_REVERSE(var, head, headname, field)		\
+	for((var) = TAILQ_LAST(head, headname);				\
+	    (var) != TAILQ_END(head);					\
+	    (var) = TAILQ_PREV(var, headname, field))
+
+/*
+ * Tail queue functions.
+ */
+#define DWC_TAILQ_INIT(head) do {					\
+	(head)->tqh_first = NULL;					\
+	(head)->tqh_last = &(head)->tqh_first;				\
+} while (0)
+
+#define DWC_TAILQ_INSERT_HEAD(head, elm, field) do {			\
+	if (((elm)->field.tqe_next = (head)->tqh_first) != NULL)	\
+		(head)->tqh_first->field.tqe_prev =			\
+		    &(elm)->field.tqe_next;				\
+	else								\
+		(head)->tqh_last = &(elm)->field.tqe_next;		\
+	(head)->tqh_first = (elm);					\
+	(elm)->field.tqe_prev = &(head)->tqh_first;			\
+} while (0)
+
+#define DWC_TAILQ_INSERT_TAIL(head, elm, field) do {			\
+	(elm)->field.tqe_next = NULL;					\
+	(elm)->field.tqe_prev = (head)->tqh_last;			\
+	*(head)->tqh_last = (elm);					\
+	(head)->tqh_last = &(elm)->field.tqe_next;			\
+} while (0)
+
+#define DWC_TAILQ_INSERT_AFTER(head, listelm, elm, field) do {		\
+	if (((elm)->field.tqe_next = (listelm)->field.tqe_next) != NULL)\
+		(elm)->field.tqe_next->field.tqe_prev =			\
+		    &(elm)->field.tqe_next;				\
+	else								\
+		(head)->tqh_last = &(elm)->field.tqe_next;		\
+	(listelm)->field.tqe_next = (elm);				\
+	(elm)->field.tqe_prev = &(listelm)->field.tqe_next;		\
+} while (0)
+
+#define DWC_TAILQ_INSERT_BEFORE(listelm, elm, field) do {		\
+	(elm)->field.tqe_prev = (listelm)->field.tqe_prev;		\
+	(elm)->field.tqe_next = (listelm);				\
+	*(listelm)->field.tqe_prev = (elm);				\
+	(listelm)->field.tqe_prev = &(elm)->field.tqe_next;		\
+} while (0)
+
+#define DWC_TAILQ_REMOVE(head, elm, field) do {				\
+	if (((elm)->field.tqe_next) != NULL)				\
+		(elm)->field.tqe_next->field.tqe_prev =			\
+		    (elm)->field.tqe_prev;				\
+	else								\
+		(head)->tqh_last = (elm)->field.tqe_prev;		\
+	*(elm)->field.tqe_prev = (elm)->field.tqe_next;			\
+} while (0)
+
+#define DWC_TAILQ_REPLACE(head, elm, elm2, field) do {			\
+	if (((elm2)->field.tqe_next = (elm)->field.tqe_next) != NULL)	\
+		(elm2)->field.tqe_next->field.tqe_prev =		\
+		    &(elm2)->field.tqe_next;				\
+	else								\
+		(head)->tqh_last = &(elm2)->field.tqe_next;		\
+	(elm2)->field.tqe_prev = (elm)->field.tqe_prev;			\
+	*(elm2)->field.tqe_prev = (elm2);				\
+} while (0)
+
+/*
+ * Circular queue definitions.
+ */
+#define DWC_CIRCLEQ_HEAD(name, type)					\
+struct name {								\
+	struct type *cqh_first;		/* first element */		\
+	struct type *cqh_last;		/* last element */		\
+}
+
+#define DWC_CIRCLEQ_HEAD_INITIALIZER(head)				\
+	{ DWC_CIRCLEQ_END(&head), DWC_CIRCLEQ_END(&head) }
+
+#define DWC_CIRCLEQ_ENTRY(type)						\
+struct {								\
+	struct type *cqe_next;		/* next element */		\
+	struct type *cqe_prev;		/* previous element */		\
+}
+
+/*
+ * Circular queue access methods
+ */
+#define DWC_CIRCLEQ_FIRST(head)		((head)->cqh_first)
+#define DWC_CIRCLEQ_LAST(head)		((head)->cqh_last)
+#define DWC_CIRCLEQ_END(head)		((void *)(head))
+#define DWC_CIRCLEQ_NEXT(elm, field)	((elm)->field.cqe_next)
+#define DWC_CIRCLEQ_PREV(elm, field)	((elm)->field.cqe_prev)
+#define DWC_CIRCLEQ_EMPTY(head)						\
+	(DWC_CIRCLEQ_FIRST(head) == DWC_CIRCLEQ_END(head))
+
+#define DWC_CIRCLEQ_EMPTY_ENTRY(elm, field) (((elm)->field.cqe_next == NULL) && ((elm)->field.cqe_prev == NULL))
+
+#define DWC_CIRCLEQ_FOREACH(var, head, field)				\
+	for((var) = DWC_CIRCLEQ_FIRST(head);				\
+	    (var) != DWC_CIRCLEQ_END(head);				\
+	    (var) = DWC_CIRCLEQ_NEXT(var, field))
+
+#define DWC_CIRCLEQ_FOREACH_SAFE(var, var2, head, field)			\
+	for((var) = DWC_CIRCLEQ_FIRST(head), var2 = DWC_CIRCLEQ_NEXT(var, field); \
+	    (var) != DWC_CIRCLEQ_END(head);					\
+	    (var) = var2, var2 = DWC_CIRCLEQ_NEXT(var, field))
+
+#define DWC_CIRCLEQ_FOREACH_REVERSE(var, head, field)			\
+	for((var) = DWC_CIRCLEQ_LAST(head);				\
+	    (var) != DWC_CIRCLEQ_END(head);				\
+	    (var) = DWC_CIRCLEQ_PREV(var, field))
+
+/*
+ * Circular queue functions.
+ */
+#define DWC_CIRCLEQ_INIT(head) do {					\
+	(head)->cqh_first = DWC_CIRCLEQ_END(head);			\
+	(head)->cqh_last = DWC_CIRCLEQ_END(head);			\
+} while (0)
+
+#define DWC_CIRCLEQ_INIT_ENTRY(elm, field) do {				\
+	(elm)->field.cqe_next = NULL;					\
+	(elm)->field.cqe_prev = NULL;					\
+} while (0)
+
+#define DWC_CIRCLEQ_INSERT_AFTER(head, listelm, elm, field) do {	\
+	(elm)->field.cqe_next = (listelm)->field.cqe_next;		\
+	(elm)->field.cqe_prev = (listelm);				\
+	if ((listelm)->field.cqe_next == DWC_CIRCLEQ_END(head))		\
+		(head)->cqh_last = (elm);				\
+	else								\
+		(listelm)->field.cqe_next->field.cqe_prev = (elm);	\
+	(listelm)->field.cqe_next = (elm);				\
+} while (0)
+
+#define DWC_CIRCLEQ_INSERT_BEFORE(head, listelm, elm, field) do {	\
+	(elm)->field.cqe_next = (listelm);				\
+	(elm)->field.cqe_prev = (listelm)->field.cqe_prev;		\
+	if ((listelm)->field.cqe_prev == DWC_CIRCLEQ_END(head))		\
+		(head)->cqh_first = (elm);				\
+	else								\
+		(listelm)->field.cqe_prev->field.cqe_next = (elm);	\
+	(listelm)->field.cqe_prev = (elm);				\
+} while (0)
+
+#define DWC_CIRCLEQ_INSERT_HEAD(head, elm, field) do {			\
+	(elm)->field.cqe_next = (head)->cqh_first;			\
+	(elm)->field.cqe_prev = DWC_CIRCLEQ_END(head);			\
+	if ((head)->cqh_last == DWC_CIRCLEQ_END(head))			\
+		(head)->cqh_last = (elm);				\
+	else								\
+		(head)->cqh_first->field.cqe_prev = (elm);		\
+	(head)->cqh_first = (elm);					\
+} while (0)
+
+#define DWC_CIRCLEQ_INSERT_TAIL(head, elm, field) do {			\
+	(elm)->field.cqe_next = DWC_CIRCLEQ_END(head);			\
+	(elm)->field.cqe_prev = (head)->cqh_last;			\
+	if ((head)->cqh_first == DWC_CIRCLEQ_END(head))			\
+		(head)->cqh_first = (elm);				\
+	else								\
+		(head)->cqh_last->field.cqe_next = (elm);		\
+	(head)->cqh_last = (elm);					\
+} while (0)
+
+#define DWC_CIRCLEQ_REMOVE(head, elm, field) do {			\
+	if ((elm)->field.cqe_next == DWC_CIRCLEQ_END(head))		\
+		(head)->cqh_last = (elm)->field.cqe_prev;		\
+	else								\
+		(elm)->field.cqe_next->field.cqe_prev =			\
+		    (elm)->field.cqe_prev;				\
+	if ((elm)->field.cqe_prev == DWC_CIRCLEQ_END(head))		\
+		(head)->cqh_first = (elm)->field.cqe_next;		\
+	else								\
+		(elm)->field.cqe_prev->field.cqe_next =			\
+		    (elm)->field.cqe_next;				\
+} while (0)
+
+#define DWC_CIRCLEQ_REMOVE_INIT(head, elm, field) do {			\
+	DWC_CIRCLEQ_REMOVE(head, elm, field);				\
+	DWC_CIRCLEQ_INIT_ENTRY(elm, field);				\
+} while (0)
+
+#define DWC_CIRCLEQ_REPLACE(head, elm, elm2, field) do {		\
+	if (((elm2)->field.cqe_next = (elm)->field.cqe_next) ==		\
+	    DWC_CIRCLEQ_END(head))					\
+		(head).cqh_last = (elm2);				\
+	else								\
+		(elm2)->field.cqe_next->field.cqe_prev = (elm2);	\
+	if (((elm2)->field.cqe_prev = (elm)->field.cqe_prev) ==		\
+	    DWC_CIRCLEQ_END(head))					\
+		(head).cqh_first = (elm2);				\
+	else								\
+		(elm2)->field.cqe_prev->field.cqe_next = (elm2);	\
+} while (0)
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _DWC_LIST_H_ */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_mem.c b/drivers/usb/gadget/udc/hiudc/dwc_mem.c
new file mode 100644
index 0000000..ad645ff
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_mem.c
@@ -0,0 +1,245 @@
+/* Memory Debugging */
+#ifdef DWC_DEBUG_MEMORY
+
+#include "dwc_os.h"
+#include "dwc_list.h"
+
+struct allocation {
+	void *addr;
+	void *ctx;
+	char *func;
+	int line;
+	uint32_t size;
+	int dma;
+	DWC_CIRCLEQ_ENTRY(allocation) entry;
+};
+
+DWC_CIRCLEQ_HEAD(allocation_queue, allocation);
+
+struct allocation_manager {
+	void *mem_ctx;
+	struct allocation_queue allocations;
+
+	/* statistics */
+	int num;
+	int num_freed;
+	int num_active;
+	uint32_t total;
+	uint32_t cur;
+	uint32_t max;
+};
+
+static struct allocation_manager *manager = NULL;
+
+static int add_allocation(void *ctx, uint32_t size, char const *func, int line, void *addr,
+			  int dma)
+{
+	struct allocation *a;
+
+	DWC_ASSERT(manager != NULL, "manager not allocated");
+
+	a = __DWC_ALLOC_ATOMIC(manager->mem_ctx, sizeof(*a));
+	if (!a) {
+		return -DWC_E_NO_MEMORY;
+	}
+
+	a->func = __DWC_ALLOC_ATOMIC(manager->mem_ctx, DWC_STRLEN(func) + 1);
+	if (!a->func) {
+		__DWC_FREE(manager->mem_ctx, a);
+		return -DWC_E_NO_MEMORY;
+	}
+
+	DWC_MEMCPY(a->func, func, DWC_STRLEN(func) + 1);
+	a->addr = addr;
+	a->ctx = ctx;
+	a->line = line;
+	a->size = size;
+	a->dma = dma;
+	DWC_CIRCLEQ_INSERT_TAIL(&manager->allocations, a, entry);
+
+	/* Update stats */
+	manager->num++;
+	manager->num_active++;
+	manager->total += size;
+	manager->cur += size;
+
+	if (manager->max < manager->cur) {
+		manager->max = manager->cur;
+	}
+
+	return 0;
+}
+
+static struct allocation *find_allocation(void *ctx, void *addr)
+{
+	struct allocation *a;
+
+	DWC_CIRCLEQ_FOREACH(a, &manager->allocations, entry) {
+		if (a->ctx == ctx && a->addr == addr) {
+			return a;
+		}
+	}
+
+	return NULL;
+}
+
+static void free_allocation(void *ctx, void *addr, char const *func, int line)
+{
+	struct allocation *a = find_allocation(ctx, addr);
+
+	if (!a) {
+		DWC_ASSERT(0,
+			   "Free of address %p that was never allocated or already freed %s:%d",
+			   addr, func, line);
+		return;
+	}
+
+	DWC_CIRCLEQ_REMOVE(&manager->allocations, a, entry);
+
+	manager->num_active--;
+	manager->num_freed++;
+	manager->cur -= a->size;
+	__DWC_FREE(manager->mem_ctx, a->func);
+	__DWC_FREE(manager->mem_ctx, a);
+}
+
+int dwc_memory_debug_start(void *mem_ctx)
+{
+	DWC_ASSERT(manager == NULL, "Memory debugging has already started\n");
+
+	if (manager) {
+		return -DWC_E_BUSY;
+	}
+
+	manager = __DWC_ALLOC(mem_ctx, sizeof(*manager));
+	if (!manager) {
+		return -DWC_E_NO_MEMORY;
+	}
+
+	DWC_CIRCLEQ_INIT(&manager->allocations);
+	manager->mem_ctx = mem_ctx;
+	manager->num = 0;
+	manager->num_freed = 0;
+	manager->num_active = 0;
+	manager->total = 0;
+	manager->cur = 0;
+	manager->max = 0;
+
+	return 0;
+}
+
+void dwc_memory_debug_stop(void)
+{
+	struct allocation *a;
+
+	dwc_memory_debug_report();
+
+	DWC_CIRCLEQ_FOREACH(a, &manager->allocations, entry) {
+		DWC_ERROR("Memory leaked from %s:%d\n", a->func, a->line);
+		free_allocation(a->ctx, a->addr, NULL, -1);
+	}
+
+	__DWC_FREE(manager->mem_ctx, manager);
+}
+
+void dwc_memory_debug_report(void)
+{
+	struct allocation *a;
+
+	DWC_PRINTF("\n\n\n----------------- Memory Debugging Report -----------------\n\n");
+	DWC_PRINTF("Num Allocations = %d\n", manager->num);
+	DWC_PRINTF("Freed = %d\n", manager->num_freed);
+	DWC_PRINTF("Active = %d\n", manager->num_active);
+	DWC_PRINTF("Current Memory Used = %d\n", manager->cur);
+	DWC_PRINTF("Total Memory Used = %d\n", manager->total);
+	DWC_PRINTF("Maximum Memory Used at Once = %d\n", manager->max);
+	DWC_PRINTF("Unfreed allocations:\n");
+
+	DWC_CIRCLEQ_FOREACH(a, &manager->allocations, entry) {
+		DWC_PRINTF("    addr=%p, size=%d from %s:%d, DMA=%d\n",
+			   a->addr, a->size, a->func, a->line, a->dma);
+	}
+}
+
+/* The replacement functions */
+void *dwc_alloc_debug(void *mem_ctx, uint32_t size, char const *func, int line)
+{
+	void *addr = __DWC_ALLOC(mem_ctx, size);
+
+	if (!addr) {
+		return NULL;
+	}
+
+	if (add_allocation(mem_ctx, size, func, line, addr, 0)) {
+		__DWC_FREE(mem_ctx, addr);
+		return NULL;
+	}
+
+	return addr;
+}
+
+void *dwc_alloc_atomic_debug(void *mem_ctx, uint32_t size, char const *func,
+			     int line)
+{
+	void *addr = __DWC_ALLOC_ATOMIC(mem_ctx, size);
+
+	if (!addr) {
+		return NULL;
+	}
+
+	if (add_allocation(mem_ctx, size, func, line, addr, 0)) {
+		__DWC_FREE(mem_ctx, addr);
+		return NULL;
+	}
+
+	return addr;
+}
+
+void dwc_free_debug(void *mem_ctx, void *addr, char const *func, int line)
+{
+	free_allocation(mem_ctx, addr, func, line);
+	__DWC_FREE(mem_ctx, addr);
+}
+
+void *dwc_dma_alloc_debug(void *dma_ctx, uint32_t size, dwc_dma_t *dma_addr,
+			  char const *func, int line)
+{
+	void *addr = __DWC_DMA_ALLOC(dma_ctx, size, dma_addr);
+
+	if (!addr) {
+		return NULL;
+	}
+
+	if (add_allocation(dma_ctx, size, func, line, addr, 1)) {
+		__DWC_DMA_FREE(dma_ctx, size, addr, *dma_addr);
+		return NULL;
+	}
+
+	return addr;
+}
+
+void *dwc_dma_alloc_atomic_debug(void *dma_ctx, uint32_t size,
+				 dwc_dma_t *dma_addr, char const *func, int line)
+{
+	void *addr = __DWC_DMA_ALLOC_ATOMIC(dma_ctx, size, dma_addr);
+
+	if (!addr) {
+		return NULL;
+	}
+
+	if (add_allocation(dma_ctx, size, func, line, addr, 1)) {
+		__DWC_DMA_FREE(dma_ctx, size, addr, *dma_addr);
+		return NULL;
+	}
+
+	return addr;
+}
+
+void dwc_dma_free_debug(void *dma_ctx, uint32_t size, void *virt_addr,
+			dwc_dma_t dma_addr, char const *func, int line)
+{
+	free_allocation(dma_ctx, virt_addr, func, line);
+	__DWC_DMA_FREE(dma_ctx, size, virt_addr, dma_addr);
+}
+
+#endif /* DWC_DEBUG_MEMORY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_modpow.c b/drivers/usb/gadget/udc/hiudc/dwc_modpow.c
new file mode 100644
index 0000000..307dbdf
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_modpow.c
@@ -0,0 +1,633 @@
+/* Bignum routines adapted from PUTTY sources.  PuTTY copyright notice follows.
+ *
+ * PuTTY is copyright 1997-2007 Simon Tatham.
+ *
+ * Portions copyright Robert de Bath, Joris van Rantwijk, Delian
+ * Delchev, Andreas Schultz, Jeroen Massar, Wez Furlong, Nicolas Barry,
+ * Justin Bradford, Ben Harris, Malcolm Smith, Ahmad Khalifa, Markus
+ * Kuhn, and CORE SDI S.A.
+ *
+ * Permission is hereby granted, free of charge, to any person
+ * obtaining a copy of this software and associated documentation files
+ * (the "Software"), to deal in the Software without restriction,
+ * including without limitation the rights to use, copy, modify, merge,
+ * publish, distribute, sublicense, and/or sell copies of the Software,
+ * and to permit persons to whom the Software is furnished to do so,
+ * subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be
+ * included in all copies or substantial portions of the Software.
+
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT.  IN NO EVENT SHALL THE COPYRIGHT HOLDERS BE LIABLE
+ * FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
+ * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+ * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ */
+#ifdef DWC_CRYPTOLIB
+
+#ifndef CONFIG_MACH_IPMATE
+
+#include "dwc_modpow.h"
+
+#define BIGNUM_INT_MASK  0xFFFFFFFFUL
+#define BIGNUM_TOP_BIT   0x80000000UL
+#define BIGNUM_INT_BITS  32
+
+
+static void *snmalloc(void *mem_ctx, size_t n, size_t size)
+{
+    void *p;
+    size *= n;
+    if (size == 0) size = 1;
+    p = dwc_alloc(mem_ctx, size);
+    return p;
+}
+
+#define snewn(ctx, n, type) ((type *)snmalloc((ctx), (n), sizeof(type)))
+#define sfree dwc_free
+
+/*
+ * Usage notes:
+ *  * Do not call the DIVMOD_WORD macro with expressions such as array
+ *    subscripts, as some implementations object to this (see below).
+ *  * Note that none of the division methods below will cope if the
+ *    quotient won't fit into BIGNUM_INT_BITS. Callers should be careful
+ *    to avoid this case.
+ *    If this condition occurs, in the case of the x86 DIV instruction,
+ *    an overflow exception will occur, which (according to a correspondent)
+ *    will manifest on Windows as something like
+ *      0xC0000095: Integer overflow
+ *    The C variant won't give the right answer, either.
+ */
+
+#define MUL_WORD(w1, w2) ((BignumDblInt)w1 * w2)
+
+#if defined __GNUC__ && defined __i386__
+#define DIVMOD_WORD(q, r, hi, lo, w) \
+    __asm__("div %2" : \
+	    "=d" (r), "=a" (q) : \
+	    "r" (w), "d" (hi), "a" (lo))
+#else
+#define DIVMOD_WORD(q, r, hi, lo, w) do { \
+    BignumDblInt n = (((BignumDblInt)hi) << BIGNUM_INT_BITS) | lo; \
+    q = n / w; \
+    r = n % w; \
+} while (0)
+#endif
+
+#define BIGNUM_INT_BYTES (BIGNUM_INT_BITS / 8)
+
+#define BIGNUM_INTERNAL
+
+static Bignum newbn(void *mem_ctx, int length)
+{
+    Bignum b = snewn(mem_ctx, length + 1, BignumInt);
+    //if (!b)
+    //abort();		       /* FIXME */
+    DWC_MEMSET(b, 0, (length + 1) * sizeof(*b));
+    b[0] = length;
+    return b;
+}
+
+void freebn(void *mem_ctx, Bignum b)
+{
+    /*
+     * Burn the evidence, just in case.
+     */
+    DWC_MEMSET(b, 0, sizeof(b[0]) * (b[0] + 1));
+    sfree(mem_ctx, b);
+}
+
+/*
+ * Compute c = a * b.
+ * Input is in the first len words of a and b.
+ * Result is returned in the first 2*len words of c.
+ */
+static void internal_mul(BignumInt *a, BignumInt *b,
+			 BignumInt *c, int len)
+{
+    int i, j;
+    BignumDblInt t;
+
+    for (j = 0; j < 2 * len; j++)
+	c[j] = 0;
+
+    for (i = len - 1; i >= 0; i--) {
+	t = 0;
+	for (j = len - 1; j >= 0; j--) {
+	    t += MUL_WORD(a[i], (BignumDblInt) b[j]);
+	    t += (BignumDblInt) c[i + j + 1];
+	    c[i + j + 1] = (BignumInt) t;
+	    t = t >> BIGNUM_INT_BITS;
+	}
+	c[i] = (BignumInt) t;
+    }
+}
+
+static void internal_add_shifted(BignumInt *number,
+				 unsigned n, int shift)
+{
+    int word = 1 + (shift / BIGNUM_INT_BITS);
+    int bshift = shift % BIGNUM_INT_BITS;
+    BignumDblInt addend;
+
+    addend = (BignumDblInt)n << bshift;
+
+    while (addend) {
+	addend += number[word];
+	number[word] = (BignumInt) addend & BIGNUM_INT_MASK;
+	addend >>= BIGNUM_INT_BITS;
+	word++;
+    }
+}
+
+/*
+ * Compute a = a % m.
+ * Input in first alen words of a and first mlen words of m.
+ * Output in first alen words of a
+ * (of which first alen-mlen words will be zero).
+ * The MSW of m MUST have its high bit set.
+ * Quotient is accumulated in the `quotient' array, which is a Bignum
+ * rather than the internal bigendian format. Quotient parts are shifted
+ * left by `qshift' before adding into quot.
+ */
+static void internal_mod(BignumInt *a, int alen,
+			 BignumInt *m, int mlen,
+			 BignumInt *quot, int qshift)
+{
+    BignumInt m0, m1;
+    unsigned int h;
+    int i, k;
+
+    m0 = m[0];
+    if (mlen > 1)
+	m1 = m[1];
+    else
+	m1 = 0;
+
+    for (i = 0; i <= alen - mlen; i++) {
+	BignumDblInt t;
+	unsigned int q, r, c, ai1;
+
+	if (i == 0) {
+	    h = 0;
+	} else {
+	    h = a[i - 1];
+	    a[i - 1] = 0;
+	}
+
+	if (i == alen - 1)
+	    ai1 = 0;
+	else
+	    ai1 = a[i + 1];
+
+	/* Find q = h:a[i] / m0 */
+	if (h >= m0) {
+	    /*
+	     * Special case.
+	     *
+	     * To illustrate it, suppose a BignumInt is 8 bits, and
+	     * we are dividing (say) A1:23:45:67 by A1:B2:C3. Then
+	     * our initial division will be 0xA123 / 0xA1, which
+	     * will give a quotient of 0x100 and a divide overflow.
+	     * However, the invariants in this division algorithm
+	     * are not violated, since the full number A1:23:... is
+	     * _less_ than the quotient prefix A1:B2:... and so the
+	     * following correction loop would have sorted it out.
+	     *
+	     * In this situation we set q to be the largest
+	     * quotient we _can_ stomach (0xFF, of course).
+	     */
+	    q = BIGNUM_INT_MASK;
+	} else {
+	    /* Macro doesn't want an array subscript expression passed
+	     * into it (see definition), so use a temporary. */
+	    BignumInt tmplo = a[i];
+	    DIVMOD_WORD(q, r, h, tmplo, m0);
+
+	    /* Refine our estimate of q by looking at
+	     h:a[i]:a[i+1] / m0:m1 */
+	    t = MUL_WORD(m1, q);
+	    if (t > ((BignumDblInt) r << BIGNUM_INT_BITS) + ai1) {
+		q--;
+		t -= m1;
+		r = (r + m0) & BIGNUM_INT_MASK;     /* overflow? */
+		if (r >= (BignumDblInt) m0 &&
+		    t > ((BignumDblInt) r << BIGNUM_INT_BITS) + ai1) q--;
+	    }
+	}
+
+	/* Subtract q * m from a[i...] */
+	c = 0;
+	for (k = mlen - 1; k >= 0; k--) {
+	    t = MUL_WORD(q, m[k]);
+	    t += c;
+	    c = (unsigned)(t >> BIGNUM_INT_BITS);
+	    if ((BignumInt) t > a[i + k])
+		c++;
+	    a[i + k] -= (BignumInt) t;
+	}
+
+	/* Add back m in case of borrow */
+	if (c != h) {
+	    t = 0;
+	    for (k = mlen - 1; k >= 0; k--) {
+		t += m[k];
+		t += a[i + k];
+		a[i + k] = (BignumInt) t;
+		t = t >> BIGNUM_INT_BITS;
+	    }
+	    q--;
+	}
+	if (quot)
+	    internal_add_shifted(quot, q, qshift + BIGNUM_INT_BITS * (alen - mlen - i));
+    }
+}
+
+/*
+ * Compute p % mod.
+ * The most significant word of mod MUST be non-zero.
+ * We assume that the result array is the same size as the mod array.
+ * We optionally write out a quotient if `quotient' is non-NULL.
+ * We can avoid writing out the result if `result' is NULL.
+ */
+void bigdivmod(void *mem_ctx, Bignum p, Bignum mod, Bignum result, Bignum quotient)
+{
+    BignumInt *n, *m;
+    int mshift;
+    int plen, mlen, i, j;
+
+    /* Allocate m of size mlen, copy mod to m */
+    /* We use big endian internally */
+    mlen = mod[0];
+    m = snewn(mem_ctx, mlen, BignumInt);
+    //if (!m)
+    //abort();		       /* FIXME */
+    for (j = 0; j < mlen; j++)
+	m[j] = mod[mod[0] - j];
+
+    /* Shift m left to make msb bit set */
+    for (mshift = 0; mshift < BIGNUM_INT_BITS-1; mshift++)
+	if ((m[0] << mshift) & BIGNUM_TOP_BIT)
+	    break;
+    if (mshift) {
+	for (i = 0; i < mlen - 1; i++)
+	    m[i] = (m[i] << mshift) | (m[i + 1] >> (BIGNUM_INT_BITS - mshift));
+	m[mlen - 1] = m[mlen - 1] << mshift;
+    }
+
+    plen = p[0];
+    /* Ensure plen > mlen */
+    if (plen <= mlen)
+	plen = mlen + 1;
+
+    /* Allocate n of size plen, copy p to n */
+    n = snewn(mem_ctx, plen, BignumInt);
+    //if (!n)
+    //abort();		       /* FIXME */
+    for (j = 0; j < plen; j++)
+	n[j] = 0;
+    for (j = 1; j <= (int)p[0]; j++)
+	n[plen - j] = p[j];
+
+    /* Main computation */
+    internal_mod(n, plen, m, mlen, quotient, mshift);
+
+    /* Fixup result in case the modulus was shifted */
+    if (mshift) {
+	for (i = plen - mlen - 1; i < plen - 1; i++)
+	    n[i] = (n[i] << mshift) | (n[i + 1] >> (BIGNUM_INT_BITS - mshift));
+	n[plen - 1] = n[plen - 1] << mshift;
+	internal_mod(n, plen, m, mlen, quotient, 0);
+	for (i = plen - 1; i >= plen - mlen; i--)
+	    n[i] = (n[i] >> mshift) | (n[i - 1] << (BIGNUM_INT_BITS - mshift));
+    }
+
+    /* Copy result to buffer */
+    if (result) {
+	for (i = 1; i <= (int)result[0]; i++) {
+	    int j = plen - i;
+	    result[i] = j >= 0 ? n[j] : 0;
+	}
+    }
+
+    /* Free temporary arrays */
+    for (i = 0; i < mlen; i++)
+	m[i] = 0;
+    sfree(mem_ctx, m);
+    for (i = 0; i < plen; i++)
+	n[i] = 0;
+    sfree(mem_ctx, n);
+}
+
+/*
+ * Simple remainder.
+ */
+Bignum bigmod(void *mem_ctx, Bignum a, Bignum b)
+{
+    Bignum r = newbn(mem_ctx, b[0]);
+    bigdivmod(mem_ctx, a, b, r, NULL);
+    return r;
+}
+
+/*
+ * Compute (base ^ exp) % mod.
+ */
+Bignum dwc_modpow(void *mem_ctx, Bignum base_in, Bignum exp, Bignum mod)
+{
+    BignumInt *a, *b, *n, *m;
+    int mshift;
+    int mlen, i, j;
+    Bignum base, result;
+
+    /*
+     * The most significant word of mod needs to be non-zero. It
+     * should already be, but let's make sure.
+     */
+    //assert(mod[mod[0]] != 0);
+
+    /*
+     * Make sure the base is smaller than the modulus, by reducing
+     * it modulo the modulus if not.
+     */
+    base = bigmod(mem_ctx, base_in, mod);
+
+    /* Allocate m of size mlen, copy mod to m */
+    /* We use big endian internally */
+    mlen = mod[0];
+    m = snewn(mem_ctx, mlen, BignumInt);
+    //if (!m)
+    //abort();		       /* FIXME */
+    for (j = 0; j < mlen; j++)
+	m[j] = mod[mod[0] - j];
+
+    /* Shift m left to make msb bit set */
+    for (mshift = 0; mshift < BIGNUM_INT_BITS - 1; mshift++)
+	if ((m[0] << mshift) & BIGNUM_TOP_BIT)
+	    break;
+    if (mshift) {
+	for (i = 0; i < mlen - 1; i++)
+	    m[i] =
+		(m[i] << mshift) | (m[i + 1] >>
+				    (BIGNUM_INT_BITS - mshift));
+	m[mlen - 1] = m[mlen - 1] << mshift;
+    }
+
+    /* Allocate n of size mlen, copy base to n */
+    n = snewn(mem_ctx, mlen, BignumInt);
+    //if (!n)
+    //abort();		       /* FIXME */
+    i = mlen - base[0];
+    for (j = 0; j < i; j++)
+	n[j] = 0;
+    for (j = 0; j < base[0]; j++)
+	n[i + j] = base[base[0] - j];
+
+    /* Allocate a and b of size 2*mlen. Set a = 1 */
+    a = snewn(mem_ctx, 2 * mlen, BignumInt);
+    //if (!a)
+    //abort();		       /* FIXME */
+    b = snewn(mem_ctx, 2 * mlen, BignumInt);
+    //if (!b)
+    //abort();		       /* FIXME */
+    for (i = 0; i < 2 * mlen; i++)
+	a[i] = 0;
+    a[2 * mlen - 1] = 1;
+
+    /* Skip leading zero bits of exp. */
+    i = 0;
+    j = BIGNUM_INT_BITS - 1;
+    while (i < exp[0] && (exp[exp[0] - i] & (1 << j)) == 0) {
+	j--;
+	if (j < 0) {
+	    i++;
+	    j = BIGNUM_INT_BITS - 1;
+	}
+    }
+
+    /* Main computation */
+    while (i < exp[0]) {
+	while (j >= 0) {
+	    internal_mul(a + mlen, a + mlen, b, mlen);
+	    internal_mod(b, mlen * 2, m, mlen, NULL, 0);
+	    if ((exp[exp[0] - i] & (1 << j)) != 0) {
+		internal_mul(b + mlen, n, a, mlen);
+		internal_mod(a, mlen * 2, m, mlen, NULL, 0);
+	    } else {
+		BignumInt *t;
+		t = a;
+		a = b;
+		b = t;
+	    }
+	    j--;
+	}
+	i++;
+	j = BIGNUM_INT_BITS - 1;
+    }
+
+    /* Fixup result in case the modulus was shifted */
+    if (mshift) {
+	for (i = mlen - 1; i < 2 * mlen - 1; i++)
+	    a[i] =
+		(a[i] << mshift) | (a[i + 1] >>
+				    (BIGNUM_INT_BITS - mshift));
+	a[2 * mlen - 1] = a[2 * mlen - 1] << mshift;
+	internal_mod(a, mlen * 2, m, mlen, NULL, 0);
+	for (i = 2 * mlen - 1; i >= mlen; i--)
+	    a[i] =
+		(a[i] >> mshift) | (a[i - 1] <<
+				    (BIGNUM_INT_BITS - mshift));
+    }
+
+    /* Copy result to buffer */
+    result = newbn(mem_ctx, mod[0]);
+    for (i = 0; i < mlen; i++)
+	result[result[0] - i] = a[i + mlen];
+    while (result[0] > 1 && result[result[0]] == 0)
+	result[0]--;
+
+    /* Free temporary arrays */
+    for (i = 0; i < 2 * mlen; i++)
+	a[i] = 0;
+    sfree(mem_ctx, a);
+    for (i = 0; i < 2 * mlen; i++)
+	b[i] = 0;
+    sfree(mem_ctx, b);
+    for (i = 0; i < mlen; i++)
+	m[i] = 0;
+    sfree(mem_ctx, m);
+    for (i = 0; i < mlen; i++)
+	n[i] = 0;
+    sfree(mem_ctx, n);
+
+    freebn(mem_ctx, base);
+
+    return result;
+}
+
+
+#ifdef UNITTEST
+
+static __u32 dh_p[] = {
+	96,
+	0xFFFFFFFF,
+	0xFFFFFFFF,
+	0xA93AD2CA,
+	0x4B82D120,
+	0xE0FD108E,
+	0x43DB5BFC,
+	0x74E5AB31,
+	0x08E24FA0,
+	0xBAD946E2,
+	0x770988C0,
+	0x7A615D6C,
+	0xBBE11757,
+	0x177B200C,
+	0x521F2B18,
+	0x3EC86A64,
+	0xD8760273,
+	0xD98A0864,
+	0xF12FFA06,
+	0x1AD2EE6B,
+	0xCEE3D226,
+	0x4A25619D,
+	0x1E8C94E0,
+	0xDB0933D7,
+	0xABF5AE8C,
+	0xA6E1E4C7,
+	0xB3970F85,
+	0x5D060C7D,
+	0x8AEA7157,
+	0x58DBEF0A,
+	0xECFB8504,
+	0xDF1CBA64,
+	0xA85521AB,
+	0x04507A33,
+	0xAD33170D,
+	0x8AAAC42D,
+	0x15728E5A,
+	0x98FA0510,
+	0x15D22618,
+	0xEA956AE5,
+	0x3995497C,
+	0x95581718,
+	0xDE2BCBF6,
+	0x6F4C52C9,
+	0xB5C55DF0,
+	0xEC07A28F,
+	0x9B2783A2,
+	0x180E8603,
+	0xE39E772C,
+	0x2E36CE3B,
+	0x32905E46,
+	0xCA18217C,
+	0xF1746C08,
+	0x4ABC9804,
+	0x670C354E,
+	0x7096966D,
+	0x9ED52907,
+	0x208552BB,
+	0x1C62F356,
+	0xDCA3AD96,
+	0x83655D23,
+	0xFD24CF5F,
+	0x69163FA8,
+	0x1C55D39A,
+	0x98DA4836,
+	0xA163BF05,
+	0xC2007CB8,
+	0xECE45B3D,
+	0x49286651,
+	0x7C4B1FE6,
+	0xAE9F2411,
+	0x5A899FA5,
+	0xEE386BFB,
+	0xF406B7ED,
+	0x0BFF5CB6,
+	0xA637ED6B,
+	0xF44C42E9,
+	0x625E7EC6,
+	0xE485B576,
+	0x6D51C245,
+	0x4FE1356D,
+	0xF25F1437,
+	0x302B0A6D,
+	0xCD3A431B,
+	0xEF9519B3,
+	0x8E3404DD,
+	0x514A0879,
+	0x3B139B22,
+	0x020BBEA6,
+	0x8A67CC74,
+	0x29024E08,
+	0x80DC1CD1,
+	0xC4C6628B,
+	0x2168C234,
+	0xC90FDAA2,
+	0xFFFFFFFF,
+	0xFFFFFFFF,
+};
+
+static __u32 dh_a[] = {
+	8,
+	0xdf367516,
+	0x86459caa,
+	0xe2d459a4,
+	0xd910dae0,
+	0x8a8b5e37,
+	0x67ab31c6,
+	0xf0b55ea9,
+	0x440051d6,
+};
+
+static __u32 dh_b[] = {
+	8,
+	0xded92656,
+	0xe07a048a,
+	0x6fa452cd,
+	0x2df89d30,
+	0xc75f1b0f,
+	0x8ce3578f,
+	0x7980a324,
+	0x5daec786,
+};
+
+static __u32 dh_g[] = {
+	1,
+	2,
+};
+
+int main(void)
+{
+	int i;
+	__u32 *k;
+	k = dwc_modpow(NULL, dh_g, dh_a, dh_p);
+
+	printf("\n\n");
+	for (i=0; i<k[0]; i++) {
+		__u32 word32 = k[k[0] - i];
+		__u16 l = word32 & 0xffff;
+		__u16 m = (word32 & 0xffff0000) >> 16;
+		printf("%04x %04x ", m, l);
+		if (!((i + 1)%13)) printf("\n");
+	}
+	printf("\n\n");
+
+	if ((k[0] == 0x60) && (k[1] == 0x28e490e5) && (k[0x60] == 0x5a0d3d4e)) {
+		printf("PASS\n\n");
+	}
+	else {
+		printf("FAIL\n\n");
+	}
+
+}
+
+#endif /* UNITTEST */
+
+#endif /* CONFIG_MACH_IPMATE */
+
+#endif /*DWC_CRYPTOLIB */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_modpow.h b/drivers/usb/gadget/udc/hiudc/dwc_modpow.h
new file mode 100644
index 0000000..64f00c2
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_modpow.h
@@ -0,0 +1,34 @@
+/*
+ * dwc_modpow.h
+ * See dwc_modpow.c for license and changes
+ */
+#ifndef _DWC_MODPOW_H
+#define _DWC_MODPOW_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "dwc_os.h"
+
+/** @file
+ *
+ * This file defines the module exponentiation function which is only used
+ * internally by the DWC UWB modules for calculation of PKs during numeric
+ * association.  The routine is taken from the PUTTY, an open source terminal
+ * emulator.  The PUTTY License is preserved in the dwc_modpow.c file.
+ *
+ */
+
+typedef uint32_t BignumInt;
+typedef uint64_t BignumDblInt;
+typedef BignumInt *Bignum;
+
+/* Compute modular exponentiaion */
+extern Bignum dwc_modpow(void *mem_ctx, Bignum base_in, Bignum exp, Bignum mod);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _LINUX_BIGNUM_H */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_notifier.c b/drivers/usb/gadget/udc/hiudc/dwc_notifier.c
new file mode 100644
index 0000000..d3dadce
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_notifier.c
@@ -0,0 +1,319 @@
+#ifdef DWC_NOTIFYLIB
+
+#include "dwc_notifier.h"
+#include "dwc_list.h"
+
+typedef struct dwc_observer {
+	void *observer;
+	dwc_notifier_callback_t callback;
+	void *data;
+	char *notification;
+	DWC_CIRCLEQ_ENTRY(dwc_observer) list_entry;
+} observer_t;
+
+DWC_CIRCLEQ_HEAD(observer_queue, dwc_observer);
+
+typedef struct dwc_notifier {
+	void *mem_ctx;
+	void *object;
+	struct observer_queue observers;
+	DWC_CIRCLEQ_ENTRY(dwc_notifier) list_entry;
+} notifier_t;
+
+DWC_CIRCLEQ_HEAD(notifier_queue, dwc_notifier);
+
+typedef struct manager {
+	void *mem_ctx;
+	void *wkq_ctx;
+	dwc_workq_t *wq;
+//	dwc_mutex_t *mutex;
+	struct notifier_queue notifiers;
+} manager_t;
+
+static manager_t *manager = NULL;
+
+static int create_manager(void *mem_ctx, void *wkq_ctx)
+{
+	manager = dwc_alloc(mem_ctx, sizeof(manager_t));
+	if (!manager) {
+		return -DWC_E_NO_MEMORY;
+	}
+
+	DWC_CIRCLEQ_INIT(&manager->notifiers);
+
+	manager->wq = dwc_workq_alloc(wkq_ctx, "DWC Notification WorkQ");
+	if (!manager->wq) {
+		return -DWC_E_NO_MEMORY;
+	}
+
+	return 0;
+}
+
+static void free_manager(void)
+{
+	dwc_workq_free(manager->wq);
+
+	/* All notifiers must have unregistered themselves before this module
+	 * can be removed.  Hitting this assertion indicates a programmer
+	 * error. */
+	DWC_ASSERT(DWC_CIRCLEQ_EMPTY(&manager->notifiers),
+		   "Notification manager being freed before all notifiers have been removed");
+	dwc_free(manager->mem_ctx, manager);
+}
+
+#ifdef DEBUG
+static void dump_manager(void)
+{
+	notifier_t *n;
+	observer_t *o;
+
+	DWC_ASSERT(manager, "Notification manager not found");
+
+	DWC_DEBUG("List of all notifiers and observers:\n");
+	DWC_CIRCLEQ_FOREACH(n, &manager->notifiers, list_entry) {
+		DWC_DEBUG("Notifier %p has observers:\n", n->object);
+		DWC_CIRCLEQ_FOREACH(o, &n->observers, list_entry) {
+			DWC_DEBUG("    %p watching %s\n", o->observer, o->notification);
+		}
+	}
+}
+#else
+#define dump_manager(...)
+#endif
+
+static observer_t *alloc_observer(void *mem_ctx, void *observer, char *notification,
+				  dwc_notifier_callback_t callback, void *data)
+{
+	observer_t *new_observer = dwc_alloc(mem_ctx, sizeof(observer_t));
+
+	if (!new_observer) {
+		return NULL;
+	}
+
+	DWC_CIRCLEQ_INIT_ENTRY(new_observer, list_entry);
+	new_observer->observer = observer;
+	new_observer->notification = notification;
+	new_observer->callback = callback;
+	new_observer->data = data;
+	return new_observer;
+}
+
+static void free_observer(void *mem_ctx, observer_t *observer)
+{
+	dwc_free(mem_ctx, observer);
+}
+
+static notifier_t *alloc_notifier(void *mem_ctx, void *object)
+{
+	notifier_t *notifier;
+
+	if (!object) {
+		return NULL;
+	}
+
+	notifier = dwc_alloc(mem_ctx, sizeof(notifier_t));
+	if (!notifier) {
+		return NULL;
+	}
+
+	DWC_CIRCLEQ_INIT(&notifier->observers);
+	DWC_CIRCLEQ_INIT_ENTRY(notifier, list_entry);
+
+	notifier->mem_ctx = mem_ctx;
+	notifier->object = object;
+	return notifier;
+}
+
+static void free_notifier(notifier_t *notifier)
+{
+	observer_t *observer;
+
+	DWC_CIRCLEQ_FOREACH(observer, &notifier->observers, list_entry) {
+		free_observer(notifier->mem_ctx, observer);
+	}
+
+	dwc_free(notifier->mem_ctx, notifier);
+}
+
+static notifier_t *find_notifier(void *object)
+{
+	notifier_t *notifier;
+
+	DWC_ASSERT(manager, "Notification manager not found");
+
+	if (!object) {
+		return NULL;
+	}
+
+	DWC_CIRCLEQ_FOREACH(notifier, &manager->notifiers, list_entry) {
+		if (notifier->object == object) {
+			return notifier;
+		}
+	}
+
+	return NULL;
+}
+
+int dwc_alloc_notification_manager(void *mem_ctx, void *wkq_ctx)
+{
+	return create_manager(mem_ctx, wkq_ctx);
+}
+
+void dwc_free_notification_manager(void)
+{
+	free_manager();
+}
+
+dwc_notifier_t *dwc_register_notifier(void *mem_ctx, void *object)
+{
+	notifier_t *notifier;
+
+	DWC_ASSERT(manager, "Notification manager not found");
+
+	notifier = find_notifier(object);
+	if (notifier) {
+		DWC_ERROR("Notifier %p is already registered\n", object);
+		return NULL;
+	}
+
+	notifier = alloc_notifier(mem_ctx, object);
+	if (!notifier) {
+		return NULL;
+	}
+
+	DWC_CIRCLEQ_INSERT_TAIL(&manager->notifiers, notifier, list_entry);
+
+	DWC_INFO("Notifier %p registered", object);
+	dump_manager();
+
+	return notifier;
+}
+
+void dwc_unregister_notifier(dwc_notifier_t *notifier)
+{
+	DWC_ASSERT(manager, "Notification manager not found");
+
+	if (!DWC_CIRCLEQ_EMPTY(&notifier->observers)) {
+		observer_t *o;
+
+		DWC_ERROR("Notifier %p has active observers when removing\n", notifier->object);
+		DWC_CIRCLEQ_FOREACH(o, &notifier->observers, list_entry) {
+			DWC_DEBUG("    %p watching %s\n", o->observer, o->notification);
+		}
+
+		DWC_ASSERT(DWC_CIRCLEQ_EMPTY(&notifier->observers),
+			   "Notifier %p has active observers when removing", notifier);
+	}
+
+	DWC_CIRCLEQ_REMOVE_INIT(&manager->notifiers, notifier, list_entry);
+	free_notifier(notifier);
+
+	DWC_INFO("Notifier unregistered");
+	dump_manager();
+}
+
+/* Add an observer to observe the notifier for a particular state, event, or notification. */
+int dwc_add_observer(void *observer, void *object, char *notification,
+		     dwc_notifier_callback_t callback, void *data)
+{
+	notifier_t *notifier = find_notifier(object);
+	observer_t *new_observer;
+
+	if (!notifier) {
+		DWC_ERROR("Notifier %p is not found when adding observer\n", object);
+		return -DWC_E_INVALID;
+	}
+
+	new_observer = alloc_observer(notifier->mem_ctx, observer, notification, callback, data);
+	if (!new_observer) {
+		return -DWC_E_NO_MEMORY;
+	}
+
+	DWC_CIRCLEQ_INSERT_TAIL(&notifier->observers, new_observer, list_entry);
+
+	DWC_INFO("Added observer %p to notifier %p observing notification %s, callback=%p, data=%p",
+		 observer, object, notification, callback, data);
+
+	dump_manager();
+	return 0;
+}
+
+int dwc_remove_observer(void *observer)
+{
+	notifier_t *n;
+
+	DWC_ASSERT(manager, "Notification manager not found");
+
+	DWC_CIRCLEQ_FOREACH(n, &manager->notifiers, list_entry) {
+		observer_t *o;
+		observer_t *o2;
+
+		DWC_CIRCLEQ_FOREACH_SAFE(o, o2, &n->observers, list_entry) {
+			if (o->observer == observer) {
+				DWC_CIRCLEQ_REMOVE_INIT(&n->observers, o, list_entry);
+				DWC_INFO("Removing observer %p from notifier %p watching notification %s:",
+					 o->observer, n->object, o->notification);
+				free_observer(n->mem_ctx, o);
+			}
+		}
+	}
+
+	dump_manager();
+	return 0;
+}
+
+typedef struct callback_data {
+	void *mem_ctx;
+	dwc_notifier_callback_t cb;
+	void *observer;
+	void *data;
+	void *object;
+	char *notification;
+	void *notification_data;
+} cb_data_t;
+
+static void cb_task(void *data)
+{
+	cb_data_t *cb = (cb_data_t *)data;
+
+	cb->cb(cb->object, cb->notification, cb->observer, cb->notification_data, cb->data);
+	dwc_free(cb->mem_ctx, cb);
+}
+
+void dwc_notify(dwc_notifier_t *notifier, char *notification, void *notification_data)
+{
+	observer_t *o;
+
+	DWC_ASSERT(manager, "Notification manager not found");
+
+	DWC_CIRCLEQ_FOREACH(o, &notifier->observers, list_entry) {
+		int len = DWC_STRLEN(notification);
+
+		if (DWC_STRLEN(o->notification) != len) {
+			continue;
+		}
+
+		if (DWC_STRNCMP(o->notification, notification, len) == 0) {
+			cb_data_t *cb_data = dwc_alloc(notifier->mem_ctx, sizeof(cb_data_t));
+
+			if (!cb_data) {
+				DWC_ERROR("Failed to allocate callback data\n");
+				return;
+			}
+
+			cb_data->mem_ctx = notifier->mem_ctx;
+			cb_data->cb = o->callback;
+			cb_data->observer = o->observer;
+			cb_data->data = o->data;
+			cb_data->object = notifier->object;
+			cb_data->notification = notification;
+			cb_data->notification_data = notification_data;
+			DWC_DEBUG("Observer found %p for notification %s\n", o->observer, notification);
+			DWC_WORKQ_SCHEDULE(manager->wq, cb_task, cb_data,
+					   "Notify callback from %p for Notification %s, to observer %p",
+					   cb_data->object, notification, cb_data->observer);
+		}
+	}
+}
+
+#endif	/* DWC_NOTIFYLIB */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_notifier.h b/drivers/usb/gadget/udc/hiudc/dwc_notifier.h
new file mode 100644
index 0000000..4a8cdfe
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_notifier.h
@@ -0,0 +1,122 @@
+
+#ifndef __DWC_NOTIFIER_H__
+#define __DWC_NOTIFIER_H__
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "dwc_os.h"
+
+/** @file
+ *
+ * A simple implementation of the Observer pattern.  Any "module" can
+ * register as an observer or notifier.  The notion of "module" is abstract and
+ * can mean anything used to identify either an observer or notifier.  Usually
+ * it will be a pointer to a data structure which contains some state, ie an
+ * object.
+ *
+ * Before any notifiers can be added, the global notification manager must be
+ * brought up with dwc_alloc_notification_manager().
+ * dwc_free_notification_manager() will bring it down and free all resources.
+ * These would typically be called upon module load and unload.  The
+ * notification manager is a single global instance that handles all registered
+ * observable modules and observers so this should be done only once.
+ *
+ * A module can be observable by using Notifications to publicize some general
+ * information about it's state or operation.  It does not care who listens, or
+ * even if anyone listens, or what they do with the information.  The observable
+ * modules do not need to know any information about it's observers or their
+ * interface, or their state or data.
+ *
+ * Any module can register to emit Notifications.  It should publish a list of
+ * notifications that it can emit and their behavior, such as when they will get
+ * triggered, and what information will be provided to the observer.  Then it
+ * should register itself as an observable module. See dwc_register_notifier().
+ *
+ * Any module can observe any observable, registered module, provided it has a
+ * handle to the other module and knows what notifications to observe.  See
+ * dwc_add_observer().
+ *
+ * A function of type dwc_notifier_callback_t is called whenever a notification
+ * is triggered with one or more observers observing it.  This function is
+ * called in it's own process so it may sleep or block if needed.  It is
+ * guaranteed to be called sometime after the notification has occurred and will
+ * be called once per each time the notification is triggered.  It will NOT be
+ * called in the same process context used to trigger the notification.
+ *
+ * @section Limitiations
+ *
+ * Keep in mind that Notifications that can be triggered in rapid sucession may
+ * schedule too many processes too handle.  Be aware of this limitation when
+ * designing to use notifications, and only add notifications for appropriate
+ * observable information.
+ *
+ * Also Notification callbacks are not synchronous.  If you need to synchronize
+ * the behavior between module/observer you must use other means.  And perhaps
+ * that will mean Notifications are not the proper solution.
+ */
+
+struct dwc_notifier;
+typedef struct dwc_notifier dwc_notifier_t;
+
+/** The callback function must be of this type.
+ *
+ * @param object This is the object that is being observed.
+ * @param notification This is the notification that was triggered.
+ * @param observer This is the observer
+ * @param notification_data This is notification-specific data that the notifier
+ * has included in this notification.  The value of this should be published in
+ * the documentation of the observable module with the notifications.
+ * @param user_data This is any custom data that the observer provided when
+ * adding itself as an observer to the notification. */
+typedef void (*dwc_notifier_callback_t)(void *object, char *notification, void *observer,
+					void *notification_data, void *user_data);
+
+/** Brings up the notification manager. */
+extern int dwc_alloc_notification_manager(void *mem_ctx, void *wkq_ctx);
+/** Brings down the notification manager. */
+extern void dwc_free_notification_manager(void);
+
+/** This function registers an observable module.  A dwc_notifier_t object is
+ * returned to the observable module.  This is an opaque object that is used by
+ * the observable module to trigger notifications.  This object should only be
+ * accessible to functions that are authorized to trigger notifications for this
+ * module.  Observers do not need this object. */
+extern dwc_notifier_t *dwc_register_notifier(void *mem_ctx, void *object);
+
+/** This function unregisters an observable module.  All observers have to be
+ * removed prior to unregistration. */
+extern void dwc_unregister_notifier(dwc_notifier_t *notifier);
+
+/** Add a module as an observer to the observable module.  The observable module
+ * needs to have previously registered with the notification manager.
+ *
+ * @param observer The observer module
+ * @param object The module to observe
+ * @param notification The notification to observe
+ * @param callback The callback function to call
+ * @param user_data Any additional user data to pass into the callback function */
+extern int dwc_add_observer(void *observer, void *object, char *notification,
+			    dwc_notifier_callback_t callback, void *user_data);
+
+/** Removes the specified observer from all notifications that it is currently
+ * observing. */
+extern int dwc_remove_observer(void *observer);
+
+/** This function triggers a Notification.  It should be called by the
+ * observable module, or any module or library which the observable module
+ * allows to trigger notification on it's behalf.  Such as the dwc_cc_t.
+ *
+ * dwc_notify is a non-blocking function.  Callbacks are scheduled called in
+ * their own process context for each trigger.  Callbacks can be blocking.
+ * dwc_notify can be called from interrupt context if needed.
+ *
+ */
+void dwc_notify(dwc_notifier_t *notifier, char *notification, void *notification_data);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* __DWC_NOTIFIER_H__ */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_os.h b/drivers/usb/gadget/udc/hiudc/dwc_os.h
new file mode 100644
index 0000000..0d0b1ed
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_os.h
@@ -0,0 +1,1200 @@
+/* =========================================================================
+ * $File: //dwh/usb_iip/dev/software/dwc_common_port_2/dwc_os.h $
+ * $Revision: #14 $
+ * $Date: 2010/11/04 $
+ * $Change: 1621695 $
+ *
+ * Synopsys Portability Library Software and documentation
+ * (hereinafter, "Software") is an Unsupported proprietary work of
+ * Synopsys, Inc. unless otherwise expressly agreed to in writing
+ * between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product
+ * under any End User Software License Agreement or Agreement for
+ * Licensed Product with Synopsys or any supplement thereto. You are
+ * permitted to use and redistribute this Software in source and binary
+ * forms, with or without modification, provided that redistributions
+ * of source code must retain this notice. You may not view, use,
+ * disclose, copy or distribute this file or any information contained
+ * herein except pursuant to this license grant from Synopsys. If you
+ * do not agree with this notice, including the disclaimer below, then
+ * you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS"
+ * BASIS AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+ * FOR A PARTICULAR PURPOSE ARE HEREBY DISCLAIMED. IN NO EVENT SHALL
+ * SYNOPSYS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
+ * USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================= */
+#ifndef _DWC_OS_H_
+#define _DWC_OS_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/** @file
+ *
+ * DWC portability library, low level os-wrapper functions
+ *
+ */
+
+/* These basic types need to be defined by some OS header file or custom header
+ * file for your specific target architecture.
+ *
+ * uint8_t, int8_t, uint16_t, int16_t, uint32_t, int32_t, uint64_t, int64_t
+ *
+ * Any custom or alternate header file must be added and enabled here.
+ */
+
+#ifdef DWC_LINUX
+# include <linux/types.h>
+# ifdef CONFIG_DEBUG_MUTEXES
+#  include <linux/mutex.h>
+# endif
+# include <linux/errno.h>
+# include <stdarg.h>
+#endif
+
+#if defined(DWC_FREEBSD) || defined(DWC_NETBSD)
+# include <os_dep.h>
+#endif
+
+
+/** @name Primitive Types and Values */
+
+/** We define a boolean type for consistency.  Can be either YES or NO */
+typedef uint8_t dwc_bool_t;
+#define YES  1
+#define NO   0
+
+#ifdef DWC_LINUX
+
+/** @name Error Codes */
+#define DWC_E_INVALID		EINVAL
+#define DWC_E_NO_MEMORY		ENOMEM
+#define DWC_E_NO_DEVICE		ENODEV
+#define DWC_E_NOT_SUPPORTED	EOPNOTSUPP
+#define DWC_E_TIMEOUT		ETIMEDOUT
+#define DWC_E_BUSY		EBUSY
+#define DWC_E_AGAIN		EAGAIN
+#define DWC_E_RESTART		ERESTART
+#define DWC_E_ABORT		ECONNABORTED
+#define DWC_E_SHUTDOWN		ESHUTDOWN
+#define DWC_E_NO_DATA		ENODATA
+#define DWC_E_DISCONNECT	ECONNRESET
+#define DWC_E_UNKNOWN		EINVAL
+#define DWC_E_NO_STREAM_RES	ENOSR
+#define DWC_E_COMMUNICATION	ECOMM
+#define DWC_E_OVERFLOW		EOVERFLOW
+#define DWC_E_PROTOCOL		EPROTO
+#define DWC_E_IN_PROGRESS	EINPROGRESS
+#define DWC_E_PIPE		EPIPE
+#define DWC_E_IO		EIO
+#define DWC_E_NO_SPACE		ENOSPC
+
+#else
+
+/** @name Error Codes */
+#define DWC_E_INVALID		1001
+#define DWC_E_NO_MEMORY		1002
+#define DWC_E_NO_DEVICE		1003
+#define DWC_E_NOT_SUPPORTED	1004
+#define DWC_E_TIMEOUT		1005
+#define DWC_E_BUSY		1006
+#define DWC_E_AGAIN		1007
+#define DWC_E_RESTART		1008
+#define DWC_E_ABORT		1009
+#define DWC_E_SHUTDOWN		1010
+#define DWC_E_NO_DATA		1011
+#define DWC_E_DISCONNECT	2000
+#define DWC_E_UNKNOWN		3000
+#define DWC_E_NO_STREAM_RES	4001
+#define DWC_E_COMMUNICATION	4002
+#define DWC_E_OVERFLOW		4003
+#define DWC_E_PROTOCOL		4004
+#define DWC_E_IN_PROGRESS	4005
+#define DWC_E_PIPE		4006
+#define DWC_E_IO		4007
+#define DWC_E_NO_SPACE		4008
+
+#endif
+
+
+/** @name Tracing/Logging Functions
+ *
+ * These function provide the capability to add tracing, debugging, and error
+ * messages, as well exceptions as assertions.  The WUDEV uses these
+ * extensively.  These could be logged to the main console, the serial port, an
+ * internal buffer, etc.  These functions could also be no-op if they are too
+ * expensive on your system.  By default undefining the DEBUG macro already
+ * no-ops some of these functions. */
+
+/** Returns non-zero if in interrupt context. */
+extern dwc_bool_t DWC_IN_IRQ(void);
+#define dwc_in_irq DWC_IN_IRQ
+
+/** Returns "IRQ" if DWC_IN_IRQ is true. */
+static inline char *dwc_irq(void) {
+	return DWC_IN_IRQ() ? "IRQ" : "";
+}
+
+/** Returns non-zero if in bottom-half context. */
+extern dwc_bool_t DWC_IN_BH(void);
+#define dwc_in_bh DWC_IN_BH
+
+/** Returns "BH" if DWC_IN_BH is true. */
+static inline char *dwc_bh(void) {
+	return DWC_IN_BH() ? "BH" : "";
+}
+
+/**
+ * A vprintf() clone.  Just call vprintf if you've got it.
+ */
+extern void DWC_VPRINTF(char *format, va_list args);
+#define dwc_vprintf DWC_VPRINTF
+
+/**
+ * A vsnprintf() clone.  Just call vprintf if you've got it.
+ */
+extern int DWC_VSNPRINTF(char *str, int size, char *format, va_list args);
+#define dwc_vsnprintf DWC_VSNPRINTF
+
+/**
+ * printf() clone.  Just call printf if you've go it.
+ */
+extern void DWC_PRINTF(char *format, ...)
+/* This provides compiler level static checking of the parameters if you're
+ * using GCC. */
+#ifdef __GNUC__
+	__attribute__ ((format(printf, 1, 2)));
+#else
+	;
+#endif
+#define dwc_printf DWC_PRINTF
+
+/**
+ * sprintf() clone.  Just call sprintf if you've got it.
+ */
+extern int DWC_SPRINTF(char *string, char *format, ...)
+#ifdef __GNUC__
+	__attribute__ ((format(printf, 2, 3)));
+#else
+	;
+#endif
+#define dwc_sprintf DWC_SPRINTF
+
+/**
+ * snprintf() clone.  Just call snprintf if you've got it.
+ */
+extern int DWC_SNPRINTF(char *string, int size, char *format, ...)
+#ifdef __GNUC__
+	__attribute__ ((format(printf, 3, 4)));
+#else
+	;
+#endif
+#define dwc_snprintf DWC_SNPRINTF
+
+/**
+ * Prints a WARNING message.  On systems that don't differentiate between
+ * warnings and regular log messages, just print it.  Indicates that something
+ * may be wrong with the driver.  Works like printf().
+ *
+ * Use the DWC_WARN macro to call this function.
+ */
+extern void __DWC_WARN(char *format, ...)
+#ifdef __GNUC__
+	__attribute__ ((format(printf, 1, 2)));
+#else
+	;
+#endif
+
+/**
+ * Prints an error message.  On systems that don't differentiate between errors
+ * and regular log messages, just print it.  Indicates that something went wrong
+ * with the driver.  Works like printf().
+ *
+ * Use the DWC_ERROR macro to call this function.
+ */
+extern void __DWC_ERROR(char *format, ...)
+#ifdef __GNUC__
+	__attribute__ ((format(printf, 1, 2)));
+#else
+	;
+#endif
+
+/**
+ * Prints an exception error message and takes some user-defined action such as
+ * print out a backtrace or trigger a breakpoint.  Indicates that something went
+ * abnormally wrong with the driver such as programmer error, or other
+ * exceptional condition.  It should not be ignored so even on systems without
+ * printing capability, some action should be taken to notify the developer of
+ * it.  Works like printf().
+ */
+extern void DWC_EXCEPTION(char *format, ...)
+#ifdef __GNUC__
+	__attribute__ ((format(printf, 1, 2)));
+#else
+	;
+#endif
+#define dwc_exception DWC_EXCEPTION
+
+#ifdef DEBUG
+/**
+ * Prints out a debug message.  Used for logging/trace messages.
+ *
+ * Use the DWC_DEBUG macro to call this function
+ */
+extern void __DWC_DEBUG(char *format, ...)
+#ifdef __GNUC__
+	__attribute__ ((format(printf, 1, 2)));
+#else
+	;
+#endif
+#else
+#define __DWC_DEBUG(...)
+#endif
+
+/**
+ * Prints out a Debug message.
+ */
+#define DWC_DEBUG(_format, _args...) __DWC_DEBUG("DEBUG:%s:%s: " _format "\n", \
+						 __func__, dwc_irq(), ## _args)
+#define dwc_debug DWC_DEBUG
+/**
+ * Prints out an informative message.
+ */
+#define DWC_INFO(_format, _args...) DWC_PRINTF("INFO:%s: " _format "\n", \
+					       dwc_irq(), ## _args)
+#define dwc_info DWC_INFO
+/**
+ * Prints out a warning message.
+ */
+#define DWC_WARN(_format, _args...) __DWC_WARN("WARN:%s:%s:%d: " _format "\n", \
+					dwc_irq(), __func__, __LINE__, ## _args)
+#define dwc_warn DWC_WARN
+/**
+ * Prints out an error message.
+ */
+#define DWC_ERROR(_format, _args...) __DWC_ERROR("ERROR:%s:%s:%d: " _format "\n", \
+					dwc_irq(), __func__, __LINE__, ## _args)
+#define dwc_error DWC_ERROR
+
+#define DWC_PROTO_ERROR(_format, _args...) __DWC_WARN("ERROR:%s:%s:%d: " _format "\n", \
+						dwc_irq(), __func__, __LINE__, ## _args)
+#define dwc_proto_error DWC_PROTO_ERROR
+
+#ifdef DEBUG
+/** Prints out a exception error message if the _expr expression fails.  Disabled
+ * if DEBUG is not enabled. */
+#define DWC_ASSERT(_expr, _format, _args...) do { \
+	if (!(_expr)) { DWC_EXCEPTION("%s:%s:%d: " _format "\n", dwc_irq(), \
+				      __FILE__, __LINE__, ## _args); } \
+	} while (0)
+#else
+#define DWC_ASSERT(_x...)
+#endif
+#define dwc_assert DWC_ASSERT
+
+
+/** @name Byte Ordering
+ * The following functions are for conversions between processor's byte ordering
+ * and specific ordering you want.
+ */
+
+/** Converts 32 bit data in CPU byte ordering to little endian. */
+extern uint32_t DWC_CPU_TO_LE32(uint32_t *p);
+#define dwc_cpu_to_le32 DWC_CPU_TO_LE32
+
+/** Converts 32 bit data in CPU byte orderint to big endian. */
+extern uint32_t DWC_CPU_TO_BE32(uint32_t *p);
+#define dwc_cpu_to_be32 DWC_CPU_TO_BE32
+
+/** Converts 32 bit little endian data to CPU byte ordering. */
+extern uint32_t DWC_LE32_TO_CPU(uint32_t *p);
+#define dwc_le32_to_cpu DWC_LE32_TO_CPU
+
+/** Converts 32 bit big endian data to CPU byte ordering. */
+extern uint32_t DWC_BE32_TO_CPU(uint32_t *p);
+#define dwc_be32_to_cpu DWC_BE32_TO_CPU
+
+/** Converts 16 bit data in CPU byte ordering to little endian. */
+extern uint16_t DWC_CPU_TO_LE16(uint16_t *p);
+#define dwc_cpu_to_le16 DWC_CPU_TO_LE16
+
+/** Converts 16 bit data in CPU byte orderint to big endian. */
+extern uint16_t DWC_CPU_TO_BE16(uint16_t *p);
+#define dwc_cpu_to_be16 DWC_CPU_TO_BE16
+
+/** Converts 16 bit little endian data to CPU byte ordering. */
+extern uint16_t DWC_LE16_TO_CPU(uint16_t *p);
+#define dwc_le16_to_cpu DWC_LE16_TO_CPU
+
+/** Converts 16 bit bi endian data to CPU byte ordering. */
+extern uint16_t DWC_BE16_TO_CPU(uint16_t *p);
+#define dwc_be16_to_cpu DWC_BE16_TO_CPU
+
+
+/** @name Register Read/Write
+ *
+ * The following six functions should be implemented to read/write registers of
+ * 32-bit and 64-bit sizes.  All modules use this to read/write register values.
+ * The reg value is a pointer to the register calculated from the void *base
+ * variable passed into the driver when it is started.  */
+
+#ifdef DWC_LINUX
+/* Linux doesn't need any extra parameters for register read/write, so we
+ * just throw away the IO context parameter.
+ */
+/** Reads the content of a 32-bit register. */
+extern uint32_t DWC_READ_REG32(uint32_t volatile *reg);
+#define dwc_read_reg32(_ctx_,_reg_) DWC_READ_REG32(_reg_)
+
+/** Reads the content of a 64-bit register. */
+extern uint64_t DWC_READ_REG64(uint64_t volatile *reg);
+#define dwc_read_reg64(_ctx_,_reg_) DWC_READ_REG64(_reg_)
+
+/** Writes to a 32-bit register. */
+extern void DWC_WRITE_REG32(uint32_t volatile *reg, uint32_t value);
+#define dwc_write_reg32(_ctx_,_reg_,_val_) DWC_WRITE_REG32(_reg_, _val_)
+
+/** Writes to a 64-bit register. */
+extern void DWC_WRITE_REG64(uint64_t volatile *reg, uint64_t value);
+#define dwc_write_reg64(_ctx_,_reg_,_val_) DWC_WRITE_REG64(_reg_, _val_)
+
+/**
+ * Modify bit values in a register.  Using the
+ * algorithm: (reg_contents & ~clear_mask) | set_mask.
+ */
+extern void DWC_MODIFY_REG32(uint32_t volatile *reg, uint32_t clear_mask, uint32_t set_mask);
+#define dwc_modify_reg32(_ctx_,_reg_,_cmsk_,_smsk_) DWC_MODIFY_REG32(_reg_,_cmsk_,_smsk_)
+extern void DWC_MODIFY_REG64(uint64_t volatile *reg, uint64_t clear_mask, uint64_t set_mask);
+#define dwc_modify_reg64(_ctx_,_reg_,_cmsk_,_smsk_) DWC_MODIFY_REG64(_reg_,_cmsk_,_smsk_)
+
+#endif	/* DWC_LINUX */
+
+#if defined(DWC_FREEBSD) || defined(DWC_NETBSD)
+typedef struct dwc_ioctx {
+	struct device *dev;
+	bus_space_tag_t iot;
+	bus_space_handle_t ioh;
+} dwc_ioctx_t;
+
+/** BSD needs two extra parameters for register read/write, so we pass
+ * them in using the IO context parameter.
+ */
+/** Reads the content of a 32-bit register. */
+extern uint32_t DWC_READ_REG32(void *io_ctx, uint32_t volatile *reg);
+#define dwc_read_reg32 DWC_READ_REG32
+
+/** Reads the content of a 64-bit register. */
+extern uint64_t DWC_READ_REG64(void *io_ctx, uint64_t volatile *reg);
+#define dwc_read_reg64 DWC_READ_REG64
+
+/** Writes to a 32-bit register. */
+extern void DWC_WRITE_REG32(void *io_ctx, uint32_t volatile *reg, uint32_t value);
+#define dwc_write_reg32 DWC_WRITE_REG32
+
+/** Writes to a 64-bit register. */
+extern void DWC_WRITE_REG64(void *io_ctx, uint64_t volatile *reg, uint64_t value);
+#define dwc_write_reg64 DWC_WRITE_REG64
+
+/**
+ * Modify bit values in a register.  Using the
+ * algorithm: (reg_contents & ~clear_mask) | set_mask.
+ */
+extern void DWC_MODIFY_REG32(void *io_ctx, uint32_t volatile *reg, uint32_t clear_mask, uint32_t set_mask);
+#define dwc_modify_reg32 DWC_MODIFY_REG32
+extern void DWC_MODIFY_REG64(void *io_ctx, uint64_t volatile *reg, uint64_t clear_mask, uint64_t set_mask);
+#define dwc_modify_reg64 DWC_MODIFY_REG64
+
+#endif	/* DWC_FREEBSD || DWC_NETBSD */
+
+/** @cond */
+
+/** @name Some convenience MACROS used internally.  Define DWC_DEBUG_REGS to log the
+ * register writes. */
+
+#ifdef DWC_LINUX
+
+# ifdef DWC_DEBUG_REGS
+
+#define dwc_define_read_write_reg_n(_reg,_container_type) \
+static inline uint32_t dwc_read_##_reg##_n(_container_type *container, int num) { \
+	return DWC_READ_REG32(&container->regs->_reg[num]); \
+} \
+static inline void dwc_write_##_reg##_n(_container_type *container, int num, uint32_t data) { \
+	DWC_DEBUG("WRITING %8s[%d]: %p: %08x", #_reg, num, \
+		  &(((uint32_t*)container->regs->_reg)[num]), data); \
+	DWC_WRITE_REG32(&(((uint32_t*)container->regs->_reg)[num]), data); \
+}
+
+#define dwc_define_read_write_reg(_reg,_container_type) \
+static inline uint32_t dwc_read_##_reg(_container_type *container) { \
+	return DWC_READ_REG32(&container->regs->_reg); \
+} \
+static inline void dwc_write_##_reg(_container_type *container, uint32_t data) { \
+	DWC_DEBUG("WRITING %11s: %p: %08x", #_reg, &container->regs->_reg, data); \
+	DWC_WRITE_REG32(&container->regs->_reg, data); \
+}
+
+# else	/* DWC_DEBUG_REGS */
+
+#define dwc_define_read_write_reg_n(_reg,_container_type) \
+static inline uint32_t dwc_read_##_reg##_n(_container_type *container, int num) { \
+	return DWC_READ_REG32(&container->regs->_reg[num]); \
+} \
+static inline void dwc_write_##_reg##_n(_container_type *container, int num, uint32_t data) { \
+	DWC_WRITE_REG32(&(((uint32_t*)container->regs->_reg)[num]), data); \
+}
+
+#define dwc_define_read_write_reg(_reg,_container_type) \
+static inline uint32_t dwc_read_##_reg(_container_type *container) { \
+	return DWC_READ_REG32(&container->regs->_reg); \
+} \
+static inline void dwc_write_##_reg(_container_type *container, uint32_t data) { \
+	DWC_WRITE_REG32(&container->regs->_reg, data); \
+}
+
+# endif	/* DWC_DEBUG_REGS */
+
+#endif	/* DWC_LINUX */
+
+#if defined(DWC_FREEBSD) || defined(DWC_NETBSD)
+
+# ifdef DWC_DEBUG_REGS
+
+#define dwc_define_read_write_reg_n(_reg,_container_type) \
+static inline uint32_t dwc_read_##_reg##_n(void *io_ctx, _container_type *container, int num) { \
+	return DWC_READ_REG32(io_ctx, &container->regs->_reg[num]); \
+} \
+static inline void dwc_write_##_reg##_n(void *io_ctx, _container_type *container, int num, uint32_t data) { \
+	DWC_DEBUG("WRITING %8s[%d]: %p: %08x", #_reg, num, \
+		  &(((uint32_t*)container->regs->_reg)[num]), data); \
+	DWC_WRITE_REG32(io_ctx, &(((uint32_t*)container->regs->_reg)[num]), data); \
+}
+
+#define dwc_define_read_write_reg(_reg,_container_type) \
+static inline uint32_t dwc_read_##_reg(void *io_ctx, _container_type *container) { \
+	return DWC_READ_REG32(io_ctx, &container->regs->_reg); \
+} \
+static inline void dwc_write_##_reg(void *io_ctx, _container_type *container, uint32_t data) { \
+	DWC_DEBUG("WRITING %11s: %p: %08x", #_reg, &container->regs->_reg, data); \
+	DWC_WRITE_REG32(io_ctx, &container->regs->_reg, data); \
+}
+
+# else	/* DWC_DEBUG_REGS */
+
+#define dwc_define_read_write_reg_n(_reg,_container_type) \
+static inline uint32_t dwc_read_##_reg##_n(void *io_ctx, _container_type *container, int num) { \
+	return DWC_READ_REG32(io_ctx, &container->regs->_reg[num]); \
+} \
+static inline void dwc_write_##_reg##_n(void *io_ctx, _container_type *container, int num, uint32_t data) { \
+	DWC_WRITE_REG32(io_ctx, &(((uint32_t*)container->regs->_reg)[num]), data); \
+}
+
+#define dwc_define_read_write_reg(_reg,_container_type) \
+static inline uint32_t dwc_read_##_reg(void *io_ctx, _container_type *container) { \
+	return DWC_READ_REG32(io_ctx, &container->regs->_reg); \
+} \
+static inline void dwc_write_##_reg(void *io_ctx, _container_type *container, uint32_t data) { \
+	DWC_WRITE_REG32(io_ctx, &container->regs->_reg, data); \
+}
+
+# endif	/* DWC_DEBUG_REGS */
+
+#endif	/* DWC_FREEBSD || DWC_NETBSD */
+
+/** @endcond */
+
+
+#ifdef DWC_CRYPTOLIB
+/** @name Crypto Functions
+ *
+ * These are the low-level cryptographic functions used by the driver. */
+
+/** Perform AES CBC */
+extern int DWC_AES_CBC(uint8_t *message, uint32_t messagelen, uint8_t *key, uint32_t keylen, uint8_t iv[16], uint8_t *out);
+#define dwc_aes_cbc DWC_AES_CBC
+
+/** Fill the provided buffer with random bytes.  These should be cryptographic grade random numbers. */
+extern void DWC_RANDOM_BYTES(uint8_t *buffer, uint32_t length);
+#define dwc_random_bytes DWC_RANDOM_BYTES
+
+/** Perform the SHA-256 hash function */
+extern int DWC_SHA256(uint8_t *message, uint32_t len, uint8_t *out);
+#define dwc_sha256 DWC_SHA256
+
+/** Calculated the HMAC-SHA256 */
+extern int DWC_HMAC_SHA256(uint8_t *message, uint32_t messagelen, uint8_t *key, uint32_t keylen, uint8_t *out);
+#define dwc_hmac_sha256 DWC_HMAC_SHA256
+
+#endif	/* DWC_CRYPTOLIB */
+
+
+/** @name Memory Allocation
+ *
+ * These function provide access to memory allocation.  There are only 2 DMA
+ * functions and 3 Regular memory functions that need to be implemented.  None
+ * of the memory debugging routines need to be implemented.  The allocation
+ * routines all ZERO the contents of the memory.
+ *
+ * Defining DWC_DEBUG_MEMORY turns on memory debugging and statistic gathering.
+ * This checks for memory leaks, keeping track of alloc/free pairs.  It also
+ * keeps track of how much memory the driver is using at any given time. */
+
+#define DWC_PAGE_SIZE 4096
+#define DWC_PAGE_OFFSET(addr) (((uint32_t)addr) & 0xfff)
+#define DWC_PAGE_ALIGNED(addr) ((((uint32_t)addr) & 0xfff) == 0)
+
+#define DWC_INVALID_DMA_ADDR 0x0
+
+#ifdef DWC_LINUX
+/** Type for a DMA address */
+typedef dma_addr_t dwc_dma_t;
+#endif
+
+#if defined(DWC_FREEBSD) || defined(DWC_NETBSD)
+typedef bus_addr_t dwc_dma_t;
+#endif
+
+#ifdef DWC_FREEBSD
+typedef struct dwc_dmactx {
+	struct device *dev;
+	bus_dma_tag_t dma_tag;
+	bus_dmamap_t dma_map;
+	bus_addr_t dma_paddr;
+	void *dma_vaddr;
+} dwc_dmactx_t;
+#endif
+
+#ifdef DWC_NETBSD
+typedef struct dwc_dmactx {
+	struct device *dev;
+	bus_dma_tag_t dma_tag;
+	bus_dmamap_t dma_map;
+	bus_dma_segment_t segs[1];
+	int nsegs;
+	bus_addr_t dma_paddr;
+	void *dma_vaddr;
+} dwc_dmactx_t;
+#endif
+
+/** Allocates a DMA capable buffer and zeroes its contents. */
+extern void *__DWC_DMA_ALLOC(void *dma_ctx, uint32_t size, dwc_dma_t *dma_addr);
+
+/** Allocates a DMA capable buffer and zeroes its contents in atomic contest */
+extern void *__DWC_DMA_ALLOC_ATOMIC(void *dma_ctx, uint32_t size, dwc_dma_t *dma_addr);
+
+/** Frees a previously allocated buffer. */
+extern void __DWC_DMA_FREE(void *dma_ctx, uint32_t size, void *virt_addr, dwc_dma_t dma_addr);
+
+/** Allocates a block of memory and zeroes its contents. */
+extern void *__DWC_ALLOC(void *mem_ctx, uint32_t size);
+
+/** Allocates a block of memory and zeroes its contents, in an atomic manner
+ * which can be used inside interrupt context.  The size should be sufficiently
+ * small, a few KB at most, such that failures are not likely to occur.  Can just call
+ * __DWC_ALLOC if it is atomic. */
+extern void *__DWC_ALLOC_ATOMIC(void *mem_ctx, uint32_t size);
+
+/** Frees a previously allocated buffer. */
+extern void __DWC_FREE(void *mem_ctx, void *addr);
+
+#ifndef DWC_DEBUG_MEMORY
+
+#define DWC_ALLOC(_size_) __DWC_ALLOC(NULL, _size_)
+#define DWC_ALLOC_ATOMIC(_size_) __DWC_ALLOC_ATOMIC(NULL, _size_)
+#define DWC_FREE(_addr_) __DWC_FREE(NULL, _addr_)
+
+# ifdef DWC_LINUX
+#define DWC_DMA_ALLOC(_size_,_dma_) __DWC_DMA_ALLOC(NULL, _size_, _dma_)
+#define DWC_DMA_ALLOC_ATOMIC(_size_,_dma_) __DWC_DMA_ALLOC_ATOMIC(NULL, _size_,_dma_)
+#define DWC_DMA_FREE(_size_,_virt_,_dma_) __DWC_DMA_FREE(NULL, _size_, _virt_, _dma_)
+# endif
+
+# if defined(DWC_FREEBSD) || defined(DWC_NETBSD)
+#define DWC_DMA_ALLOC __DWC_DMA_ALLOC
+#define DWC_DMA_FREE __DWC_DMA_FREE
+# endif
+
+#else	/* DWC_DEBUG_MEMORY */
+
+extern void *dwc_alloc_debug(void *mem_ctx, uint32_t size, char const *func, int line);
+extern void *dwc_alloc_atomic_debug(void *mem_ctx, uint32_t size, char const *func, int line);
+extern void dwc_free_debug(void *mem_ctx, void *addr, char const *func, int line);
+extern void *dwc_dma_alloc_debug(void *dma_ctx, uint32_t size, dwc_dma_t *dma_addr,
+				 char const *func, int line);
+extern void *dwc_dma_alloc_atomic_debug(void *dma_ctx, uint32_t size, dwc_dma_t *dma_addr,
+				char const *func, int line);
+extern void dwc_dma_free_debug(void *dma_ctx, uint32_t size, void *virt_addr,
+			       dwc_dma_t dma_addr, char const *func, int line);
+
+extern int dwc_memory_debug_start(void *mem_ctx);
+extern void dwc_memory_debug_stop(void);
+extern void dwc_memory_debug_report(void);
+
+#define DWC_ALLOC(_size_) dwc_alloc_debug(NULL, _size_, __func__, __LINE__)
+#define DWC_ALLOC_ATOMIC(_size_) dwc_alloc_atomic_debug(NULL, _size_, \
+							__func__, __LINE__)
+#define DWC_FREE(_addr_) dwc_free_debug(NULL, _addr_, __func__, __LINE__)
+
+# ifdef DWC_LINUX
+#define DWC_DMA_ALLOC(_size_,_dma_) dwc_dma_alloc_debug(NULL, _size_, \
+						_dma_, __func__, __LINE__)
+#define DWC_DMA_ALLOC_ATOMIC(_size_,_dma_) dwc_dma_alloc_atomic_debug(NULL, _size_, \
+						_dma_, __func__, __LINE__)
+#define DWC_DMA_FREE(_size_,_virt_,_dma_) dwc_dma_free_debug(NULL, _size_, \
+						_virt_, _dma_, __func__, __LINE__)
+# endif
+
+# if defined(DWC_FREEBSD) || defined(DWC_NETBSD)
+#define DWC_DMA_ALLOC(_ctx_,_size_,_dma_) dwc_dma_alloc_debug(_ctx_, _size_, \
+						_dma_, __func__, __LINE__)
+#define DWC_DMA_FREE(_ctx_,_size_,_virt_,_dma_) dwc_dma_free_debug(_ctx_, _size_, \
+						 _virt_, _dma_, __func__, __LINE__)
+# endif
+
+#endif /* DWC_DEBUG_MEMORY */
+
+#define dwc_alloc(_ctx_,_size_) DWC_ALLOC(_size_)
+#define dwc_alloc_atomic(_ctx_,_size_) DWC_ALLOC_ATOMIC(_size_)
+#define dwc_free(_ctx_,_addr_) DWC_FREE(_addr_)
+
+#ifdef DWC_LINUX
+/* Linux doesn't need any extra parameters for DMA buffer allocation, so we
+ * just throw away the DMA context parameter.
+ */
+#define dwc_dma_alloc(_ctx_,_size_,_dma_) DWC_DMA_ALLOC(_size_, _dma_)
+#define dwc_dma_alloc_atomic(_ctx_,_size_,_dma_) DWC_DMA_ALLOC_ATOMIC(_size_, _dma_)
+#define dwc_dma_free(_ctx_,_size_,_virt_,_dma_) DWC_DMA_FREE(_size_, _virt_, _dma_)
+#endif
+
+#if defined(DWC_FREEBSD) || defined(DWC_NETBSD)
+/** BSD needs several extra parameters for DMA buffer allocation, so we pass
+ * them in using the DMA context parameter.
+ */
+#define dwc_dma_alloc DWC_DMA_ALLOC
+#define dwc_dma_free DWC_DMA_FREE
+#endif
+
+
+/** @name Memory and String Processing */
+
+/** memset() clone */
+extern void *DWC_MEMSET(void *dest, uint8_t byte, uint32_t size);
+#define dwc_memset DWC_MEMSET
+
+/** memcpy() clone */
+extern void *DWC_MEMCPY(void *dest, void const *src, uint32_t size);
+#define dwc_memcpy DWC_MEMCPY
+
+/** memmove() clone */
+extern void *DWC_MEMMOVE(void *dest, void *src, uint32_t size);
+#define dwc_memmove DWC_MEMMOVE
+
+/** memcmp() clone */
+extern int DWC_MEMCMP(void *m1, void *m2, uint32_t size);
+#define dwc_memcmp DWC_MEMCMP
+
+/** strcmp() clone */
+extern int DWC_STRCMP(void *s1, void *s2);
+#define dwc_strcmp DWC_STRCMP
+
+/** strncmp() clone */
+extern int DWC_STRNCMP(void *s1, void *s2, uint32_t size);
+#define dwc_strncmp DWC_STRNCMP
+
+/** strlen() clone, for NULL terminated ASCII strings */
+extern int DWC_STRLEN(char const *str);
+#define dwc_strlen DWC_STRLEN
+
+/** strcpy() clone, for NULL terminated ASCII strings */
+extern char *DWC_STRCPY(char *to, const char *from);
+#define dwc_strcpy DWC_STRCPY
+
+/** strdup() clone.  If you wish to use memory allocation debugging, this
+ * implementation of strdup should use the DWC_* memory routines instead of
+ * calling a predefined strdup.  Otherwise the memory allocated by this routine
+ * will not be seen by the debugging routines. */
+extern char *DWC_STRDUP(char const *str);
+#define dwc_strdup(_ctx_,_str_) DWC_STRDUP(_str_)
+
+/** NOT an atoi() clone.  Read the description carefully.  Returns an integer
+ * converted from the string str in base 10 unless the string begins with a "0x"
+ * in which case it is base 16.  String must be a NULL terminated sequence of
+ * ASCII characters and may optionally begin with whitespace, a + or -, and a
+ * "0x" prefix if base 16.  The remaining characters must be valid digits for
+ * the number and end with a NULL character.  If any invalid characters are
+ * encountered or it returns with a negative error code and the results of the
+ * conversion are undefined.  On sucess it returns 0.  Overflow conditions are
+ * undefined.  An example implementation using atoi() can be referenced from the
+ * Linux implementation. */
+extern int DWC_ATOI(const char *str, int32_t *value);
+#define dwc_atoi DWC_ATOI
+
+/** Same as above but for unsigned. */
+extern int DWC_ATOUI(const char *str, uint32_t *value);
+#define dwc_atoui DWC_ATOUI
+
+#ifdef DWC_UTFLIB
+/** This routine returns a UTF16LE unicode encoded string from a UTF8 string. */
+extern int DWC_UTF8_TO_UTF16LE(uint8_t const *utf8string, uint16_t *utf16string, unsigned len);
+#define dwc_utf8_to_utf16le DWC_UTF8_TO_UTF16LE
+#endif
+
+
+/** @name Wait queues
+ *
+ * Wait queues provide a means of synchronizing between threads or processes.  A
+ * process can block on a waitq if some condition is not true, waiting for it to
+ * become true.  When the waitq is triggered all waiting process will get
+ * unblocked and the condition will be check again.  Waitqs should be triggered
+ * every time a condition can potentially change.*/
+struct dwc_waitq;
+
+/** Type for a waitq */
+typedef struct dwc_waitq dwc_waitq_t;
+
+/** The type of waitq condition callback function.  This is called every time
+ * condition is evaluated. */
+typedef int (*dwc_waitq_condition_t)(void *data);
+
+/** Allocate a waitq */
+extern dwc_waitq_t *DWC_WAITQ_ALLOC(void);
+#define dwc_waitq_alloc(_ctx_) DWC_WAITQ_ALLOC()
+
+/** Free a waitq */
+extern void DWC_WAITQ_FREE(dwc_waitq_t *wq);
+#define dwc_waitq_free DWC_WAITQ_FREE
+
+/** Check the condition and if it is false, block on the waitq.  When unblocked, check the
+ * condition again.  The function returns when the condition becomes true.  The return value
+ * is 0 on condition true, DWC_WAITQ_ABORTED on abort or killed, or DWC_WAITQ_UNKNOWN on error. */
+extern int32_t DWC_WAITQ_WAIT(dwc_waitq_t *wq, dwc_waitq_condition_t cond, void *data);
+#define dwc_waitq_wait DWC_WAITQ_WAIT
+
+/** Check the condition and if it is false, block on the waitq.  When unblocked,
+ * check the condition again.  The function returns when the condition become
+ * true or the timeout has passed.  The return value is 0 on condition true or
+ * DWC_TIMED_OUT on timeout, or DWC_WAITQ_ABORTED, or DWC_WAITQ_UNKNOWN on
+ * error. */
+extern int32_t DWC_WAITQ_WAIT_TIMEOUT(dwc_waitq_t *wq, dwc_waitq_condition_t cond,
+				      void *data, int32_t msecs);
+#define dwc_waitq_wait_timeout DWC_WAITQ_WAIT_TIMEOUT
+
+/** Trigger a waitq, unblocking all processes.  This should be called whenever a condition
+ * has potentially changed. */
+extern void DWC_WAITQ_TRIGGER(dwc_waitq_t *wq);
+#define dwc_waitq_trigger DWC_WAITQ_TRIGGER
+
+/** Unblock all processes waiting on the waitq with an ABORTED result. */
+extern void DWC_WAITQ_ABORT(dwc_waitq_t *wq);
+#define dwc_waitq_abort DWC_WAITQ_ABORT
+
+
+/** @name Threads
+ *
+ * A thread must be explicitly stopped.  It must check DWC_THREAD_SHOULD_STOP
+ * whenever it is woken up, and then return.  The DWC_THREAD_STOP function
+ * returns the value from the thread.
+ */
+
+struct dwc_thread;
+
+/** Type for a thread */
+typedef struct dwc_thread dwc_thread_t;
+
+/** The thread function */
+typedef int (*dwc_thread_function_t)(void *data);
+
+/** Create a thread and start it running the thread_function.  Returns a handle
+ * to the thread */
+extern dwc_thread_t *DWC_THREAD_RUN(dwc_thread_function_t func, char *name, void *data);
+#define dwc_thread_run(_ctx_,_func_,_name_,_data_) DWC_THREAD_RUN(_func_, _name_, _data_)
+
+/** Stops a thread.  Return the value returned by the thread.  Or will return
+ * DWC_ABORT if the thread never started. */
+extern int DWC_THREAD_STOP(dwc_thread_t *thread);
+#define dwc_thread_stop DWC_THREAD_STOP
+
+/** Signifies to the thread that it must stop. */
+#ifdef DWC_LINUX
+/* Linux doesn't need any parameters for kthread_should_stop() */
+extern dwc_bool_t DWC_THREAD_SHOULD_STOP(void);
+#define dwc_thread_should_stop(_thrd_) DWC_THREAD_SHOULD_STOP()
+
+/* No thread_exit function in Linux */
+#define dwc_thread_exit(_thrd_)
+#endif
+
+#if defined(DWC_FREEBSD) || defined(DWC_NETBSD)
+/** BSD needs the thread pointer for kthread_suspend_check() */
+extern dwc_bool_t DWC_THREAD_SHOULD_STOP(dwc_thread_t *thread);
+#define dwc_thread_should_stop DWC_THREAD_SHOULD_STOP
+
+/** The thread must call this to exit. */
+extern void DWC_THREAD_EXIT(dwc_thread_t *thread);
+#define dwc_thread_exit DWC_THREAD_EXIT
+#endif
+
+
+/** @name Work queues
+ *
+ * Workqs are used to queue a callback function to be called at some later time,
+ * in another thread. */
+struct dwc_workq;
+
+/** Type for a workq */
+typedef struct dwc_workq dwc_workq_t;
+
+/** The type of the callback function to be called. */
+typedef void (*dwc_work_callback_t)(void *data);
+
+/** Allocate a workq */
+extern dwc_workq_t *DWC_WORKQ_ALLOC(char *name);
+#define dwc_workq_alloc(_ctx_,_name_) DWC_WORKQ_ALLOC(_name_)
+
+/** Free a workq.  All work must be completed before being freed. */
+extern void DWC_WORKQ_FREE(dwc_workq_t *workq);
+#define dwc_workq_free DWC_WORKQ_FREE
+
+/** Schedule a callback on the workq, passing in data.  The function will be
+ * scheduled at some later time. */
+extern void DWC_WORKQ_SCHEDULE(dwc_workq_t *workq, dwc_work_callback_t cb,
+			       void *data, char *format, ...)
+#ifdef __GNUC__
+	__attribute__ ((format(printf, 4, 5)));
+#else
+	;
+#endif
+#define dwc_workq_schedule DWC_WORKQ_SCHEDULE
+
+/** Schedule a callback on the workq, that will be called until at least
+ * given number miliseconds have passed. */
+extern void DWC_WORKQ_SCHEDULE_DELAYED(dwc_workq_t *workq, dwc_work_callback_t cb,
+				       void *data, uint32_t time, char *format, ...)
+#ifdef __GNUC__
+	__attribute__ ((format(printf, 5, 6)));
+#else
+	;
+#endif
+#define dwc_workq_schedule_delayed DWC_WORKQ_SCHEDULE_DELAYED
+
+/** The number of processes in the workq */
+extern int DWC_WORKQ_PENDING(dwc_workq_t *workq);
+#define dwc_workq_pending DWC_WORKQ_PENDING
+
+/** Blocks until all the work in the workq is complete or timed out.  Returns <
+ * 0 on timeout. */
+extern int DWC_WORKQ_WAIT_WORK_DONE(dwc_workq_t *workq, int timeout);
+#define dwc_workq_wait_work_done DWC_WORKQ_WAIT_WORK_DONE
+
+
+/** @name Tasklets
+ *
+ */
+struct dwc_tasklet;
+
+/** Type for a tasklet */
+typedef struct dwc_tasklet dwc_tasklet_t;
+
+/** The type of the callback function to be called */
+typedef void (*dwc_tasklet_callback_t)(void *data);
+
+/** Allocates a tasklet */
+extern dwc_tasklet_t *DWC_TASK_ALLOC(char *name, dwc_tasklet_callback_t cb, void *data);
+#define dwc_task_alloc(_ctx_,_name_,_cb_,_data_) DWC_TASK_ALLOC(_name_, _cb_, _data_)
+
+/** Frees a tasklet */
+extern void DWC_TASK_FREE(dwc_tasklet_t *task);
+#define dwc_task_free DWC_TASK_FREE
+
+/** Schedules a tasklet to run */
+extern void DWC_TASK_SCHEDULE(dwc_tasklet_t *task);
+#define dwc_task_schedule DWC_TASK_SCHEDULE
+
+
+/** @name Timer
+ *
+ * Callbacks must be small and atomic.
+ */
+struct dwc_timer;
+
+/** Type for a timer */
+typedef struct dwc_timer dwc_timer_t;
+
+/** The type of the callback function to be called */
+typedef void (*dwc_timer_callback_t)(void *data);
+
+/** Allocates a timer */
+extern dwc_timer_t *DWC_TIMER_ALLOC(char *name, dwc_timer_callback_t cb, void *data);
+#define dwc_timer_alloc(_ctx_,_name_,_cb_,_data_) DWC_TIMER_ALLOC(_name_,_cb_,_data_)
+
+/** Frees a timer */
+extern void DWC_TIMER_FREE(dwc_timer_t *timer);
+#define dwc_timer_free DWC_TIMER_FREE
+
+/** Schedules the timer to run at time ms from now.  And will repeat at every
+ * repeat_interval msec therafter
+ *
+ * Modifies a timer that is still awaiting execution to a new expiration time.
+ * The mod_time is added to the old time.  */
+extern void DWC_TIMER_SCHEDULE(dwc_timer_t *timer, uint32_t time);
+#define dwc_timer_schedule DWC_TIMER_SCHEDULE
+
+/** Disables the timer from execution. */
+extern void DWC_TIMER_CANCEL(dwc_timer_t *timer);
+#define dwc_timer_cancel DWC_TIMER_CANCEL
+
+
+/** @name Spinlocks
+ *
+ * These locks are used when the work between the lock/unlock is atomic and
+ * short.  Interrupts are also disabled during the lock/unlock and thus they are
+ * suitable to lock between interrupt/non-interrupt context.  They also lock
+ * between processes if you have multiple CPUs or Preemption.  If you don't have
+ * multiple CPUS or Preemption, then the you can simply implement the
+ * DWC_SPINLOCK and DWC_SPINUNLOCK to disable and enable interrupts.  Because
+ * the work between the lock/unlock is atomic, the process context will never
+ * change, and so you never have to lock between processes.  */
+
+struct dwc_spinlock;
+
+/** Type for a spinlock */
+typedef struct dwc_spinlock dwc_spinlock_t;
+
+/** Type for the 'flags' argument to spinlock funtions */
+typedef unsigned long dwc_irqflags_t;
+
+/** Returns an initialized lock variable.  This function should allocate and
+ * initialize the OS-specific data structure used for locking.  This data
+ * structure is to be used for the DWC_LOCK and DWC_UNLOCK functions and should
+ * be freed by the DWC_FREE_LOCK when it is no longer used. */
+extern dwc_spinlock_t *DWC_SPINLOCK_ALLOC(void);
+#define dwc_spinlock_alloc(_ctx_) DWC_SPINLOCK_ALLOC()
+
+/** Frees an initialized lock variable. */
+extern void DWC_SPINLOCK_FREE(dwc_spinlock_t *lock);
+#define dwc_spinlock_free(_ctx_,_lock_) DWC_SPINLOCK_FREE(_lock_)
+
+/** Disables interrupts and blocks until it acquires the lock.
+ *
+ * @param lock Pointer to the spinlock.
+ * @param flags Unsigned long for irq flags storage.
+ */
+extern void DWC_SPINLOCK_IRQSAVE(dwc_spinlock_t *lock, dwc_irqflags_t *flags);
+#define dwc_spinlock_irqsave DWC_SPINLOCK_IRQSAVE
+
+/** Re-enables the interrupt and releases the lock.
+ *
+ * @param lock Pointer to the spinlock.
+ * @param flags Unsigned long for irq flags storage.  Must be the same as was
+ * passed into DWC_LOCK.
+ */
+extern void DWC_SPINUNLOCK_IRQRESTORE(dwc_spinlock_t *lock, dwc_irqflags_t flags);
+#define dwc_spinunlock_irqrestore DWC_SPINUNLOCK_IRQRESTORE
+
+/** Blocks until it acquires the lock.
+ *
+ * @param lock Pointer to the spinlock.
+ */
+extern void DWC_SPINLOCK(dwc_spinlock_t *lock);
+#define dwc_spinlock DWC_SPINLOCK
+
+/** Releases the lock.
+ *
+ * @param lock Pointer to the spinlock.
+ */
+extern void DWC_SPINUNLOCK(dwc_spinlock_t *lock);
+#define dwc_spinunlock DWC_SPINUNLOCK
+
+
+/** @name Mutexes
+ *
+ * Unlike spinlocks Mutexes lock only between processes and the work between the
+ * lock/unlock CAN block, therefore it CANNOT be called from interrupt context.
+ */
+
+struct dwc_mutex;
+
+/** Type for a mutex */
+typedef struct dwc_mutex dwc_mutex_t;
+
+/* For Linux Mutex Debugging make it inline because the debugging routines use
+ * the symbol to determine recursive locking.  This makes it falsely think
+ * recursive locking occurs. */
+#if defined(DWC_LINUX) && defined(CONFIG_DEBUG_MUTEXES)
+#define DWC_MUTEX_ALLOC_LINUX_DEBUG(__mutexp) ({ \
+	__mutexp = (dwc_mutex_t *)DWC_ALLOC(sizeof(struct mutex)); \
+	mutex_init((struct mutex *)__mutexp); \
+})
+#endif
+
+/** Allocate a mutex */
+extern dwc_mutex_t *DWC_MUTEX_ALLOC(void);
+#define dwc_mutex_alloc(_ctx_) DWC_MUTEX_ALLOC()
+
+/* For memory leak debugging when using Linux Mutex Debugging */
+#if defined(DWC_LINUX) && defined(CONFIG_DEBUG_MUTEXES)
+#define DWC_MUTEX_FREE(__mutexp) do { \
+	mutex_destroy((struct mutex *)__mutexp); \
+	DWC_FREE(__mutexp); \
+} while(0)
+#else
+/** Free a mutex */
+extern void DWC_MUTEX_FREE(dwc_mutex_t *mutex);
+#define dwc_mutex_free(_ctx_,_mutex_) DWC_MUTEX_FREE(_mutex_)
+#endif
+
+/** Lock a mutex */
+extern void DWC_MUTEX_LOCK(dwc_mutex_t *mutex);
+#define dwc_mutex_lock DWC_MUTEX_LOCK
+
+/** Non-blocking lock returns 1 on successful lock. */
+extern int DWC_MUTEX_TRYLOCK(dwc_mutex_t *mutex);
+#define dwc_mutex_trylock DWC_MUTEX_TRYLOCK
+
+/** Unlock a mutex */
+extern void DWC_MUTEX_UNLOCK(dwc_mutex_t *mutex);
+#define dwc_mutex_unlock DWC_MUTEX_UNLOCK
+
+
+/** @name Time */
+
+/** Microsecond delay.
+ *
+ * @param usecs  Microseconds to delay.
+ */
+extern void DWC_UDELAY(uint32_t usecs);
+#define dwc_udelay DWC_UDELAY
+
+/** Millisecond delay.
+ *
+ * @param msecs  Milliseconds to delay.
+ */
+extern void DWC_MDELAY(uint32_t msecs);
+#define dwc_mdelay DWC_MDELAY
+
+/** Non-busy waiting.
+ * Sleeps for specified number of milliseconds.
+ *
+ * @param msecs Milliseconds to sleep.
+ */
+extern void DWC_MSLEEP(uint32_t msecs);
+#define dwc_msleep DWC_MSLEEP
+
+/**
+ * Returns number of milliseconds since boot.
+ */
+extern uint32_t DWC_TIME(void);
+#define dwc_time DWC_TIME
+
+
+
+
+/* @mainpage DWC Portability and Common Library
+ *
+ * This is the documentation for the DWC Portability and Common Library.
+ *
+ * @section intro Introduction
+ *
+ * The DWC Portability library consists of wrapper calls and data structures to
+ * all low-level functions which are typically provided by the OS.  The WUDEV
+ * driver uses only these functions.  In order to port the WUDEV driver, only
+ * the functions in this library need to be re-implemented, with the same
+ * behavior as documented here.
+ *
+ * The Common library consists of higher level functions, which rely only on
+ * calling the functions from the DWC Portability library.  These common
+ * routines are shared across modules.  Some of the common libraries need to be
+ * used directly by the driver programmer when porting WUDEV.  Such as the
+ * parameter and notification libraries.
+ *
+ * @section low Portability Library OS Wrapper Functions
+ *
+ * Any function starting with DWC and in all CAPS is a low-level OS-wrapper that
+ * needs to be implemented when porting, for example DWC_MUTEX_ALLOC().  All of
+ * these functions are included in the dwc_os.h file.
+ *
+ * There are many functions here covering a wide array of OS services.  Please
+ * see dwc_os.h for details, and implementation notes for each function.
+ *
+ * @section common Common Library Functions
+ *
+ * Any function starting with dwc and in all lowercase is a common library
+ * routine.  These functions have a portable implementation and do not need to
+ * be reimplemented when porting.  The common routines can be used by any
+ * driver, and some must be used by the end user to control the drivers.  For
+ * example, you must use the Parameter common library in order to set the
+ * parameters in the WUDEV module.
+ *
+ * The common libraries consist of the following:
+ *
+ * - Connection Contexts - Used internally and can be used by end-user.  See dwc_cc.h
+ * - Parameters - Used internally and can be used by end-user.  See dwc_params.h
+ * - Notifications - Used internally and can be used by end-user.  See dwc_notifier.h
+ * - Lists - Used internally and can be used by end-user.  See dwc_list.h
+ * - Memory Debugging - Used internally and can be used by end-user.  See dwc_os.h
+ * - Modpow - Used internally only.  See dwc_modpow.h
+ * - DH - Used internally only.  See dwc_dh.h
+ * - Crypto - Used internally only.  See dwc_crypto.h
+ *
+ *
+ * @section prereq Prerequistes For dwc_os.h
+ * @subsection types Data Types
+ *
+ * The dwc_os.h file assumes that several low-level data types are pre defined for the
+ * compilation environment.  These data types are:
+ *
+ * - uint8_t - unsigned 8-bit data type
+ * - int8_t - signed 8-bit data type
+ * - uint16_t - unsigned 16-bit data type
+ * - int16_t - signed 16-bit data type
+ * - uint32_t - unsigned 32-bit data type
+ * - int32_t - signed 32-bit data type
+ * - uint64_t - unsigned 64-bit data type
+ * - int64_t - signed 64-bit data type
+ *
+ * Ensure that these are defined before using dwc_os.h.  The easiest way to do
+ * that is to modify the top of the file to include the appropriate header.
+ * This is already done for the Linux environment.  If the DWC_LINUX macro is
+ * defined, the correct header will be added.  A standard header <stdint.h> is
+ * also used for environments where standard C headers are available.
+ *
+ * @subsection stdarg Variable Arguments
+ *
+ * Variable arguments are provided by a standard C header <stdarg.h>.  it is
+ * available in Both the Linux and ANSI C enviornment.  An equivalent must be
+ * provided in your enviornment in order to use dwc_os.h with the debug and
+ * tracing message functionality.
+ *
+ * @subsection thread Threading
+ *
+ * WUDEV Core must be run on an operating system that provides for multiple
+ * threads/processes.  Threading can be implemented in many ways, even in
+ * embedded systems without an operating system.  At the bare minimum, the
+ * system should be able to start any number of processes at any time to handle
+ * special work.  It need not be a pre-emptive system.  Process context can
+ * change upon a call to a blocking function.  The hardware interrupt context
+ * that calls the module's ISR() function must be differentiable from process
+ * context, even if your processes are impemented via a hardware interrupt.
+ * Further locking mechanism between process must exist (or be implemented), and
+ * process context must have a way to disable interrupts for a period of time to
+ * lock them out.  If all of this exists, the functions in dwc_os.h related to
+ * threading should be able to be implemented with the defined behavior.
+ *
+ */
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _DWC_OS_H_ */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_adp.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_adp.c
new file mode 100644
index 0000000..fdf4f6e
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_adp.c
@@ -0,0 +1,718 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_adp.c $
+ * $Revision: #16 $
+ * $Date: 2013/04/22 $
+ * $Change: 2211149 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#include "dwc_os.h"
+#include "dwc_otg_regs.h"
+#include "dwc_otg_cil.h"
+#include "dwc_otg_adp.h"
+
+/** @file
+ *
+ * This file contains the most of the Attach Detect Protocol implementation for
+ * the driver to support OTG Rev2.0.
+ *
+ */
+
+void dwc_otg_adp_write_reg(dwc_otg_core_if_t * core_if, uint32_t value)
+{
+	adpctl_data_t adpctl;
+
+	adpctl.d32 = value;
+	adpctl.b.ar = 0x2;
+
+	DWC_WRITE_REG32(&core_if->core_global_regs->adpctl, adpctl.d32);
+
+	while (adpctl.b.ar) {
+		adpctl.d32 = DWC_READ_REG32(&core_if->core_global_regs->adpctl);
+	}
+
+}
+
+/**
+ * Function is called to read ADP registers
+ */
+uint32_t dwc_otg_adp_read_reg(dwc_otg_core_if_t * core_if)
+{
+	adpctl_data_t adpctl;
+
+	adpctl.d32 = 0;
+	adpctl.b.ar = 0x1;
+
+	DWC_WRITE_REG32(&core_if->core_global_regs->adpctl, adpctl.d32);
+
+	while (adpctl.b.ar) {
+		adpctl.d32 = DWC_READ_REG32(&core_if->core_global_regs->adpctl);
+	}
+
+	return adpctl.d32;
+}
+
+/**
+ * Function is called to read ADPCTL register and filter Write-clear bits
+ */
+uint32_t dwc_otg_adp_read_reg_filter(dwc_otg_core_if_t * core_if)
+{
+	adpctl_data_t adpctl;
+
+	adpctl.d32 = dwc_otg_adp_read_reg(core_if);
+	adpctl.b.adp_tmout_int = 0;
+	adpctl.b.adp_prb_int = 0;
+	adpctl.b.adp_tmout_int = 0;
+
+	return adpctl.d32;
+}
+
+/**
+ * Function is called to write ADP registers
+ */
+void dwc_otg_adp_modify_reg(dwc_otg_core_if_t * core_if, uint32_t clr,
+			    uint32_t set)
+{
+	dwc_otg_adp_write_reg(core_if,
+			      (dwc_otg_adp_read_reg(core_if) & (~clr)) | set);
+}
+
+/**
+ * Start the ADP Initial Probe timer to detect if Port Connected interrupt is
+ * not asserted within 1.1 seconds.
+ *
+ * @param core_if the pointer to core_if strucure.
+ */
+void dwc_otg_adp_vbuson_timer_start(dwc_otg_core_if_t * core_if)
+{
+	core_if->adp.vbuson_timer_started = 1;
+	if (core_if->adp.vbuson_timer)
+	{
+		DWC_PRINTF("SCHEDULING VBUSON TIMER\n");
+		/* 1.1 secs + 60ms necessary for cil_hcd_start*/
+		DWC_TIMER_SCHEDULE(core_if->adp.vbuson_timer, 1160);
+	} else {
+		DWC_WARN("VBUSON_TIMER = %p\n",core_if->adp.vbuson_timer);
+	}
+}
+
+/**
+ * Starts the ADP Probing
+ *
+ * @param core_if the pointer to core_if structure.
+ */
+uint32_t dwc_otg_adp_probe_start(dwc_otg_core_if_t * core_if)
+{
+
+	adpctl_data_t adpctl = {.d32 = 0};
+	gpwrdn_data_t gpwrdn;
+
+	if (core_if->stop_adpprb) {
+		core_if->stop_adpprb = 0;
+		return 0;
+	}
+
+	dwc_otg_disable_global_interrupts(core_if);
+	DWC_DEBUGPL(DBG_ANY, "ADP Probe Start\n");
+	core_if->adp.probe_enabled = 1;
+
+	adpctl.b.adpres = 1;
+	dwc_otg_adp_write_reg(core_if, adpctl.d32);
+
+	while (adpctl.b.adpres) {
+		adpctl.d32 = dwc_otg_adp_read_reg(core_if);
+	}
+
+	adpctl.d32 = 0;
+	gpwrdn.d32 = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+
+	/* In Host mode unmask SRP detected interrupt also change the
+	 * probe preiod accordingly */
+	if (!gpwrdn.b.idsts) {
+		gpwrdn.d32 = 0;
+		gpwrdn.b.srp_det_msk = 1;
+		adpctl.b.prb_per = 0;
+	}
+	else {
+		gpwrdn.d32 = 0;
+		gpwrdn.b.srp_det_msk = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, gpwrdn.d32, 0);
+		gpwrdn.d32 = 0;
+		gpwrdn.b.sts_chngint_msk = 1;
+		adpctl.b.prb_per = 1;
+	}
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+
+	adpctl.b.adp_tmout_int_msk = 1;
+	adpctl.b.adp_prb_int_msk = 1;
+	adpctl.b.prb_dschg = 1;
+	adpctl.b.prb_delta = 1;
+	dwc_otg_adp_write_reg(core_if, adpctl.d32);
+
+	adpctl.b.adpen = 1;
+	adpctl.b.enaprb = 1;
+	dwc_otg_adp_write_reg(core_if, adpctl.d32);
+	DWC_DEBUGPL(DBG_ANY, "ADP Probe Finish\n");
+
+	return 0;
+}
+
+/**
+ * Starts the ADP Sense timer to detect if ADP Sense interrupt is not asserted
+ * within 3 seconds.
+ *
+ * @param core_if the pointer to core_if strucure.
+ */
+void dwc_otg_adp_sense_timer_start(dwc_otg_core_if_t * core_if)
+{
+	core_if->adp.sense_timer_started = 1;
+	DWC_TIMER_SCHEDULE(core_if->adp.sense_timer, 3300 /* 3.3 secs */ );
+}
+
+/**
+ * Starts the ADP Sense
+ *
+ * @param core_if the pointer to core_if strucure.
+ */
+uint32_t dwc_otg_adp_sense_start(dwc_otg_core_if_t * core_if)
+{
+	adpctl_data_t adpctl;
+
+	DWC_DEBUGPL(DBG_PCD, "ADP Sense Start\n");
+
+	/* Set ADP reset bit*/
+	adpctl.d32 = dwc_otg_adp_read_reg_filter(core_if);
+	adpctl.b.adpres = 1;
+	dwc_otg_adp_write_reg(core_if, adpctl.d32);
+
+	while (adpctl.b.adpres) {
+		adpctl.d32 = dwc_otg_adp_read_reg(core_if);
+	}
+
+	/* Unmask ADP sense interrupt and mask all other from the core */
+	adpctl.d32 = dwc_otg_adp_read_reg_filter(core_if);
+	adpctl.b.adp_sns_int_msk = 1;
+	dwc_otg_adp_write_reg(core_if, adpctl.d32);
+	dwc_otg_disable_global_interrupts(core_if);
+
+	adpctl.b.adpres = 0;
+	adpctl.b.adpen = 1;
+	adpctl.b.enasns = 1;
+	dwc_otg_adp_write_reg(core_if, adpctl.d32);
+
+	dwc_otg_adp_sense_timer_start(core_if);
+
+	return 0;
+}
+
+/**
+ * Stops the ADP Probing
+ *
+ * @param core_if the pointer to core_if strucure.
+ */
+uint32_t dwc_otg_adp_probe_stop(dwc_otg_core_if_t * core_if)
+{
+
+	adpctl_data_t adpctl;
+	DWC_DEBUGPL(DBG_ANY, "Stop ADP probe\n");
+	core_if->adp.probe_enabled = 0;
+	//core_if->adp.probe_counter = 0;
+	adpctl.d32 = dwc_otg_adp_read_reg(core_if);
+
+	adpctl.b.adpen = 0;
+	adpctl.b.adp_prb_int = 1;
+	adpctl.b.adp_tmout_int = 1;
+	adpctl.b.adp_sns_int = 1;
+	dwc_otg_adp_write_reg(core_if, adpctl.d32);
+
+	return 0;
+}
+
+/**
+ * Stops the ADP Sensing
+ *
+ * @param core_if the pointer to core_if strucure.
+ */
+uint32_t dwc_otg_adp_sense_stop(dwc_otg_core_if_t * core_if)
+{
+	adpctl_data_t adpctl;
+
+	core_if->adp.sense_enabled = 0;
+
+	adpctl.d32 = dwc_otg_adp_read_reg_filter(core_if);
+	adpctl.b.enasns = 0;
+	adpctl.b.adp_sns_int = 1;
+	dwc_otg_adp_write_reg(core_if, adpctl.d32);
+
+	return 0;
+}
+
+/**
+ * Called to turn on the VBUS after initial ADP probe in host mode.
+ * If port power was already enabled in cil_hcd_start function then
+ * only schedule a timer.
+ *
+ * @param core_if the pointer to core_if structure.
+ */
+void dwc_otg_adp_turnon_vbus(dwc_otg_core_if_t * core_if)
+{
+	hprt0_data_t hprt0 = {.d32 = 0 };
+	hprt0.d32 = dwc_otg_read_hprt0(core_if);
+	DWC_PRINTF("Turn on VBUS for 1.1s, port power is %d\n", hprt0.b.prtpwr);
+
+	if (hprt0.b.prtpwr == 0) {
+		hprt0.b.prtpwr = 1;
+		//DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+	}
+
+	dwc_otg_adp_vbuson_timer_start(core_if);
+}
+
+/**
+ * Called right after driver is loaded
+ * to perform initial actions for ADP
+ *
+ * @param core_if the pointer to core_if structure.
+ * @param is_host - flag for current mode of operation either from GINTSTS or GPWRDN
+ */
+void dwc_otg_adp_start(dwc_otg_core_if_t * core_if, uint8_t is_host)
+{
+	gpwrdn_data_t gpwrdn;
+
+	DWC_DEBUGPL(DBG_ANY, "ADP Initial Start\n");
+	core_if->adp.adp_started = 1;
+
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, 0xFFFFFFFF);
+	dwc_otg_disable_global_interrupts(core_if);
+	if (is_host) {
+		DWC_PRINTF("HOST MODE\n");
+		//core_if->op_state = A_HOST; - vahrama, modified checking in hcd_start()
+		/* Enable Power Down Logic Interrupt*/
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pmuintsel = 1;
+		gpwrdn.b.pmuactv = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+		/* Initialize first ADP probe to obtain Ramp Time value */
+		core_if->adp.initial_probe = 1;
+		dwc_otg_adp_probe_start(core_if);
+	} else {
+		gotgctl_data_t gotgctl;
+		gotgctl.d32 = DWC_READ_REG32(&core_if->core_global_regs->gotgctl);
+		DWC_DEBUGPL(DBG_ANY, "DEVICE MODE\n");
+		//dwc_otg_core_init(core_if);
+		if (gotgctl.b.bsesvld == 0) {
+			/* Enable Power Down Logic Interrupt*/
+			gpwrdn.d32 = 0;
+			DWC_DEBUGPL(DBG_ANY, "VBUS is not valid - start ADP probe\n");
+			gpwrdn.b.pmuintsel = 1;
+			gpwrdn.b.pmuactv = 1;
+			DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+			/* Do not need to return to inital probe if we are coming back to
+			 * the device mode after HNP */
+			if (core_if->op_state != B_HOST)
+				core_if->adp.initial_probe = 1;
+			dwc_otg_adp_probe_start(core_if);
+		} else {
+			DWC_PRINTF("VBUS is valid - initialize core as a Device\n");
+			core_if->op_state = B_PERIPHERAL;
+			//dwc_otg_core_init(core_if);
+			dwc_otg_enable_global_interrupts(core_if);
+			cil_pcd_start(core_if);
+			dwc_otg_dump_global_registers(core_if);
+			dwc_otg_dump_dev_registers(core_if);
+		}
+	}
+}
+
+void dwc_otg_adp_init(dwc_otg_core_if_t * core_if)
+{
+	core_if->adp.adp_started = 0;
+	core_if->adp.initial_probe = 0;
+	core_if->adp.probe_timer_values[0] = -1;
+	core_if->adp.probe_timer_values[1] = -1;
+	core_if->adp.probe_enabled = 0;
+	core_if->adp.sense_enabled = 0;
+	core_if->adp.sense_timer_started = 0;
+	core_if->adp.vbuson_timer_started = 0;
+	core_if->adp.probe_counter = 0;
+	core_if->adp.gpwrdn = 0;
+	core_if->adp.attached = DWC_OTG_ADP_UNKOWN;
+}
+
+void dwc_otg_adp_remove(dwc_otg_core_if_t * core_if)
+{
+	gpwrdn_data_t gpwrdn = { .d32 = 0 };
+	gpwrdn.b.pmuintsel = 1;
+	gpwrdn.b.pmuactv = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+	if (core_if->adp.probe_enabled)
+		dwc_otg_adp_probe_stop(core_if);
+	if (core_if->adp.sense_enabled)
+		dwc_otg_adp_sense_stop(core_if);
+	if (core_if->adp.sense_timer_started)
+		DWC_TIMER_CANCEL(core_if->adp.sense_timer);
+	if (core_if->adp.vbuson_timer_started)
+		DWC_TIMER_CANCEL(core_if->adp.vbuson_timer);
+	DWC_TIMER_FREE(core_if->adp.sense_timer);
+	DWC_TIMER_FREE(core_if->adp.vbuson_timer);
+}
+
+/////////////////////////////////////////////////////////////////////
+////////////// ADP Interrupt Handlers ///////////////////////////////
+/////////////////////////////////////////////////////////////////////
+/**
+ * This function sets Ramp Timer values
+ */
+static uint32_t set_timer_value(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	if (core_if->adp.probe_timer_values[0] == -1) {
+		core_if->adp.probe_timer_values[0] = val;
+		core_if->adp.probe_timer_values[1] = -1;
+		return 1;
+	} else {
+		core_if->adp.probe_timer_values[1] =
+		    core_if->adp.probe_timer_values[0];
+		core_if->adp.probe_timer_values[0] = val;
+		return 0;
+	}
+}
+
+/**
+ * This function compares Ramp Timer values
+ */
+static uint32_t compare_timer_values(dwc_otg_core_if_t * core_if)
+{
+	uint32_t diff;
+	uint32_t thres;
+	gpwrdn_data_t gpwrdn;
+
+	/* RTIM difference thresold differs for host and device modes */
+	gpwrdn.d32 = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+	if (!gpwrdn.b.idsts)
+		thres = HOST_RTIM_THRESHOLD;
+	else
+		thres = DEVICE_RTIM_THRESHOLD;
+
+	DWC_DEBUGPL(DBG_ANY, "timer value 0 %d timer value 1 %d\n",
+		core_if->adp.probe_timer_values[0], core_if->adp.probe_timer_values[1]);
+	if (core_if->adp.probe_timer_values[0] >= core_if->adp.probe_timer_values[1])
+		diff = core_if->adp.probe_timer_values[0] - core_if->adp.probe_timer_values[1];
+	else
+		diff = core_if->adp.probe_timer_values[1] - core_if->adp.probe_timer_values[0];
+	if (diff < thres)
+		return 0;
+	else
+		return 1;
+}
+
+/**
+ * This function handles ADP Probe Interrupts
+ */
+static int32_t dwc_otg_adp_handle_prb_intr(dwc_otg_core_if_t * core_if,
+						 uint32_t val)
+{
+	adpctl_data_t adpctl = {.d32 = 0 };
+	gpwrdn_data_t gpwrdn, temp;
+	adpctl.d32 = val;
+
+	temp.d32 = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+
+	core_if->adp.gpwrdn = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+	if (adpctl.b.rtim == 0 /*&& !temp.b.idsts*/){
+		DWC_PRINTF("RTIM value is 0\n");
+		goto exit;
+	}
+	core_if->adp.probe_counter++;
+
+	if (set_timer_value(core_if, adpctl.b.rtim) &&
+	    core_if->adp.initial_probe) {
+		core_if->adp.initial_probe = 0;
+		dwc_otg_adp_probe_stop(core_if);
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pmuactv = 1;
+		gpwrdn.b.pmuintsel = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, 0xFFFFFFFF);
+
+		/* check which value is for device mode and which for Host mode */
+		if (!temp.b.idsts) {	/* considered host mode value is 0 */
+			/* Choose right op_state depending on previous one */
+			if (core_if->op_state == B_PERIPHERAL)
+				core_if->op_state = B_HOST;
+			else
+				core_if->op_state = A_HOST;
+			dwc_otg_enable_global_interrupts(core_if);
+			/*
+			 * Turn on VBUS after initial ADP probe.
+			 */
+			DWC_SPINUNLOCK(core_if->lock);
+			cil_hcd_start(core_if);
+			dwc_otg_adp_turnon_vbus(core_if);
+			DWC_SPINLOCK(core_if->lock);
+		} else {
+			/*
+			 * Initiate SRP after initial ADP probe.
+			 */
+			dwc_otg_enable_global_interrupts(core_if);
+			dwc_otg_initiate_srp(core_if);
+		}
+	} else if (core_if->adp.probe_counter > 2){
+		gpwrdn.d32 = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+		if (compare_timer_values(core_if)) {
+			DWC_PRINTF("Difference in timer values !!! \n");
+//          core_if->adp.attached = DWC_OTG_ADP_ATTACHED;
+			dwc_otg_adp_probe_stop(core_if);
+
+			/* Power on the core */
+			if (core_if->power_down == 2) {
+				gpwrdn.b.pwrdnswtch = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+			}
+
+			/* check which value is for device mode and which for Host mode */
+			if (!temp.b.idsts) {	/* considered host mode value is 0 */
+				/* Disable Interrupt from Power Down Logic */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.pmuintsel = 1;
+				gpwrdn.b.pmuactv = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, gpwrdn.d32, 0);
+
+				/*
+				 * Initialize the Core for Host mode.
+				 * Choose right op_state depending on previous one
+				 */
+				if (core_if->op_state == B_PERIPHERAL)
+					core_if->op_state = B_HOST;
+				else
+					core_if->op_state = A_HOST;
+
+				dwc_otg_core_init(core_if);
+				dwc_otg_enable_global_interrupts(core_if);
+				cil_hcd_start(core_if);
+				dwc_otg_adp_turnon_vbus(core_if);
+			} else {
+				gotgctl_data_t gotgctl;
+				/* Mask SRP detected interrupt from Power Down Logic */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.srp_det_msk = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, gpwrdn.d32, 0);
+
+				/* Disable Power Down Logic */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.pmuintsel = 1;
+				gpwrdn.b.pmuactv = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, gpwrdn.d32, 0);
+
+				/*
+				 * Initialize the Core for Device mode.
+				 */
+				core_if->op_state = B_PERIPHERAL;
+				//dwc_otg_core_init(core_if);
+				cil_pcd_start(core_if);
+				dwc_otg_enable_global_interrupts(core_if);
+
+				gotgctl.d32 = DWC_READ_REG32(&core_if->core_global_regs->gotgctl);
+				if (!gotgctl.b.bsesvld)
+					dwc_otg_initiate_srp(core_if);
+			}
+		}
+		if (core_if->power_down == 2) {
+			if (gpwrdn.b.bsessvld) {
+				/* Mask SRP detected interrupt from Power Down Logic */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.srp_det_msk = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+				/* Disable Power Down Logic */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.pmuactv = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+				/*
+				 * Initialize the Core for Device mode.
+				 */
+				core_if->op_state = B_PERIPHERAL;
+				dwc_otg_core_init(core_if);
+				dwc_otg_enable_global_interrupts(core_if);
+				cil_pcd_start(core_if);
+			}
+		}
+	}
+exit:
+	/* Clear interrupt */
+	adpctl.d32 = dwc_otg_adp_read_reg(core_if);
+	adpctl.b.adp_prb_int = 1;
+	dwc_otg_adp_write_reg(core_if, adpctl.d32);
+
+	return 0;
+}
+
+/**
+ * This function hadles ADP Sense Interrupt
+ */
+static int32_t dwc_otg_adp_handle_sns_intr(dwc_otg_core_if_t * core_if)
+{
+	adpctl_data_t adpctl;
+	/* Stop ADP Sense timer */
+	DWC_TIMER_CANCEL(core_if->adp.sense_timer);
+
+	/* Restart ADP Sense timer */
+	dwc_otg_adp_sense_timer_start(core_if);
+
+	/* Clear interrupt */
+	adpctl.d32 = dwc_otg_adp_read_reg(core_if);
+	adpctl.b.adp_sns_int = 1;
+	dwc_otg_adp_write_reg(core_if, adpctl.d32);
+
+	return 0;
+}
+
+/**
+ * This function handles ADP Probe Interrupts
+ */
+static int32_t dwc_otg_adp_handle_prb_tmout_intr(dwc_otg_core_if_t * core_if,
+						 uint32_t val)
+{
+	adpctl_data_t adpctl = {.d32 = 0 };
+	adpctl.d32 = val;
+	set_timer_value(core_if, adpctl.b.rtim);
+
+	/* Clear interrupt */
+	adpctl.d32 = dwc_otg_adp_read_reg(core_if);
+	adpctl.b.adp_tmout_int = 1;
+	dwc_otg_adp_write_reg(core_if, adpctl.d32);
+
+	return 0;
+}
+
+/**
+ * ADP Interrupt handler.
+ *
+ */
+int32_t dwc_otg_adp_handle_intr(dwc_otg_core_if_t * core_if)
+{
+	int retval = 0;
+	adpctl_data_t adpctl = {.d32 = 0};
+
+	adpctl.d32 = dwc_otg_adp_read_reg(core_if);
+	DWC_DEBUGPL(DBG_ANY, "ADPCTL = %08x RAMP TIME = %d\n", adpctl.d32, adpctl.b.rtim);
+
+	if (adpctl.b.adp_sns_int & adpctl.b.adp_sns_int_msk) {
+		DWC_DEBUGPL(DBG_ANY, "ADP Sense interrupt\n");
+		retval |= dwc_otg_adp_handle_sns_intr(core_if);
+	}
+	if (adpctl.b.adp_tmout_int & adpctl.b.adp_tmout_int_msk) {
+		DWC_DEBUGPL(DBG_ANY, "ADP timeout interrupt\n");
+		retval |= dwc_otg_adp_handle_prb_tmout_intr(core_if, adpctl.d32);
+	}
+	if (adpctl.b.adp_prb_int & adpctl.b.adp_prb_int_msk) {
+		DWC_DEBUGPL(DBG_ANY, "ADP Probe interrupt\n");
+		adpctl.b.adp_prb_int = 1;
+		retval |= dwc_otg_adp_handle_prb_intr(core_if, adpctl.d32);
+	}
+
+//	dwc_otg_adp_modify_reg(core_if, adpctl.d32, 0);
+	//dwc_otg_adp_write_reg(core_if, adpctl.d32);
+	DWC_DEBUGPL(DBG_ANY, "RETURN FROM ADP ISR\n");
+
+	return retval;
+}
+
+/**
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+int32_t dwc_otg_adp_handle_srp_intr(dwc_otg_core_if_t * core_if)
+{
+
+#ifndef DWC_HOST_ONLY
+	hprt0_data_t hprt0;
+	gpwrdn_data_t gpwrdn;
+	DWC_DEBUGPL(DBG_ANY, "++ Power Down Logic Session Request Interrupt++\n");
+
+	gpwrdn.d32 = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+	/* check which value is for device mode and which for Host mode */
+	if (!gpwrdn.b.idsts) {	/* considered host mode value is 0 */
+		DWC_PRINTF("SRP: Host mode\n");
+
+		if (core_if->adp_enable) {
+			dwc_otg_adp_probe_stop(core_if);
+
+			/* Power on the core */
+			if (core_if->power_down == 2) {
+				gpwrdn.b.pwrdnswtch = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+			}
+
+			core_if->op_state = A_HOST;
+			dwc_otg_core_init(core_if);
+			dwc_otg_enable_global_interrupts(core_if);
+			cil_hcd_start(core_if);
+		}
+
+		/* Turn on the port power bit. */
+		hprt0.d32 = dwc_otg_read_hprt0(core_if);
+		hprt0.b.prtpwr = 1;
+		DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+
+		/* Start the Connection timer. So a message can be displayed
+		 * if connect does not occur within 10 seconds. */
+		cil_hcd_session_start(core_if);
+	} else {
+		DWC_DEBUGPL(DBG_PCD, "SRP: Device mode %s\n", __FUNCTION__);
+		if (core_if->adp_enable) {
+			dwc_otg_adp_probe_stop(core_if);
+
+			/* Power on the core */
+			if (core_if->power_down == 2) {
+				gpwrdn.b.pwrdnswtch = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+			}
+
+			gpwrdn.d32 = 0;
+			gpwrdn.b.pmuactv = 0;
+			DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0,
+					 gpwrdn.d32);
+
+			core_if->op_state = B_PERIPHERAL;
+			dwc_otg_core_init(core_if);
+			dwc_otg_enable_global_interrupts(core_if);
+			cil_pcd_start(core_if);
+		}
+	}
+#endif
+	return 1;
+}
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_adp.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_adp.h
new file mode 100644
index 0000000..c21b2f0
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_adp.h
@@ -0,0 +1,82 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_adp.h $
+ * $Revision: #8 $
+ * $Date: 2013/04/09 $
+ * $Change: 2201932 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#ifndef __DWC_OTG_ADP_H__
+#define __DWC_OTG_ADP_H__
+
+/**
+ * @file
+ *
+ * This file contains the Attach Detect Protocol interfaces and defines
+ * (functions) and structures for Linux.
+ *
+ */
+
+#define DWC_OTG_ADP_UNATTACHED	0
+#define DWC_OTG_ADP_ATTACHED	1
+#define DWC_OTG_ADP_UNKOWN	2
+#define HOST_RTIM_THRESHOLD 5
+#define DEVICE_RTIM_THRESHOLD 3
+
+typedef struct dwc_otg_adp {
+	uint32_t adp_started;
+	uint32_t initial_probe;
+	int32_t probe_timer_values[2];
+	uint32_t probe_enabled;
+	uint32_t sense_enabled;
+	dwc_timer_t *sense_timer;
+	uint32_t sense_timer_started;
+	dwc_timer_t *vbuson_timer;
+	uint32_t vbuson_timer_started;
+	uint32_t attached;
+	uint32_t probe_counter;
+	uint32_t gpwrdn;
+} dwc_otg_adp_t;
+
+/**
+ * Attach Detect Protocol functions
+ */
+
+extern void dwc_otg_adp_write_reg(dwc_otg_core_if_t * core_if, uint32_t value);
+extern uint32_t dwc_otg_adp_read_reg(dwc_otg_core_if_t * core_if);
+extern uint32_t dwc_otg_adp_probe_start(dwc_otg_core_if_t * core_if);
+extern uint32_t dwc_otg_adp_sense_start(dwc_otg_core_if_t * core_if);
+extern uint32_t dwc_otg_adp_probe_stop(dwc_otg_core_if_t * core_if);
+extern uint32_t dwc_otg_adp_sense_stop(dwc_otg_core_if_t * core_if);
+extern void dwc_otg_adp_start(dwc_otg_core_if_t * core_if, uint8_t is_host);
+extern void dwc_otg_adp_init(dwc_otg_core_if_t * core_if);
+extern void dwc_otg_adp_remove(dwc_otg_core_if_t * core_if);
+extern int32_t dwc_otg_adp_handle_intr(dwc_otg_core_if_t * core_if);
+extern int32_t dwc_otg_adp_handle_srp_intr(dwc_otg_core_if_t * core_if);
+
+#endif //__DWC_OTG_ADP_H__
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_attr.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_attr.c
new file mode 100644
index 0000000..73fc330
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_attr.c
@@ -0,0 +1,1311 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_attr.c $
+ * $Revision: #46 $
+ * $Date: 2012/12/12 $
+ * $Change: 2124654 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+/** @file
+ *
+ * The diagnostic interface will provide access to the controller for
+ * bringing up the hardware and testing.  The Linux driver attributes
+ * feature will be used to provide the Linux Diagnostic
+ * Interface. These attributes are accessed through sysfs.
+ */
+
+/** @page "Linux Module Attributes"
+ *
+ * The Linux module attributes feature is used to provide the Linux
+ * Diagnostic Interface.  These attributes are accessed through sysfs.
+ * The diagnostic interface will provide access to the controller for
+ * bringing up the hardware and testing.
+
+ The following table shows the attributes.
+ <table>
+ <tr>
+ <td><b> Name</b></td>
+ <td><b> Description</b></td>
+ <td><b> Access</b></td>
+ </tr>
+
+ <tr>
+ <td> mode </td>
+ <td> Returns the current mode: 0 for device mode, 1 for host mode</td>
+ <td> Read</td>
+ </tr>
+
+ <tr>
+ <td> hnpcapable </td>
+ <td> Gets or sets the "HNP-capable" bit in the Core USB Configuraton Register.
+ Read returns the current value.</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> srpcapable </td>
+ <td> Gets or sets the "SRP-capable" bit in the Core USB Configuraton Register.
+ Read returns the current value.</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> hsic_connect </td>
+ <td> Gets or sets the "HSIC-Connect" bit in the GLPMCFG Register.
+ Read returns the current value.</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> inv_sel_hsic </td>
+ <td> Gets or sets the "Invert Select HSIC" bit in the GLPMFG Register.
+ Read returns the current value.</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> hnp </td>
+ <td> Initiates the Host Negotiation Protocol.  Read returns the status.</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> srp </td>
+ <td> Initiates the Session Request Protocol.  Read returns the status.</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> buspower </td>
+ <td> Gets or sets the Power State of the bus (0 - Off or 1 - On)</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> bussuspend </td>
+ <td> Suspends the USB bus.</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> busconnected </td>
+ <td> Gets the connection status of the bus</td>
+ <td> Read</td>
+ </tr>
+
+ <tr>
+ <td> gotgctl </td>
+ <td> Gets or sets the Core Control Status Register.</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> gusbcfg </td>
+ <td> Gets or sets the Core USB Configuration Register</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> grxfsiz </td>
+ <td> Gets or sets the Receive FIFO Size Register</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> gnptxfsiz </td>
+ <td> Gets or sets the non-periodic Transmit Size Register</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> gpvndctl </td>
+ <td> Gets or sets the PHY Vendor Control Register</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> ggpio </td>
+ <td> Gets the value in the lower 16-bits of the General Purpose IO Register
+ or sets the upper 16 bits.</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> guid </td>
+ <td> Gets or sets the value of the User ID Register</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> gsnpsid </td>
+ <td> Gets the value of the Synopsys ID Regester</td>
+ <td> Read</td>
+ </tr>
+
+ <tr>
+ <td> devspeed </td>
+ <td> Gets or sets the device speed setting in the DCFG register</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> enumspeed </td>
+ <td> Gets the device enumeration Speed.</td>
+ <td> Read</td>
+ </tr>
+
+ <tr>
+ <td> hptxfsiz </td>
+ <td> Gets the value of the Host Periodic Transmit FIFO</td>
+ <td> Read</td>
+ </tr>
+
+ <tr>
+ <td> hprt0 </td>
+ <td> Gets or sets the value in the Host Port Control and Status Register</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> regoffset </td>
+ <td> Sets the register offset for the next Register Access</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> regvalue </td>
+ <td> Gets or sets the value of the register at the offset in the regoffset attribute.</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> remote_wakeup </td>
+ <td> On read, shows the status of Remote Wakeup. On write, initiates a remote
+ wakeup of the host. When bit 0 is 1 and Remote Wakeup is enabled, the Remote
+ Wakeup signalling bit in the Device Control Register is set for 1
+ milli-second.</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> rem_wakeup_pwrdn </td>
+ <td> On read, shows the status core - hibernated or not. On write, initiates
+ a remote wakeup of the device from Hibernation. </td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> mode_ch_tim_en </td>
+ <td> This bit is used to enable or disable the host core to wait for 200 PHY
+ clock cycles at the end of Resume to change the opmode signal to the PHY to 00
+ after Suspend or LPM. </td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> fr_interval </td>
+ <td> On read, shows the value of HFIR Frame Interval. On write, dynamically
+ reload HFIR register during runtime. The application can write a value to this
+ register only after the Port Enable bit of the Host Port Control and Status
+ register (HPRT.PrtEnaPort) has been set </td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> disconnect_us </td>
+ <td> On read, shows the status of disconnect_device_us. On write, sets disconnect_us
+ which causes soft disconnect for 100us. Applicable only for device mode of operation.</td>
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> regdump </td>
+ <td> Dumps the contents of core registers.</td>
+ <td> Read</td>
+ </tr>
+
+ <tr>
+ <td> spramdump </td>
+ <td> Dumps the contents of core registers.</td>
+ <td> Read</td>
+ </tr>
+
+ <tr>
+ <td> hcddump </td>
+ <td> Dumps the current HCD state.</td>
+ <td> Read</td>
+ </tr>
+
+ <tr>
+ <td> hcd_frrem </td>
+ <td> Shows the average value of the Frame Remaining
+ field in the Host Frame Number/Frame Remaining register when an SOF interrupt
+ occurs. This can be used to determine the average interrupt latency. Also
+ shows the average Frame Remaining value for start_transfer and the "a" and
+ "b" sample points. The "a" and "b" sample points may be used during debugging
+ bto determine how long it takes to execute a section of the HCD code.</td>
+ <td> Read</td>
+ </tr>
+
+ <tr>
+ <td> rd_reg_test </td>
+ <td> Displays the time required to read the GNPTXFSIZ register many times
+ (the output shows the number of times the register is read).
+ <td> Read</td>
+ </tr>
+
+ <tr>
+ <td> wr_reg_test </td>
+ <td> Displays the time required to write the GNPTXFSIZ register many times
+ (the output shows the number of times the register is written).
+ <td> Read</td>
+ </tr>
+
+ <tr>
+ <td> lpm_response </td>
+ <td> Gets or sets lpm_response mode. Applicable only in device mode.
+ <td> Write</td>
+ </tr>
+
+ <tr>
+ <td> sleep_status </td>
+ <td> Shows sleep status of device.
+ <td> Read</td>
+ </tr>
+
+ <tr>
+ <td> hird_thres </td>
+ <td> Gets or sets the "HIRD_Thres[3:0]" bits in the Core LPM Configuration Register.
+ <td> Read/Write</td>
+ </tr>
+
+ <tr>
+ <td> besl_reject </td>
+ <td> Gets or sets the "besl_reject" bit in the Device Control Register.
+ <td> Read/Write</td>
+ </tr>
+
+ </table>
+
+ Example usage:
+ To get the current mode:
+ cat /sys/devices/lm0/mode
+
+ To power down the USB:
+ echo 0 > /sys/devices/lm0/buspower
+ */
+
+#include "dwc_otg_os_dep.h"
+#include "dwc_os.h"
+#include "dwc_otg_driver.h"
+#include "dwc_otg_attr.h"
+#include "dwc_otg_core_if.h"
+#include "dwc_otg_pcd_if.h"
+#include "dwc_otg_hcd_if.h"
+
+/*
+ * MACROs for defining sysfs attribute
+ */
+
+
+#define DWC_OTG_DEVICE_ATTR_BITFIELD_SHOW(_otg_attr_name_,_string_) \
+static ssize_t _otg_attr_name_##_show (struct device *_dev, struct device_attribute *attr, char *buf) \
+{ \
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev); \
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);		\
+	uint32_t val; \
+	val = dwc_otg_get_##_otg_attr_name_ (otg_dev->core_if); \
+	return sprintf (buf, "%s = 0x%x\n", _string_, val); \
+}
+#define DWC_OTG_DEVICE_ATTR_BITFIELD_STORE(_otg_attr_name_,_string_) \
+static ssize_t _otg_attr_name_##_store (struct device *_dev, struct device_attribute *attr, \
+					const char *buf, size_t count) \
+{ \
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev); \
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev); \
+	uint32_t set = simple_strtoul(buf, NULL, 16); \
+	dwc_otg_set_##_otg_attr_name_(otg_dev->core_if, set);\
+	return count; \
+}
+
+
+/*
+ * MACROs for defining sysfs attribute for 32-bit registers
+ */
+#define DWC_OTG_DEVICE_ATTR_REG_SHOW(_otg_attr_name_,_string_) \
+static ssize_t _otg_attr_name_##_show (struct device *_dev, struct device_attribute *attr, char *buf) \
+{ \
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev); \
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev); \
+	uint32_t val; \
+	val = dwc_otg_get_##_otg_attr_name_ (otg_dev->core_if); \
+	return sprintf (buf, "%s = 0x%08x\n", _string_, val); \
+}
+#define DWC_OTG_DEVICE_ATTR_REG_STORE(_otg_attr_name_,_string_) \
+static ssize_t _otg_attr_name_##_store (struct device *_dev, struct device_attribute *attr, \
+					const char *buf, size_t count) \
+{ \
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev); \
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev); \
+	uint32_t val = simple_strtoul(buf, NULL, 16); \
+	dwc_otg_set_##_otg_attr_name_ (otg_dev->core_if, val); \
+	return count; \
+}
+
+#define DWC_OTG_DEVICE_ATTR_BITFIELD_RW(_otg_attr_name_,_string_) \
+DWC_OTG_DEVICE_ATTR_BITFIELD_SHOW(_otg_attr_name_,_string_) \
+DWC_OTG_DEVICE_ATTR_BITFIELD_STORE(_otg_attr_name_,_string_) \
+DEVICE_ATTR(_otg_attr_name_,0644,_otg_attr_name_##_show,_otg_attr_name_##_store);
+
+#define DWC_OTG_DEVICE_ATTR_BITFIELD_RO(_otg_attr_name_,_string_) \
+DWC_OTG_DEVICE_ATTR_BITFIELD_SHOW(_otg_attr_name_,_string_) \
+DEVICE_ATTR(_otg_attr_name_,0444,_otg_attr_name_##_show,NULL);
+
+#define DWC_OTG_DEVICE_ATTR_REG32_RW(_otg_attr_name_,_addr_,_string_) \
+DWC_OTG_DEVICE_ATTR_REG_SHOW(_otg_attr_name_,_string_) \
+DWC_OTG_DEVICE_ATTR_REG_STORE(_otg_attr_name_,_string_) \
+DEVICE_ATTR(_otg_attr_name_,0644,_otg_attr_name_##_show,_otg_attr_name_##_store);
+
+#define DWC_OTG_DEVICE_ATTR_REG32_RO(_otg_attr_name_,_addr_,_string_) \
+DWC_OTG_DEVICE_ATTR_REG_SHOW(_otg_attr_name_,_string_) \
+DEVICE_ATTR(_otg_attr_name_,0444,_otg_attr_name_##_show,NULL);
+
+/** @name Functions for Show/Store of Attributes */
+/**@{*/
+
+/**
+ * Show the register offset of the Register Access.
+ */
+static ssize_t regoffset_show(struct device *_dev,
+			      struct device_attribute *attr, char *buf)
+{
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	return snprintf(buf, sizeof("0xFFFFFFFF\n") + 1, "0x%08x\n",
+			otg_dev->os_dep.reg_offset);
+}
+
+/**
+ * Set the register offset for the next Register Access		Read/Write
+ */
+static ssize_t regoffset_store(struct device *_dev,
+			       struct device_attribute *attr,
+			       const char *buf, size_t count)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	uint32_t offset = simple_strtoul(buf, NULL, 16);
+	if (offset < SZ_256K) {
+		otg_dev->os_dep.reg_offset = offset;
+	} else {
+		dev_err(_dev, "invalid offset\n");
+	}
+
+	return count;
+}
+
+DEVICE_ATTR(regoffset, S_IRUGO | S_IWUSR, regoffset_show, regoffset_store);
+
+/**
+ * Show the value of the register at the offset in the reg_offset
+ * attribute.
+ */
+static ssize_t regvalue_show(struct device *_dev,
+			     struct device_attribute *attr, char *buf)
+{
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	uint32_t val;
+	volatile uint32_t *addr;
+
+	if (otg_dev->os_dep.reg_offset != 0xFFFFFFFF && 0 != otg_dev->os_dep.base) {
+		/* Calculate the address */
+		addr = (uint32_t *) (otg_dev->os_dep.reg_offset +
+				     (uint8_t *) otg_dev->os_dep.base);
+		val = DWC_READ_REG32(addr);
+		return snprintf(buf,
+				sizeof("Reg@0xFFFFFFFF = 0xFFFFFFFF\n") + 1,
+				"Reg@0x%06x = 0x%08x\n", otg_dev->os_dep.reg_offset,
+				val);
+	} else {
+		dev_err(_dev, "Invalid offset (0x%0x)\n", otg_dev->os_dep.reg_offset);
+		return sprintf(buf, "invalid offset\n");
+	}
+}
+
+/**
+ * Store the value in the register at the offset in the reg_offset
+ * attribute.
+ *
+ */
+static ssize_t regvalue_store(struct device *_dev,
+			      struct device_attribute *attr,
+			      const char *buf, size_t count)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	volatile uint32_t *addr;
+	uint32_t val = simple_strtoul(buf, NULL, 16);
+	//dev_dbg(_dev, "Offset=0x%08x Val=0x%08x\n", otg_dev->reg_offset, val);
+	if (otg_dev->os_dep.reg_offset != 0xFFFFFFFF && 0 != otg_dev->os_dep.base) {
+		/* Calculate the address */
+		addr = (uint32_t *) (otg_dev->os_dep.reg_offset +
+				     (uint8_t *) otg_dev->os_dep.base);
+		DWC_WRITE_REG32(addr, val);
+	} else {
+		dev_err(_dev, "Invalid Register Offset (0x%08x)\n",
+			otg_dev->os_dep.reg_offset);
+	}
+	return count;
+}
+
+DEVICE_ATTR(regvalue, S_IRUGO | S_IWUSR, regvalue_show, regvalue_store);
+
+/*
+ * Attributes
+ */
+DWC_OTG_DEVICE_ATTR_BITFIELD_RO(mode, "Mode");
+DWC_OTG_DEVICE_ATTR_BITFIELD_RW(hnpcapable, "HNPCapable");
+DWC_OTG_DEVICE_ATTR_BITFIELD_RW(srpcapable, "SRPCapable");
+DWC_OTG_DEVICE_ATTR_BITFIELD_RW(hsic_connect, "HSIC Connect");
+DWC_OTG_DEVICE_ATTR_BITFIELD_RW(inv_sel_hsic, "Invert Select HSIC");
+
+//DWC_OTG_DEVICE_ATTR_BITFIELD_RW(buspower,&(otg_dev->core_if->core_global_regs->gotgctl),(1<<8),8,"Mode");
+//DWC_OTG_DEVICE_ATTR_BITFIELD_RW(bussuspend,&(otg_dev->core_if->core_global_regs->gotgctl),(1<<8),8,"Mode");
+DWC_OTG_DEVICE_ATTR_BITFIELD_RO(busconnected, "Bus Connected");
+
+DWC_OTG_DEVICE_ATTR_REG32_RW(gotgctl, 0, "GOTGCTL");
+DWC_OTG_DEVICE_ATTR_REG32_RW(gusbcfg,
+			     &(otg_dev->core_if->core_global_regs->gusbcfg),
+			     "GUSBCFG");
+DWC_OTG_DEVICE_ATTR_REG32_RW(grxfsiz,
+			     &(otg_dev->core_if->core_global_regs->grxfsiz),
+			     "GRXFSIZ");
+DWC_OTG_DEVICE_ATTR_REG32_RW(gnptxfsiz,
+			     &(otg_dev->core_if->core_global_regs->gnptxfsiz),
+			     "GNPTXFSIZ");
+DWC_OTG_DEVICE_ATTR_REG32_RW(gpvndctl,
+			     &(otg_dev->core_if->core_global_regs->gpvndctl),
+			     "GPVNDCTL");
+DWC_OTG_DEVICE_ATTR_REG32_RW(ggpio,
+			     &(otg_dev->core_if->core_global_regs->ggpio),
+			     "GGPIO");
+DWC_OTG_DEVICE_ATTR_REG32_RW(guid, &(otg_dev->core_if->core_global_regs->guid),
+			     "GUID");
+DWC_OTG_DEVICE_ATTR_REG32_RO(gsnpsid,
+			     &(otg_dev->core_if->core_global_regs->gsnpsid),
+			     "GSNPSID");
+DWC_OTG_DEVICE_ATTR_BITFIELD_RW(devspeed, "Device Speed");
+DWC_OTG_DEVICE_ATTR_BITFIELD_RO(enumspeed, "Device Enumeration Speed");
+
+DWC_OTG_DEVICE_ATTR_REG32_RO(hptxfsiz,
+			     &(otg_dev->core_if->core_global_regs->hptxfsiz),
+			     "HPTXFSIZ");
+DWC_OTG_DEVICE_ATTR_REG32_RW(hprt0, otg_dev->core_if->host_if->hprt0, "HPRT0");
+
+/**
+ * @todo Add code to initiate the HNP.
+ */
+/**
+ * Show the HNP status bit
+ */
+static ssize_t hnp_show(struct device *_dev,
+			struct device_attribute *attr, char *buf)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+	return sprintf(buf, "HstNegScs = 0x%x\n",
+		       dwc_otg_get_hnpstatus(otg_dev->core_if));
+}
+
+/**
+ * Set the HNP Request bit
+ */
+static ssize_t hnp_store(struct device *_dev,
+			 struct device_attribute *attr,
+			 const char *buf, size_t count)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+	uint32_t in = simple_strtoul(buf, NULL, 16);
+	dwc_otg_set_hnpreq(otg_dev->core_if, in);
+	return count;
+}
+
+DEVICE_ATTR(hnp, 0644, hnp_show, hnp_store);
+
+/**
+ * @todo Add code to initiate the SRP.
+ */
+/**
+ * Show the SRP status bit
+ */
+static ssize_t srp_show(struct device *_dev,
+			struct device_attribute *attr, char *buf)
+{
+#ifndef DWC_HOST_ONLY
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+	return sprintf(buf, "SesReqScs = 0x%x\n",
+		       dwc_otg_get_srpstatus(otg_dev->core_if));
+#else
+	return sprintf(buf, "Host Only Mode!\n");
+#endif
+}
+
+/**
+ * Set the SRP Request bit
+ */
+static ssize_t srp_store(struct device *_dev,
+			 struct device_attribute *attr,
+			 const char *buf, size_t count)
+{
+#ifndef DWC_HOST_ONLY
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+	dwc_otg_pcd_initiate_srp(otg_dev->pcd);
+#endif
+	return count;
+}
+
+DEVICE_ATTR(srp, 0644, srp_show, srp_store);
+
+/**
+ * @todo Need to do more for power on/off?
+ */
+/**
+ * Show the Bus Power status
+ */
+static ssize_t buspower_show(struct device *_dev,
+			     struct device_attribute *attr, char *buf)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+	return sprintf(buf, "Bus Power = 0x%x\n",
+		       dwc_otg_get_prtpower(otg_dev->core_if));
+}
+
+/**
+ * Set the Bus Power status
+ */
+static ssize_t buspower_store(struct device *_dev,
+			      struct device_attribute *attr,
+			      const char *buf, size_t count)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+	uint32_t on = simple_strtoul(buf, NULL, 16);
+	dwc_otg_set_prtpower(otg_dev->core_if, on);
+	return count;
+}
+
+DEVICE_ATTR(buspower, 0644, buspower_show, buspower_store);
+
+/**
+ * @todo Need to do more for suspend?
+ */
+/**
+ * Show the Bus Suspend status
+ */
+static ssize_t bussuspend_show(struct device *_dev,
+			       struct device_attribute *attr, char *buf)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+	return sprintf(buf, "Bus Suspend = 0x%x\n",
+		       dwc_otg_get_prtsuspend(otg_dev->core_if));
+}
+
+/**
+ * Set the Bus Suspend status
+ */
+static ssize_t bussuspend_store(struct device *_dev,
+				struct device_attribute *attr,
+				const char *buf, size_t count)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	uint32_t in = simple_strtoul(buf, NULL, 16);
+	dwc_otg_set_prtsuspend(otg_dev->core_if, in);
+	return count;
+}
+
+DEVICE_ATTR(bussuspend, 0644, bussuspend_show, bussuspend_store);
+
+/**
+ * Show the Mode Change Ready Timer status
+ */
+static ssize_t mode_ch_tim_en_show(struct device *_dev,
+				   struct device_attribute *attr, char *buf)
+{
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+	return sprintf(buf, "Mode Change Ready Timer Enable = 0x%x\n",
+		       dwc_otg_get_mode_ch_tim(otg_dev->core_if));
+}
+
+/**
+ * Set the Mode Change Ready Timer status
+ */
+static ssize_t mode_ch_tim_en_store(struct device *_dev,
+				    struct device_attribute *attr,
+				    const char *buf, size_t count)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+	uint32_t in = simple_strtoul(buf, NULL, 16);
+	dwc_otg_set_mode_ch_tim(otg_dev->core_if, in);
+	return count;
+}
+
+DEVICE_ATTR(mode_ch_tim_en, 0644, mode_ch_tim_en_show, mode_ch_tim_en_store);
+
+/**
+ * Show the value of HFIR Frame Interval bitfield
+ */
+static ssize_t fr_interval_show(struct device *_dev,
+				struct device_attribute *attr, char *buf)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+	return sprintf(buf, "Frame Interval = 0x%x\n",
+		       dwc_otg_get_fr_interval(otg_dev->core_if));
+}
+
+/**
+ * Set the HFIR Frame Interval value
+ */
+static ssize_t fr_interval_store(struct device *_dev,
+				 struct device_attribute *attr,
+				 const char *buf, size_t count)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	uint32_t in = simple_strtoul(buf, NULL, 10);
+	dwc_otg_set_fr_interval(otg_dev->core_if, in);
+	return count;
+}
+
+DEVICE_ATTR(fr_interval, 0644, fr_interval_show, fr_interval_store);
+
+/**
+ * Show the status of Remote Wakeup.
+ */
+static ssize_t remote_wakeup_show(struct device *_dev,
+				  struct device_attribute *attr, char *buf)
+{
+#ifndef DWC_HOST_ONLY
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev =platform_get_drvdata(lm_dev);
+
+
+	return sprintf(buf,
+		       "Remote Wakeup Sig = %d Enabled = %d LPM Remote Wakeup = %d\n",
+		       dwc_otg_get_remotewakesig(otg_dev->core_if),
+		       dwc_otg_pcd_get_rmwkup_enable(otg_dev->pcd),
+		       dwc_otg_get_lpm_remotewakeenabled(otg_dev->core_if));
+#else
+	return sprintf(buf, "Host Only Mode!\n");
+#endif /* DWC_HOST_ONLY */
+}
+
+/**
+ * Initiate a remote wakeup of the host.  The Device control register
+ * Remote Wakeup Signal bit is written if the PCD Remote wakeup enable
+ * flag is set.
+ *
+ */
+static ssize_t remote_wakeup_store(struct device *_dev,
+				   struct device_attribute *attr,
+				   const char *buf, size_t count)
+{
+#ifndef DWC_HOST_ONLY
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	uint32_t val = simple_strtoul(buf, NULL, 16);
+
+	if (val & 1) {
+		dwc_otg_pcd_remote_wakeup(otg_dev->pcd, 1);
+	} else {
+		dwc_otg_pcd_remote_wakeup(otg_dev->pcd, 0);
+	}
+#endif /* DWC_HOST_ONLY */
+	return count;
+}
+
+DEVICE_ATTR(remote_wakeup, S_IRUGO | S_IWUSR, remote_wakeup_show,
+	    remote_wakeup_store);
+
+/**
+ * Show the whether core is hibernated or not.
+ */
+static ssize_t rem_wakeup_pwrdn_show(struct device *_dev,
+				     struct device_attribute *attr, char *buf)
+{
+#ifndef DWC_HOST_ONLY
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+	if (dwc_otg_get_core_state(otg_dev->core_if)) {
+		DWC_PRINTF("Core is in hibernation\n");
+	} else {
+		DWC_PRINTF("Core is not in hibernation\n");
+	}
+#endif /* DWC_HOST_ONLY */
+	return 0;
+}
+
+extern int dwc_otg_device_hibernation_restore(dwc_otg_core_if_t * core_if,
+					      int rem_wakeup, int reset);
+
+/**
+ * Initiate a remote wakeup of the device to exit from hibernation.
+ */
+static ssize_t rem_wakeup_pwrdn_store(struct device *_dev,
+				      struct device_attribute *attr,
+				      const char *buf, size_t count)
+{
+#ifndef DWC_HOST_ONLY
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+	dwc_otg_device_hibernation_restore(otg_dev->core_if, 1, 0);
+#endif
+	return count;
+}
+
+DEVICE_ATTR(rem_wakeup_pwrdn, S_IRUGO | S_IWUSR, rem_wakeup_pwrdn_show,
+	    rem_wakeup_pwrdn_store);
+
+static ssize_t disconnect_us(struct device *_dev,
+			     struct device_attribute *attr,
+			     const char *buf, size_t count)
+{
+
+#ifndef DWC_HOST_ONLY
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+	uint32_t val = simple_strtoul(buf, NULL, 16);
+	DWC_PRINTF("The Passed value is %04x\n", val);
+
+	dwc_otg_pcd_disconnect_us(otg_dev->pcd, 50);
+
+#endif /* DWC_HOST_ONLY */
+	return count;
+}
+
+DEVICE_ATTR(disconnect_us, S_IWUSR, 0, disconnect_us);
+
+/**
+ * Dump global registers and either host or device registers (depending on the
+ * current mode of the core).
+ */
+static ssize_t regdump_show(struct device *_dev,
+			    struct device_attribute *attr, char *buf)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	dwc_otg_dump_global_registers(otg_dev->core_if);
+	if (dwc_otg_is_host_mode(otg_dev->core_if)) {
+		dwc_otg_dump_host_registers(otg_dev->core_if);
+	} else {
+		dwc_otg_dump_dev_registers(otg_dev->core_if);
+
+	}
+	return sprintf(buf, "Register Dump\n");
+}
+
+DEVICE_ATTR(regdump, S_IRUGO | S_IWUSR, regdump_show, 0);
+
+/**
+ * Dump global registers and either host or device registers (depending on the
+ * current mode of the core).
+ */
+static ssize_t spramdump_show(struct device *_dev,
+			      struct device_attribute *attr, char *buf)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	dwc_otg_dump_spram(otg_dev->core_if);
+
+	return sprintf(buf, "SPRAM Dump\n");
+}
+
+DEVICE_ATTR(spramdump, S_IRUGO | S_IWUSR, spramdump_show, 0);
+
+/**
+ * Dump the current hcd state.
+ */
+static ssize_t hcddump_show(struct device *_dev,
+			    struct device_attribute *attr, char *buf)
+{
+#ifndef DWC_DEVICE_ONLY
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev =platform_get_drvdata(lm_dev);
+
+
+	dwc_otg_hcd_dump_state(otg_dev->hcd);
+#endif /* DWC_DEVICE_ONLY */
+	return sprintf(buf, "HCD Dump\n");
+}
+
+DEVICE_ATTR(hcddump, S_IRUGO | S_IWUSR, hcddump_show, 0);
+
+/**
+ * Dump the average frame remaining at SOF. This can be used to
+ * determine average interrupt latency. Frame remaining is also shown for
+ * start transfer and two additional sample points.
+ */
+static ssize_t hcd_frrem_show(struct device *_dev,
+			      struct device_attribute *attr, char *buf)
+{
+#ifndef DWC_DEVICE_ONLY
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	dwc_otg_hcd_dump_frrem(otg_dev->hcd);
+#endif /* DWC_DEVICE_ONLY */
+	return sprintf(buf, "HCD Dump Frame Remaining\n");
+}
+
+DEVICE_ATTR(hcd_frrem, S_IRUGO | S_IWUSR, hcd_frrem_show, 0);
+
+/**
+ * Displays the time required to read the GNPTXFSIZ register many times (the
+ * output shows the number of times the register is read).
+ */
+#define RW_REG_COUNT 10000000
+#define MSEC_PER_JIFFIE 1000/HZ
+static ssize_t rd_reg_test_show(struct device *_dev,
+				struct device_attribute *attr, char *buf)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	int i;
+	int time;
+	int start_jiffies;
+
+	printk("HZ %d, MSEC_PER_JIFFIE %d, loops_per_jiffy %lu\n",
+	       HZ, MSEC_PER_JIFFIE, loops_per_jiffy);
+	start_jiffies = jiffies;
+	for (i = 0; i < RW_REG_COUNT; i++) {
+		dwc_otg_get_gnptxfsiz(otg_dev->core_if);
+	}
+	time = jiffies - start_jiffies;
+	return sprintf(buf,
+		       "Time to read GNPTXFSIZ reg %d times: %d msecs (%d jiffies)\n",
+		       RW_REG_COUNT, time * MSEC_PER_JIFFIE, time);
+}
+
+DEVICE_ATTR(rd_reg_test, S_IRUGO | S_IWUSR, rd_reg_test_show, 0);
+
+/**
+ * Displays the time required to write the GNPTXFSIZ register many times (the
+ * output shows the number of times the register is written).
+ */
+static ssize_t wr_reg_test_show(struct device *_dev,
+				struct device_attribute *attr, char *buf)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	uint32_t reg_val;
+	int i;
+	int time;
+	int start_jiffies;
+
+	printk("HZ %d, MSEC_PER_JIFFIE %d, loops_per_jiffy %lu\n",
+	       HZ, MSEC_PER_JIFFIE, loops_per_jiffy);
+	reg_val = dwc_otg_get_gnptxfsiz(otg_dev->core_if);
+	start_jiffies = jiffies;
+	for (i = 0; i < RW_REG_COUNT; i++) {
+		dwc_otg_set_gnptxfsiz(otg_dev->core_if, reg_val);
+	}
+	time = jiffies - start_jiffies;
+	return sprintf(buf,
+		       "Time to write GNPTXFSIZ reg %d times: %d msecs (%d jiffies)\n",
+		       RW_REG_COUNT, time * MSEC_PER_JIFFIE, time);
+}
+
+DEVICE_ATTR(wr_reg_test, S_IRUGO | S_IWUSR, wr_reg_test_show, 0);
+
+#ifdef CONFIG_USB_DWC_OTG_LPM
+
+/**
+* Show the lpm_response attribute.
+*/
+static ssize_t lpmresp_show(struct device *_dev,
+			    struct device_attribute *attr, char *buf)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	if (!dwc_otg_get_param_lpm_enable(otg_dev->core_if))
+		return sprintf(buf, "** LPM is DISABLED **\n");
+
+	if (!dwc_otg_is_device_mode(otg_dev->core_if)) {
+		return sprintf(buf, "** Current mode is not device mode\n");
+	}
+	return sprintf(buf, "lpm_response = %d\n",
+		       dwc_otg_get_lpmresponse(otg_dev->core_if));
+}
+
+/**
+* Store the lpm_response attribute.
+*/
+static ssize_t lpmresp_store(struct device *_dev,
+			     struct device_attribute *attr,
+			     const char *buf, size_t count)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	uint32_t val = simple_strtoul(buf, NULL, 16);
+
+	if (!dwc_otg_get_param_lpm_enable(otg_dev->core_if)) {
+		return 0;
+	}
+
+	if (!dwc_otg_is_device_mode(otg_dev->core_if)) {
+		return 0;
+	}
+
+	dwc_otg_set_lpmresponse(otg_dev->core_if, val);
+	return count;
+}
+
+DEVICE_ATTR(lpm_response, S_IRUGO | S_IWUSR, lpmresp_show, lpmresp_store);
+
+/**
+* Show the besl_reject attribute.
+*/
+static ssize_t beslreject_show(struct device *_dev,
+			    struct device_attribute *attr, char *buf)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	if (!dwc_otg_get_param_lpm_enable(otg_dev->core_if))
+		return sprintf(buf, "** LPM is DISABLED **\n");
+	if (!dwc_otg_get_param_besl_enable(otg_dev->core_if))
+		return sprintf(buf, "** EnBesl is DISABLED **\n");
+
+	if (!dwc_otg_is_device_mode(otg_dev->core_if)) {
+		return sprintf(buf, "** Current mode is not device mode\n");
+	}
+
+	return sprintf(buf, "besl_reject = %d\n",
+		        dwc_otg_get_beslreject(otg_dev->core_if));
+}
+
+/**
+* Store the besl_reject attribute.
+*/
+static ssize_t beslreject_store(struct device *_dev,
+			     struct device_attribute *attr,
+			     const char *buf, size_t count)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	uint32_t val = simple_strtoul(buf, NULL, 16);
+
+	if (!dwc_otg_get_param_lpm_enable(otg_dev->core_if)) {
+		return 0;
+	}
+
+	if (!dwc_otg_get_param_besl_enable(otg_dev->core_if)) {
+		return 0;
+	}
+
+	if (!dwc_otg_is_device_mode(otg_dev->core_if)) {
+		return 0;
+	}
+
+	 dwc_otg_set_beslreject(otg_dev->core_if,val);
+
+	return count;
+}
+
+DEVICE_ATTR(besl_reject, S_IRUGO | S_IWUSR, beslreject_show, beslreject_store);
+
+/**
+* Show the hird_thresh attribute.
+*/
+static ssize_t hirdthresh_show(struct device *_dev,
+			    struct device_attribute *attr, char *buf)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	if (!dwc_otg_get_param_lpm_enable(otg_dev->core_if))
+		return sprintf(buf, "** LPM is DISABLED **\n");
+
+	if (!dwc_otg_is_device_mode(otg_dev->core_if)) {
+		return sprintf(buf, "** Current mode is not device mode\n");
+	}
+
+	return sprintf(buf, "hirdthresh = 0x%x\n",
+		        dwc_otg_get_hirdthresh(otg_dev->core_if));
+}
+
+/**
+* Store the hird_thresh attribute.
+*/
+static ssize_t hirdthresh_store(struct device *_dev,
+			     struct device_attribute *attr,
+			     const char *buf, size_t count)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	uint32_t val = simple_strtoul(buf, NULL, 16);
+
+	if (!dwc_otg_get_param_lpm_enable(otg_dev->core_if)) {
+		return 0;
+	}
+
+	if (!dwc_otg_is_device_mode(otg_dev->core_if)) {
+		return 0;
+	}
+
+	 dwc_otg_set_hirdthresh(otg_dev->core_if,val);
+
+	return count;
+}
+
+DEVICE_ATTR(hird_thres, S_IRUGO | S_IWUSR, hirdthresh_show, hirdthresh_store);
+
+/**
+* Show the sleep_status attribute.
+*/
+static ssize_t sleepstatus_show(struct device *_dev,
+				struct device_attribute *attr, char *buf)
+{
+
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	return sprintf(buf, "Sleep Status = %d\n",
+		       dwc_otg_get_lpm_portsleepstatus(otg_dev->core_if));
+}
+
+/**
+ * Store the sleep_status attribure.
+ */
+static ssize_t sleepstatus_store(struct device *_dev,
+				 struct device_attribute *attr,
+				 const char *buf, size_t count)
+{
+	struct platform_device *lm_dev = container_of(_dev, struct platform_device, dev);
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(lm_dev);
+
+
+	dwc_otg_core_if_t *core_if = otg_dev->core_if;
+
+	if (dwc_otg_get_lpm_portsleepstatus(otg_dev->core_if)) {
+		if (dwc_otg_is_host_mode(core_if)) {
+
+			DWC_PRINTF("Host initiated resume\n");
+			dwc_otg_set_prtresume(otg_dev->core_if, 1);
+		}
+	}
+
+	return count;
+}
+
+DEVICE_ATTR(sleep_status, S_IRUGO | S_IWUSR, sleepstatus_show,
+	    sleepstatus_store);
+
+#endif /* CONFIG_USB_DWC_OTG_LPM_ENABLE */
+
+/**@}*/
+
+/**
+ * Create the device files
+ */
+void dwc_otg_attr_create(struct platform_device *dev)
+{
+	int error;
+
+	error = device_create_file(&dev->dev, &dev_attr_regoffset);
+	error = device_create_file(&dev->dev, &dev_attr_regvalue);
+	error = device_create_file(&dev->dev, &dev_attr_mode);
+	error = device_create_file(&dev->dev, &dev_attr_hnpcapable);
+	error = device_create_file(&dev->dev, &dev_attr_srpcapable);
+	error = device_create_file(&dev->dev, &dev_attr_hsic_connect);
+	error = device_create_file(&dev->dev, &dev_attr_inv_sel_hsic);
+	error = device_create_file(&dev->dev, &dev_attr_hnp);
+	error = device_create_file(&dev->dev, &dev_attr_srp);
+	error = device_create_file(&dev->dev, &dev_attr_buspower);
+	error = device_create_file(&dev->dev, &dev_attr_bussuspend);
+	error = device_create_file(&dev->dev, &dev_attr_mode_ch_tim_en);
+	error = device_create_file(&dev->dev, &dev_attr_fr_interval);
+	error = device_create_file(&dev->dev, &dev_attr_busconnected);
+	error = device_create_file(&dev->dev, &dev_attr_gotgctl);
+	error = device_create_file(&dev->dev, &dev_attr_gusbcfg);
+	error = device_create_file(&dev->dev, &dev_attr_grxfsiz);
+	error = device_create_file(&dev->dev, &dev_attr_gnptxfsiz);
+	error = device_create_file(&dev->dev, &dev_attr_gpvndctl);
+	error = device_create_file(&dev->dev, &dev_attr_ggpio);
+	error = device_create_file(&dev->dev, &dev_attr_guid);
+	error = device_create_file(&dev->dev, &dev_attr_gsnpsid);
+	error = device_create_file(&dev->dev, &dev_attr_devspeed);
+	error = device_create_file(&dev->dev, &dev_attr_enumspeed);
+	error = device_create_file(&dev->dev, &dev_attr_hptxfsiz);
+	error = device_create_file(&dev->dev, &dev_attr_hprt0);
+	error = device_create_file(&dev->dev, &dev_attr_remote_wakeup);
+	error = device_create_file(&dev->dev, &dev_attr_rem_wakeup_pwrdn);
+	error = device_create_file(&dev->dev, &dev_attr_disconnect_us);
+	error = device_create_file(&dev->dev, &dev_attr_regdump);
+	error = device_create_file(&dev->dev, &dev_attr_spramdump);
+	error = device_create_file(&dev->dev, &dev_attr_hcddump);
+	error = device_create_file(&dev->dev, &dev_attr_hcd_frrem);
+	error = device_create_file(&dev->dev, &dev_attr_rd_reg_test);
+	error = device_create_file(&dev->dev, &dev_attr_wr_reg_test);
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	error = device_create_file(&dev->dev, &dev_attr_lpm_response);
+	error = device_create_file(&dev->dev, &dev_attr_sleep_status);
+	error = device_create_file(&dev->dev, &dev_attr_besl_reject);
+	error = device_create_file(&dev->dev, &dev_attr_hird_thres);
+#endif
+}
+
+/**
+ * Remove the device files
+ */
+void dwc_otg_attr_remove(struct platform_device *dev
+
+    )
+{
+	device_remove_file(&dev->dev, &dev_attr_regoffset);
+	device_remove_file(&dev->dev, &dev_attr_regvalue);
+	device_remove_file(&dev->dev, &dev_attr_mode);
+	device_remove_file(&dev->dev, &dev_attr_hnpcapable);
+	device_remove_file(&dev->dev, &dev_attr_srpcapable);
+	device_remove_file(&dev->dev, &dev_attr_hsic_connect);
+	device_remove_file(&dev->dev, &dev_attr_inv_sel_hsic);
+	device_remove_file(&dev->dev, &dev_attr_hnp);
+	device_remove_file(&dev->dev, &dev_attr_srp);
+	device_remove_file(&dev->dev, &dev_attr_buspower);
+	device_remove_file(&dev->dev, &dev_attr_bussuspend);
+	device_remove_file(&dev->dev, &dev_attr_mode_ch_tim_en);
+	device_remove_file(&dev->dev, &dev_attr_fr_interval);
+	device_remove_file(&dev->dev, &dev_attr_busconnected);
+	device_remove_file(&dev->dev, &dev_attr_gotgctl);
+	device_remove_file(&dev->dev, &dev_attr_gusbcfg);
+	device_remove_file(&dev->dev, &dev_attr_grxfsiz);
+	device_remove_file(&dev->dev, &dev_attr_gnptxfsiz);
+	device_remove_file(&dev->dev, &dev_attr_gpvndctl);
+	device_remove_file(&dev->dev, &dev_attr_ggpio);
+	device_remove_file(&dev->dev, &dev_attr_guid);
+	device_remove_file(&dev->dev, &dev_attr_gsnpsid);
+	device_remove_file(&dev->dev, &dev_attr_devspeed);
+	device_remove_file(&dev->dev, &dev_attr_enumspeed);
+	device_remove_file(&dev->dev, &dev_attr_hptxfsiz);
+	device_remove_file(&dev->dev, &dev_attr_hprt0);
+	device_remove_file(&dev->dev, &dev_attr_remote_wakeup);
+	device_remove_file(&dev->dev, &dev_attr_rem_wakeup_pwrdn);
+	device_remove_file(&dev->dev, &dev_attr_disconnect_us);
+	device_remove_file(&dev->dev, &dev_attr_regdump);
+	device_remove_file(&dev->dev, &dev_attr_spramdump);
+	device_remove_file(&dev->dev, &dev_attr_hcddump);
+	device_remove_file(&dev->dev, &dev_attr_hcd_frrem);
+	device_remove_file(&dev->dev, &dev_attr_rd_reg_test);
+	device_remove_file(&dev->dev, &dev_attr_wr_reg_test);
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	device_remove_file(&dev->dev, &dev_attr_lpm_response);
+	device_remove_file(&dev->dev, &dev_attr_sleep_status);
+	device_remove_file(&dev->dev, &dev_attr_besl_reject);
+	device_remove_file(&dev->dev, &dev_attr_hird_thres);
+#endif
+}
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_attr.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_attr.h
new file mode 100644
index 0000000..4d43296
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_attr.h
@@ -0,0 +1,78 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_attr.h $
+ * $Revision: #13 $
+ * $Date: 2010/06/21 $
+ * $Change: 1532021 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#if !defined(__DWC_OTG_ATTR_H__)
+#define __DWC_OTG_ATTR_H__
+
+#include <linux/platform_device.h>
+
+/** @file
+ * This file contains the interface to the Linux device attributes.
+ */
+extern struct device_attribute dev_attr_regoffset;
+extern struct device_attribute dev_attr_regvalue;
+
+extern struct device_attribute dev_attr_mode;
+extern struct device_attribute dev_attr_hnpcapable;
+extern struct device_attribute dev_attr_srpcapable;
+extern struct device_attribute dev_attr_hnp;
+extern struct device_attribute dev_attr_srp;
+extern struct device_attribute dev_attr_buspower;
+extern struct device_attribute dev_attr_bussuspend;
+extern struct device_attribute dev_attr_mode_ch_tim_en;
+extern struct device_attribute dev_attr_fr_interval;
+extern struct device_attribute dev_attr_busconnected;
+extern struct device_attribute dev_attr_gotgctl;
+extern struct device_attribute dev_attr_gusbcfg;
+extern struct device_attribute dev_attr_grxfsiz;
+extern struct device_attribute dev_attr_gnptxfsiz;
+extern struct device_attribute dev_attr_gpvndctl;
+extern struct device_attribute dev_attr_ggpio;
+extern struct device_attribute dev_attr_guid;
+extern struct device_attribute dev_attr_gsnpsid;
+extern struct device_attribute dev_attr_devspeed;
+extern struct device_attribute dev_attr_enumspeed;
+extern struct device_attribute dev_attr_hptxfsiz;
+extern struct device_attribute dev_attr_hprt0;
+#ifdef CONFIG_USB_DWC_OTG_LPM
+extern struct device_attribute dev_attr_lpm_response;
+extern struct device_attribute devi_attr_sleep_status;
+#endif
+
+void dwc_otg_attr_create(struct platform_device *dev
+    );
+
+void dwc_otg_attr_remove(struct platform_device *dev
+
+    );
+#endif
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_cfi.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_cfi.c
new file mode 100644
index 0000000..530a661
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_cfi.c
@@ -0,0 +1,1869 @@
+/* ==========================================================================
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+/** @file
+ *
+ * This file contains the most of the CFI(Core Feature Interface)
+ * implementation for the OTG.
+ */
+
+#ifdef DWC_UTE_CFI
+
+#include "dwc_otg_pcd.h"
+#include "dwc_otg_cfi.h"
+
+/** This definition should actually migrate to the Portability Library */
+#define DWC_CONSTANT_CPU_TO_LE16(x) (x)
+
+extern dwc_otg_pcd_ep_t *get_ep_by_addr(dwc_otg_pcd_t * pcd, u16 wIndex);
+
+static int cfi_core_features_buf(uint8_t * buf, uint16_t buflen);
+static int cfi_get_feature_value(uint8_t * buf, uint16_t buflen,
+				 struct dwc_otg_pcd *pcd,
+				 struct cfi_usb_ctrlrequest *ctrl_req);
+static int cfi_set_feature_value(struct dwc_otg_pcd *pcd);
+static int cfi_ep_get_sg_val(uint8_t * buf, struct dwc_otg_pcd *pcd,
+			     struct cfi_usb_ctrlrequest *req);
+static int cfi_ep_get_concat_val(uint8_t * buf, struct dwc_otg_pcd *pcd,
+				 struct cfi_usb_ctrlrequest *req);
+static int cfi_ep_get_align_val(uint8_t * buf, struct dwc_otg_pcd *pcd,
+				struct cfi_usb_ctrlrequest *req);
+static int cfi_preproc_reset(struct dwc_otg_pcd *pcd,
+			     struct cfi_usb_ctrlrequest *req);
+static void cfi_free_ep_bs_dyn_data(cfi_ep_t * cfiep);
+
+static uint16_t get_dfifo_size(dwc_otg_core_if_t * core_if);
+static int32_t get_rxfifo_size(dwc_otg_core_if_t * core_if, uint16_t wValue);
+static int32_t get_txfifo_size(struct dwc_otg_pcd *pcd, uint16_t wValue);
+
+static uint8_t resize_fifos(dwc_otg_core_if_t * core_if);
+
+/** This is the header of the all features descriptor */
+static cfi_all_features_header_t all_props_desc_header = {
+	.wVersion = DWC_CONSTANT_CPU_TO_LE16(0x100),
+	.wCoreID = DWC_CONSTANT_CPU_TO_LE16(CFI_CORE_ID_OTG),
+	.wNumFeatures = DWC_CONSTANT_CPU_TO_LE16(9),
+};
+
+/** This is an array of statically allocated feature descriptors */
+static cfi_feature_desc_header_t prop_descs[] = {
+
+	/* FT_ID_DMA_MODE */
+	{
+	 .wFeatureID = DWC_CONSTANT_CPU_TO_LE16(FT_ID_DMA_MODE),
+	 .bmAttributes = CFI_FEATURE_ATTR_RW,
+	 .wDataLength = DWC_CONSTANT_CPU_TO_LE16(1),
+	 },
+
+	/* FT_ID_DMA_BUFFER_SETUP */
+	{
+	 .wFeatureID = DWC_CONSTANT_CPU_TO_LE16(FT_ID_DMA_BUFFER_SETUP),
+	 .bmAttributes = CFI_FEATURE_ATTR_RW,
+	 .wDataLength = DWC_CONSTANT_CPU_TO_LE16(6),
+	 },
+
+	/* FT_ID_DMA_BUFF_ALIGN */
+	{
+	 .wFeatureID = DWC_CONSTANT_CPU_TO_LE16(FT_ID_DMA_BUFF_ALIGN),
+	 .bmAttributes = CFI_FEATURE_ATTR_RW,
+	 .wDataLength = DWC_CONSTANT_CPU_TO_LE16(2),
+	 },
+
+	/* FT_ID_DMA_CONCAT_SETUP */
+	{
+	 .wFeatureID = DWC_CONSTANT_CPU_TO_LE16(FT_ID_DMA_CONCAT_SETUP),
+	 .bmAttributes = CFI_FEATURE_ATTR_RW,
+	 //.wDataLength  = DWC_CONSTANT_CPU_TO_LE16(6),
+	 },
+
+	/* FT_ID_DMA_CIRCULAR */
+	{
+	 .wFeatureID = DWC_CONSTANT_CPU_TO_LE16(FT_ID_DMA_CIRCULAR),
+	 .bmAttributes = CFI_FEATURE_ATTR_RW,
+	 .wDataLength = DWC_CONSTANT_CPU_TO_LE16(6),
+	 },
+
+	/* FT_ID_THRESHOLD_SETUP */
+	{
+	 .wFeatureID = DWC_CONSTANT_CPU_TO_LE16(FT_ID_THRESHOLD_SETUP),
+	 .bmAttributes = CFI_FEATURE_ATTR_RW,
+	 .wDataLength = DWC_CONSTANT_CPU_TO_LE16(6),
+	 },
+
+	/* FT_ID_DFIFO_DEPTH */
+	{
+	 .wFeatureID = DWC_CONSTANT_CPU_TO_LE16(FT_ID_DFIFO_DEPTH),
+	 .bmAttributes = CFI_FEATURE_ATTR_RO,
+	 .wDataLength = DWC_CONSTANT_CPU_TO_LE16(2),
+	 },
+
+	/* FT_ID_TX_FIFO_DEPTH */
+	{
+	 .wFeatureID = DWC_CONSTANT_CPU_TO_LE16(FT_ID_TX_FIFO_DEPTH),
+	 .bmAttributes = CFI_FEATURE_ATTR_RW,
+	 .wDataLength = DWC_CONSTANT_CPU_TO_LE16(2),
+	 },
+
+	/* FT_ID_RX_FIFO_DEPTH */
+	{
+	 .wFeatureID = DWC_CONSTANT_CPU_TO_LE16(FT_ID_RX_FIFO_DEPTH),
+	 .bmAttributes = CFI_FEATURE_ATTR_RW,
+	 .wDataLength = DWC_CONSTANT_CPU_TO_LE16(2),
+	 }
+};
+
+/** The table of feature names */
+cfi_string_t prop_name_table[] = {
+	{FT_ID_DMA_MODE, "dma_mode"},
+	{FT_ID_DMA_BUFFER_SETUP, "buffer_setup"},
+	{FT_ID_DMA_BUFF_ALIGN, "buffer_align"},
+	{FT_ID_DMA_CONCAT_SETUP, "concat_setup"},
+	{FT_ID_DMA_CIRCULAR, "buffer_circular"},
+	{FT_ID_THRESHOLD_SETUP, "threshold_setup"},
+	{FT_ID_DFIFO_DEPTH, "dfifo_depth"},
+	{FT_ID_TX_FIFO_DEPTH, "txfifo_depth"},
+	{FT_ID_RX_FIFO_DEPTH, "rxfifo_depth"},
+	{}
+};
+
+/************************************************************************/
+
+/**
+ * Returns the name of the feature by its ID
+ * or NULL if no featute ID matches.
+ *
+ */
+const uint8_t *get_prop_name(uint16_t prop_id, int *len)
+{
+	cfi_string_t *pstr;
+	*len = 0;
+
+	for (pstr = prop_name_table; pstr && pstr->s; pstr++) {
+		if (pstr->id == prop_id) {
+			*len = DWC_STRLEN(pstr->s);
+			return pstr->s;
+		}
+	}
+	return NULL;
+}
+
+/**
+ * This function handles all CFI specific control requests.
+ *
+ * Return a negative value to stall the DCE.
+ */
+int cfi_setup(struct dwc_otg_pcd *pcd, struct cfi_usb_ctrlrequest *ctrl)
+{
+	int retval = 0;
+	dwc_otg_pcd_ep_t *ep = NULL;
+	cfiobject_t *cfi = pcd->cfi;
+	struct dwc_otg_core_if *coreif = GET_CORE_IF(pcd);
+	uint16_t wLen = DWC_LE16_TO_CPU(&ctrl->wLength);
+	uint16_t wValue = DWC_LE16_TO_CPU(&ctrl->wValue);
+	uint16_t wIndex = DWC_LE16_TO_CPU(&ctrl->wIndex);
+	uint32_t regaddr = 0;
+	uint32_t regval = 0;
+
+	/* Save this Control Request in the CFI object.
+	 * The data field will be assigned in the data stage completion CB function.
+	 */
+	cfi->ctrl_req = *ctrl;
+	cfi->ctrl_req.data = NULL;
+
+	cfi->need_gadget_att = 0;
+	cfi->need_status_in_complete = 0;
+
+	switch (ctrl->bRequest) {
+	case VEN_CORE_GET_FEATURES:
+		retval = cfi_core_features_buf(cfi->buf_in.buf, CFI_IN_BUF_LEN);
+		if (retval >= 0) {
+			//dump_msg(cfi->buf_in.buf, retval);
+			ep = &pcd->ep0;
+
+			retval = min((uint16_t) retval, wLen);
+			/* Transfer this buffer to the host through the EP0-IN EP */
+			ep->dwc_ep.dma_addr = cfi->buf_in.addr;
+			ep->dwc_ep.start_xfer_buff = cfi->buf_in.buf;
+			ep->dwc_ep.xfer_buff = cfi->buf_in.buf;
+			ep->dwc_ep.xfer_len = retval;
+			ep->dwc_ep.xfer_count = 0;
+			ep->dwc_ep.sent_zlp = 0;
+			ep->dwc_ep.total_len = ep->dwc_ep.xfer_len;
+
+			pcd->ep0_pending = 1;
+			dwc_otg_ep0_start_transfer(coreif, &ep->dwc_ep);
+		}
+		retval = 0;
+		break;
+
+	case VEN_CORE_GET_FEATURE:
+		CFI_INFO("VEN_CORE_GET_FEATURE\n");
+		retval = cfi_get_feature_value(cfi->buf_in.buf, CFI_IN_BUF_LEN,
+					       pcd, ctrl);
+		if (retval >= 0) {
+			ep = &pcd->ep0;
+
+			retval = min((uint16_t) retval, wLen);
+			/* Transfer this buffer to the host through the EP0-IN EP */
+			ep->dwc_ep.dma_addr = cfi->buf_in.addr;
+			ep->dwc_ep.start_xfer_buff = cfi->buf_in.buf;
+			ep->dwc_ep.xfer_buff = cfi->buf_in.buf;
+			ep->dwc_ep.xfer_len = retval;
+			ep->dwc_ep.xfer_count = 0;
+			ep->dwc_ep.sent_zlp = 0;
+			ep->dwc_ep.total_len = ep->dwc_ep.xfer_len;
+
+			pcd->ep0_pending = 1;
+			dwc_otg_ep0_start_transfer(coreif, &ep->dwc_ep);
+		}
+		CFI_INFO("VEN_CORE_GET_FEATURE=%d\n", retval);
+		dump_msg(cfi->buf_in.buf, retval);
+		break;
+
+	case VEN_CORE_SET_FEATURE:
+		CFI_INFO("VEN_CORE_SET_FEATURE\n");
+		/* Set up an XFER to get the data stage of the control request,
+		 * which is the new value of the feature to be modified.
+		 */
+		ep = &pcd->ep0;
+		ep->dwc_ep.is_in = 0;
+		ep->dwc_ep.dma_addr = cfi->buf_out.addr;
+		ep->dwc_ep.start_xfer_buff = cfi->buf_out.buf;
+		ep->dwc_ep.xfer_buff = cfi->buf_out.buf;
+		ep->dwc_ep.xfer_len = wLen;
+		ep->dwc_ep.xfer_count = 0;
+		ep->dwc_ep.sent_zlp = 0;
+		ep->dwc_ep.total_len = ep->dwc_ep.xfer_len;
+
+		pcd->ep0_pending = 1;
+		/* Read the control write's data stage */
+		dwc_otg_ep0_start_transfer(coreif, &ep->dwc_ep);
+		retval = 0;
+		break;
+
+	case VEN_CORE_RESET_FEATURES:
+		CFI_INFO("VEN_CORE_RESET_FEATURES\n");
+		cfi->need_gadget_att = 1;
+		cfi->need_status_in_complete = 1;
+		retval = cfi_preproc_reset(pcd, ctrl);
+		CFI_INFO("VEN_CORE_RESET_FEATURES = (%d)\n", retval);
+		break;
+
+	case VEN_CORE_ACTIVATE_FEATURES:
+		CFI_INFO("VEN_CORE_ACTIVATE_FEATURES\n");
+		break;
+
+	case VEN_CORE_READ_REGISTER:
+		CFI_INFO("VEN_CORE_READ_REGISTER\n");
+		/* wValue optionally contains the HI WORD of the register offset and
+		 * wIndex contains the LOW WORD of the register offset
+		 */
+		if (wValue == 0) {
+			/* @TODO - MAS - fix the access to the base field */
+			regaddr = 0;
+			//regaddr = (uint32_t) pcd->otg_dev->os_dep.base;
+			//GET_CORE_IF(pcd)->co
+			regaddr |= wIndex;
+		} else {
+			regaddr = (wValue << 16) | wIndex;
+		}
+
+		/* Read a 32-bit value of the memory at the regaddr */
+		regval = DWC_READ_REG32((uint32_t *) regaddr);
+
+		ep = &pcd->ep0;
+		dwc_memcpy(cfi->buf_in.buf, &regval, sizeof(uint32_t));
+		ep->dwc_ep.is_in = 1;
+		ep->dwc_ep.dma_addr = cfi->buf_in.addr;
+		ep->dwc_ep.start_xfer_buff = cfi->buf_in.buf;
+		ep->dwc_ep.xfer_buff = cfi->buf_in.buf;
+		ep->dwc_ep.xfer_len = wLen;
+		ep->dwc_ep.xfer_count = 0;
+		ep->dwc_ep.sent_zlp = 0;
+		ep->dwc_ep.total_len = ep->dwc_ep.xfer_len;
+
+		pcd->ep0_pending = 1;
+		dwc_otg_ep0_start_transfer(coreif, &ep->dwc_ep);
+		cfi->need_gadget_att = 0;
+		retval = 0;
+		break;
+
+	case VEN_CORE_WRITE_REGISTER:
+		CFI_INFO("VEN_CORE_WRITE_REGISTER\n");
+		/* Set up an XFER to get the data stage of the control request,
+		 * which is the new value of the register to be modified.
+		 */
+		ep = &pcd->ep0;
+		ep->dwc_ep.is_in = 0;
+		ep->dwc_ep.dma_addr = cfi->buf_out.addr;
+		ep->dwc_ep.start_xfer_buff = cfi->buf_out.buf;
+		ep->dwc_ep.xfer_buff = cfi->buf_out.buf;
+		ep->dwc_ep.xfer_len = wLen;
+		ep->dwc_ep.xfer_count = 0;
+		ep->dwc_ep.sent_zlp = 0;
+		ep->dwc_ep.total_len = ep->dwc_ep.xfer_len;
+
+		pcd->ep0_pending = 1;
+		/* Read the control write's data stage */
+		dwc_otg_ep0_start_transfer(coreif, &ep->dwc_ep);
+		retval = 0;
+		break;
+
+	default:
+		retval = -DWC_E_NOT_SUPPORTED;
+		break;
+	}
+
+	return retval;
+}
+
+/**
+ * This function prepares the core features descriptors and copies its
+ * raw representation into the buffer <buf>.
+ *
+ * The buffer structure is as follows:
+ *	all_features_header (8 bytes)
+ *	features_#1 (8 bytes + feature name string length)
+ *	features_#2 (8 bytes + feature name string length)
+ *	.....
+ *	features_#n - where n=the total count of feature descriptors
+ */
+static int cfi_core_features_buf(uint8_t * buf, uint16_t buflen)
+{
+	cfi_feature_desc_header_t *prop_hdr = prop_descs;
+	cfi_feature_desc_header_t *prop;
+	cfi_all_features_header_t *all_props_hdr = &all_props_desc_header;
+	cfi_all_features_header_t *tmp;
+	uint8_t *tmpbuf = buf;
+	const uint8_t *pname = NULL;
+	int i, j, namelen = 0, totlen;
+
+	/* Prepare and copy the core features into the buffer */
+	CFI_INFO("%s:\n", __func__);
+
+	tmp = (cfi_all_features_header_t *) tmpbuf;
+	*tmp = *all_props_hdr;
+	tmpbuf += CFI_ALL_FEATURES_HDR_LEN;
+
+	j = sizeof(prop_descs) / sizeof(cfi_all_features_header_t);
+	for (i = 0; i < j; i++, prop_hdr++) {
+		pname = get_prop_name(prop_hdr->wFeatureID, &namelen);
+		prop = (cfi_feature_desc_header_t *) tmpbuf;
+		*prop = *prop_hdr;
+
+		prop->bNameLen = namelen;
+		prop->wLength =
+		    DWC_CONSTANT_CPU_TO_LE16(CFI_FEATURE_DESC_HDR_LEN +
+					     namelen);
+
+		tmpbuf += CFI_FEATURE_DESC_HDR_LEN;
+		dwc_memcpy(tmpbuf, pname, namelen);
+		tmpbuf += namelen;
+	}
+
+	totlen = tmpbuf - buf;
+
+	if (totlen > 0) {
+		tmp = (cfi_all_features_header_t *) buf;
+		tmp->wTotalLen = DWC_CONSTANT_CPU_TO_LE16(totlen);
+	}
+
+	return totlen;
+}
+
+/**
+ * This function releases all the dynamic memory in the CFI object.
+ */
+static void cfi_release(cfiobject_t * cfiobj)
+{
+	cfi_ep_t *cfiep;
+	dwc_list_link_t *tmp;
+
+	CFI_INFO("%s\n", __func__);
+
+	if (cfiobj->buf_in.buf) {
+		DWC_DMA_FREE(CFI_IN_BUF_LEN, cfiobj->buf_in.buf,
+			     cfiobj->buf_in.addr);
+		cfiobj->buf_in.buf = NULL;
+	}
+
+	if (cfiobj->buf_out.buf) {
+		DWC_DMA_FREE(CFI_OUT_BUF_LEN, cfiobj->buf_out.buf,
+			     cfiobj->buf_out.addr);
+		cfiobj->buf_out.buf = NULL;
+	}
+
+	/* Free the Buffer Setup values for each EP */
+	//list_for_each_entry(cfiep, &cfiobj->active_eps, lh) {
+	DWC_LIST_FOREACH(tmp, &cfiobj->active_eps) {
+		cfiep = DWC_LIST_ENTRY(tmp, struct cfi_ep, lh);
+		cfi_free_ep_bs_dyn_data(cfiep);
+	}
+}
+
+/**
+ * This function frees the dynamically allocated EP buffer setup data.
+ */
+static void cfi_free_ep_bs_dyn_data(cfi_ep_t * cfiep)
+{
+	if (cfiep->bm_sg) {
+		DWC_FREE(cfiep->bm_sg);
+		cfiep->bm_sg = NULL;
+	}
+
+	if (cfiep->bm_align) {
+		DWC_FREE(cfiep->bm_align);
+		cfiep->bm_align = NULL;
+	}
+
+	if (cfiep->bm_concat) {
+		if (NULL != cfiep->bm_concat->wTxBytes) {
+			DWC_FREE(cfiep->bm_concat->wTxBytes);
+			cfiep->bm_concat->wTxBytes = NULL;
+		}
+		DWC_FREE(cfiep->bm_concat);
+		cfiep->bm_concat = NULL;
+	}
+}
+
+/**
+ * This function initializes the default values of the features
+ * for a specific endpoint and should be called only once when
+ * the EP is enabled first time.
+ */
+static int cfi_ep_init_defaults(struct dwc_otg_pcd *pcd, cfi_ep_t * cfiep)
+{
+	int retval = 0;
+
+	cfiep->bm_sg = DWC_ALLOC(sizeof(ddma_sg_buffer_setup_t));
+	if (NULL == cfiep->bm_sg) {
+		CFI_INFO("Failed to allocate memory for SG feature value\n");
+		return -DWC_E_NO_MEMORY;
+	}
+	dwc_memset(cfiep->bm_sg, 0, sizeof(ddma_sg_buffer_setup_t));
+
+	/* For the Concatenation feature's default value we do not allocate
+	 * memory for the wTxBytes field - it will be done in the set_feature_value
+	 * request handler.
+	 */
+	cfiep->bm_concat = DWC_ALLOC(sizeof(ddma_concat_buffer_setup_t));
+	if (NULL == cfiep->bm_concat) {
+		CFI_INFO
+		    ("Failed to allocate memory for CONCATENATION feature value\n");
+		DWC_FREE(cfiep->bm_sg);
+		return -DWC_E_NO_MEMORY;
+	}
+	dwc_memset(cfiep->bm_concat, 0, sizeof(ddma_concat_buffer_setup_t));
+
+	cfiep->bm_align = DWC_ALLOC(sizeof(ddma_align_buffer_setup_t));
+	if (NULL == cfiep->bm_align) {
+		CFI_INFO
+		    ("Failed to allocate memory for Alignment feature value\n");
+		DWC_FREE(cfiep->bm_sg);
+		DWC_FREE(cfiep->bm_concat);
+		return -DWC_E_NO_MEMORY;
+	}
+	dwc_memset(cfiep->bm_align, 0, sizeof(ddma_align_buffer_setup_t));
+
+	return retval;
+}
+
+/**
+ * The callback function that notifies the CFI on the activation of
+ * an endpoint in the PCD. The following steps are done in this function:
+ *
+ *	Create a dynamically allocated cfi_ep_t object (a CFI wrapper to the PCD's
+ *		active endpoint)
+ *	Create MAX_DMA_DESCS_PER_EP count DMA Descriptors for the EP
+ *	Set the Buffer Mode to standard
+ *	Initialize the default values for all EP modes (SG, Circular, Concat, Align)
+ *	Add the cfi_ep_t object to the list of active endpoints in the CFI object
+ */
+static int cfi_ep_enable(struct cfiobject *cfi, struct dwc_otg_pcd *pcd,
+			 struct dwc_otg_pcd_ep *ep)
+{
+	cfi_ep_t *cfiep;
+	int retval = -DWC_E_NOT_SUPPORTED;
+
+	CFI_INFO("%s: epname=%s; epnum=0x%02x\n", __func__,
+		 "EP_" /*ep->ep.name */ , ep->desc->bEndpointAddress);
+	/* MAS - Check whether this endpoint already is in the list */
+	cfiep = get_cfi_ep_by_pcd_ep(cfi, ep);
+
+	if (NULL == cfiep) {
+		/* Allocate a cfi_ep_t object */
+		cfiep = DWC_ALLOC(sizeof(cfi_ep_t));
+		if (NULL == cfiep) {
+			CFI_INFO
+			    ("Unable to allocate memory for <cfiep> in function %s\n",
+			     __func__);
+			return -DWC_E_NO_MEMORY;
+		}
+		dwc_memset(cfiep, 0, sizeof(cfi_ep_t));
+
+		/* Save the dwc_otg_pcd_ep pointer in the cfiep object */
+		cfiep->ep = ep;
+
+		/* Allocate the DMA Descriptors chain of MAX_DMA_DESCS_PER_EP count */
+		ep->dwc_ep.descs =
+		    DWC_DMA_ALLOC(MAX_DMA_DESCS_PER_EP *
+				  sizeof(dwc_otg_dma_desc_t),
+				  &ep->dwc_ep.descs_dma_addr);
+
+		if (NULL == ep->dwc_ep.descs) {
+			DWC_FREE(cfiep);
+			return -DWC_E_NO_MEMORY;
+		}
+
+		DWC_LIST_INIT(&cfiep->lh);
+
+		/* Set the buffer mode to BM_STANDARD. It will be modified
+		 * when building descriptors for a specific buffer mode */
+		ep->dwc_ep.buff_mode = BM_STANDARD;
+
+		/* Create and initialize the default values for this EP's Buffer modes */
+		if ((retval = cfi_ep_init_defaults(pcd, cfiep)) < 0)
+			return retval;
+
+		/* Add the cfi_ep_t object to the CFI object's list of active endpoints */
+		DWC_LIST_INSERT_TAIL(&cfi->active_eps, &cfiep->lh);
+		retval = 0;
+	} else {		/* The sought EP already is in the list */
+		CFI_INFO("%s: The sought EP already is in the list\n",
+			 __func__);
+	}
+
+	return retval;
+}
+
+/**
+ * This function is called when the data stage of a 3-stage Control Write request
+ * is complete.
+ *
+ */
+static int cfi_ctrl_write_complete(struct cfiobject *cfi,
+				   struct dwc_otg_pcd *pcd)
+{
+	uint32_t addr, reg_value;
+	uint16_t wIndex, wValue;
+	uint8_t bRequest;
+	uint8_t *buf = cfi->buf_out.buf;
+	//struct usb_ctrlrequest *ctrl_req = &cfi->ctrl_req_saved;
+	struct cfi_usb_ctrlrequest *ctrl_req = &cfi->ctrl_req;
+	int retval = -DWC_E_NOT_SUPPORTED;
+
+	CFI_INFO("%s\n", __func__);
+
+	bRequest = ctrl_req->bRequest;
+	wIndex = DWC_CONSTANT_CPU_TO_LE16(ctrl_req->wIndex);
+	wValue = DWC_CONSTANT_CPU_TO_LE16(ctrl_req->wValue);
+
+	/*
+	 * Save the pointer to the data stage in the ctrl_req's <data> field.
+	 * The request should be already saved in the command stage by now.
+	 */
+	ctrl_req->data = cfi->buf_out.buf;
+	cfi->need_status_in_complete = 0;
+	cfi->need_gadget_att = 0;
+
+	switch (bRequest) {
+	case VEN_CORE_WRITE_REGISTER:
+		/* The buffer contains raw data of the new value for the register */
+		reg_value = *((uint32_t *) buf);
+		if (wValue == 0) {
+			addr = 0;
+			//addr = (uint32_t) pcd->otg_dev->os_dep.base;
+			addr += wIndex;
+		} else {
+			addr = (wValue << 16) | wIndex;
+		}
+
+		//writel(reg_value, addr);
+
+		retval = 0;
+		cfi->need_status_in_complete = 1;
+		break;
+
+	case VEN_CORE_SET_FEATURE:
+		/* The buffer contains raw data of the new value of the feature */
+		retval = cfi_set_feature_value(pcd);
+		if (retval < 0)
+			return retval;
+
+		cfi->need_status_in_complete = 1;
+		break;
+
+	default:
+		break;
+	}
+
+	return retval;
+}
+
+/**
+ * This function builds the DMA descriptors for the SG buffer mode.
+ */
+static void cfi_build_sg_descs(struct cfiobject *cfi, cfi_ep_t * cfiep,
+			       dwc_otg_pcd_request_t * req)
+{
+	struct dwc_otg_pcd_ep *ep = cfiep->ep;
+	ddma_sg_buffer_setup_t *sgval = cfiep->bm_sg;
+	struct dwc_otg_dma_desc *desc = cfiep->ep->dwc_ep.descs;
+	struct dwc_otg_dma_desc *desc_last = cfiep->ep->dwc_ep.descs;
+	dma_addr_t buff_addr = req->dma;
+	int i;
+	uint32_t txsize, off;
+
+	txsize = sgval->wSize;
+	off = sgval->bOffset;
+
+//      CFI_INFO("%s: %s TXSIZE=0x%08x; OFFSET=0x%08x\n",
+//              __func__, cfiep->ep->ep.name, txsize, off);
+
+	for (i = 0; i < sgval->bCount; i++) {
+		desc->status.b.bs = BS_HOST_BUSY;
+		desc->buf = buff_addr;
+		desc->status.b.l = 0;
+		desc->status.b.ioc = 0;
+		desc->status.b.sp = 0;
+		desc->status.b.bytes = txsize;
+		desc->status.b.bs = BS_HOST_READY;
+
+		/* Set the next address of the buffer */
+		buff_addr += txsize + off;
+		desc_last = desc;
+		desc++;
+	}
+
+	/* Set the last, ioc and sp bits on the Last DMA Descriptor */
+	desc_last->status.b.l = 1;
+	desc_last->status.b.ioc = 1;
+	desc_last->status.b.sp = ep->dwc_ep.sent_zlp;
+	/* Save the last DMA descriptor pointer */
+	cfiep->dma_desc_last = desc_last;
+	cfiep->desc_count = sgval->bCount;
+}
+
+/**
+ * This function builds the DMA descriptors for the Concatenation buffer mode.
+ */
+static void cfi_build_concat_descs(struct cfiobject *cfi, cfi_ep_t * cfiep,
+				   dwc_otg_pcd_request_t * req)
+{
+	struct dwc_otg_pcd_ep *ep = cfiep->ep;
+	ddma_concat_buffer_setup_t *concatval = cfiep->bm_concat;
+	struct dwc_otg_dma_desc *desc = cfiep->ep->dwc_ep.descs;
+	struct dwc_otg_dma_desc *desc_last = cfiep->ep->dwc_ep.descs;
+	dma_addr_t buff_addr = req->dma;
+	int i;
+	uint16_t *txsize;
+
+	txsize = concatval->wTxBytes;
+
+	for (i = 0; i < concatval->hdr.bDescCount; i++) {
+		desc->buf = buff_addr;
+		desc->status.b.bs = BS_HOST_BUSY;
+		desc->status.b.l = 0;
+		desc->status.b.ioc = 0;
+		desc->status.b.sp = 0;
+		desc->status.b.bytes = *txsize;
+		desc->status.b.bs = BS_HOST_READY;
+
+		txsize++;
+		/* Set the next address of the buffer */
+		buff_addr += UGETW(ep->desc->wMaxPacketSize);
+		desc_last = desc;
+		desc++;
+	}
+
+	/* Set the last, ioc and sp bits on the Last DMA Descriptor */
+	desc_last->status.b.l = 1;
+	desc_last->status.b.ioc = 1;
+	desc_last->status.b.sp = ep->dwc_ep.sent_zlp;
+	cfiep->dma_desc_last = desc_last;
+	cfiep->desc_count = concatval->hdr.bDescCount;
+}
+
+/**
+ * This function builds the DMA descriptors for the Circular buffer mode
+ */
+static void cfi_build_circ_descs(struct cfiobject *cfi, cfi_ep_t * cfiep,
+				 dwc_otg_pcd_request_t * req)
+{
+	/* @todo: MAS - add implementation when this feature needs to be tested */
+}
+
+/**
+ * This function builds the DMA descriptors for the Alignment buffer mode
+ */
+static void cfi_build_align_descs(struct cfiobject *cfi, cfi_ep_t * cfiep,
+				  dwc_otg_pcd_request_t * req)
+{
+	struct dwc_otg_pcd_ep *ep = cfiep->ep;
+	ddma_align_buffer_setup_t *alignval = cfiep->bm_align;
+	struct dwc_otg_dma_desc *desc = cfiep->ep->dwc_ep.descs;
+	dma_addr_t buff_addr = req->dma;
+
+	desc->status.b.bs = BS_HOST_BUSY;
+	desc->status.b.l = 1;
+	desc->status.b.ioc = 1;
+	desc->status.b.sp = ep->dwc_ep.sent_zlp;
+	desc->status.b.bytes = req->length;
+	/* Adjust the buffer alignment */
+	desc->buf = (buff_addr + alignval->bAlign);
+	desc->status.b.bs = BS_HOST_READY;
+	cfiep->dma_desc_last = desc;
+	cfiep->desc_count = 1;
+}
+
+/**
+ * This function builds the DMA descriptors chain for different modes of the
+ * buffer setup of an endpoint.
+ */
+static void cfi_build_descriptors(struct cfiobject *cfi,
+				  struct dwc_otg_pcd *pcd,
+				  struct dwc_otg_pcd_ep *ep,
+				  dwc_otg_pcd_request_t * req)
+{
+	cfi_ep_t *cfiep;
+
+	/* Get the cfiep by the dwc_otg_pcd_ep */
+	cfiep = get_cfi_ep_by_pcd_ep(cfi, ep);
+	if (NULL == cfiep) {
+		CFI_INFO("%s: Unable to find a matching active endpoint\n",
+			 __func__);
+		return;
+	}
+
+	cfiep->xfer_len = req->length;
+
+	/* Iterate through all the DMA descriptors */
+	switch (cfiep->ep->dwc_ep.buff_mode) {
+	case BM_SG:
+		cfi_build_sg_descs(cfi, cfiep, req);
+		break;
+
+	case BM_CONCAT:
+		cfi_build_concat_descs(cfi, cfiep, req);
+		break;
+
+	case BM_CIRCULAR:
+		cfi_build_circ_descs(cfi, cfiep, req);
+		break;
+
+	case BM_ALIGN:
+		cfi_build_align_descs(cfi, cfiep, req);
+		break;
+
+	default:
+		break;
+	}
+}
+
+/**
+ * Allocate DMA buffer for different Buffer modes.
+ */
+static void *cfi_ep_alloc_buf(struct cfiobject *cfi, struct dwc_otg_pcd *pcd,
+			      struct dwc_otg_pcd_ep *ep, dma_addr_t * dma,
+			      unsigned size, gfp_t flags)
+{
+	return DWC_DMA_ALLOC(size, dma);
+}
+
+/**
+ * This function initializes the CFI object.
+ */
+int init_cfi(cfiobject_t * cfiobj)
+{
+	CFI_INFO("%s\n", __func__);
+
+	/* Allocate a buffer for IN XFERs */
+	cfiobj->buf_in.buf =
+	    DWC_DMA_ALLOC(CFI_IN_BUF_LEN, &cfiobj->buf_in.addr);
+	if (NULL == cfiobj->buf_in.buf) {
+		CFI_INFO("Unable to allocate buffer for INs\n");
+		return -DWC_E_NO_MEMORY;
+	}
+
+	/* Allocate a buffer for OUT XFERs */
+	cfiobj->buf_out.buf =
+	    DWC_DMA_ALLOC(CFI_OUT_BUF_LEN, &cfiobj->buf_out.addr);
+	if (NULL == cfiobj->buf_out.buf) {
+		CFI_INFO("Unable to allocate buffer for OUT\n");
+		return -DWC_E_NO_MEMORY;
+	}
+
+	/* Initialize the callback function pointers */
+	cfiobj->ops.release = cfi_release;
+	cfiobj->ops.ep_enable = cfi_ep_enable;
+	cfiobj->ops.ctrl_write_complete = cfi_ctrl_write_complete;
+	cfiobj->ops.build_descriptors = cfi_build_descriptors;
+	cfiobj->ops.ep_alloc_buf = cfi_ep_alloc_buf;
+
+	/* Initialize the list of active endpoints in the CFI object */
+	DWC_LIST_INIT(&cfiobj->active_eps);
+
+	return 0;
+}
+
+/**
+ * This function reads the required feature's current value into the buffer
+ *
+ * @retval: Returns negative as error, or the data length of the feature
+ */
+static int cfi_get_feature_value(uint8_t * buf, uint16_t buflen,
+				 struct dwc_otg_pcd *pcd,
+				 struct cfi_usb_ctrlrequest *ctrl_req)
+{
+	int retval = -DWC_E_NOT_SUPPORTED;
+	struct dwc_otg_core_if *coreif = GET_CORE_IF(pcd);
+	uint16_t dfifo, rxfifo, txfifo;
+
+	switch (ctrl_req->wIndex) {
+		/* Whether the DDMA is enabled or not */
+	case FT_ID_DMA_MODE:
+		*buf = (coreif->dma_enable && coreif->dma_desc_enable) ? 1 : 0;
+		retval = 1;
+		break;
+
+	case FT_ID_DMA_BUFFER_SETUP:
+		retval = cfi_ep_get_sg_val(buf, pcd, ctrl_req);
+		break;
+
+	case FT_ID_DMA_BUFF_ALIGN:
+		retval = cfi_ep_get_align_val(buf, pcd, ctrl_req);
+		break;
+
+	case FT_ID_DMA_CONCAT_SETUP:
+		retval = cfi_ep_get_concat_val(buf, pcd, ctrl_req);
+		break;
+
+	case FT_ID_DMA_CIRCULAR:
+		CFI_INFO("GetFeature value (FT_ID_DMA_CIRCULAR)\n");
+		break;
+
+	case FT_ID_THRESHOLD_SETUP:
+		CFI_INFO("GetFeature value (FT_ID_THRESHOLD_SETUP)\n");
+		break;
+
+	case FT_ID_DFIFO_DEPTH:
+		dfifo = get_dfifo_size(coreif);
+		*((uint16_t *) buf) = dfifo;
+		retval = sizeof(uint16_t);
+		break;
+
+	case FT_ID_TX_FIFO_DEPTH:
+		retval = get_txfifo_size(pcd, ctrl_req->wValue);
+		if (retval >= 0) {
+			txfifo = retval;
+			*((uint16_t *) buf) = txfifo;
+			retval = sizeof(uint16_t);
+		}
+		break;
+
+	case FT_ID_RX_FIFO_DEPTH:
+		retval = get_rxfifo_size(coreif, ctrl_req->wValue);
+		if (retval >= 0) {
+			rxfifo = retval;
+			*((uint16_t *) buf) = rxfifo;
+			retval = sizeof(uint16_t);
+		}
+		break;
+	}
+
+	return retval;
+}
+
+/**
+ * This function resets the SG for the specified EP to its default value
+ */
+static int cfi_reset_sg_val(cfi_ep_t * cfiep)
+{
+	dwc_memset(cfiep->bm_sg, 0, sizeof(ddma_sg_buffer_setup_t));
+	return 0;
+}
+
+/**
+ * This function resets the Alignment for the specified EP to its default value
+ */
+static int cfi_reset_align_val(cfi_ep_t * cfiep)
+{
+	dwc_memset(cfiep->bm_sg, 0, sizeof(ddma_sg_buffer_setup_t));
+	return 0;
+}
+
+/**
+ * This function resets the Concatenation for the specified EP to its default value
+ * This function will also set the value of the wTxBytes field to NULL after
+ * freeing the memory previously allocated for this field.
+ */
+static int cfi_reset_concat_val(cfi_ep_t * cfiep)
+{
+	/* First we need to free the wTxBytes field */
+	if (cfiep->bm_concat->wTxBytes) {
+		DWC_FREE(cfiep->bm_concat->wTxBytes);
+		cfiep->bm_concat->wTxBytes = NULL;
+	}
+
+	dwc_memset(cfiep->bm_concat, 0, sizeof(ddma_concat_buffer_setup_t));
+	return 0;
+}
+
+/**
+ * This function resets all the buffer setups of the specified endpoint
+ */
+static int cfi_ep_reset_all_setup_vals(cfi_ep_t * cfiep)
+{
+	cfi_reset_sg_val(cfiep);
+	cfi_reset_align_val(cfiep);
+	cfi_reset_concat_val(cfiep);
+	return 0;
+}
+
+static int cfi_handle_reset_fifo_val(struct dwc_otg_pcd *pcd, uint8_t ep_addr,
+				     uint8_t rx_rst, uint8_t tx_rst)
+{
+	int retval = -DWC_E_INVALID;
+	uint16_t tx_siz[15];
+	uint16_t rx_siz = 0;
+	dwc_otg_pcd_ep_t *ep = NULL;
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_otg_core_params_t *params = GET_CORE_IF(pcd)->core_params;
+
+	if (rx_rst) {
+		rx_siz = params->dev_rx_fifo_size;
+		params->dev_rx_fifo_size = GET_CORE_IF(pcd)->init_rxfsiz;
+	}
+
+	if (tx_rst) {
+		if (ep_addr == 0) {
+			int i;
+
+			for (i = 0; i < core_if->hwcfg4.b.num_in_eps; i++) {
+				tx_siz[i] =
+				    core_if->core_params->dev_tx_fifo_size[i];
+				core_if->core_params->dev_tx_fifo_size[i] =
+				    core_if->init_txfsiz[i];
+			}
+		} else {
+
+			ep = get_ep_by_addr(pcd, ep_addr);
+
+			if (NULL == ep) {
+				CFI_INFO
+				    ("%s: Unable to get the endpoint addr=0x%02x\n",
+				     __func__, ep_addr);
+				return -DWC_E_INVALID;
+			}
+
+			tx_siz[0] =
+			    params->dev_tx_fifo_size[ep->dwc_ep.tx_fifo_num -
+						     1];
+			params->dev_tx_fifo_size[ep->dwc_ep.tx_fifo_num - 1] =
+			    GET_CORE_IF(pcd)->init_txfsiz[ep->
+							  dwc_ep.tx_fifo_num -
+							  1];
+		}
+	}
+
+	if (resize_fifos(GET_CORE_IF(pcd))) {
+		retval = 0;
+	} else {
+		CFI_INFO
+		    ("%s: Error resetting the feature Reset All(FIFO size)\n",
+		     __func__);
+		if (rx_rst) {
+			params->dev_rx_fifo_size = rx_siz;
+		}
+
+		if (tx_rst) {
+			if (ep_addr == 0) {
+				int i;
+				for (i = 0; i < core_if->hwcfg4.b.num_in_eps;
+				     i++) {
+					core_if->
+					    core_params->dev_tx_fifo_size[i] =
+					    tx_siz[i];
+				}
+			} else {
+				params->dev_tx_fifo_size[ep->
+							 dwc_ep.tx_fifo_num -
+							 1] = tx_siz[0];
+			}
+		}
+		retval = -DWC_E_INVALID;
+	}
+	return retval;
+}
+
+static int cfi_handle_reset_all(struct dwc_otg_pcd *pcd, uint8_t addr)
+{
+	int retval = 0;
+	cfi_ep_t *cfiep;
+	cfiobject_t *cfi = pcd->cfi;
+	dwc_list_link_t *tmp;
+
+	retval = cfi_handle_reset_fifo_val(pcd, addr, 1, 1);
+	if (retval < 0) {
+		return retval;
+	}
+
+	/* If the EP address is known then reset the features for only that EP */
+	if (addr) {
+		cfiep = get_cfi_ep_by_addr(pcd->cfi, addr);
+		if (NULL == cfiep) {
+			CFI_INFO("%s: Error getting the EP address 0x%02x\n",
+				 __func__, addr);
+			return -DWC_E_INVALID;
+		}
+		retval = cfi_ep_reset_all_setup_vals(cfiep);
+		cfiep->ep->dwc_ep.buff_mode = BM_STANDARD;
+	}
+	/* Otherwise (wValue == 0), reset all features of all EP's */
+	else {
+		/* Traverse all the active EP's and reset the feature(s) value(s) */
+		//list_for_each_entry(cfiep, &cfi->active_eps, lh) {
+		DWC_LIST_FOREACH(tmp, &cfi->active_eps) {
+			cfiep = DWC_LIST_ENTRY(tmp, struct cfi_ep, lh);
+			retval = cfi_ep_reset_all_setup_vals(cfiep);
+			cfiep->ep->dwc_ep.buff_mode = BM_STANDARD;
+			if (retval < 0) {
+				CFI_INFO
+				    ("%s: Error resetting the feature Reset All\n",
+				     __func__);
+				return retval;
+			}
+		}
+	}
+	return retval;
+}
+
+static int cfi_handle_reset_dma_buff_setup(struct dwc_otg_pcd *pcd,
+					   uint8_t addr)
+{
+	int retval = 0;
+	cfi_ep_t *cfiep;
+	cfiobject_t *cfi = pcd->cfi;
+	dwc_list_link_t *tmp;
+
+	/* If the EP address is known then reset the features for only that EP */
+	if (addr) {
+		cfiep = get_cfi_ep_by_addr(pcd->cfi, addr);
+		if (NULL == cfiep) {
+			CFI_INFO("%s: Error getting the EP address 0x%02x\n",
+				 __func__, addr);
+			return -DWC_E_INVALID;
+		}
+		retval = cfi_reset_sg_val(cfiep);
+	}
+	/* Otherwise (wValue == 0), reset all features of all EP's */
+	else {
+		/* Traverse all the active EP's and reset the feature(s) value(s) */
+		//list_for_each_entry(cfiep, &cfi->active_eps, lh) {
+		DWC_LIST_FOREACH(tmp, &cfi->active_eps) {
+			cfiep = DWC_LIST_ENTRY(tmp, struct cfi_ep, lh);
+			retval = cfi_reset_sg_val(cfiep);
+			if (retval < 0) {
+				CFI_INFO
+				    ("%s: Error resetting the feature Buffer Setup\n",
+				     __func__);
+				return retval;
+			}
+		}
+	}
+	return retval;
+}
+
+static int cfi_handle_reset_concat_val(struct dwc_otg_pcd *pcd, uint8_t addr)
+{
+	int retval = 0;
+	cfi_ep_t *cfiep;
+	cfiobject_t *cfi = pcd->cfi;
+	dwc_list_link_t *tmp;
+
+	/* If the EP address is known then reset the features for only that EP */
+	if (addr) {
+		cfiep = get_cfi_ep_by_addr(pcd->cfi, addr);
+		if (NULL == cfiep) {
+			CFI_INFO("%s: Error getting the EP address 0x%02x\n",
+				 __func__, addr);
+			return -DWC_E_INVALID;
+		}
+		retval = cfi_reset_concat_val(cfiep);
+	}
+	/* Otherwise (wValue == 0), reset all features of all EP's */
+	else {
+		/* Traverse all the active EP's and reset the feature(s) value(s) */
+		//list_for_each_entry(cfiep, &cfi->active_eps, lh) {
+		DWC_LIST_FOREACH(tmp, &cfi->active_eps) {
+			cfiep = DWC_LIST_ENTRY(tmp, struct cfi_ep, lh);
+			retval = cfi_reset_concat_val(cfiep);
+			if (retval < 0) {
+				CFI_INFO
+				    ("%s: Error resetting the feature Concatenation Value\n",
+				     __func__);
+				return retval;
+			}
+		}
+	}
+	return retval;
+}
+
+static int cfi_handle_reset_align_val(struct dwc_otg_pcd *pcd, uint8_t addr)
+{
+	int retval = 0;
+	cfi_ep_t *cfiep;
+	cfiobject_t *cfi = pcd->cfi;
+	dwc_list_link_t *tmp;
+
+	/* If the EP address is known then reset the features for only that EP */
+	if (addr) {
+		cfiep = get_cfi_ep_by_addr(pcd->cfi, addr);
+		if (NULL == cfiep) {
+			CFI_INFO("%s: Error getting the EP address 0x%02x\n",
+				 __func__, addr);
+			return -DWC_E_INVALID;
+		}
+		retval = cfi_reset_align_val(cfiep);
+	}
+	/* Otherwise (wValue == 0), reset all features of all EP's */
+	else {
+		/* Traverse all the active EP's and reset the feature(s) value(s) */
+		//list_for_each_entry(cfiep, &cfi->active_eps, lh) {
+		DWC_LIST_FOREACH(tmp, &cfi->active_eps) {
+			cfiep = DWC_LIST_ENTRY(tmp, struct cfi_ep, lh);
+			retval = cfi_reset_align_val(cfiep);
+			if (retval < 0) {
+				CFI_INFO
+				    ("%s: Error resetting the feature Aliignment Value\n",
+				     __func__);
+				return retval;
+			}
+		}
+	}
+	return retval;
+
+}
+
+static int cfi_preproc_reset(struct dwc_otg_pcd *pcd,
+			     struct cfi_usb_ctrlrequest *req)
+{
+	int retval = 0;
+
+	switch (req->wIndex) {
+	case 0:
+		/* Reset all features */
+		retval = cfi_handle_reset_all(pcd, req->wValue & 0xff);
+		break;
+
+	case FT_ID_DMA_BUFFER_SETUP:
+		/* Reset the SG buffer setup */
+		retval =
+		    cfi_handle_reset_dma_buff_setup(pcd, req->wValue & 0xff);
+		break;
+
+	case FT_ID_DMA_CONCAT_SETUP:
+		/* Reset the Concatenation buffer setup */
+		retval = cfi_handle_reset_concat_val(pcd, req->wValue & 0xff);
+		break;
+
+	case FT_ID_DMA_BUFF_ALIGN:
+		/* Reset the Alignment buffer setup */
+		retval = cfi_handle_reset_align_val(pcd, req->wValue & 0xff);
+		break;
+
+	case FT_ID_TX_FIFO_DEPTH:
+		retval =
+		    cfi_handle_reset_fifo_val(pcd, req->wValue & 0xff, 0, 1);
+		pcd->cfi->need_gadget_att = 0;
+		break;
+
+	case FT_ID_RX_FIFO_DEPTH:
+		retval = cfi_handle_reset_fifo_val(pcd, 0, 1, 0);
+		pcd->cfi->need_gadget_att = 0;
+		break;
+	default:
+		break;
+	}
+	return retval;
+}
+
+/**
+ * This function sets a new value for the SG buffer setup.
+ */
+static int cfi_ep_set_sg_val(uint8_t * buf, struct dwc_otg_pcd *pcd)
+{
+	uint8_t inaddr, outaddr;
+	cfi_ep_t *epin, *epout;
+	ddma_sg_buffer_setup_t *psgval;
+	uint32_t desccount, size;
+
+	CFI_INFO("%s\n", __func__);
+
+	psgval = (ddma_sg_buffer_setup_t *) buf;
+	desccount = (uint32_t) psgval->bCount;
+	size = (uint32_t) psgval->wSize;
+
+	/* Check the DMA descriptor count */
+	if ((desccount > MAX_DMA_DESCS_PER_EP) || (desccount == 0)) {
+		CFI_INFO
+		    ("%s: The count of DMA Descriptors should be between 1 and %d\n",
+		     __func__, MAX_DMA_DESCS_PER_EP);
+		return -DWC_E_INVALID;
+	}
+
+	/* Check the DMA descriptor count */
+
+	if (size == 0) {
+
+		CFI_INFO("%s: The transfer size should be at least 1 byte\n",
+			 __func__);
+
+		return -DWC_E_INVALID;
+
+	}
+
+	inaddr = psgval->bInEndpointAddress;
+	outaddr = psgval->bOutEndpointAddress;
+
+	epin = get_cfi_ep_by_addr(pcd->cfi, inaddr);
+	epout = get_cfi_ep_by_addr(pcd->cfi, outaddr);
+
+	if (NULL == epin || NULL == epout) {
+		CFI_INFO
+		    ("%s: Unable to get the endpoints inaddr=0x%02x outaddr=0x%02x\n",
+		     __func__, inaddr, outaddr);
+		return -DWC_E_INVALID;
+	}
+
+	epin->ep->dwc_ep.buff_mode = BM_SG;
+	dwc_memcpy(epin->bm_sg, psgval, sizeof(ddma_sg_buffer_setup_t));
+
+	epout->ep->dwc_ep.buff_mode = BM_SG;
+	dwc_memcpy(epout->bm_sg, psgval, sizeof(ddma_sg_buffer_setup_t));
+
+	return 0;
+}
+
+/**
+ * This function sets a new value for the buffer Alignment setup.
+ */
+static int cfi_ep_set_alignment_val(uint8_t * buf, struct dwc_otg_pcd *pcd)
+{
+	cfi_ep_t *ep;
+	uint8_t addr;
+	ddma_align_buffer_setup_t *palignval;
+
+	palignval = (ddma_align_buffer_setup_t *) buf;
+	addr = palignval->bEndpointAddress;
+
+	ep = get_cfi_ep_by_addr(pcd->cfi, addr);
+
+	if (NULL == ep) {
+		CFI_INFO("%s: Unable to get the endpoint addr=0x%02x\n",
+			 __func__, addr);
+		return -DWC_E_INVALID;
+	}
+
+	ep->ep->dwc_ep.buff_mode = BM_ALIGN;
+	dwc_memcpy(ep->bm_align, palignval, sizeof(ddma_align_buffer_setup_t));
+
+	return 0;
+}
+
+/**
+ * This function sets a new value for the Concatenation buffer setup.
+ */
+static int cfi_ep_set_concat_val(uint8_t * buf, struct dwc_otg_pcd *pcd)
+{
+	uint8_t addr;
+	cfi_ep_t *ep;
+	struct _ddma_concat_buffer_setup_hdr *pConcatValHdr;
+	uint16_t *pVals;
+	uint32_t desccount;
+	int i;
+	uint16_t mps;
+
+	pConcatValHdr = (struct _ddma_concat_buffer_setup_hdr *)buf;
+	desccount = (uint32_t) pConcatValHdr->bDescCount;
+	pVals = (uint16_t *) (buf + BS_CONCAT_VAL_HDR_LEN);
+
+	/* Check the DMA descriptor count */
+	if (desccount > MAX_DMA_DESCS_PER_EP) {
+		CFI_INFO("%s: Maximum DMA Descriptor count should be %d\n",
+			 __func__, MAX_DMA_DESCS_PER_EP);
+		return -DWC_E_INVALID;
+	}
+
+	addr = pConcatValHdr->bEndpointAddress;
+	ep = get_cfi_ep_by_addr(pcd->cfi, addr);
+	if (NULL == ep) {
+		CFI_INFO("%s: Unable to get the endpoint addr=0x%02x\n",
+			 __func__, addr);
+		return -DWC_E_INVALID;
+	}
+
+	mps = UGETW(ep->ep->desc->wMaxPacketSize);
+
+	/* Check the wTxSizes to be less than or equal to the mps */
+	for (i = 0; i < desccount; i++) {
+		if (pVals[i] > mps) {
+			CFI_INFO
+			    ("%s: ERROR - the wTxSize[%d] should be <= MPS (wTxSize=%d)\n",
+			     __func__, i, pVals[i]);
+			return -DWC_E_INVALID;
+		}
+	}
+
+	ep->ep->dwc_ep.buff_mode = BM_CONCAT;
+	dwc_memcpy(ep->bm_concat, pConcatValHdr, BS_CONCAT_VAL_HDR_LEN);
+
+	/* Free the previously allocated storage for the wTxBytes */
+	if (ep->bm_concat->wTxBytes) {
+		DWC_FREE(ep->bm_concat->wTxBytes);
+	}
+
+	/* Allocate a new storage for the wTxBytes field */
+	ep->bm_concat->wTxBytes =
+	    DWC_ALLOC(sizeof(uint16_t) * pConcatValHdr->bDescCount);
+	if (NULL == ep->bm_concat->wTxBytes) {
+		CFI_INFO("%s: Unable to allocate memory\n", __func__);
+		return -DWC_E_NO_MEMORY;
+	}
+
+	/* Copy the new values into the wTxBytes filed */
+	dwc_memcpy(ep->bm_concat->wTxBytes, buf + BS_CONCAT_VAL_HDR_LEN,
+		   sizeof(uint16_t) * pConcatValHdr->bDescCount);
+
+	return 0;
+}
+
+/**
+ * This function calculates the total of all FIFO sizes
+ *
+ * @param core_if Programming view of DWC_otg controller
+ *
+ * @return The total of data FIFO sizes.
+ *
+ */
+static uint16_t get_dfifo_size(dwc_otg_core_if_t * core_if)
+{
+	dwc_otg_core_params_t *params = core_if->core_params;
+	uint16_t dfifo_total = 0;
+	int i;
+
+	/* The shared RxFIFO size */
+	dfifo_total =
+	    params->dev_rx_fifo_size + params->dev_nperio_tx_fifo_size;
+
+	/* Add up each TxFIFO size to the total */
+	for (i = 0; i < core_if->hwcfg4.b.num_in_eps; i++) {
+		dfifo_total += params->dev_tx_fifo_size[i];
+	}
+
+	return dfifo_total;
+}
+
+/**
+ * This function returns Rx FIFO size
+ *
+ * @param core_if Programming view of DWC_otg controller
+ *
+ * @return The total of data FIFO sizes.
+ *
+ */
+static int32_t get_rxfifo_size(dwc_otg_core_if_t * core_if, uint16_t wValue)
+{
+	switch (wValue >> 8) {
+	case 0:
+		return (core_if->pwron_rxfsiz <
+			32768) ? core_if->pwron_rxfsiz : 32768;
+		break;
+	case 1:
+		return core_if->core_params->dev_rx_fifo_size;
+		break;
+	default:
+		return -DWC_E_INVALID;
+		break;
+	}
+}
+
+/**
+ * This function returns Tx FIFO size for IN EP
+ *
+ * @param core_if Programming view of DWC_otg controller
+ *
+ * @return The total of data FIFO sizes.
+ *
+ */
+static int32_t get_txfifo_size(struct dwc_otg_pcd *pcd, uint16_t wValue)
+{
+	dwc_otg_pcd_ep_t *ep;
+
+	ep = get_ep_by_addr(pcd, wValue & 0xff);
+
+	if (NULL == ep) {
+		CFI_INFO("%s: Unable to get the endpoint addr=0x%02x\n",
+			 __func__, wValue & 0xff);
+		return -DWC_E_INVALID;
+	}
+
+	if (!ep->dwc_ep.is_in) {
+		CFI_INFO
+		    ("%s: No Tx FIFO assingned to the Out endpoint addr=0x%02x\n",
+		     __func__, wValue & 0xff);
+		return -DWC_E_INVALID;
+	}
+
+	switch (wValue >> 8) {
+	case 0:
+		return (GET_CORE_IF(pcd)->pwron_txfsiz
+			[ep->dwc_ep.tx_fifo_num - 1] <
+			768) ? GET_CORE_IF(pcd)->pwron_txfsiz[ep->
+							      dwc_ep.tx_fifo_num
+							      - 1] : 32768;
+		break;
+	case 1:
+		return GET_CORE_IF(pcd)->core_params->
+		    dev_tx_fifo_size[ep->dwc_ep.num - 1];
+		break;
+	default:
+		return -DWC_E_INVALID;
+		break;
+	}
+}
+
+/**
+ * This function checks if the submitted combination of
+ * device mode FIFO sizes is possible or not.
+ *
+ * @param core_if Programming view of DWC_otg controller
+ *
+ * @return 1 if possible, 0 otherwise.
+ *
+ */
+static uint8_t check_fifo_sizes(dwc_otg_core_if_t * core_if)
+{
+	uint16_t dfifo_actual = 0;
+	dwc_otg_core_params_t *params = core_if->core_params;
+	uint16_t start_addr = 0;
+	int i;
+
+	dfifo_actual =
+	    params->dev_rx_fifo_size + params->dev_nperio_tx_fifo_size;
+
+	for (i = 0; i < core_if->hwcfg4.b.num_in_eps; i++) {
+		dfifo_actual += params->dev_tx_fifo_size[i];
+	}
+
+	if (dfifo_actual > core_if->total_fifo_size) {
+		return 0;
+	}
+
+	if (params->dev_rx_fifo_size > 32768 || params->dev_rx_fifo_size < 16)
+		return 0;
+
+	if (params->dev_nperio_tx_fifo_size > 32768
+	    || params->dev_nperio_tx_fifo_size < 16)
+		return 0;
+
+	for (i = 0; i < core_if->hwcfg4.b.num_in_eps; i++) {
+
+		if (params->dev_tx_fifo_size[i] > 768
+		    || params->dev_tx_fifo_size[i] < 4)
+			return 0;
+	}
+
+	if (params->dev_rx_fifo_size > core_if->pwron_rxfsiz)
+		return 0;
+	start_addr = params->dev_rx_fifo_size;
+
+	if (params->dev_nperio_tx_fifo_size > core_if->pwron_gnptxfsiz)
+		return 0;
+	start_addr += params->dev_nperio_tx_fifo_size;
+
+	for (i = 0; i < core_if->hwcfg4.b.num_in_eps; i++) {
+
+		if (params->dev_tx_fifo_size[i] > core_if->pwron_txfsiz[i])
+			return 0;
+		start_addr += params->dev_tx_fifo_size[i];
+	}
+
+	return 1;
+}
+
+/**
+ * This function resizes Device mode FIFOs
+ *
+ * @param core_if Programming view of DWC_otg controller
+ *
+ * @return 1 if successful, 0 otherwise
+ *
+ */
+static uint8_t resize_fifos(dwc_otg_core_if_t * core_if)
+{
+	int i = 0;
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	dwc_otg_core_params_t *params = core_if->core_params;
+	uint32_t rx_fifo_size;
+	fifosize_data_t nptxfifosize;
+	fifosize_data_t txfifosize[15];
+
+	uint32_t rx_fsz_bak;
+	uint32_t nptxfsz_bak;
+	uint32_t txfsz_bak[15];
+
+	uint16_t start_address;
+	uint8_t retval = 1;
+
+	if (!check_fifo_sizes(core_if)) {
+		return 0;
+	}
+
+	/* Configure data FIFO sizes */
+	if (core_if->hwcfg2.b.dynamic_fifo && params->enable_dynamic_fifo) {
+		rx_fsz_bak = DWC_READ_REG32(&global_regs->grxfsiz);
+		rx_fifo_size = params->dev_rx_fifo_size;
+		DWC_WRITE_REG32(&global_regs->grxfsiz, rx_fifo_size);
+
+		/*
+		 * Tx FIFOs These FIFOs are numbered from 1 to 15.
+		 * Indexes of the FIFO size module parameters in the
+		 * dev_tx_fifo_size array and the FIFO size registers in
+		 * the dtxfsiz array run from 0 to 14.
+		 */
+
+		/* Non-periodic Tx FIFO */
+		nptxfsz_bak = DWC_READ_REG32(&global_regs->gnptxfsiz);
+		nptxfifosize.b.depth = params->dev_nperio_tx_fifo_size;
+		start_address = params->dev_rx_fifo_size;
+		nptxfifosize.b.startaddr = start_address;
+
+		DWC_WRITE_REG32(&global_regs->gnptxfsiz, nptxfifosize.d32);
+
+		start_address += nptxfifosize.b.depth;
+
+		for (i = 0; i < core_if->hwcfg4.b.num_in_eps; i++) {
+			txfsz_bak[i] = DWC_READ_REG32(&global_regs->dtxfsiz[i]);
+
+			txfifosize[i].b.depth = params->dev_tx_fifo_size[i];
+			txfifosize[i].b.startaddr = start_address;
+			DWC_WRITE_REG32(&global_regs->dtxfsiz[i],
+					txfifosize[i].d32);
+
+			start_address += txfifosize[i].b.depth;
+		}
+
+		/** Check if register values are set correctly */
+		if (rx_fifo_size != DWC_READ_REG32(&global_regs->grxfsiz)) {
+			retval = 0;
+		}
+
+		if (nptxfifosize.d32 != DWC_READ_REG32(&global_regs->gnptxfsiz)) {
+			retval = 0;
+		}
+
+		for (i = 0; i < core_if->hwcfg4.b.num_in_eps; i++) {
+			if (txfifosize[i].d32 !=
+			    DWC_READ_REG32(&global_regs->dtxfsiz[i])) {
+				retval = 0;
+			}
+		}
+
+		/** If register values are not set correctly, reset old values */
+		if (retval == 0) {
+			DWC_WRITE_REG32(&global_regs->grxfsiz, rx_fsz_bak);
+
+			/* Non-periodic Tx FIFO */
+			DWC_WRITE_REG32(&global_regs->gnptxfsiz, nptxfsz_bak);
+
+			for (i = 0; i < core_if->hwcfg4.b.num_in_eps; i++) {
+				DWC_WRITE_REG32(&global_regs->dtxfsiz[i],
+						txfsz_bak[i]);
+			}
+		}
+	} else {
+		return 0;
+	}
+
+	/* Flush the FIFOs */
+	dwc_otg_flush_tx_fifo(core_if, 0x10);	/* all Tx FIFOs */
+	dwc_otg_flush_rx_fifo(core_if);
+
+	return retval;
+}
+
+/**
+ * This function sets a new value for the buffer Alignment setup.
+ */
+static int cfi_ep_set_tx_fifo_val(uint8_t * buf, dwc_otg_pcd_t * pcd)
+{
+	int retval;
+	uint32_t fsiz;
+	uint16_t size;
+	uint16_t ep_addr;
+	dwc_otg_pcd_ep_t *ep;
+	dwc_otg_core_params_t *params = GET_CORE_IF(pcd)->core_params;
+	tx_fifo_size_setup_t *ptxfifoval;
+
+	ptxfifoval = (tx_fifo_size_setup_t *) buf;
+	ep_addr = ptxfifoval->bEndpointAddress;
+	size = ptxfifoval->wDepth;
+
+	ep = get_ep_by_addr(pcd, ep_addr);
+
+	CFI_INFO
+	    ("%s: Set Tx FIFO size: endpoint addr=0x%02x, depth=%d, FIFO Num=%d\n",
+	     __func__, ep_addr, size, ep->dwc_ep.tx_fifo_num);
+
+	if (NULL == ep) {
+		CFI_INFO("%s: Unable to get the endpoint addr=0x%02x\n",
+			 __func__, ep_addr);
+		return -DWC_E_INVALID;
+	}
+
+	fsiz = params->dev_tx_fifo_size[ep->dwc_ep.tx_fifo_num - 1];
+	params->dev_tx_fifo_size[ep->dwc_ep.tx_fifo_num - 1] = size;
+
+	if (resize_fifos(GET_CORE_IF(pcd))) {
+		retval = 0;
+	} else {
+		CFI_INFO
+		    ("%s: Error setting the feature Tx FIFO Size for EP%d\n",
+		     __func__, ep_addr);
+		params->dev_tx_fifo_size[ep->dwc_ep.tx_fifo_num - 1] = fsiz;
+		retval = -DWC_E_INVALID;
+	}
+
+	return retval;
+}
+
+/**
+ * This function sets a new value for the buffer Alignment setup.
+ */
+static int cfi_set_rx_fifo_val(uint8_t * buf, dwc_otg_pcd_t * pcd)
+{
+	int retval;
+	uint32_t fsiz;
+	uint16_t size;
+	dwc_otg_core_params_t *params = GET_CORE_IF(pcd)->core_params;
+	rx_fifo_size_setup_t *prxfifoval;
+
+	prxfifoval = (rx_fifo_size_setup_t *) buf;
+	size = prxfifoval->wDepth;
+
+	fsiz = params->dev_rx_fifo_size;
+	params->dev_rx_fifo_size = size;
+
+	if (resize_fifos(GET_CORE_IF(pcd))) {
+		retval = 0;
+	} else {
+		CFI_INFO("%s: Error setting the feature Rx FIFO Size\n",
+			 __func__);
+		params->dev_rx_fifo_size = fsiz;
+		retval = -DWC_E_INVALID;
+	}
+
+	return retval;
+}
+
+/**
+ * This function reads the SG of an EP's buffer setup into the buffer buf
+ */
+static int cfi_ep_get_sg_val(uint8_t * buf, struct dwc_otg_pcd *pcd,
+			     struct cfi_usb_ctrlrequest *req)
+{
+	int retval = -DWC_E_INVALID;
+	uint8_t addr;
+	cfi_ep_t *ep;
+
+	/* The Low Byte of the wValue contains a non-zero address of the endpoint */
+	addr = req->wValue & 0xFF;
+	if (addr == 0)		/* The address should be non-zero */
+		return retval;
+
+	ep = get_cfi_ep_by_addr(pcd->cfi, addr);
+	if (NULL == ep) {
+		CFI_INFO("%s: Unable to get the endpoint address(0x%02x)\n",
+			 __func__, addr);
+		return retval;
+	}
+
+	dwc_memcpy(buf, ep->bm_sg, BS_SG_VAL_DESC_LEN);
+	retval = BS_SG_VAL_DESC_LEN;
+	return retval;
+}
+
+/**
+ * This function reads the Concatenation value of an EP's buffer mode into
+ * the buffer buf
+ */
+static int cfi_ep_get_concat_val(uint8_t * buf, struct dwc_otg_pcd *pcd,
+				 struct cfi_usb_ctrlrequest *req)
+{
+	int retval = -DWC_E_INVALID;
+	uint8_t addr;
+	cfi_ep_t *ep;
+	uint8_t desc_count;
+
+	/* The Low Byte of the wValue contains a non-zero address of the endpoint */
+	addr = req->wValue & 0xFF;
+	if (addr == 0)		/* The address should be non-zero */
+		return retval;
+
+	ep = get_cfi_ep_by_addr(pcd->cfi, addr);
+	if (NULL == ep) {
+		CFI_INFO("%s: Unable to get the endpoint address(0x%02x)\n",
+			 __func__, addr);
+		return retval;
+	}
+
+	/* Copy the header to the buffer */
+	dwc_memcpy(buf, ep->bm_concat, BS_CONCAT_VAL_HDR_LEN);
+	/* Advance the buffer pointer by the header size */
+	buf += BS_CONCAT_VAL_HDR_LEN;
+
+	desc_count = ep->bm_concat->hdr.bDescCount;
+	/* Copy alll the wTxBytes to the buffer */
+	dwc_memcpy(buf, ep->bm_concat->wTxBytes, sizeof(uid16_t) * desc_count);
+
+	retval = BS_CONCAT_VAL_HDR_LEN + sizeof(uid16_t) * desc_count;
+	return retval;
+}
+
+/**
+ * This function reads the buffer Alignment value of an EP's buffer mode into
+ * the buffer buf
+ *
+ * @return The total number of bytes copied to the buffer or negative error code.
+ */
+static int cfi_ep_get_align_val(uint8_t * buf, struct dwc_otg_pcd *pcd,
+				struct cfi_usb_ctrlrequest *req)
+{
+	int retval = -DWC_E_INVALID;
+	uint8_t addr;
+	cfi_ep_t *ep;
+
+	/* The Low Byte of the wValue contains a non-zero address of the endpoint */
+	addr = req->wValue & 0xFF;
+	if (addr == 0)		/* The address should be non-zero */
+		return retval;
+
+	ep = get_cfi_ep_by_addr(pcd->cfi, addr);
+	if (NULL == ep) {
+		CFI_INFO("%s: Unable to get the endpoint address(0x%02x)\n",
+			 __func__, addr);
+		return retval;
+	}
+
+	dwc_memcpy(buf, ep->bm_align, BS_ALIGN_VAL_HDR_LEN);
+	retval = BS_ALIGN_VAL_HDR_LEN;
+
+	return retval;
+}
+
+/**
+ * This function sets a new value for the specified feature
+ *
+ * @param	pcd	A pointer to the PCD object
+ *
+ * @return 0 if successful, negative error code otherwise to stall the DCE.
+ */
+static int cfi_set_feature_value(struct dwc_otg_pcd *pcd)
+{
+	int retval = -DWC_E_NOT_SUPPORTED;
+	uint16_t wIndex, wValue;
+	uint8_t bRequest;
+	struct dwc_otg_core_if *coreif;
+	cfiobject_t *cfi = pcd->cfi;
+	struct cfi_usb_ctrlrequest *ctrl_req;
+	uint8_t *buf;
+	ctrl_req = &cfi->ctrl_req;
+
+	buf = pcd->cfi->ctrl_req.data;
+
+	coreif = GET_CORE_IF(pcd);
+	bRequest = ctrl_req->bRequest;
+	wIndex = DWC_CONSTANT_CPU_TO_LE16(ctrl_req->wIndex);
+	wValue = DWC_CONSTANT_CPU_TO_LE16(ctrl_req->wValue);
+
+	/* See which feature is to be modified */
+	switch (wIndex) {
+	case FT_ID_DMA_BUFFER_SETUP:
+		/* Modify the feature */
+		if ((retval = cfi_ep_set_sg_val(buf, pcd)) < 0)
+			return retval;
+
+		/* And send this request to the gadget */
+		cfi->need_gadget_att = 1;
+		break;
+
+	case FT_ID_DMA_BUFF_ALIGN:
+		if ((retval = cfi_ep_set_alignment_val(buf, pcd)) < 0)
+			return retval;
+		cfi->need_gadget_att = 1;
+		break;
+
+	case FT_ID_DMA_CONCAT_SETUP:
+		/* Modify the feature */
+		if ((retval = cfi_ep_set_concat_val(buf, pcd)) < 0)
+			return retval;
+		cfi->need_gadget_att = 1;
+		break;
+
+	case FT_ID_DMA_CIRCULAR:
+		CFI_INFO("FT_ID_DMA_CIRCULAR\n");
+		break;
+
+	case FT_ID_THRESHOLD_SETUP:
+		CFI_INFO("FT_ID_THRESHOLD_SETUP\n");
+		break;
+
+	case FT_ID_DFIFO_DEPTH:
+		CFI_INFO("FT_ID_DFIFO_DEPTH\n");
+		break;
+
+	case FT_ID_TX_FIFO_DEPTH:
+		CFI_INFO("FT_ID_TX_FIFO_DEPTH\n");
+		if ((retval = cfi_ep_set_tx_fifo_val(buf, pcd)) < 0)
+			return retval;
+		cfi->need_gadget_att = 0;
+		break;
+
+	case FT_ID_RX_FIFO_DEPTH:
+		CFI_INFO("FT_ID_RX_FIFO_DEPTH\n");
+		if ((retval = cfi_set_rx_fifo_val(buf, pcd)) < 0)
+			return retval;
+		cfi->need_gadget_att = 0;
+		break;
+	}
+
+	return retval;
+}
+
+#endif //DWC_UTE_CFI
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_cfi.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_cfi.h
new file mode 100644
index 0000000..55fd337
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_cfi.h
@@ -0,0 +1,320 @@
+/* ==========================================================================
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#if !defined(__DWC_OTG_CFI_H__)
+#define __DWC_OTG_CFI_H__
+
+#include "dwc_otg_pcd.h"
+#include "dwc_cfi_common.h"
+
+/**
+ * @file
+ * This file contains the CFI related OTG PCD specific common constants,
+ * interfaces(functions and macros) and data structures.The CFI Protocol is an
+ * optional interface for internal testing purposes that a DUT may implement to
+ * support testing of configurable features.
+ *
+ */
+
+struct dwc_otg_pcd;
+struct dwc_otg_pcd_ep;
+
+/** OTG CFI Features (properties) ID constants */
+/** This is a request for all Core Features */
+#define FT_ID_DMA_MODE					0x0001
+#define FT_ID_DMA_BUFFER_SETUP			0x0002
+#define FT_ID_DMA_BUFF_ALIGN			0x0003
+#define FT_ID_DMA_CONCAT_SETUP			0x0004
+#define FT_ID_DMA_CIRCULAR				0x0005
+#define FT_ID_THRESHOLD_SETUP			0x0006
+#define FT_ID_DFIFO_DEPTH				0x0007
+#define FT_ID_TX_FIFO_DEPTH				0x0008
+#define FT_ID_RX_FIFO_DEPTH				0x0009
+
+/**********************************************************/
+#define CFI_INFO_DEF
+
+#ifdef CFI_INFO_DEF
+#define CFI_INFO(fmt...)	DWC_PRINTF("CFI: " fmt);
+#else
+#define CFI_INFO(fmt...)
+#endif
+
+#define min(x,y) ({ \
+	x < y ? x : y; })
+
+#define max(x,y) ({ \
+	x > y ? x : y; })
+
+/**
+ * Descriptor DMA SG Buffer setup structure (SG buffer). This structure is
+ * also used for setting up a buffer for Circular DDMA.
+ */
+struct _ddma_sg_buffer_setup {
+#define BS_SG_VAL_DESC_LEN	6
+	/* The OUT EP address */
+	uint8_t bOutEndpointAddress;
+	/* The IN EP address */
+	uint8_t bInEndpointAddress;
+	/* Number of bytes to put between transfer segments (must be DWORD boundaries) */
+	uint8_t bOffset;
+	/* The number of transfer segments (a DMA descriptors per each segment) */
+	uint8_t bCount;
+	/* Size (in byte) of each transfer segment */
+	uint16_t wSize;
+} __attribute__ ((packed));
+typedef struct _ddma_sg_buffer_setup ddma_sg_buffer_setup_t;
+
+/** Descriptor DMA Concatenation Buffer setup structure */
+struct _ddma_concat_buffer_setup_hdr {
+#define BS_CONCAT_VAL_HDR_LEN	4
+	/* The endpoint for which the buffer is to be set up */
+	uint8_t bEndpointAddress;
+	/* The count of descriptors to be used */
+	uint8_t bDescCount;
+	/* The total size of the transfer */
+	uint16_t wSize;
+} __attribute__ ((packed));
+typedef struct _ddma_concat_buffer_setup_hdr ddma_concat_buffer_setup_hdr_t;
+
+/** Descriptor DMA Concatenation Buffer setup structure */
+struct _ddma_concat_buffer_setup {
+	/* The SG header */
+	ddma_concat_buffer_setup_hdr_t hdr;
+
+	/* The XFER sizes pointer (allocated dynamically) */
+	uint16_t *wTxBytes;
+} __attribute__ ((packed));
+typedef struct _ddma_concat_buffer_setup ddma_concat_buffer_setup_t;
+
+/** Descriptor DMA Alignment Buffer setup structure */
+struct _ddma_align_buffer_setup {
+#define BS_ALIGN_VAL_HDR_LEN	2
+	uint8_t bEndpointAddress;
+	uint8_t bAlign;
+} __attribute__ ((packed));
+typedef struct _ddma_align_buffer_setup ddma_align_buffer_setup_t;
+
+/** Transmit FIFO Size setup structure */
+struct _tx_fifo_size_setup {
+	uint8_t bEndpointAddress;
+	uint16_t wDepth;
+} __attribute__ ((packed));
+typedef struct _tx_fifo_size_setup tx_fifo_size_setup_t;
+
+/** Transmit FIFO Size setup structure */
+struct _rx_fifo_size_setup {
+	uint16_t wDepth;
+} __attribute__ ((packed));
+typedef struct _rx_fifo_size_setup rx_fifo_size_setup_t;
+
+/**
+ * struct cfi_usb_ctrlrequest - the CFI implementation of the struct usb_ctrlrequest
+ * This structure encapsulates the standard usb_ctrlrequest and adds a pointer
+ * to the data returned in the data stage of a 3-stage Control Write requests.
+ */
+struct cfi_usb_ctrlrequest {
+	uint8_t bRequestType;
+	uint8_t bRequest;
+	uint16_t wValue;
+	uint16_t wIndex;
+	uint16_t wLength;
+	uint8_t *data;
+} UPACKED;
+
+/*---------------------------------------------------------------------------*/
+
+/**
+ * The CFI wrapper of the enabled and activated dwc_otg_pcd_ep structures.
+ * This structure is used to store the buffer setup data for any
+ * enabled endpoint in the PCD.
+ */
+struct cfi_ep {
+	/* Entry for the list container */
+	dwc_list_link_t lh;
+	/* Pointer to the active PCD endpoint structure */
+	struct dwc_otg_pcd_ep *ep;
+	/* The last descriptor in the chain of DMA descriptors of the endpoint */
+	struct dwc_otg_dma_desc *dma_desc_last;
+	/* The SG feature value */
+	ddma_sg_buffer_setup_t *bm_sg;
+	/* The Circular feature value */
+	ddma_sg_buffer_setup_t *bm_circ;
+	/* The Concatenation feature value */
+	ddma_concat_buffer_setup_t *bm_concat;
+	/* The Alignment feature value */
+	ddma_align_buffer_setup_t *bm_align;
+	/* XFER length */
+	uint32_t xfer_len;
+	/*
+	 * Count of DMA descriptors currently used.
+	 * The total should not exceed the MAX_DMA_DESCS_PER_EP value
+	 * defined in the dwc_otg_cil.h
+	 */
+	uint32_t desc_count;
+};
+typedef struct cfi_ep cfi_ep_t;
+
+typedef struct cfi_dma_buff {
+#define CFI_IN_BUF_LEN	1024
+#define CFI_OUT_BUF_LEN	1024
+	dma_addr_t addr;
+	uint8_t *buf;
+} cfi_dma_buff_t;
+
+struct cfiobject;
+
+/**
+ * This is the interface for the CFI operations.
+ *
+ * @param	ep_enable			Called when any endpoint is enabled and activated.
+ * @param	release				Called when the CFI object is released and it needs to correctly
+ *								deallocate the dynamic memory
+ * @param	ctrl_write_complete	Called when the data stage of the request is complete
+ */
+typedef struct cfi_ops {
+	int (*ep_enable) (struct cfiobject * cfi, struct dwc_otg_pcd * pcd,
+			  struct dwc_otg_pcd_ep * ep);
+	void *(*ep_alloc_buf) (struct cfiobject * cfi, struct dwc_otg_pcd * pcd,
+			       struct dwc_otg_pcd_ep * ep, dma_addr_t * dma,
+			       unsigned size, gfp_t flags);
+	void (*release) (struct cfiobject * cfi);
+	int (*ctrl_write_complete) (struct cfiobject * cfi,
+				    struct dwc_otg_pcd * pcd);
+	void (*build_descriptors) (struct cfiobject * cfi,
+				   struct dwc_otg_pcd * pcd,
+				   struct dwc_otg_pcd_ep * ep,
+				   dwc_otg_pcd_request_t * req);
+} cfi_ops_t;
+
+struct cfiobject {
+	cfi_ops_t ops;
+	struct dwc_otg_pcd *pcd;
+	struct usb_gadget *gadget;
+
+	/* Buffers used to send/receive CFI-related request data */
+	cfi_dma_buff_t buf_in;
+	cfi_dma_buff_t buf_out;
+
+	/* CFI specific Control request wrapper */
+	struct cfi_usb_ctrlrequest ctrl_req;
+
+	/* The list of active EP's in the PCD of type cfi_ep_t */
+	dwc_list_link_t active_eps;
+
+	/* This flag shall control the propagation of a specific request
+	 * to the gadget's processing routines.
+	 * 0 - no gadget handling
+	 * 1 - the gadget needs to know about this request (w/o completing a status
+	 * phase - just return a 0 to the _setup callback)
+	 */
+	uint8_t need_gadget_att;
+
+	/* Flag indicating whether the status IN phase needs to be
+	 * completed by the PCD
+	 */
+	uint8_t need_status_in_complete;
+};
+typedef struct cfiobject cfiobject_t;
+
+#define DUMP_MSG
+
+#if defined(DUMP_MSG)
+static inline void dump_msg(const u8 * buf, unsigned int length)
+{
+	unsigned int start, num, i;
+	char line[52], *p;
+
+	if (length >= 512)
+		return;
+
+	start = 0;
+	while (length > 0) {
+		num = min(length, 16u);
+		p = line;
+		for (i = 0; i < num; ++i) {
+			if (i == 8)
+				*p++ = ' ';
+			DWC_SPRINTF(p, " %02x", buf[i]);
+			p += 3;
+		}
+		*p = 0;
+		DWC_DEBUG("%6x: %s\n", start, line);
+		buf += num;
+		start += num;
+		length -= num;
+	}
+}
+#else
+static inline void dump_msg(const u8 * buf, unsigned int length)
+{
+}
+#endif
+
+/**
+ * This function returns a pointer to cfi_ep_t object with the addr address.
+ */
+static inline struct cfi_ep *get_cfi_ep_by_addr(struct cfiobject *cfi,
+						uint8_t addr)
+{
+	struct cfi_ep *pcfiep;
+	dwc_list_link_t *tmp;
+
+	DWC_LIST_FOREACH(tmp, &cfi->active_eps) {
+		pcfiep = DWC_LIST_ENTRY(tmp, struct cfi_ep, lh);
+
+		if (pcfiep->ep->desc->bEndpointAddress == addr) {
+			return pcfiep;
+		}
+	}
+
+	return NULL;
+}
+
+/**
+ * This function returns a pointer to cfi_ep_t object that matches
+ * the dwc_otg_pcd_ep object.
+ */
+static inline struct cfi_ep *get_cfi_ep_by_pcd_ep(struct cfiobject *cfi,
+						  struct dwc_otg_pcd_ep *ep)
+{
+	struct cfi_ep *pcfiep = NULL;
+	dwc_list_link_t *tmp;
+
+	DWC_LIST_FOREACH(tmp, &cfi->active_eps) {
+		pcfiep = DWC_LIST_ENTRY(tmp, struct cfi_ep, lh);
+		if (pcfiep->ep == ep) {
+			return pcfiep;
+		}
+	}
+	return NULL;
+}
+
+int cfi_setup(struct dwc_otg_pcd *pcd, struct cfi_usb_ctrlrequest *ctrl);
+
+#endif /* (__DWC_OTG_CFI_H__) */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_cil.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_cil.c
new file mode 100644
index 0000000..6403349
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_cil.c
@@ -0,0 +1,7302 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_cil.c $
+ * $Revision: #203 $
+ * $Date: 2013/05/16 $
+ * $Change: 2231774 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+/** @file
+ *
+ * The Core Interface Layer provides basic services for accessing and
+ * managing the DWC_otg hardware. These services are used by both the
+ * Host Controller Driver and the Peripheral Controller Driver.
+ *
+ * The CIL manages the memory map for the core so that the HCD and PCD
+ * don't have to do this separately. It also handles basic tasks like
+ * reading/writing the registers and data FIFOs in the controller.
+ * Some of the data access functions provide encapsulation of several
+ * operations required to perform a task, such as writing multiple
+ * registers to start a transfer. Finally, the CIL performs basic
+ * services that are not specific to either the host or device modes
+ * of operation. These services include management of the OTG Host
+ * Negotiation Protocol (HNP) and Session Request Protocol (SRP). A
+ * Diagnostic API is also provided to allow testing of the controller
+ * hardware.
+ *
+ * The Core Interface Layer has the following requirements:
+ * - Provides basic controller operations.
+ * - Minimal use of OS services.
+ * - The OS services used will be abstracted by using inline functions
+ *	 or macros.
+ *
+ */
+
+#include "dwc_os.h"
+#include "dwc_otg_regs.h"
+#include "dwc_otg_cil.h"
+
+static int dwc_otg_setup_params(dwc_otg_core_if_t * core_if);
+
+/**
+ * This function is called to initialize the DWC_otg CSR data
+ * structures. The register addresses in the device and host
+ * structures are initialized from the base address supplied by the
+ * caller. The calling function must make the OS calls to get the
+ * base address of the DWC_otg controller registers. The core_params
+ * argument holds the parameters that specify how the core should be
+ * configured.
+ *
+ * @param reg_base_addr Base address of DWC_otg core registers
+ *
+ */
+dwc_otg_core_if_t *dwc_otg_cil_init(const uint32_t * reg_base_addr)
+{
+	dwc_otg_core_if_t *core_if = 0;
+	dwc_otg_dev_if_t *dev_if = 0;
+	dwc_otg_host_if_t *host_if = 0;
+	uint8_t *reg_base = (uint8_t *) reg_base_addr;
+	int i = 0;
+
+	DWC_DEBUGPL(DBG_CILV, "%s(%p)\n", __func__, reg_base_addr);
+
+	core_if = DWC_ALLOC(sizeof(dwc_otg_core_if_t));
+
+	if (core_if == NULL) {
+		DWC_DEBUGPL(DBG_CIL,
+			    "Allocation of dwc_otg_core_if_t failed\n");
+		return 0;
+	}
+	core_if->core_global_regs = (dwc_otg_core_global_regs_t *) reg_base;
+
+	/*
+	 * Allocate the Device Mode structures.
+	 */
+	dev_if = DWC_ALLOC(sizeof(dwc_otg_dev_if_t));
+
+	if (dev_if == NULL) {
+		DWC_DEBUGPL(DBG_CIL, "Allocation of dwc_otg_dev_if_t failed\n");
+		DWC_FREE(core_if);
+		return 0;
+	}
+
+	dev_if->dev_global_regs =
+	    (dwc_otg_device_global_regs_t *) (reg_base +
+					      DWC_DEV_GLOBAL_REG_OFFSET);
+
+	for (i = 0; i < MAX_EPS_CHANNELS; i++) {
+		dev_if->in_ep_regs[i] = (dwc_otg_dev_in_ep_regs_t *)
+		    (reg_base + DWC_DEV_IN_EP_REG_OFFSET +
+		     (i * DWC_EP_REG_OFFSET));
+
+		dev_if->out_ep_regs[i] = (dwc_otg_dev_out_ep_regs_t *)
+		    (reg_base + DWC_DEV_OUT_EP_REG_OFFSET +
+		     (i * DWC_EP_REG_OFFSET));
+		DWC_DEBUGPL(DBG_CILV, "in_ep_regs[%d]->diepctl=%p\n",
+			    i, &dev_if->in_ep_regs[i]->diepctl);
+		DWC_DEBUGPL(DBG_CILV, "out_ep_regs[%d]->doepctl=%p\n",
+			    i, &dev_if->out_ep_regs[i]->doepctl);
+	}
+
+	dev_if->speed = 0;	// unknown
+
+	core_if->dev_if = dev_if;
+
+	/*
+	 * Allocate the Host Mode structures.
+	 */
+	host_if = DWC_ALLOC(sizeof(dwc_otg_host_if_t));
+
+	if (host_if == NULL) {
+		DWC_DEBUGPL(DBG_CIL,
+			    "Allocation of dwc_otg_host_if_t failed\n");
+		DWC_FREE(dev_if);
+		DWC_FREE(core_if);
+		return 0;
+	}
+
+	host_if->host_global_regs = (dwc_otg_host_global_regs_t *)
+	    (reg_base + DWC_OTG_HOST_GLOBAL_REG_OFFSET);
+
+	host_if->hprt0 =
+	    (uint32_t *) (reg_base + DWC_OTG_HOST_PORT_REGS_OFFSET);
+
+	for (i = 0; i < MAX_EPS_CHANNELS; i++) {
+		host_if->hc_regs[i] = (dwc_otg_hc_regs_t *)
+		    (reg_base + DWC_OTG_HOST_CHAN_REGS_OFFSET +
+		     (i * DWC_OTG_CHAN_REGS_OFFSET));
+		DWC_DEBUGPL(DBG_CILV, "hc_reg[%d]->hcchar=%p\n",
+			    i, &host_if->hc_regs[i]->hcchar);
+	}
+
+	host_if->num_host_channels = MAX_EPS_CHANNELS;
+	core_if->host_if = host_if;
+
+	for (i = 0; i < MAX_EPS_CHANNELS; i++) {
+		core_if->data_fifo[i] =
+		    (uint32_t *) (reg_base + DWC_OTG_DATA_FIFO_OFFSET +
+				  (i * DWC_OTG_DATA_FIFO_SIZE));
+		DWC_DEBUGPL(DBG_CILV, "data_fifo[%d]=0x%08lx\n",
+			    i, (unsigned long)core_if->data_fifo[i]);
+	}
+
+	core_if->pcgcctl = (uint32_t *) (reg_base + DWC_OTG_PCGCCTL_OFFSET);
+
+	/* Initiate lx_state to L3 disconnected state */
+	core_if->lx_state = DWC_OTG_L3;
+	/*
+	 * Store the contents of the hardware configuration registers here for
+	 * easy access later.
+	 */
+	core_if->hwcfg1.d32 =
+	    DWC_READ_REG32(&core_if->core_global_regs->ghwcfg1);
+	core_if->hwcfg2.d32 =
+	    DWC_READ_REG32(&core_if->core_global_regs->ghwcfg2);
+	core_if->hwcfg3.d32 =
+	    DWC_READ_REG32(&core_if->core_global_regs->ghwcfg3);
+	core_if->hwcfg4.d32 =
+	    DWC_READ_REG32(&core_if->core_global_regs->ghwcfg4);
+
+	/* Force host mode to get HPTXFSIZ exact power on value */
+	{
+		gusbcfg_data_t gusbcfg = {.d32 = 0 };
+		gusbcfg.d32 =  DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+		gusbcfg.b.force_host_mode = 1;
+		DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg, gusbcfg.d32);
+		dwc_mdelay(10);
+		core_if->hptxfsiz.d32 =
+		    DWC_READ_REG32(&core_if->core_global_regs->hptxfsiz);
+		gusbcfg.d32 =  DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+		gusbcfg.b.force_host_mode = 0;
+		DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg, gusbcfg.d32);
+		dwc_mdelay(10);
+
+		gusbcfg.d32 =  DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+		gusbcfg.b.force_dev_mode = 1;
+		DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg, gusbcfg.d32);
+		dwc_mdelay(10);
+	}
+
+	DWC_DEBUGPL(DBG_CILV, "hwcfg1=%08x\n", core_if->hwcfg1.d32);
+	DWC_DEBUGPL(DBG_CILV, "hwcfg2=%08x\n", core_if->hwcfg2.d32);
+	DWC_DEBUGPL(DBG_CILV, "hwcfg3=%08x\n", core_if->hwcfg3.d32);
+	DWC_DEBUGPL(DBG_CILV, "hwcfg4=%08x\n", core_if->hwcfg4.d32);
+
+	core_if->hcfg.d32 =
+	    DWC_READ_REG32(&core_if->host_if->host_global_regs->hcfg);
+	core_if->dcfg.d32 =
+	    DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dcfg);
+
+	DWC_DEBUGPL(DBG_CILV, "hcfg=%08x\n", core_if->hcfg.d32);
+	DWC_DEBUGPL(DBG_CILV, "dcfg=%08x\n", core_if->dcfg.d32);
+
+	DWC_DEBUGPL(DBG_CILV, "op_mode=%0x\n", core_if->hwcfg2.b.op_mode);
+	DWC_DEBUGPL(DBG_CILV, "arch=%0x\n", core_if->hwcfg2.b.architecture);
+	DWC_DEBUGPL(DBG_CILV, "num_dev_ep=%d\n", core_if->hwcfg2.b.num_dev_ep);
+	DWC_DEBUGPL(DBG_CILV, "num_host_chan=%d\n",
+		    core_if->hwcfg2.b.num_host_chan);
+	DWC_DEBUGPL(DBG_CILV, "nonperio_tx_q_depth=0x%0x\n",
+		    core_if->hwcfg2.b.nonperio_tx_q_depth);
+	DWC_DEBUGPL(DBG_CILV, "host_perio_tx_q_depth=0x%0x\n",
+		    core_if->hwcfg2.b.host_perio_tx_q_depth);
+	DWC_DEBUGPL(DBG_CILV, "dev_token_q_depth=0x%0x\n",
+		    core_if->hwcfg2.b.dev_token_q_depth);
+
+	DWC_DEBUGPL(DBG_CILV, "Total FIFO SZ=%d\n",
+		    core_if->hwcfg3.b.dfifo_depth);
+	DWC_DEBUGPL(DBG_CILV, "xfer_size_cntr_width=%0x\n",
+		    core_if->hwcfg3.b.xfer_size_cntr_width);
+
+	/*
+	 * Set the SRP sucess bit for FS-I2c
+	 */
+	core_if->srp_success = 0;
+	core_if->srp_timer_started = 0;
+
+	/*
+	 * Create new workqueue and init works
+	 */
+	core_if->wq_otg = DWC_WORKQ_ALLOC("dwc_otg");
+	if (core_if->wq_otg == 0) {
+		DWC_WARN("DWC_WORKQ_ALLOC failed\n");
+		DWC_FREE(host_if);
+		DWC_FREE(dev_if);
+		DWC_FREE(core_if);
+		return 0;
+	}
+
+	core_if->snpsid = DWC_READ_REG32(&core_if->core_global_regs->gsnpsid);
+
+	DWC_PRINTF("Core Release: %x.%x%x%x\n",
+		   (core_if->snpsid >> 12 & 0xF),
+		   (core_if->snpsid >> 8 & 0xF),
+		   (core_if->snpsid >> 4 & 0xF), (core_if->snpsid & 0xF));
+
+	if (dwc_otg_setup_params(core_if)) {
+		DWC_WARN("Error while setting core params\n");
+	}
+
+	core_if->hibernation_suspend = 0;
+	if (core_if->otg_ver)
+		core_if->test_mode = 0;
+
+	/** ADP initialization */
+	dwc_otg_adp_init(core_if);
+
+	return core_if;
+}
+
+/**
+ * This function frees the structures allocated by dwc_otg_cil_init().
+ *
+ * @param core_if The core interface pointer returned from
+ *		  dwc_otg_cil_init().
+ *
+ */
+void dwc_otg_cil_remove(dwc_otg_core_if_t * core_if)
+{
+	dctl_data_t dctl = {.d32 = 0 };
+	/* Disable all interrupts */
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gahbcfg, 1, 0);
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintmsk, 0);
+
+	dctl.b.sftdiscon = 1;
+	if (core_if->snpsid >= OTG_CORE_REV_3_00a) {
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl, 0,
+				 dctl.d32);
+	}
+
+	if (core_if->wq_otg) {
+		DWC_WORKQ_WAIT_WORK_DONE(core_if->wq_otg, 500);
+		DWC_WORKQ_FREE(core_if->wq_otg);
+	}
+	if (core_if->dev_if) {
+		DWC_FREE(core_if->dev_if);
+	}
+	if (core_if->host_if) {
+		DWC_FREE(core_if->host_if);
+	}
+
+	/** Remove ADP Stuff  */
+	dwc_otg_adp_remove(core_if);
+	if (core_if->core_params) {
+		DWC_FREE(core_if->core_params);
+	}
+	if (core_if->wkp_timer) {
+		DWC_TIMER_FREE(core_if->wkp_timer);
+	}
+	if (core_if->srp_timer) {
+		DWC_TIMER_FREE(core_if->srp_timer);
+	}
+	DWC_FREE(core_if);
+}
+
+/**
+ * This function enables the controller's Global Interrupt in the AHB Config
+ * register.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+void dwc_otg_enable_global_interrupts(dwc_otg_core_if_t * core_if)
+{
+	gahbcfg_data_t ahbcfg = {.d32 = 0 };
+	ahbcfg.b.glblintrmsk = 1;	/* Enable interrupts */
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gahbcfg, 0, ahbcfg.d32);
+}
+
+/**
+ * This function disables the controller's Global Interrupt in the AHB Config
+ * register.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+void dwc_otg_disable_global_interrupts(dwc_otg_core_if_t * core_if)
+{
+	gahbcfg_data_t ahbcfg = {.d32 = 0 };
+	ahbcfg.b.glblintrmsk = 1;	/* Disable interrupts */
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gahbcfg, ahbcfg.d32, 0);
+}
+
+/**
+ * This function initializes the commmon interrupts, used in both
+ * device and host modes.
+ *
+ * @param core_if Programming view of the DWC_otg controller
+ *
+ */
+static void dwc_otg_enable_common_interrupts(dwc_otg_core_if_t * core_if)
+{
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+
+	/* Clear any pending OTG Interrupts */
+	DWC_WRITE_REG32(&global_regs->gotgint, 0xFFFFFFFF);
+
+	/* Clear any pending interrupts */
+	DWC_WRITE_REG32(&global_regs->gintsts, 0xFFFFFFFF);
+
+	/*
+	 * Enable the interrupts in the GINTMSK.
+	 */
+	if (!core_if->core_params->otg_ver)
+	/* To avoid system hang during OTG 2.0 role switch */
+		intr_mask.b.modemismatch = 1;
+	intr_mask.b.otgintr = 1;
+
+	if (!core_if->dma_enable) {
+		intr_mask.b.rxstsqlvl = 1;
+	}
+
+	intr_mask.b.conidstschng = 1;
+	intr_mask.b.wkupintr = 1;
+	intr_mask.b.disconnect = 0;
+	intr_mask.b.usbsuspend = 1;
+	intr_mask.b.sessreqintr = 1;
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	if (core_if->core_params->lpm_enable) {
+		intr_mask.b.lpmtranrcvd = 1;
+	}
+#endif
+	DWC_WRITE_REG32(&global_regs->gintmsk, intr_mask.d32);
+}
+
+/*
+ * The restore operation is modified to support Synopsys Emulated Powerdown and
+ * Hibernation. This function is for exiting from Device mode hibernation by
+ * Host Initiated Resume/Reset and Device Initiated Remote-Wakeup.
+ * @param core_if Programming view of DWC_otg controller.
+ * @param rem_wakeup - indicates whether resume is initiated by Device or Host.
+ * @param reset - indicates whether resume is initiated by Reset.
+ */
+int dwc_otg_device_hibernation_restore(dwc_otg_core_if_t * core_if,
+				       int rem_wakeup, int reset)
+{
+	gpwrdn_data_t gpwrdn = {.d32 = 0 };
+	pcgcctl_data_t pcgcctl = {.d32 = 0 };
+	dctl_data_t dctl = {.d32 = 0 };
+
+	int timeout = 2000;
+
+	if (!core_if->hibernation_suspend) {
+		DWC_PRINTF("Already exited from Hibernation\n");
+		return 1;
+	}
+
+	DWC_DEBUGPL(DBG_PCD, "%s called\n", __FUNCTION__);
+	/* Switch-on voltage to the core */
+	gpwrdn.b.pwrdnswtch = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	/* Reset core */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pwrdnrstn = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	/* Assert Restore signal */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.restore = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+	dwc_udelay(10);
+
+	/* Disable power clamps */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pwrdnclmp = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+	if (rem_wakeup) {
+		dwc_udelay(70);
+	}
+
+	/* Deassert Reset core */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pwrdnrstn = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+	dwc_udelay(10);
+
+	/* Disable PMU interrupt */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pmuintsel = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+	/* Mask interrupts from gpwrdn */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.connect_det_msk = 1;
+	gpwrdn.b.srp_det_msk = 1;
+	gpwrdn.b.disconn_det_msk = 1;
+	gpwrdn.b.rst_det_msk = 1;
+	gpwrdn.b.lnstchng_msk = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+	/* Indicates that we are going out from hibernation */
+	core_if->hibernation_suspend = 0;
+
+	/*
+	 * Set Restore Essential Regs bit in PCGCCTL register, restore_mode = 1
+	 * indicates restore from remote_wakeup
+	 */
+	restore_essential_regs(core_if, rem_wakeup, 0);
+
+	/*
+	 * Wait a little for seeing new value of variable hibernation_suspend if
+	 * Restore done interrupt received before polling
+	 */
+	dwc_udelay(10);
+
+	if (core_if->hibernation_suspend == 0) {
+		/*
+		 * Wait For Restore_done Interrupt. This mechanism of polling the
+		 * interrupt is introduced to avoid any possible race conditions
+		 */
+		do {
+			gintsts_data_t gintsts;
+			gintsts.d32 =
+			    DWC_READ_REG32(&core_if->core_global_regs->gintsts);
+			if (gintsts.b.restoredone) {
+				gintsts.d32 = 0;
+				gintsts.b.restoredone = 1;
+				DWC_WRITE_REG32(&core_if->core_global_regs->
+						gintsts, gintsts.d32);
+				DWC_PRINTF("Restore Done Interrupt seen\n");
+				break;
+			}
+			dwc_udelay(10);
+		} while (--timeout);
+		if (!timeout) {
+			DWC_PRINTF("Restore Done interrupt wasn't generated here\n");
+		}
+	}
+	/* Clear all pending interupts */
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, 0xFFFFFFFF);
+
+	/* De-assert Restore */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.restore = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	if (!rem_wakeup) {
+		pcgcctl.d32 = 0;
+		pcgcctl.b.rstpdwnmodule = 1;
+		DWC_MODIFY_REG32(core_if->pcgcctl, pcgcctl.d32, 0);
+	}
+
+	/* Restore GUSBCFG and DCFG */
+	DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg,
+			core_if->gr_backup->gusbcfg_local);
+	DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dcfg,
+			core_if->dr_backup->dcfg);
+
+	/* De-assert Wakeup Logic */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pmuactv = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	if (!rem_wakeup) {
+		/* Set Device programming done bit */
+		dctl.b.pwronprgdone = 1;
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl, 0, dctl.d32);
+	} else {
+		/* Start Remote Wakeup Signaling */
+		dctl.d32 = core_if->dr_backup->dctl;
+		dctl.b.rmtwkupsig = 1;
+		DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dctl, dctl.d32);
+	}
+
+	dwc_mdelay(2);
+	/* Clear all pending interupts */
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, 0xFFFFFFFF);
+
+	/* Restore global registers */
+	dwc_otg_restore_global_regs(core_if);
+	/* Restore device global registers */
+	dwc_otg_restore_dev_regs(core_if, rem_wakeup);
+
+	if (rem_wakeup) {
+		dwc_mdelay(7);
+		dctl.d32 = 0;
+		dctl.b.rmtwkupsig = 1;
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl, dctl.d32, 0);
+	}
+
+	core_if->hibernation_suspend = 0;
+	/* The core will be in ON STATE */
+	core_if->lx_state = DWC_OTG_L0;
+	DWC_PRINTF("Hibernation recovery completes here\n");
+
+	return 1;
+}
+
+/*
+ * The restore operation is modified to support Synopsys Emulated Powerdown and
+ * Hibernation. This function is for exiting from Host mode hibernation by
+ * Host Initiated Resume/Reset and Device Initiated Remote-Wakeup.
+ * @param core_if Programming view of DWC_otg controller.
+ * @param rem_wakeup - indicates whether resume is initiated by Device or Host.
+ * @param reset - indicates whether resume is initiated by Reset.
+ */
+int dwc_otg_host_hibernation_restore(dwc_otg_core_if_t * core_if,
+				     int rem_wakeup, int reset)
+{
+	gpwrdn_data_t gpwrdn = {.d32 = 0 };
+	hprt0_data_t hprt0 = {.d32 = 0 };
+
+	int timeout = 2000;
+
+	DWC_DEBUGPL(DBG_HCD, "%s called\n", __FUNCTION__);
+	/* Switch-on voltage to the core */
+	gpwrdn.b.pwrdnswtch = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	/* Reset core */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pwrdnrstn = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	/* Assert Restore signal */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.restore = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+	dwc_udelay(10);
+
+	/* Disable power clamps */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pwrdnclmp = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+	if (!rem_wakeup) {
+		dwc_udelay(50);
+	}
+
+	/* Deassert Reset core */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pwrdnrstn = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+	dwc_udelay(10);
+
+	/* Disable PMU interrupt */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pmuintsel = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+	gpwrdn.d32 = 0;
+	gpwrdn.b.connect_det_msk = 1;
+	gpwrdn.b.srp_det_msk = 1;
+	gpwrdn.b.disconn_det_msk = 1;
+	gpwrdn.b.rst_det_msk = 1;
+	gpwrdn.b.lnstchng_msk = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+	/* Indicates that we are going out from hibernation */
+	core_if->hibernation_suspend = 0;
+
+	/* Set Restore Essential Regs bit in PCGCCTL register */
+	restore_essential_regs(core_if, rem_wakeup, 1);
+
+	/* Wait a little for seeing new value of variable hibernation_suspend if
+	 * Restore done interrupt received before polling */
+	dwc_udelay(10);
+
+	if (core_if->hibernation_suspend == 0) {
+		/* Wait For Restore_done Interrupt. This mechanism of polling the
+		 * interrupt is introduced to avoid any possible race conditions
+		 */
+		do {
+			gintsts_data_t gintsts;
+			gintsts.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintsts);
+			if (gintsts.b.restoredone) {
+				gintsts.d32 = 0;
+				gintsts.b.restoredone = 1;
+			DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+				DWC_DEBUGPL(DBG_HCD,"Restore Done Interrupt seen\n");
+				break;
+			}
+			dwc_udelay(10);
+		} while (--timeout);
+		if (!timeout) {
+			DWC_WARN("Restore Done interrupt wasn't generated\n");
+		}
+	}
+
+	/* Set the flag's value to 0 again after receiving restore done interrupt */
+	core_if->hibernation_suspend = 0;
+
+	/* This step is not described in functional spec but if not wait for this
+	 * delay, mismatch interrupts occurred because just after restore core is
+	 * in Device mode(gintsts.curmode == 0) */
+	dwc_mdelay(100);
+
+	/* Clear all pending interrupts */
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, 0xFFFFFFFF);
+
+	/* De-assert Restore */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.restore = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	/* Restore GUSBCFG and HCFG */
+	DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg,
+			core_if->gr_backup->gusbcfg_local);
+	DWC_WRITE_REG32(&core_if->host_if->host_global_regs->hcfg,
+			core_if->hr_backup->hcfg_local);
+
+	/* De-assert Wakeup Logic */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pmuactv = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	/* Start the Resume operation by programming HPRT0 */
+	hprt0.d32 = core_if->hr_backup->hprt0_local;
+	hprt0.b.prtpwr = 1;
+	hprt0.b.prtena = 0;
+	hprt0.b.prtsusp = 0;
+	DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+
+	DWC_PRINTF("Resume Starts Now\n");
+	if (!reset) {		// Indicates it is Resume Operation
+		hprt0.d32 = core_if->hr_backup->hprt0_local;
+		hprt0.b.prtres = 1;
+		hprt0.b.prtpwr = 1;
+		hprt0.b.prtena = 0;
+		hprt0.b.prtsusp = 0;
+		DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+
+		if (!rem_wakeup)
+			hprt0.b.prtres = 0;
+		/* Wait for Resume time and then program HPRT again */
+		dwc_mdelay(100);
+		DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+
+	} else {		// Indicates it is Reset Operation
+		hprt0.d32 = core_if->hr_backup->hprt0_local;
+		hprt0.b.prtrst = 1;
+		hprt0.b.prtpwr = 1;
+		hprt0.b.prtena = 0;
+		hprt0.b.prtsusp = 0;
+		DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+		/* Wait for Reset time and then program HPRT again */
+		dwc_mdelay(60);
+		hprt0.b.prtrst = 0;
+		DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+	}
+	/* Clear all interrupt status */
+	hprt0.d32 = dwc_otg_read_hprt0(core_if);
+	hprt0.b.prtconndet = 1;
+	hprt0.b.prtenchng = 1;
+	DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+
+	/* Clear all pending interupts */
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, 0xFFFFFFFF);
+
+	/* Restore global registers */
+	dwc_otg_restore_global_regs(core_if);
+	/* Restore host global registers */
+	dwc_otg_restore_host_regs(core_if, reset);
+
+	/* The core will be in ON STATE */
+	core_if->lx_state = DWC_OTG_L0;
+	DWC_PRINTF("Hibernation recovery is complete here\n");
+	return 0;
+}
+
+/** Saves some register values into system memory. */
+int dwc_otg_save_global_regs(dwc_otg_core_if_t * core_if)
+{
+	struct dwc_otg_global_regs_backup *gr;
+	int i;
+
+	gr = core_if->gr_backup;
+	if (!gr) {
+		gr = DWC_ALLOC(sizeof(*gr));
+		if (!gr) {
+			return -DWC_E_NO_MEMORY;
+		}
+		core_if->gr_backup = gr;
+	}
+
+	gr->gotgctl_local = DWC_READ_REG32(&core_if->core_global_regs->gotgctl);
+	gr->gintmsk_local = DWC_READ_REG32(&core_if->core_global_regs->gintmsk);
+	gr->gahbcfg_local = DWC_READ_REG32(&core_if->core_global_regs->gahbcfg);
+	gr->gusbcfg_local = DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+	gr->grxfsiz_local = DWC_READ_REG32(&core_if->core_global_regs->grxfsiz);
+	gr->gnptxfsiz_local = DWC_READ_REG32(&core_if->core_global_regs->gnptxfsiz);
+	gr->hptxfsiz_local = DWC_READ_REG32(&core_if->core_global_regs->hptxfsiz);
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	gr->glpmcfg_local = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+#endif
+	gr->gi2cctl_local = DWC_READ_REG32(&core_if->core_global_regs->gi2cctl);
+	gr->pcgcctl_local = DWC_READ_REG32(core_if->pcgcctl);
+	gr->gdfifocfg_local =
+	    DWC_READ_REG32(&core_if->core_global_regs->gdfifocfg);
+	for (i = 0; i < MAX_EPS_CHANNELS; i++) {
+		gr->dtxfsiz_local[i] =
+		    DWC_READ_REG32(&(core_if->core_global_regs->dtxfsiz[i]));
+	}
+
+	DWC_DEBUGPL(DBG_ANY, "===========Backing Global registers==========\n");
+	DWC_DEBUGPL(DBG_ANY, "Backed up gotgctl   = %08x\n", gr->gotgctl_local);
+	DWC_DEBUGPL(DBG_ANY, "Backed up gintmsk   = %08x\n", gr->gintmsk_local);
+	DWC_DEBUGPL(DBG_ANY, "Backed up gahbcfg   = %08x\n", gr->gahbcfg_local);
+	DWC_DEBUGPL(DBG_ANY, "Backed up gusbcfg   = %08x\n", gr->gusbcfg_local);
+	DWC_DEBUGPL(DBG_ANY, "Backed up grxfsiz   = %08x\n", gr->grxfsiz_local);
+	DWC_DEBUGPL(DBG_ANY, "Backed up gnptxfsiz = %08x\n",
+		    gr->gnptxfsiz_local);
+	DWC_DEBUGPL(DBG_ANY, "Backed up hptxfsiz  = %08x\n",
+		    gr->hptxfsiz_local);
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	DWC_DEBUGPL(DBG_ANY, "Backed up glpmcfg   = %08x\n", gr->glpmcfg_local);
+#endif
+	DWC_DEBUGPL(DBG_ANY, "Backed up gi2cctl   = %08x\n", gr->gi2cctl_local);
+	DWC_DEBUGPL(DBG_ANY, "Backed up pcgcctl   = %08x\n", gr->pcgcctl_local);
+	DWC_DEBUGPL(DBG_ANY,"Backed up gdfifocfg   = %08x\n",gr->gdfifocfg_local);
+
+	return 0;
+}
+
+/** Saves GINTMSK register before setting the msk bits. */
+int dwc_otg_save_gintmsk_reg(dwc_otg_core_if_t * core_if)
+{
+	struct dwc_otg_global_regs_backup *gr;
+
+	gr = core_if->gr_backup;
+	if (!gr) {
+		gr = DWC_ALLOC(sizeof(*gr));
+		if (!gr) {
+			return -DWC_E_NO_MEMORY;
+		}
+		core_if->gr_backup = gr;
+	}
+
+	gr->gintmsk_local = DWC_READ_REG32(&core_if->core_global_regs->gintmsk);
+
+	DWC_DEBUGPL(DBG_ANY,"=============Backing GINTMSK registers============\n");
+	DWC_DEBUGPL(DBG_ANY, "Backed up gintmsk   = %08x\n", gr->gintmsk_local);
+
+	return 0;
+}
+
+int dwc_otg_save_dev_regs(dwc_otg_core_if_t * core_if)
+{
+	struct dwc_otg_dev_regs_backup *dr;
+	int i;
+
+	dr = core_if->dr_backup;
+	if (!dr) {
+		dr = DWC_ALLOC(sizeof(*dr));
+		if (!dr) {
+			return -DWC_E_NO_MEMORY;
+		}
+		core_if->dr_backup = dr;
+	}
+
+	dr->dcfg = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dcfg);
+	dr->dctl = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dctl);
+	dr->daintmsk =
+	    DWC_READ_REG32(&core_if->dev_if->dev_global_regs->daintmsk);
+	dr->diepmsk =
+	    DWC_READ_REG32(&core_if->dev_if->dev_global_regs->diepmsk);
+	dr->doepmsk =
+	    DWC_READ_REG32(&core_if->dev_if->dev_global_regs->doepmsk);
+
+	for (i = 0; i < core_if->dev_if->num_in_eps; ++i) {
+		dr->diepctl[i] =
+		    DWC_READ_REG32(&core_if->dev_if->in_ep_regs[i]->diepctl);
+		dr->dieptsiz[i] =
+		    DWC_READ_REG32(&core_if->dev_if->in_ep_regs[i]->dieptsiz);
+		dr->diepdma[i] =
+		    DWC_READ_REG32(&core_if->dev_if->in_ep_regs[i]->diepdma);
+	}
+
+	DWC_DEBUGPL(DBG_ANY,
+		    "=============Backing Host registers==============\n");
+	DWC_DEBUGPL(DBG_ANY, "Backed up dcfg            = %08x\n", dr->dcfg);
+	DWC_DEBUGPL(DBG_ANY, "Backed up dctl        = %08x\n", dr->dctl);
+	DWC_DEBUGPL(DBG_ANY, "Backed up daintmsk            = %08x\n",
+		    dr->daintmsk);
+	DWC_DEBUGPL(DBG_ANY, "Backed up diepmsk        = %08x\n", dr->diepmsk);
+	DWC_DEBUGPL(DBG_ANY, "Backed up doepmsk        = %08x\n", dr->doepmsk);
+	for (i = 0; i < core_if->dev_if->num_in_eps; ++i) {
+		DWC_DEBUGPL(DBG_ANY, "Backed up diepctl[%d]        = %08x\n", i,
+			    dr->diepctl[i]);
+		DWC_DEBUGPL(DBG_ANY, "Backed up dieptsiz[%d]        = %08x\n",
+			    i, dr->dieptsiz[i]);
+		DWC_DEBUGPL(DBG_ANY, "Backed up diepdma[%d]        = %08x\n", i,
+			    dr->diepdma[i]);
+	}
+
+	return 0;
+}
+
+int dwc_otg_save_host_regs(dwc_otg_core_if_t * core_if)
+{
+	struct dwc_otg_host_regs_backup *hr;
+	int i;
+
+	hr = core_if->hr_backup;
+	if (!hr) {
+		hr = DWC_ALLOC(sizeof(*hr));
+		if (!hr) {
+			return -DWC_E_NO_MEMORY;
+		}
+		core_if->hr_backup = hr;
+	}
+
+	hr->hcfg_local =
+	    DWC_READ_REG32(&core_if->host_if->host_global_regs->hcfg);
+	hr->haintmsk_local =
+	    DWC_READ_REG32(&core_if->host_if->host_global_regs->haintmsk);
+	for (i = 0; i < dwc_otg_get_param_host_channels(core_if); ++i) {
+		hr->hcintmsk_local[i] =
+		    DWC_READ_REG32(&core_if->host_if->hc_regs[i]->hcintmsk);
+	}
+	hr->hprt0_local = DWC_READ_REG32(core_if->host_if->hprt0);
+	hr->hfir_local =
+	    DWC_READ_REG32(&core_if->host_if->host_global_regs->hfir);
+
+	DWC_DEBUGPL(DBG_ANY,
+		    "=============Backing Host registers===============\n");
+	DWC_DEBUGPL(DBG_ANY, "Backed up hcfg		= %08x\n",
+		    hr->hcfg_local);
+	DWC_DEBUGPL(DBG_ANY, "Backed up haintmsk = %08x\n", hr->haintmsk_local);
+	for (i = 0; i < dwc_otg_get_param_host_channels(core_if); ++i) {
+		DWC_DEBUGPL(DBG_ANY, "Backed up hcintmsk[%02d]=%08x\n", i,
+			    hr->hcintmsk_local[i]);
+	}
+	DWC_DEBUGPL(DBG_ANY, "Backed up hprt0           = %08x\n",
+		    hr->hprt0_local);
+	DWC_DEBUGPL(DBG_ANY, "Backed up hfir           = %08x\n",
+		    hr->hfir_local);
+
+	return 0;
+}
+
+int dwc_otg_restore_global_regs(dwc_otg_core_if_t * core_if)
+{
+	struct dwc_otg_global_regs_backup *gr;
+	int i;
+
+	gr = core_if->gr_backup;
+	if (!gr) {
+		return -DWC_E_INVALID;
+	}
+
+	DWC_WRITE_REG32(&core_if->core_global_regs->gotgctl, gr->gotgctl_local);
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintmsk, gr->gintmsk_local);
+	DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg, gr->gusbcfg_local);
+	DWC_WRITE_REG32(&core_if->core_global_regs->gahbcfg, gr->gahbcfg_local);
+	DWC_WRITE_REG32(&core_if->core_global_regs->grxfsiz, gr->grxfsiz_local);
+	DWC_WRITE_REG32(&core_if->core_global_regs->gnptxfsiz,
+			gr->gnptxfsiz_local);
+	DWC_WRITE_REG32(&core_if->core_global_regs->hptxfsiz,
+			gr->hptxfsiz_local);
+	DWC_WRITE_REG32(&core_if->core_global_regs->gdfifocfg,
+			gr->gdfifocfg_local);
+	for (i = 0; i < MAX_EPS_CHANNELS; i++) {
+		DWC_WRITE_REG32(&core_if->core_global_regs->dtxfsiz[i],
+				gr->dtxfsiz_local[i]);
+	}
+
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, 0xFFFFFFFF);
+	DWC_WRITE_REG32(core_if->host_if->hprt0, 0x0000100A);
+	DWC_WRITE_REG32(&core_if->core_global_regs->gahbcfg,
+			(gr->gahbcfg_local));
+	return 0;
+}
+
+int dwc_otg_restore_dev_regs(dwc_otg_core_if_t * core_if, int rem_wakeup)
+{
+	struct dwc_otg_dev_regs_backup *dr;
+	int i;
+
+	dr = core_if->dr_backup;
+
+	if (!dr) {
+		return -DWC_E_INVALID;
+	}
+
+	if (!rem_wakeup) {
+		DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dctl,
+				dr->dctl);
+	}
+
+	DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->daintmsk, dr->daintmsk);
+	DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->diepmsk, dr->diepmsk);
+	DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->doepmsk, dr->doepmsk);
+
+	for (i = 0; i < core_if->dev_if->num_in_eps; ++i) {
+		DWC_WRITE_REG32(&core_if->dev_if->in_ep_regs[i]->dieptsiz, dr->dieptsiz[i]);
+		DWC_WRITE_REG32(&core_if->dev_if->in_ep_regs[i]->diepdma, dr->diepdma[i]);
+		DWC_WRITE_REG32(&core_if->dev_if->in_ep_regs[i]->diepctl, dr->diepctl[i]);
+	}
+
+	return 0;
+}
+
+int dwc_otg_restore_host_regs(dwc_otg_core_if_t * core_if, int reset)
+{
+	struct dwc_otg_host_regs_backup *hr;
+	int i;
+	hr = core_if->hr_backup;
+
+	if (!hr) {
+		return -DWC_E_INVALID;
+	}
+
+	DWC_WRITE_REG32(&core_if->host_if->host_global_regs->hcfg, hr->hcfg_local);
+	//if (!reset)
+	//{
+	//      DWC_WRITE_REG32(&core_if->host_if->host_global_regs->hfir, hr->hfir_local);
+	//}
+
+	DWC_WRITE_REG32(&core_if->host_if->host_global_regs->haintmsk,
+			hr->haintmsk_local);
+	for (i = 0; i < dwc_otg_get_param_host_channels(core_if); ++i) {
+		DWC_WRITE_REG32(&core_if->host_if->hc_regs[i]->hcintmsk,
+				hr->hcintmsk_local[i]);
+	}
+
+	return 0;
+}
+
+int restore_lpm_i2c_regs(dwc_otg_core_if_t * core_if)
+{
+	struct dwc_otg_global_regs_backup *gr;
+
+	gr = core_if->gr_backup;
+
+	/* Restore values for LPM and I2C */
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	DWC_WRITE_REG32(&core_if->core_global_regs->glpmcfg, gr->glpmcfg_local);
+#endif
+	DWC_WRITE_REG32(&core_if->core_global_regs->gi2cctl, gr->gi2cctl_local);
+
+	return 0;
+}
+
+int restore_essential_regs(dwc_otg_core_if_t * core_if, int rmode, int is_host)
+{
+	struct dwc_otg_global_regs_backup *gr;
+	pcgcctl_data_t pcgcctl = {.d32 = 0 };
+	gahbcfg_data_t gahbcfg = {.d32 = 0 };
+	gusbcfg_data_t gusbcfg = {.d32 = 0 };
+	gintmsk_data_t gintmsk = {.d32 = 0 };
+
+	/* Restore LPM and I2C registers */
+	restore_lpm_i2c_regs(core_if);
+
+	/* Set PCGCCTL to 0 */
+	DWC_WRITE_REG32(core_if->pcgcctl, 0x00000000);
+
+	gr = core_if->gr_backup;
+	/* Load restore values for [31:14] bits */
+	DWC_WRITE_REG32(core_if->pcgcctl,
+			((gr->pcgcctl_local & 0xffffc000) | 0x00020000));
+
+	/* Umnask global Interrupt in GAHBCFG and restore it */
+	gahbcfg.d32 = gr->gahbcfg_local;
+	gahbcfg.b.glblintrmsk = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gahbcfg, gahbcfg.d32);
+
+	/* Clear all pending interupts */
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, 0xFFFFFFFF);
+
+	/* Unmask restore done interrupt */
+	gintmsk.b.restoredone = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintmsk, gintmsk.d32);
+
+	/* Restore GUSBCFG and HCFG/DCFG */
+	gusbcfg.d32 = core_if->gr_backup->gusbcfg_local;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg, gusbcfg.d32);
+
+	if (is_host) {
+		hcfg_data_t hcfg = {.d32 = 0 };
+		hcfg.d32 = core_if->hr_backup->hcfg_local;
+		DWC_WRITE_REG32(&core_if->host_if->host_global_regs->hcfg,
+				hcfg.d32);
+
+		/* Load restore values for [31:14] bits */
+		pcgcctl.d32 = gr->pcgcctl_local & 0xffffc000;
+		pcgcctl.d32 = gr->pcgcctl_local | 0x00020000;
+
+		if (rmode)
+			pcgcctl.b.restoremode = 1;
+		DWC_WRITE_REG32(core_if->pcgcctl, pcgcctl.d32);
+		dwc_udelay(10);
+
+		/* Load restore values for [31:14] bits and set EssRegRestored bit */
+		pcgcctl.d32 = gr->pcgcctl_local | 0xffffc000;
+		pcgcctl.d32 = gr->pcgcctl_local & 0xffffc000;
+		pcgcctl.b.ess_reg_restored = 1;
+		if (rmode)
+			pcgcctl.b.restoremode = 1;
+		DWC_WRITE_REG32(core_if->pcgcctl, pcgcctl.d32);
+	} else {
+		dcfg_data_t dcfg = {.d32 = 0 };
+		dcfg.d32 = core_if->dr_backup->dcfg;
+		DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dcfg, dcfg.d32);
+
+		/* Load restore values for [31:14] bits */
+		pcgcctl.d32 = gr->pcgcctl_local & 0xffffc000;
+		pcgcctl.d32 = gr->pcgcctl_local | 0x00020000;
+		if (!rmode) {
+			pcgcctl.d32 |= 0x208;
+		}
+		DWC_WRITE_REG32(core_if->pcgcctl, pcgcctl.d32);
+		dwc_udelay(10);
+
+		/* Load restore values for [31:14] bits */
+		pcgcctl.d32 = gr->pcgcctl_local & 0xffffc000;
+		pcgcctl.d32 = gr->pcgcctl_local | 0x00020000;
+		pcgcctl.b.ess_reg_restored = 1;
+		if (!rmode)
+			pcgcctl.d32 |= 0x208;
+		DWC_WRITE_REG32(core_if->pcgcctl, pcgcctl.d32);
+	}
+
+	return 0;
+}
+
+/**
+ * Initializes the FSLSPClkSel field of the HCFG register depending on the PHY
+ * type.
+ */
+static void init_fslspclksel(dwc_otg_core_if_t * core_if)
+{
+	uint32_t val;
+	hcfg_data_t hcfg;
+
+	if (((core_if->hwcfg2.b.hs_phy_type == 2) &&
+	     (core_if->hwcfg2.b.fs_phy_type == 1) &&
+	     (core_if->core_params->ulpi_fs_ls)) ||
+	    (core_if->core_params->phy_type == DWC_PHY_TYPE_PARAM_FS)) {
+		/* Full speed PHY */
+		val = DWC_HCFG_48_MHZ;
+	} else {
+		/* High speed PHY running at full speed or high speed */
+		val = DWC_HCFG_30_60_MHZ;
+	}
+
+	DWC_DEBUGPL(DBG_CIL, "Initializing HCFG.FSLSPClkSel to 0x%1x\n", val);
+	hcfg.d32 = DWC_READ_REG32(&core_if->host_if->host_global_regs->hcfg);
+	hcfg.b.fslspclksel = val;
+	DWC_WRITE_REG32(&core_if->host_if->host_global_regs->hcfg, hcfg.d32);
+}
+
+/**
+ * Initializes the DevSpd field of the DCFG register depending on the PHY type
+ * and the enumeration speed of the device.
+ */
+static void init_devspd(dwc_otg_core_if_t * core_if)
+{
+	uint32_t val;
+	dcfg_data_t dcfg;
+
+	if (((core_if->hwcfg2.b.hs_phy_type == 2) &&
+	     (core_if->hwcfg2.b.fs_phy_type == 1) &&
+	     (core_if->core_params->ulpi_fs_ls)) ||
+	    (core_if->core_params->phy_type == DWC_PHY_TYPE_PARAM_FS)) {
+		/* Full speed PHY */
+		val = 0x3;
+	} else if (core_if->core_params->speed == DWC_SPEED_PARAM_FULL) {
+		/* High speed PHY running at full speed */
+		val = 0x1;
+	} else {
+		/* High speed PHY running at high speed */
+		val = 0x0;
+	}
+
+	DWC_DEBUGPL(DBG_CIL, "Initializing DCFG.DevSpd to 0x%1x\n", val);
+
+	dcfg.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dcfg);
+	dcfg.b.devspd = val;
+	DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dcfg, dcfg.d32);
+}
+
+/**
+ * This function calculates the number of IN EPS
+ * using GHWCFG1 and GHWCFG2 registers values
+ *
+ * @param core_if Programming view of the DWC_otg controller
+ */
+static uint32_t calc_num_in_eps(dwc_otg_core_if_t * core_if)
+{
+	uint32_t num_in_eps = 0;
+	uint32_t num_eps = core_if->hwcfg2.b.num_dev_ep;
+	uint32_t hwcfg1 = core_if->hwcfg1.d32 >> 3;
+	uint32_t num_tx_fifos = core_if->hwcfg4.b.num_in_eps;
+	int i;
+
+	for (i = 0; i < num_eps; ++i) {
+		if (!(hwcfg1 & 0x1))
+			num_in_eps++;
+
+		hwcfg1 >>= 2;
+	}
+
+	if (core_if->hwcfg4.b.ded_fifo_en) {
+		num_in_eps =
+		    (num_in_eps > num_tx_fifos) ? num_tx_fifos : num_in_eps;
+	}
+
+	return num_in_eps;
+}
+
+/**
+ * This function calculates the number of OUT EPS
+ * using GHWCFG1 and GHWCFG2 registers values
+ *
+ * @param core_if Programming view of the DWC_otg controller
+ */
+static uint32_t calc_num_out_eps(dwc_otg_core_if_t * core_if)
+{
+	uint32_t num_out_eps = 0;
+	uint32_t num_eps = core_if->hwcfg2.b.num_dev_ep;
+	uint32_t hwcfg1 = core_if->hwcfg1.d32 >> 2;
+	int i;
+
+	for (i = 0; i < num_eps; ++i) {
+		if (!(hwcfg1 & 0x1))
+			num_out_eps++;
+
+		hwcfg1 >>= 2;
+	}
+	return num_out_eps;
+}
+
+/**
+ * This function initializes the DWC_otg controller registers and
+ * prepares the core for device mode or host mode operation.
+ *
+ * @param core_if Programming view of the DWC_otg controller
+ *
+ */
+void dwc_otg_core_init(dwc_otg_core_if_t * core_if)
+{
+	int i = 0;
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	gahbcfg_data_t ahbcfg = {.d32 = 0 };
+	gusbcfg_data_t usbcfg = {.d32 = 0 };
+	gi2cctl_data_t i2cctl = {.d32 = 0 };
+
+	DWC_DEBUGPL(DBG_CILV, "dwc_otg_core_init(%p)\n", core_if);
+
+	/* Common Initialization */
+	usbcfg.d32 = DWC_READ_REG32(&global_regs->gusbcfg);
+
+	/* Program the ULPI External VBUS bit if needed */
+	usbcfg.b.ulpi_ext_vbus_drv =
+	    (core_if->core_params->phy_ulpi_ext_vbus ==
+	     DWC_PHY_ULPI_EXTERNAL_VBUS) ? 1 : 0;
+
+	/* Set external TS Dline pulsing */
+	usbcfg.b.term_sel_dl_pulse =
+	    (core_if->core_params->ts_dline == 1) ? 1 : 0;
+	DWC_WRITE_REG32(&global_regs->gusbcfg, usbcfg.d32);
+
+	/* Reset the Controller */
+	dwc_otg_core_reset(core_if);
+
+	core_if->adp_enable = core_if->core_params->adp_supp_enable;
+	core_if->power_down = core_if->core_params->power_down;
+
+	/* Initialize parameters from Hardware configuration registers. */
+	dev_if->num_in_eps = calc_num_in_eps(core_if);
+	dev_if->num_out_eps = calc_num_out_eps(core_if);
+
+	DWC_DEBUGPL(DBG_CIL, "num_dev_perio_in_ep=%d\n",
+		    core_if->hwcfg4.b.num_dev_perio_in_ep);
+
+	for (i = 0; i < core_if->hwcfg4.b.num_dev_perio_in_ep; i++) {
+		dev_if->perio_tx_fifo_size[i] =
+		    DWC_READ_REG32(&global_regs->dtxfsiz[i]) >> 16;
+		DWC_DEBUGPL(DBG_CIL, "Periodic Tx FIFO SZ #%d=0x%0x\n",
+			    i, dev_if->perio_tx_fifo_size[i]);
+	}
+
+	for (i = 0; i < core_if->hwcfg4.b.num_in_eps; i++) {
+		dev_if->tx_fifo_size[i] =
+		    DWC_READ_REG32(&global_regs->dtxfsiz[i]) >> 16;
+		DWC_DEBUGPL(DBG_CIL, "Tx FIFO SZ #%d=0x%0x\n",
+			    i, dev_if->tx_fifo_size[i]);
+	}
+
+	core_if->total_fifo_size = core_if->hwcfg3.b.dfifo_depth;
+	core_if->rx_fifo_size = DWC_READ_REG32(&global_regs->grxfsiz);
+	core_if->nperio_tx_fifo_size =
+	    DWC_READ_REG32(&global_regs->gnptxfsiz) >> 16;
+
+	DWC_DEBUGPL(DBG_CIL, "Total FIFO SZ=%d\n", core_if->total_fifo_size);
+	DWC_DEBUGPL(DBG_CIL, "Rx FIFO SZ=%d\n", core_if->rx_fifo_size);
+	DWC_DEBUGPL(DBG_CIL, "NP Tx FIFO SZ=%d\n",
+		    core_if->nperio_tx_fifo_size);
+
+	/* This programming sequence needs to happen in FS mode before any other
+	 * programming occurs */
+	if ((core_if->core_params->speed == DWC_SPEED_PARAM_FULL) &&
+	    (core_if->core_params->phy_type == DWC_PHY_TYPE_PARAM_FS)) {
+		/* If FS mode with FS PHY */
+
+		/* core_init() is now called on every switch so only call the
+		 * following for the first time through. */
+		if (!core_if->phy_init_done) {
+			core_if->phy_init_done = 1;
+			DWC_DEBUGPL(DBG_CIL, "FS_PHY detected\n");
+			usbcfg.d32 = DWC_READ_REG32(&global_regs->gusbcfg);
+			usbcfg.b.physel = 1;
+			DWC_WRITE_REG32(&global_regs->gusbcfg, usbcfg.d32);
+
+			/* Reset after a PHY select */
+			dwc_otg_core_reset(core_if);
+		}
+
+		/* Program DCFG.DevSpd or HCFG.FSLSPclkSel to 48Mhz in FS.      Also
+		 * do this on HNP Dev/Host mode switches (done in dev_init and
+		 * host_init). */
+		if (dwc_otg_is_host_mode(core_if)) {
+			init_fslspclksel(core_if);
+		} else {
+			init_devspd(core_if);
+		}
+
+		if (core_if->core_params->i2c_enable) {
+			DWC_DEBUGPL(DBG_CIL, "FS_PHY Enabling I2c\n");
+			/* Program GUSBCFG.OtgUtmifsSel to I2C */
+			usbcfg.d32 = DWC_READ_REG32(&global_regs->gusbcfg);
+			usbcfg.b.otgutmifssel = 1;
+			DWC_WRITE_REG32(&global_regs->gusbcfg, usbcfg.d32);
+
+			/* Program GI2CCTL.I2CEn */
+			i2cctl.d32 = DWC_READ_REG32(&global_regs->gi2cctl);
+			i2cctl.b.i2cdevaddr = 1;
+			i2cctl.b.i2cen = 0;
+			DWC_WRITE_REG32(&global_regs->gi2cctl, i2cctl.d32);
+			i2cctl.b.i2cen = 1;
+			DWC_WRITE_REG32(&global_regs->gi2cctl, i2cctl.d32);
+		}
+
+	} /* endif speed == DWC_SPEED_PARAM_FULL */
+	else {
+		/* High speed PHY. */
+		if (!core_if->phy_init_done) {
+			core_if->phy_init_done = 1;
+			/* HS PHY parameters.  These parameters are preserved
+			 * during soft reset so only program the first time.  Do
+			 * a soft reset immediately after setting phyif.  */
+
+			if (core_if->core_params->phy_type == 2) {
+				/* ULPI interface */
+				usbcfg.b.ulpi_utmi_sel = 1;
+				usbcfg.b.phyif = 0;
+				usbcfg.b.ddrsel =
+				    core_if->core_params->phy_ulpi_ddr;
+			} else if (core_if->core_params->phy_type == 1) {
+				/* UTMI+ interface */
+				usbcfg.b.ulpi_utmi_sel = 0;
+				if (core_if->core_params->phy_utmi_width == 16) {
+					usbcfg.b.phyif = 1;
+
+				} else {
+					usbcfg.b.phyif = 0;
+				}
+			} else {
+				DWC_ERROR("FS PHY TYPE\n");
+			}
+			DWC_WRITE_REG32(&global_regs->gusbcfg, usbcfg.d32);
+			/* Reset after setting the PHY parameters */
+			dwc_otg_core_reset(core_if);
+		}
+	}
+
+	if ((core_if->hwcfg2.b.hs_phy_type == 2) &&
+	    (core_if->hwcfg2.b.fs_phy_type == 1) &&
+	    (core_if->core_params->ulpi_fs_ls)) {
+		DWC_DEBUGPL(DBG_CIL, "Setting ULPI FSLS\n");
+		usbcfg.d32 = DWC_READ_REG32(&global_regs->gusbcfg);
+		usbcfg.b.ulpi_fsls = 1;
+		usbcfg.b.ulpi_clk_sus_m = 1;
+		DWC_WRITE_REG32(&global_regs->gusbcfg, usbcfg.d32);
+	} else {
+		usbcfg.d32 = DWC_READ_REG32(&global_regs->gusbcfg);
+		usbcfg.b.ulpi_fsls = 0;
+		usbcfg.b.ulpi_clk_sus_m = 0;
+		DWC_WRITE_REG32(&global_regs->gusbcfg, usbcfg.d32);
+	}
+
+	/* Program the GAHBCFG Register. */
+	switch (core_if->hwcfg2.b.architecture) {
+
+	case DWC_SLAVE_ONLY_ARCH:
+		DWC_DEBUGPL(DBG_CIL, "Slave Only Mode\n");
+		ahbcfg.b.nptxfemplvl_txfemplvl =
+		    DWC_GAHBCFG_TXFEMPTYLVL_HALFEMPTY;
+		ahbcfg.b.ptxfemplvl = DWC_GAHBCFG_TXFEMPTYLVL_HALFEMPTY;
+		core_if->dma_enable = 0;
+		core_if->dma_desc_enable = 0;
+		break;
+
+	case DWC_EXT_DMA_ARCH:
+		DWC_DEBUGPL(DBG_CIL, "External DMA Mode\n");
+		{
+			uint8_t brst_sz = core_if->core_params->dma_burst_size;
+			ahbcfg.b.hburstlen = 0;
+			while (brst_sz > 1) {
+				ahbcfg.b.hburstlen++;
+				brst_sz >>= 1;
+			}
+		}
+		core_if->dma_enable = (core_if->core_params->dma_enable != 0);
+		core_if->dma_desc_enable =
+		    (core_if->core_params->dma_desc_enable != 0);
+		break;
+
+	case DWC_INT_DMA_ARCH:
+		DWC_DEBUGPL(DBG_CIL, "Internal DMA Mode\n");
+		/* Old value was DWC_GAHBCFG_INT_DMA_BURST_INCR - done for
+		   Host mode ISOC in issue fix - vahrama */
+		ahbcfg.b.hburstlen = DWC_GAHBCFG_INT_DMA_BURST_INCR4;
+		core_if->dma_enable = (core_if->core_params->dma_enable != 0);
+		core_if->dma_desc_enable =
+		    (core_if->core_params->dma_desc_enable != 0);
+		break;
+
+	}
+	if (core_if->dma_enable) {
+		if (core_if->dma_desc_enable) {
+			DWC_PRINTF("Using Descriptor DMA mode\n");
+		} else {
+			DWC_PRINTF("Using Buffer DMA mode\n");
+		}
+	} else {
+		DWC_PRINTF("Using Slave mode\n");
+		core_if->dma_desc_enable = 0;
+	}
+
+	if (core_if->core_params->ahb_single) {
+		ahbcfg.b.ahbsingle = 1;
+	}
+
+	ahbcfg.b.dmaenable = core_if->dma_enable;
+	DWC_WRITE_REG32(&global_regs->gahbcfg, ahbcfg.d32);
+
+	core_if->en_multiple_tx_fifo = core_if->hwcfg4.b.ded_fifo_en;
+
+	core_if->pti_enh_enable = core_if->core_params->pti_enable != 0;
+	core_if->multiproc_int_enable = core_if->core_params->mpi_enable;
+
+	/*
+	 * Program the GUSBCFG register.
+	 */
+	usbcfg.d32 = DWC_READ_REG32(&global_regs->gusbcfg);
+
+	switch (core_if->hwcfg2.b.op_mode) {
+	case DWC_MODE_HNP_SRP_CAPABLE:
+		usbcfg.b.hnpcap = (core_if->core_params->otg_cap ==
+				   DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE);
+		usbcfg.b.srpcap = (core_if->core_params->otg_cap !=
+				   DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE);
+		break;
+
+	case DWC_MODE_SRP_ONLY_CAPABLE:
+		usbcfg.b.hnpcap = 0;
+		usbcfg.b.srpcap = (core_if->core_params->otg_cap !=
+				   DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE);
+		break;
+
+	case DWC_MODE_NO_HNP_SRP_CAPABLE:
+		usbcfg.b.hnpcap = 0;
+		usbcfg.b.srpcap = 0;
+		break;
+
+	case DWC_MODE_SRP_CAPABLE_DEVICE:
+		usbcfg.b.hnpcap = 0;
+		usbcfg.b.srpcap = (core_if->core_params->otg_cap !=
+				   DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE);
+		break;
+
+	case DWC_MODE_NO_SRP_CAPABLE_DEVICE:
+		usbcfg.b.hnpcap = 0;
+		usbcfg.b.srpcap = 0;
+		break;
+
+	case DWC_MODE_SRP_CAPABLE_HOST:
+		usbcfg.b.hnpcap = 0;
+		usbcfg.b.srpcap = (core_if->core_params->otg_cap !=
+				   DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE);
+		break;
+
+	case DWC_MODE_NO_SRP_CAPABLE_HOST:
+		usbcfg.b.hnpcap = 0;
+		usbcfg.b.srpcap = 0;
+		break;
+	}
+
+	DWC_WRITE_REG32(&global_regs->gusbcfg, usbcfg.d32);
+
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	if (core_if->core_params->lpm_enable) {
+		glpmcfg_data_t lpmcfg = {.d32 = 0 };
+
+		/* To enable LPM support set lpm_cap_en bit */
+		lpmcfg.b.lpm_cap_en = 1;
+
+		/* Make AppL1Res ACK */
+		lpmcfg.b.appl_resp = 1;
+
+		/* Retry 3 times */
+		lpmcfg.b.retry_count = 3;
+
+		DWC_MODIFY_REG32(&core_if->core_global_regs->glpmcfg,
+				 0, lpmcfg.d32);
+
+	}
+#endif
+	if (core_if->core_params->ic_usb_cap) {
+		gusbcfg_data_t gusbcfg = {.d32 = 0 };
+		gusbcfg.b.ic_usb_cap = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gusbcfg,
+				 0, gusbcfg.d32);
+	}
+	{
+		gotgctl_data_t gotgctl = {.d32 = 0 };
+		gotgctl.b.otgver = core_if->core_params->otg_ver;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gotgctl, 0,
+				 gotgctl.d32);
+		/* Set OTG version supported */
+		core_if->otg_ver = core_if->core_params->otg_ver;
+	}
+
+	/* Enable common interrupts */
+	dwc_otg_enable_common_interrupts(core_if);
+
+	/* Do device or host intialization based on mode during PCD
+	 * and HCD initialization  */
+	if (dwc_otg_is_host_mode(core_if)) {
+		DWC_DEBUGPL(DBG_ANY, "Host Mode\n");
+		core_if->op_state = A_HOST;
+	} else {
+		DWC_DEBUGPL(DBG_ANY, "Device Mode\n");
+		core_if->op_state = B_PERIPHERAL;
+#ifdef DWC_DEVICE_ONLY
+		dwc_otg_core_dev_init(core_if);
+#endif
+	}
+}
+
+/**
+ * This function enables the Device mode interrupts.
+ *
+ * @param core_if Programming view of DWC_otg controller
+ */
+void dwc_otg_enable_device_interrupts(dwc_otg_core_if_t * core_if)
+{
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+
+	DWC_DEBUGPL(DBG_CIL, "%s()\n", __func__);
+
+	/* Disable all interrupts. */
+	DWC_WRITE_REG32(&global_regs->gintmsk, 0);
+
+	/* Clear any pending interrupts */
+	DWC_WRITE_REG32(&global_regs->gintsts, 0xFFFFFFFF);
+
+	/* Enable the common interrupts */
+	dwc_otg_enable_common_interrupts(core_if);
+
+	/* Enable interrupts */
+	intr_mask.b.usbreset = 1;
+	intr_mask.b.enumdone = 1;
+	/* Disable Disconnect interrupt in Device mode */
+	intr_mask.b.disconnect = 0;
+
+	if (!core_if->multiproc_int_enable) {
+		intr_mask.b.inepintr = 1;
+		intr_mask.b.outepintr = 1;
+	}
+
+	intr_mask.b.erlysuspend = 1;
+
+	if (core_if->en_multiple_tx_fifo == 0) {
+		intr_mask.b.epmismatch = 1;
+	}
+
+	/* intr_mask.b.incomplisoout = 1; */
+	if (!core_if->dma_desc_enable)
+		intr_mask.b.incomplisoin = 1;
+#ifdef DWC_EN_ISOC
+	if (core_if->dma_enable) {
+		if (core_if->dma_desc_enable == 0) {
+			if (core_if->pti_enh_enable) {
+				dctl_data_t dctl = {.d32 = 0 };
+				dctl.b.ifrmnum = 1;
+				DWC_MODIFY_REG32(&core_if->
+						 dev_if->dev_global_regs->dctl,
+						 0, dctl.d32);
+			} else {
+				intr_mask.b.incomplisoin = 1;
+				intr_mask.b.incomplisoout = 1;
+			}
+		}
+	} else {
+		intr_mask.b.incomplisoin = 1;
+		intr_mask.b.incomplisoout = 1;
+	}
+#endif /* DWC_EN_ISOC */
+
+	/** @todo NGS: Should this be a module parameter? */
+#ifdef USE_PERIODIC_EP
+	intr_mask.b.isooutdrop = 1;
+	intr_mask.b.eopframe = 1;
+	intr_mask.b.incomplisoin = 1;
+	intr_mask.b.incomplisoout = 1;
+#endif
+
+	DWC_MODIFY_REG32(&global_regs->gintmsk, intr_mask.d32, intr_mask.d32);
+
+	DWC_DEBUGPL(DBG_CIL, "%s() gintmsk=%0x\n", __func__,
+		    DWC_READ_REG32(&global_regs->gintmsk));
+}
+
+/**
+ * This function initializes the DWC_otg controller registers for
+ * device mode.
+ *
+ * @param core_if Programming view of DWC_otg controller
+ *
+ */
+void dwc_otg_core_dev_init(dwc_otg_core_if_t * core_if)
+{
+	int i;
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	dwc_otg_core_params_t *params = core_if->core_params;
+	dcfg_data_t dcfg = {.d32 = 0 };
+	depctl_data_t diepctl = {.d32 = 0 };
+	grstctl_t resetctl = {.d32 = 0 };
+	uint32_t rx_fifo_size;
+	fifosize_data_t nptxfifosize;
+	fifosize_data_t txfifosize;
+	dthrctl_data_t dthrctl;
+	fifosize_data_t ptxfifosize;
+	uint16_t rxfsiz, nptxfsiz;
+	gdfifocfg_data_t gdfifocfg = {.d32 = 0 };
+	hwcfg3_data_t hwcfg3 = {.d32 = 0 };
+	gotgctl_data_t gotgctl = {.d32 = 0 };
+
+	/* Restart the Phy Clock */
+	pcgcctl_data_t pcgcctl = {.d32 = 0 };
+	/* Restart the Phy Clock */
+	pcgcctl.b.stoppclk = 1;
+	DWC_MODIFY_REG32(core_if->pcgcctl, pcgcctl.d32, 0);
+	dwc_udelay(10);
+
+	/* Device configuration register */
+	init_devspd(core_if);
+	dcfg.d32 = DWC_READ_REG32(&dev_if->dev_global_regs->dcfg);
+	dcfg.b.descdma = (core_if->dma_desc_enable) ? 1 : 0;
+	dcfg.b.perfrint = DWC_DCFG_FRAME_INTERVAL_80;
+	/* Enable Device OUT NAK in case of DDMA mode */
+	if (core_if->core_params->dev_out_nak) {
+		dcfg.b.endevoutnak = 1;
+	}
+
+	if (core_if->core_params->cont_on_bna) {
+		dctl_data_t dctl = {.d32 = 0 };
+		dctl.b.encontonbna = 1;
+		DWC_MODIFY_REG32(&dev_if->dev_global_regs->dctl, 0, dctl.d32);
+	}
+	/** should be done before every reset */
+	if (core_if->otg_ver) {
+		core_if->otg_sts = 0;
+		gotgctl.b.devhnpen = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gotgctl, gotgctl.d32, 0);
+	}
+
+	DWC_WRITE_REG32(&dev_if->dev_global_regs->dcfg, dcfg.d32);
+
+	/* Configure data FIFO sizes */
+	if (core_if->hwcfg2.b.dynamic_fifo && params->enable_dynamic_fifo) {
+		DWC_DEBUGPL(DBG_CIL, "Total FIFO Size=%d\n",
+			    core_if->total_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "Rx FIFO Size=%d\n",
+			    params->dev_rx_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "NP Tx FIFO Size=%d\n",
+			    params->dev_nperio_tx_fifo_size);
+
+		/* Rx FIFO */
+		DWC_DEBUGPL(DBG_CIL, "initial grxfsiz=%08x\n",
+			    DWC_READ_REG32(&global_regs->grxfsiz));
+
+#ifdef DWC_UTE_CFI
+		core_if->pwron_rxfsiz = DWC_READ_REG32(&global_regs->grxfsiz);
+		core_if->init_rxfsiz = params->dev_rx_fifo_size;
+#endif
+		rx_fifo_size = params->dev_rx_fifo_size;
+		DWC_WRITE_REG32(&global_regs->grxfsiz, rx_fifo_size);
+
+		DWC_DEBUGPL(DBG_CIL, "new grxfsiz=%08x\n",
+			    DWC_READ_REG32(&global_regs->grxfsiz));
+
+		/** Set Periodic Tx FIFO Mask all bits 0 */
+		core_if->p_tx_msk = 0;
+
+		/** Set Tx FIFO Mask all bits 0 */
+		core_if->tx_msk = 0;
+
+		if (core_if->en_multiple_tx_fifo == 0) {
+			/* Non-periodic Tx FIFO */
+			DWC_DEBUGPL(DBG_CIL, "initial gnptxfsiz=%08x\n",
+				    DWC_READ_REG32(&global_regs->gnptxfsiz));
+
+			nptxfifosize.b.depth = params->dev_nperio_tx_fifo_size;
+			nptxfifosize.b.startaddr = params->dev_rx_fifo_size;
+
+			DWC_WRITE_REG32(&global_regs->gnptxfsiz,
+					nptxfifosize.d32);
+
+			DWC_DEBUGPL(DBG_CIL, "new gnptxfsiz=%08x\n",
+				    DWC_READ_REG32(&global_regs->gnptxfsiz));
+
+			/**@todo NGS: Fix Periodic FIFO Sizing! */
+			/*
+			 * Periodic Tx FIFOs These FIFOs are numbered from 1 to 15.
+			 * Indexes of the FIFO size module parameters in the
+			 * dev_perio_tx_fifo_size array and the FIFO size registers in
+			 * the dptxfsiz array run from 0 to 14.
+			 */
+			/** @todo Finish debug of this */
+			ptxfifosize.b.startaddr =
+			    nptxfifosize.b.startaddr + nptxfifosize.b.depth;
+			for (i = 0; i < core_if->hwcfg4.b.num_dev_perio_in_ep; i++) {
+				ptxfifosize.b.depth =
+				    params->dev_perio_tx_fifo_size[i];
+				DWC_DEBUGPL(DBG_CIL,
+					    "initial dtxfsiz[%d]=%08x\n", i,
+					    DWC_READ_REG32(&global_regs->dtxfsiz
+							   [i]));
+				DWC_WRITE_REG32(&global_regs->dtxfsiz[i],
+						ptxfifosize.d32);
+				DWC_DEBUGPL(DBG_CIL, "new dtxfsiz[%d]=%08x\n",
+					    i,
+					    DWC_READ_REG32(&global_regs->dtxfsiz
+							   [i]));
+				ptxfifosize.b.startaddr += ptxfifosize.b.depth;
+			}
+		} else {
+			/*
+			 * Tx FIFOs These FIFOs are numbered from 1 to 15.
+			 * Indexes of the FIFO size module parameters in the
+			 * dev_tx_fifo_size array and the FIFO size registers in
+			 * the dtxfsiz array run from 0 to 14.
+			 */
+
+			/* Non-periodic Tx FIFO */
+			DWC_DEBUGPL(DBG_CIL, "initial gnptxfsiz=%08x\n",
+				    DWC_READ_REG32(&global_regs->gnptxfsiz));
+
+#ifdef DWC_UTE_CFI
+			core_if->pwron_gnptxfsiz =
+			    (DWC_READ_REG32(&global_regs->gnptxfsiz) >> 16);
+			core_if->init_gnptxfsiz =
+			    params->dev_nperio_tx_fifo_size;
+#endif
+			nptxfifosize.b.depth = params->dev_nperio_tx_fifo_size;
+			nptxfifosize.b.startaddr = params->dev_rx_fifo_size;
+
+			DWC_WRITE_REG32(&global_regs->gnptxfsiz,
+					nptxfifosize.d32);
+
+			DWC_DEBUGPL(DBG_CIL, "new gnptxfsiz=%08x\n",
+				    DWC_READ_REG32(&global_regs->gnptxfsiz));
+
+			txfifosize.b.startaddr =
+			    nptxfifosize.b.startaddr + nptxfifosize.b.depth;
+
+			for (i = 0; i < core_if->hwcfg4.b.num_in_eps; i++) {
+
+				txfifosize.b.depth =
+				    params->dev_tx_fifo_size[i];
+
+				DWC_DEBUGPL(DBG_CIL,
+					    "initial dtxfsiz[%d]=%08x\n",
+					    i,
+					    DWC_READ_REG32(&global_regs->dtxfsiz
+							   [i]));
+
+#ifdef DWC_UTE_CFI
+				core_if->pwron_txfsiz[i] =
+				    (DWC_READ_REG32
+				     (&global_regs->dtxfsiz[i]) >> 16);
+				core_if->init_txfsiz[i] =
+				    params->dev_tx_fifo_size[i];
+#endif
+				DWC_WRITE_REG32(&global_regs->dtxfsiz[i],
+						txfifosize.d32);
+
+				DWC_DEBUGPL(DBG_CIL,
+					    "new dtxfsiz[%d]=%08x\n",
+					    i,
+					    DWC_READ_REG32(&global_regs->dtxfsiz
+							   [i]));
+
+				txfifosize.b.startaddr += txfifosize.b.depth;
+			}
+
+			/* Calculating DFIFOCFG for Device mode to include RxFIFO and NPTXFIFO
+			 * Before 3.00a EpInfoBase was being configured in ep enable/disable
+			 * routine as well. Starting from 3.00a it will be set to the end of
+			 * allocated FIFO space here due to ep 0 OUT always keeping enabled
+			 */
+			gdfifocfg.d32 = DWC_READ_REG32(&global_regs->gdfifocfg);
+			hwcfg3.d32 = DWC_READ_REG32(&global_regs->ghwcfg3);
+			gdfifocfg.b.gdfifocfg = (DWC_READ_REG32(&global_regs->ghwcfg3) >> 16);
+			DWC_WRITE_REG32(&global_regs->gdfifocfg, gdfifocfg.d32);
+			if (core_if->snpsid <= OTG_CORE_REV_2_94a) {
+				rxfsiz = (DWC_READ_REG32(&global_regs->grxfsiz) & 0x0000ffff);
+				nptxfsiz = (DWC_READ_REG32(&global_regs->gnptxfsiz) >> 16);
+				gdfifocfg.b.epinfobase = rxfsiz + nptxfsiz;
+			} else {
+				gdfifocfg.b.epinfobase = txfifosize.b.startaddr;
+			}
+			DWC_WRITE_REG32(&global_regs->gdfifocfg, gdfifocfg.d32);
+		}
+	}
+
+	/* Flush the FIFOs */
+	dwc_otg_flush_tx_fifo(core_if, 0x10);	/* all Tx FIFOs */
+	dwc_otg_flush_rx_fifo(core_if);
+
+	/* Flush the Learning Queue. */
+	resetctl.b.intknqflsh = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->grstctl, resetctl.d32);
+
+	if (!core_if->core_params->en_multiple_tx_fifo && core_if->dma_enable) {
+		core_if->start_predict = 0;
+		for (i = 0; i <= core_if->dev_if->num_in_eps; ++i) {
+			core_if->nextep_seq[i] = 0xff;	// 0xff - EP not active
+		}
+		core_if->nextep_seq[0] = 0;
+		core_if->first_in_nextep_seq = 0;
+		diepctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[0]->diepctl);
+		diepctl.b.nextep = 0;
+		DWC_WRITE_REG32(&dev_if->in_ep_regs[0]->diepctl, diepctl.d32);
+
+		/* Update IN Endpoint Mismatch Count by active IN NP EP count + 1 */
+		dcfg.d32 = DWC_READ_REG32(&dev_if->dev_global_regs->dcfg);
+		dcfg.b.epmscnt = 2;
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->dcfg, dcfg.d32);
+
+		DWC_DEBUGPL(DBG_CILV,
+			    "%s first_in_nextep_seq= %2d; nextep_seq[]:\n",
+			    __func__, core_if->first_in_nextep_seq);
+		for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+			DWC_DEBUGPL(DBG_CILV, "%2d ", core_if->nextep_seq[i]);
+		}
+		DWC_DEBUGPL(DBG_CILV, "\n");
+	}
+
+	/* Clear all pending Device Interrupts */
+	/** @todo - if the condition needed to be checked
+	 *  or in any case all pending interrutps should be cleared?
+     */
+	if (core_if->multiproc_int_enable) {
+		for (i = 0; i < core_if->dev_if->num_in_eps; ++i) {
+			DWC_WRITE_REG32(&dev_if->dev_global_regs->
+					diepeachintmsk[i], 0);
+		}
+
+		for (i = 0; i < core_if->dev_if->num_out_eps; ++i) {
+			DWC_WRITE_REG32(&dev_if->dev_global_regs->
+					doepeachintmsk[i], 0);
+		}
+
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->deachint, 0xFFFFFFFF);
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->deachintmsk, 0);
+	} else {
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->diepmsk, 0);
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->doepmsk, 0);
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->daint, 0xFFFFFFFF);
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->daintmsk, 0);
+	}
+
+	for (i = 0; i <= dev_if->num_in_eps; i++) {
+		depctl_data_t depctl;
+		depctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[i]->diepctl);
+		if (depctl.b.epena) {
+			depctl.d32 = 0;
+			depctl.b.epdis = 1;
+			depctl.b.snak = 1;
+		} else {
+			depctl.d32 = 0;
+			depctl.b.snak = 1;
+		}
+
+		DWC_WRITE_REG32(&dev_if->in_ep_regs[i]->diepctl, depctl.d32);
+
+		DWC_WRITE_REG32(&dev_if->in_ep_regs[i]->dieptsiz, 0);
+		DWC_WRITE_REG32(&dev_if->in_ep_regs[i]->diepdma, 0);
+		DWC_WRITE_REG32(&dev_if->in_ep_regs[i]->diepint, 0xFF);
+	}
+
+	for (i = 1; i <= dev_if->num_out_eps; i++) {
+		depctl_data_t depctl;
+		depctl.d32 = DWC_READ_REG32(&dev_if->out_ep_regs[i]->doepctl);
+		if (depctl.b.epena) {
+			int j = 0;
+			dctl_data_t dctl = {.d32 = 0 };
+			gintmsk_data_t gintsts = {.d32 = 0 };
+			doepint_data_t doepint = {.d32 = 0 };
+			device_grxsts_data_t status;
+			dctl.b.sgoutnak = 1;
+			DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl, 0, dctl.d32);
+			if (!core_if->dma_enable) {
+				do {
+					j++;
+					dwc_udelay(10);
+					gintsts.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintsts);
+					if (j == 100000) {
+						DWC_ERROR("SNAK is not set during 10s\n");
+						break;
+					}
+				} while (!gintsts.b.rxstsqlvl);
+				status.d32 = DWC_READ_REG32(&global_regs->grxstsp);
+				if (status.b.pktsts == DWC_DSTS_GOUT_NAK)
+					DWC_DEBUGPL(DBG_PCDV, "Global OUT NAK\n");
+				gintsts.d32 = 0;
+				gintsts.b.rxstsqlvl = 1;
+				DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+			}
+			j = 0;
+			do {
+				j++;
+				dwc_udelay(10);
+				gintsts.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintsts);
+				if (j == 100000) {
+					DWC_ERROR("SNAK is not set during 10s\n");
+					break;
+				}
+			} while (!gintsts.b.goutnakeff);
+			gintsts.d32 = 0;
+			gintsts.b.goutnakeff = 1;
+			DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+
+			depctl.d32 = 0;
+			depctl.b.epdis = 1;
+			depctl.b.snak = 1;
+			j = 0;
+			DWC_WRITE_REG32(&core_if->dev_if->out_ep_regs[i]->doepctl, depctl.d32);
+			do {
+				dwc_udelay(10);
+				doepint.d32 = DWC_READ_REG32(&core_if->dev_if->
+					out_ep_regs[i]->doepint);
+				if (j == 100000) {
+					DWC_ERROR("EPDIS was not set during 10s\n");
+					break;
+				}
+			} while (!doepint.b.epdisabled);
+
+			doepint.b.epdisabled = 1;
+			DWC_WRITE_REG32(&core_if->dev_if->out_ep_regs[i]->doepint, doepint.d32);
+
+			dctl.d32 = 0;
+			dctl.b.cgoutnak = 1;
+			DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl, 0, dctl.d32);
+		} else {
+			depctl.d32 = 0;
+			depctl.b.snak = 1;
+		}
+
+		DWC_WRITE_REG32(&dev_if->out_ep_regs[i]->doepctl, depctl.d32);
+		DWC_WRITE_REG32(&dev_if->out_ep_regs[i]->doeptsiz, 0);
+		DWC_WRITE_REG32(&dev_if->out_ep_regs[i]->doepdma, 0);
+		DWC_WRITE_REG32(&dev_if->out_ep_regs[i]->doepint, 0xFF);
+	}
+
+	if (core_if->en_multiple_tx_fifo && core_if->dma_enable) {
+		dev_if->non_iso_tx_thr_en = params->thr_ctl & 0x1;
+		dev_if->iso_tx_thr_en = (params->thr_ctl >> 1) & 0x1;
+		dev_if->rx_thr_en = (params->thr_ctl >> 2) & 0x1;
+
+		dev_if->rx_thr_length = params->rx_thr_length;
+		dev_if->tx_thr_length = params->tx_thr_length;
+
+		dev_if->setup_desc_index = 0;
+
+		dthrctl.d32 = 0;
+		dthrctl.b.non_iso_thr_en = dev_if->non_iso_tx_thr_en;
+		dthrctl.b.iso_thr_en = dev_if->iso_tx_thr_en;
+		dthrctl.b.tx_thr_len = dev_if->tx_thr_length;
+		dthrctl.b.rx_thr_en = dev_if->rx_thr_en;
+		dthrctl.b.rx_thr_len = dev_if->rx_thr_length;
+		dthrctl.b.ahb_thr_ratio = params->ahb_thr_ratio;
+
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->dtknqr3_dthrctl,
+				dthrctl.d32);
+
+		DWC_DEBUGPL(DBG_CIL,
+			    "Non ISO Tx Thr - %d\nISO Tx Thr - %d\nRx Thr - %d\nTx Thr Len - %d\nRx Thr Len - %d\n",
+			    dthrctl.b.non_iso_thr_en, dthrctl.b.iso_thr_en,
+			    dthrctl.b.rx_thr_en, dthrctl.b.tx_thr_len,
+			    dthrctl.b.rx_thr_len);
+
+	}
+
+	dwc_otg_enable_device_interrupts(core_if);
+
+	{
+		diepmsk_data_t msk = {.d32 = 0 };
+		msk.b.txfifoundrn = 1;
+		if (core_if->multiproc_int_enable) {
+			DWC_MODIFY_REG32(&dev_if->dev_global_regs->
+					 diepeachintmsk[0], msk.d32, msk.d32);
+		} else {
+			DWC_MODIFY_REG32(&dev_if->dev_global_regs->diepmsk,
+					 msk.d32, msk.d32);
+		}
+	}
+
+	if (core_if->multiproc_int_enable) {
+		/* Set NAK on Babble */
+		dctl_data_t dctl = {.d32 = 0 };
+		dctl.b.nakonbble = 1;
+		DWC_MODIFY_REG32(&dev_if->dev_global_regs->dctl, 0, dctl.d32);
+	}
+
+	if (core_if->snpsid >= OTG_CORE_REV_2_94a) {
+		dctl_data_t dctl = {.d32 = 0 };
+		dctl.d32 = DWC_READ_REG32(&dev_if->dev_global_regs->dctl);
+		dctl.b.sftdiscon = 0;
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->dctl, dctl.d32);
+	}
+}
+
+/**
+ * This function enables the Host mode interrupts.
+ *
+ * @param core_if Programming view of DWC_otg controller
+ */
+void dwc_otg_enable_host_interrupts(dwc_otg_core_if_t * core_if)
+{
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+
+	DWC_DEBUGPL(DBG_CIL, "%s()\n", __func__);
+
+	/* Disable all interrupts. */
+	DWC_WRITE_REG32(&global_regs->gintmsk, 0);
+
+	/* Clear any pending interrupts. */
+	DWC_WRITE_REG32(&global_regs->gintsts, 0xFFFFFFFF);
+
+	/* Enable the common interrupts */
+	dwc_otg_enable_common_interrupts(core_if);
+
+	/*
+	 * Enable host mode interrupts without disturbing common
+	 * interrupts.
+	 */
+
+	intr_mask.b.disconnect = 1;
+	intr_mask.b.portintr = 1;
+	intr_mask.b.hcintr = 1;
+
+	DWC_MODIFY_REG32(&global_regs->gintmsk, intr_mask.d32, intr_mask.d32);
+}
+
+/**
+ * This function disables the Host Mode interrupts.
+ *
+ * @param core_if Programming view of DWC_otg controller
+ */
+void dwc_otg_disable_host_interrupts(dwc_otg_core_if_t * core_if)
+{
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+
+	DWC_DEBUGPL(DBG_CILV, "%s()\n", __func__);
+
+	/*
+	 * Disable host mode interrupts without disturbing common
+	 * interrupts.
+	 */
+	intr_mask.b.sofintr = 1;
+	intr_mask.b.portintr = 1;
+	intr_mask.b.hcintr = 1;
+	intr_mask.b.ptxfempty = 1;
+	intr_mask.b.nptxfempty = 1;
+
+	DWC_MODIFY_REG32(&global_regs->gintmsk, intr_mask.d32, 0);
+}
+
+/**
+ * This function initializes the DWC_otg controller registers for
+ * host mode.
+ *
+ * This function flushes the Tx and Rx FIFOs and it flushes any entries in the
+ * request queues. Host channels are reset to ensure that they are ready for
+ * performing transfers.
+ *
+ * @param core_if Programming view of DWC_otg controller
+ *
+ */
+void dwc_otg_core_host_init(dwc_otg_core_if_t * core_if)
+{
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	dwc_otg_host_if_t *host_if = core_if->host_if;
+	dwc_otg_core_params_t *params = core_if->core_params;
+	hprt0_data_t hprt0 = {.d32 = 0 };
+	fifosize_data_t nptxfifosize;
+	fifosize_data_t ptxfifosize;
+	uint16_t rxfsiz, nptxfsiz, hptxfsiz;
+	gdfifocfg_data_t gdfifocfg = {.d32 = 0 };
+	int i;
+	hcchar_data_t hcchar;
+	hcfg_data_t hcfg;
+	hfir_data_t hfir;
+	dwc_otg_hc_regs_t *hc_regs;
+	int num_channels;
+	gotgctl_data_t gotgctl = {.d32 = 0 };
+	pcgcctl_data_t pcgcctl = {.d32 = 0 };
+
+	DWC_DEBUGPL(DBG_CILV, "%s(%p)\n", __func__, core_if);
+
+	/* Restart the Phy Clock */
+	pcgcctl.b.stoppclk = 1;
+	DWC_MODIFY_REG32(core_if->pcgcctl, pcgcctl.d32, 0);
+	dwc_udelay(10);
+
+	if ((core_if->otg_ver == 1) && (core_if->op_state == A_HOST)) {
+		DWC_PRINTF("Init: Port Power? op_state=%d\n", core_if->op_state);
+		hprt0.d32 = dwc_otg_read_hprt0(core_if);
+		DWC_PRINTF("Init: Power Port (%d)\n", hprt0.b.prtpwr);
+		if (hprt0.b.prtpwr == 0) {
+			hprt0.b.prtpwr = 1;
+			DWC_WRITE_REG32(host_if->hprt0, hprt0.d32);
+		}
+	}
+
+	/* Initialize Host Configuration Register */
+	init_fslspclksel(core_if);
+	if (core_if->core_params->speed == DWC_SPEED_PARAM_FULL) {
+		hcfg.d32 = DWC_READ_REG32(&host_if->host_global_regs->hcfg);
+		hcfg.b.fslssupp = 1;
+		DWC_WRITE_REG32(&host_if->host_global_regs->hcfg, hcfg.d32);
+
+	}
+
+	/* This bit allows dynamic reloading of the HFIR register
+	 * during runtime. This bit needs to be programmed during
+	 * initial configuration and its value must not be changed
+	 * during runtime.*/
+	if (core_if->core_params->reload_ctl == 1) {
+		hfir.d32 = DWC_READ_REG32(&host_if->host_global_regs->hfir);
+		hfir.b.hfirrldctrl = 1;
+		DWC_WRITE_REG32(&host_if->host_global_regs->hfir, hfir.d32);
+	}
+
+	if (core_if->core_params->dma_desc_enable) {
+		uint8_t op_mode = core_if->hwcfg2.b.op_mode;
+		if (!
+		    (core_if->hwcfg4.b.desc_dma
+		     && (core_if->snpsid >= OTG_CORE_REV_2_90a)
+		     && ((op_mode == DWC_HWCFG2_OP_MODE_HNP_SRP_CAPABLE_OTG)
+			 || (op_mode == DWC_HWCFG2_OP_MODE_SRP_ONLY_CAPABLE_OTG)
+			 || (op_mode ==
+			     DWC_HWCFG2_OP_MODE_NO_HNP_SRP_CAPABLE_OTG)
+			 || (op_mode == DWC_HWCFG2_OP_MODE_SRP_CAPABLE_HOST)
+			 || (op_mode ==
+			     DWC_HWCFG2_OP_MODE_NO_SRP_CAPABLE_HOST)))) {
+
+			DWC_ERROR("Host can't operate in Descriptor DMA mode.\n"
+				  "Either core version is below 2.90a or "
+				  "GHWCFG2, GHWCFG4 registers' values do not allow Descriptor DMA in host mode.\n"
+				  "To run the driver in Buffer DMA host mode set dma_desc_enable "
+				  "module parameter to 0.\n");
+			return;
+		}
+		hcfg.d32 = DWC_READ_REG32(&host_if->host_global_regs->hcfg);
+		hcfg.b.descdma = 1;
+		DWC_WRITE_REG32(&host_if->host_global_regs->hcfg, hcfg.d32);
+	}
+
+	/* Configure data FIFO sizes */
+	if (core_if->hwcfg2.b.dynamic_fifo && params->enable_dynamic_fifo) {
+		DWC_DEBUGPL(DBG_CIL, "Total FIFO Size=%d\n",
+			    core_if->total_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "Rx FIFO Size=%d\n",
+			    params->host_rx_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "NP Tx FIFO Size=%d\n",
+			    params->host_nperio_tx_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "P Tx FIFO Size=%d\n",
+			    params->host_perio_tx_fifo_size);
+
+		/* Rx FIFO */
+		DWC_DEBUGPL(DBG_CIL, "initial grxfsiz=%08x\n",
+			    DWC_READ_REG32(&global_regs->grxfsiz));
+		DWC_WRITE_REG32(&global_regs->grxfsiz,
+				params->host_rx_fifo_size);
+		DWC_DEBUGPL(DBG_CIL, "new grxfsiz=%08x\n",
+			    DWC_READ_REG32(&global_regs->grxfsiz));
+
+		/* Non-periodic Tx FIFO */
+		DWC_DEBUGPL(DBG_CIL, "initial gnptxfsiz=%08x\n",
+			    DWC_READ_REG32(&global_regs->gnptxfsiz));
+		nptxfifosize.b.depth = params->host_nperio_tx_fifo_size;
+		nptxfifosize.b.startaddr = params->host_rx_fifo_size;
+		DWC_WRITE_REG32(&global_regs->gnptxfsiz, nptxfifosize.d32);
+		DWC_DEBUGPL(DBG_CIL, "new gnptxfsiz=%08x\n",
+			    DWC_READ_REG32(&global_regs->gnptxfsiz));
+
+		/* Periodic Tx FIFO */
+		DWC_DEBUGPL(DBG_CIL, "initial hptxfsiz=%08x\n",
+			    DWC_READ_REG32(&global_regs->hptxfsiz));
+		ptxfifosize.b.depth = params->host_perio_tx_fifo_size;
+		ptxfifosize.b.startaddr =
+		    nptxfifosize.b.startaddr + nptxfifosize.b.depth;
+		DWC_WRITE_REG32(&global_regs->hptxfsiz, ptxfifosize.d32);
+		DWC_DEBUGPL(DBG_CIL, "new hptxfsiz=%08x\n",
+			    DWC_READ_REG32(&global_regs->hptxfsiz));
+
+		if (core_if->en_multiple_tx_fifo) {
+			/* Global DFIFOCFG calculation for Host mode - include RxFIFO, NPTXFIFO and HPTXFIFO */
+			gdfifocfg.d32 = DWC_READ_REG32(&global_regs->gdfifocfg);
+			rxfsiz = (DWC_READ_REG32(&global_regs->grxfsiz) & 0x0000ffff);
+			nptxfsiz = (DWC_READ_REG32(&global_regs->gnptxfsiz) >> 16);
+			hptxfsiz = (DWC_READ_REG32(&global_regs->hptxfsiz) >> 16);
+			gdfifocfg.b.epinfobase = rxfsiz + nptxfsiz + hptxfsiz;
+			DWC_WRITE_REG32(&global_regs->gdfifocfg, gdfifocfg.d32);
+		}
+	}
+
+	/* TODO - check this */
+	/* Clear Host Set HNP Enable in the OTG Control Register */
+	gotgctl.b.hstsethnpen = 1;
+	DWC_MODIFY_REG32(&global_regs->gotgctl, gotgctl.d32, 0);
+	/* Make sure the FIFOs are flushed. */
+	dwc_otg_flush_tx_fifo(core_if, 0x10 /* all TX FIFOs */ );
+	dwc_otg_flush_rx_fifo(core_if);
+
+	/* Clear Host Set HNP Enable in the OTG Control Register */
+	gotgctl.b.hstsethnpen = 1;
+	DWC_MODIFY_REG32(&global_regs->gotgctl, gotgctl.d32, 0);
+
+	if (!core_if->core_params->dma_desc_enable) {
+		/* Flush out any leftover queued requests. */
+		num_channels = core_if->core_params->host_channels;
+
+		for (i = 0; i < num_channels; i++) {
+			hc_regs = core_if->host_if->hc_regs[i];
+			hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+			hcchar.b.chen = 0;
+			hcchar.b.chdis = 1;
+			hcchar.b.epdir = 0;
+			DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+		}
+
+		/* Halt all channels to put them into a known state. */
+		for (i = 0; i < num_channels; i++) {
+			int count = 0;
+			hc_regs = core_if->host_if->hc_regs[i];
+			hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+			hcchar.b.chen = 1;
+			hcchar.b.chdis = 1;
+			hcchar.b.epdir = 0;
+			DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+			DWC_DEBUGPL(DBG_HCDV, "%s: Halt channel %d\n", __func__, i);
+			do {
+				hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+				if (++count > 1000) {
+					DWC_ERROR
+					    ("%s: Unable to clear halt on channel %d\n",
+					     __func__, i);
+					break;
+				}
+				dwc_udelay(1);
+			} while (hcchar.b.chen);
+		}
+	}
+
+	/* Turn on the vbus power. */
+	if ((core_if->otg_ver == 0) && (core_if->op_state == A_HOST)) {
+		hprt0.d32 = dwc_otg_read_hprt0(core_if);
+		DWC_PRINTF("Init: Power Port (%d)\n", hprt0.b.prtpwr);
+		if (hprt0.b.prtpwr == 0) {
+			hprt0.b.prtpwr = 1;
+			DWC_WRITE_REG32(host_if->hprt0, hprt0.d32);
+		}
+	}
+
+	dwc_otg_enable_host_interrupts(core_if);
+}
+
+/**
+ * Prepares a host channel for transferring packets to/from a specific
+ * endpoint. The HCCHARn register is set up with the characteristics specified
+ * in _hc. Host channel interrupts that may need to be serviced while this
+ * transfer is in progress are enabled.
+ *
+ * @param core_if Programming view of DWC_otg controller
+ * @param hc Information needed to initialize the host channel
+ */
+void dwc_otg_hc_init(dwc_otg_core_if_t * core_if, dwc_hc_t * hc)
+{
+	uint32_t intr_enable;
+	hcintmsk_data_t hc_intr_mask;
+	gintmsk_data_t gintmsk = {.d32 = 0 };
+	hcchar_data_t hcchar;
+	hcsplt_data_t hcsplt;
+
+	uint8_t hc_num = hc->hc_num;
+	dwc_otg_host_if_t *host_if = core_if->host_if;
+	dwc_otg_hc_regs_t *hc_regs = host_if->hc_regs[hc_num];
+
+	/* Clear old interrupt conditions for this host channel. */
+	hc_intr_mask.d32 = 0xFFFFFFFF;
+	hc_intr_mask.b.reserved14_31 = 0;
+	DWC_WRITE_REG32(&hc_regs->hcint, hc_intr_mask.d32);
+
+	/* Enable channel interrupts required for this transfer. */
+	hc_intr_mask.d32 = 0;
+	hc_intr_mask.b.chhltd = 1;
+	if (core_if->dma_enable) {
+		/* For Descriptor DMA mode core halts the channel on AHB error. Interrupt is not required */
+		if (!core_if->dma_desc_enable)
+			hc_intr_mask.b.ahberr = 1;
+		else {
+			if (hc->ep_type == DWC_OTG_EP_TYPE_ISOC)
+				hc_intr_mask.b.xfercompl = 1;
+		}
+
+		if (hc->error_state && !hc->do_split &&
+		    hc->ep_type != DWC_OTG_EP_TYPE_ISOC) {
+			hc_intr_mask.b.ack = 1;
+			if (hc->ep_is_in) {
+				hc_intr_mask.b.datatglerr = 1;
+				if (hc->ep_type != DWC_OTG_EP_TYPE_INTR) {
+					hc_intr_mask.b.nak = 1;
+				}
+			}
+		}
+	} else {
+		switch (hc->ep_type) {
+		case DWC_OTG_EP_TYPE_CONTROL:
+		case DWC_OTG_EP_TYPE_BULK:
+			hc_intr_mask.b.xfercompl = 1;
+			hc_intr_mask.b.stall = 1;
+			hc_intr_mask.b.xacterr = 1;
+			hc_intr_mask.b.datatglerr = 1;
+			if (hc->ep_is_in) {
+				hc_intr_mask.b.bblerr = 1;
+			} else {
+				hc_intr_mask.b.nak = 1;
+				hc_intr_mask.b.nyet = 1;
+				if (hc->do_ping) {
+					hc_intr_mask.b.ack = 1;
+				}
+			}
+
+			if (hc->do_split) {
+				hc_intr_mask.b.nak = 1;
+				if (hc->complete_split) {
+					hc_intr_mask.b.nyet = 1;
+				} else {
+					hc_intr_mask.b.ack = 1;
+				}
+			}
+
+			if (hc->error_state) {
+				hc_intr_mask.b.ack = 1;
+			}
+			break;
+		case DWC_OTG_EP_TYPE_INTR:
+			hc_intr_mask.b.xfercompl = 1;
+			hc_intr_mask.b.nak = 1;
+			hc_intr_mask.b.stall = 1;
+			hc_intr_mask.b.xacterr = 1;
+			hc_intr_mask.b.datatglerr = 1;
+			hc_intr_mask.b.frmovrun = 1;
+
+			if (hc->ep_is_in) {
+				hc_intr_mask.b.bblerr = 1;
+			}
+			if (hc->error_state) {
+				hc_intr_mask.b.ack = 1;
+			}
+			if (hc->do_split) {
+				if (hc->complete_split) {
+					hc_intr_mask.b.nyet = 1;
+				} else {
+					hc_intr_mask.b.ack = 1;
+				}
+			}
+			break;
+		case DWC_OTG_EP_TYPE_ISOC:
+			hc_intr_mask.b.xfercompl = 1;
+			hc_intr_mask.b.frmovrun = 1;
+			hc_intr_mask.b.ack = 1;
+
+			if (hc->ep_is_in) {
+				hc_intr_mask.b.xacterr = 1;
+				hc_intr_mask.b.bblerr = 1;
+			}
+			break;
+		}
+	}
+	DWC_WRITE_REG32(&hc_regs->hcintmsk, hc_intr_mask.d32);
+
+	/* Enable the top level host channel interrupt. */
+	intr_enable = (1 << hc_num);
+	DWC_MODIFY_REG32(&host_if->host_global_regs->haintmsk, 0, intr_enable);
+
+	/* Make sure host channel interrupts are enabled. */
+	gintmsk.b.hcintr = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gintmsk, 0, gintmsk.d32);
+
+	/*
+	 * Program the HCCHARn register with the endpoint characteristics for
+	 * the current transfer.
+	 */
+	hcchar.d32 = 0;
+	hcchar.b.devaddr = hc->dev_addr;
+	hcchar.b.epnum = hc->ep_num;
+	hcchar.b.epdir = hc->ep_is_in;
+	hcchar.b.lspddev = (hc->speed == DWC_OTG_EP_SPEED_LOW);
+	hcchar.b.eptype = hc->ep_type;
+	hcchar.b.mps = hc->max_packet;
+
+	DWC_WRITE_REG32(&host_if->hc_regs[hc_num]->hcchar, hcchar.d32);
+
+	DWC_DEBUGPL(DBG_HCDV, "%s: Channel %d\n", __func__, hc->hc_num);
+	DWC_DEBUGPL(DBG_HCDV, "	 Dev Addr: %d\n", hcchar.b.devaddr);
+	DWC_DEBUGPL(DBG_HCDV, "	 Ep Num: %d\n", hcchar.b.epnum);
+	DWC_DEBUGPL(DBG_HCDV, "	 Is In: %d\n", hcchar.b.epdir);
+	DWC_DEBUGPL(DBG_HCDV, "	 Is Low Speed: %d\n", hcchar.b.lspddev);
+	DWC_DEBUGPL(DBG_HCDV, "	 Ep Type: %d\n", hcchar.b.eptype);
+	DWC_DEBUGPL(DBG_HCDV, "	 Max Pkt: %d\n", hcchar.b.mps);
+	DWC_DEBUGPL(DBG_HCDV, "	 Multi Cnt: %d\n", hcchar.b.multicnt);
+
+	/*
+	 * Program the HCSPLIT register for SPLITs
+	 */
+	hcsplt.d32 = 0;
+	if (hc->do_split) {
+		DWC_DEBUGPL(DBG_HCDV, "Programming HC %d with split --> %s\n",
+			    hc->hc_num,
+			    hc->complete_split ? "CSPLIT" : "SSPLIT");
+		hcsplt.b.compsplt = hc->complete_split;
+		hcsplt.b.xactpos = hc->xact_pos;
+		hcsplt.b.hubaddr = hc->hub_addr;
+		hcsplt.b.prtaddr = hc->port_addr;
+		DWC_DEBUGPL(DBG_HCDV, "	  comp split %d\n", hc->complete_split);
+		DWC_DEBUGPL(DBG_HCDV, "	  xact pos %d\n", hc->xact_pos);
+		DWC_DEBUGPL(DBG_HCDV, "	  hub addr %d\n", hc->hub_addr);
+		DWC_DEBUGPL(DBG_HCDV, "	  port addr %d\n", hc->port_addr);
+		DWC_DEBUGPL(DBG_HCDV, "	  is_in %d\n", hc->ep_is_in);
+		DWC_DEBUGPL(DBG_HCDV, "	  Max Pkt: %d\n", hcchar.b.mps);
+		DWC_DEBUGPL(DBG_HCDV, "	  xferlen: %d\n", hc->xfer_len);
+	}
+	DWC_WRITE_REG32(&host_if->hc_regs[hc_num]->hcsplt, hcsplt.d32);
+
+}
+
+/**
+ * Attempts to halt a host channel. This function should only be called in
+ * Slave mode or to abort a transfer in either Slave mode or DMA mode. Under
+ * normal circumstances in DMA mode, the controller halts the channel when the
+ * transfer is complete or a condition occurs that requires application
+ * intervention.
+ *
+ * In slave mode, checks for a free request queue entry, then sets the Channel
+ * Enable and Channel Disable bits of the Host Channel Characteristics
+ * register of the specified channel to intiate the halt. If there is no free
+ * request queue entry, sets only the Channel Disable bit of the HCCHARn
+ * register to flush requests for this channel. In the latter case, sets a
+ * flag to indicate that the host channel needs to be halted when a request
+ * queue slot is open.
+ *
+ * In DMA mode, always sets the Channel Enable and Channel Disable bits of the
+ * HCCHARn register. The controller ensures there is space in the request
+ * queue before submitting the halt request.
+ *
+ * Some time may elapse before the core flushes any posted requests for this
+ * host channel and halts. The Channel Halted interrupt handler completes the
+ * deactivation of the host channel.
+ *
+ * @param core_if Controller register interface.
+ * @param hc Host channel to halt.
+ * @param halt_status Reason for halting the channel.
+ */
+void dwc_otg_hc_halt(dwc_otg_core_if_t * core_if,
+		     dwc_hc_t * hc, dwc_otg_halt_status_e halt_status)
+{
+	gnptxsts_data_t nptxsts;
+	hptxsts_data_t hptxsts;
+	hcchar_data_t hcchar;
+	dwc_otg_hc_regs_t *hc_regs;
+	dwc_otg_core_global_regs_t *global_regs;
+	dwc_otg_host_global_regs_t *host_global_regs;
+
+	hc_regs = core_if->host_if->hc_regs[hc->hc_num];
+	global_regs = core_if->core_global_regs;
+	host_global_regs = core_if->host_if->host_global_regs;
+
+	DWC_ASSERT(!(halt_status == DWC_OTG_HC_XFER_NO_HALT_STATUS),
+		   "halt_status = %d\n", halt_status);
+
+	if (halt_status == DWC_OTG_HC_XFER_URB_DEQUEUE ||
+	    halt_status == DWC_OTG_HC_XFER_AHB_ERR) {
+		/*
+		 * Disable all channel interrupts except Ch Halted. The QTD
+		 * and QH state associated with this transfer has been cleared
+		 * (in the case of URB_DEQUEUE), so the channel needs to be
+		 * shut down carefully to prevent crashes.
+		 */
+		hcintmsk_data_t hcintmsk;
+		hcintmsk.d32 = 0;
+		hcintmsk.b.chhltd = 1;
+		DWC_WRITE_REG32(&hc_regs->hcintmsk, hcintmsk.d32);
+
+		/*
+		 * Make sure no other interrupts besides halt are currently
+		 * pending. Handling another interrupt could cause a crash due
+		 * to the QTD and QH state.
+		 */
+		DWC_WRITE_REG32(&hc_regs->hcint, ~hcintmsk.d32);
+
+		/*
+		 * Make sure the halt status is set to URB_DEQUEUE or AHB_ERR
+		 * even if the channel was already halted for some other
+		 * reason.
+		 */
+		hc->halt_status = halt_status;
+
+		hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+		if (hcchar.b.chen == 0) {
+			/*
+			 * The channel is either already halted or it hasn't
+			 * started yet. In DMA mode, the transfer may halt if
+			 * it finishes normally or a condition occurs that
+			 * requires driver intervention. Don't want to halt
+			 * the channel again. In either Slave or DMA mode,
+			 * it's possible that the transfer has been assigned
+			 * to a channel, but not started yet when an URB is
+			 * dequeued. Don't want to halt a channel that hasn't
+			 * started yet.
+			 */
+			return;
+		}
+	}
+	if (hc->halt_pending) {
+		/*
+		 * A halt has already been issued for this channel. This might
+		 * happen when a transfer is aborted by a higher level in
+		 * the stack.
+		 */
+#ifdef DEBUG
+		DWC_PRINTF
+		    ("*** %s: Channel %d, _hc->halt_pending already set ***\n",
+		     __func__, hc->hc_num);
+
+#endif
+		return;
+	}
+
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+
+	/* No need to set the bit in DDMA for disabling the channel */
+	//TODO check it everywhere channel is disabled
+	if (!core_if->core_params->dma_desc_enable)
+		hcchar.b.chen = 1;
+	hcchar.b.chdis = 1;
+
+	if (!core_if->dma_enable) {
+		/* Check for space in the request queue to issue the halt. */
+		if (hc->ep_type == DWC_OTG_EP_TYPE_CONTROL ||
+		    hc->ep_type == DWC_OTG_EP_TYPE_BULK) {
+			nptxsts.d32 = DWC_READ_REG32(&global_regs->gnptxsts);
+			if (nptxsts.b.nptxqspcavail == 0) {
+				hcchar.b.chen = 0;
+			}
+		} else {
+			hptxsts.d32 =
+			    DWC_READ_REG32(&host_global_regs->hptxsts);
+			if ((hptxsts.b.ptxqspcavail == 0)
+			    || (core_if->queuing_high_bandwidth)) {
+				hcchar.b.chen = 0;
+			}
+		}
+	}
+	DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+
+	hc->halt_status = halt_status;
+
+	if (hcchar.b.chen) {
+		hc->halt_pending = 1;
+		hc->halt_on_queue = 0;
+	} else {
+		hc->halt_on_queue = 1;
+	}
+
+	DWC_DEBUGPL(DBG_HCDV, "%s: Channel %d\n", __func__, hc->hc_num);
+	DWC_DEBUGPL(DBG_HCDV, "	 hcchar: 0x%08x\n", hcchar.d32);
+	DWC_DEBUGPL(DBG_HCDV, "	 halt_pending: %d\n", hc->halt_pending);
+	DWC_DEBUGPL(DBG_HCDV, "	 halt_on_queue: %d\n", hc->halt_on_queue);
+	DWC_DEBUGPL(DBG_HCDV, "	 halt_status: %d\n", hc->halt_status);
+
+	return;
+}
+
+/**
+ * Clears the transfer state for a host channel. This function is normally
+ * called after a transfer is done and the host channel is being released.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param hc Identifies the host channel to clean up.
+ */
+void dwc_otg_hc_cleanup(dwc_otg_core_if_t * core_if, dwc_hc_t * hc)
+{
+	dwc_otg_hc_regs_t *hc_regs;
+
+	hc->xfer_started = 0;
+
+	/*
+	 * Clear channel interrupt enables and any unhandled channel interrupt
+	 * conditions.
+	 */
+	hc_regs = core_if->host_if->hc_regs[hc->hc_num];
+	DWC_WRITE_REG32(&hc_regs->hcintmsk, 0);
+	DWC_WRITE_REG32(&hc_regs->hcint, 0xFFFFFFFF);
+#ifdef DEBUG
+	DWC_TIMER_CANCEL(core_if->hc_xfer_timer[hc->hc_num]);
+#endif
+}
+
+/**
+ * Sets the channel property that indicates in which frame a periodic transfer
+ * should occur. This is always set to the _next_ frame. This function has no
+ * effect on non-periodic transfers.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param hc Identifies the host channel to set up and its properties.
+ * @param hcchar Current value of the HCCHAR register for the specified host
+ * channel.
+ */
+static inline void hc_set_even_odd_frame(dwc_otg_core_if_t * core_if,
+					 dwc_hc_t * hc, hcchar_data_t * hcchar)
+{
+	if (hc->ep_type == DWC_OTG_EP_TYPE_INTR ||
+	    hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+		hfnum_data_t hfnum;
+		hfnum.d32 =
+		    DWC_READ_REG32(&core_if->host_if->host_global_regs->hfnum);
+
+		/* 1 if _next_ frame is odd, 0 if it's even */
+		hcchar->b.oddfrm = (hfnum.b.frnum & 0x1) ? 0 : 1;
+#ifdef DEBUG
+		if (hc->ep_type == DWC_OTG_EP_TYPE_INTR && hc->do_split
+		    && !hc->complete_split) {
+			switch (hfnum.b.frnum & 0x7) {
+			case 7:
+				core_if->hfnum_7_samples++;
+				core_if->hfnum_7_frrem_accum += hfnum.b.frrem;
+				break;
+			case 0:
+				core_if->hfnum_0_samples++;
+				core_if->hfnum_0_frrem_accum += hfnum.b.frrem;
+				break;
+			default:
+				core_if->hfnum_other_samples++;
+				core_if->hfnum_other_frrem_accum +=
+				    hfnum.b.frrem;
+				break;
+			}
+		}
+#endif
+	}
+}
+
+#ifdef DEBUG
+void hc_xfer_timeout(void *ptr)
+{
+	hc_xfer_info_t *xfer_info = NULL;
+	int hc_num = 0;
+
+	if (ptr)
+		xfer_info = (hc_xfer_info_t *) ptr;
+
+	if (!xfer_info->hc) {
+		DWC_ERROR("xfer_info->hc = %p\n", xfer_info->hc);
+		return;
+	}
+
+	hc_num = xfer_info->hc->hc_num;
+	DWC_WARN("%s: timeout on channel %d\n", __func__, hc_num);
+	DWC_WARN("	start_hcchar_val 0x%08x\n",
+		 xfer_info->core_if->start_hcchar_val[hc_num]);
+}
+#endif
+
+void ep_xfer_timeout(void *ptr)
+{
+	ep_xfer_info_t *xfer_info = NULL;
+	int ep_num = 0;
+	dctl_data_t dctl = {.d32 = 0 };
+	gintsts_data_t gintsts = {.d32 = 0 };
+	gintmsk_data_t gintmsk = {.d32 = 0 };
+
+	if (ptr)
+		xfer_info = (ep_xfer_info_t *) ptr;
+
+	if (!xfer_info->ep) {
+		DWC_ERROR("xfer_info->ep = %p\n", xfer_info->ep);
+		return;
+	}
+
+	ep_num = xfer_info->ep->num;
+	DWC_WARN("%s: timeout on endpoit %d\n", __func__, ep_num);
+	/* Put the sate to 2 as it was time outed */
+	xfer_info->state = 2;
+
+	dctl.d32 =
+	    DWC_READ_REG32(&xfer_info->core_if->dev_if->dev_global_regs->dctl);
+	gintsts.d32 =
+	    DWC_READ_REG32(&xfer_info->core_if->core_global_regs->gintsts);
+	gintmsk.d32 =
+	    DWC_READ_REG32(&xfer_info->core_if->core_global_regs->gintmsk);
+
+	if (!gintmsk.b.goutnakeff) {
+		/* Unmask it */
+		gintmsk.b.goutnakeff = 1;
+		DWC_WRITE_REG32(&xfer_info->core_if->core_global_regs->gintmsk,
+				gintmsk.d32);
+
+	}
+
+	if (!gintsts.b.goutnakeff) {
+		dctl.b.sgoutnak = 1;
+	}
+	DWC_WRITE_REG32(&xfer_info->core_if->dev_if->dev_global_regs->dctl,
+			dctl.d32);
+
+}
+
+void set_pid_isoc(dwc_hc_t * hc)
+{
+	/* Set up the initial PID for the transfer. */
+	if (hc->speed == DWC_OTG_EP_SPEED_HIGH) {
+		if (hc->ep_is_in) {
+			if (hc->multi_count == 1) {
+				hc->data_pid_start = DWC_OTG_HC_PID_DATA0;
+			} else if (hc->multi_count == 2) {
+				hc->data_pid_start = DWC_OTG_HC_PID_DATA1;
+			} else {
+				hc->data_pid_start = DWC_OTG_HC_PID_DATA2;
+			}
+		} else {
+			if (hc->multi_count == 1) {
+				hc->data_pid_start = DWC_OTG_HC_PID_DATA0;
+			} else {
+				hc->data_pid_start = DWC_OTG_HC_PID_MDATA;
+			}
+		}
+	} else {
+		hc->data_pid_start = DWC_OTG_HC_PID_DATA0;
+	}
+}
+
+/**
+ * This function does the setup for a data transfer for a host channel and
+ * starts the transfer. May be called in either Slave mode or DMA mode. In
+ * Slave mode, the caller must ensure that there is sufficient space in the
+ * request queue and Tx Data FIFO.
+ *
+ * For an OUT transfer in Slave mode, it loads a data packet into the
+ * appropriate FIFO. If necessary, additional data packets will be loaded in
+ * the Host ISR.
+ *
+ * For an IN transfer in Slave mode, a data packet is requested. The data
+ * packets are unloaded from the Rx FIFO in the Host ISR. If necessary,
+ * additional data packets are requested in the Host ISR.
+ *
+ * For a PING transfer in Slave mode, the Do Ping bit is set in the HCTSIZ
+ * register along with a packet count of 1 and the channel is enabled. This
+ * causes a single PING transaction to occur. Other fields in HCTSIZ are
+ * simply set to 0 since no data transfer occurs in this case.
+ *
+ * For a PING transfer in DMA mode, the HCTSIZ register is initialized with
+ * all the information required to perform the subsequent data transfer. In
+ * addition, the Do Ping bit is set in the HCTSIZ register. In this case, the
+ * controller performs the entire PING protocol, then starts the data
+ * transfer.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param hc Information needed to initialize the host channel. The xfer_len
+ * value may be reduced to accommodate the max widths of the XferSize and
+ * PktCnt fields in the HCTSIZn register. The multi_count value may be changed
+ * to reflect the final xfer_len value.
+ */
+void dwc_otg_hc_start_transfer(dwc_otg_core_if_t * core_if, dwc_hc_t * hc)
+{
+	hcchar_data_t hcchar;
+	hctsiz_data_t hctsiz;
+	uint16_t num_packets;
+	uint32_t max_hc_xfer_size = core_if->core_params->max_transfer_size;
+	uint16_t max_hc_pkt_count = core_if->core_params->max_packet_count;
+	dwc_otg_hc_regs_t *hc_regs = core_if->host_if->hc_regs[hc->hc_num];
+
+	hctsiz.d32 = 0;
+
+	if (hc->do_ping) {
+		if (!core_if->dma_enable) {
+			dwc_otg_hc_do_ping(core_if, hc);
+			hc->xfer_started = 1;
+			return;
+		} else {
+			hctsiz.b.dopng = 1;
+		}
+	}
+
+	if (hc->do_split) {
+		num_packets = 1;
+
+		if (hc->complete_split && !hc->ep_is_in) {
+			/* For CSPLIT OUT Transfer, set the size to 0 so the
+			 * core doesn't expect any data written to the FIFO */
+			hc->xfer_len = 0;
+		} else if (hc->ep_is_in || (hc->xfer_len > hc->max_packet)) {
+			hc->xfer_len = hc->max_packet;
+		} else if (!hc->ep_is_in && (hc->xfer_len > 188)) {
+			hc->xfer_len = 188;
+		}
+
+		hctsiz.b.xfersize = hc->xfer_len;
+	} else {
+		/*
+		 * Ensure that the transfer length and packet count will fit
+		 * in the widths allocated for them in the HCTSIZn register.
+		 */
+		if (hc->ep_type == DWC_OTG_EP_TYPE_INTR ||
+		    hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+			/*
+			 * Make sure the transfer size is no larger than one
+			 * (micro)frame's worth of data. (A check was done
+			 * when the periodic transfer was accepted to ensure
+			 * that a (micro)frame's worth of data can be
+			 * programmed into a channel.)
+			 */
+			uint32_t max_periodic_len =
+			    hc->multi_count * hc->max_packet;
+			if (hc->xfer_len > max_periodic_len) {
+				hc->xfer_len = max_periodic_len;
+			} else {
+			}
+		} else if (hc->xfer_len > max_hc_xfer_size) {
+			/* Make sure that xfer_len is a multiple of max packet size. */
+			hc->xfer_len = max_hc_xfer_size - hc->max_packet + 1;
+		}
+
+		if (hc->xfer_len > 0) {
+			num_packets =
+			    (hc->xfer_len + hc->max_packet -
+			     1) / hc->max_packet;
+			if (num_packets > max_hc_pkt_count) {
+				num_packets = max_hc_pkt_count;
+				hc->xfer_len = num_packets * hc->max_packet;
+			}
+		} else {
+			/* Need 1 packet for transfer length of 0. */
+			num_packets = 1;
+		}
+
+		if (hc->ep_is_in) {
+			/* Always program an integral # of max packets for IN transfers. */
+			hc->xfer_len = num_packets * hc->max_packet;
+		}
+
+		if (hc->ep_type == DWC_OTG_EP_TYPE_INTR ||
+		    hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+			/*
+			 * Make sure that the multi_count field matches the
+			 * actual transfer length.
+			 */
+			hc->multi_count = num_packets;
+		}
+
+		if (hc->ep_type == DWC_OTG_EP_TYPE_ISOC)
+			set_pid_isoc(hc);
+
+		hctsiz.b.xfersize = hc->xfer_len;
+	}
+
+	hc->start_pkt_count = num_packets;
+	hctsiz.b.pktcnt = num_packets;
+	hctsiz.b.pid = hc->data_pid_start;
+	DWC_WRITE_REG32(&hc_regs->hctsiz, hctsiz.d32);
+
+	DWC_DEBUGPL(DBG_HCDV, "%s: Channel %d\n", __func__, hc->hc_num);
+	DWC_DEBUGPL(DBG_HCDV, "	 Xfer Size: %d\n", hctsiz.b.xfersize);
+	DWC_DEBUGPL(DBG_HCDV, "	 Num Pkts: %d\n", hctsiz.b.pktcnt);
+	DWC_DEBUGPL(DBG_HCDV, "	 Start PID: %d\n", hctsiz.b.pid);
+
+	if (core_if->dma_enable) {
+		dwc_dma_t dma_addr;
+		if (hc->align_buff) {
+			dma_addr = hc->align_buff;
+		} else {
+			dma_addr = ((unsigned long)hc->xfer_buff & 0xffffffff);
+		}
+		DWC_WRITE_REG32(&hc_regs->hcdma, dma_addr);
+	}
+
+	/* Start the split */
+	if (hc->do_split) {
+		hcsplt_data_t hcsplt;
+		hcsplt.d32 = DWC_READ_REG32(&hc_regs->hcsplt);
+		hcsplt.b.spltena = 1;
+		DWC_WRITE_REG32(&hc_regs->hcsplt, hcsplt.d32);
+	}
+
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	hcchar.b.multicnt = hc->multi_count;
+	hc_set_even_odd_frame(core_if, hc, &hcchar);
+#ifdef DEBUG
+	core_if->start_hcchar_val[hc->hc_num] = hcchar.d32;
+	if (hcchar.b.chdis) {
+		DWC_WARN("%s: chdis set, channel %d, hcchar 0x%08x\n",
+			 __func__, hc->hc_num, hcchar.d32);
+	}
+#endif
+
+	/* Set host channel enable after all other setup is complete. */
+	hcchar.b.chen = 1;
+	hcchar.b.chdis = 0;
+	DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+
+	hc->xfer_started = 1;
+	hc->requests++;
+
+	if (!core_if->dma_enable && !hc->ep_is_in && hc->xfer_len > 0) {
+		/* Load OUT packet into the appropriate Tx FIFO. */
+		dwc_otg_hc_write_packet(core_if, hc);
+	}
+#ifdef DEBUG
+	if (hc->ep_type != DWC_OTG_EP_TYPE_INTR) {
+		core_if->hc_xfer_info[hc->hc_num].core_if = core_if;
+		core_if->hc_xfer_info[hc->hc_num].hc = hc;
+
+		/* Start a timer for this transfer. */
+		DWC_TIMER_SCHEDULE(core_if->hc_xfer_timer[hc->hc_num], 10000);
+	}
+#endif
+}
+
+/**
+ * This function does the setup for a data transfer for a host channel
+ * and starts the transfer in Descriptor DMA mode.
+ *
+ * Initializes HCTSIZ register. For a PING transfer the Do Ping bit is set.
+ * Sets PID and NTD values. For periodic transfers
+ * initializes SCHED_INFO field with micro-frame bitmap.
+ *
+ * Initializes HCDMA register with descriptor list address and CTD value
+ * then starts the transfer via enabling the channel.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param hc Information needed to initialize the host channel.
+ */
+void dwc_otg_hc_start_transfer_ddma(dwc_otg_core_if_t * core_if, dwc_hc_t * hc)
+{
+	dwc_otg_hc_regs_t *hc_regs = core_if->host_if->hc_regs[hc->hc_num];
+	hcchar_data_t hcchar;
+	hctsiz_data_t hctsiz;
+	hcdma_data_t hcdma;
+
+	hctsiz.d32 = 0;
+
+	if (hc->do_ping)
+		hctsiz.b_ddma.dopng = 1;
+
+	if (hc->ep_type == DWC_OTG_EP_TYPE_ISOC)
+		set_pid_isoc(hc);
+
+	/* Packet Count and Xfer Size are not used in Descriptor DMA mode */
+	hctsiz.b_ddma.pid = hc->data_pid_start;
+	hctsiz.b_ddma.ntd = hc->ntd - 1;	/* 0 - 1 descriptor, 1 - 2 descriptors, etc. */
+	hctsiz.b_ddma.schinfo = hc->schinfo;	/* Non-zero only for high-speed interrupt endpoints */
+
+	DWC_DEBUGPL(DBG_HCDV, "%s: Channel %d\n", __func__, hc->hc_num);
+	DWC_DEBUGPL(DBG_HCDV, "	 Start PID: %d\n", hctsiz.b.pid);
+	DWC_DEBUGPL(DBG_HCDV, "	 NTD: %d\n", hctsiz.b_ddma.ntd);
+
+	DWC_WRITE_REG32(&hc_regs->hctsiz, hctsiz.d32);
+
+	hcdma.d32 = 0;
+	hcdma.b.dma_addr = ((uint32_t) hc->desc_list_addr) >> 11;
+
+	/* Always start from first descriptor. */
+	hcdma.b.ctd = 0;
+	DWC_WRITE_REG32(&hc_regs->hcdma, hcdma.d32);
+
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	hcchar.b.multicnt = hc->multi_count;
+
+#ifdef DEBUG
+	core_if->start_hcchar_val[hc->hc_num] = hcchar.d32;
+	if (hcchar.b.chdis) {
+		DWC_WARN("%s: chdis set, channel %d, hcchar 0x%08x\n",
+			 __func__, hc->hc_num, hcchar.d32);
+	}
+#endif
+
+	/* Set host channel enable after all other setup is complete. */
+	hcchar.b.chen = 1;
+	hcchar.b.chdis = 0;
+
+	DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+
+	hc->xfer_started = 1;
+	hc->requests++;
+
+#ifdef DEBUG
+	if ((hc->ep_type != DWC_OTG_EP_TYPE_INTR)
+	    && (hc->ep_type != DWC_OTG_EP_TYPE_ISOC)) {
+		core_if->hc_xfer_info[hc->hc_num].core_if = core_if;
+		core_if->hc_xfer_info[hc->hc_num].hc = hc;
+		/* Start a timer for this transfer. */
+		DWC_TIMER_SCHEDULE(core_if->hc_xfer_timer[hc->hc_num], 10000);
+	}
+#endif
+
+}
+
+/**
+ * This function continues a data transfer that was started by previous call
+ * to <code>dwc_otg_hc_start_transfer</code>. The caller must ensure there is
+ * sufficient space in the request queue and Tx Data FIFO. This function
+ * should only be called in Slave mode. In DMA mode, the controller acts
+ * autonomously to complete transfers programmed to a host channel.
+ *
+ * For an OUT transfer, a new data packet is loaded into the appropriate FIFO
+ * if there is any data remaining to be queued. For an IN transfer, another
+ * data packet is always requested. For the SETUP phase of a control transfer,
+ * this function does nothing.
+ *
+ * @return 1 if a new request is queued, 0 if no more requests are required
+ * for this transfer.
+ */
+int dwc_otg_hc_continue_transfer(dwc_otg_core_if_t * core_if, dwc_hc_t * hc)
+{
+	DWC_DEBUGPL(DBG_HCDV, "%s: Channel %d\n", __func__, hc->hc_num);
+
+	if (hc->do_split) {
+		/* SPLITs always queue just once per channel */
+		return 0;
+	} else if (hc->data_pid_start == DWC_OTG_HC_PID_SETUP) {
+		/* SETUPs are queued only once since they can't be NAKed. */
+		return 0;
+	} else if (hc->ep_is_in) {
+		/*
+		 * Always queue another request for other IN transfers. If
+		 * back-to-back INs are issued and NAKs are received for both,
+		 * the driver may still be processing the first NAK when the
+		 * second NAK is received. When the interrupt handler clears
+		 * the NAK interrupt for the first NAK, the second NAK will
+		 * not be seen. So we can't depend on the NAK interrupt
+		 * handler to requeue a NAKed request. Instead, IN requests
+		 * are issued each time this function is called. When the
+		 * transfer completes, the extra requests for the channel will
+		 * be flushed.
+		 */
+		hcchar_data_t hcchar;
+		dwc_otg_hc_regs_t *hc_regs =
+		    core_if->host_if->hc_regs[hc->hc_num];
+
+		hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+		hc_set_even_odd_frame(core_if, hc, &hcchar);
+		hcchar.b.chen = 1;
+		hcchar.b.chdis = 0;
+		DWC_DEBUGPL(DBG_HCDV, "	 IN xfer: hcchar = 0x%08x\n",
+			    hcchar.d32);
+		DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+		hc->requests++;
+		return 1;
+	} else {
+		/* OUT transfers. */
+		if (hc->xfer_count < hc->xfer_len) {
+			if (hc->ep_type == DWC_OTG_EP_TYPE_INTR ||
+			    hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+				hcchar_data_t hcchar;
+				dwc_otg_hc_regs_t *hc_regs;
+				hc_regs = core_if->host_if->hc_regs[hc->hc_num];
+				hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+				hc_set_even_odd_frame(core_if, hc, &hcchar);
+			}
+
+			/* Load OUT packet into the appropriate Tx FIFO. */
+			dwc_otg_hc_write_packet(core_if, hc);
+			hc->requests++;
+			return 1;
+		} else {
+			return 0;
+		}
+	}
+}
+
+/**
+ * Starts a PING transfer. This function should only be called in Slave mode.
+ * The Do Ping bit is set in the HCTSIZ register, then the channel is enabled.
+ */
+void dwc_otg_hc_do_ping(dwc_otg_core_if_t * core_if, dwc_hc_t * hc)
+{
+	hcchar_data_t hcchar;
+	hctsiz_data_t hctsiz;
+	dwc_otg_hc_regs_t *hc_regs = core_if->host_if->hc_regs[hc->hc_num];
+
+	DWC_DEBUGPL(DBG_HCDV, "%s: Channel %d\n", __func__, hc->hc_num);
+
+	hctsiz.d32 = 0;
+	hctsiz.b.dopng = 1;
+	hctsiz.b.pktcnt = 1;
+	DWC_WRITE_REG32(&hc_regs->hctsiz, hctsiz.d32);
+
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	hcchar.b.chen = 1;
+	hcchar.b.chdis = 0;
+	DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+}
+
+/*
+ * This function writes a packet into the Tx FIFO associated with the Host
+ * Channel. For a channel associated with a non-periodic EP, the non-periodic
+ * Tx FIFO is written. For a channel associated with a periodic EP, the
+ * periodic Tx FIFO is written. This function should only be called in Slave
+ * mode.
+ *
+ * Upon return the xfer_buff and xfer_count fields in _hc are incremented by
+ * then number of bytes written to the Tx FIFO.
+ */
+void dwc_otg_hc_write_packet(dwc_otg_core_if_t * core_if, dwc_hc_t * hc)
+{
+	uint32_t i;
+	uint32_t remaining_count;
+	uint32_t byte_count;
+	uint32_t dword_count;
+
+	uint32_t *data_buff = (uint32_t *) (hc->xfer_buff);
+	uint32_t *data_fifo = core_if->data_fifo[hc->hc_num];
+
+	remaining_count = hc->xfer_len - hc->xfer_count;
+	if (remaining_count > hc->max_packet) {
+		byte_count = hc->max_packet;
+	} else {
+		byte_count = remaining_count;
+	}
+
+	dword_count = (byte_count + 3) / 4;
+
+	if ((((unsigned long)data_buff) & 0x3) == 0) {
+		/* xfer_buff is DWORD aligned. */
+		for (i = 0; i < dword_count; i++, data_buff++) {
+			DWC_WRITE_REG32(data_fifo, *data_buff);
+		}
+	} else {
+		/* xfer_buff is not DWORD aligned. */
+		for (i = 0; i < dword_count; i++, data_buff++) {
+			uint32_t data;
+			data =
+			    (data_buff[0] | data_buff[1] << 8 | data_buff[2] <<
+			     16 | data_buff[3] << 24);
+			DWC_WRITE_REG32(data_fifo, data);
+		}
+	}
+
+	hc->xfer_count += byte_count;
+	hc->xfer_buff += byte_count;
+}
+
+/**
+ * Gets the current USB frame number. This is the frame number from the last
+ * SOF packet.
+ */
+uint32_t dwc_otg_get_frame_number(dwc_otg_core_if_t * core_if)
+{
+	dsts_data_t dsts;
+	dsts.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dsts);
+
+	/* read current frame/microframe number from DSTS register */
+	return dsts.b.soffn;
+}
+
+/**
+ * Calculates and gets the frame Interval value of HFIR register according PHY
+ * type and speed.The application can modify a value of HFIR register only after
+ * the Port Enable bit of the Host Port Control and Status register
+ * (HPRT.PrtEnaPort) has been set.
+*/
+
+uint32_t calc_frame_interval(dwc_otg_core_if_t * core_if)
+{
+	gusbcfg_data_t usbcfg;
+	hwcfg2_data_t hwcfg2;
+	hprt0_data_t hprt0;
+	int clock = 60;		// default value
+	usbcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+	hwcfg2.d32 = DWC_READ_REG32(&core_if->core_global_regs->ghwcfg2);
+	hprt0.d32 = DWC_READ_REG32(core_if->host_if->hprt0);
+	if (!usbcfg.b.physel && usbcfg.b.ulpi_utmi_sel && !usbcfg.b.phyif)
+		clock = 60;
+	if (usbcfg.b.physel && hwcfg2.b.fs_phy_type == 3)
+		clock = 48;
+	if (!usbcfg.b.phylpwrclksel && !usbcfg.b.physel &&
+	    !usbcfg.b.ulpi_utmi_sel && usbcfg.b.phyif)
+		clock = 30;
+	if (!usbcfg.b.phylpwrclksel && !usbcfg.b.physel &&
+	    !usbcfg.b.ulpi_utmi_sel && !usbcfg.b.phyif)
+		clock = 60;
+	if (usbcfg.b.phylpwrclksel && !usbcfg.b.physel &&
+	    !usbcfg.b.ulpi_utmi_sel && usbcfg.b.phyif)
+		clock = 48;
+	if (usbcfg.b.physel && !usbcfg.b.phyif && hwcfg2.b.fs_phy_type == 2)
+		clock = 48;
+	if (usbcfg.b.physel && hwcfg2.b.fs_phy_type == 1)
+		clock = 48;
+	if (hprt0.b.prtspd == 0)
+		/* High speed case */
+		return 125 * clock;
+	else
+		/* FS/LS case */
+		return 1000 * clock;
+}
+
+/**
+ * This function reads a setup packet from the Rx FIFO into the destination
+ * buffer. This function is called from the Rx Status Queue Level (RxStsQLvl)
+ * Interrupt routine when a SETUP packet has been received in Slave mode.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param dest Destination buffer for packet data.
+ */
+void dwc_otg_read_setup_packet(dwc_otg_core_if_t * core_if, uint32_t * dest)
+{
+	device_grxsts_data_t status;
+	/* Get the 8 bytes of a setup transaction data */
+
+	/* Pop 2 DWORDS off the receive data FIFO into memory */
+	dest[0] = DWC_READ_REG32(core_if->data_fifo[0]);
+	dest[1] = DWC_READ_REG32(core_if->data_fifo[0]);
+	if (core_if->snpsid >= OTG_CORE_REV_3_00a) {
+		status.d32 =
+		    DWC_READ_REG32(&core_if->core_global_regs->grxstsp);
+		DWC_DEBUGPL(DBG_ANY,
+			    "EP:%d BCnt:%d " "pktsts:%x Frame:%d(0x%0x)\n",
+			    status.b.epnum, status.b.bcnt, status.b.pktsts,
+			    status.b.fn, status.b.fn);
+	}
+}
+
+/**
+ * This function enables EP0 OUT to receive SETUP packets and configures EP0
+ * IN for transmitting packets. It is normally called when the
+ * "Enumeration Done" interrupt occurs.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP0 data.
+ */
+void dwc_otg_ep0_activate(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	dsts_data_t dsts;
+	depctl_data_t diepctl;
+	depctl_data_t doepctl;
+	dctl_data_t dctl = {.d32 = 0 };
+
+	ep->stp_rollover = 0;
+	/* Read the Device Status and Endpoint 0 Control registers */
+	dsts.d32 = DWC_READ_REG32(&dev_if->dev_global_regs->dsts);
+	diepctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[0]->diepctl);
+	doepctl.d32 = DWC_READ_REG32(&dev_if->out_ep_regs[0]->doepctl);
+
+	/* Set the MPS of the IN EP based on the enumeration speed */
+	switch (dsts.b.enumspd) {
+	case DWC_DSTS_ENUMSPD_HS_PHY_30MHZ_OR_60MHZ:
+	case DWC_DSTS_ENUMSPD_FS_PHY_30MHZ_OR_60MHZ:
+	case DWC_DSTS_ENUMSPD_FS_PHY_48MHZ:
+		diepctl.b.mps = DWC_DEP0CTL_MPS_64;
+		break;
+	case DWC_DSTS_ENUMSPD_LS_PHY_6MHZ:
+		diepctl.b.mps = DWC_DEP0CTL_MPS_8;
+		break;
+	}
+
+	DWC_WRITE_REG32(&dev_if->in_ep_regs[0]->diepctl, diepctl.d32);
+
+	/* Enable OUT EP for receive */
+	if (core_if->snpsid <= OTG_CORE_REV_2_94a) {
+		doepctl.b.epena = 1;
+		DWC_WRITE_REG32(&dev_if->out_ep_regs[0]->doepctl, doepctl.d32);
+	}
+#ifdef VERBOSE
+	DWC_DEBUGPL(DBG_PCDV, "doepctl0=%0x\n",
+		    DWC_READ_REG32(&dev_if->out_ep_regs[0]->doepctl));
+	DWC_DEBUGPL(DBG_PCDV, "diepctl0=%0x\n",
+		    DWC_READ_REG32(&dev_if->in_ep_regs[0]->diepctl));
+#endif
+	dctl.b.cgnpinnak = 1;
+
+	DWC_MODIFY_REG32(&dev_if->dev_global_regs->dctl, dctl.d32, dctl.d32);
+	DWC_DEBUGPL(DBG_PCDV, "dctl=%0x\n",
+		    DWC_READ_REG32(&dev_if->dev_global_regs->dctl));
+
+}
+
+/**
+ * This function activates an EP.  The Device EP control register for
+ * the EP is configured as defined in the ep structure. Note: This
+ * function is not used for EP0.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to activate.
+ */
+void dwc_otg_ep_activate(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	depctl_data_t depctl;
+	volatile uint32_t *addr;
+	daint_data_t daintmsk = {.d32 = 0 };
+	dcfg_data_t dcfg;
+	uint8_t i;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s() EP%d-%s\n", __func__, ep->num,
+		    (ep->is_in ? "IN" : "OUT"));
+
+#ifdef DWC_UTE_PER_IO
+	ep->xiso_frame_num = 0xFFFFFFFF;
+	ep->xiso_active_xfers = 0;
+	ep->xiso_queued_xfers = 0;
+#endif
+	/* Read DEPCTLn register */
+	if (ep->is_in == 1) {
+		addr = &dev_if->in_ep_regs[ep->num]->diepctl;
+		daintmsk.ep.in = 1 << ep->num;
+	} else {
+		addr = &dev_if->out_ep_regs[ep->num]->doepctl;
+		daintmsk.ep.out = 1 << ep->num;
+	}
+
+	/* If the EP is already active don't change the EP Control
+	 * register. */
+	depctl.d32 = DWC_READ_REG32(addr);
+	if (!depctl.b.usbactep) {
+		depctl.b.mps = ep->maxpacket;
+		depctl.b.eptype = ep->type;
+		depctl.b.txfnum = ep->tx_fifo_num;
+
+		if (ep->type == DWC_OTG_EP_TYPE_ISOC) {
+			depctl.b.setd0pid = 1;	// ???
+		} else {
+			depctl.b.setd0pid = 1;
+		}
+		depctl.b.usbactep = 1;
+
+		/* Update nextep_seq array and EPMSCNT in DCFG */
+		if (!(depctl.b.eptype & 1) && (ep->is_in == 1)) {	// NP IN EP
+			for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+				if (core_if->nextep_seq[i] == core_if->first_in_nextep_seq)
+					break;
+			}
+			core_if->nextep_seq[i] = ep->num;
+			core_if->nextep_seq[ep->num] = core_if->first_in_nextep_seq;
+			depctl.b.nextep = core_if->nextep_seq[ep->num];
+			dcfg.d32 = DWC_READ_REG32(&dev_if->dev_global_regs->dcfg);
+			dcfg.b.epmscnt++;
+			DWC_WRITE_REG32(&dev_if->dev_global_regs->dcfg, dcfg.d32);
+
+			DWC_DEBUGPL(DBG_PCDV,
+				    "%s first_in_nextep_seq= %2d; nextep_seq[]:\n",
+				    __func__, core_if->first_in_nextep_seq);
+			for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+				DWC_DEBUGPL(DBG_PCDV, "%2d\n",
+					    core_if->nextep_seq[i]);
+			}
+
+		}
+
+
+		DWC_WRITE_REG32(addr, depctl.d32);
+		DWC_DEBUGPL(DBG_PCDV, "DEPCTL=%08x\n", DWC_READ_REG32(addr));
+	}
+
+	/* Enable the Interrupt for this EP */
+	if (core_if->multiproc_int_enable) {
+		if (ep->is_in == 1) {
+			diepmsk_data_t diepmsk = {.d32 = 0 };
+			diepmsk.b.xfercompl = 1;
+			diepmsk.b.timeout = 1;
+			diepmsk.b.epdisabled = 1;
+			diepmsk.b.ahberr = 1;
+			diepmsk.b.intknepmis = 1;
+			if (!core_if->en_multiple_tx_fifo && core_if->dma_enable)
+				diepmsk.b.intknepmis = 0;
+			diepmsk.b.txfifoundrn = 1;	//?????
+			if (ep->type == DWC_OTG_EP_TYPE_ISOC) {
+				diepmsk.b.nak = 1;
+			}
+
+/*
+			if (core_if->dma_desc_enable) {
+				diepmsk.b.bna = 1;
+			}
+*/
+/*
+			if (core_if->dma_enable) {
+				doepmsk.b.nak = 1;
+			}
+*/
+			DWC_WRITE_REG32(&dev_if->dev_global_regs->
+					diepeachintmsk[ep->num], diepmsk.d32);
+
+		} else {
+			doepmsk_data_t doepmsk = {.d32 = 0 };
+			doepmsk.b.xfercompl = 1;
+			doepmsk.b.ahberr = 1;
+			doepmsk.b.epdisabled = 1;
+			if (ep->type == DWC_OTG_EP_TYPE_ISOC)
+				doepmsk.b.outtknepdis = 1;
+
+/*
+
+			if (core_if->dma_desc_enable) {
+				doepmsk.b.bna = 1;
+			}
+*/
+/*
+			doepmsk.b.babble = 1;
+			doepmsk.b.nyet = 1;
+			doepmsk.b.nak = 1;
+*/
+			DWC_WRITE_REG32(&dev_if->dev_global_regs->
+					doepeachintmsk[ep->num], doepmsk.d32);
+		}
+		DWC_MODIFY_REG32(&dev_if->dev_global_regs->deachintmsk,
+				 0, daintmsk.d32);
+	} else {
+		if (ep->type == DWC_OTG_EP_TYPE_ISOC) {
+			if (ep->is_in) {
+				diepmsk_data_t diepmsk = {.d32 = 0 };
+				diepmsk.b.nak = 1;
+				DWC_MODIFY_REG32(&dev_if->dev_global_regs->diepmsk, 0, diepmsk.d32);
+			} else {
+				doepmsk_data_t doepmsk = {.d32 = 0 };
+				doepmsk.b.outtknepdis = 1;
+				DWC_MODIFY_REG32(&dev_if->dev_global_regs->doepmsk, 0, doepmsk.d32);
+			}
+		}
+		DWC_MODIFY_REG32(&dev_if->dev_global_regs->daintmsk,
+				 0, daintmsk.d32);
+	}
+
+	DWC_DEBUGPL(DBG_PCDV, "DAINTMSK=%0x\n",
+		    DWC_READ_REG32(&dev_if->dev_global_regs->daintmsk));
+
+	ep->stall_clear_flag = 0;
+
+	return;
+}
+
+/**
+ * This function deactivates an EP. This is done by clearing the USB Active
+ * EP bit in the Device EP control register. Note: This function is not used
+ * for EP0. EP0 cannot be deactivated.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to deactivate.
+ */
+void dwc_otg_ep_deactivate(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	depctl_data_t depctl = {.d32 = 0 };
+	volatile uint32_t *addr;
+	daint_data_t daintmsk = {.d32 = 0 };
+	dcfg_data_t dcfg;
+	uint8_t i = 0;
+
+#ifdef DWC_UTE_PER_IO
+	ep->xiso_frame_num = 0xFFFFFFFF;
+	ep->xiso_active_xfers = 0;
+	ep->xiso_queued_xfers = 0;
+#endif
+
+	/* Read DEPCTLn register */
+	if (ep->is_in == 1) {
+		addr = &core_if->dev_if->in_ep_regs[ep->num]->diepctl;
+		daintmsk.ep.in = 1 << ep->num;
+	} else {
+		addr = &core_if->dev_if->out_ep_regs[ep->num]->doepctl;
+		daintmsk.ep.out = 1 << ep->num;
+	}
+
+	depctl.d32 = DWC_READ_REG32(addr);
+
+	depctl.b.usbactep = 0;
+
+	/* Update nextep_seq array and EPMSCNT in DCFG */
+	if (!(depctl.b.eptype & 1) && ep->is_in == 1) {	// NP EP IN
+		for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+			if (core_if->nextep_seq[i] == ep->num)
+				break;
+		}
+		core_if->nextep_seq[i] = core_if->nextep_seq[ep->num];
+		if (core_if->first_in_nextep_seq == ep->num)
+			core_if->first_in_nextep_seq = i;
+		core_if->nextep_seq[ep->num] = 0xff;
+		depctl.b.nextep = 0;
+		dcfg.d32 =
+		    DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dcfg);
+		dcfg.b.epmscnt--;
+		DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dcfg,
+				dcfg.d32);
+
+		DWC_DEBUGPL(DBG_PCDV,
+			    "%s first_in_nextep_seq= %2d; nextep_seq[]:\n",
+			    __func__, core_if->first_in_nextep_seq);
+		for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+			DWC_DEBUGPL(DBG_PCDV, "%2d\n", core_if->nextep_seq[i]);
+		}
+	}
+
+	if (ep->is_in == 1)
+		depctl.b.txfnum = 0;
+
+	if (core_if->dma_desc_enable)
+		depctl.b.epdis = 1;
+
+	DWC_WRITE_REG32(addr, depctl.d32);
+	depctl.d32 = DWC_READ_REG32(addr);
+	if (core_if->dma_enable && depctl.b.epena) {
+		depctl_data_t depctl = {.d32 = 0 };
+		if (ep->is_in) {
+			diepint_data_t diepint = {.d32 = 0 };
+
+			depctl.b.snak = 1;
+			DWC_WRITE_REG32(&core_if->dev_if->in_ep_regs[ep->num]->
+					diepctl, depctl.d32);
+/*			do { */
+				dwc_udelay(10);
+				diepint.d32 =
+				    DWC_READ_REG32(&core_if->
+						   dev_if->in_ep_regs[ep->num]->
+						   diepint);
+/*			} while (!diepint.b.inepnakeff); */
+			diepint.b.inepnakeff = 1;
+			DWC_WRITE_REG32(&core_if->dev_if->in_ep_regs[ep->num]->
+					diepint, diepint.d32);
+			depctl.d32 = 0;
+			depctl.b.epdis = 1;
+			DWC_WRITE_REG32(&core_if->dev_if->in_ep_regs[ep->num]->
+					diepctl, depctl.d32);
+/*			do {  */
+				dwc_udelay(10);
+				diepint.d32 =
+				    DWC_READ_REG32(&core_if->
+						   dev_if->in_ep_regs[ep->num]->
+						   diepint);
+/*			} while (!diepint.b.epdisabled); */
+			diepint.b.epdisabled = 1;
+			DWC_WRITE_REG32(&core_if->dev_if->in_ep_regs[ep->num]->
+					diepint, diepint.d32);
+		} else if (ep->type == DWC_OTG_EP_TYPE_ISOC) {
+			dctl_data_t dctl = {.d32 = 0};
+			gintmsk_data_t gintsts = {.d32 = 0};
+			doepint_data_t doepint = {.d32 = 0};
+			dctl.b.sgoutnak = 1;
+			DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->
+					 dctl, 0, dctl.d32);
+			do {
+				dwc_udelay(10);
+				gintsts.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintsts);
+			} while (!gintsts.b.goutnakeff);
+			gintsts.d32 = 0;
+			gintsts.b.goutnakeff = 1;
+			DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+
+			depctl.d32 = 0;
+			depctl.b.epdis = 1;
+			depctl.b.snak = 1;
+			DWC_WRITE_REG32(&core_if->dev_if->out_ep_regs[ep->num]->doepctl, depctl.d32);
+			do
+			{
+				dwc_udelay(10);
+				doepint.d32 = DWC_READ_REG32(&core_if->dev_if->
+											out_ep_regs[ep->num]->doepint);
+			} while (!doepint.b.epdisabled);
+
+			doepint.b.epdisabled = 1;
+			DWC_WRITE_REG32(&core_if->dev_if->out_ep_regs[ep->num]->doepint, doepint.d32);
+
+			dctl.d32 = 0;
+			dctl.b.cgoutnak = 1;
+			DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl, 0, dctl.d32);
+		}
+	}
+
+	/* Disable the Interrupt for this EP */
+	if (core_if->multiproc_int_enable) {
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->deachintmsk,
+				 daintmsk.d32, 0);
+
+		if (ep->is_in == 1) {
+			DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->
+					diepeachintmsk[ep->num], 0);
+		} else {
+			DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->
+					doepeachintmsk[ep->num], 0);
+		}
+	} else {
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->daintmsk,
+				 daintmsk.d32, 0);
+	}
+
+}
+
+/**
+ * This function initializes dma descriptor chain.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to start the transfer on.
+ */
+static void init_dma_desc_chain(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	dwc_otg_dev_dma_desc_t *dma_desc;
+	uint32_t offset;
+	uint32_t xfer_est;
+	int i;
+	unsigned maxxfer_local, total_len;
+
+	if (!ep->is_in && ep->type == DWC_OTG_EP_TYPE_INTR &&
+	    (ep->maxpacket % 4)) {
+		maxxfer_local = ep->maxpacket;
+		total_len = ep->xfer_len;
+	} else {
+		maxxfer_local = ep->maxxfer;
+		total_len = ep->total_len;
+	}
+
+	ep->desc_cnt = (total_len / maxxfer_local) +
+	    ((total_len % maxxfer_local) ? 1 : 0);
+
+	if (!ep->desc_cnt)
+		ep->desc_cnt = 1;
+
+	if (ep->desc_cnt > MAX_DMA_DESC_CNT)
+		ep->desc_cnt = MAX_DMA_DESC_CNT;
+
+	dma_desc = ep->desc_addr;
+	if (maxxfer_local == ep->maxpacket) {
+		if ((total_len % maxxfer_local) &&
+		    (total_len / maxxfer_local < MAX_DMA_DESC_CNT)) {
+			xfer_est = (ep->desc_cnt - 1) * maxxfer_local +
+			    (total_len % maxxfer_local);
+		} else
+			xfer_est = ep->desc_cnt * maxxfer_local;
+	} else
+		xfer_est = total_len;
+	offset = 0;
+	for (i = 0; i < ep->desc_cnt; ++i) {
+		/** DMA Descriptor Setup */
+		if (xfer_est > maxxfer_local) {
+			dma_desc->status.b.bs = BS_HOST_BUSY;
+			dma_desc->status.b.l = 0;
+			dma_desc->status.b.ioc = 0;
+			dma_desc->status.b.sp = 0;
+			dma_desc->status.b.bytes = maxxfer_local;
+			dma_desc->buf = ep->dma_addr + offset;
+			dma_desc->status.b.sts = 0;
+			dma_desc->status.b.bs = BS_HOST_READY;
+
+			xfer_est -= maxxfer_local;
+			offset += maxxfer_local;
+		} else {
+			dma_desc->status.b.bs = BS_HOST_BUSY;
+			dma_desc->status.b.l = 1;
+			dma_desc->status.b.ioc = 1;
+			if (ep->is_in) {
+				dma_desc->status.b.sp =
+				    (xfer_est %
+				     ep->maxpacket) ? 1 : ((ep->
+							    sent_zlp) ? 1 : 0);
+				dma_desc->status.b.bytes = xfer_est;
+			} else {
+				if (maxxfer_local == ep->maxpacket)
+					dma_desc->status.b.bytes = xfer_est;
+				else
+					dma_desc->status.b.bytes =
+						xfer_est + ((4 - (xfer_est & 0x3)) & 0x3);
+			}
+
+			dma_desc->buf = ep->dma_addr + offset;
+			dma_desc->status.b.sts = 0;
+			dma_desc->status.b.bs = BS_HOST_READY;
+		}
+		dma_desc++;
+	}
+}
+
+/**
+ * This function is called when to write ISOC data into appropriate dedicated
+ * periodic FIFO.
+ */
+static int32_t write_isoc_tx_fifo(dwc_otg_core_if_t * core_if, dwc_ep_t * dwc_ep)
+{
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	dwc_otg_dev_in_ep_regs_t *ep_regs;
+	dtxfsts_data_t txstatus = {.d32 = 0 };
+	uint32_t len = 0;
+	int epnum = dwc_ep->num;
+	int dwords;
+
+	DWC_DEBUGPL(DBG_PCD, "Dedicated TxFifo Empty: %d \n", epnum);
+
+	ep_regs = core_if->dev_if->in_ep_regs[epnum];
+
+	len = dwc_ep->xfer_len - dwc_ep->xfer_count;
+
+	if (len > dwc_ep->maxpacket) {
+		len = dwc_ep->maxpacket;
+	}
+
+	dwords = (len + 3) / 4;
+
+	/* While there is space in the queue and space in the FIFO and
+	 * More data to tranfer, Write packets to the Tx FIFO */
+	txstatus.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->dtxfsts);
+	DWC_DEBUGPL(DBG_PCDV, "b4 dtxfsts[%d]=0x%08x\n", epnum, txstatus.d32);
+
+	while (txstatus.b.txfspcavail >= dwords &&
+	       dwc_ep->xfer_count < dwc_ep->xfer_len && dwc_ep->xfer_len != 0) {
+		/* Write the FIFO */
+		dwc_otg_ep_write_packet(core_if, dwc_ep, 0);
+
+		len = dwc_ep->xfer_len - dwc_ep->xfer_count;
+		if (len > dwc_ep->maxpacket) {
+			len = dwc_ep->maxpacket;
+		}
+
+		dwords = (len + 3) / 4;
+		txstatus.d32 =
+		    DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->dtxfsts);
+		DWC_DEBUGPL(DBG_PCDV, "dtxfsts[%d]=0x%08x\n", epnum,
+			    txstatus.d32);
+	}
+
+	DWC_DEBUGPL(DBG_PCDV, "b4 dtxfsts[%d]=0x%08x\n", epnum,
+		    DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->dtxfsts));
+
+	return 1;
+}
+
+/**
+ * This function does the setup for a data transfer for an EP and
+ * starts the transfer. For an IN transfer, the packets will be
+ * loaded into the appropriate Tx FIFO in the ISR. For OUT transfers,
+ * the packets are unloaded from the Rx FIFO in the ISR.  the ISR.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to start the transfer on.
+ */
+
+void dwc_otg_ep_start_transfer(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	depctl_data_t depctl;
+	deptsiz_data_t deptsiz;
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+
+	DWC_DEBUGPL((DBG_PCDV | DBG_CILV), "%s()\n", __func__);
+	DWC_DEBUGPL(DBG_PCD, "ep%d-%s xfer_len=%d xfer_cnt=%d "
+		    "xfer_buff=%p start_xfer_buff=%p, total_len = %d\n",
+		    ep->num, (ep->is_in ? "IN" : "OUT"), ep->xfer_len,
+		    ep->xfer_count, ep->xfer_buff, ep->start_xfer_buff,
+		    ep->total_len);
+	/* IN endpoint */
+	if (ep->is_in == 1) {
+		dwc_otg_dev_in_ep_regs_t *in_regs =
+		    core_if->dev_if->in_ep_regs[ep->num];
+
+		gnptxsts_data_t gtxstatus;
+
+		gtxstatus.d32 =
+		    DWC_READ_REG32(&core_if->core_global_regs->gnptxsts);
+
+		if (core_if->en_multiple_tx_fifo == 0
+		    && gtxstatus.b.nptxqspcavail == 0 && !core_if->dma_enable) {
+#ifdef DEBUG
+			DWC_PRINTF("TX Queue Full (0x%0x)\n", gtxstatus.d32);
+#endif
+			return;
+		}
+
+		depctl.d32 = DWC_READ_REG32(&(in_regs->diepctl));
+		deptsiz.d32 = DWC_READ_REG32(&(in_regs->dieptsiz));
+
+		if (ep->maxpacket > ep->maxxfer / MAX_PKT_CNT)
+			ep->xfer_len += (ep->maxxfer < (ep->total_len - ep->xfer_len)) ?
+				ep->maxxfer : (ep->total_len - ep->xfer_len);
+		else
+			ep->xfer_len += (MAX_PKT_CNT * ep->maxpacket < (ep->total_len - ep->xfer_len)) ?
+				 MAX_PKT_CNT * ep->maxpacket : (ep->total_len - ep->xfer_len);
+
+
+		/* Zero Length Packet? */
+		if ((ep->xfer_len - ep->xfer_count) == 0) {
+			deptsiz.b.xfersize = 0;
+			deptsiz.b.pktcnt = 1;
+		} else {
+			/* Program the transfer size and packet count
+			 *      as follows: xfersize = N * maxpacket +
+			 *      short_packet pktcnt = N + (short_packet
+			 *      exist ? 1 : 0)
+			 */
+			deptsiz.b.xfersize = ep->xfer_len - ep->xfer_count;
+			deptsiz.b.pktcnt =
+			    (ep->xfer_len - ep->xfer_count - 1 +
+			     ep->maxpacket) / ep->maxpacket;
+			if (deptsiz.b.pktcnt > MAX_PKT_CNT) {
+				deptsiz.b.pktcnt = MAX_PKT_CNT;
+				deptsiz.b.xfersize = deptsiz.b.pktcnt * ep->maxpacket;
+			}
+			if (ep->type == DWC_OTG_EP_TYPE_ISOC)
+				deptsiz.b.mc = deptsiz.b.pktcnt;
+		}
+
+		/* Write the DMA register */
+		if (core_if->dma_enable) {
+			if (core_if->dma_desc_enable == 0) {
+				if (ep->type != DWC_OTG_EP_TYPE_ISOC)
+					deptsiz.b.mc = 1;
+				DWC_WRITE_REG32(&in_regs->dieptsiz,
+						deptsiz.d32);
+				DWC_WRITE_REG32(&(in_regs->diepdma),
+						(uint32_t) ep->dma_addr);
+			} else {
+#ifdef DWC_UTE_CFI
+				/* The descriptor chain should be already initialized by now */
+				if (ep->buff_mode != BM_STANDARD) {
+					DWC_WRITE_REG32(&in_regs->diepdma,
+							ep->descs_dma_addr);
+				} else {
+#endif
+					init_dma_desc_chain(core_if, ep);
+				/** DIEPDMAn Register write */
+					DWC_WRITE_REG32(&in_regs->diepdma,
+							ep->dma_desc_addr);
+#ifdef DWC_UTE_CFI
+				}
+#endif
+			}
+		} else {
+			DWC_WRITE_REG32(&in_regs->dieptsiz, deptsiz.d32);
+			if (ep->type != DWC_OTG_EP_TYPE_ISOC) {
+				/**
+				 * Enable the Non-Periodic Tx FIFO empty interrupt,
+				 * or the Tx FIFO epmty interrupt in dedicated Tx FIFO mode,
+				 * the data will be written into the fifo by the ISR.
+				 */
+				if (core_if->en_multiple_tx_fifo == 0) {
+					intr_mask.b.nptxfempty = 1;
+					DWC_MODIFY_REG32
+					    (&core_if->core_global_regs->gintmsk,
+					     intr_mask.d32, intr_mask.d32);
+				} else {
+					/* Enable the Tx FIFO Empty Interrupt for this EP */
+					if (ep->xfer_len > 0) {
+						uint32_t fifoemptymsk = 0;
+						fifoemptymsk = 1 << ep->num;
+						DWC_MODIFY_REG32
+						    (&core_if->dev_if->dev_global_regs->dtknqr4_fifoemptymsk,
+						     0, fifoemptymsk);
+
+					}
+				}
+			}
+		}
+		if (!core_if->core_params->en_multiple_tx_fifo && core_if->dma_enable)
+			depctl.b.nextep = core_if->nextep_seq[ep->num];
+
+		if (ep->type == DWC_OTG_EP_TYPE_ISOC) {
+			dsts_data_t dsts = {.d32 = 0 };
+			if (ep->bInterval == 1) {
+				dsts.d32 =
+				    DWC_READ_REG32(&core_if->dev_if->
+						   dev_global_regs->dsts);
+				ep->frame_num = dsts.b.soffn + ep->bInterval;
+				if (ep->frame_num > 0x3FFF) {
+					ep->frm_overrun = 1;
+					ep->frame_num &= 0x3FFF;
+				} else
+					ep->frm_overrun = 0;
+				if (ep->frame_num & 0x1) {
+					depctl.b.setd1pid = 1;
+				} else {
+					depctl.b.setd0pid = 1;
+				}
+			}
+		}
+		/* EP enable, IN data in FIFO */
+		depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+		DWC_WRITE_REG32(&in_regs->diepctl, depctl.d32);
+
+		if (!core_if->dma_enable && ep->type == DWC_OTG_EP_TYPE_ISOC) {
+				write_isoc_tx_fifo(core_if, ep);
+		}
+
+	} else {
+		/* OUT endpoint */
+		dwc_otg_dev_out_ep_regs_t *out_regs =
+		    core_if->dev_if->out_ep_regs[ep->num];
+
+		depctl.d32 = DWC_READ_REG32(&(out_regs->doepctl));
+		deptsiz.d32 = DWC_READ_REG32(&(out_regs->doeptsiz));
+
+		if (!core_if->dma_desc_enable) {
+			if (ep->maxpacket > ep->maxxfer / MAX_PKT_CNT)
+				ep->xfer_len += (ep->maxxfer < (ep->total_len - ep->xfer_len)) ?
+				ep->maxxfer : (ep->total_len - ep->xfer_len);
+                else
+					ep->xfer_len += (MAX_PKT_CNT * ep->maxpacket < (ep->total_len
+					- ep->xfer_len)) ? MAX_PKT_CNT * ep->maxpacket : (ep->total_len - ep->xfer_len);
+		}
+
+		/* Program the transfer size and packet count as follows:
+		 *
+		 *      pktcnt = N
+		 *      xfersize = N * maxpacket
+		 */
+		if ((ep->xfer_len - ep->xfer_count) == 0) {
+			/* Zero Length Packet */
+			deptsiz.b.xfersize = ep->maxpacket;
+			deptsiz.b.pktcnt = 1;
+		} else {
+			deptsiz.b.pktcnt =
+			    (ep->xfer_len - ep->xfer_count +
+			     (ep->maxpacket - 1)) / ep->maxpacket;
+			if (deptsiz.b.pktcnt > MAX_PKT_CNT) {
+				deptsiz.b.pktcnt = MAX_PKT_CNT;
+			}
+			if (!core_if->dma_desc_enable) {
+				ep->xfer_len =
+					deptsiz.b.pktcnt * ep->maxpacket + ep->xfer_count;
+			}
+			deptsiz.b.xfersize = ep->xfer_len - ep->xfer_count;
+		}
+
+		DWC_DEBUGPL(DBG_PCDV, "ep%d xfersize=%d pktcnt=%d\n",
+			    ep->num, deptsiz.b.xfersize, deptsiz.b.pktcnt);
+
+		if (core_if->dma_enable) {
+			if (!core_if->dma_desc_enable) {
+				DWC_WRITE_REG32(&out_regs->doeptsiz,
+						deptsiz.d32);
+
+				DWC_WRITE_REG32(&(out_regs->doepdma),
+						(uint32_t) ep->dma_addr);
+			} else {
+#ifdef DWC_UTE_CFI
+				/* The descriptor chain should be already initialized by now */
+				if (ep->buff_mode != BM_STANDARD) {
+					DWC_WRITE_REG32(&out_regs->doepdma,
+							ep->descs_dma_addr);
+				} else {
+#endif
+					/** This is used for interrupt out transfers*/
+					if (!ep->xfer_len)
+						ep->xfer_len = ep->total_len;
+					init_dma_desc_chain(core_if, ep);
+
+					if (core_if->core_params->dev_out_nak) {
+						if (ep->type == DWC_OTG_EP_TYPE_BULK) {
+							deptsiz.b.pktcnt = (ep->total_len +
+								(ep->maxpacket - 1)) / ep->maxpacket;
+							deptsiz.b.xfersize = ep->total_len;
+							/* Remember initial value of doeptsiz */
+							core_if->start_doeptsiz_val[ep->num] = deptsiz.d32;
+							DWC_WRITE_REG32(&out_regs->doeptsiz,
+								deptsiz.d32);
+						}
+					}
+				/** DOEPDMAn Register write */
+					DWC_WRITE_REG32(&out_regs->doepdma,
+							ep->dma_desc_addr);
+#ifdef DWC_UTE_CFI
+				}
+#endif
+			}
+		} else {
+			DWC_WRITE_REG32(&out_regs->doeptsiz, deptsiz.d32);
+		}
+
+		if (ep->type == DWC_OTG_EP_TYPE_ISOC) {
+			dsts_data_t dsts = {.d32 = 0 };
+			if (ep->bInterval == 1) {
+				dsts.d32 =
+				    DWC_READ_REG32(&core_if->dev_if->
+						   dev_global_regs->dsts);
+				ep->frame_num = dsts.b.soffn + ep->bInterval;
+				if (ep->frame_num > 0x3FFF) {
+					ep->frm_overrun = 1;
+					ep->frame_num &= 0x3FFF;
+				} else
+					ep->frm_overrun = 0;
+
+				if (ep->frame_num & 0x1) {
+					depctl.b.setd1pid = 1;
+				} else {
+					depctl.b.setd0pid = 1;
+				}
+			}
+		}
+
+		/* EP enable */
+		depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+
+		DWC_WRITE_REG32(&out_regs->doepctl, depctl.d32);
+
+		DWC_DEBUGPL(DBG_PCD, "DOEPCTL=%08x DOEPTSIZ=%08x\n",
+			    DWC_READ_REG32(&out_regs->doepctl),
+			    DWC_READ_REG32(&out_regs->doeptsiz));
+		DWC_DEBUGPL(DBG_PCD, "DAINTMSK=%08x GINTMSK=%08x\n",
+			    DWC_READ_REG32(&core_if->dev_if->dev_global_regs->
+					   daintmsk),
+			    DWC_READ_REG32(&core_if->core_global_regs->
+					   gintmsk));
+
+		/* Timer is scheduling only for out bulk transfers for
+		 * "Device DDMA OUT NAK Enhancement" feature to inform user
+		 * about received data payload in case of timeout
+		 */
+		if (core_if->core_params->dev_out_nak) {
+			if (ep->type == DWC_OTG_EP_TYPE_BULK) {
+				core_if->ep_xfer_info[ep->num].core_if = core_if;
+				core_if->ep_xfer_info[ep->num].ep = ep;
+				core_if->ep_xfer_info[ep->num].state = 1;
+
+				/* Start a timer for this transfer. */
+				DWC_TIMER_SCHEDULE(core_if->ep_xfer_timer[ep->num], 10000);
+			}
+		}
+	}
+}
+
+/**
+ * This function setup a zero length transfer in Buffer DMA and
+ * Slave modes for usb requests with zero field set
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to start the transfer on.
+ *
+ */
+void dwc_otg_ep_start_zl_transfer(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+
+	depctl_data_t depctl;
+	deptsiz_data_t deptsiz;
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+
+	DWC_DEBUGPL((DBG_PCDV | DBG_CILV), "%s()\n", __func__);
+	DWC_PRINTF("zero length transfer is called\n");
+
+	/* IN endpoint */
+	if (ep->is_in == 1) {
+		dwc_otg_dev_in_ep_regs_t *in_regs =
+		    core_if->dev_if->in_ep_regs[ep->num];
+
+		depctl.d32 = DWC_READ_REG32(&(in_regs->diepctl));
+		deptsiz.d32 = DWC_READ_REG32(&(in_regs->dieptsiz));
+
+		deptsiz.b.xfersize = 0;
+		deptsiz.b.pktcnt = 1;
+
+		/* Write the DMA register */
+		if (core_if->dma_enable) {
+			if (core_if->dma_desc_enable == 0) {
+				deptsiz.b.mc = 1;
+				DWC_WRITE_REG32(&in_regs->dieptsiz,
+						deptsiz.d32);
+				DWC_WRITE_REG32(&(in_regs->diepdma),
+						(uint32_t) ep->dma_addr);
+			}
+		} else {
+			DWC_WRITE_REG32(&in_regs->dieptsiz, deptsiz.d32);
+			/**
+			 * Enable the Non-Periodic Tx FIFO empty interrupt,
+			 * or the Tx FIFO epmty interrupt in dedicated Tx FIFO mode,
+			 * the data will be written into the fifo by the ISR.
+			 */
+			if (core_if->en_multiple_tx_fifo == 0) {
+				intr_mask.b.nptxfempty = 1;
+				DWC_MODIFY_REG32(&core_if->
+						 core_global_regs->gintmsk,
+						 intr_mask.d32, intr_mask.d32);
+			} else {
+				/* Enable the Tx FIFO Empty Interrupt for this EP */
+				if (ep->xfer_len > 0) {
+					uint32_t fifoemptymsk = 0;
+					fifoemptymsk = 1 << ep->num;
+					DWC_MODIFY_REG32(&core_if->
+							 dev_if->dev_global_regs->dtknqr4_fifoemptymsk,
+							 0, fifoemptymsk);
+				}
+			}
+		}
+
+		if (!core_if->core_params->en_multiple_tx_fifo && core_if->dma_enable)
+			depctl.b.nextep = core_if->nextep_seq[ep->num];
+		/* EP enable, IN data in FIFO */
+		depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+		DWC_WRITE_REG32(&in_regs->diepctl, depctl.d32);
+
+	} else {
+		/* OUT endpoint */
+		dwc_otg_dev_out_ep_regs_t *out_regs =
+		    core_if->dev_if->out_ep_regs[ep->num];
+
+		depctl.d32 = DWC_READ_REG32(&(out_regs->doepctl));
+		deptsiz.d32 = DWC_READ_REG32(&(out_regs->doeptsiz));
+
+		/* Zero Length Packet */
+		deptsiz.b.xfersize = ep->maxpacket;
+		deptsiz.b.pktcnt = 1;
+
+		if (core_if->dma_enable) {
+			if (!core_if->dma_desc_enable) {
+				DWC_WRITE_REG32(&out_regs->doeptsiz,
+						deptsiz.d32);
+
+				DWC_WRITE_REG32(&(out_regs->doepdma),
+						(uint32_t) ep->dma_addr);
+			}
+		} else {
+			DWC_WRITE_REG32(&out_regs->doeptsiz, deptsiz.d32);
+		}
+
+		/* EP enable */
+		depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+
+		DWC_WRITE_REG32(&out_regs->doepctl, depctl.d32);
+
+	}
+}
+
+/**
+ * This function does the setup for a data transfer for EP0 and starts
+ * the transfer.  For an IN transfer, the packets will be loaded into
+ * the appropriate Tx FIFO in the ISR. For OUT transfers, the packets are
+ * unloaded from the Rx FIFO in the ISR.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP0 data.
+ */
+void dwc_otg_ep0_start_transfer(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	depctl_data_t depctl;
+	deptsiz0_data_t deptsiz;
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+	dwc_otg_dev_dma_desc_t *dma_desc;
+
+	DWC_DEBUGPL(DBG_PCD, "ep%d-%s xfer_len=%d xfer_cnt=%d "
+		    "xfer_buff=%p start_xfer_buff=%p \n",
+		    ep->num, (ep->is_in ? "IN" : "OUT"), ep->xfer_len,
+		    ep->xfer_count, ep->xfer_buff, ep->start_xfer_buff);
+
+	ep->total_len = ep->xfer_len;
+
+	/* IN endpoint */
+	if (ep->is_in == 1) {
+		dwc_otg_dev_in_ep_regs_t *in_regs =
+		    core_if->dev_if->in_ep_regs[0];
+
+		gnptxsts_data_t gtxstatus;
+
+		if (core_if->snpsid >= OTG_CORE_REV_3_00a) {
+			depctl.d32 = DWC_READ_REG32(&in_regs->diepctl);
+			if (depctl.b.epena)
+				return;
+		}
+
+		gtxstatus.d32 =
+		    DWC_READ_REG32(&core_if->core_global_regs->gnptxsts);
+
+		/* If dedicated FIFO every time flush fifo before enable ep*/
+		if (core_if->en_multiple_tx_fifo && core_if->snpsid >= OTG_CORE_REV_3_00a)
+			dwc_otg_flush_tx_fifo(core_if, ep->tx_fifo_num);
+
+            dwc_otg_flush_tx_fifo(core_if, 0x10);
+
+		if (core_if->en_multiple_tx_fifo == 0
+		    && gtxstatus.b.nptxqspcavail == 0
+		    && !core_if->dma_enable) {
+#ifdef DEBUG
+			deptsiz.d32 = DWC_READ_REG32(&in_regs->dieptsiz);
+			DWC_DEBUGPL(DBG_PCD, "DIEPCTL0=%0x\n",
+				    DWC_READ_REG32(&in_regs->diepctl));
+			DWC_DEBUGPL(DBG_PCD, "DIEPTSIZ0=%0x (sz=%d, pcnt=%d)\n",
+				    deptsiz.d32,
+				    deptsiz.b.xfersize, deptsiz.b.pktcnt);
+			DWC_PRINTF("TX Queue or FIFO Full (0x%0x)\n",
+				   gtxstatus.d32);
+#endif
+			return;
+		}
+
+		depctl.d32 = DWC_READ_REG32(&in_regs->diepctl);
+		deptsiz.d32 = DWC_READ_REG32(&in_regs->dieptsiz);
+
+		/* Zero Length Packet? */
+		if (ep->xfer_len == 0) {
+			deptsiz.b.xfersize = 0;
+			deptsiz.b.pktcnt = 1;
+		} else {
+			/* Program the transfer size and packet count
+			 *      as follows: xfersize = N * maxpacket +
+			 *      short_packet pktcnt = N + (short_packet
+			 *      exist ? 1 : 0)
+			 */
+			if (ep->xfer_len > ep->maxpacket) {
+				ep->xfer_len = ep->maxpacket;
+				deptsiz.b.xfersize = ep->maxpacket;
+			} else {
+				deptsiz.b.xfersize = ep->xfer_len;
+			}
+			deptsiz.b.pktcnt = 1;
+
+		}
+		DWC_DEBUGPL(DBG_PCDV,
+			    "IN len=%d  xfersize=%d pktcnt=%d [%08x]\n",
+			    ep->xfer_len, deptsiz.b.xfersize, deptsiz.b.pktcnt,
+			    deptsiz.d32);
+
+		/* Write the DMA register */
+		if (core_if->dma_enable) {
+			if (core_if->dma_desc_enable == 0) {
+				DWC_WRITE_REG32(&in_regs->dieptsiz,
+						deptsiz.d32);
+
+				DWC_WRITE_REG32(&(in_regs->diepdma),
+						(uint32_t) ep->dma_addr);
+			} else {
+				dma_desc = core_if->dev_if->in_desc_addr;
+
+				/** DMA Descriptor Setup */
+				dma_desc->status.b.bs = BS_HOST_BUSY;
+				dma_desc->status.b.l = 1;
+				dma_desc->status.b.ioc = 1;
+				dma_desc->status.b.sp =
+				    (ep->xfer_len == ep->maxpacket) ? 0 : 1;
+				dma_desc->status.b.bytes = ep->xfer_len;
+				dma_desc->buf = ep->dma_addr;
+				dma_desc->status.b.sts = 0;
+				dma_desc->status.b.bs = BS_HOST_READY;
+
+				/** DIEPDMA0 Register write */
+				DWC_WRITE_REG32(&in_regs->diepdma,
+						core_if->
+						dev_if->dma_in_desc_addr);
+			}
+		} else {
+			DWC_WRITE_REG32(&in_regs->dieptsiz, deptsiz.d32);
+		}
+
+		if (!core_if->core_params->en_multiple_tx_fifo && core_if->dma_enable)
+			depctl.b.nextep = core_if->nextep_seq[ep->num];
+		/* EP enable, IN data in FIFO */
+		depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+		DWC_WRITE_REG32(&in_regs->diepctl, depctl.d32);
+
+		/**
+		 * Enable the Non-Periodic Tx FIFO empty interrupt, the
+		 * data will be written into the fifo by the ISR.
+		 */
+		if (!core_if->dma_enable) {
+			if (core_if->en_multiple_tx_fifo == 0) {
+				intr_mask.b.nptxfempty = 1;
+				DWC_MODIFY_REG32(&core_if->
+						 core_global_regs->gintmsk,
+						 intr_mask.d32, intr_mask.d32);
+			} else {
+				/* Enable the Tx FIFO Empty Interrupt for this EP */
+				if (ep->xfer_len > 0) {
+					uint32_t fifoemptymsk = 0;
+					fifoemptymsk |= 1 << ep->num;
+					DWC_MODIFY_REG32(&core_if->
+							 dev_if->dev_global_regs->dtknqr4_fifoemptymsk,
+							 0, fifoemptymsk);
+				}
+			}
+		}
+	} else {
+		/* OUT endpoint */
+		dwc_otg_dev_out_ep_regs_t *out_regs =
+		    core_if->dev_if->out_ep_regs[0];
+
+		depctl.d32 = DWC_READ_REG32(&out_regs->doepctl);
+		deptsiz.d32 = DWC_READ_REG32(&out_regs->doeptsiz);
+
+		/* Program the transfer size and packet count as follows:
+		 *      xfersize = N * (maxpacket + 4 - (maxpacket % 4))
+		 *      pktcnt = N                                                                                      */
+		/* Zero Length Packet */
+		deptsiz.b.xfersize = ep->maxpacket;
+		deptsiz.b.pktcnt = 1;
+		if (core_if->snpsid >= OTG_CORE_REV_3_00a)
+			deptsiz.b.supcnt = 3;
+
+		DWC_DEBUGPL(DBG_PCDV, "len=%d  xfersize=%d pktcnt=%d\n",
+			    ep->xfer_len, deptsiz.b.xfersize, deptsiz.b.pktcnt);
+
+		if (core_if->dma_enable) {
+			if (!core_if->dma_desc_enable) {
+				DWC_WRITE_REG32(&out_regs->doeptsiz,
+						deptsiz.d32);
+
+				DWC_WRITE_REG32(&(out_regs->doepdma),
+						(uint32_t) ep->dma_addr);
+			} else {
+				dma_desc = core_if->dev_if->out_desc_addr;
+
+				/** DMA Descriptor Setup */
+				dma_desc->status.b.bs = BS_HOST_BUSY;
+				if (core_if->snpsid >= OTG_CORE_REV_3_00a) {
+					dma_desc->status.b.mtrf = 0;
+					dma_desc->status.b.sr = 0;
+				}
+				dma_desc->status.b.l = 1;
+				dma_desc->status.b.ioc = 1;
+				dma_desc->status.b.bytes = ep->maxpacket;
+				dma_desc->buf = ep->dma_addr;
+				dma_desc->status.b.sts = 0;
+				dma_desc->status.b.bs = BS_HOST_READY;
+
+				/** DOEPDMA0 Register write */
+				DWC_WRITE_REG32(&out_regs->doepdma,
+						core_if->dev_if->
+						dma_out_desc_addr);
+			}
+		} else {
+			DWC_WRITE_REG32(&out_regs->doeptsiz, deptsiz.d32);
+		}
+
+		/* EP enable */
+		depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+		DWC_WRITE_REG32(&(out_regs->doepctl), depctl.d32);
+	}
+}
+
+/**
+ * This function continues control IN transfers started by
+ * dwc_otg_ep0_start_transfer, when the transfer does not fit in a
+ * single packet.  NOTE: The DIEPCTL0/DOEPCTL0 registers only have one
+ * bit for the packet count.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP0 data.
+ */
+void dwc_otg_ep0_continue_transfer(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	depctl_data_t depctl;
+	deptsiz0_data_t deptsiz;
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+	dwc_otg_dev_dma_desc_t *dma_desc;
+
+	if (ep->is_in == 1) {
+		dwc_otg_dev_in_ep_regs_t *in_regs =
+		    core_if->dev_if->in_ep_regs[0];
+		gnptxsts_data_t tx_status = {.d32 = 0 };
+
+		tx_status.d32 =
+		    DWC_READ_REG32(&core_if->core_global_regs->gnptxsts);
+		/** @todo Should there be check for room in the Tx
+		 * Status Queue.  If not remove the code above this comment. */
+
+		depctl.d32 = DWC_READ_REG32(&in_regs->diepctl);
+		deptsiz.d32 = DWC_READ_REG32(&in_regs->dieptsiz);
+
+		/* Program the transfer size and packet count
+		 *      as follows: xfersize = N * maxpacket +
+		 *      short_packet pktcnt = N + (short_packet
+		 *      exist ? 1 : 0)
+		 */
+
+		if (core_if->dma_desc_enable == 0) {
+			deptsiz.b.xfersize =
+			    (ep->total_len - ep->xfer_count) >
+			    ep->maxpacket ? ep->maxpacket : (ep->total_len -
+							     ep->xfer_count);
+			deptsiz.b.pktcnt = 1;
+			if (core_if->dma_enable == 0) {
+				ep->xfer_len += deptsiz.b.xfersize;
+			} else {
+				ep->xfer_len = deptsiz.b.xfersize;
+			}
+			DWC_WRITE_REG32(&in_regs->dieptsiz, deptsiz.d32);
+		} else {
+			ep->xfer_len =
+			    (ep->total_len - ep->xfer_count) >
+			    ep->maxpacket ? ep->maxpacket : (ep->total_len -
+							     ep->xfer_count);
+
+			dma_desc = core_if->dev_if->in_desc_addr;
+
+			/** DMA Descriptor Setup */
+			dma_desc->status.b.bs = BS_HOST_BUSY;
+			dma_desc->status.b.l = 1;
+			dma_desc->status.b.ioc = 1;
+			dma_desc->status.b.sp =
+			    (ep->xfer_len == ep->maxpacket) ? 0 : 1;
+			dma_desc->status.b.bytes = ep->xfer_len;
+			dma_desc->buf = ep->dma_addr;
+			dma_desc->status.b.sts = 0;
+			dma_desc->status.b.bs = BS_HOST_READY;
+
+			/** DIEPDMA0 Register write */
+			DWC_WRITE_REG32(&in_regs->diepdma,
+					core_if->dev_if->dma_in_desc_addr);
+		}
+
+		DWC_DEBUGPL(DBG_PCDV,
+			    "IN len=%d  xfersize=%d pktcnt=%d [%08x]\n",
+			    ep->xfer_len, deptsiz.b.xfersize, deptsiz.b.pktcnt,
+			    deptsiz.d32);
+
+		/* Write the DMA register */
+		if (core_if->hwcfg2.b.architecture == DWC_INT_DMA_ARCH) {
+			if (core_if->dma_desc_enable == 0)
+				DWC_WRITE_REG32(&(in_regs->diepdma),
+						(uint32_t) ep->dma_addr);
+		}
+		if (!core_if->core_params->en_multiple_tx_fifo && core_if->dma_enable)
+			depctl.b.nextep = core_if->nextep_seq[ep->num];
+		/* EP enable, IN data in FIFO */
+		depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+		DWC_WRITE_REG32(&in_regs->diepctl, depctl.d32);
+
+		/**
+		 * Enable the Non-Periodic Tx FIFO empty interrupt, the
+		 * data will be written into the fifo by the ISR.
+		 */
+		if (!core_if->dma_enable) {
+			if (core_if->en_multiple_tx_fifo == 0) {
+				/* First clear it from GINTSTS */
+				intr_mask.b.nptxfempty = 1;
+				DWC_MODIFY_REG32(&core_if->
+						 core_global_regs->gintmsk,
+						 intr_mask.d32, intr_mask.d32);
+
+			} else {
+				/* Enable the Tx FIFO Empty Interrupt for this EP */
+				if (ep->xfer_len > 0) {
+					uint32_t fifoemptymsk = 0;
+					fifoemptymsk |= 1 << ep->num;
+					DWC_MODIFY_REG32(&core_if->
+							 dev_if->dev_global_regs->dtknqr4_fifoemptymsk,
+							 0, fifoemptymsk);
+				}
+			}
+		}
+	} else {
+		dwc_otg_dev_out_ep_regs_t *out_regs =
+		    core_if->dev_if->out_ep_regs[0];
+
+		depctl.d32 = DWC_READ_REG32(&out_regs->doepctl);
+		deptsiz.d32 = DWC_READ_REG32(&out_regs->doeptsiz);
+
+		/* Program the transfer size and packet count
+		 *      as follows: xfersize = N * maxpacket +
+		 *      short_packet pktcnt = N + (short_packet
+		 *      exist ? 1 : 0)
+		 */
+		deptsiz.b.xfersize = ep->maxpacket;
+		deptsiz.b.pktcnt = 1;
+
+		if (core_if->dma_desc_enable == 0) {
+			DWC_WRITE_REG32(&out_regs->doeptsiz, deptsiz.d32);
+		} else {
+			dma_desc = core_if->dev_if->out_desc_addr;
+
+			/** DMA Descriptor Setup */
+			dma_desc->status.b.bs = BS_HOST_BUSY;
+			dma_desc->status.b.l = 1;
+			dma_desc->status.b.ioc = 1;
+			dma_desc->status.b.bytes = ep->maxpacket;
+			dma_desc->buf = ep->dma_addr;
+			dma_desc->status.b.sts = 0;
+			dma_desc->status.b.bs = BS_HOST_READY;
+
+			/** DOEPDMA0 Register write */
+			DWC_WRITE_REG32(&out_regs->doepdma,
+					core_if->dev_if->dma_out_desc_addr);
+		}
+
+		DWC_DEBUGPL(DBG_PCDV,
+			    "IN len=%d  xfersize=%d pktcnt=%d [%08x]\n",
+			    ep->xfer_len, deptsiz.b.xfersize, deptsiz.b.pktcnt,
+			    deptsiz.d32);
+
+		/* Write the DMA register */
+		if (core_if->hwcfg2.b.architecture == DWC_INT_DMA_ARCH) {
+			if (core_if->dma_desc_enable == 0)
+				DWC_WRITE_REG32(&(out_regs->doepdma),
+						(uint32_t) ep->dma_addr);
+
+		}
+
+		/* EP enable, IN data in FIFO */
+		depctl.b.cnak = 1;
+		depctl.b.epena = 1;
+		DWC_WRITE_REG32(&out_regs->doepctl, depctl.d32);
+
+	}
+}
+
+#ifdef DEBUG
+void dump_msg(const u8 * buf, unsigned int length)
+{
+	unsigned int start, num, i;
+	char line[52], *p;
+
+	if (length >= 512)
+		return;
+	start = 0;
+	while (length > 0) {
+		num = length < 16u ? length : 16u;
+		p = line;
+		for (i = 0; i < num; ++i) {
+			if (i == 8)
+				*p++ = ' ';
+			DWC_SPRINTF(p, " %02x", buf[i]);
+			p += 3;
+		}
+		*p = 0;
+		DWC_PRINTF("%6x: %s\n", start, line);
+		buf += num;
+		start += num;
+		length -= num;
+	}
+}
+#else
+static inline void dump_msg(const u8 * buf, unsigned int length)
+{
+}
+#endif
+
+/**
+ * This function writes a packet into the Tx FIFO associated with the
+ * EP. For non-periodic EPs the non-periodic Tx FIFO is written.  For
+ * periodic EPs the periodic Tx FIFO associated with the EP is written
+ * with all packets for the next micro-frame.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to write packet for.
+ * @param dma Indicates if DMA is being used.
+ */
+void dwc_otg_ep_write_packet(dwc_otg_core_if_t * core_if, dwc_ep_t * ep,
+			     int dma)
+{
+	/**
+	 * The buffer is padded to DWORD on a per packet basis in
+	 * slave/dma mode if the MPS is not DWORD aligned. The last
+	 * packet, if short, is also padded to a multiple of DWORD.
+	 *
+	 * ep->xfer_buff always starts DWORD aligned in memory and is a
+	 * multiple of DWORD in length
+	 *
+	 * ep->xfer_len can be any number of bytes
+	 *
+	 * ep->xfer_count is a multiple of ep->maxpacket until the last
+	 *	packet
+	 *
+	 * FIFO access is DWORD */
+
+	uint32_t i;
+	uint32_t byte_count;
+	uint32_t dword_count;
+	uint32_t *fifo;
+	uint32_t *data_buff = (uint32_t *) ep->xfer_buff;
+
+	DWC_DEBUGPL((DBG_PCDV | DBG_CILV), "%s(%p,%p)\n", __func__, core_if,
+		    ep);
+	if (ep->xfer_count >= ep->xfer_len) {
+		DWC_WARN("%s() No data for EP%d!!!\n", __func__, ep->num);
+		return;
+	}
+
+	/* Find the byte length of the packet either short packet or MPS */
+	if ((ep->xfer_len - ep->xfer_count) < ep->maxpacket) {
+		byte_count = ep->xfer_len - ep->xfer_count;
+	} else {
+		byte_count = ep->maxpacket;
+	}
+
+	/* Find the DWORD length, padded by extra bytes as neccessary if MPS
+	 * is not a multiple of DWORD */
+	dword_count = (byte_count + 3) / 4;
+
+#ifdef VERBOSE
+	dump_msg(ep->xfer_buff, byte_count);
+#endif
+
+	/**@todo NGS Where are the Periodic Tx FIFO addresses
+	 * intialized?	What should this be? */
+
+	fifo = core_if->data_fifo[ep->num];
+
+	DWC_DEBUGPL((DBG_PCDV | DBG_CILV), "fifo=%p buff=%p *p=%08x bc=%d\n",
+		    fifo, data_buff, *data_buff, byte_count);
+
+	if (!dma) {
+		for (i = 0; i < dword_count; i++, data_buff++) {
+			DWC_WRITE_REG32(fifo, *data_buff);
+		}
+	}
+
+	ep->xfer_count += byte_count;
+	ep->xfer_buff += byte_count;
+	ep->dma_addr += byte_count;
+}
+
+/**
+ * Set the EP STALL.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to set the stall on.
+ */
+void dwc_otg_ep_set_stall(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	depctl_data_t depctl;
+	volatile uint32_t *depctl_addr;
+
+	DWC_DEBUGPL(DBG_PCD, "%s ep%d-%s\n", __func__, ep->num,
+		    (ep->is_in ? "IN" : "OUT"));
+
+	if (ep->is_in == 1) {
+		depctl_addr = &(core_if->dev_if->in_ep_regs[ep->num]->diepctl);
+		depctl.d32 = DWC_READ_REG32(depctl_addr);
+
+		/* set the disable and stall bits */
+		if (depctl.b.epena) {
+			depctl.b.epdis = 1;
+		}
+		depctl.b.stall = 1;
+		DWC_WRITE_REG32(depctl_addr, depctl.d32);
+	} else {
+		depctl_addr = &(core_if->dev_if->out_ep_regs[ep->num]->doepctl);
+		depctl.d32 = DWC_READ_REG32(depctl_addr);
+
+		/* set the stall bit */
+		depctl.b.stall = 1;
+		DWC_WRITE_REG32(depctl_addr, depctl.d32);
+	}
+
+	DWC_DEBUGPL(DBG_PCD, "DEPCTL=%0x\n", DWC_READ_REG32(depctl_addr));
+
+	return;
+}
+
+/**
+ * Clear the EP STALL.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to clear stall from.
+ */
+void dwc_otg_ep_clear_stall(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	depctl_data_t depctl;
+	volatile uint32_t *depctl_addr;
+
+	DWC_DEBUGPL(DBG_PCD, "%s ep%d-%s\n", __func__, ep->num,
+		    (ep->is_in ? "IN" : "OUT"));
+
+	if (ep->is_in == 1) {
+		depctl_addr = &(core_if->dev_if->in_ep_regs[ep->num]->diepctl);
+	} else {
+		depctl_addr = &(core_if->dev_if->out_ep_regs[ep->num]->doepctl);
+	}
+
+	depctl.d32 = DWC_READ_REG32(depctl_addr);
+
+	/* clear the stall bits */
+	depctl.b.stall = 0;
+
+	/*
+	 * USB Spec 9.4.5: For endpoints using data toggle, regardless
+	 * of whether an endpoint has the Halt feature set, a
+	 * ClearFeature(ENDPOINT_HALT) request always results in the
+	 * data toggle being reinitialized to DATA0.
+	 */
+	if (ep->type == DWC_OTG_EP_TYPE_INTR ||
+	    ep->type == DWC_OTG_EP_TYPE_BULK) {
+		depctl.b.setd0pid = 1;	/* DATA0 */
+	}
+
+	DWC_WRITE_REG32(depctl_addr, depctl.d32);
+	DWC_DEBUGPL(DBG_PCD, "DEPCTL=%0x\n", DWC_READ_REG32(depctl_addr));
+	return;
+}
+
+/**
+ * This function reads a packet from the Rx FIFO into the destination
+ * buffer. To read SETUP data use dwc_otg_read_setup_packet.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param dest	  Destination buffer for the packet.
+ * @param bytes  Number of bytes to copy to the destination.
+ */
+void dwc_otg_read_packet(dwc_otg_core_if_t * core_if,
+			 uint8_t * dest, uint16_t bytes)
+{
+	int i;
+	int word_count = (bytes + 3) / 4;
+
+	volatile uint32_t *fifo = core_if->data_fifo[0];
+	uint32_t *data_buff = (uint32_t *) dest;
+
+	/**
+	 * @todo Account for the case where _dest is not dword aligned. This
+	 * requires reading data from the FIFO into a uint32_t temp buffer,
+	 * then moving it into the data buffer.
+	 */
+
+	DWC_DEBUGPL((DBG_PCDV | DBG_CILV), "%s(%p,%p,%d)\n", __func__,
+		    core_if, dest, bytes);
+
+	for (i = 0; i < word_count; i++, data_buff++) {
+		*data_buff = DWC_READ_REG32(fifo);
+	}
+
+	return;
+}
+
+/**
+ * This functions reads the device registers and prints them
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+void dwc_otg_dump_dev_registers(dwc_otg_core_if_t * core_if)
+{
+	int i;
+	volatile uint32_t *addr;
+
+	DWC_PRINTF("Device Global Registers\n");
+	addr = &core_if->dev_if->dev_global_regs->dcfg;
+	DWC_PRINTF("DCFG		 @0x%08lX : 0x%08X\n",
+		   (unsigned long)addr, DWC_READ_REG32(addr));
+	addr = &core_if->dev_if->dev_global_regs->dctl;
+	DWC_PRINTF("DCTL		 @0x%08lX : 0x%08X\n",
+		   (unsigned long)addr, DWC_READ_REG32(addr));
+	addr = &core_if->dev_if->dev_global_regs->dsts;
+	DWC_PRINTF("DSTS		 @0x%08lX : 0x%08X\n",
+		   (unsigned long)addr, DWC_READ_REG32(addr));
+	addr = &core_if->dev_if->dev_global_regs->diepmsk;
+	DWC_PRINTF("DIEPMSK	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->dev_if->dev_global_regs->doepmsk;
+	DWC_PRINTF("DOEPMSK	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->dev_if->dev_global_regs->daint;
+	DWC_PRINTF("DAINT	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->dev_if->dev_global_regs->daintmsk;
+	DWC_PRINTF("DAINTMSK	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->dev_if->dev_global_regs->dtknqr1;
+	DWC_PRINTF("DTKNQR1	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	if (core_if->hwcfg2.b.dev_token_q_depth > 6) {
+		addr = &core_if->dev_if->dev_global_regs->dtknqr2;
+		DWC_PRINTF("DTKNQR2	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+	}
+
+	addr = &core_if->dev_if->dev_global_regs->dvbusdis;
+	DWC_PRINTF("DVBUSID	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+
+	addr = &core_if->dev_if->dev_global_regs->dvbuspulse;
+	DWC_PRINTF("DVBUSPULSE	@0x%08lX : 0x%08X\n",
+		   (unsigned long)addr, DWC_READ_REG32(addr));
+
+	addr = &core_if->dev_if->dev_global_regs->dtknqr3_dthrctl;
+	DWC_PRINTF("DTKNQR3_DTHRCTL	 @0x%08lX : 0x%08X\n",
+		   (unsigned long)addr, DWC_READ_REG32(addr));
+
+	if (core_if->hwcfg2.b.dev_token_q_depth > 22) {
+		addr = &core_if->dev_if->dev_global_regs->dtknqr4_fifoemptymsk;
+		DWC_PRINTF("DTKNQR4	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+	}
+
+	addr = &core_if->dev_if->dev_global_regs->dtknqr4_fifoemptymsk;
+	DWC_PRINTF("FIFOEMPMSK	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+
+	if (core_if->hwcfg2.b.multi_proc_int) {
+
+		addr = &core_if->dev_if->dev_global_regs->deachint;
+		DWC_PRINTF("DEACHINT	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->dev_if->dev_global_regs->deachintmsk;
+		DWC_PRINTF("DEACHINTMSK	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+
+		for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+			addr =
+			    &core_if->dev_if->
+			    dev_global_regs->diepeachintmsk[i];
+			DWC_PRINTF("DIEPEACHINTMSK[%d]	 @0x%08lX : 0x%08X\n",
+				   i, (unsigned long)addr,
+				   DWC_READ_REG32(addr));
+		}
+
+		for (i = 0; i <= core_if->dev_if->num_out_eps; i++) {
+			addr =
+			    &core_if->dev_if->
+			    dev_global_regs->doepeachintmsk[i];
+			DWC_PRINTF("DOEPEACHINTMSK[%d]	 @0x%08lX : 0x%08X\n",
+				   i, (unsigned long)addr,
+				   DWC_READ_REG32(addr));
+		}
+	}
+
+	for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+		DWC_PRINTF("Device IN EP %d Registers\n", i);
+		addr = &core_if->dev_if->in_ep_regs[i]->diepctl;
+		DWC_PRINTF("DIEPCTL	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->dev_if->in_ep_regs[i]->diepint;
+		DWC_PRINTF("DIEPINT	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->dev_if->in_ep_regs[i]->dieptsiz;
+		DWC_PRINTF("DIETSIZ	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->dev_if->in_ep_regs[i]->diepdma;
+		DWC_PRINTF("DIEPDMA	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->dev_if->in_ep_regs[i]->dtxfsts;
+		DWC_PRINTF("DTXFSTS	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->dev_if->in_ep_regs[i]->diepdmab;
+		DWC_PRINTF("DIEPDMAB	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, 0 /*DWC_READ_REG32(addr) */ );
+	}
+
+	for (i = 0; i <= core_if->dev_if->num_out_eps; i++) {
+		DWC_PRINTF("Device OUT EP %d Registers\n", i);
+		addr = &core_if->dev_if->out_ep_regs[i]->doepctl;
+		DWC_PRINTF("DOEPCTL	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->dev_if->out_ep_regs[i]->doepint;
+		DWC_PRINTF("DOEPINT	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->dev_if->out_ep_regs[i]->doeptsiz;
+		DWC_PRINTF("DOETSIZ	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->dev_if->out_ep_regs[i]->doepdma;
+		DWC_PRINTF("DOEPDMA	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		if (core_if->dma_enable) {	/* Don't access this register in SLAVE mode */
+			addr = &core_if->dev_if->out_ep_regs[i]->doepdmab;
+			DWC_PRINTF("DOEPDMAB	 @0x%08lX : 0x%08X\n",
+				   (unsigned long)addr, DWC_READ_REG32(addr));
+		}
+
+	}
+}
+
+/**
+ * This functions reads the SPRAM and prints its content
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+void dwc_otg_dump_spram(dwc_otg_core_if_t * core_if)
+{
+	volatile uint8_t *addr, *start_addr, *end_addr;
+
+	DWC_PRINTF("SPRAM Data:\n");
+	start_addr = (void *)core_if->core_global_regs;
+	DWC_PRINTF("Base Address: 0x%8lX\n", (unsigned long)start_addr);
+	start_addr += 0x00028000;
+	end_addr = (void *)core_if->core_global_regs;
+	end_addr += 0x000280e0;
+
+	for (addr = start_addr; addr < end_addr; addr += 16) {
+		DWC_PRINTF
+		    ("0x%8lX:\t%2X %2X %2X %2X %2X %2X %2X %2X %2X %2X %2X %2X %2X %2X %2X %2X\n",
+		     (unsigned long)addr, addr[0], addr[1], addr[2], addr[3],
+		     addr[4], addr[5], addr[6], addr[7], addr[8], addr[9],
+		     addr[10], addr[11], addr[12], addr[13], addr[14], addr[15]
+		    );
+	}
+
+	return;
+}
+
+/**
+ * This function reads the host registers and prints them
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+void dwc_otg_dump_host_registers(dwc_otg_core_if_t * core_if)
+{
+	int i;
+	volatile uint32_t *addr;
+
+	DWC_PRINTF("Host Global Registers\n");
+	addr = &core_if->host_if->host_global_regs->hcfg;
+	DWC_PRINTF("HCFG		 @0x%08lX : 0x%08X\n",
+		   (unsigned long)addr, DWC_READ_REG32(addr));
+	addr = &core_if->host_if->host_global_regs->hfir;
+	DWC_PRINTF("HFIR		 @0x%08lX : 0x%08X\n",
+		   (unsigned long)addr, DWC_READ_REG32(addr));
+	addr = &core_if->host_if->host_global_regs->hfnum;
+	DWC_PRINTF("HFNUM	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->host_if->host_global_regs->hptxsts;
+	DWC_PRINTF("HPTXSTS	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->host_if->host_global_regs->haint;
+	DWC_PRINTF("HAINT	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->host_if->host_global_regs->haintmsk;
+	DWC_PRINTF("HAINTMSK	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	if (core_if->dma_desc_enable) {
+		addr = &core_if->host_if->host_global_regs->hflbaddr;
+		DWC_PRINTF("HFLBADDR	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+	}
+
+	addr = core_if->host_if->hprt0;
+	DWC_PRINTF("HPRT0	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+
+	for (i = 0; i < core_if->core_params->host_channels; i++) {
+		DWC_PRINTF("Host Channel %d Specific Registers\n", i);
+		addr = &core_if->host_if->hc_regs[i]->hcchar;
+		DWC_PRINTF("HCCHAR	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->host_if->hc_regs[i]->hcsplt;
+		DWC_PRINTF("HCSPLT	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->host_if->hc_regs[i]->hcint;
+		DWC_PRINTF("HCINT	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->host_if->hc_regs[i]->hcintmsk;
+		DWC_PRINTF("HCINTMSK	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->host_if->hc_regs[i]->hctsiz;
+		DWC_PRINTF("HCTSIZ	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		addr = &core_if->host_if->hc_regs[i]->hcdma;
+		DWC_PRINTF("HCDMA	 @0x%08lX : 0x%08X\n",
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+		if (core_if->dma_desc_enable) {
+			addr = &core_if->host_if->hc_regs[i]->hcdmab;
+			DWC_PRINTF("HCDMAB	 @0x%08lX : 0x%08X\n",
+				   (unsigned long)addr, DWC_READ_REG32(addr));
+		}
+
+	}
+	return;
+}
+
+/**
+ * This function reads the core global registers and prints them
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+void dwc_otg_dump_global_registers(dwc_otg_core_if_t * core_if)
+{
+	int i, ep_num;
+	volatile uint32_t *addr;
+	char *txfsiz;
+
+	DWC_PRINTF("Core Global Registers\n");
+	addr = &core_if->core_global_regs->gotgctl;
+	DWC_PRINTF("GOTGCTL	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->gotgint;
+	DWC_PRINTF("GOTGINT	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->gahbcfg;
+	DWC_PRINTF("GAHBCFG	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->gusbcfg;
+	DWC_PRINTF("GUSBCFG	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->grstctl;
+	DWC_PRINTF("GRSTCTL	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->gintsts;
+	DWC_PRINTF("GINTSTS	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->gintmsk;
+	DWC_PRINTF("GINTMSK	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->grxstsr;
+	DWC_PRINTF("GRXSTSR	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->grxfsiz;
+	DWC_PRINTF("GRXFSIZ	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->gnptxfsiz;
+	DWC_PRINTF("GNPTXFSIZ @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->gnptxsts;
+	DWC_PRINTF("GNPTXSTS	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->gi2cctl;
+	DWC_PRINTF("GI2CCTL	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->gpvndctl;
+	DWC_PRINTF("GPVNDCTL	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->ggpio;
+	DWC_PRINTF("GGPIO	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->guid;
+	DWC_PRINTF("GUID		 @0x%08lX : 0x%08X\n",
+		   (unsigned long)addr, DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->gsnpsid;
+	DWC_PRINTF("GSNPSID	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->ghwcfg1;
+	DWC_PRINTF("GHWCFG1	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->ghwcfg2;
+	DWC_PRINTF("GHWCFG2	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->ghwcfg3;
+	DWC_PRINTF("GHWCFG3	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->ghwcfg4;
+	DWC_PRINTF("GHWCFG4	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->glpmcfg;
+	DWC_PRINTF("GLPMCFG	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->gpwrdn;
+	DWC_PRINTF("GPWRDN	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->gdfifocfg;
+	DWC_PRINTF("GDFIFOCFG	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+	addr = &core_if->core_global_regs->adpctl;
+	DWC_PRINTF("ADPCTL	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   dwc_otg_adp_read_reg(core_if));
+	addr = &core_if->core_global_regs->hptxfsiz;
+	DWC_PRINTF("HPTXFSIZ	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+
+	if (core_if->en_multiple_tx_fifo == 0) {
+		ep_num = core_if->hwcfg4.b.num_dev_perio_in_ep;
+		txfsiz = "DPTXFSIZ";
+	} else {
+		ep_num = core_if->hwcfg4.b.num_in_eps;
+		txfsiz = "DIENPTXF";
+	}
+	for (i = 0; i < ep_num; i++) {
+		addr = &core_if->core_global_regs->dtxfsiz[i];
+		DWC_PRINTF("%s[%d] @0x%08lX : 0x%08X\n", txfsiz, i + 1,
+			   (unsigned long)addr, DWC_READ_REG32(addr));
+	}
+	addr = core_if->pcgcctl;
+	DWC_PRINTF("PCGCCTL	 @0x%08lX : 0x%08X\n", (unsigned long)addr,
+		   DWC_READ_REG32(addr));
+}
+
+/**
+ * Flush a Tx FIFO.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param num Tx FIFO to flush.
+ */
+void dwc_otg_flush_tx_fifo(dwc_otg_core_if_t * core_if, const int num)
+{
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	volatile grstctl_t greset = {.d32 = 0 };
+	int count = 0;
+
+	DWC_DEBUGPL((DBG_CIL | DBG_PCDV), "Flush Tx FIFO %d\n", num);
+
+	greset.b.txfflsh = 1;
+	greset.b.txfnum = num;
+	DWC_WRITE_REG32(&global_regs->grstctl, greset.d32);
+
+	do {
+		greset.d32 = DWC_READ_REG32(&global_regs->grstctl);
+		if (++count > 10000) {
+			DWC_WARN("%s() HANG! GRSTCTL=%0x GNPTXSTS=0x%08x\n",
+				 __func__, greset.d32,
+				 DWC_READ_REG32(&global_regs->gnptxsts));
+			break;
+		}
+		dwc_udelay(1);
+	} while (greset.b.txfflsh == 1);
+
+	/* Wait for 3 PHY Clocks */
+	dwc_udelay(1);
+}
+
+/**
+ * Flush Rx FIFO.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+void dwc_otg_flush_rx_fifo(dwc_otg_core_if_t * core_if)
+{
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	volatile grstctl_t greset = {.d32 = 0 };
+	int count = 0;
+
+	DWC_DEBUGPL((DBG_CIL | DBG_PCDV), "%s\n", __func__);
+	/*
+	 *
+	 */
+	greset.b.rxfflsh = 1;
+	DWC_WRITE_REG32(&global_regs->grstctl, greset.d32);
+
+	do {
+		greset.d32 = DWC_READ_REG32(&global_regs->grstctl);
+		if (++count > 10000) {
+			DWC_WARN("%s() HANG! GRSTCTL=%0x\n", __func__,
+				 greset.d32);
+			break;
+		}
+		dwc_udelay(1);
+	} while (greset.b.rxfflsh == 1);
+
+	/* Wait for 3 PHY Clocks */
+	dwc_udelay(1);
+}
+
+/**
+ * Do core a soft reset of the core.  Be careful with this because it
+ * resets all the internal state machines of the core.
+ */
+void dwc_otg_core_reset(dwc_otg_core_if_t * core_if)
+{
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	volatile grstctl_t greset = {.d32 = 0 };
+	int count = 0;
+
+	DWC_DEBUGPL(DBG_CILV, "%s\n", __func__);
+	/* Wait for AHB master IDLE state. */
+	do {
+		dwc_udelay(10);
+		greset.d32 = DWC_READ_REG32(&global_regs->grstctl);
+		if (++count > 100000) {
+			DWC_WARN("%s() HANG! AHB Idle GRSTCTL=%0x\n", __func__,
+				 greset.d32);
+			return;
+		}
+	}
+	while (greset.b.ahbidle == 0);
+
+	/* Core Soft Reset */
+	count = 0;
+	greset.b.csftrst = 1;
+	DWC_WRITE_REG32(&global_regs->grstctl, greset.d32);
+	do {
+		greset.d32 = DWC_READ_REG32(&global_regs->grstctl);
+		if (++count > 10000) {
+			DWC_WARN("%s() HANG! Soft Reset GRSTCTL=%0x\n",
+				 __func__, greset.d32);
+			break;
+		}
+		dwc_udelay(1);
+	}
+	while (greset.b.csftrst == 1);
+
+	/* Wait for 3 PHY Clocks */
+	dwc_mdelay(100);
+}
+
+uint8_t dwc_otg_is_device_mode(dwc_otg_core_if_t * _core_if)
+{
+	return (dwc_otg_mode(_core_if) != DWC_HOST_MODE);
+}
+
+uint8_t dwc_otg_is_host_mode(dwc_otg_core_if_t * _core_if)
+{
+	return (dwc_otg_mode(_core_if) == DWC_HOST_MODE);
+}
+
+/**
+ * Register HCD callbacks. The callbacks are used to start and stop
+ * the HCD for interrupt processing.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param cb the HCD callback structure.
+ * @param p pointer to be passed to callback function (usb_hcd*).
+ */
+void dwc_otg_cil_register_hcd_callbacks(dwc_otg_core_if_t * core_if,
+					dwc_otg_cil_callbacks_t * cb, void *p)
+{
+	core_if->hcd_cb = cb;
+	cb->p = p;
+}
+
+/**
+ * Register PCD callbacks. The callbacks are used to start and stop
+ * the PCD for interrupt processing.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param cb the PCD callback structure.
+ * @param p pointer to be passed to callback function (pcd*).
+ */
+void dwc_otg_cil_register_pcd_callbacks(dwc_otg_core_if_t * core_if,
+					dwc_otg_cil_callbacks_t * cb, void *p)
+{
+	core_if->pcd_cb = cb;
+	cb->p = p;
+}
+
+#ifdef DWC_EN_ISOC
+
+/**
+ * This function writes isoc data per 1 (micro)frame into tx fifo
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to start the transfer on.
+ *
+ */
+void write_isoc_frame_data(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	dwc_otg_dev_in_ep_regs_t *ep_regs;
+	dtxfsts_data_t txstatus = {.d32 = 0 };
+	uint32_t len = 0;
+	uint32_t dwords;
+
+	ep->xfer_len = ep->data_per_frame;
+	ep->xfer_count = 0;
+
+	ep_regs = core_if->dev_if->in_ep_regs[ep->num];
+
+	len = ep->xfer_len - ep->xfer_count;
+
+	if (len > ep->maxpacket) {
+		len = ep->maxpacket;
+	}
+
+	dwords = (len + 3) / 4;
+
+	/* While there is space in the queue and space in the FIFO and
+	 * More data to tranfer, Write packets to the Tx FIFO */
+	txstatus.d32 =
+	    DWC_READ_REG32(&core_if->dev_if->in_ep_regs[ep->num]->dtxfsts);
+	DWC_DEBUGPL(DBG_PCDV, "b4 dtxfsts[%d]=0x%08x\n", ep->num, txstatus.d32);
+
+	while (txstatus.b.txfspcavail > dwords &&
+	       ep->xfer_count < ep->xfer_len && ep->xfer_len != 0) {
+		/* Write the FIFO */
+		dwc_otg_ep_write_packet(core_if, ep, 0);
+
+		len = ep->xfer_len - ep->xfer_count;
+		if (len > ep->maxpacket) {
+			len = ep->maxpacket;
+		}
+
+		dwords = (len + 3) / 4;
+		txstatus.d32 =
+		    DWC_READ_REG32(&core_if->dev_if->in_ep_regs[ep->num]->
+				   dtxfsts);
+		DWC_DEBUGPL(DBG_PCDV, "dtxfsts[%d]=0x%08x\n", ep->num,
+			    txstatus.d32);
+	}
+}
+
+/**
+ * This function initializes a descriptor chain for Isochronous transfer
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to start the transfer on.
+ *
+ */
+void dwc_otg_iso_ep_start_frm_transfer(dwc_otg_core_if_t * core_if,
+				       dwc_ep_t * ep)
+{
+	deptsiz_data_t deptsiz = {.d32 = 0 };
+	depctl_data_t depctl = {.d32 = 0 };
+	dsts_data_t dsts = {.d32 = 0 };
+	volatile uint32_t *addr;
+
+	if (ep->is_in) {
+		addr = &core_if->dev_if->in_ep_regs[ep->num]->diepctl;
+	} else {
+		addr = &core_if->dev_if->out_ep_regs[ep->num]->doepctl;
+	}
+
+	ep->xfer_len = ep->data_per_frame;
+	ep->xfer_count = 0;
+	ep->xfer_buff = ep->cur_pkt_addr;
+	ep->dma_addr = ep->cur_pkt_dma_addr;
+
+	if (ep->is_in) {
+		/* Program the transfer size and packet count
+		 *      as follows: xfersize = N * maxpacket +
+		 *      short_packet pktcnt = N + (short_packet
+		 *      exist ? 1 : 0)
+		 */
+		deptsiz.b.xfersize = ep->xfer_len;
+		deptsiz.b.pktcnt =
+		    (ep->xfer_len - 1 + ep->maxpacket) / ep->maxpacket;
+		deptsiz.b.mc = deptsiz.b.pktcnt;
+		DWC_WRITE_REG32(&core_if->dev_if->in_ep_regs[ep->num]->dieptsiz,
+				deptsiz.d32);
+
+		/* Write the DMA register */
+		if (core_if->dma_enable) {
+			DWC_WRITE_REG32(&
+					(core_if->dev_if->in_ep_regs[ep->num]->
+					 diepdma), (uint32_t) ep->dma_addr);
+		}
+	} else {
+		deptsiz.b.pktcnt =
+		    (ep->xfer_len + (ep->maxpacket - 1)) / ep->maxpacket;
+		deptsiz.b.xfersize = deptsiz.b.pktcnt * ep->maxpacket;
+
+		DWC_WRITE_REG32(&core_if->dev_if->
+				out_ep_regs[ep->num]->doeptsiz, deptsiz.d32);
+
+		if (core_if->dma_enable) {
+			DWC_WRITE_REG32(&
+					(core_if->dev_if->
+					 out_ep_regs[ep->num]->doepdma),
+					(uint32_t) ep->dma_addr);
+		}
+	}
+
+	/** Enable endpoint, clear nak  */
+
+	depctl.d32 = 0;
+	if (ep->bInterval == 1) {
+		dsts.d32 =
+		    DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dsts);
+		ep->next_frame = dsts.b.soffn + ep->bInterval;
+
+		if (ep->next_frame & 0x1) {
+			depctl.b.setd1pid = 1;
+		} else {
+			depctl.b.setd0pid = 1;
+		}
+	} else {
+		ep->next_frame += ep->bInterval;
+
+		if (ep->next_frame & 0x1) {
+			depctl.b.setd1pid = 1;
+		} else {
+			depctl.b.setd0pid = 1;
+		}
+	}
+	depctl.b.epena = 1;
+	depctl.b.cnak = 1;
+
+	DWC_MODIFY_REG32(addr, 0, depctl.d32);
+	depctl.d32 = DWC_READ_REG32(addr);
+
+	if (ep->is_in && core_if->dma_enable == 0) {
+		write_isoc_frame_data(core_if, ep);
+	}
+
+}
+#endif /* DWC_EN_ISOC */
+
+static void dwc_otg_set_uninitialized(int32_t * p, int size)
+{
+	int i;
+	for (i = 0; i < size; i++) {
+		p[i] = -1;
+	}
+}
+
+static int dwc_otg_param_initialized(int32_t val)
+{
+	return val != -1;
+}
+
+static int dwc_otg_setup_params(dwc_otg_core_if_t * core_if)
+{
+	int i;
+	gintsts_data_t gintsts;
+	gintsts.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintsts);
+
+	core_if->core_params = DWC_ALLOC(sizeof(*core_if->core_params));
+	if (!core_if->core_params) {
+		return -DWC_E_NO_MEMORY;
+	}
+	dwc_otg_set_uninitialized((int32_t *) core_if->core_params,
+				  sizeof(*core_if->core_params) /
+				  sizeof(int32_t));
+	DWC_PRINTF("Setting default values for core params\n");
+	dwc_otg_set_param_otg_cap(core_if, dwc_param_otg_cap_default);
+	dwc_otg_set_param_dma_enable(core_if, dwc_param_dma_enable_default);
+	dwc_otg_set_param_dma_desc_enable(core_if,
+					  dwc_param_dma_desc_enable_default);
+	dwc_otg_set_param_opt(core_if, dwc_param_opt_default);
+	dwc_otg_set_param_dma_burst_size(core_if,
+					 dwc_param_dma_burst_size_default);
+	dwc_otg_set_param_host_support_fs_ls_low_power(core_if,
+						       dwc_param_host_support_fs_ls_low_power_default);
+	dwc_otg_set_param_enable_dynamic_fifo(core_if,
+					      dwc_param_enable_dynamic_fifo_default);
+	dwc_otg_set_param_data_fifo_size(core_if,
+					 dwc_param_data_fifo_size_default);
+	dwc_otg_set_param_dev_rx_fifo_size(core_if,
+					   dwc_param_dev_rx_fifo_size_default);
+	dwc_otg_set_param_dev_nperio_tx_fifo_size(core_if,
+						  dwc_param_dev_nperio_tx_fifo_size_default);
+	dwc_otg_set_param_host_rx_fifo_size(core_if,
+					    dwc_param_host_rx_fifo_size_default);
+	dwc_otg_set_param_host_nperio_tx_fifo_size(core_if,
+						   dwc_param_host_nperio_tx_fifo_size_default);
+	dwc_otg_set_param_host_perio_tx_fifo_size(core_if,
+						  dwc_param_host_perio_tx_fifo_size_default);
+	dwc_otg_set_param_max_transfer_size(core_if,
+					    dwc_param_max_transfer_size_default);
+	dwc_otg_set_param_max_packet_count(core_if,
+					   dwc_param_max_packet_count_default);
+	dwc_otg_set_param_host_channels(core_if,
+					dwc_param_host_channels_default);
+	dwc_otg_set_param_dev_endpoints(core_if,
+					dwc_param_dev_endpoints_default);
+	dwc_otg_set_param_phy_type(core_if, dwc_param_phy_type_default);
+	dwc_otg_set_param_speed(core_if, dwc_param_speed_default);
+	dwc_otg_set_param_host_ls_low_power_phy_clk(core_if,
+						    dwc_param_host_ls_low_power_phy_clk_default);
+	dwc_otg_set_param_phy_ulpi_ddr(core_if, dwc_param_phy_ulpi_ddr_default);
+	dwc_otg_set_param_phy_ulpi_ext_vbus(core_if,
+					    dwc_param_phy_ulpi_ext_vbus_default);
+	dwc_otg_set_param_phy_utmi_width(core_if,
+					 dwc_param_phy_utmi_width_default);
+	dwc_otg_set_param_ts_dline(core_if, dwc_param_ts_dline_default);
+	dwc_otg_set_param_i2c_enable(core_if, dwc_param_i2c_enable_default);
+	dwc_otg_set_param_ulpi_fs_ls(core_if, dwc_param_ulpi_fs_ls_default);
+	dwc_otg_set_param_en_multiple_tx_fifo(core_if,
+					      dwc_param_en_multiple_tx_fifo_default);
+
+	if (gintsts.b.curmode) {
+		/* Force device mode to get power-on values of device FIFOs */
+		gusbcfg_data_t gusbcfg = {.d32 = 0 };
+		gusbcfg.d32 =  DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+		gusbcfg.b.force_dev_mode = 1;
+		DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg, gusbcfg.d32);
+		dwc_mdelay(100);
+		for (i = 0; i < 15; i++) {
+		dwc_otg_set_param_dev_perio_tx_fifo_size(core_if,
+							 dwc_param_dev_perio_tx_fifo_size_default, i);
+		}
+		for (i = 0; i < 15; i++) {
+			dwc_otg_set_param_dev_tx_fifo_size(core_if,
+							   dwc_param_dev_tx_fifo_size_default, i);
+		}
+		gusbcfg.d32 =  DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+		gusbcfg.b.force_dev_mode = 0;
+		DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg, gusbcfg.d32);
+		dwc_mdelay(100);
+	} else {
+		for (i = 0; i < 15; i++) {
+			dwc_otg_set_param_dev_perio_tx_fifo_size(core_if,
+				dwc_param_dev_perio_tx_fifo_size_default, i);
+		}
+		for (i = 0; i < 15; i++) {
+			dwc_otg_set_param_dev_tx_fifo_size(core_if,
+				dwc_param_dev_tx_fifo_size_default, i);
+		}
+	}
+
+	dwc_otg_set_param_thr_ctl(core_if, dwc_param_thr_ctl_default);
+	dwc_otg_set_param_mpi_enable(core_if, dwc_param_mpi_enable_default);
+	dwc_otg_set_param_pti_enable(core_if, dwc_param_pti_enable_default);
+	dwc_otg_set_param_lpm_enable(core_if, dwc_param_lpm_enable_default);
+
+	dwc_otg_set_param_besl_enable(core_if, dwc_param_besl_enable_default);
+	dwc_otg_set_param_baseline_besl(core_if, dwc_param_baseline_besl_default);
+	dwc_otg_set_param_deep_besl(core_if, dwc_param_deep_besl_default);
+
+	dwc_otg_set_param_ic_usb_cap(core_if, dwc_param_ic_usb_cap_default);
+	dwc_otg_set_param_tx_thr_length(core_if,
+					dwc_param_tx_thr_length_default);
+	dwc_otg_set_param_rx_thr_length(core_if,
+					dwc_param_rx_thr_length_default);
+	dwc_otg_set_param_ahb_thr_ratio(core_if,
+					dwc_param_ahb_thr_ratio_default);
+	dwc_otg_set_param_power_down(core_if, dwc_param_power_down_default);
+	dwc_otg_set_param_reload_ctl(core_if, dwc_param_reload_ctl_default);
+	dwc_otg_set_param_dev_out_nak(core_if, dwc_param_dev_out_nak_default);
+	dwc_otg_set_param_cont_on_bna(core_if, dwc_param_cont_on_bna_default);
+	dwc_otg_set_param_ahb_single(core_if, dwc_param_ahb_single_default);
+	dwc_otg_set_param_otg_ver(core_if, dwc_param_otg_ver_default);
+	dwc_otg_set_param_adp_enable(core_if, dwc_param_adp_enable_default);
+	return 0;
+}
+
+uint8_t dwc_otg_is_dma_enable(dwc_otg_core_if_t * core_if)
+{
+	return core_if->dma_enable;
+}
+
+/* Checks if the parameter is outside of its valid range of values */
+#define DWC_OTG_PARAM_TEST(_param_, _low_, _high_) \
+		(((_param_) < (_low_)) || \
+		((_param_) > (_high_)))
+
+/* Parameter access functions */
+int dwc_otg_set_param_otg_cap(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int valid;
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 0, 2)) {
+		DWC_WARN("Wrong value for otg_cap parameter\n");
+		DWC_WARN("otg_cap parameter must be 0,1 or 2\n");
+		retval = -DWC_E_INVALID;
+		goto out;
+	}
+
+	valid = 1;
+	switch (val) {
+	case DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE:
+		if (core_if->hwcfg2.b.op_mode !=
+		    DWC_HWCFG2_OP_MODE_HNP_SRP_CAPABLE_OTG)
+			valid = 0;
+		break;
+	case DWC_OTG_CAP_PARAM_SRP_ONLY_CAPABLE:
+		if ((core_if->hwcfg2.b.op_mode !=
+		     DWC_HWCFG2_OP_MODE_HNP_SRP_CAPABLE_OTG)
+		    && (core_if->hwcfg2.b.op_mode !=
+			DWC_HWCFG2_OP_MODE_SRP_ONLY_CAPABLE_OTG)
+		    && (core_if->hwcfg2.b.op_mode !=
+			DWC_HWCFG2_OP_MODE_SRP_CAPABLE_DEVICE)
+		    && (core_if->hwcfg2.b.op_mode !=
+			DWC_HWCFG2_OP_MODE_SRP_CAPABLE_HOST)) {
+			valid = 0;
+		}
+		break;
+	case DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE:
+		/* always valid */
+		break;
+	}
+	if (!valid) {
+		if (dwc_otg_param_initialized(core_if->core_params->otg_cap)) {
+			DWC_ERROR
+			    ("%d invalid for otg_cap paremter. Check HW configuration.\n",
+			     val);
+		}
+		val =
+		    (((core_if->hwcfg2.b.op_mode ==
+		       DWC_HWCFG2_OP_MODE_HNP_SRP_CAPABLE_OTG)
+		      || (core_if->hwcfg2.b.op_mode ==
+			  DWC_HWCFG2_OP_MODE_SRP_ONLY_CAPABLE_OTG)
+		      || (core_if->hwcfg2.b.op_mode ==
+			  DWC_HWCFG2_OP_MODE_SRP_CAPABLE_DEVICE)
+		      || (core_if->hwcfg2.b.op_mode ==
+			  DWC_HWCFG2_OP_MODE_SRP_CAPABLE_HOST)) ?
+		     DWC_OTG_CAP_PARAM_SRP_ONLY_CAPABLE :
+		     DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE);
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->otg_cap = val;
+out:
+	return retval;
+}
+
+int32_t dwc_otg_get_param_otg_cap(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->otg_cap;
+}
+
+int dwc_otg_set_param_opt(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong value for opt parameter\n");
+		return -DWC_E_INVALID;
+	}
+	core_if->core_params->opt = val;
+	return 0;
+}
+
+int32_t dwc_otg_get_param_opt(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->opt;
+}
+
+int dwc_otg_set_param_dma_enable(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong value for dma enable\n");
+		return -DWC_E_INVALID;
+	}
+
+	if ((val == 1) && (core_if->hwcfg2.b.architecture == 0)) {
+		if (dwc_otg_param_initialized(core_if->core_params->dma_enable)) {
+			DWC_ERROR
+			    ("%d invalid for dma_enable paremter. Check HW configuration.\n",
+			     val);
+		}
+		val = 0;
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->dma_enable = val;
+	if (val == 0) {
+		dwc_otg_set_param_dma_desc_enable(core_if, 0);
+	}
+	return retval;
+}
+
+int32_t dwc_otg_get_param_dma_enable(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->dma_enable;
+}
+
+int dwc_otg_set_param_dma_desc_enable(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong value for dma_enable\n");
+		DWC_WARN("dma_desc_enable must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	if ((val == 1)
+	    && ((dwc_otg_get_param_dma_enable(core_if) == 0)
+		|| (core_if->hwcfg4.b.desc_dma == 0))) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->dma_desc_enable)) {
+			DWC_ERROR
+			    ("%d invalid for dma_desc_enable paremter. Check HW configuration.\n",
+			     val);
+		}
+		val = 0;
+		retval = -DWC_E_INVALID;
+	}
+	core_if->core_params->dma_desc_enable = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_dma_desc_enable(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->dma_desc_enable;
+}
+
+int dwc_otg_set_param_host_support_fs_ls_low_power(dwc_otg_core_if_t * core_if,
+						   int32_t val)
+{
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong value for host_support_fs_low_power\n");
+		DWC_WARN("host_support_fs_low_power must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+	core_if->core_params->host_support_fs_ls_low_power = val;
+	return 0;
+}
+
+int32_t dwc_otg_get_param_host_support_fs_ls_low_power(dwc_otg_core_if_t *
+						       core_if)
+{
+	return core_if->core_params->host_support_fs_ls_low_power;
+}
+
+int dwc_otg_set_param_enable_dynamic_fifo(dwc_otg_core_if_t * core_if,
+					  int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong value for enable_dynamic_fifo\n");
+		DWC_WARN("enable_dynamic_fifo must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	if ((val == 1) && (core_if->hwcfg2.b.dynamic_fifo == 0)) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->enable_dynamic_fifo)) {
+			DWC_ERROR
+			    ("%d invalid for enable_dynamic_fifo paremter. Check HW configuration.\n",
+			     val);
+		}
+		val = 0;
+		retval = -DWC_E_INVALID;
+	}
+	core_if->core_params->enable_dynamic_fifo = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_enable_dynamic_fifo(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->enable_dynamic_fifo;
+}
+
+int dwc_otg_set_param_data_fifo_size(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 32, 32768)) {
+		DWC_WARN("Wrong value for data_fifo_size\n");
+		DWC_WARN("data_fifo_size must be 32-32768\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val > core_if->hwcfg3.b.dfifo_depth) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->data_fifo_size)) {
+			DWC_ERROR
+			    ("%d invalid for data_fifo_size parameter. Check HW configuration.\n",
+			     val);
+		}
+		val = core_if->hwcfg3.b.dfifo_depth;
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->data_fifo_size = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_data_fifo_size(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->data_fifo_size;
+}
+
+int dwc_otg_set_param_dev_rx_fifo_size(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 16, 32768)) {
+		DWC_WARN("Wrong value for dev_rx_fifo_size\n");
+		DWC_WARN("dev_rx_fifo_size must be 16-32768\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val > DWC_READ_REG32(&core_if->core_global_regs->grxfsiz)) {
+		if (dwc_otg_param_initialized(core_if->core_params->dev_rx_fifo_size)) {
+		DWC_WARN("%d invalid for dev_rx_fifo_size parameter\n", val);
+		}
+		val = DWC_READ_REG32(&core_if->core_global_regs->grxfsiz);
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->dev_rx_fifo_size = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_dev_rx_fifo_size(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->dev_rx_fifo_size;
+}
+
+int dwc_otg_set_param_dev_nperio_tx_fifo_size(dwc_otg_core_if_t * core_if,
+					      int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 16, 32768)) {
+		DWC_WARN("Wrong value for dev_nperio_tx_fifo\n");
+		DWC_WARN("dev_nperio_tx_fifo must be 16-32768\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val > (DWC_READ_REG32(&core_if->core_global_regs->gnptxfsiz) >> 16)) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->dev_nperio_tx_fifo_size)) {
+			DWC_ERROR
+			    ("%d invalid for dev_nperio_tx_fifo_size. Check HW configuration.\n",
+			     val);
+		}
+		val =
+		    (DWC_READ_REG32(&core_if->core_global_regs->gnptxfsiz) >>
+		     16);
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->dev_nperio_tx_fifo_size = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_dev_nperio_tx_fifo_size(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->dev_nperio_tx_fifo_size;
+}
+
+int dwc_otg_set_param_host_rx_fifo_size(dwc_otg_core_if_t * core_if,
+					int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 16, 32768)) {
+		DWC_WARN("Wrong value for host_rx_fifo_size\n");
+		DWC_WARN("host_rx_fifo_size must be 16-32768\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val > DWC_READ_REG32(&core_if->core_global_regs->grxfsiz)) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->host_rx_fifo_size)) {
+			DWC_ERROR
+			    ("%d invalid for host_rx_fifo_size. Check HW configuration.\n",
+			     val);
+		}
+		val = DWC_READ_REG32(&core_if->core_global_regs->grxfsiz);
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->host_rx_fifo_size = val;
+	return retval;
+
+}
+
+int32_t dwc_otg_get_param_host_rx_fifo_size(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->host_rx_fifo_size;
+}
+
+int dwc_otg_set_param_host_nperio_tx_fifo_size(dwc_otg_core_if_t * core_if,
+					       int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 16, 32768)) {
+		DWC_WARN("Wrong value for host_nperio_tx_fifo_size\n");
+		DWC_WARN("host_nperio_tx_fifo_size must be 16-32768\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val > (DWC_READ_REG32(&core_if->core_global_regs->gnptxfsiz) >> 16)) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->host_nperio_tx_fifo_size)) {
+			DWC_ERROR
+			    ("%d invalid for host_nperio_tx_fifo_size. Check HW configuration.\n",
+			     val);
+		}
+		val =
+		    (DWC_READ_REG32(&core_if->core_global_regs->gnptxfsiz) >>
+		     16);
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->host_nperio_tx_fifo_size = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_host_nperio_tx_fifo_size(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->host_nperio_tx_fifo_size;
+}
+
+int dwc_otg_set_param_host_perio_tx_fifo_size(dwc_otg_core_if_t * core_if,
+					      int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 16, 32768)) {
+		DWC_WARN("Wrong value for host_perio_tx_fifo_size\n");
+		DWC_WARN("host_perio_tx_fifo_size must be 16-32768\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val > ((core_if->hptxfsiz.d32) >> 16)) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->host_perio_tx_fifo_size)) {
+			DWC_ERROR
+			    ("%d invalid for host_perio_tx_fifo_size. Check HW configuration.\n",
+			     val);
+		}
+		val = (core_if->hptxfsiz.d32) >> 16;
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->host_perio_tx_fifo_size = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_host_perio_tx_fifo_size(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->host_perio_tx_fifo_size;
+}
+
+int dwc_otg_set_param_max_transfer_size(dwc_otg_core_if_t * core_if,
+					int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 2047, 524288)) {
+		DWC_WARN("Wrong value for max_transfer_size\n");
+		DWC_WARN("max_transfer_size must be 2047-524288\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val >= (1 << (core_if->hwcfg3.b.xfer_size_cntr_width + 11))) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->max_transfer_size)) {
+			DWC_ERROR
+			    ("%d invalid for max_transfer_size. Check HW configuration.\n",
+			     val);
+		}
+		val =
+		    ((1 << (core_if->hwcfg3.b.packet_size_cntr_width + 11)) -
+		     1);
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->max_transfer_size = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_max_transfer_size(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->max_transfer_size;
+}
+
+int dwc_otg_set_param_max_packet_count(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 15, 511)) {
+		DWC_WARN("Wrong value for max_packet_count\n");
+		DWC_WARN("max_packet_count must be 15-511\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val > (1 << (core_if->hwcfg3.b.packet_size_cntr_width + 4))) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->max_packet_count)) {
+			DWC_ERROR
+			    ("%d invalid for max_packet_count. Check HW configuration.\n",
+			     val);
+		}
+		val =
+		    ((1 << (core_if->hwcfg3.b.packet_size_cntr_width + 4)) - 1);
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->max_packet_count = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_max_packet_count(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->max_packet_count;
+}
+
+int dwc_otg_set_param_host_channels(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 1, 16)) {
+		DWC_WARN("Wrong value for host_channels\n");
+		DWC_WARN("host_channels must be 1-16\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val > (core_if->hwcfg2.b.num_host_chan + 1)) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->host_channels)) {
+			DWC_ERROR
+			    ("%d invalid for host_channels. Check HW configurations.\n",
+			     val);
+		}
+		val = (core_if->hwcfg2.b.num_host_chan + 1);
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->host_channels = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_host_channels(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->host_channels;
+}
+
+int dwc_otg_set_param_dev_endpoints(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 1, 15)) {
+		DWC_WARN("Wrong value for dev_endpoints\n");
+		DWC_WARN("dev_endpoints must be 1-15\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val > (core_if->hwcfg2.b.num_dev_ep)) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->dev_endpoints)) {
+			DWC_ERROR
+			    ("%d invalid for dev_endpoints. Check HW configurations.\n",
+			     val);
+		}
+		val = core_if->hwcfg2.b.num_dev_ep;
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->dev_endpoints = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_dev_endpoints(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->dev_endpoints;
+}
+
+int dwc_otg_set_param_phy_type(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	int valid = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 2)) {
+		DWC_WARN("Wrong value for phy_type\n");
+		DWC_WARN("phy_type must be 0,1 or 2\n");
+		return -DWC_E_INVALID;
+	}
+#ifndef NO_FS_PHY_HW_CHECKS
+	if ((val == DWC_PHY_TYPE_PARAM_UTMI) &&
+	    ((core_if->hwcfg2.b.hs_phy_type == 1) ||
+	     (core_if->hwcfg2.b.hs_phy_type == 3))) {
+		valid = 1;
+	} else if ((val == DWC_PHY_TYPE_PARAM_ULPI) &&
+		   ((core_if->hwcfg2.b.hs_phy_type == 2) ||
+		    (core_if->hwcfg2.b.hs_phy_type == 3))) {
+		valid = 1;
+	} else if ((val == DWC_PHY_TYPE_PARAM_FS) &&
+		   (core_if->hwcfg2.b.fs_phy_type == 1)) {
+		valid = 1;
+	}
+	if (!valid) {
+		if (dwc_otg_param_initialized(core_if->core_params->phy_type)) {
+			DWC_ERROR
+			    ("%d invalid for phy_type. Check HW configurations.\n",
+			     val);
+		}
+		if (core_if->hwcfg2.b.hs_phy_type) {
+			if ((core_if->hwcfg2.b.hs_phy_type == 3) ||
+			    (core_if->hwcfg2.b.hs_phy_type == 1)) {
+				val = DWC_PHY_TYPE_PARAM_UTMI;
+			} else {
+				val = DWC_PHY_TYPE_PARAM_ULPI;
+			}
+		}
+		retval = -DWC_E_INVALID;
+	}
+#endif
+	core_if->core_params->phy_type = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_phy_type(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->phy_type;
+}
+
+int dwc_otg_set_param_speed(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong value for speed parameter\n");
+		DWC_WARN("max_speed parameter must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+	if ((val == 0)
+	    && dwc_otg_get_param_phy_type(core_if) == DWC_PHY_TYPE_PARAM_FS) {
+		if (dwc_otg_param_initialized(core_if->core_params->speed)) {
+			DWC_ERROR
+			    ("%d invalid for speed paremter. Check HW configuration.\n",
+			     val);
+		}
+		val =
+		    (dwc_otg_get_param_phy_type(core_if) ==
+		     DWC_PHY_TYPE_PARAM_FS ? 1 : 0);
+		retval = -DWC_E_INVALID;
+	}
+	core_if->core_params->speed = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_speed(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->speed;
+}
+
+int dwc_otg_set_param_host_ls_low_power_phy_clk(dwc_otg_core_if_t * core_if,
+						int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN
+		    ("Wrong value for host_ls_low_power_phy_clk parameter\n");
+		DWC_WARN("host_ls_low_power_phy_clk must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	if ((val == DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_48MHZ)
+	    && (dwc_otg_get_param_phy_type(core_if) == DWC_PHY_TYPE_PARAM_FS)) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->host_ls_low_power_phy_clk)) {
+			DWC_ERROR
+			    ("%d invalid for host_ls_low_power_phy_clk. Check HW configuration.\n",
+			     val);
+		}
+		val =
+		    (dwc_otg_get_param_phy_type(core_if) ==
+		     DWC_PHY_TYPE_PARAM_FS) ?
+		    DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_6MHZ :
+		    DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_48MHZ;
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->host_ls_low_power_phy_clk = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_host_ls_low_power_phy_clk(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->host_ls_low_power_phy_clk;
+}
+
+int dwc_otg_set_param_phy_ulpi_ddr(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong value for phy_ulpi_ddr\n");
+		DWC_WARN("phy_upli_ddr must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	core_if->core_params->phy_ulpi_ddr = val;
+	return 0;
+}
+
+int32_t dwc_otg_get_param_phy_ulpi_ddr(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->phy_ulpi_ddr;
+}
+
+int dwc_otg_set_param_phy_ulpi_ext_vbus(dwc_otg_core_if_t * core_if,
+					int32_t val)
+{
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong valaue for phy_ulpi_ext_vbus\n");
+		DWC_WARN("phy_ulpi_ext_vbus must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	core_if->core_params->phy_ulpi_ext_vbus = val;
+	return 0;
+}
+
+int32_t dwc_otg_get_param_phy_ulpi_ext_vbus(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->phy_ulpi_ext_vbus;
+}
+
+int dwc_otg_set_param_phy_utmi_width(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	if (DWC_OTG_PARAM_TEST(val, 8, 8) && DWC_OTG_PARAM_TEST(val, 16, 16)) {
+		DWC_WARN("Wrong valaue for phy_utmi_width\n");
+		DWC_WARN("phy_utmi_width must be 8 or 16\n");
+		return -DWC_E_INVALID;
+	}
+
+	core_if->core_params->phy_utmi_width = val;
+	return 0;
+}
+
+int32_t dwc_otg_get_param_phy_utmi_width(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->phy_utmi_width;
+}
+
+int dwc_otg_set_param_ulpi_fs_ls(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong valaue for ulpi_fs_ls\n");
+		DWC_WARN("ulpi_fs_ls must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	core_if->core_params->ulpi_fs_ls = val;
+	return 0;
+}
+
+int32_t dwc_otg_get_param_ulpi_fs_ls(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->ulpi_fs_ls;
+}
+
+int dwc_otg_set_param_ts_dline(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong valaue for ts_dline\n");
+		DWC_WARN("ts_dline must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	core_if->core_params->ts_dline = val;
+	return 0;
+}
+
+int32_t dwc_otg_get_param_ts_dline(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->ts_dline;
+}
+
+int dwc_otg_set_param_i2c_enable(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong valaue for i2c_enable\n");
+		DWC_WARN("i2c_enable must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+#ifndef NO_FS_PHY_HW_CHECK
+	if (val == 1 && core_if->hwcfg3.b.i2c == 0) {
+		if (dwc_otg_param_initialized(core_if->core_params->i2c_enable)) {
+			DWC_ERROR
+			    ("%d invalid for i2c_enable. Check HW configuration.\n",
+			     val);
+		}
+		val = 0;
+		retval = -DWC_E_INVALID;
+	}
+#endif
+
+	core_if->core_params->i2c_enable = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_i2c_enable(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->i2c_enable;
+}
+
+int dwc_otg_set_param_dev_perio_tx_fifo_size(dwc_otg_core_if_t * core_if,
+					     int32_t val, int fifo_num)
+{
+	int retval = 0;
+	gintsts_data_t gintsts;
+	gintsts.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintsts);
+
+	if (DWC_OTG_PARAM_TEST(val, 4, 768)) {
+		DWC_WARN("Wrong value for dev_perio_tx_fifo_size\n");
+		DWC_WARN("dev_perio_tx_fifo_size must be 4-768\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val >
+	    (DWC_READ_REG32(&core_if->core_global_regs->dtxfsiz[fifo_num]) >> 16)) {
+		DWC_WARN("Value is larger then power-on FIFO size\n");
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->dev_perio_tx_fifo_size[fifo_num])) {
+			DWC_ERROR
+			    ("`%d' invalid for parameter `dev_perio_fifo_size_%d'. Check HW configuration.\n",
+			     val, fifo_num);
+		}
+		val = (DWC_READ_REG32(&core_if->core_global_regs->dtxfsiz[fifo_num]) >> 16);
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->dev_perio_tx_fifo_size[fifo_num] = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_dev_perio_tx_fifo_size(dwc_otg_core_if_t * core_if,
+						 int fifo_num)
+{
+	return core_if->core_params->dev_perio_tx_fifo_size[fifo_num];
+}
+
+int dwc_otg_set_param_en_multiple_tx_fifo(dwc_otg_core_if_t * core_if,
+					  int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong valaue for en_multiple_tx_fifo,\n");
+		DWC_WARN("en_multiple_tx_fifo must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val == 1 && core_if->hwcfg4.b.ded_fifo_en == 0) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->en_multiple_tx_fifo)) {
+			DWC_ERROR
+			    ("%d invalid for parameter en_multiple_tx_fifo. Check HW configuration.\n",
+			     val);
+		}
+		val = 0;
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->en_multiple_tx_fifo = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_en_multiple_tx_fifo(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->en_multiple_tx_fifo;
+}
+
+int dwc_otg_set_param_dev_tx_fifo_size(dwc_otg_core_if_t * core_if, int32_t val,
+				       int fifo_num)
+{
+	int retval = 0;
+	fifosize_data_t txfifosize;
+	txfifosize.d32 = DWC_READ_REG32(&core_if->core_global_regs->dtxfsiz[fifo_num]);
+
+	if (DWC_OTG_PARAM_TEST(val, 16, 32768)) {
+		DWC_WARN("Wrong value for dev_tx_fifo_size\n");
+		DWC_WARN("dev_tx_fifo_size must be 16-32768\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val > txfifosize.b.depth) {
+		DWC_WARN("Value is larger then power-on FIFO size\n");
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->dev_tx_fifo_size[fifo_num])) {
+			DWC_ERROR
+			    ("`%d' invalid for parameter `dev_tx_fifo_size_%d'. Check HW configuration.\n",
+			     val, fifo_num);
+		}
+		val = txfifosize.b.depth;
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->dev_tx_fifo_size[fifo_num] = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_dev_tx_fifo_size(dwc_otg_core_if_t * core_if,
+					   int fifo_num)
+{
+	return core_if->core_params->dev_tx_fifo_size[fifo_num];
+}
+
+int dwc_otg_set_param_thr_ctl(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 7)) {
+		DWC_WARN("Wrong value for thr_ctl\n");
+		DWC_WARN("thr_ctl must be 0-7\n");
+		return -DWC_E_INVALID;
+	}
+
+	if ((val != 0) &&
+	    (!dwc_otg_get_param_dma_enable(core_if) ||
+	     !core_if->hwcfg4.b.ded_fifo_en)) {
+		if (dwc_otg_param_initialized(core_if->core_params->thr_ctl)) {
+			DWC_ERROR
+			    ("%d invalid for parameter thr_ctl. Check HW configuration.\n",
+			     val);
+		}
+		val = 0;
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->thr_ctl = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_thr_ctl(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->thr_ctl;
+}
+
+int dwc_otg_set_param_lpm_enable(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong value for lpm_enable\n");
+		DWC_WARN("lpm_enable must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val && !core_if->hwcfg3.b.otg_lpm_en) {
+		if (dwc_otg_param_initialized(core_if->core_params->lpm_enable)) {
+			DWC_ERROR
+			    ("%d invalid for parameter lpm_enable. Check HW configuration.\n",
+			     val);
+		}
+		val = 0;
+		retval = -DWC_E_INVALID;
+	}
+
+	core_if->core_params->lpm_enable = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_lpm_enable(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->lpm_enable;
+}
+
+int dwc_otg_set_param_besl_enable(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("Wrong value for besl_enable\n");
+		DWC_WARN("besl_enable must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	core_if->core_params->besl_enable = val;
+
+	if(val)
+	{
+		retval += dwc_otg_set_param_lpm_enable(core_if,val);
+	}
+
+	return retval;
+}
+
+int32_t dwc_otg_get_param_besl_enable(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->besl_enable;
+}
+
+int dwc_otg_set_param_baseline_besl(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 15)) {
+		DWC_WARN("Wrong value for baseline_besl\n");
+		DWC_WARN("baseline_besl must be 0-15\n");
+		return -DWC_E_INVALID;
+	}
+
+	core_if->core_params->baseline_besl = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_baseline_besl(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->baseline_besl;
+}
+
+int dwc_otg_set_param_deep_besl(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 15)) {
+		DWC_WARN("Wrong value for deep_besl\n");
+		DWC_WARN("deep_besl must be 0-15\n");
+		return -DWC_E_INVALID;
+	}
+
+	core_if->core_params->deep_besl = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_deep_besl(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->deep_besl;
+}
+
+int dwc_otg_set_param_tx_thr_length(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	if (DWC_OTG_PARAM_TEST(val, 8, 128)) {
+		DWC_WARN("Wrong valaue for tx_thr_length\n");
+		DWC_WARN("tx_thr_length must be 8 - 128\n");
+		return -DWC_E_INVALID;
+	}
+
+	core_if->core_params->tx_thr_length = val;
+	return 0;
+}
+
+int32_t dwc_otg_get_param_tx_thr_length(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->tx_thr_length;
+}
+
+int dwc_otg_set_param_rx_thr_length(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	if (DWC_OTG_PARAM_TEST(val, 8, 128)) {
+		DWC_WARN("Wrong valaue for rx_thr_length\n");
+		DWC_WARN("rx_thr_length must be 8 - 128\n");
+		return -DWC_E_INVALID;
+	}
+
+	core_if->core_params->rx_thr_length = val;
+	return 0;
+}
+
+int32_t dwc_otg_get_param_rx_thr_length(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->rx_thr_length;
+}
+
+int dwc_otg_set_param_dma_burst_size(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	if (DWC_OTG_PARAM_TEST(val, 1, 1) &&
+	    DWC_OTG_PARAM_TEST(val, 4, 4) &&
+	    DWC_OTG_PARAM_TEST(val, 8, 8) &&
+	    DWC_OTG_PARAM_TEST(val, 16, 16) &&
+	    DWC_OTG_PARAM_TEST(val, 32, 32) &&
+	    DWC_OTG_PARAM_TEST(val, 64, 64) &&
+	    DWC_OTG_PARAM_TEST(val, 128, 128) &&
+	    DWC_OTG_PARAM_TEST(val, 256, 256)) {
+		DWC_WARN("`%d' invalid for parameter `dma_burst_size'\n", val);
+		return -DWC_E_INVALID;
+	}
+	core_if->core_params->dma_burst_size = val;
+	return 0;
+}
+
+int32_t dwc_otg_get_param_dma_burst_size(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->dma_burst_size;
+}
+
+int dwc_otg_set_param_pti_enable(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("`%d' invalid for parameter `pti_enable'\n", val);
+		return -DWC_E_INVALID;
+	}
+	if (val && (core_if->snpsid < OTG_CORE_REV_2_72a)) {
+		if (dwc_otg_param_initialized(core_if->core_params->pti_enable)) {
+			DWC_ERROR
+			    ("%d invalid for parameter pti_enable. Check HW configuration.\n",
+			     val);
+		}
+		retval = -DWC_E_INVALID;
+		val = 0;
+	}
+	core_if->core_params->pti_enable = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_pti_enable(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->pti_enable;
+}
+
+int dwc_otg_set_param_mpi_enable(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("`%d' invalid for parameter `mpi_enable'\n", val);
+		return -DWC_E_INVALID;
+	}
+	if (val && (core_if->hwcfg2.b.multi_proc_int == 0)) {
+		if (dwc_otg_param_initialized(core_if->core_params->mpi_enable)) {
+			DWC_ERROR
+			    ("%d invalid for parameter mpi_enable. Check HW configuration.\n",
+			     val);
+		}
+		retval = -DWC_E_INVALID;
+		val = 0;
+	}
+	core_if->core_params->mpi_enable = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_mpi_enable(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->mpi_enable;
+}
+
+int dwc_otg_set_param_adp_enable(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("`%d' invalid for parameter `adp_enable'\n", val);
+		return -DWC_E_INVALID;
+	}
+	if (val && (core_if->hwcfg3.b.adp_supp == 0)) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->adp_supp_enable)) {
+			DWC_ERROR
+			    ("%d invalid for parameter adp_enable. Check HW configuration.\n",
+			     val);
+		}
+		retval = -DWC_E_INVALID;
+		val = 0;
+	}
+	core_if->core_params->adp_supp_enable = val;
+	/* Set OTG version 2.0 in case of enabling ADP */
+	if (val)
+		dwc_otg_set_param_otg_ver(core_if, 1);
+
+	return retval;
+}
+
+int32_t dwc_otg_get_param_adp_enable(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->adp_supp_enable;
+}
+
+int dwc_otg_set_param_ic_usb_cap(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("`%d' invalid for parameter `ic_usb_cap'\n", val);
+		DWC_WARN("ic_usb_cap must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val && (core_if->hwcfg2.b.otg_enable_ic_usb == 0)) {
+		if (dwc_otg_param_initialized(core_if->core_params->ic_usb_cap)) {
+			DWC_ERROR
+			    ("%d invalid for parameter ic_usb_cap. Check HW configuration.\n",
+			     val);
+		}
+		retval = -DWC_E_INVALID;
+		val = 0;
+	}
+	core_if->core_params->ic_usb_cap = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_ic_usb_cap(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->ic_usb_cap;
+}
+
+int dwc_otg_set_param_ahb_thr_ratio(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	int valid = 1;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 3)) {
+		DWC_WARN("`%d' invalid for parameter `ahb_thr_ratio'\n", val);
+		DWC_WARN("ahb_thr_ratio must be 0 - 3\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (val
+	    && (core_if->snpsid < OTG_CORE_REV_2_81a
+		|| !dwc_otg_get_param_thr_ctl(core_if))) {
+		valid = 0;
+	} else if (val
+		   && ((dwc_otg_get_param_tx_thr_length(core_if) / (1 << val)) <
+		       4)) {
+		valid = 0;
+	}
+	if (valid == 0) {
+		if (dwc_otg_param_initialized
+		    (core_if->core_params->ahb_thr_ratio)) {
+			DWC_ERROR
+			    ("%d invalid for parameter ahb_thr_ratio. Check HW configuration.\n",
+			     val);
+		}
+		retval = -DWC_E_INVALID;
+		val = 0;
+	}
+
+	core_if->core_params->ahb_thr_ratio = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_ahb_thr_ratio(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->ahb_thr_ratio;
+}
+
+int dwc_otg_set_param_power_down(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	int valid = 1;
+	hwcfg4_data_t hwcfg4 = {.d32 = 0 };
+	hwcfg4.d32 = DWC_READ_REG32(&core_if->core_global_regs->ghwcfg4);
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 3)) {
+		DWC_WARN("`%d' invalid for parameter `power_down'\n", val);
+		DWC_WARN("power_down must be 0 - 2\n");
+		return -DWC_E_INVALID;
+	}
+
+	if ((val == 2) && (core_if->snpsid < OTG_CORE_REV_2_91a)) {
+		valid = 0;
+	}
+	if ((val == 3)
+	    && ((core_if->snpsid < OTG_CORE_REV_3_00a)
+		|| (hwcfg4.b.xhiber == 0))) {
+		valid = 0;
+	}
+	if (valid == 0) {
+		if (dwc_otg_param_initialized(core_if->core_params->power_down)) {
+			DWC_ERROR
+			    ("%d invalid for parameter power_down. Check HW configuration.\n",
+			     val);
+		}
+		retval = -DWC_E_INVALID;
+		val = 0;
+	}
+	core_if->core_params->power_down = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_power_down(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->power_down;
+}
+
+int dwc_otg_set_param_reload_ctl(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	int valid = 1;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("`%d' invalid for parameter `reload_ctl'\n", val);
+		DWC_WARN("reload_ctl must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	if ((val == 1) && (core_if->snpsid < OTG_CORE_REV_2_92a)) {
+		valid = 0;
+	}
+	if (valid == 0) {
+		if (dwc_otg_param_initialized(core_if->core_params->reload_ctl)) {
+			DWC_ERROR("%d invalid for parameter reload_ctl."
+				  "Check HW configuration.\n", val);
+		}
+		retval = -DWC_E_INVALID;
+		val = 0;
+	}
+	core_if->core_params->reload_ctl = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_reload_ctl(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->reload_ctl;
+}
+
+int dwc_otg_set_param_dev_out_nak(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	int valid = 1;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("`%d' invalid for parameter `dev_out_nak'\n", val);
+		DWC_WARN("dev_out_nak must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	if ((val == 1) && ((core_if->snpsid < OTG_CORE_REV_2_93a) ||
+			   !(core_if->core_params->dma_desc_enable))) {
+		valid = 0;
+	}
+	if (valid == 0) {
+		if (dwc_otg_param_initialized(core_if->core_params->dev_out_nak)) {
+			DWC_ERROR("%d invalid for parameter dev_out_nak."
+				  "Check HW configuration.\n", val);
+		}
+		retval = -DWC_E_INVALID;
+		val = 0;
+	}
+	core_if->core_params->dev_out_nak = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_dev_out_nak(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->dev_out_nak;
+}
+
+int dwc_otg_set_param_cont_on_bna(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	int valid = 1;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("`%d' invalid for parameter `cont_on_bna'\n", val);
+		DWC_WARN("cont_on_bna must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	if ((val == 1) && ((core_if->snpsid < OTG_CORE_REV_2_94a) ||
+			   !(core_if->core_params->dma_desc_enable))) {
+		valid = 0;
+	}
+	if (valid == 0) {
+		if (dwc_otg_param_initialized(core_if->core_params->cont_on_bna)) {
+			DWC_ERROR("%d invalid for parameter cont_on_bna."
+				"Check HW configuration.\n", val);
+		}
+		retval = -DWC_E_INVALID;
+		val = 0;
+	}
+	core_if->core_params->cont_on_bna = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_cont_on_bna(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->cont_on_bna;
+}
+
+int dwc_otg_set_param_ahb_single(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+	int valid = 1;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("`%d' invalid for parameter `ahb_single'\n", val);
+		DWC_WARN("ahb_single must be 0 or 1\n");
+		return -DWC_E_INVALID;
+	}
+
+	if ((val == 1) && (core_if->snpsid < OTG_CORE_REV_2_94a)) {
+		valid = 0;
+	}
+	if (valid == 0) {
+		if (dwc_otg_param_initialized(core_if->core_params->ahb_single)) {
+			DWC_ERROR("%d invalid for parameter ahb_single."
+				  "Check HW configuration.\n", val);
+		}
+		retval = -DWC_E_INVALID;
+		val = 0;
+	}
+	core_if->core_params->ahb_single = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_ahb_single(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->ahb_single;
+}
+
+int dwc_otg_set_param_otg_ver(dwc_otg_core_if_t * core_if, int32_t val)
+{
+	int retval = 0;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 1)) {
+		DWC_WARN("`%d' invalid for parameter `otg_ver'\n", val);
+		DWC_WARN
+		    ("otg_ver must be 0(for OTG 1.3 support) or 1(for OTG 2.0 support)\n");
+		return -DWC_E_INVALID;
+	}
+
+	core_if->core_params->otg_ver = val;
+	return retval;
+}
+
+int32_t dwc_otg_get_param_otg_ver(dwc_otg_core_if_t * core_if)
+{
+	return core_if->core_params->otg_ver;
+}
+
+uint32_t dwc_otg_get_hnpstatus(dwc_otg_core_if_t * core_if)
+{
+	gotgctl_data_t otgctl;
+	otgctl.d32 = DWC_READ_REG32(&core_if->core_global_regs->gotgctl);
+	return otgctl.b.hstnegscs;
+}
+
+uint32_t dwc_otg_get_srpstatus(dwc_otg_core_if_t * core_if)
+{
+	gotgctl_data_t otgctl;
+	otgctl.d32 = DWC_READ_REG32(&core_if->core_global_regs->gotgctl);
+	return otgctl.b.sesreqscs;
+}
+
+void dwc_otg_set_hnpreq(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	if(core_if->otg_ver == 0) {
+		gotgctl_data_t otgctl;
+		otgctl.d32 = DWC_READ_REG32(&core_if->core_global_regs->gotgctl);
+		otgctl.b.hnpreq = val;
+		DWC_WRITE_REG32(&core_if->core_global_regs->gotgctl, otgctl.d32);
+	} else {
+		core_if->otg_sts = val;
+	}
+}
+
+uint32_t dwc_otg_get_gsnpsid(dwc_otg_core_if_t * core_if)
+{
+	return core_if->snpsid;
+}
+
+uint32_t dwc_otg_get_mode(dwc_otg_core_if_t * core_if)
+{
+	gintsts_data_t gintsts;
+	gintsts.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintsts);
+	return gintsts.b.curmode;
+}
+
+uint32_t dwc_otg_get_hnpcapable(dwc_otg_core_if_t * core_if)
+{
+	gusbcfg_data_t usbcfg;
+	usbcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+	return usbcfg.b.hnpcap;
+}
+
+void dwc_otg_set_hnpcapable(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	gusbcfg_data_t usbcfg;
+	usbcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+	usbcfg.b.hnpcap = val;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg, usbcfg.d32);
+}
+
+uint32_t dwc_otg_get_srpcapable(dwc_otg_core_if_t * core_if)
+{
+	gusbcfg_data_t usbcfg;
+	usbcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+	return usbcfg.b.srpcap;
+}
+
+void dwc_otg_set_srpcapable(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	gusbcfg_data_t usbcfg;
+	usbcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+	usbcfg.b.srpcap = val;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg, usbcfg.d32);
+}
+
+uint32_t dwc_otg_get_devspeed(dwc_otg_core_if_t * core_if)
+{
+	dcfg_data_t dcfg;
+	dcfg.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dcfg);
+	return dcfg.b.devspd;
+}
+
+void dwc_otg_set_devspeed(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	dcfg_data_t dcfg;
+	dcfg.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dcfg);
+	dcfg.b.devspd = val;
+	DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dcfg, dcfg.d32);
+}
+
+uint32_t dwc_otg_get_busconnected(dwc_otg_core_if_t * core_if)
+{
+	hprt0_data_t hprt0;
+	hprt0.d32 = DWC_READ_REG32(core_if->host_if->hprt0);
+	return hprt0.b.prtconnsts;
+}
+
+uint32_t dwc_otg_get_enumspeed(dwc_otg_core_if_t * core_if)
+{
+	dsts_data_t dsts;
+	dsts.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dsts);
+	return dsts.b.enumspd;
+}
+
+uint32_t dwc_otg_get_prtpower(dwc_otg_core_if_t * core_if)
+{
+	hprt0_data_t hprt0;
+	hprt0.d32 = DWC_READ_REG32(core_if->host_if->hprt0);
+	return hprt0.b.prtpwr;
+
+}
+
+uint32_t dwc_otg_get_core_state(dwc_otg_core_if_t * core_if)
+{
+	return core_if->hibernation_suspend;
+}
+
+void dwc_otg_set_prtpower(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	hprt0_data_t hprt0;
+	hprt0.d32 = dwc_otg_read_hprt0(core_if);
+	hprt0.b.prtpwr = val;
+	DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+}
+
+uint32_t dwc_otg_get_prtsuspend(dwc_otg_core_if_t * core_if)
+{
+	hprt0_data_t hprt0;
+	hprt0.d32 = DWC_READ_REG32(core_if->host_if->hprt0);
+	return hprt0.b.prtsusp;
+
+}
+
+void dwc_otg_set_prtsuspend(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	hprt0_data_t hprt0;
+	hprt0.d32 = dwc_otg_read_hprt0(core_if);
+	hprt0.b.prtsusp = val;
+	DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+}
+
+uint32_t dwc_otg_get_fr_interval(dwc_otg_core_if_t * core_if)
+{
+	hfir_data_t hfir;
+	hfir.d32 = DWC_READ_REG32(&core_if->host_if->host_global_regs->hfir);
+	return hfir.b.frint;
+
+}
+
+void dwc_otg_set_fr_interval(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	hfir_data_t hfir;
+	uint32_t fram_int;
+	fram_int = calc_frame_interval(core_if);
+	hfir.d32 = DWC_READ_REG32(&core_if->host_if->host_global_regs->hfir);
+	if (!core_if->core_params->reload_ctl) {
+		DWC_WARN("\nCannot reload HFIR register.HFIR.HFIRRldCtrl bit is"
+			 "not set to 1.\nShould load driver with reload_ctl=1"
+			 " module parameter\n");
+		return;
+	}
+	switch (fram_int) {
+	case 3750:
+		if ((val < 3350) || (val > 4150)) {
+			DWC_WARN("HFIR interval for HS core and 30 MHz"
+				 "clock freq should be from 3350 to 4150\n");
+			return;
+		}
+		break;
+	case 30000:
+		if ((val < 26820) || (val > 33180)) {
+			DWC_WARN("HFIR interval for FS/LS core and 30 MHz"
+				 "clock freq should be from 26820 to 33180\n");
+			return;
+		}
+		break;
+	case 6000:
+		if ((val < 5360) || (val > 6640)) {
+			DWC_WARN("HFIR interval for HS core and 48 MHz"
+				 "clock freq should be from 5360 to 6640\n");
+			return;
+		}
+		break;
+	case 48000:
+		if ((val < 42912) || (val > 53088)) {
+			DWC_WARN("HFIR interval for FS/LS core and 48 MHz"
+				 "clock freq should be from 42912 to 53088\n");
+			return;
+		}
+		break;
+	case 7500:
+		if ((val < 6700) || (val > 8300)) {
+			DWC_WARN("HFIR interval for HS core and 60 MHz"
+				 "clock freq should be from 6700 to 8300\n");
+			return;
+		}
+		break;
+	case 60000:
+		if ((val < 53640) || (val > 65536)) {
+			DWC_WARN("HFIR interval for FS/LS core and 60 MHz"
+				 "clock freq should be from 53640 to 65536\n");
+			return;
+		}
+		break;
+	default:
+		DWC_WARN("Unknown frame interval\n");
+		return;
+		break;
+
+	}
+	hfir.b.frint = val;
+	DWC_WRITE_REG32(&core_if->host_if->host_global_regs->hfir, hfir.d32);
+}
+
+uint32_t dwc_otg_get_mode_ch_tim(dwc_otg_core_if_t * core_if)
+{
+	hcfg_data_t hcfg;
+	hcfg.d32 = DWC_READ_REG32(&core_if->host_if->host_global_regs->hcfg);
+	return hcfg.b.modechtimen;
+
+}
+
+void dwc_otg_set_mode_ch_tim(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	hcfg_data_t hcfg;
+	hcfg.d32 = DWC_READ_REG32(&core_if->host_if->host_global_regs->hcfg);
+	hcfg.b.modechtimen = val;
+	DWC_WRITE_REG32(&core_if->host_if->host_global_regs->hcfg, hcfg.d32);
+}
+
+void dwc_otg_set_prtresume(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	hprt0_data_t hprt0;
+	hprt0.d32 = dwc_otg_read_hprt0(core_if);
+	hprt0.b.prtres = val;
+	DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+}
+
+uint32_t dwc_otg_get_remotewakesig(dwc_otg_core_if_t * core_if)
+{
+	dctl_data_t dctl;
+	dctl.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dctl);
+	return dctl.b.rmtwkupsig;
+}
+
+uint32_t dwc_otg_get_beslreject(dwc_otg_core_if_t * core_if)
+{
+	dctl_data_t dctl;
+	dctl.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dctl);
+	return dctl.b.besl_reject;
+}
+
+void dwc_otg_set_beslreject(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+    dctl_data_t dctl;
+	dctl.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dctl);
+	dctl.b.besl_reject = val;
+	DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dctl, dctl.d32);
+}
+uint32_t dwc_otg_get_hirdthresh(dwc_otg_core_if_t * core_if)
+{
+	glpmcfg_data_t lpmcfg;
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+	return lpmcfg.b.hird_thres;
+}
+
+void dwc_otg_set_hirdthresh(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	glpmcfg_data_t lpmcfg;
+
+	if (DWC_OTG_PARAM_TEST(val, 0, 15)) {
+		DWC_WARN("Wrong valaue for hird_thres\n");
+		DWC_WARN("hird_thres must be 0-f\n");
+		return ;
+	}
+
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+	lpmcfg.b.hird_thres &= (1<<4);
+	lpmcfg.b.hird_thres |= val;
+	DWC_WRITE_REG32(&core_if->core_global_regs->glpmcfg, lpmcfg.d32);
+}
+
+uint32_t dwc_otg_get_lpm_portsleepstatus(dwc_otg_core_if_t * core_if)
+{
+	glpmcfg_data_t lpmcfg;
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+
+	DWC_ASSERT(!
+		   ((core_if->lx_state == DWC_OTG_L1) ^ lpmcfg.b.prt_sleep_sts),
+		   "lx_state = %d, lmpcfg.prt_sleep_sts = %d\n",
+		   core_if->lx_state, lpmcfg.b.prt_sleep_sts);
+
+	return lpmcfg.b.prt_sleep_sts;
+}
+
+uint32_t dwc_otg_get_lpm_remotewakeenabled(dwc_otg_core_if_t * core_if)
+{
+	glpmcfg_data_t lpmcfg;
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+	return lpmcfg.b.rem_wkup_en;
+}
+
+uint32_t dwc_otg_get_lpmresponse(dwc_otg_core_if_t * core_if)
+{
+	glpmcfg_data_t lpmcfg;
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+	return lpmcfg.b.appl_resp;
+}
+
+void dwc_otg_set_lpmresponse(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	glpmcfg_data_t lpmcfg;
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+	lpmcfg.b.appl_resp = val;
+	DWC_WRITE_REG32(&core_if->core_global_regs->glpmcfg, lpmcfg.d32);
+}
+
+uint32_t dwc_otg_get_hsic_connect(dwc_otg_core_if_t * core_if)
+{
+	glpmcfg_data_t lpmcfg;
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+	return lpmcfg.b.hsic_connect;
+}
+
+void dwc_otg_set_hsic_connect(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	glpmcfg_data_t lpmcfg;
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+	lpmcfg.b.hsic_connect = val;
+	DWC_WRITE_REG32(&core_if->core_global_regs->glpmcfg, lpmcfg.d32);
+}
+
+uint32_t dwc_otg_get_inv_sel_hsic(dwc_otg_core_if_t * core_if)
+{
+	glpmcfg_data_t lpmcfg;
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+	return lpmcfg.b.inv_sel_hsic;
+
+}
+
+void dwc_otg_set_inv_sel_hsic(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	glpmcfg_data_t lpmcfg;
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+	lpmcfg.b.inv_sel_hsic = val;
+	DWC_WRITE_REG32(&core_if->core_global_regs->glpmcfg, lpmcfg.d32);
+}
+
+uint32_t dwc_otg_get_gotgctl(dwc_otg_core_if_t * core_if)
+{
+	return DWC_READ_REG32(&core_if->core_global_regs->gotgctl);
+}
+
+void dwc_otg_set_gotgctl(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	DWC_WRITE_REG32(&core_if->core_global_regs->gotgctl, val);
+}
+
+uint32_t dwc_otg_get_gusbcfg(dwc_otg_core_if_t * core_if)
+{
+	return DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+}
+
+void dwc_otg_set_gusbcfg(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg, val);
+}
+
+uint32_t dwc_otg_get_grxfsiz(dwc_otg_core_if_t * core_if)
+{
+	return DWC_READ_REG32(&core_if->core_global_regs->grxfsiz);
+}
+
+void dwc_otg_set_grxfsiz(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	DWC_WRITE_REG32(&core_if->core_global_regs->grxfsiz, val);
+}
+
+uint32_t dwc_otg_get_gnptxfsiz(dwc_otg_core_if_t * core_if)
+{
+	return DWC_READ_REG32(&core_if->core_global_regs->gnptxfsiz);
+}
+
+void dwc_otg_set_gnptxfsiz(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	DWC_WRITE_REG32(&core_if->core_global_regs->gnptxfsiz, val);
+}
+
+uint32_t dwc_otg_get_gpvndctl(dwc_otg_core_if_t * core_if)
+{
+	return DWC_READ_REG32(&core_if->core_global_regs->gpvndctl);
+}
+
+void dwc_otg_set_gpvndctl(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	DWC_WRITE_REG32(&core_if->core_global_regs->gpvndctl, val);
+}
+
+uint32_t dwc_otg_get_ggpio(dwc_otg_core_if_t * core_if)
+{
+	return DWC_READ_REG32(&core_if->core_global_regs->ggpio);
+}
+
+void dwc_otg_set_ggpio(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	DWC_WRITE_REG32(&core_if->core_global_regs->ggpio, val);
+}
+
+uint32_t dwc_otg_get_hprt0(dwc_otg_core_if_t * core_if)
+{
+	return DWC_READ_REG32(core_if->host_if->hprt0);
+
+}
+
+void dwc_otg_set_hprt0(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	DWC_WRITE_REG32(core_if->host_if->hprt0, val);
+}
+
+uint32_t dwc_otg_get_guid(dwc_otg_core_if_t * core_if)
+{
+	return DWC_READ_REG32(&core_if->core_global_regs->guid);
+}
+
+void dwc_otg_set_guid(dwc_otg_core_if_t * core_if, uint32_t val)
+{
+	DWC_WRITE_REG32(&core_if->core_global_regs->guid, val);
+}
+
+uint32_t dwc_otg_get_hptxfsiz(dwc_otg_core_if_t * core_if)
+{
+	return DWC_READ_REG32(&core_if->core_global_regs->hptxfsiz);
+}
+
+uint16_t dwc_otg_get_otg_version(dwc_otg_core_if_t * core_if)
+{
+	return ((core_if->otg_ver == 1) ? (uint16_t)0x0200 : (uint16_t)0x0103);
+}
+
+/**
+ * Start the SRP timer to detect when the SRP does not complete within
+ * 6 seconds.
+ *
+ * @param core_if the pointer to core_if strucure.
+ */
+void dwc_otg_pcd_start_srp_timer(dwc_otg_core_if_t * core_if)
+{
+	core_if->srp_timer_started = 1;
+	DWC_TIMER_SCHEDULE(core_if->srp_timer, 6000 /* 6 secs */ );
+}
+
+void dwc_otg_initiate_srp(void * p)
+{
+	dwc_otg_core_if_t * core_if = p;
+	uint32_t *addr = (uint32_t *) & (core_if->core_global_regs->gotgctl);
+	gotgctl_data_t mem;
+	gotgctl_data_t val;
+
+	val.d32 = DWC_READ_REG32(addr);
+	if (val.b.sesreq) {
+		DWC_ERROR("Session Request Already active!\n");
+		return;
+	}
+
+	DWC_INFO("Session Request Initated\n");	//NOTICE
+	mem.d32 = DWC_READ_REG32(addr);
+	mem.b.sesreq = 1;
+	DWC_WRITE_REG32(addr, mem.d32);
+
+	/* Start the SRP timer */
+	dwc_otg_pcd_start_srp_timer(core_if);
+	return;
+}
+
+int dwc_otg_check_haps_status(dwc_otg_core_if_t * core_if)
+{
+   int retval = 0;
+
+   if(DWC_READ_REG32(&core_if->core_global_regs->gsnpsid) == 0xffffffff)
+   {
+		return -1;
+   } else {
+		return retval;
+   }
+
+}
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_cil.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_cil.h
new file mode 100644
index 0000000..b52a280
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_cil.h
@@ -0,0 +1,1498 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_cil.h $
+ * $Revision: #128 $
+ * $Date: 2013/05/16 $
+ * $Change: 2231774 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#if !defined(__DWC_CIL_H__)
+#define __DWC_CIL_H__
+
+#include "dwc_list.h"
+#include "dwc_otg_dbg.h"
+#include "dwc_otg_regs.h"
+
+#include "dwc_otg_core_if.h"
+#include "dwc_otg_adp.h"
+
+/**
+ * @file
+ * This file contains the interface to the Core Interface Layer.
+ */
+
+#ifdef DWC_UTE_CFI
+
+#define MAX_DMA_DESCS_PER_EP	256
+
+/**
+ * Enumeration for the data buffer mode
+ */
+typedef enum _data_buffer_mode {
+	BM_STANDARD = 0,	/* data buffer is in normal mode */
+	BM_SG = 1,		/* data buffer uses the scatter/gather mode */
+	BM_CONCAT = 2,		/* data buffer uses the concatenation mode */
+	BM_CIRCULAR = 3,	/* data buffer uses the circular DMA mode */
+	BM_ALIGN = 4		/* data buffer is in buffer alignment mode */
+} data_buffer_mode_e;
+#endif //DWC_UTE_CFI
+
+/** Macros defined for DWC OTG HW Release version */
+
+#define OTG_CORE_REV_2_60a	0x4F54260A
+#define OTG_CORE_REV_2_71a	0x4F54271A
+#define OTG_CORE_REV_2_72a	0x4F54272A
+#define OTG_CORE_REV_2_80a	0x4F54280A
+#define OTG_CORE_REV_2_81a	0x4F54281A
+#define OTG_CORE_REV_2_90a	0x4F54290A
+#define OTG_CORE_REV_2_91a	0x4F54291A
+#define OTG_CORE_REV_2_92a	0x4F54292A
+#define OTG_CORE_REV_2_93a	0x4F54293A
+#define OTG_CORE_REV_2_94a	0x4F54294A
+#define OTG_CORE_REV_3_00a	0x4F54300A
+#define OTG_CORE_REV_3_10a	0x4F54310A
+
+/**
+ * Information for each ISOC packet.
+ */
+typedef struct iso_pkt_info {
+	uint32_t offset;
+	uint32_t length;
+	int32_t status;
+} iso_pkt_info_t;
+
+/**
+ * The <code>dwc_ep</code> structure represents the state of a single
+ * endpoint when acting in device mode. It contains the data items
+ * needed for an endpoint to be activated and transfer packets.
+ */
+typedef struct dwc_ep {
+	/** EP number used for register address lookup */
+	uint8_t num;
+	/** EP direction 0 = OUT */
+	unsigned is_in:1;
+	/** EP active. */
+	unsigned active:1;
+
+	/**
+	 * Periodic Tx FIFO # for IN EPs For INTR EP set to 0 to use non-periodic
+	 * Tx FIFO. If dedicated Tx FIFOs are enabled Tx FIFO # FOR IN EPs*/
+	unsigned tx_fifo_num:4;
+	/** EP type: 0 - Control, 1 - ISOC,	 2 - BULK,	3 - INTR */
+	unsigned type:2;
+#define DWC_OTG_EP_TYPE_CONTROL	   0
+#define DWC_OTG_EP_TYPE_ISOC	   1
+#define DWC_OTG_EP_TYPE_BULK	   2
+#define DWC_OTG_EP_TYPE_INTR	   3
+
+	/** DATA start PID for INTR and BULK EP */
+	unsigned data_pid_start:1;
+	/** Frame (even/odd) for ISOC EP */
+	unsigned even_odd_frame:1;
+	/** Max Packet bytes */
+	unsigned maxpacket:11;
+
+	/** Max Transfer size */
+	uint32_t maxxfer;
+
+	/** @name Transfer state */
+	/** @{ */
+
+	/**
+	 * Pointer to the beginning of the transfer buffer -- do not modify
+	 * during transfer.
+	 */
+	dwc_dma_t dma_addr;
+
+	dwc_dma_t dma_desc_addr;
+	dwc_otg_dev_dma_desc_t *desc_addr;
+
+	/* Additional desc chain for ISO transfers */
+	dwc_dma_t dma_desc_addr1;
+	dwc_otg_dev_dma_desc_t *desc_addr1;
+	/* Flag indicating which one of two ISO desc chains currently is in use */
+	uint8_t use_add_buf;
+
+	uint8_t *start_xfer_buff;
+	/** pointer to the transfer buffer */
+	uint8_t *xfer_buff;
+	/** Number of bytes to transfer */
+	unsigned xfer_len:19;
+	/** Number of bytes transferred. */
+	unsigned xfer_count:19;
+	/** Sent ZLP */
+	unsigned sent_zlp:1;
+	/** Total len for control transfer */
+	unsigned total_len:19;
+
+	/** stall clear flag */
+	unsigned stall_clear_flag:1;
+
+	/** SETUP pkt cnt rollover flag for EP0 out*/
+	unsigned stp_rollover;
+
+#ifdef DWC_UTE_CFI
+	/* The buffer mode */
+	data_buffer_mode_e buff_mode;
+
+	/* The chain of DMA descriptors.
+	 * MAX_DMA_DESCS_PER_EP will be allocated for each active EP.
+	 */
+	dwc_otg_dma_desc_t *descs;
+
+	/* The DMA address of the descriptors chain start */
+	dma_addr_t descs_dma_addr;
+	/** This variable stores the length of the last enqueued request */
+	uint32_t cfi_req_len;
+#endif				//DWC_UTE_CFI
+
+/** Max DMA Descriptor count for any EP */
+#define MAX_DMA_DESC_CNT 256
+	/** Allocated DMA Desc count */
+	uint32_t desc_cnt;
+
+	/** First ISO Desc in use in the first chain*/
+	uint32_t iso_desc_first;
+	/** Last ISO Desc in use in the second chain */
+	uint32_t iso_desc_second;
+	/** Flag indicated that iso transfers were started */
+	uint8_t iso_transfer_started;
+
+	/** bInterval */
+	uint32_t bInterval;
+	/** Next frame num to setup next ISOC transfer */
+	uint32_t frame_num;
+	/** Indicates SOF number overrun in DSTS */
+	uint8_t frm_overrun;
+
+#ifdef DWC_UTE_PER_IO
+	/** Next frame num for which will be setup DMA Desc */
+	uint32_t xiso_frame_num;
+	/** bInterval */
+	uint32_t xiso_bInterval;
+	/** Count of currently active transfers - shall be either 0 or 1 */
+	int xiso_active_xfers;
+	int xiso_queued_xfers;
+#endif
+#ifdef DWC_EN_ISOC
+	/**
+	 * Variables specific for ISOC EPs
+	 *
+	 */
+	/** DMA addresses of ISOC buffers */
+	dwc_dma_t dma_addr0;
+	dwc_dma_t dma_addr1;
+
+	dwc_dma_t iso_dma_desc_addr;
+	dwc_otg_dev_dma_desc_t *iso_desc_addr;
+
+	/** pointer to the transfer buffers */
+	uint8_t *xfer_buff0;
+	uint8_t *xfer_buff1;
+
+	/** number of ISOC Buffer is processing */
+	uint32_t proc_buf_num;
+	/** Interval of ISOC Buffer processing */
+	uint32_t buf_proc_intrvl;
+	/** Data size for regular frame */
+	uint32_t data_per_frame;
+
+	/* todo - pattern data support is to be implemented in the future */
+	/** Data size for pattern frame */
+	uint32_t data_pattern_frame;
+	/** Frame number of pattern data */
+	uint32_t sync_frame;
+
+	/** bInterval */
+	uint32_t bInterval;
+	/** ISO Packet number per frame */
+	uint32_t pkt_per_frm;
+	/** Next frame num for which will be setup DMA Desc */
+	uint32_t next_frame;
+	/** Number of packets per buffer processing */
+	uint32_t pkt_cnt;
+	/** Info for all isoc packets */
+	iso_pkt_info_t *pkt_info;
+	/** current pkt number */
+	uint32_t cur_pkt;
+	/** current pkt number */
+	uint8_t *cur_pkt_addr;
+	/** current pkt number */
+	uint32_t cur_pkt_dma_addr;
+#endif				/* DWC_EN_ISOC */
+
+/** @} */
+} dwc_ep_t;
+
+/*
+ * Reasons for halting a host channel.
+ */
+typedef enum dwc_otg_halt_status {
+	DWC_OTG_HC_XFER_NO_HALT_STATUS,
+	DWC_OTG_HC_XFER_COMPLETE,
+	DWC_OTG_HC_XFER_URB_COMPLETE,
+	DWC_OTG_HC_XFER_ACK,
+	DWC_OTG_HC_XFER_NAK,
+	DWC_OTG_HC_XFER_NYET,
+	DWC_OTG_HC_XFER_STALL,
+	DWC_OTG_HC_XFER_XACT_ERR,
+	DWC_OTG_HC_XFER_FRAME_OVERRUN,
+	DWC_OTG_HC_XFER_BABBLE_ERR,
+	DWC_OTG_HC_XFER_DATA_TOGGLE_ERR,
+	DWC_OTG_HC_XFER_AHB_ERR,
+	DWC_OTG_HC_XFER_PERIODIC_INCOMPLETE,
+	DWC_OTG_HC_XFER_URB_DEQUEUE
+} dwc_otg_halt_status_e;
+
+/**
+ * Host channel descriptor. This structure represents the state of a single
+ * host channel when acting in host mode. It contains the data items needed to
+ * transfer packets to an endpoint via a host channel.
+ */
+typedef struct dwc_hc {
+	/** Host channel number used for register address lookup */
+	uint8_t hc_num;
+
+	/** Device to access */
+	unsigned dev_addr:7;
+
+	/** EP to access */
+	unsigned ep_num:4;
+
+	/** EP direction. 0: OUT, 1: IN */
+	unsigned ep_is_in:1;
+
+	/**
+	 * EP speed.
+	 * One of the following values:
+	 *	- DWC_OTG_EP_SPEED_LOW
+	 *	- DWC_OTG_EP_SPEED_FULL
+	 *	- DWC_OTG_EP_SPEED_HIGH
+	 */
+	unsigned speed:2;
+#define DWC_OTG_EP_SPEED_LOW	0
+#define DWC_OTG_EP_SPEED_FULL	1
+#define DWC_OTG_EP_SPEED_HIGH	2
+
+	/**
+	 * Endpoint type.
+	 * One of the following values:
+	 *	- DWC_OTG_EP_TYPE_CONTROL: 0
+	 *	- DWC_OTG_EP_TYPE_ISOC: 1
+	 *	- DWC_OTG_EP_TYPE_BULK: 2
+	 *	- DWC_OTG_EP_TYPE_INTR: 3
+	 */
+	unsigned ep_type:2;
+
+	/** Max packet size in bytes */
+	unsigned max_packet:11;
+
+	/**
+	 * PID for initial transaction.
+	 * 0: DATA0,<br>
+	 * 1: DATA2,<br>
+	 * 2: DATA1,<br>
+	 * 3: MDATA (non-Control EP),
+	 *	  SETUP (Control EP)
+	 */
+	unsigned data_pid_start:2;
+#define DWC_OTG_HC_PID_DATA0 0
+#define DWC_OTG_HC_PID_DATA2 1
+#define DWC_OTG_HC_PID_DATA1 2
+#define DWC_OTG_HC_PID_MDATA 3
+#define DWC_OTG_HC_PID_SETUP 3
+
+	/** Number of periodic transactions per (micro)frame */
+	unsigned multi_count:2;
+
+	/** @name Transfer State */
+	/** @{ */
+
+	/** Pointer to the current transfer buffer position. */
+	uint8_t *xfer_buff;
+	/**
+	 * In Buffer DMA mode this buffer will be used
+	 * if xfer_buff is not DWORD aligned.
+	 */
+	dwc_dma_t align_buff;
+	/** Total number of bytes to transfer. */
+	uint32_t xfer_len;
+	/** Number of bytes transferred so far. */
+	uint32_t xfer_count;
+	/** Packet count at start of transfer.*/
+	uint16_t start_pkt_count;
+
+	/**
+	 * Flag to indicate whether the transfer has been started. Set to 1 if
+	 * it has been started, 0 otherwise.
+	 */
+	uint8_t xfer_started;
+
+	/**
+	 * Set to 1 to indicate that a PING request should be issued on this
+	 * channel. If 0, process normally.
+	 */
+	uint8_t do_ping;
+
+	/**
+	 * Set to 1 to indicate that the error count for this transaction is
+	 * non-zero. Set to 0 if the error count is 0.
+	 */
+	uint8_t error_state;
+
+	/**
+	 * Set to 1 to indicate that this channel should be halted the next
+	 * time a request is queued for the channel. This is necessary in
+	 * slave mode if no request queue space is available when an attempt
+	 * is made to halt the channel.
+	 */
+	uint8_t halt_on_queue;
+
+	/**
+	 * Set to 1 if the host channel has been halted, but the core is not
+	 * finished flushing queued requests. Otherwise 0.
+	 */
+	uint8_t halt_pending;
+
+	/**
+	 * Reason for halting the host channel.
+	 */
+	dwc_otg_halt_status_e halt_status;
+
+	/*
+	 * Split settings for the host channel
+	 */
+	uint8_t do_split;		   /**< Enable split for the channel */
+	uint8_t complete_split;	   /**< Enable complete split */
+	uint8_t hub_addr;		   /**< Address of high speed hub */
+
+	uint8_t port_addr;		   /**< Port of the low/full speed device */
+	/** Split transaction position
+	 * One of the following values:
+	 *	  - DWC_HCSPLIT_XACTPOS_MID
+	 *	  - DWC_HCSPLIT_XACTPOS_BEGIN
+	 *	  - DWC_HCSPLIT_XACTPOS_END
+	 *	  - DWC_HCSPLIT_XACTPOS_ALL */
+	uint8_t xact_pos;
+
+	/** Set when the host channel does a short read. */
+	uint8_t short_read;
+
+	/**
+	 * Number of requests issued for this channel since it was assigned to
+	 * the current transfer (not counting PINGs).
+	 */
+	uint8_t requests;
+
+	/**
+	 * Queue Head for the transfer being processed by this channel.
+	 */
+	struct dwc_otg_qh *qh;
+
+	/** @} */
+
+	/** Entry in list of host channels. */
+	 DWC_CIRCLEQ_ENTRY(dwc_hc) hc_list_entry;
+
+	/** @name Descriptor DMA support */
+	/** @{ */
+
+	/** Number of Transfer Descriptors */
+	uint16_t ntd;
+
+	/** Descriptor List DMA address */
+	dwc_dma_t desc_list_addr;
+
+	/** Scheduling micro-frame bitmap. */
+	uint8_t schinfo;
+
+	/** @} */
+} dwc_hc_t;
+
+/**
+ * The following parameters may be specified when starting the module. These
+ * parameters define how the DWC_otg controller should be configured.
+ */
+typedef struct dwc_otg_core_params {
+	int32_t opt;
+
+	/**
+	 * Specifies the OTG capabilities. The driver will automatically
+	 * detect the value for this parameter if none is specified.
+	 * 0 - HNP and SRP capable (default)
+	 * 1 - SRP Only capable
+	 * 2 - No HNP/SRP capable
+	 */
+	int32_t otg_cap;
+
+	/**
+	 * Specifies whether to use slave or DMA mode for accessing the data
+	 * FIFOs. The driver will automatically detect the value for this
+	 * parameter if none is specified.
+	 * 0 - Slave
+	 * 1 - DMA (default, if available)
+	 */
+	int32_t dma_enable;
+
+	/**
+	 * When DMA mode is enabled specifies whether to use address DMA or DMA
+	 * Descriptor mode for accessing the data FIFOs in device mode. The driver
+	 * will automatically detect the value for this if none is specified.
+	 * 0 - address DMA
+	 * 1 - DMA Descriptor(default, if available)
+	 */
+	int32_t dma_desc_enable;
+	/** The DMA Burst size (applicable only for External DMA
+	 * Mode). 1, 4, 8 16, 32, 64, 128, 256 (default 32)
+	 */
+	int32_t dma_burst_size;	/* Translate this to GAHBCFG values */
+
+	/**
+	 * Specifies the maximum speed of operation in host and device mode.
+	 * The actual speed depends on the speed of the attached device and
+	 * the value of phy_type. The actual speed depends on the speed of the
+	 * attached device.
+	 * 0 - High Speed (default)
+	 * 1 - Full Speed
+	 */
+	int32_t speed;
+	/** Specifies whether low power mode is supported when attached
+	 *	to a Full Speed or Low Speed device in host mode.
+	 * 0 - Don't support low power mode (default)
+	 * 1 - Support low power mode
+	 */
+	int32_t host_support_fs_ls_low_power;
+
+	/** Specifies the PHY clock rate in low power mode when connected to a
+	 * Low Speed device in host mode. This parameter is applicable only if
+	 * HOST_SUPPORT_FS_LS_LOW_POWER is enabled. If PHY_TYPE is set to FS
+	 * then defaults to 6 MHZ otherwise 48 MHZ.
+	 *
+	 * 0 - 48 MHz
+	 * 1 - 6 MHz
+	 */
+	int32_t host_ls_low_power_phy_clk;
+
+	/**
+	 * 0 - Use cC FIFO size parameters
+	 * 1 - Allow dynamic FIFO sizing (default)
+	 */
+	int32_t enable_dynamic_fifo;
+
+	/** Total number of 4-byte words in the data FIFO memory. This
+	 * memory includes the Rx FIFO, non-periodic Tx FIFO, and periodic
+	 * Tx FIFOs.
+	 * 32 to 32768 (default 8192)
+	 * Note: The total FIFO memory depth in the FPGA configuration is 8192.
+	 */
+	int32_t data_fifo_size;
+
+	/** Number of 4-byte words in the Rx FIFO in device mode when dynamic
+	 * FIFO sizing is enabled.
+	 * 16 to 32768 (default 1064)
+	 */
+	int32_t dev_rx_fifo_size;
+
+	/** Number of 4-byte words in the non-periodic Tx FIFO in device mode
+	 * when dynamic FIFO sizing is enabled.
+	 * 16 to 32768 (default 1024)
+	 */
+	int32_t dev_nperio_tx_fifo_size;
+
+	/** Number of 4-byte words in each of the periodic Tx FIFOs in device
+	 * mode when dynamic FIFO sizing is enabled.
+	 * 4 to 768 (default 256)
+	 */
+	uint32_t dev_perio_tx_fifo_size[MAX_PERIO_FIFOS];
+
+	/** Number of 4-byte words in the Rx FIFO in host mode when dynamic
+	 * FIFO sizing is enabled.
+	 * 16 to 32768 (default 1024)
+	 */
+	int32_t host_rx_fifo_size;
+
+	/** Number of 4-byte words in the non-periodic Tx FIFO in host mode
+	 * when Dynamic FIFO sizing is enabled in the core.
+	 * 16 to 32768 (default 1024)
+	 */
+	int32_t host_nperio_tx_fifo_size;
+
+	/** Number of 4-byte words in the host periodic Tx FIFO when dynamic
+	 * FIFO sizing is enabled.
+	 * 16 to 32768 (default 1024)
+	 */
+	int32_t host_perio_tx_fifo_size;
+
+	/** The maximum transfer size supported in bytes.
+	 * 2047 to 65,535  (default 65,535)
+	 */
+	int32_t max_transfer_size;
+
+	/** The maximum number of packets in a transfer.
+	 * 15 to 511  (default 511)
+	 */
+	int32_t max_packet_count;
+
+	/** The number of host channel registers to use.
+	 * 1 to 16 (default 12)
+	 * Note: The FPGA configuration supports a maximum of 12 host channels.
+	 */
+	int32_t host_channels;
+
+	/** The number of endpoints in addition to EP0 available for device
+	 * mode operations.
+	 * 1 to 15 (default 6 IN and OUT)
+	 * Note: The FPGA configuration supports a maximum of 6 IN and OUT
+	 * endpoints in addition to EP0.
+	 */
+	int32_t dev_endpoints;
+
+		/**
+		 * Specifies the type of PHY interface to use. By default, the driver
+		 * will automatically detect the phy_type.
+		 *
+		 * 0 - Full Speed PHY
+		 * 1 - UTMI+ (default)
+		 * 2 - ULPI
+		 */
+	int32_t phy_type;
+
+	/**
+	 * Specifies the UTMI+ Data Width. This parameter is
+	 * applicable for a PHY_TYPE of UTMI+ or ULPI. (For a ULPI
+	 * PHY_TYPE, this parameter indicates the data width between
+	 * the MAC and the ULPI Wrapper.) Also, this parameter is
+	 * applicable only if the OTG_HSPHY_WIDTH cC parameter was set
+	 * to "8 and 16 bits", meaning that the core has been
+	 * configured to work at either data path width.
+	 *
+	 * 8 or 16 bits (default 16)
+	 */
+	int32_t phy_utmi_width;
+
+	/**
+	 * Specifies whether the ULPI operates at double or single
+	 * data rate. This parameter is only applicable if PHY_TYPE is
+	 * ULPI.
+	 *
+	 * 0 - single data rate ULPI interface with 8 bit wide data
+	 * bus (default)
+	 * 1 - double data rate ULPI interface with 4 bit wide data
+	 * bus
+	 */
+	int32_t phy_ulpi_ddr;
+
+	/**
+	 * Specifies whether to use the internal or external supply to
+	 * drive the vbus with a ULPI phy.
+	 */
+	int32_t phy_ulpi_ext_vbus;
+
+	/**
+	 * Specifies whether to use the I2Cinterface for full speed PHY. This
+	 * parameter is only applicable if PHY_TYPE is FS.
+	 * 0 - No (default)
+	 * 1 - Yes
+	 */
+	int32_t i2c_enable;
+
+	int32_t ulpi_fs_ls;
+
+	int32_t ts_dline;
+
+	/**
+	 * Specifies whether dedicated transmit FIFOs are
+	 * enabled for non periodic IN endpoints in device mode
+	 * 0 - No
+	 * 1 - Yes
+	 */
+	int32_t en_multiple_tx_fifo;
+
+	/** Number of 4-byte words in each of the Tx FIFOs in device
+	 * mode when dynamic FIFO sizing is enabled.
+	 * 4 to 768 (default 256)
+	 */
+	uint32_t dev_tx_fifo_size[MAX_TX_FIFOS];
+
+	/** Thresholding enable flag-
+	 * bit 0 - enable non-ISO Tx thresholding
+	 * bit 1 - enable ISO Tx thresholding
+	 * bit 2 - enable Rx thresholding
+	 */
+	uint32_t thr_ctl;
+
+	/** Thresholding length for Tx
+	 *	FIFOs in 32 bit DWORDs
+	 */
+	uint32_t tx_thr_length;
+
+	/** Thresholding length for Rx
+	 *	FIFOs in 32 bit DWORDs
+	 */
+	uint32_t rx_thr_length;
+
+	/**
+	 * Specifies whether LPM (Link Power Management) support is enabled
+	 */
+	int32_t lpm_enable;
+
+	/**
+	* Specifies whether LPM Errata (Link Power Management) support is enabled
+	*/
+	int32_t besl_enable;
+
+	/**
+	* Specifies the baseline besl value
+	*/
+	int32_t baseline_besl;
+
+	/**
+	* Specifies the deep besl value
+	*/
+	int32_t deep_besl;
+	/** Per Transfer Interrupt
+	 *	mode enable flag
+	 * 1 - Enabled
+	 * 0 - Disabled
+	 */
+	int32_t pti_enable;
+
+	/** Multi Processor Interrupt
+	 *	mode enable flag
+	 * 1 - Enabled
+	 * 0 - Disabled
+	 */
+	int32_t mpi_enable;
+
+	/** IS_USB Capability
+	 * 1 - Enabled
+	 * 0 - Disabled
+	 */
+	int32_t ic_usb_cap;
+
+	/** AHB Threshold Ratio
+	 * 2'b00 AHB Threshold =	MAC Threshold
+	 * 2'b01 AHB Threshold = 1/2	MAC Threshold
+	 * 2'b10 AHB Threshold = 1/4	MAC Threshold
+	 * 2'b11 AHB Threshold = 1/8	MAC Threshold
+	 */
+	int32_t ahb_thr_ratio;
+
+	/** ADP Support
+	 * 1 - Enabled
+	 * 0 - Disabled
+	 */
+	int32_t adp_supp_enable;
+
+	/** HFIR Reload Control
+	 * 0 - The HFIR cannot be reloaded dynamically.
+	 * 1 - Allow dynamic reloading of the HFIR register during runtime.
+	 */
+	int32_t reload_ctl;
+
+	/** DCFG: Enable device Out NAK
+	 * 0 - The core does not set NAK after Bulk Out transfer complete.
+	 * 1 - The core sets NAK after Bulk OUT transfer complete.
+	 */
+	int32_t dev_out_nak;
+
+	/** DCFG: Enable Continue on BNA
+	 * After receiving BNA interrupt the core disables the endpoint,when the
+	 * endpoint is re-enabled by the application the core starts processing
+	 * 0 - from the DOEPDMA descriptor
+	 * 1 - from the descriptor which received the BNA.
+	 */
+	int32_t cont_on_bna;
+
+	/** GAHBCFG: AHB Single Support
+	 * This bit when programmed supports SINGLE transfers for remainder
+	 * data in a transfer for DMA mode of operation.
+	 * 0 - in this case the remainder data will be sent using INCR burst size.
+	 * 1 - in this case the remainder data will be sent using SINGLE burst size.
+	 */
+	int32_t ahb_single;
+
+	/** Core Power down mode
+	 * 0 - No Power Down is enabled
+	 * 1 - Reserved
+	 * 2 - Complete Power Down (Hibernation)
+	 */
+	int32_t power_down;
+
+	/** OTG revision supported
+	 * 0 - OTG 1.3 revision
+	 * 1 - OTG 2.0 revision
+	 */
+	int32_t otg_ver;
+
+} dwc_otg_core_params_t;
+
+#ifdef DEBUG
+struct dwc_otg_core_if;
+typedef struct hc_xfer_info {
+	struct dwc_otg_core_if *core_if;
+	dwc_hc_t *hc;
+} hc_xfer_info_t;
+#endif
+
+typedef struct ep_xfer_info {
+	struct dwc_otg_core_if *core_if;
+	dwc_ep_t *ep;
+	uint8_t state;
+} ep_xfer_info_t;
+/*
+ * Device States
+ */
+typedef enum dwc_otg_lx_state {
+	/** On state */
+	DWC_OTG_L0,
+	/** LPM sleep state*/
+	DWC_OTG_L1,
+	/** USB suspend state*/
+	DWC_OTG_L2,
+	/** Off state*/
+	DWC_OTG_L3
+} dwc_otg_lx_state_e;
+
+struct dwc_otg_global_regs_backup {
+	uint32_t gotgctl_local;
+	uint32_t gintmsk_local;
+	uint32_t gahbcfg_local;
+	uint32_t gusbcfg_local;
+	uint32_t grxfsiz_local;
+	uint32_t gnptxfsiz_local;
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	uint32_t glpmcfg_local;
+#endif
+	uint32_t gi2cctl_local;
+	uint32_t hptxfsiz_local;
+	uint32_t pcgcctl_local;
+	uint32_t gdfifocfg_local;
+	uint32_t dtxfsiz_local[MAX_EPS_CHANNELS];
+	uint32_t gpwrdn_local;
+	uint32_t xhib_pcgcctl;
+	uint32_t xhib_gpwrdn;
+};
+
+struct dwc_otg_host_regs_backup {
+	uint32_t hcfg_local;
+	uint32_t haintmsk_local;
+	uint32_t hcintmsk_local[MAX_EPS_CHANNELS];
+	uint32_t hprt0_local;
+	uint32_t hfir_local;
+};
+
+struct dwc_otg_dev_regs_backup {
+	uint32_t dcfg;
+	uint32_t dctl;
+	uint32_t daintmsk;
+	uint32_t diepmsk;
+	uint32_t doepmsk;
+	uint32_t diepctl[MAX_EPS_CHANNELS];
+	uint32_t dieptsiz[MAX_EPS_CHANNELS];
+	uint32_t diepdma[MAX_EPS_CHANNELS];
+};
+/**
+ * The <code>dwc_otg_core_if</code> structure contains information needed to manage
+ * the DWC_otg controller acting in either host or device mode. It
+ * represents the programming view of the controller as a whole.
+ */
+struct dwc_otg_core_if {
+	/** Parameters that define how the core should be configured.*/
+	dwc_otg_core_params_t *core_params;
+
+	/** Core Global registers starting at offset 000h. */
+	dwc_otg_core_global_regs_t *core_global_regs;
+
+	/** Device-specific information */
+	dwc_otg_dev_if_t *dev_if;
+	/** Host-specific information */
+	dwc_otg_host_if_t *host_if;
+
+	/** Value from SNPSID register */
+	uint32_t snpsid;
+
+	/*
+	 * Set to 1 if the core PHY interface bits in USBCFG have been
+	 * initialized.
+	 */
+	uint8_t phy_init_done;
+
+	/*
+	 * SRP Success flag, set by srp success interrupt in FS I2C mode
+	 */
+	uint8_t srp_success;
+	uint8_t srp_timer_started;
+	/** Timer for SRP. If it expires before SRP is successful
+	 * clear the SRP. */
+	dwc_timer_t *srp_timer;
+
+#ifdef DWC_DEV_SRPCAP
+	/* This timer is needed to power on the hibernated host core if SRP is not
+	 * initiated on connected SRP capable device for limited period of time
+	 */
+	uint8_t pwron_timer_started;
+	dwc_timer_t *pwron_timer;
+#endif
+	/* Common configuration information */
+	/** Power and Clock Gating Control Register */
+	volatile uint32_t *pcgcctl;
+#define DWC_OTG_PCGCCTL_OFFSET 0xE00
+
+	/** Push/pop addresses for endpoints or host channels.*/
+	uint32_t *data_fifo[MAX_EPS_CHANNELS];
+#define DWC_OTG_DATA_FIFO_OFFSET 0x1000
+#define DWC_OTG_DATA_FIFO_SIZE 0x1000
+
+	/** Total RAM for FIFOs (Bytes) */
+	uint16_t total_fifo_size;
+	/** Size of Rx FIFO (Bytes) */
+	uint16_t rx_fifo_size;
+	/** Size of Non-periodic Tx FIFO (Bytes) */
+	uint16_t nperio_tx_fifo_size;
+
+	/** 1 if DMA is enabled, 0 otherwise. */
+	uint8_t dma_enable;
+
+	/** 1 if DMA descriptor is enabled, 0 otherwise. */
+	uint8_t dma_desc_enable;
+
+	/** 1 if PTI Enhancement mode is enabled, 0 otherwise. */
+	uint8_t pti_enh_enable;
+
+	/** 1 if MPI Enhancement mode is enabled, 0 otherwise. */
+	uint8_t multiproc_int_enable;
+
+	/** 1 if dedicated Tx FIFOs are enabled, 0 otherwise. */
+	uint8_t en_multiple_tx_fifo;
+
+	/** Set to 1 if multiple packets of a high-bandwidth transfer is in
+	 * process of being queued */
+	uint8_t queuing_high_bandwidth;
+
+	/** Hardware Configuration -- stored here for convenience.*/
+	hwcfg1_data_t hwcfg1;
+	hwcfg2_data_t hwcfg2;
+	hwcfg3_data_t hwcfg3;
+	hwcfg4_data_t hwcfg4;
+	fifosize_data_t hptxfsiz;
+
+	/** Host and Device Configuration -- stored here for convenience.*/
+	hcfg_data_t hcfg;
+	dcfg_data_t dcfg;
+
+	/** The operational State, during transations
+	 * (a_host>>a_peripherial and b_device=>b_host) this may not
+	 * match the core but allows the software to determine
+	 * transitions.
+	 */
+	uint8_t op_state;
+
+	/** Test mode for PET testing */
+	uint8_t test_mode;
+
+	/**
+	 * Set to 1 if the HCD needs to be restarted on a session request
+	 * interrupt. This is required if no connector ID status change has
+	 * occurred since the HCD was last disconnected.
+	 */
+	uint8_t restart_hcd_on_session_req;
+
+	/** HCD callbacks */
+	/** A-Device is a_host */
+#define A_HOST		(1)
+	/** A-Device is a_suspend */
+#define A_SUSPEND	(2)
+	/** A-Device is a_peripherial */
+#define A_PERIPHERAL	(3)
+	/** B-Device is operating as a Peripheral. */
+#define B_PERIPHERAL	(4)
+	/** B-Device is operating as a Host. */
+#define B_HOST		(5)
+
+	/** HCD callbacks */
+	struct dwc_otg_cil_callbacks *hcd_cb;
+	/** PCD callbacks */
+	struct dwc_otg_cil_callbacks *pcd_cb;
+
+	/** Device mode Periodic Tx FIFO Mask */
+	uint32_t p_tx_msk;
+	/** Device mode Periodic Tx FIFO Mask */
+	uint32_t tx_msk;
+
+	/** Workqueue object used for handling several interrupts */
+	dwc_workq_t *wq_otg;
+
+	/** Timer object used for handling "Wakeup Detected" Interrupt */
+	dwc_timer_t *wkp_timer;
+	/** This arrays used for debug purposes for DEV OUT NAK enhancement */
+	uint32_t start_doeptsiz_val[MAX_EPS_CHANNELS];
+	ep_xfer_info_t ep_xfer_info[MAX_EPS_CHANNELS];
+	dwc_timer_t *ep_xfer_timer[MAX_EPS_CHANNELS];
+#ifdef DEBUG
+	uint32_t start_hcchar_val[MAX_EPS_CHANNELS];
+
+	hc_xfer_info_t hc_xfer_info[MAX_EPS_CHANNELS];
+	dwc_timer_t *hc_xfer_timer[MAX_EPS_CHANNELS];
+
+	uint32_t hfnum_7_samples;
+	uint64_t hfnum_7_frrem_accum;
+	uint32_t hfnum_0_samples;
+	uint64_t hfnum_0_frrem_accum;
+	uint32_t hfnum_other_samples;
+	uint64_t hfnum_other_frrem_accum;
+#endif
+
+#ifdef DWC_UTE_CFI
+	uint16_t pwron_rxfsiz;
+	uint16_t pwron_gnptxfsiz;
+	uint16_t pwron_txfsiz[15];
+
+	uint16_t init_rxfsiz;
+	uint16_t init_gnptxfsiz;
+	uint16_t init_txfsiz[15];
+#endif
+
+	/** Lx state of device */
+	dwc_otg_lx_state_e lx_state;
+
+	/** Saved Core Global registers */
+	struct dwc_otg_global_regs_backup *gr_backup;
+	/** Saved Host registers */
+	struct dwc_otg_host_regs_backup *hr_backup;
+	/** Saved Device registers */
+	struct dwc_otg_dev_regs_backup *dr_backup;
+
+	/** Power Down Enable */
+	uint32_t power_down;
+
+	/** ADP support Enable */
+	uint32_t adp_enable;
+
+	/** ADP structure object */
+	dwc_otg_adp_t adp;
+
+	/** hibernation/suspend flag */
+	int hibernation_suspend;
+
+	/** Device mode extended hibernation flag */
+	int xhib;
+
+	/** OTG revision supported */
+	uint32_t otg_ver;
+
+	/** OTG status flag used for HNP polling */
+	uint8_t otg_sts;
+
+	/** Pointer to either hcd->lock or pcd->lock */
+	dwc_spinlock_t *lock;
+
+	/** Start predict NextEP based on Learning Queue if equal 1,
+	 * also used as counter of disabled NP IN EP's */
+	uint8_t start_predict;
+
+	/** NextEp sequence, including EP0: nextep_seq[] = EP if non-periodic and
+	 * active, 0xff otherwise */
+	uint8_t nextep_seq[MAX_EPS_CHANNELS];
+
+	/** Index of fisrt EP in nextep_seq array which should be re-enabled **/
+	uint8_t first_in_nextep_seq;
+
+	/** Frame number while entering to ISR - needed for ISOCs **/
+	uint32_t frame_num;
+
+	/** Flag to not perform ADP probing if IDSTS event happened */
+	uint8_t stop_adpprb;
+
+};
+
+#ifdef DEBUG
+/*
+ * This function is called when transfer is timed out.
+ */
+extern void hc_xfer_timeout(void *ptr);
+#endif
+
+/*
+ * This function is called when transfer is timed out on endpoint.
+ */
+extern void ep_xfer_timeout(void *ptr);
+
+/*
+ * The following functions are functions for works
+ * using during handling some interrupts
+ */
+extern void w_conn_id_status_change(void *p);
+
+extern void w_wakeup_detected(void *p);
+
+/** Saves global register values into system memory. */
+extern int dwc_otg_save_global_regs(dwc_otg_core_if_t * core_if);
+/** Saves device register values into system memory. */
+extern int dwc_otg_save_dev_regs(dwc_otg_core_if_t * core_if);
+/** Saves host register values into system memory. */
+extern int dwc_otg_save_host_regs(dwc_otg_core_if_t * core_if);
+/** Restore global register values. */
+extern int dwc_otg_restore_global_regs(dwc_otg_core_if_t * core_if);
+/** Restore host register values. */
+extern int dwc_otg_restore_host_regs(dwc_otg_core_if_t * core_if, int reset);
+/** Restore device register values. */
+extern int dwc_otg_restore_dev_regs(dwc_otg_core_if_t * core_if,
+				    int rem_wakeup);
+extern int restore_lpm_i2c_regs(dwc_otg_core_if_t * core_if);
+extern int restore_essential_regs(dwc_otg_core_if_t * core_if, int rmode,
+				  int is_host);
+
+extern int dwc_otg_host_hibernation_restore(dwc_otg_core_if_t * core_if,
+					    int restore_mode, int reset);
+extern int dwc_otg_device_hibernation_restore(dwc_otg_core_if_t * core_if,
+					      int rem_wakeup, int reset);
+
+/*
+ * The following functions support initialization of the CIL driver component
+ * and the DWC_otg controller.
+ */
+extern void dwc_otg_core_host_init(dwc_otg_core_if_t * _core_if);
+extern void dwc_otg_core_dev_init(dwc_otg_core_if_t * _core_if);
+
+/** @name Device CIL Functions
+ * The following functions support managing the DWC_otg controller in device
+ * mode.
+ */
+/**@{*/
+extern void dwc_otg_wakeup(dwc_otg_core_if_t * _core_if);
+extern void dwc_otg_read_setup_packet(dwc_otg_core_if_t * _core_if,
+				      uint32_t * _dest);
+extern uint32_t dwc_otg_get_frame_number(dwc_otg_core_if_t * _core_if);
+extern void dwc_otg_ep0_activate(dwc_otg_core_if_t * _core_if, dwc_ep_t * _ep);
+extern void dwc_otg_ep_activate(dwc_otg_core_if_t * _core_if, dwc_ep_t * _ep);
+extern void dwc_otg_ep_deactivate(dwc_otg_core_if_t * _core_if, dwc_ep_t * _ep);
+extern void dwc_otg_ep_start_transfer(dwc_otg_core_if_t * _core_if,
+				      dwc_ep_t * _ep);
+extern void dwc_otg_ep_start_zl_transfer(dwc_otg_core_if_t * _core_if,
+					 dwc_ep_t * _ep);
+extern void dwc_otg_ep0_start_transfer(dwc_otg_core_if_t * _core_if,
+				       dwc_ep_t * _ep);
+extern void dwc_otg_ep0_continue_transfer(dwc_otg_core_if_t * _core_if,
+					  dwc_ep_t * _ep);
+extern void dwc_otg_ep_write_packet(dwc_otg_core_if_t * _core_if,
+				    dwc_ep_t * _ep, int _dma);
+extern void dwc_otg_ep_set_stall(dwc_otg_core_if_t * _core_if, dwc_ep_t * _ep);
+extern void dwc_otg_ep_clear_stall(dwc_otg_core_if_t * _core_if,
+				   dwc_ep_t * _ep);
+extern void dwc_otg_enable_device_interrupts(dwc_otg_core_if_t * _core_if);
+
+#ifdef DWC_EN_ISOC
+extern void dwc_otg_iso_ep_start_frm_transfer(dwc_otg_core_if_t * core_if,
+					      dwc_ep_t * ep);
+extern void dwc_otg_iso_ep_start_buf_transfer(dwc_otg_core_if_t * core_if,
+					      dwc_ep_t * ep);
+#endif /* DWC_EN_ISOC */
+/**@}*/
+
+/** @name Host CIL Functions
+ * The following functions support managing the DWC_otg controller in host
+ * mode.
+ */
+/**@{*/
+extern void dwc_otg_hc_init(dwc_otg_core_if_t * _core_if, dwc_hc_t * _hc);
+extern void dwc_otg_hc_halt(dwc_otg_core_if_t * _core_if,
+			    dwc_hc_t * _hc, dwc_otg_halt_status_e _halt_status);
+extern void dwc_otg_hc_cleanup(dwc_otg_core_if_t * _core_if, dwc_hc_t * _hc);
+extern void dwc_otg_hc_start_transfer(dwc_otg_core_if_t * _core_if,
+				      dwc_hc_t * _hc);
+extern int dwc_otg_hc_continue_transfer(dwc_otg_core_if_t * _core_if,
+					dwc_hc_t * _hc);
+extern void dwc_otg_hc_do_ping(dwc_otg_core_if_t * _core_if, dwc_hc_t * _hc);
+extern void dwc_otg_hc_write_packet(dwc_otg_core_if_t * _core_if,
+				    dwc_hc_t * _hc);
+extern void dwc_otg_enable_host_interrupts(dwc_otg_core_if_t * _core_if);
+extern void dwc_otg_disable_host_interrupts(dwc_otg_core_if_t * _core_if);
+
+extern void dwc_otg_hc_start_transfer_ddma(dwc_otg_core_if_t * core_if,
+					   dwc_hc_t * hc);
+
+extern uint32_t calc_frame_interval(dwc_otg_core_if_t * core_if);
+extern int dwc_otg_check_haps_status(dwc_otg_core_if_t * core_if);
+
+/* Macro used to clear one channel interrupt */
+#define clear_hc_int(_hc_regs_, _intr_) \
+do { \
+	hcint_data_t hcint_clear = {.d32 = 0}; \
+	hcint_clear.b._intr_ = 1; \
+	DWC_WRITE_REG32(&(_hc_regs_)->hcint, hcint_clear.d32); \
+} while (0)
+
+/*
+ * Macro used to disable one channel interrupt. Channel interrupts are
+ * disabled when the channel is halted or released by the interrupt handler.
+ * There is no need to handle further interrupts of that type until the
+ * channel is re-assigned. In fact, subsequent handling may cause crashes
+ * because the channel structures are cleaned up when the channel is released.
+ */
+#define disable_hc_int(_hc_regs_, _intr_) \
+do { \
+	hcintmsk_data_t hcintmsk = {.d32 = 0}; \
+	hcintmsk.b._intr_ = 1; \
+	DWC_MODIFY_REG32(&(_hc_regs_)->hcintmsk, hcintmsk.d32, 0); \
+} while (0)
+
+/**
+ * This function Reads HPRT0 in preparation to modify. It keeps the
+ * WC bits 0 so that if they are read as 1, they won't clear when you
+ * write it back
+ */
+static inline uint32_t dwc_otg_read_hprt0(dwc_otg_core_if_t * _core_if)
+{
+	hprt0_data_t hprt0;
+	hprt0.d32 = DWC_READ_REG32(_core_if->host_if->hprt0);
+	hprt0.b.prtena = 0;
+	hprt0.b.prtconndet = 0;
+	hprt0.b.prtenchng = 0;
+	hprt0.b.prtovrcurrchng = 0;
+	return hprt0.d32;
+}
+
+/**@}*/
+
+/** @name Common CIL Functions
+ * The following functions support managing the DWC_otg controller in either
+ * device or host mode.
+ */
+/**@{*/
+
+extern void dwc_otg_read_packet(dwc_otg_core_if_t * core_if,
+				uint8_t * dest, uint16_t bytes);
+
+extern void dwc_otg_flush_tx_fifo(dwc_otg_core_if_t * _core_if, const int _num);
+extern void dwc_otg_flush_rx_fifo(dwc_otg_core_if_t * _core_if);
+extern void dwc_otg_core_reset(dwc_otg_core_if_t * _core_if);
+
+/**
+ * This function returns the Core Interrupt register.
+ */
+static inline uint32_t dwc_otg_read_core_intr(dwc_otg_core_if_t * core_if)
+{
+	return (DWC_READ_REG32(&core_if->core_global_regs->gintsts) &
+		DWC_READ_REG32(&core_if->core_global_regs->gintmsk));
+}
+
+/**
+ * This function returns the OTG Interrupt register.
+ */
+static inline uint32_t dwc_otg_read_otg_intr(dwc_otg_core_if_t * core_if)
+{
+	return (DWC_READ_REG32(&core_if->core_global_regs->gotgint));
+}
+
+/**
+ * This function reads the Device All Endpoints Interrupt register and
+ * returns the IN endpoint interrupt bits.
+ */
+static inline uint32_t dwc_otg_read_dev_all_in_ep_intr(dwc_otg_core_if_t *
+						       core_if)
+{
+
+	uint32_t v;
+
+	if (core_if->multiproc_int_enable) {
+		v = DWC_READ_REG32(&core_if->dev_if->
+				   dev_global_regs->deachint) &
+		    DWC_READ_REG32(&core_if->
+				   dev_if->dev_global_regs->deachintmsk);
+	} else {
+		v = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->daint) &
+		    DWC_READ_REG32(&core_if->dev_if->dev_global_regs->daintmsk);
+	}
+	return (v & 0xffff);
+}
+
+/**
+ * This function reads the Device All Endpoints Interrupt register and
+ * returns the OUT endpoint interrupt bits.
+ */
+static inline uint32_t dwc_otg_read_dev_all_out_ep_intr(dwc_otg_core_if_t *
+							core_if)
+{
+	uint32_t v;
+
+	if (core_if->multiproc_int_enable) {
+		v = DWC_READ_REG32(&core_if->dev_if->
+				   dev_global_regs->deachint) &
+		    DWC_READ_REG32(&core_if->
+				   dev_if->dev_global_regs->deachintmsk);
+	} else {
+		v = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->daint) &
+		    DWC_READ_REG32(&core_if->dev_if->dev_global_regs->daintmsk);
+	}
+
+	return ((v & 0xffff0000) >> 16);
+}
+
+/**
+ * This function returns the Device IN EP Interrupt register
+ */
+static inline uint32_t dwc_otg_read_dev_in_ep_intr(dwc_otg_core_if_t * core_if,
+						   dwc_ep_t * ep)
+{
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	uint32_t v, msk, emp;
+
+	if (core_if->multiproc_int_enable) {
+		msk =
+		    DWC_READ_REG32(&dev_if->
+				   dev_global_regs->diepeachintmsk[ep->num]);
+		emp =
+		    DWC_READ_REG32(&dev_if->
+				   dev_global_regs->dtknqr4_fifoemptymsk);
+		msk |= ((emp >> ep->num) & 0x1) << 7;
+		v = DWC_READ_REG32(&dev_if->in_ep_regs[ep->num]->diepint) & msk;
+	} else {
+		msk = DWC_READ_REG32(&dev_if->dev_global_regs->diepmsk);
+		emp =
+		    DWC_READ_REG32(&dev_if->
+				   dev_global_regs->dtknqr4_fifoemptymsk);
+		msk |= ((emp >> ep->num) & 0x1) << 7;
+		v = DWC_READ_REG32(&dev_if->in_ep_regs[ep->num]->diepint) & msk;
+	}
+
+	return v;
+}
+
+/**
+ * This function returns the Device OUT EP Interrupt register
+ */
+static inline uint32_t dwc_otg_read_dev_out_ep_intr(dwc_otg_core_if_t *
+						    _core_if, dwc_ep_t * _ep)
+{
+	dwc_otg_dev_if_t *dev_if = _core_if->dev_if;
+	uint32_t v;
+	doepmsk_data_t msk = {.d32 = 0 };
+
+	if (_core_if->multiproc_int_enable) {
+		msk.d32 =
+		    DWC_READ_REG32(&dev_if->
+				   dev_global_regs->doepeachintmsk[_ep->num]);
+		if (_core_if->pti_enh_enable) {
+			msk.b.pktdrpsts = 1;
+		}
+		v = DWC_READ_REG32(&dev_if->
+				   out_ep_regs[_ep->num]->doepint) & msk.d32;
+	} else {
+		msk.d32 = DWC_READ_REG32(&dev_if->dev_global_regs->doepmsk);
+		if (_core_if->pti_enh_enable) {
+			msk.b.pktdrpsts = 1;
+		}
+		v = DWC_READ_REG32(&dev_if->
+				   out_ep_regs[_ep->num]->doepint) & msk.d32;
+	}
+	return v;
+}
+
+/**
+ * This function returns the Host All Channel Interrupt register
+ */
+static inline uint32_t dwc_otg_read_host_all_channels_intr(dwc_otg_core_if_t *
+							   _core_if)
+{
+	return (DWC_READ_REG32(&_core_if->host_if->host_global_regs->haint));
+}
+
+static inline uint32_t dwc_otg_read_host_channel_intr(dwc_otg_core_if_t *
+						      _core_if, dwc_hc_t * _hc)
+{
+	return (DWC_READ_REG32
+		(&_core_if->host_if->hc_regs[_hc->hc_num]->hcint));
+}
+
+/**
+ * This function returns the mode of the operation, host or device.
+ *
+ * @return 0 - Device Mode, 1 - Host Mode
+ */
+static inline uint32_t dwc_otg_mode(dwc_otg_core_if_t * _core_if)
+{
+	return (DWC_READ_REG32(&_core_if->core_global_regs->gintsts) & 0x1);
+}
+
+/**@}*/
+
+/**
+ * DWC_otg CIL callback structure. This structure allows the HCD and
+ * PCD to register functions used for starting and stopping the PCD
+ * and HCD for role change on for a DRD.
+ */
+typedef struct dwc_otg_cil_callbacks {
+	/** Start function for role change */
+	int (*start) (void *_p);
+	/** Stop Function for role change */
+	int (*stop) (void *_p);
+	/** Disconnect Function for role change */
+	int (*disconnect) (void *_p);
+	/** Resume/Remote wakeup Function */
+	int (*resume_wakeup) (void *_p);
+	/** Suspend function */
+	int (*suspend) (void *_p);
+	/** Session Start (SRP) */
+	int (*session_start) (void *_p);
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	/** Sleep (switch to L0 state) */
+	int (*sleep) (void *_p);
+#endif
+	/** Pointer passed to start() and stop() */
+	void *p;
+} dwc_otg_cil_callbacks_t;
+
+extern void dwc_otg_cil_register_pcd_callbacks(dwc_otg_core_if_t * _core_if,
+					       dwc_otg_cil_callbacks_t * _cb,
+					       void *_p);
+extern void dwc_otg_cil_register_hcd_callbacks(dwc_otg_core_if_t * _core_if,
+					       dwc_otg_cil_callbacks_t * _cb,
+					       void *_p);
+
+void dwc_otg_initiate_srp(void * core_if);
+
+//////////////////////////////////////////////////////////////////////
+/** Start the HCD.  Helper function for using the HCD callbacks.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+static inline void cil_hcd_start(dwc_otg_core_if_t * core_if)
+{
+	if (core_if->hcd_cb && core_if->hcd_cb->start) {
+		core_if->hcd_cb->start(core_if->hcd_cb->p);
+	}
+}
+
+/** Stop the HCD.  Helper function for using the HCD callbacks.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+static inline void cil_hcd_stop(dwc_otg_core_if_t * core_if)
+{
+	if (core_if->hcd_cb && core_if->hcd_cb->stop) {
+		core_if->hcd_cb->stop(core_if->hcd_cb->p);
+	}
+}
+
+/** Disconnect the HCD.  Helper function for using the HCD callbacks.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+static inline void cil_hcd_disconnect(dwc_otg_core_if_t * core_if)
+{
+	if (core_if->hcd_cb && core_if->hcd_cb->disconnect) {
+		core_if->hcd_cb->disconnect(core_if->hcd_cb->p);
+	}
+}
+
+/** Inform the HCD the a New Session has begun.  Helper function for
+ * using the HCD callbacks.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+static inline void cil_hcd_session_start(dwc_otg_core_if_t * core_if)
+{
+	if (core_if->hcd_cb && core_if->hcd_cb->session_start) {
+		core_if->hcd_cb->session_start(core_if->hcd_cb->p);
+	}
+}
+
+#ifdef CONFIG_USB_DWC_OTG_LPM
+/**
+ * Inform the HCD about LPM sleep.
+ * Helper function for using the HCD callbacks.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+static inline void cil_hcd_sleep(dwc_otg_core_if_t * core_if)
+{
+	if (core_if->hcd_cb && core_if->hcd_cb->sleep) {
+		core_if->hcd_cb->sleep(core_if->hcd_cb->p);
+	}
+}
+#endif
+
+/** Resume the HCD.  Helper function for using the HCD callbacks.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+static inline void cil_hcd_resume(dwc_otg_core_if_t * core_if)
+{
+	if (core_if->hcd_cb && core_if->hcd_cb->resume_wakeup) {
+		core_if->hcd_cb->resume_wakeup(core_if->hcd_cb->p);
+	}
+}
+
+/** Start the PCD.  Helper function for using the PCD callbacks.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+static inline void cil_pcd_start(dwc_otg_core_if_t * core_if)
+{
+	if (core_if->pcd_cb && core_if->pcd_cb->start) {
+		core_if->pcd_cb->start(core_if->pcd_cb->p);
+	}
+}
+
+/** Stop the PCD.  Helper function for using the PCD callbacks.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+static inline void cil_pcd_stop(dwc_otg_core_if_t * core_if)
+{
+	if (core_if->pcd_cb && core_if->pcd_cb->stop) {
+		core_if->pcd_cb->stop(core_if->pcd_cb->p);
+	}
+}
+
+/** Suspend the PCD.  Helper function for using the PCD callbacks.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+static inline void cil_pcd_suspend(dwc_otg_core_if_t * core_if)
+{
+	if (core_if->pcd_cb && core_if->pcd_cb->suspend) {
+		core_if->pcd_cb->suspend(core_if->pcd_cb->p);
+	}
+}
+
+/** Resume the PCD.  Helper function for using the PCD callbacks.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+static inline void cil_pcd_resume(dwc_otg_core_if_t * core_if)
+{
+	if (core_if->pcd_cb && core_if->pcd_cb->resume_wakeup) {
+		core_if->pcd_cb->resume_wakeup(core_if->pcd_cb->p);
+	}
+}
+
+//////////////////////////////////////////////////////////////////////
+
+#endif
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_cil_intr.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_cil_intr.c
new file mode 100644
index 0000000..3f0d01f
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_cil_intr.c
@@ -0,0 +1,1731 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_cil_intr.c $
+ * $Revision: #37 $
+ * $Date: 2013/04/16 $
+ * $Change: 2207267 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+/** @file
+ *
+ * The Core Interface Layer provides basic services for accessing and
+ * managing the DWC_otg hardware. These services are used by both the
+ * Host Controller Driver and the Peripheral Controller Driver.
+ *
+ * This file contains the Common Interrupt handlers.
+ */
+#include "dwc_os.h"
+#include "dwc_otg_regs.h"
+#include "dwc_otg_cil.h"
+#include "dwc_otg_driver.h"
+#include "dwc_otg_pcd.h"
+#include "dwc_otg_hcd.h"
+
+#ifdef DEBUG
+inline const char *op_state_str(dwc_otg_core_if_t * core_if)
+{
+	return (core_if->op_state == A_HOST ? "a_host" :
+		(core_if->op_state == A_SUSPEND ? "a_suspend" :
+		 (core_if->op_state == A_PERIPHERAL ? "a_peripheral" :
+		  (core_if->op_state == B_PERIPHERAL ? "b_peripheral" :
+		   (core_if->op_state == B_HOST ? "b_host" : "unknown")))));
+}
+#endif
+
+/** This function will log a debug message
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+int32_t dwc_otg_handle_mode_mismatch_intr(dwc_otg_core_if_t * core_if)
+{
+	gintsts_data_t gintsts;
+	DWC_WARN("Mode Mismatch Interrupt: currently in %s mode\n",
+		 dwc_otg_mode(core_if) ? "Host" : "Device");
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.modemismatch = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+	return 1;
+}
+
+/**
+ * This function handles the OTG Interrupts. It reads the OTG
+ * Interrupt Register (GOTGINT) to determine what interrupt has
+ * occurred.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+int32_t dwc_otg_handle_otg_intr(dwc_otg_core_if_t * core_if)
+{
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	gotgint_data_t gotgint;
+	gotgctl_data_t gotgctl;
+	gintmsk_data_t gintmsk;
+	gpwrdn_data_t gpwrdn;
+
+	gotgint.d32 = DWC_READ_REG32(&global_regs->gotgint);
+	gotgctl.d32 = DWC_READ_REG32(&global_regs->gotgctl);
+	DWC_DEBUGPL(DBG_CIL, "++OTG Interrupt gotgint=%0x [%s]\n", gotgint.d32,
+		    op_state_str(core_if));
+
+	if (gotgint.b.sesenddet) {
+		DWC_DEBUGPL(DBG_ANY, " ++OTG Interrupt: "
+			    "Session End Detected++ (%s)\n",
+			    op_state_str(core_if));
+		gotgctl.d32 = DWC_READ_REG32(&global_regs->gotgctl);
+
+		if (core_if->op_state == B_HOST) {
+			if (core_if->adp_enable && DWC_WORKQ_PENDING(core_if->wq_otg)) {
+
+				/* During ST_B_ADP test after HNP HSOTG tries to go to B_HOST
+				 * mode but PET is not expecting fully functional host at that
+				 * point and switches off the VBUS expecting immediate ADP probe */
+				gpwrdn.b.pmuintsel = 1;
+				gpwrdn.b.pmuactv = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+				dwc_mdelay(20);
+				dwc_otg_adp_probe_start(core_if);
+				goto exit_interrupt;
+			}
+			cil_pcd_start(core_if);
+			core_if->op_state = B_PERIPHERAL;
+		} else {
+			/* If not B_HOST and Device HNP still set. HNP
+			 * Did not succeed!*/
+			if (gotgctl.b.devhnpen) {
+				DWC_DEBUGPL(DBG_ANY, "Session End Detected\n");
+				__DWC_ERROR("Device Not Connected/Responding!\n");
+			}
+
+			/* If Session End Detected the B-Cable has
+			 * been disconnected. */
+			/* Reset PCD and Gadget driver to a
+			 * clean state. */
+			core_if->lx_state = DWC_OTG_L0;
+			DWC_SPINUNLOCK(core_if->lock);
+			cil_pcd_stop(core_if);
+			DWC_SPINLOCK(core_if->lock);
+
+			if (core_if->otg_ver) {
+				/** PET testing*/
+				gotgctl.d32 = 0;
+				gotgctl.b.devhnpen = 1;
+				DWC_MODIFY_REG32(&global_regs->gotgctl, gotgctl.d32, 0);
+				if (core_if->test_mode == 6) {
+					DWC_WORKQ_SCHEDULE_DELAYED(core_if->wq_otg,	dwc_otg_initiate_srp,
+								core_if, 3000, "initate SRP"); //manukz: old value was 50
+					core_if->test_mode = 0;
+				} else	if (core_if->adp_enable) {
+					if (core_if->power_down == 2) {
+						gpwrdn.d32 = 0;
+						gpwrdn.b.pwrdnswtch = 1;
+						DWC_MODIFY_REG32(&core_if->
+								 core_global_regs->
+								 gpwrdn, gpwrdn.d32, 0);
+					}
+
+					gpwrdn.d32 = 0;
+					gpwrdn.b.pmuintsel = 1;
+					gpwrdn.b.pmuactv = 1;
+					DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+					dwc_otg_adp_sense_start(core_if);
+				}
+			}
+		}
+exit_interrupt:
+		if (core_if->otg_ver == 0) {
+			gotgctl.d32 = 0;
+			gotgctl.b.devhnpen = 1;
+			DWC_MODIFY_REG32(&global_regs->gotgctl, gotgctl.d32, 0);
+		}
+	}
+	if (gotgint.b.sesreqsucstschng) {
+		DWC_DEBUGPL(DBG_ANY, " ++OTG Interrupt: "
+			    "Session Reqeust Success Status Change++\n");
+		gotgctl.d32 = DWC_READ_REG32(&global_regs->gotgctl);
+		if (gotgctl.b.sesreqscs) {
+
+			if ((core_if->core_params->phy_type ==
+			     DWC_PHY_TYPE_PARAM_FS) && (core_if->core_params->i2c_enable)) {
+				core_if->srp_success = 1;
+			} else {
+				DWC_SPINUNLOCK(core_if->lock);
+				cil_pcd_resume(core_if);
+				DWC_SPINLOCK(core_if->lock);
+				/* Clear Session Request */
+				gotgctl.d32 = 0;
+				gotgctl.b.sesreq = 1;
+				DWC_MODIFY_REG32(&global_regs->gotgctl,
+						 gotgctl.d32, 0);
+			}
+		}
+	}
+	if (gotgint.b.hstnegsucstschng) {
+		/* Print statements during the HNP interrupt handling
+		 * can cause it to fail.*/
+		gotgctl.d32 = DWC_READ_REG32(&global_regs->gotgctl);
+		/* WA for 3.00a- HW is not setting cur_mode, even sometimes
+		 * this does not help*/
+		if (core_if->snpsid >= OTG_CORE_REV_3_00a)
+			dwc_udelay(100);
+		if (gotgctl.b.hstnegscs) {
+			if (dwc_otg_is_host_mode(core_if)) {
+				core_if->op_state = B_HOST;
+				/*
+				 * Need to disable SOF interrupt immediately.
+				 * When switching from device to host, the PCD
+				 * interrupt handler won't handle the
+				 * interrupt if host mode is already set. The
+				 * HCD interrupt handler won't get called if
+				 * the HCD state is HALT. This means that the
+				 * interrupt does not get handled and Linux
+				 * complains loudly.
+				 */
+				gintmsk.d32 = 0;
+				gintmsk.b.sofintr = 1;
+				/* To avoid multiple USB Suspend interrupts during
+				 * OTG 2.0 role change */
+				if (core_if->otg_ver)
+					gintmsk.b.usbsuspend = 1;
+				DWC_MODIFY_REG32(&global_regs->gintmsk,
+						 gintmsk.d32, 0);
+				/* Call callback function with spin lock released */
+				DWC_SPINUNLOCK(core_if->lock);
+				cil_pcd_stop(core_if);
+				/*
+				 * Initialize the Core for Host mode.
+				 */
+				if (core_if->otg_ver) {
+					dwc_mdelay(100);
+					cil_hcd_start(core_if);
+					cil_hcd_session_start(core_if);
+				} else {
+					cil_hcd_start(core_if);
+				}
+				DWC_SPINLOCK(core_if->lock);
+			}
+		} else {
+			gotgctl.d32 = 0;
+			gotgctl.b.hnpreq = 1;
+			gotgctl.b.devhnpen = 1;
+			DWC_MODIFY_REG32(&global_regs->gotgctl, gotgctl.d32, 0);
+			DWC_DEBUGPL(DBG_ANY, "HNP Failed\n");
+			__DWC_ERROR("Device Not Connected/Responding\n");
+		}
+	}
+	if (gotgint.b.hstnegdet) {
+		/* The disconnect interrupt is set at the same time as
+		 * Host Negotiation Detected.  During the mode
+		 * switch all interrupts are cleared so the disconnect
+		 * interrupt handler will not get executed.
+		 */
+		DWC_DEBUGPL(DBG_ANY, " ++OTG Interrupt: "
+			    "Host Negotiation Detected++ (%s)\n",
+			    (dwc_otg_is_host_mode(core_if) ? "Host" :
+			     "Device"));
+		if (dwc_otg_is_device_mode(core_if)) {
+			DWC_DEBUGPL(DBG_ANY, "a_suspend->a_peripheral (%d)\n",
+				    core_if->op_state);
+			DWC_SPINUNLOCK(core_if->lock);
+			cil_hcd_disconnect(core_if);
+			cil_pcd_start(core_if);
+			DWC_SPINLOCK(core_if->lock);
+			core_if->op_state = A_PERIPHERAL;
+		} else {
+			/*
+			 * Need to disable SOF interrupt immediately. When
+			 * switching from device to host, the PCD interrupt
+			 * handler won't handle the interrupt if host mode is
+			 * already set. The HCD interrupt handler won't get
+			 * called if the HCD state is HALT. This means that
+			 * the interrupt does not get handled and Linux
+			 * complains loudly.
+			 */
+			gintmsk.d32 = 0;
+			gintmsk.b.sofintr = 1;
+			DWC_MODIFY_REG32(&global_regs->gintmsk, gintmsk.d32, 0);
+			DWC_SPINUNLOCK(core_if->lock);
+			cil_pcd_stop(core_if);
+			cil_hcd_start(core_if);
+			DWC_SPINLOCK(core_if->lock);
+			core_if->op_state = A_HOST;
+		}
+	}
+	if (gotgint.b.adevtoutchng) {
+		DWC_DEBUGPL(DBG_ANY, " ++OTG Interrupt: "
+			    "A-Device Timeout Change++\n");
+	}
+	if (gotgint.b.debdone) {
+		DWC_DEBUGPL(DBG_ANY, " ++OTG Interrupt: " "Debounce Done++\n");
+		/* Need to power off VBUS after 10s if OTG2 non-hnp capable host*/
+		if (core_if->otg_ver && core_if->op_state == A_PERIPHERAL) {
+			DWC_DEBUGPL(DBG_ANY, "a_peripheral->a_host\n");
+			/* Clear the a_peripheral flag, back to a_host. */
+			DWC_SPINUNLOCK(core_if->lock);
+			cil_pcd_stop(core_if);
+			cil_hcd_start(core_if);
+			DWC_SPINLOCK(core_if->lock);
+			core_if->op_state = A_HOST;
+		}
+
+		if(core_if->otg_ver == 1)
+			cil_hcd_session_start(core_if);
+	}
+
+	/* Clear GOTGINT */
+	DWC_WRITE_REG32(&core_if->core_global_regs->gotgint, gotgint.d32);
+
+	return 1;
+}
+
+void w_conn_id_status_change(void *p)
+{
+	dwc_otg_core_if_t *core_if = p;
+	uint32_t count = 0;
+	gotgctl_data_t gotgctl = {.d32 = 0 };
+
+	gotgctl.d32 = DWC_READ_REG32(&core_if->core_global_regs->gotgctl);
+	DWC_DEBUGPL(DBG_CIL, "gotgctl=%0x\n", gotgctl.d32);
+	DWC_DEBUGPL(DBG_CIL, "gotgctl.b.conidsts=%d\n", gotgctl.b.conidsts);
+
+	/* B-Device connector (Device Mode) */
+	if (gotgctl.b.conidsts) {
+		gotgctl_data_t gotgctl_local;
+		/* Wait for switch to device mode. */
+		while (!dwc_otg_is_device_mode(core_if)) {
+			gotgctl_local.d32 = DWC_READ_REG32(&core_if->core_global_regs->gotgctl);
+			DWC_DEBUGPL(DBG_ANY, "Waiting for Peripheral Mode, Mode=%s count = %d gotgctl=%08x\n",
+				   (dwc_otg_is_host_mode(core_if) ? "Host" :
+				    "Peripheral"), count, gotgctl_local.d32);
+			dwc_mdelay(1); //vahrama previous value was 100
+			if(!gotgctl_local.b.conidsts)
+				goto host;
+			if (++count > 10000)
+				break;
+		}
+		DWC_ASSERT(++count < 10000,
+			   "Connection id status change timed out");
+		core_if->op_state = B_PERIPHERAL;
+		if(core_if->otg_ver == 0)
+			dwc_otg_core_init(core_if);
+		dwc_otg_enable_global_interrupts(core_if);
+		cil_pcd_start(core_if);
+	} else {
+host:
+		/* A-Device connector (Host Mode) */
+		while (!dwc_otg_is_host_mode(core_if)) {
+		DWC_DEBUGPL(DBG_ANY,"Waiting for Host Mode, Mode=%s\n",
+				   (dwc_otg_is_host_mode(core_if) ? "Host" :
+				    "Peripheral"));
+			dwc_mdelay(1);	//vahrama previously was 100
+			if (++count > 10000)
+				break;
+		}
+		DWC_ASSERT(++count < 10000,
+			   "Connection id status change timed out");
+		core_if->op_state = A_HOST;
+		/*
+		 * Initialize the Core for Host mode.
+		 */
+		if (core_if->otg_ver)
+			/* To power off the bus in 10s from the beginning
+			 * of test while denounce has not come yet */
+			cil_hcd_session_start(core_if);
+		else
+			dwc_otg_core_init(core_if);
+		dwc_otg_enable_global_interrupts(core_if);
+		cil_hcd_start(core_if);
+	}
+}
+
+/**
+ * This function handles the Connector ID Status Change Interrupt.  It
+ * reads the OTG Interrupt Register (GOTCTL) to determine whether this
+ * is a Device to Host Mode transition or a Host Mode to Device
+ * Transition.
+ *
+ * This only occurs when the cable is connected/removed from the PHY
+ * connector.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+int32_t dwc_otg_handle_conn_id_status_change_intr(dwc_otg_core_if_t * core_if)
+{
+
+	/*
+	 * Need to disable SOF interrupt immediately. If switching from device
+	 * to host, the PCD interrupt handler won't handle the interrupt if
+	 * host mode is already set. The HCD interrupt handler won't get
+	 * called if the HCD state is HALT. This means that the interrupt does
+	 * not get handled and Linux complains loudly.
+	 */
+	gintmsk_data_t gintmsk = {.d32 = 0 };
+	gintsts_data_t gintsts = {.d32 = 0 };
+
+	gintmsk.b.sofintr = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gintmsk, gintmsk.d32, 0);
+
+	DWC_DEBUGPL(DBG_CIL,
+		    " ++Connector ID Status Change Interrupt++  (%s)\n",
+		    (dwc_otg_is_host_mode(core_if) ? "Host" : "Device"));
+
+	DWC_SPINUNLOCK(core_if->lock);
+
+	/* Needed to avoit conn_id_status change duplication */
+	//if (core_if->otg_ver)
+		//dwc_mdelay(50);
+	/*
+	 * Need to schedule a work, as there are possible DELAY function calls
+	 * Release lock before scheduling workq as it holds spinlock during scheduling
+	 */
+
+	DWC_WORKQ_SCHEDULE(core_if->wq_otg, w_conn_id_status_change,
+			   core_if, "connection id status change");
+	DWC_SPINLOCK(core_if->lock);
+
+	/* Set flag and clear interrupt */
+	gintsts.b.conidstschng = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * This interrupt indicates that a device is initiating the Session
+ * Request Protocol to request the host to turn on bus power so a new
+ * session can begin. The handler responds by turning on bus power. If
+ * the DWC_otg controller is in low power mode, the handler brings the
+ * controller out of low power mode before turning on bus power.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+int32_t dwc_otg_handle_session_req_intr(dwc_otg_core_if_t * core_if)
+{
+	gintsts_data_t gintsts;
+
+#ifndef DWC_HOST_ONLY
+	DWC_DEBUGPL(DBG_ANY, "++Session Request Interrupt++\n");
+
+	if (dwc_otg_is_device_mode(core_if)) {
+		gotgctl_data_t gotgctl = {.d32 = 0 };
+		DWC_DEBUGPL(DBG_PCD, "SRP: Device mode\n");
+		gotgctl.d32 =
+			DWC_READ_REG32(&core_if->core_global_regs->gotgctl);
+		if (gotgctl.b.sesreqscs)
+			DWC_PRINTF("SRP Success\n");
+		else
+			DWC_PRINTF("SRP Fail\n");
+		if (core_if->otg_ver) {
+			gotgctl.d32 = 0 ;
+			gotgctl.b.devhnpen = 1;
+			DWC_MODIFY_REG32(&core_if->core_global_regs->gotgctl, gotgctl.d32, 0);
+		}
+	} else {
+		hprt0_data_t hprt0;
+		DWC_PRINTF("SRP: Host mode\n");
+
+		/* Turn on the port power bit. */
+		hprt0.d32 = dwc_otg_read_hprt0(core_if);
+		hprt0.b.prtpwr = 1;
+		DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+
+		/* Start the Connection timer. So a message can be displayed
+		 * if connect does not occur within 10 seconds. */
+		cil_hcd_session_start(core_if);
+	}
+#endif
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.sessreqintr = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+
+	return 1;
+}
+
+void w_wakeup_detected(void *p)
+{
+	dwc_otg_core_if_t *core_if = (dwc_otg_core_if_t *) p;
+	/*
+	 * Clear the Resume after 70ms. (Need 20 ms minimum. Use 70 ms
+	 * so that OPT tests pass with all PHYs).
+	 */
+	hprt0_data_t hprt0 = {.d32 = 0 };
+
+	hprt0.d32 = dwc_otg_read_hprt0(core_if);
+	DWC_DEBUGPL(DBG_ANY, "Resume: HPRT0=%0x\n", hprt0.d32);
+	hprt0.b.prtres = 0;	/* Resume */
+	DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+	DWC_DEBUGPL(DBG_ANY, "Clear Resume: HPRT0=%0x\n",
+		    DWC_READ_REG32(core_if->host_if->hprt0));
+
+	cil_hcd_resume(core_if);
+
+	/** Change to L0 state*/
+	core_if->lx_state = DWC_OTG_L0;
+}
+
+/**
+ * This interrupt indicates that the DWC_otg controller has detected a
+ * resume or remote wakeup sequence. If the DWC_otg controller is in
+ * low power mode, the handler must brings the controller out of low
+ * power mode. The controller automatically begins resume
+ * signaling. The handler schedules a time to stop resume signaling.
+ */
+int32_t dwc_otg_handle_wakeup_detected_intr(dwc_otg_core_if_t * core_if)
+{
+	gintsts_data_t gintsts;
+
+	DWC_DEBUGPL(DBG_ANY,
+		    "++Resume and Remote Wakeup Detected Interrupt++\n");
+
+	DWC_PRINTF("%s lxstate = %d\n", __func__, core_if->lx_state);
+
+	if (dwc_otg_is_device_mode(core_if)) {
+		dctl_data_t dctl = {.d32 = 0 };
+		DWC_DEBUGPL(DBG_PCD, "DSTS=0x%0x\n",
+			    DWC_READ_REG32(&core_if->dev_if->dev_global_regs->
+					   dsts));
+		if (core_if->lx_state == DWC_OTG_L2) {
+#ifdef PARTIAL_POWER_DOWN
+			if (core_if->hwcfg4.b.power_optimiz) {
+				pcgcctl_data_t power = {.d32 = 0 };
+
+				power.d32 = DWC_READ_REG32(core_if->pcgcctl);
+				DWC_DEBUGPL(DBG_CIL, "PCGCCTL=%0x\n",
+					    power.d32);
+
+				power.b.stoppclk = 0;
+				DWC_WRITE_REG32(core_if->pcgcctl, power.d32);
+
+				power.b.pwrclmp = 0;
+				DWC_WRITE_REG32(core_if->pcgcctl, power.d32);
+
+				power.b.rstpdwnmodule = 0;
+				DWC_WRITE_REG32(core_if->pcgcctl, power.d32);
+			}
+#endif
+			/* Clear the Remote Wakeup Signaling */
+			dctl.b.rmtwkupsig = 1;
+			DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->
+					 dctl, dctl.d32, 0);
+
+			DWC_SPINUNLOCK(core_if->lock);
+			if (core_if->pcd_cb && core_if->pcd_cb->resume_wakeup) {
+				core_if->pcd_cb->resume_wakeup(core_if->pcd_cb->p);
+			}
+			DWC_SPINLOCK(core_if->lock);
+		} else {
+			glpmcfg_data_t lpmcfg;
+			pcgcctl_data_t pcgcctl = {.d32 = 0 };
+
+			lpmcfg.d32 =
+			    DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+			lpmcfg.b.hird_thres &= (~(1 << 4));
+		lpmcfg.b.en_utmi_sleep = 0;
+
+			/* Clear Enbl_L1Gating bit. */
+			pcgcctl.b.enbl_sleep_gating = 1;
+			DWC_MODIFY_REG32(core_if->pcgcctl, pcgcctl.d32,0);
+
+			DWC_WRITE_REG32(&core_if->core_global_regs->glpmcfg,
+					lpmcfg.d32);
+		}
+		/** Change to L0 state*/
+		core_if->lx_state = DWC_OTG_L0;
+	} else {
+		if (core_if->lx_state != DWC_OTG_L1) {
+			pcgcctl_data_t pcgcctl = {.d32 = 0 };
+
+			/* Restart the Phy Clock */
+			pcgcctl.b.stoppclk = 1;
+			DWC_MODIFY_REG32(core_if->pcgcctl, pcgcctl.d32, 0);
+			DWC_TIMER_SCHEDULE(core_if->wkp_timer, 71);
+		} else {
+			/** Change to L0 state*/
+			core_if->lx_state = DWC_OTG_L0;
+		}
+	}
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.wkupintr = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * This interrupt indicates that the Wakeup Logic has detected a
+ * Device disconnect.
+ */
+static int32_t dwc_otg_handle_pwrdn_disconnect_intr(dwc_otg_core_if_t * core_if)
+{
+	gpwrdn_data_t gpwrdn = {.d32 = 0 };
+	gpwrdn_data_t gpwrdn_temp = {.d32 = 0 };
+	gpwrdn_temp.d32 = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+
+	DWC_PRINTF("%s called\n", __FUNCTION__);
+
+	if (!core_if->hibernation_suspend) {
+		DWC_PRINTF("Already exited from Hibernation\n");
+		return 1;
+	}
+
+	/* Switch on the voltage to the core */
+	gpwrdn.b.pwrdnswtch = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	/* Reset the core */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pwrdnrstn = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	/* Disable power clamps */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pwrdnclmp = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+	/* Remove reset the core signal */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pwrdnrstn = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+	dwc_udelay(10);
+
+	/* Disable PMU interrupt */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pmuintsel = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+	core_if->hibernation_suspend = 0;
+
+	/* Disable PMU */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pmuactv = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	if (gpwrdn_temp.b.idsts) {
+		core_if->op_state = B_PERIPHERAL;
+		dwc_otg_core_init(core_if);
+		dwc_otg_enable_global_interrupts(core_if);
+		cil_pcd_start(core_if);
+	} else {
+		core_if->op_state = A_HOST;
+		dwc_otg_core_init(core_if);
+		dwc_otg_enable_global_interrupts(core_if);
+		cil_hcd_start(core_if);
+	}
+
+	return 1;
+}
+
+/**
+ * This interrupt indicates that the Wakeup Logic has detected a
+ * remote wakeup sequence.
+ */
+static int32_t dwc_otg_handle_pwrdn_wakeup_detected_intr(dwc_otg_core_if_t * core_if)
+{
+	gpwrdn_data_t gpwrdn = {.d32 = 0 };
+	DWC_DEBUGPL(DBG_ANY,
+		    "++Powerdown Remote Wakeup Detected Interrupt++\n");
+
+	if (!core_if->hibernation_suspend) {
+		DWC_PRINTF("Already exited from Hibernation\n");
+		return 1;
+	}
+
+	gpwrdn.d32 = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+	if (gpwrdn.b.idsts) {	// Device Mode
+		if ((core_if->power_down == 2)
+		    && (core_if->hibernation_suspend == 1)) {
+			dwc_otg_device_hibernation_restore(core_if, 0, 0);
+		}
+	} else {
+		if ((core_if->power_down == 2)
+		    && (core_if->hibernation_suspend == 1)) {
+			dwc_otg_host_hibernation_restore(core_if, 1, 0);
+		}
+	}
+	return 1;
+}
+
+static int32_t dwc_otg_handle_pwrdn_idsts_change(dwc_otg_device_t * otg_dev)
+{
+	gpwrdn_data_t gpwrdn = {.d32 = 0 };
+	gpwrdn_data_t gpwrdn_temp = {.d32 = 0 };
+	dwc_otg_core_if_t *core_if = otg_dev->core_if;
+
+	DWC_DEBUGPL(DBG_ANY, "%s called\n", __FUNCTION__);
+	gpwrdn_temp.d32 = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+	if (core_if->power_down == 2) {
+		if (!core_if->hibernation_suspend) {
+			DWC_PRINTF("Already exited from Hibernation\n");
+			return 1;
+		}
+		DWC_DEBUGPL(DBG_ANY, "Exit from hibernation on ID sts change\n");
+		/* Switch on the voltage to the core */
+		gpwrdn.b.pwrdnswtch = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		dwc_udelay(10);
+
+		/* Reset the core */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pwrdnrstn = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		dwc_udelay(10);
+
+		/* Disable power clamps */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pwrdnclmp = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+		/* Remove reset the core signal */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pwrdnrstn = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+		dwc_udelay(10);
+
+		/* Disable PMU interrupt */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pmuintsel = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+		/*Indicates that we are exiting from hibernation */
+		core_if->hibernation_suspend = 0;
+
+		/* Disable PMU */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pmuactv = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		dwc_udelay(10);
+
+		gpwrdn.d32 = core_if->gr_backup->gpwrdn_local;
+		if (gpwrdn.b.dis_vbus == 1) {
+			gpwrdn.d32 = 0;
+			gpwrdn.b.dis_vbus = 1;
+			DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		}
+
+		if (gpwrdn_temp.b.idsts) {
+			core_if->op_state = B_PERIPHERAL;
+			dwc_otg_core_init(core_if);
+			dwc_otg_enable_global_interrupts(core_if);
+			cil_pcd_start(core_if);
+		} else {
+			core_if->op_state = A_HOST;
+			dwc_otg_core_init(core_if);
+			dwc_otg_enable_global_interrupts(core_if);
+			cil_hcd_start(core_if);
+		}
+	}
+
+	if (core_if->adp_enable) {
+		uint8_t is_host = 0;
+		DWC_SPINUNLOCK(core_if->lock);
+		/* Change the core_if's lock to hcd/pcd lock depend on mode? */
+#ifndef DWC_HOST_ONLY
+		if (gpwrdn_temp.b.idsts)
+			core_if->lock = otg_dev->pcd->lock;
+#endif
+#ifndef DWC_DEVICE_ONLY
+		if (!gpwrdn_temp.b.idsts) {
+			core_if->lock = otg_dev->hcd->lock;
+			is_host = 1;
+		}
+#endif
+		DWC_DEBUGPL(DBG_ANY, "RESTART ADP\n");
+		if (core_if->adp.probe_enabled)
+			dwc_otg_adp_probe_stop(core_if);
+		if (core_if->adp.sense_enabled)
+			dwc_otg_adp_sense_stop(core_if);
+		if (core_if->adp.sense_timer_started)
+			DWC_TIMER_CANCEL(core_if->adp.sense_timer);
+		if (core_if->adp.vbuson_timer_started)
+			DWC_TIMER_CANCEL(core_if->adp.vbuson_timer);
+		/* Do not need to reset ADP if we are coming back
+		 * to the device mode after HNP. This is needed
+		 * not to perform SRP after reverse, just do ADP
+		 * probe and compare the RTIM values with the one
+		 * before HNP */
+		if (core_if->op_state != B_HOST) {
+			core_if->adp.probe_timer_values[0] = -1;
+			core_if->adp.probe_timer_values[1] = -1;
+			core_if->adp.probe_counter = 0;
+			core_if->adp.gpwrdn = 0;
+		}
+		core_if->adp.sense_timer_started = 0;
+		core_if->adp.vbuson_timer_started = 0;
+
+		/* Disable PMU and restart ADP */
+		gpwrdn_temp.d32 = 0;
+		gpwrdn_temp.b.pmuactv = 1;
+		gpwrdn_temp.b.pmuintsel = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		dwc_mdelay(110);
+		dwc_otg_adp_start(core_if, is_host);
+		DWC_SPINLOCK(core_if->lock);
+	}
+
+	return 1;
+}
+
+static int32_t dwc_otg_handle_pwrdn_session_change(dwc_otg_core_if_t * core_if)
+{
+	gpwrdn_data_t gpwrdn = {.d32 = 0 };
+	int32_t otg_cap_param = core_if->core_params->otg_cap;
+	DWC_DEBUGPL(DBG_ANY, "%s called\n", __FUNCTION__);
+
+	gpwrdn.d32 = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+	if (core_if->power_down == 2) {
+		if (!core_if->hibernation_suspend) {
+			DWC_PRINTF("Already exited from Hibernation\n");
+			return 1;
+		}
+
+		if ((otg_cap_param != DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE ||
+		     otg_cap_param != DWC_OTG_CAP_PARAM_SRP_ONLY_CAPABLE) &&
+		    gpwrdn.b.bsessvld == 0) {
+			/* Save gpwrdn register for further usage if stschng interrupt */
+			core_if->gr_backup->gpwrdn_local =
+			    DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+			/*Exit from ISR and wait for stschng interrupt with bsessvld = 1 */
+			return 1;
+		}
+
+		/* Switch on the voltage to the core */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pwrdnswtch = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		dwc_udelay(10);
+
+		/* Reset the core */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pwrdnrstn = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		dwc_udelay(10);
+
+		/* Disable power clamps */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pwrdnclmp = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+		/* Remove reset the core signal */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pwrdnrstn = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+		dwc_udelay(10);
+
+		/* Disable PMU interrupt */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pmuintsel = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		dwc_udelay(10);
+
+		/*Indicates that we are exiting from hibernation */
+		core_if->hibernation_suspend = 0;
+
+		/* Disable PMU */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pmuactv = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		dwc_udelay(10);
+
+		core_if->op_state = B_PERIPHERAL;
+		dwc_otg_core_init(core_if);
+		dwc_otg_enable_global_interrupts(core_if);
+		cil_pcd_start(core_if);
+
+		if (otg_cap_param == DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE ||
+		    otg_cap_param == DWC_OTG_CAP_PARAM_SRP_ONLY_CAPABLE) {
+			/*
+			 * Initiate SRP after initial ADP probe.
+			 */
+			dwc_otg_initiate_srp(core_if);
+		}
+	} else if (core_if->adp_enable && core_if->op_state != A_HOST){
+		dwc_otg_adp_probe_stop(core_if);
+		if (DWC_WORKQ_PENDING(core_if->wq_otg))
+			core_if->stop_adpprb = 1;
+		/* Disable Power Down Logic */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pmuintsel = 1;
+		gpwrdn.b.pmuactv = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->
+				 gpwrdn, gpwrdn.d32, 0);
+
+		/*
+		 * Initialize the Core for Device mode.
+		 */
+		core_if->op_state = B_PERIPHERAL;
+		cil_pcd_start(core_if);
+		dwc_otg_enable_global_interrupts(core_if);
+	}
+
+	return 1;
+}
+
+/**
+ * This interrupt indicates that the Wakeup Logic has detected a
+ * status change either on IDDIG or BSessVld.
+ */
+static uint32_t dwc_otg_handle_pwrdn_stschng_intr(dwc_otg_device_t * otg_dev)
+{
+	int retval;
+	gpwrdn_data_t gpwrdn = {.d32 = 0 };
+	gpwrdn_data_t gpwrdn_temp = {.d32 = 0 };
+	dwc_otg_core_if_t *core_if = otg_dev->core_if;
+
+	DWC_DEBUGPL(DBG_CIL, "%s called\n", __FUNCTION__);
+
+	if (core_if->power_down == 2) {
+		if (core_if->hibernation_suspend <= 0) {
+			DWC_PRINTF("Already exited from Hibernation\n");
+			return 1;
+		} else
+			gpwrdn_temp.d32 = core_if->gr_backup->gpwrdn_local;
+
+	} else {
+		gpwrdn_temp.d32 = core_if->adp.gpwrdn;
+	}
+
+	gpwrdn.d32 = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+
+	if (gpwrdn.b.idsts ^ gpwrdn_temp.b.idsts) {
+		retval = dwc_otg_handle_pwrdn_idsts_change(otg_dev);
+	} else if (gpwrdn.b.bsessvld ^ gpwrdn_temp.b.bsessvld) {
+		retval = dwc_otg_handle_pwrdn_session_change(core_if);
+	}
+
+	return retval;
+}
+
+/**
+ * This interrupt indicates that the Wakeup Logic has detected a
+ * SRP.
+ */
+static int32_t dwc_otg_handle_pwrdn_srp_intr(dwc_otg_core_if_t * core_if)
+{
+	gpwrdn_data_t gpwrdn = {.d32 = 0 };
+
+	DWC_PRINTF("%s called\n", __FUNCTION__);
+
+	if (core_if->power_down == 2) {
+		if (!core_if->hibernation_suspend) {
+			DWC_PRINTF("Already exited from Hibernation\n");
+			return 1;
+		}
+#ifdef DWC_DEV_SRPCAP
+		if (core_if->pwron_timer_started) {
+			core_if->pwron_timer_started = 0;
+			DWC_TIMER_CANCEL(core_if->pwron_timer);
+		}
+#endif
+
+		/* Switch on the voltage to the core */
+		gpwrdn.b.pwrdnswtch = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		dwc_udelay(10);
+
+		/* Reset the core */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pwrdnrstn = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		dwc_udelay(10);
+
+		/* Disable power clamps */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pwrdnclmp = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+		/* Remove reset the core signal */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pwrdnrstn = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+		dwc_udelay(10);
+
+		/* Disable PMU interrupt */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pmuintsel = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+		/* Indicates that we are exiting from hibernation */
+		core_if->hibernation_suspend = 0;
+
+		/* Disable PMU */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pmuactv = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+		dwc_udelay(10);
+
+		/* Programm Disable VBUS to 0 */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.dis_vbus = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+		/*Initialize the core as Host */
+		core_if->op_state = A_HOST;
+		dwc_otg_core_init(core_if);
+		dwc_otg_enable_global_interrupts(core_if);
+		cil_hcd_start(core_if);
+	}
+	/* Do not need to du anything if this is "old" SRP and we are already
+	 * in the normal mode of operation */
+	if(core_if->adp_enable) {
+		gpwrdn.d32 =  DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+		if (!gpwrdn.b.pmuactv) {
+			return 1;
+		}
+
+		dwc_otg_adp_probe_stop(core_if);
+		/* Disable Interrupt from Power Down Logic */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.pmuintsel = 1;
+		gpwrdn.b.pmuactv = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->
+				 gpwrdn, gpwrdn.d32, 0);
+
+		/*
+		 * Initialize the Core for Host mode.
+		 */
+		core_if->op_state = A_HOST;
+		dwc_otg_core_init(core_if);
+		dwc_otg_enable_global_interrupts(core_if);
+		cil_hcd_start(core_if);
+		/* Start the Connection timer. So a message can be displayed
+		 * if connect does not occur within 10 seconds. */
+		cil_hcd_session_start(core_if);
+	}
+
+	return 1;
+}
+
+/** This interrupt indicates that restore command after Hibernation
+ * was completed by the core. */
+int32_t dwc_otg_handle_restore_done_intr(dwc_otg_core_if_t * core_if)
+{
+	pcgcctl_data_t pcgcctl;
+	DWC_DEBUGPL(DBG_ANY, "++Restore Done Interrupt++\n");
+
+	//TODO De-assert restore signal. 8.a
+	pcgcctl.d32 = DWC_READ_REG32(core_if->pcgcctl);
+	if (pcgcctl.b.restoremode == 1) {
+		gintmsk_data_t gintmsk = {.d32 = 0 };
+		/*
+		 * If restore mode is Remote Wakeup,
+		 * unmask Remote Wakeup interrupt.
+		 */
+		gintmsk.b.wkupintr = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gintmsk,
+				 0, gintmsk.d32);
+	}
+
+	return 1;
+}
+
+/**
+ * This interrupt indicates that a device has been disconnected from
+ * the root port.
+ */
+int32_t dwc_otg_handle_disconnect_intr(dwc_otg_core_if_t * core_if)
+{
+	gintsts_data_t gintsts;
+
+	DWC_DEBUGPL(DBG_ANY, "++Disconnect Detected Interrupt++ (%s) %s\n",
+		    (dwc_otg_is_host_mode(core_if) ? "Host" : "Device"),
+		    op_state_str(core_if));
+
+/** @todo Consolidate this if statement. */
+#ifndef DWC_HOST_ONLY
+	if (core_if->op_state == B_HOST) {
+		/* If in device mode Disconnect and stop the HCD, then
+		 * start the PCD. */
+		DWC_SPINUNLOCK(core_if->lock);
+		cil_hcd_disconnect(core_if);
+		cil_pcd_start(core_if);
+		DWC_SPINLOCK(core_if->lock);
+		core_if->op_state = B_PERIPHERAL;
+	} else if (dwc_otg_is_device_mode(core_if)) {
+		gotgctl_data_t gotgctl = {.d32 = 0 };
+		gotgctl.d32 =
+		    DWC_READ_REG32(&core_if->core_global_regs->gotgctl);
+		if (gotgctl.b.hstsethnpen == 1) {
+			/* Do nothing, if HNP in process the OTG
+			 * interrupt "Host Negotiation Detected"
+			 * interrupt will do the mode switch.
+			 */
+		} else if (gotgctl.b.devhnpen == 0) {
+			/* If in device mode Disconnect and stop the HCD, then
+			 * start the PCD. */
+			DWC_SPINUNLOCK(core_if->lock);
+			cil_hcd_disconnect(core_if);
+			cil_pcd_start(core_if);
+			DWC_SPINLOCK(core_if->lock);
+			core_if->op_state = B_PERIPHERAL;
+		} else {
+			DWC_DEBUGPL(DBG_ANY, "!a_peripheral && !devhnpen\n");
+		}
+	} else {
+		if (core_if->op_state == A_HOST) {
+			/* A-Cable still connected but device disconnected. */
+			cil_hcd_disconnect(core_if);
+			if (core_if->adp_enable) {
+				gpwrdn_data_t gpwrdn = {.d32 = 0 };
+				cil_hcd_stop(core_if);
+				/* Enable Power Down Logic */
+				gpwrdn.b.pmuintsel = 1;
+				gpwrdn.b.pmuactv = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+				dwc_otg_adp_probe_start(core_if);
+
+				/* Power off the core */
+				if (core_if->power_down == 2) {
+					gpwrdn.d32 = 0;
+					gpwrdn.b.pwrdnswtch = 1;
+					DWC_MODIFY_REG32
+					    (&core_if->core_global_regs->gpwrdn,
+					     gpwrdn.d32, 0);
+				}
+			}
+		}
+	}
+#endif
+	/* Change to L3(OFF) state */
+	core_if->lx_state = DWC_OTG_L3;
+
+	gintsts.d32 = 0;
+	gintsts.b.disconnect = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+	return 1;
+}
+
+/**
+ * This interrupt indicates that SUSPEND state has been detected on
+ * the USB.
+ *
+ * For HNP the USB Suspend interrupt signals the change from
+ * "a_peripheral" to "a_host".
+ *
+ * When power management is enabled the core will be put in low power
+ * mode.
+ */
+int32_t dwc_otg_handle_usb_suspend_intr(dwc_otg_core_if_t * core_if)
+{
+	dsts_data_t dsts;
+	gintsts_data_t gintsts;
+	dcfg_data_t dcfg;
+
+	DWC_DEBUGPL(DBG_ANY, "USB SUSPEND\n");
+
+	if ((core_if->otg_ver == 1) && (core_if->op_state == A_PERIPHERAL)) {
+		core_if->lx_state = DWC_OTG_L2;
+
+		/* Clear interrupt */
+		gintsts.d32 = 0;
+		gintsts.b.usbsuspend = 1;
+		DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+
+		return 1;
+	}
+
+	if (dwc_otg_is_device_mode(core_if)) {
+		/* Check the Device status register to determine if the Suspend
+		 * state is active. */
+		dsts.d32 =
+		    DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dsts);
+		DWC_DEBUGPL(DBG_PCD, "DSTS=0x%0x\n", dsts.d32);
+		DWC_DEBUGPL(DBG_PCD, "DSTS.Suspend Status=%d "
+			    "HWCFG4.power Optimize=%d\n",
+			    dsts.b.suspsts, core_if->hwcfg4.b.power_optimiz);
+
+#ifdef PARTIAL_POWER_DOWN
+/** @todo Add a module parameter for power management. */
+
+		if (dsts.b.suspsts && core_if->hwcfg4.b.power_optimiz) {
+			pcgcctl_data_t power = {.d32 = 0 };
+			DWC_DEBUGPL(DBG_CIL, "suspend\n");
+
+			power.b.pwrclmp = 1;
+			DWC_WRITE_REG32(core_if->pcgcctl, power.d32);
+
+			power.b.rstpdwnmodule = 1;
+			DWC_MODIFY_REG32(core_if->pcgcctl, 0, power.d32);
+
+			power.b.stoppclk = 1;
+			DWC_MODIFY_REG32(core_if->pcgcctl, 0, power.d32);
+
+		} else {
+			DWC_DEBUGPL(DBG_ANY, "disconnect?\n");
+		}
+#endif
+		/* PCD callback for suspend. Release the lock inside of callback function */
+		cil_pcd_suspend(core_if);
+		if (core_if->power_down == 2) {
+			dcfg.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dcfg);
+			DWC_DEBUGPL(DBG_ANY,"lx_state = %08x\n",core_if->lx_state);
+			DWC_DEBUGPL(DBG_ANY," device address = %08d\n",dcfg.b.devaddr);
+
+			if (core_if->lx_state != DWC_OTG_L3 && dcfg.b.devaddr) {
+				pcgcctl_data_t pcgcctl = {.d32 = 0 };
+				gpwrdn_data_t gpwrdn = {.d32 = 0 };
+				gusbcfg_data_t gusbcfg = {.d32 = 0 };
+
+				/* Change to L2(suspend) state */
+				core_if->lx_state = DWC_OTG_L2;
+
+				/* Clear interrupt in gintsts */
+				gintsts.d32 = 0;
+				gintsts.b.usbsuspend = 1;
+				DWC_WRITE_REG32(&core_if->core_global_regs->
+						gintsts, gintsts.d32);
+				DWC_PRINTF("Start of hibernation completed\n");
+				dwc_otg_save_global_regs(core_if);
+				dwc_otg_save_dev_regs(core_if);
+
+				gusbcfg.d32 =
+				    DWC_READ_REG32(&core_if->core_global_regs->
+						   gusbcfg);
+				if (gusbcfg.b.ulpi_utmi_sel == 1) {
+					/* ULPI interface */
+					/* Suspend the Phy Clock */
+					pcgcctl.d32 = 0;
+					pcgcctl.b.stoppclk = 1;
+					DWC_MODIFY_REG32(core_if->pcgcctl, 0,
+							 pcgcctl.d32);
+					dwc_udelay(10);
+					gpwrdn.b.pmuactv = 1;
+					DWC_MODIFY_REG32(&core_if->
+							 core_global_regs->
+							 gpwrdn, 0, gpwrdn.d32);
+				} else {
+					/* UTMI+ Interface */
+					gpwrdn.b.pmuactv = 1;
+					DWC_MODIFY_REG32(&core_if->
+							 core_global_regs->
+							 gpwrdn, 0, gpwrdn.d32);
+					dwc_udelay(10);
+					pcgcctl.b.stoppclk = 1;
+					DWC_MODIFY_REG32(core_if->pcgcctl, 0,
+							 pcgcctl.d32);
+					dwc_udelay(10);
+				}
+
+				/* Set flag to indicate that we are in hibernation */
+				core_if->hibernation_suspend = 1;
+				/* Enable interrupts from wake up logic */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.pmuintsel = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+				dwc_udelay(10);
+
+				/* Unmask device mode interrupts in GPWRDN */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.rst_det_msk = 1;
+				gpwrdn.b.lnstchng_msk = 1;
+				gpwrdn.b.sts_chngint_msk = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+				dwc_udelay(10);
+
+				/* Enable Power Down Clamp */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.pwrdnclmp = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+				dwc_udelay(10);
+
+				/* Switch off VDD */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.pwrdnswtch = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+
+				/* Save gpwrdn register for further usage if stschng interrupt */
+				core_if->gr_backup->gpwrdn_local =
+							DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+				DWC_PRINTF("Hibernation completed\n");
+
+				return 1;
+			}
+		} else if (core_if->power_down == 3) {
+			pcgcctl_data_t pcgcctl = {.d32 = 0 };
+			dcfg.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dcfg);
+			DWC_DEBUGPL(DBG_ANY, "lx_state = %08x\n",core_if->lx_state);
+			DWC_DEBUGPL(DBG_ANY, " device address = %08d\n",dcfg.b.devaddr);
+
+			if (core_if->lx_state != DWC_OTG_L3 && dcfg.b.devaddr) {
+				DWC_DEBUGPL(DBG_ANY, "Start entering to extended hibernation\n");
+				core_if->xhib = 1;
+
+				/* Clear interrupt in gintsts */
+				gintsts.d32 = 0;
+				gintsts.b.usbsuspend = 1;
+				DWC_WRITE_REG32(&core_if->core_global_regs->
+					gintsts, gintsts.d32);
+
+				dwc_otg_save_global_regs(core_if);
+				dwc_otg_save_dev_regs(core_if);
+
+				/* Wait for 10 PHY clocks */
+				dwc_udelay(10);
+
+				/* Program GPIO register while entering to xHib */
+				DWC_WRITE_REG32(&core_if->core_global_regs->ggpio, 0x1);
+
+				pcgcctl.b.enbl_extnd_hiber = 1;
+				DWC_MODIFY_REG32(core_if->pcgcctl, 0, pcgcctl.d32);
+				DWC_MODIFY_REG32(core_if->pcgcctl, 0, pcgcctl.d32);
+
+				pcgcctl.d32 = 0;
+				pcgcctl.b.extnd_hiber_pwrclmp = 1;
+				DWC_MODIFY_REG32(core_if->pcgcctl, 0, pcgcctl.d32);
+
+				pcgcctl.d32 = 0;
+				pcgcctl.b.extnd_hiber_switch = 1;
+				core_if->gr_backup->xhib_gpwrdn = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+				core_if->gr_backup->xhib_pcgcctl = DWC_READ_REG32(core_if->pcgcctl) | pcgcctl.d32;
+				DWC_MODIFY_REG32(core_if->pcgcctl, 0, pcgcctl.d32);
+
+				DWC_DEBUGPL(DBG_ANY, "Finished entering to extended hibernation\n");
+
+				return 1;
+			}
+		}
+		if ((core_if->otg_ver == 1) && (core_if->core_params->otg_cap == DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE)) {
+			gotgctl_data_t gotgctl = {.d32 = 0 };
+			gotgctl.d32 = DWC_READ_REG32(&core_if->core_global_regs->gotgctl);
+			if (gotgctl.b.devhnpen && core_if->otg_ver == 1){
+				gotgctl_data_t gotgctl = {.d32 = 0 };
+				dwc_mdelay(5);
+				/**@todo Is the gotgctl.devhnpen cleared
+				 * by a USB Reset? */
+				gotgctl.b.devhnpen = 1;
+				gotgctl.b.hnpreq = 1;
+				DWC_WRITE_REG32(&core_if->core_global_regs->gotgctl,
+						gotgctl.d32);
+			}
+		}
+	} else {
+		if (core_if->op_state == A_PERIPHERAL) {
+			DWC_DEBUGPL(DBG_ANY, "a_peripheral->a_host\n");
+			/* Clear the a_peripheral flag, back to a_host. */
+			DWC_SPINUNLOCK(core_if->lock);
+			cil_pcd_stop(core_if);
+			cil_hcd_start(core_if);
+			DWC_SPINLOCK(core_if->lock);
+			core_if->op_state = A_HOST;
+		}
+	}
+
+	/* Change to L2(suspend) state */
+	core_if->lx_state = DWC_OTG_L2;
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.usbsuspend = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+
+	return 1;
+}
+
+static int32_t dwc_otg_handle_xhib_exit_intr(dwc_otg_core_if_t * core_if)
+{
+	gpwrdn_data_t gpwrdn = {.d32 = 0 };
+	pcgcctl_data_t pcgcctl = {.d32 = 0 };
+	gahbcfg_data_t gahbcfg = {.d32 = 0 };
+
+	dwc_udelay(10);
+
+	/* Program GPIO register while entering to xHib */
+	DWC_WRITE_REG32(&core_if->core_global_regs->ggpio, 0x0);
+
+	pcgcctl.d32 = core_if->gr_backup->xhib_pcgcctl;
+	pcgcctl.b.extnd_hiber_pwrclmp = 0;
+	DWC_WRITE_REG32(core_if->pcgcctl, pcgcctl.d32);
+	dwc_udelay(10);
+
+	gpwrdn.d32 = core_if->gr_backup->xhib_gpwrdn;
+	gpwrdn.b.restore = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32);
+	dwc_udelay(10);
+
+	restore_lpm_i2c_regs(core_if);
+
+	pcgcctl.d32 = core_if->gr_backup->pcgcctl_local & (0x3FFFF << 14);
+	pcgcctl.b.max_xcvrselect = 1;
+	pcgcctl.b.ess_reg_restored = 0;
+	pcgcctl.b.extnd_hiber_switch = 0;
+	pcgcctl.b.extnd_hiber_pwrclmp = 0;
+	pcgcctl.b.enbl_extnd_hiber = 1;
+	DWC_WRITE_REG32(core_if->pcgcctl, pcgcctl.d32);
+
+	gahbcfg.d32 = core_if->gr_backup->gahbcfg_local;
+	gahbcfg.b.glblintrmsk = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gahbcfg, gahbcfg.d32);
+
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, 0xFFFFFFFF);
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintmsk, 0x1 << 16);
+
+	DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg,
+			core_if->gr_backup->gusbcfg_local);
+	DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dcfg,
+			core_if->dr_backup->dcfg);
+
+	pcgcctl.d32 = 0;
+	pcgcctl.d32 = core_if->gr_backup->pcgcctl_local & (0x3FFFF << 14);
+	pcgcctl.b.max_xcvrselect = 1;
+	pcgcctl.d32 |= 0x608;
+	DWC_WRITE_REG32(core_if->pcgcctl, pcgcctl.d32);
+	dwc_udelay(10);
+
+	pcgcctl.d32 = 0;
+	pcgcctl.d32 = core_if->gr_backup->pcgcctl_local & (0x3FFFF << 14);
+	pcgcctl.b.max_xcvrselect = 1;
+	pcgcctl.b.ess_reg_restored = 1;
+	pcgcctl.b.enbl_extnd_hiber = 1;
+	pcgcctl.b.rstpdwnmodule = 1;
+	pcgcctl.b.restoremode = 1;
+	DWC_WRITE_REG32(core_if->pcgcctl, pcgcctl.d32);
+
+	DWC_DEBUGPL(DBG_ANY, "%s called\n", __FUNCTION__);
+
+	return 1;
+}
+
+#ifdef CONFIG_USB_DWC_OTG_LPM
+/**
+ * This function hadles LPM transaction received interrupt.
+ */
+static int32_t dwc_otg_handle_lpm_intr(dwc_otg_core_if_t * core_if)
+{
+	glpmcfg_data_t lpmcfg;
+	gintsts_data_t gintsts;
+
+	if (!core_if->core_params->lpm_enable) {
+		DWC_PRINTF("Unexpected LPM interrupt\n");
+	}
+
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+	DWC_PRINTF("LPM config register = 0x%08x\n", lpmcfg.d32);
+
+	if (dwc_otg_is_host_mode(core_if)) {
+		cil_hcd_sleep(core_if);
+	} else {
+
+		pcgcctl_data_t pcgcctl = {.d32 = 0 };
+
+		lpmcfg.b.hird_thres |= (1 << 4);
+		lpmcfg.b.en_utmi_sleep = 1;
+
+		pcgcctl.b.enbl_sleep_gating = 1;
+		DWC_MODIFY_REG32(core_if->pcgcctl,0,pcgcctl.d32);
+
+		if(dwc_otg_get_param_besl_enable(core_if)) {
+			lpmcfg.b.en_besl = 1;
+		}
+
+		DWC_WRITE_REG32(&core_if->core_global_regs->glpmcfg,
+				lpmcfg.d32);
+	}
+
+	/* Examine prt_sleep_sts after TL1TokenTetry period max (10 us) */
+	dwc_udelay(10);
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+	if (lpmcfg.b.prt_sleep_sts) {
+		/* Save the current state */
+		core_if->lx_state = DWC_OTG_L1;
+	}
+
+	/* Clear interrupt  */
+	gintsts.d32 = 0;
+	gintsts.b.lpmtranrcvd = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+	return 1;
+}
+#endif /* CONFIG_USB_DWC_OTG_LPM */
+
+/**
+ * This function returns the Core Interrupt register.
+ */
+static inline uint32_t dwc_otg_read_common_intr(dwc_otg_core_if_t * core_if)
+{
+	gahbcfg_data_t gahbcfg = {.d32 = 0 };
+	gintsts_data_t gintsts;
+	gintmsk_data_t gintmsk;
+	gintmsk_data_t gintmsk_common = {.d32 = 0 };
+	gintmsk_common.b.wkupintr = 1;
+	gintmsk_common.b.sessreqintr = 1;
+	gintmsk_common.b.conidstschng = 1;
+	gintmsk_common.b.otgintr = 1;
+	gintmsk_common.b.modemismatch = 1;
+	gintmsk_common.b.disconnect = 1;
+	gintmsk_common.b.usbsuspend = 1;
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	gintmsk_common.b.lpmtranrcvd = 1;
+#endif
+	gintmsk_common.b.restoredone = 1;
+	/** @todo: The port interrupt occurs while in device
+         * mode. Added code to CIL to clear the interrupt for now!
+         */
+	gintmsk_common.b.portintr = 1;
+
+	gintsts.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintsts);
+	gintmsk.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintmsk);
+	gahbcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->gahbcfg);
+
+#ifdef DEBUG
+	/* if any common interrupts set */
+	if (gintsts.d32 & gintmsk_common.d32) {
+		DWC_DEBUGPL(DBG_ANY, "gintsts=%08x  gintmsk=%08x\n",
+			    gintsts.d32, gintmsk.d32);
+	}
+#endif
+	if (gahbcfg.b.glblintrmsk)
+		return ((gintsts.d32 & gintmsk.d32) & gintmsk_common.d32);
+	else
+		return 0;
+
+}
+
+/* MACRO for clearing interupt bits in GPWRDN register */
+#define CLEAR_GPWRDN_INTR(__core_if,__intr) \
+do { \
+		gpwrdn_data_t gpwrdn = {.d32=0}; \
+		gpwrdn.b.__intr = 1; \
+		DWC_MODIFY_REG32(&__core_if->core_global_regs->gpwrdn, \
+		0, gpwrdn.d32); \
+} while (0)
+
+/**
+ * Common interrupt handler.
+ *
+ * The common interrupts are those that occur in both Host and Device mode.
+ * This handler handles the following interrupts:
+ * - Mode Mismatch Interrupt
+ * - Disconnect Interrupt
+ * - OTG Interrupt
+ * - Connector ID Status Change Interrupt
+ * - Session Request Interrupt.
+ * - Resume / Remote Wakeup Detected Interrupt.
+ * - LPM Transaction Received Interrupt
+ * - ADP Transaction Received Interrupt
+ *
+ */
+int32_t dwc_otg_handle_common_intr(void *dev)
+{
+	int retval = 0;
+	gintsts_data_t gintsts;
+	gpwrdn_data_t gpwrdn = {.d32 = 0 };
+	dwc_otg_device_t *otg_dev = dev;
+	dwc_otg_core_if_t *core_if = otg_dev->core_if;
+	gpwrdn.d32 = DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+
+	if (dwc_otg_check_haps_status(core_if) == -1 ) {
+		DWC_WARN("HAPS is disconnected");
+		return retval;
+	}
+
+	if (dwc_otg_is_device_mode(core_if))
+		core_if->frame_num = dwc_otg_get_frame_number(core_if);
+
+	if (core_if->lock)
+		DWC_SPINLOCK(core_if->lock);
+
+	if (core_if->power_down == 3 && core_if->xhib == 1) {
+		DWC_DEBUGPL(DBG_ANY, "Exiting from xHIB state\n");
+		retval |= dwc_otg_handle_xhib_exit_intr(core_if);
+		core_if->xhib = 2;
+		if (core_if->lock)
+			DWC_SPINUNLOCK(core_if->lock);
+
+		return retval;
+	}
+
+	if (core_if->hibernation_suspend <= 0) {
+		gintsts.d32 = dwc_otg_read_common_intr(core_if);
+
+		if (gintsts.b.modemismatch) {
+			retval |= dwc_otg_handle_mode_mismatch_intr(core_if);
+		}
+		if (gintsts.b.otgintr) {
+			retval |= dwc_otg_handle_otg_intr(core_if);
+		}
+		if (gintsts.b.conidstschng) {
+			retval |=
+			    dwc_otg_handle_conn_id_status_change_intr(core_if);
+		}
+		if (gintsts.b.disconnect) {
+			retval |= dwc_otg_handle_disconnect_intr(core_if);
+		}
+		if (gintsts.b.sessreqintr) {
+			retval |= dwc_otg_handle_session_req_intr(core_if);
+		}
+		if (gintsts.b.wkupintr) {
+			retval |= dwc_otg_handle_wakeup_detected_intr(core_if);
+		}
+		if (gintsts.b.usbsuspend) {
+			retval |= dwc_otg_handle_usb_suspend_intr(core_if);
+		}
+#ifdef CONFIG_USB_DWC_OTG_LPM
+		if (gintsts.b.lpmtranrcvd) {
+			retval |= dwc_otg_handle_lpm_intr(core_if);
+		}
+#endif
+		if (gintsts.b.restoredone) {
+			gintsts.d32 = 0;
+			if (core_if->power_down == 2)
+				core_if->hibernation_suspend = -1;
+			else if (core_if->power_down == 3 && core_if->xhib == 2) {
+				gpwrdn_data_t gpwrdn = {.d32 = 0 };
+				pcgcctl_data_t pcgcctl = {.d32 = 0 };
+				dctl_data_t dctl = {.d32 = 0 };
+
+				DWC_WRITE_REG32(&core_if->core_global_regs->
+						gintsts, 0xFFFFFFFF);
+
+				DWC_DEBUGPL(DBG_ANY,
+					    "RESTORE DONE generated\n");
+
+				gpwrdn.b.restore = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+				dwc_udelay(10);
+
+				pcgcctl.b.rstpdwnmodule = 1;
+				DWC_MODIFY_REG32(core_if->pcgcctl, pcgcctl.d32, 0);
+
+				DWC_WRITE_REG32(&core_if->core_global_regs->gusbcfg, core_if->gr_backup->gusbcfg_local);
+				DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dcfg, core_if->dr_backup->dcfg);
+				DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dctl, core_if->dr_backup->dctl);
+				dwc_udelay(50);
+
+				dctl.b.pwronprgdone = 1;
+				DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl, 0, dctl.d32);
+				dwc_udelay(10);
+
+				dwc_otg_restore_global_regs(core_if);
+				dwc_otg_restore_dev_regs(core_if, 0);
+
+				dctl.d32 = 0;
+				dctl.b.pwronprgdone = 1;
+				DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl, dctl.d32, 0);
+				dwc_udelay(10);
+
+				pcgcctl.d32 = 0;
+				pcgcctl.b.enbl_extnd_hiber = 1;
+				DWC_MODIFY_REG32(core_if->pcgcctl, pcgcctl.d32, 0);
+
+				/* The core will be in ON STATE */
+				core_if->lx_state = DWC_OTG_L0;
+				core_if->xhib = 0;
+
+				DWC_SPINUNLOCK(core_if->lock);
+				if (core_if->pcd_cb && core_if->pcd_cb->resume_wakeup) {
+					core_if->pcd_cb->resume_wakeup(core_if->pcd_cb->p);
+				}
+				DWC_SPINLOCK(core_if->lock);
+
+			}
+
+			gintsts.b.restoredone = 1;
+			DWC_WRITE_REG32(&core_if->core_global_regs->gintsts,gintsts.d32);
+			DWC_PRINTF(" --Restore done interrupt received-- \n");
+			retval |= 1;
+		}
+		if (gintsts.b.portintr && dwc_otg_is_device_mode(core_if)) {
+			/* The port interrupt occurs while in device mode with HPRT0
+			 * Port Enable/Disable.
+			 */
+			gintsts.d32 = 0;
+			gintsts.b.portintr = 1;
+			DWC_WRITE_REG32(&core_if->core_global_regs->gintsts,gintsts.d32);
+			retval |= 1;
+
+		}
+	} else {
+		DWC_DEBUGPL(DBG_ANY, "gpwrdn=%08x\n", gpwrdn.d32);
+
+		if (gpwrdn.b.disconn_det && gpwrdn.b.disconn_det_msk) {
+			CLEAR_GPWRDN_INTR(core_if, disconn_det);
+			if (gpwrdn.b.linestate == 0) {
+				dwc_otg_handle_pwrdn_disconnect_intr(core_if);
+			} else {
+				DWC_PRINTF("Disconnect detected while linestate is not 0\n");
+			}
+
+			retval |= 1;
+		}
+		if (gpwrdn.b.lnstschng && gpwrdn.b.lnstchng_msk) {
+			CLEAR_GPWRDN_INTR(core_if, lnstschng);
+			/* remote wakeup from hibernation */
+			if (gpwrdn.b.linestate == 2 || gpwrdn.b.linestate == 1) {
+				dwc_otg_handle_pwrdn_wakeup_detected_intr(core_if);
+			} else {
+				DWC_PRINTF("gpwrdn.linestate = %d\n", gpwrdn.b.linestate);
+			}
+			retval |= 1;
+		}
+		if (gpwrdn.b.rst_det && gpwrdn.b.rst_det_msk) {
+			CLEAR_GPWRDN_INTR(core_if, rst_det);
+			if (gpwrdn.b.linestate == 0) {
+				DWC_PRINTF("Reset detected\n");
+				retval |= dwc_otg_device_hibernation_restore(core_if, 0, 1);
+			}
+		}
+		if (gpwrdn.b.srp_det && gpwrdn.b.srp_det_msk) {
+			CLEAR_GPWRDN_INTR(core_if, srp_det);
+			dwc_otg_handle_pwrdn_srp_intr(core_if);
+			retval |= 1;
+		}
+	}
+	/* Handle ADP interrupt here */
+	if (gpwrdn.b.adp_int) {
+		CLEAR_GPWRDN_INTR(core_if, adp_int);
+		dwc_otg_adp_handle_intr(core_if);
+		retval |= 1;
+	}
+	if (gpwrdn.b.sts_chngint && gpwrdn.b.sts_chngint_msk) {
+		CLEAR_GPWRDN_INTR(core_if, sts_chngint);
+		dwc_otg_handle_pwrdn_stschng_intr(otg_dev);
+
+		retval |= 1;
+	}
+	if (gpwrdn.b.srp_det && gpwrdn.b.srp_det_msk) {
+		CLEAR_GPWRDN_INTR(core_if, srp_det);
+		dwc_otg_handle_pwrdn_srp_intr(core_if);
+		retval |= 1;
+	}
+	if (core_if->lock)
+		DWC_SPINUNLOCK(core_if->lock);
+
+	return retval;
+}
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_core_if.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_core_if.h
new file mode 100644
index 0000000..c9ab2e5
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_core_if.h
@@ -0,0 +1,743 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_core_if.h $
+ * $Revision: #15 $
+ * $Date: 2012/12/10 $
+ * $Change: 2123206 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#if !defined(__DWC_CORE_IF_H__)
+#define __DWC_CORE_IF_H__
+
+#include "dwc_os.h"
+
+/** @file
+ * This file defines DWC_OTG Core API
+ */
+
+struct dwc_otg_core_if;
+typedef struct dwc_otg_core_if dwc_otg_core_if_t;
+
+/** Maximum number of Periodic FIFOs */
+#define MAX_PERIO_FIFOS 15
+/** Maximum number of Periodic FIFOs */
+#define MAX_TX_FIFOS 15
+
+/** Maximum number of Endpoints/HostChannels */
+#define MAX_EPS_CHANNELS 16
+
+extern dwc_otg_core_if_t *dwc_otg_cil_init(const uint32_t * _reg_base_addr);
+extern void dwc_otg_core_init(dwc_otg_core_if_t * _core_if);
+extern void dwc_otg_cil_remove(dwc_otg_core_if_t * _core_if);
+
+extern void dwc_otg_enable_global_interrupts(dwc_otg_core_if_t * _core_if);
+extern void dwc_otg_disable_global_interrupts(dwc_otg_core_if_t * _core_if);
+
+extern uint8_t dwc_otg_is_device_mode(dwc_otg_core_if_t * _core_if);
+extern uint8_t dwc_otg_is_host_mode(dwc_otg_core_if_t * _core_if);
+
+extern uint8_t dwc_otg_is_dma_enable(dwc_otg_core_if_t * core_if);
+
+/** This function should be called on every hardware interrupt. */
+extern int32_t dwc_otg_handle_common_intr(void *otg_dev);
+
+/** @name OTG Core Parameters */
+/** @{ */
+
+/**
+ * Specifies the OTG capabilities. The driver will automatically
+ * detect the value for this parameter if none is specified.
+ * 0 - HNP and SRP capable (default)
+ * 1 - SRP Only capable
+ * 2 - No HNP/SRP capable
+ */
+extern int dwc_otg_set_param_otg_cap(dwc_otg_core_if_t * core_if, int32_t val);
+extern int32_t dwc_otg_get_param_otg_cap(dwc_otg_core_if_t * core_if);
+#define DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE 0
+#define DWC_OTG_CAP_PARAM_SRP_ONLY_CAPABLE 1
+#define DWC_OTG_CAP_PARAM_NO_HNP_SRP_CAPABLE 2
+#define dwc_param_otg_cap_default DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE
+
+extern int dwc_otg_set_param_opt(dwc_otg_core_if_t * core_if, int32_t val);
+extern int32_t dwc_otg_get_param_opt(dwc_otg_core_if_t * core_if);
+#define dwc_param_opt_default 1
+
+/**
+ * Specifies whether to use slave or DMA mode for accessing the data
+ * FIFOs. The driver will automatically detect the value for this
+ * parameter if none is specified.
+ * 0 - Slave
+ * 1 - DMA (default, if available)
+ */
+extern int dwc_otg_set_param_dma_enable(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_dma_enable(dwc_otg_core_if_t * core_if);
+#define dwc_param_dma_enable_default 1
+
+/**
+ * When DMA mode is enabled specifies whether to use
+ * address DMA or DMA Descritor mode for accessing the data
+ * FIFOs in device mode. The driver will automatically detect
+ * the value for this parameter if none is specified.
+ * 0 - address DMA
+ * 1 - DMA Descriptor(default, if available)
+ */
+extern int dwc_otg_set_param_dma_desc_enable(dwc_otg_core_if_t * core_if,
+					     int32_t val);
+extern int32_t dwc_otg_get_param_dma_desc_enable(dwc_otg_core_if_t * core_if);
+#define dwc_param_dma_desc_enable_default 1
+
+/** The DMA Burst size (applicable only for External DMA
+ * Mode). 1, 4, 8 16, 32, 64, 128, 256 (default 32)
+ */
+extern int dwc_otg_set_param_dma_burst_size(dwc_otg_core_if_t * core_if,
+					    int32_t val);
+extern int32_t dwc_otg_get_param_dma_burst_size(dwc_otg_core_if_t * core_if);
+#define dwc_param_dma_burst_size_default 32
+
+/**
+ * Specifies the maximum speed of operation in host and device mode.
+ * The actual speed depends on the speed of the attached device and
+ * the value of phy_type. The actual speed depends on the speed of the
+ * attached device.
+ * 0 - High Speed (default)
+ * 1 - Full Speed
+ */
+extern int dwc_otg_set_param_speed(dwc_otg_core_if_t * core_if, int32_t val);
+extern int32_t dwc_otg_get_param_speed(dwc_otg_core_if_t * core_if);
+#define dwc_param_speed_default 0
+#define DWC_SPEED_PARAM_HIGH 0
+#define DWC_SPEED_PARAM_FULL 1
+
+/** Specifies whether low power mode is supported when attached
+ *	to a Full Speed or Low Speed device in host mode.
+ * 0 - Don't support low power mode (default)
+ * 1 - Support low power mode
+ */
+extern int dwc_otg_set_param_host_support_fs_ls_low_power(dwc_otg_core_if_t *
+							  core_if, int32_t val);
+extern int32_t dwc_otg_get_param_host_support_fs_ls_low_power(dwc_otg_core_if_t
+							      * core_if);
+#define dwc_param_host_support_fs_ls_low_power_default 0
+
+/** Specifies the PHY clock rate in low power mode when connected to a
+ * Low Speed device in host mode. This parameter is applicable only if
+ * HOST_SUPPORT_FS_LS_LOW_POWER is enabled. If PHY_TYPE is set to FS
+ * then defaults to 6 MHZ otherwise 48 MHZ.
+ *
+ * 0 - 48 MHz
+ * 1 - 6 MHz
+ */
+extern int dwc_otg_set_param_host_ls_low_power_phy_clk(dwc_otg_core_if_t *
+						       core_if, int32_t val);
+extern int32_t dwc_otg_get_param_host_ls_low_power_phy_clk(dwc_otg_core_if_t *
+							   core_if);
+#define dwc_param_host_ls_low_power_phy_clk_default 0
+#define DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_48MHZ 0
+#define DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_6MHZ 1
+
+/**
+ * 0 - Use cC FIFO size parameters
+ * 1 - Allow dynamic FIFO sizing (default)
+ */
+extern int dwc_otg_set_param_enable_dynamic_fifo(dwc_otg_core_if_t * core_if,
+						 int32_t val);
+extern int32_t dwc_otg_get_param_enable_dynamic_fifo(dwc_otg_core_if_t *
+						     core_if);
+#define dwc_param_enable_dynamic_fifo_default 1
+
+/** Total number of 4-byte words in the data FIFO memory. This
+ * memory includes the Rx FIFO, non-periodic Tx FIFO, and periodic
+ * Tx FIFOs.
+ * 32 to 32768 (default 8192)
+ * Note: The total FIFO memory depth in the FPGA configuration is 8192.
+ */
+extern int dwc_otg_set_param_data_fifo_size(dwc_otg_core_if_t * core_if,
+					    int32_t val);
+extern int32_t dwc_otg_get_param_data_fifo_size(dwc_otg_core_if_t * core_if);
+#define dwc_param_data_fifo_size_default 8192
+
+/** Number of 4-byte words in the Rx FIFO in device mode when dynamic
+ * FIFO sizing is enabled.
+ * 16 to 32768 (default 1064)
+ */
+extern int dwc_otg_set_param_dev_rx_fifo_size(dwc_otg_core_if_t * core_if,
+					      int32_t val);
+extern int32_t dwc_otg_get_param_dev_rx_fifo_size(dwc_otg_core_if_t * core_if);
+#define dwc_param_dev_rx_fifo_size_default 1064
+
+/** Number of 4-byte words in the non-periodic Tx FIFO in device mode
+ * when dynamic FIFO sizing is enabled.
+ * 16 to 32768 (default 1024)
+ */
+extern int dwc_otg_set_param_dev_nperio_tx_fifo_size(dwc_otg_core_if_t *
+						     core_if, int32_t val);
+extern int32_t dwc_otg_get_param_dev_nperio_tx_fifo_size(dwc_otg_core_if_t *
+							 core_if);
+#define dwc_param_dev_nperio_tx_fifo_size_default 1024
+
+/** Number of 4-byte words in each of the periodic Tx FIFOs in device
+ * mode when dynamic FIFO sizing is enabled.
+ * 4 to 768 (default 256)
+ */
+extern int dwc_otg_set_param_dev_perio_tx_fifo_size(dwc_otg_core_if_t * core_if,
+						    int32_t val, int fifo_num);
+extern int32_t dwc_otg_get_param_dev_perio_tx_fifo_size(dwc_otg_core_if_t *
+							core_if, int fifo_num);
+#define dwc_param_dev_perio_tx_fifo_size_default 256
+
+/** Number of 4-byte words in the Rx FIFO in host mode when dynamic
+ * FIFO sizing is enabled.
+ * 16 to 32768 (default 1024)
+ */
+extern int dwc_otg_set_param_host_rx_fifo_size(dwc_otg_core_if_t * core_if,
+					       int32_t val);
+extern int32_t dwc_otg_get_param_host_rx_fifo_size(dwc_otg_core_if_t * core_if);
+#define dwc_param_host_rx_fifo_size_default 1024
+
+/** Number of 4-byte words in the non-periodic Tx FIFO in host mode
+ * when Dynamic FIFO sizing is enabled in the core.
+ * 16 to 32768 (default 1024)
+ */
+extern int dwc_otg_set_param_host_nperio_tx_fifo_size(dwc_otg_core_if_t *
+						      core_if, int32_t val);
+extern int32_t dwc_otg_get_param_host_nperio_tx_fifo_size(dwc_otg_core_if_t *
+							  core_if);
+#define dwc_param_host_nperio_tx_fifo_size_default 1024
+
+/** Number of 4-byte words in the host periodic Tx FIFO when dynamic
+ * FIFO sizing is enabled.
+ * 16 to 32768 (default 1024)
+ */
+extern int dwc_otg_set_param_host_perio_tx_fifo_size(dwc_otg_core_if_t *
+						     core_if, int32_t val);
+extern int32_t dwc_otg_get_param_host_perio_tx_fifo_size(dwc_otg_core_if_t *
+							 core_if);
+#define dwc_param_host_perio_tx_fifo_size_default 1024
+
+/** The maximum transfer size supported in bytes.
+ * 2047 to 65,535  (default 65,535)
+ */
+extern int dwc_otg_set_param_max_transfer_size(dwc_otg_core_if_t * core_if,
+					       int32_t val);
+extern int32_t dwc_otg_get_param_max_transfer_size(dwc_otg_core_if_t * core_if);
+#define dwc_param_max_transfer_size_default 65535
+
+/** The maximum number of packets in a transfer.
+ * 15 to 511  (default 511)
+ */
+extern int dwc_otg_set_param_max_packet_count(dwc_otg_core_if_t * core_if,
+					      int32_t val);
+extern int32_t dwc_otg_get_param_max_packet_count(dwc_otg_core_if_t * core_if);
+#define dwc_param_max_packet_count_default 511
+
+/** The number of host channel registers to use.
+ * 1 to 16 (default 12)
+ * Note: The FPGA configuration supports a maximum of 12 host channels.
+ */
+extern int dwc_otg_set_param_host_channels(dwc_otg_core_if_t * core_if,
+					   int32_t val);
+extern int32_t dwc_otg_get_param_host_channels(dwc_otg_core_if_t * core_if);
+#define dwc_param_host_channels_default 12
+
+/** The number of endpoints in addition to EP0 available for device
+ * mode operations.
+ * 1 to 15 (default 6 IN and OUT)
+ * Note: The FPGA configuration supports a maximum of 6 IN and OUT
+ * endpoints in addition to EP0.
+ */
+extern int dwc_otg_set_param_dev_endpoints(dwc_otg_core_if_t * core_if,
+					   int32_t val);
+extern int32_t dwc_otg_get_param_dev_endpoints(dwc_otg_core_if_t * core_if);
+#define dwc_param_dev_endpoints_default 6
+
+/**
+ * Specifies the type of PHY interface to use. By default, the driver
+ * will automatically detect the phy_type.
+ *
+ * 0 - Full Speed PHY
+ * 1 - UTMI+ (default)
+ * 2 - ULPI
+ */
+extern int dwc_otg_set_param_phy_type(dwc_otg_core_if_t * core_if, int32_t val);
+extern int32_t dwc_otg_get_param_phy_type(dwc_otg_core_if_t * core_if);
+#define DWC_PHY_TYPE_PARAM_FS 0
+#define DWC_PHY_TYPE_PARAM_UTMI 1
+#define DWC_PHY_TYPE_PARAM_ULPI 2
+#define dwc_param_phy_type_default DWC_PHY_TYPE_PARAM_UTMI
+
+/**
+ * Specifies the UTMI+ Data Width. This parameter is
+ * applicable for a PHY_TYPE of UTMI+ or ULPI. (For a ULPI
+ * PHY_TYPE, this parameter indicates the data width between
+ * the MAC and the ULPI Wrapper.) Also, this parameter is
+ * applicable only if the OTG_HSPHY_WIDTH cC parameter was set
+ * to "8 and 16 bits", meaning that the core has been
+ * configured to work at either data path width.
+ *
+ * 8 or 16 bits (default 16)
+ */
+extern int dwc_otg_set_param_phy_utmi_width(dwc_otg_core_if_t * core_if,
+					    int32_t val);
+extern int32_t dwc_otg_get_param_phy_utmi_width(dwc_otg_core_if_t * core_if);
+#define dwc_param_phy_utmi_width_default 16
+
+/**
+ * Specifies whether the ULPI operates at double or single
+ * data rate. This parameter is only applicable if PHY_TYPE is
+ * ULPI.
+ *
+ * 0 - single data rate ULPI interface with 8 bit wide data
+ * bus (default)
+ * 1 - double data rate ULPI interface with 4 bit wide data
+ * bus
+ */
+extern int dwc_otg_set_param_phy_ulpi_ddr(dwc_otg_core_if_t * core_if,
+					  int32_t val);
+extern int32_t dwc_otg_get_param_phy_ulpi_ddr(dwc_otg_core_if_t * core_if);
+#define dwc_param_phy_ulpi_ddr_default 0
+
+/**
+ * Specifies whether to use the internal or external supply to
+ * drive the vbus with a ULPI phy.
+ */
+extern int dwc_otg_set_param_phy_ulpi_ext_vbus(dwc_otg_core_if_t * core_if,
+					       int32_t val);
+extern int32_t dwc_otg_get_param_phy_ulpi_ext_vbus(dwc_otg_core_if_t * core_if);
+#define DWC_PHY_ULPI_INTERNAL_VBUS 0
+#define DWC_PHY_ULPI_EXTERNAL_VBUS 1
+#define dwc_param_phy_ulpi_ext_vbus_default DWC_PHY_ULPI_INTERNAL_VBUS
+
+/**
+ * Specifies whether to use the I2Cinterface for full speed PHY. This
+ * parameter is only applicable if PHY_TYPE is FS.
+ * 0 - No (default)
+ * 1 - Yes
+ */
+extern int dwc_otg_set_param_i2c_enable(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_i2c_enable(dwc_otg_core_if_t * core_if);
+#define dwc_param_i2c_enable_default 0
+
+extern int dwc_otg_set_param_ulpi_fs_ls(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_ulpi_fs_ls(dwc_otg_core_if_t * core_if);
+#define dwc_param_ulpi_fs_ls_default 0
+
+extern int dwc_otg_set_param_ts_dline(dwc_otg_core_if_t * core_if, int32_t val);
+extern int32_t dwc_otg_get_param_ts_dline(dwc_otg_core_if_t * core_if);
+#define dwc_param_ts_dline_default 0
+
+/**
+ * Specifies whether dedicated transmit FIFOs are
+ * enabled for non periodic IN endpoints in device mode
+ * 0 - No
+ * 1 - Yes
+ */
+extern int dwc_otg_set_param_en_multiple_tx_fifo(dwc_otg_core_if_t * core_if,
+						 int32_t val);
+extern int32_t dwc_otg_get_param_en_multiple_tx_fifo(dwc_otg_core_if_t *
+						     core_if);
+#define dwc_param_en_multiple_tx_fifo_default 1
+
+/** Number of 4-byte words in each of the Tx FIFOs in device
+ * mode when dynamic FIFO sizing is enabled.
+ * 4 to 768 (default 256)
+ */
+extern int dwc_otg_set_param_dev_tx_fifo_size(dwc_otg_core_if_t * core_if,
+					      int fifo_num, int32_t val);
+extern int32_t dwc_otg_get_param_dev_tx_fifo_size(dwc_otg_core_if_t * core_if,
+						  int fifo_num);
+#define dwc_param_dev_tx_fifo_size_default 256
+
+/** Thresholding enable flag-
+ * bit 0 - enable non-ISO Tx thresholding
+ * bit 1 - enable ISO Tx thresholding
+ * bit 2 - enable Rx thresholding
+ */
+extern int dwc_otg_set_param_thr_ctl(dwc_otg_core_if_t * core_if, int32_t val);
+extern int32_t dwc_otg_get_thr_ctl(dwc_otg_core_if_t * core_if, int fifo_num);
+#define dwc_param_thr_ctl_default 0
+
+/** Thresholding length for Tx
+ * FIFOs in 32 bit DWORDs
+ */
+extern int dwc_otg_set_param_tx_thr_length(dwc_otg_core_if_t * core_if,
+					   int32_t val);
+extern int32_t dwc_otg_get_tx_thr_length(dwc_otg_core_if_t * core_if);
+#define dwc_param_tx_thr_length_default 64
+
+/** Thresholding length for Rx
+ *	FIFOs in 32 bit DWORDs
+ */
+extern int dwc_otg_set_param_rx_thr_length(dwc_otg_core_if_t * core_if,
+					   int32_t val);
+extern int32_t dwc_otg_get_rx_thr_length(dwc_otg_core_if_t * core_if);
+#define dwc_param_rx_thr_length_default 64
+
+/**
+ * Specifies whether LPM (Link Power Management) support is enabled
+ */
+extern int dwc_otg_set_param_lpm_enable(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_lpm_enable(dwc_otg_core_if_t * core_if);
+#define dwc_param_lpm_enable_default 1
+
+/**
+ * Specifies whether LPM Errata (Link Power Management) support is enabled
+ */
+extern int dwc_otg_set_param_besl_enable(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_besl_enable(dwc_otg_core_if_t * core_if);
+#define dwc_param_besl_enable_default 0
+
+/**
+ * Specifies baseline_besl default value
+ */
+extern int dwc_otg_set_param_baseline_besl(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_baseline_besl(dwc_otg_core_if_t * core_if);
+#define dwc_param_baseline_besl_default 0
+
+/**
+ * Specifies deep_besl default value
+ */
+extern int dwc_otg_set_param_deep_besl(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_deep_besl(dwc_otg_core_if_t * core_if);
+#define dwc_param_deep_besl_default 15
+
+/**
+ * Specifies whether PTI enhancement is enabled
+ */
+extern int dwc_otg_set_param_pti_enable(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_pti_enable(dwc_otg_core_if_t * core_if);
+#define dwc_param_pti_enable_default 0
+
+/**
+ * Specifies whether MPI enhancement is enabled
+ */
+extern int dwc_otg_set_param_mpi_enable(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_mpi_enable(dwc_otg_core_if_t * core_if);
+#define dwc_param_mpi_enable_default 0
+
+/**
+ * Specifies whether ADP capability is enabled
+ */
+extern int dwc_otg_set_param_adp_enable(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_adp_enable(dwc_otg_core_if_t * core_if);
+#define dwc_param_adp_enable_default 0
+
+/**
+ * Specifies whether IC_USB capability is enabled
+ */
+
+extern int dwc_otg_set_param_ic_usb_cap(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_ic_usb_cap(dwc_otg_core_if_t * core_if);
+#define dwc_param_ic_usb_cap_default 0
+
+extern int dwc_otg_set_param_ahb_thr_ratio(dwc_otg_core_if_t * core_if,
+					   int32_t val);
+extern int32_t dwc_otg_get_param_ahb_thr_ratio(dwc_otg_core_if_t * core_if);
+#define dwc_param_ahb_thr_ratio_default 0
+
+extern int dwc_otg_set_param_power_down(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_power_down(dwc_otg_core_if_t * core_if);
+#define dwc_param_power_down_default 0
+
+extern int dwc_otg_set_param_reload_ctl(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_reload_ctl(dwc_otg_core_if_t * core_if);
+#define dwc_param_reload_ctl_default 0
+
+extern int dwc_otg_set_param_dev_out_nak(dwc_otg_core_if_t * core_if,
+					 int32_t val);
+extern int32_t dwc_otg_get_param_dev_out_nak(dwc_otg_core_if_t * core_if);
+#define dwc_param_dev_out_nak_default 0
+
+extern int dwc_otg_set_param_cont_on_bna(dwc_otg_core_if_t * core_if,
+					 int32_t val);
+extern int32_t dwc_otg_get_param_cont_on_bna(dwc_otg_core_if_t * core_if);
+#define dwc_param_cont_on_bna_default 0
+
+extern int dwc_otg_set_param_ahb_single(dwc_otg_core_if_t * core_if,
+					int32_t val);
+extern int32_t dwc_otg_get_param_ahb_single(dwc_otg_core_if_t * core_if);
+#define dwc_param_ahb_single_default 0
+
+extern int dwc_otg_set_param_otg_ver(dwc_otg_core_if_t * core_if, int32_t val);
+extern int32_t dwc_otg_get_param_otg_ver(dwc_otg_core_if_t * core_if);
+#define dwc_param_otg_ver_default 0
+
+/** @} */
+
+/** @name Access to registers and bit-fields */
+
+/**
+ * Dump core registers and SPRAM
+ */
+extern void dwc_otg_dump_dev_registers(dwc_otg_core_if_t * _core_if);
+extern void dwc_otg_dump_spram(dwc_otg_core_if_t * _core_if);
+extern void dwc_otg_dump_host_registers(dwc_otg_core_if_t * _core_if);
+extern void dwc_otg_dump_global_registers(dwc_otg_core_if_t * _core_if);
+
+/**
+ * Get host negotiation status.
+ */
+extern uint32_t dwc_otg_get_hnpstatus(dwc_otg_core_if_t * core_if);
+
+/**
+ * Get srp status
+ */
+extern uint32_t dwc_otg_get_srpstatus(dwc_otg_core_if_t * core_if);
+
+/**
+ * Set hnpreq bit in the GOTGCTL register.
+ */
+extern void dwc_otg_set_hnpreq(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * Get Content of SNPSID register.
+ */
+extern uint32_t dwc_otg_get_gsnpsid(dwc_otg_core_if_t * core_if);
+
+/**
+ * Get current mode.
+ * Returns 0 if in device mode, and 1 if in host mode.
+ */
+extern uint32_t dwc_otg_get_mode(dwc_otg_core_if_t * core_if);
+
+/**
+ * Get value of hnpcapable field in the GUSBCFG register
+ */
+extern uint32_t dwc_otg_get_hnpcapable(dwc_otg_core_if_t * core_if);
+/**
+ * Set value of hnpcapable field in the GUSBCFG register
+ */
+extern void dwc_otg_set_hnpcapable(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * Get value of srpcapable field in the GUSBCFG register
+ */
+extern uint32_t dwc_otg_get_srpcapable(dwc_otg_core_if_t * core_if);
+/**
+ * Set value of srpcapable field in the GUSBCFG register
+ */
+extern void dwc_otg_set_srpcapable(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * Get value of devspeed field in the DCFG register
+ */
+extern uint32_t dwc_otg_get_devspeed(dwc_otg_core_if_t * core_if);
+/**
+ * Set value of devspeed field in the DCFG register
+ */
+extern void dwc_otg_set_devspeed(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * Get the value of busconnected field from the HPRT0 register
+ */
+extern uint32_t dwc_otg_get_busconnected(dwc_otg_core_if_t * core_if);
+
+/**
+ * Gets the device enumeration Speed.
+ */
+extern uint32_t dwc_otg_get_enumspeed(dwc_otg_core_if_t * core_if);
+
+/**
+ * Get value of prtpwr field from the HPRT0 register
+ */
+extern uint32_t dwc_otg_get_prtpower(dwc_otg_core_if_t * core_if);
+
+/**
+ * Get value of flag indicating core state - hibernated or not
+ */
+extern uint32_t dwc_otg_get_core_state(dwc_otg_core_if_t * core_if);
+
+/**
+ * Set value of prtpwr field from the HPRT0 register
+ */
+extern void dwc_otg_set_prtpower(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * Get value of prtsusp field from the HPRT0 regsiter
+ */
+extern uint32_t dwc_otg_get_prtsuspend(dwc_otg_core_if_t * core_if);
+/**
+ * Set value of prtpwr field from the HPRT0 register
+ */
+extern void dwc_otg_set_prtsuspend(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * Get value of ModeChTimEn field from the HCFG regsiter
+ */
+extern uint32_t dwc_otg_get_mode_ch_tim(dwc_otg_core_if_t * core_if);
+/**
+ * Set value of ModeChTimEn field from the HCFG regsiter
+ */
+extern void dwc_otg_set_mode_ch_tim(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * Get value of Fram Interval field from the HFIR regsiter
+ */
+extern uint32_t dwc_otg_get_fr_interval(dwc_otg_core_if_t * core_if);
+/**
+ * Set value of Frame Interval field from the HFIR regsiter
+ */
+extern void dwc_otg_set_fr_interval(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * Set value of prtres field from the HPRT0 register
+ *FIXME Remove?
+ */
+extern void dwc_otg_set_prtresume(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * Get value of rmtwkupsig bit in DCTL register
+ */
+extern uint32_t dwc_otg_get_remotewakesig(dwc_otg_core_if_t * core_if);
+
+/**
+ * Get value of besl_reject bit in DCTL register
+ */
+
+extern uint32_t dwc_otg_get_beslreject(dwc_otg_core_if_t * core_if);
+
+/**
+ * Set value of besl_reject bit in DCTL register
+ */
+
+extern void dwc_otg_set_beslreject(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * Get value of prt_sleep_sts field from the GLPMCFG register
+ */
+extern uint32_t dwc_otg_get_lpm_portsleepstatus(dwc_otg_core_if_t * core_if);
+
+/**
+ * Get value of rem_wkup_en field from the GLPMCFG register
+ */
+extern uint32_t dwc_otg_get_lpm_remotewakeenabled(dwc_otg_core_if_t * core_if);
+
+/**
+ * Get value of appl_resp field from the GLPMCFG register
+ */
+extern uint32_t dwc_otg_get_lpmresponse(dwc_otg_core_if_t * core_if);
+/**
+ * Set value of appl_resp field from the GLPMCFG register
+ */
+extern void dwc_otg_set_lpmresponse(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * Get value of hsic_connect field from the GLPMCFG register
+ */
+extern uint32_t dwc_otg_get_hsic_connect(dwc_otg_core_if_t * core_if);
+/**
+ * Set value of hsic_connect field from the GLPMCFG register
+ */
+extern void dwc_otg_set_hsic_connect(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * Get value of inv_sel_hsic field from the GLPMCFG register.
+ */
+extern uint32_t dwc_otg_get_inv_sel_hsic(dwc_otg_core_if_t * core_if);
+/**
+ * Set value of inv_sel_hsic field from the GLPMFG register.
+ */
+extern void dwc_otg_set_inv_sel_hsic(dwc_otg_core_if_t * core_if, uint32_t val);
+/**
+ * Set value of hird_thresh field from the GLPMFG register.
+ */
+extern void dwc_otg_set_hirdthresh(dwc_otg_core_if_t * core_if, uint32_t val);
+/**
+ * Get value of hird_thresh field from the GLPMFG register.
+ */
+extern uint32_t dwc_otg_get_hirdthresh(dwc_otg_core_if_t * core_if);
+
+
+/*
+ * Some functions for accessing registers
+ */
+
+/**
+ *  GOTGCTL register
+ */
+extern uint32_t dwc_otg_get_gotgctl(dwc_otg_core_if_t * core_if);
+extern void dwc_otg_set_gotgctl(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * GUSBCFG register
+ */
+extern uint32_t dwc_otg_get_gusbcfg(dwc_otg_core_if_t * core_if);
+extern void dwc_otg_set_gusbcfg(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * GRXFSIZ register
+ */
+extern uint32_t dwc_otg_get_grxfsiz(dwc_otg_core_if_t * core_if);
+extern void dwc_otg_set_grxfsiz(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * GNPTXFSIZ register
+ */
+extern uint32_t dwc_otg_get_gnptxfsiz(dwc_otg_core_if_t * core_if);
+extern void dwc_otg_set_gnptxfsiz(dwc_otg_core_if_t * core_if, uint32_t val);
+
+extern uint32_t dwc_otg_get_gpvndctl(dwc_otg_core_if_t * core_if);
+extern void dwc_otg_set_gpvndctl(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * GGPIO register
+ */
+extern uint32_t dwc_otg_get_ggpio(dwc_otg_core_if_t * core_if);
+extern void dwc_otg_set_ggpio(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * GUID register
+ */
+extern uint32_t dwc_otg_get_guid(dwc_otg_core_if_t * core_if);
+extern void dwc_otg_set_guid(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * HPRT0 register
+ */
+extern uint32_t dwc_otg_get_hprt0(dwc_otg_core_if_t * core_if);
+extern void dwc_otg_set_hprt0(dwc_otg_core_if_t * core_if, uint32_t val);
+
+/**
+ * GHPTXFSIZE
+ */
+extern uint32_t dwc_otg_get_hptxfsiz(dwc_otg_core_if_t * core_if);
+
+/** @} */
+
+#endif /* __DWC_CORE_IF_H__ */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_dbg.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_dbg.h
new file mode 100644
index 0000000..32c7d10
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_dbg.h
@@ -0,0 +1,113 @@
+/* ==========================================================================
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#ifndef __DWC_OTG_DBG_H__
+#define __DWC_OTG_DBG_H__
+
+/** @file
+ * This file defines debug levels.
+ * Debugging support vanishes in non-debug builds.
+ */
+
+/**
+ * The Debug Level bit-mask variable.
+ */
+extern uint32_t g_dbg_lvl;
+/**
+ * Set the Debug Level variable.
+ */
+static inline uint32_t SET_DEBUG_LEVEL(const uint32_t new)
+{
+	uint32_t old = g_dbg_lvl;
+	g_dbg_lvl = new;
+	return old;
+}
+
+/** When debug level has the DBG_CIL bit set, display CIL Debug messages. */
+#define DBG_CIL		(0x2)
+/** When debug level has the DBG_CILV bit set, display CIL Verbose debug
+ * messages */
+#define DBG_CILV	(0x20)
+/**  When debug level has the DBG_PCD bit set, display PCD (Device) debug
+ *  messages */
+#define DBG_PCD		(0x4)
+/** When debug level has the DBG_PCDV set, display PCD (Device) Verbose debug
+ * messages */
+#define DBG_PCDV	(0x40)
+/** When debug level has the DBG_HCD bit set, display Host debug messages */
+#define DBG_HCD		(0x8)
+/** When debug level has the DBG_HCDV bit set, display Verbose Host debug
+ * messages */
+#define DBG_HCDV	(0x80)
+/** When debug level has the DBG_HCD_URB bit set, display enqueued URBs in host
+ *  mode. */
+#define DBG_HCD_URB	(0x800)
+
+/** When debug level has any bit set, display debug messages */
+#define DBG_ANY		(0xFF)
+
+/** All debug messages off */
+#define DBG_OFF		0
+
+/** Prefix string for DWC_DEBUG print macros. */
+#define USB_DWC "DWC_otg: "
+
+/**
+ * Print a debug message when the Global debug level variable contains
+ * the bit defined in <code>lvl</code>.
+ *
+ * @param[in] lvl - Debug level, use one of the DBG_ constants above.
+ * @param[in] x - like printf
+ *
+ *    Example:<p>
+ * <code>
+ *      DWC_DEBUGPL( DBG_ANY, "%s(%p)\n", __func__, _reg_base_addr);
+ * </code>
+ * <br>
+ * results in:<br>
+ * <code>
+ * usb-DWC_otg: dwc_otg_cil_init(ca867000)
+ * </code>
+ */
+#ifdef DEBUG
+
+# define DWC_DEBUGPL(lvl, x...) do{ if ((lvl)&g_dbg_lvl)__DWC_DEBUG(USB_DWC x ); }while(0)
+# define DWC_DEBUGP(x...)	DWC_DEBUGPL(DBG_ANY, x )
+
+# define CHK_DEBUG_LEVEL(level) ((level) & g_dbg_lvl)
+
+#else
+
+# define DWC_DEBUGPL(lvl, x...) do{}while(0)
+# define DWC_DEBUGP(x...)
+
+# define CHK_DEBUG_LEVEL(level) (0)
+
+#endif /*DEBUG*/
+#endif
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_driver.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_driver.c
new file mode 100644
index 0000000..2ca6dcc
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_driver.c
@@ -0,0 +1,802 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_driver.c $
+ * $Revision: #96 $
+ * $Date: 2013/05/20 $
+ * $Change: 2234037 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+/** @file
+ * The dwc_otg_driver module provides the initialization and cleanup entry
+ * points for the DWC_otg driver. This module will be dynamically installed
+ * after Linux is booted using the insmod command. When the module is
+ * installed, the dwc_otg_driver_init function is called. When the module is
+ * removed (using rmmod), the dwc_otg_driver_cleanup function is called.
+ *
+ * This module also defines a data structure for the dwc_otg_driver, which is
+ * used in conjunction with the standard ARM lm_device structure. These
+ * structures allow the OTG driver to comply with the standard Linux driver
+ * model in which devices and drivers are registered with a bus driver. This
+ * has the benefit that Linux can expose attributes of the driver and device
+ * in its special sysfs file system. Users can then read or write files in
+ * this file system to perform diagnostics on the driver components or the
+ * device.
+ */
+#include <linux/clk.h>
+#include <linux/dma-mapping.h>
+#include <linux/err.h>
+#include <linux/kernel.h>
+#include <linux/hrtimer.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/platform_device.h>
+
+#include "dwc_otg_os_dep.h"
+#include "dwc_os.h"
+#include "dwc_otg_dbg.h"
+#include "dwc_otg_driver.h"
+#include "dwc_otg_attr.h"
+#include "dwc_otg_core_if.h"
+#include "dwc_otg_pcd_if.h"
+#include "dwc_otg_hcd_if.h"
+
+
+#define DWC_DRIVER_VERSION	"3.00a 10-AUG-2012"
+
+static const char driver_name[] = "hiudc";
+
+extern int pcd_init(  struct platform_device *_dev , int irqnum);
+extern int hcd_init(  struct platform_device *_dev );
+extern int pcd_remove(  struct platform_device *_dev );
+extern void hcd_remove(  struct platform_device *_dev );
+extern void dwc_otg_adp_start(dwc_otg_core_if_t * core_if, uint8_t is_host);
+
+/******************************************************************************/
+
+/* Encapsulate the module parameter settings */
+
+struct dwc_otg_driver_module_params {
+	int32_t opt;
+	int32_t otg_cap;
+	int32_t dma_enable;
+	int32_t dma_desc_enable;
+	int32_t dma_burst_size;
+	int32_t speed;
+	int32_t host_support_fs_ls_low_power;
+	int32_t host_ls_low_power_phy_clk;
+	int32_t enable_dynamic_fifo;
+	int32_t data_fifo_size;
+	int32_t dev_rx_fifo_size;
+	int32_t dev_nperio_tx_fifo_size;
+	uint32_t dev_perio_tx_fifo_size[MAX_PERIO_FIFOS];
+	int32_t host_rx_fifo_size;
+	int32_t host_nperio_tx_fifo_size;
+	int32_t host_perio_tx_fifo_size;
+	int32_t max_transfer_size;
+	int32_t max_packet_count;
+	int32_t host_channels;
+	int32_t dev_endpoints;
+	int32_t phy_type;
+	int32_t phy_utmi_width;
+	int32_t phy_ulpi_ddr;
+	int32_t phy_ulpi_ext_vbus;
+	int32_t i2c_enable;
+	int32_t ulpi_fs_ls;
+	int32_t ts_dline;
+	int32_t en_multiple_tx_fifo;
+	uint32_t dev_tx_fifo_size[MAX_TX_FIFOS];
+	uint32_t thr_ctl;
+	uint32_t tx_thr_length;
+	uint32_t rx_thr_length;
+	int32_t pti_enable;
+	int32_t mpi_enable;
+	int32_t lpm_enable;
+	int32_t besl_enable;
+	int32_t baseline_besl;
+	int32_t deep_besl;
+	int32_t ic_usb_cap;
+	int32_t ahb_thr_ratio;
+	int32_t power_down;
+	int32_t reload_ctl;
+	int32_t dev_out_nak;
+	int32_t cont_on_bna;
+	int32_t ahb_single;
+	int32_t otg_ver;
+	int32_t adp_enable;
+};
+/******************************************************************************/
+
+static struct dwc_otg_driver_module_params dwc_otg_module_params = {
+	.opt = -1,
+	.otg_cap = 2, /*non-hnp/srp-capable*/
+	.dma_enable = 1, /* enable */
+	.dma_desc_enable = 1,
+	.dma_burst_size = -1,
+	.speed = -1,/*high-speed*/
+	.host_support_fs_ls_low_power = -1, /* lowpower mode isn't supported */
+	.host_ls_low_power_phy_clk = -1,
+	.enable_dynamic_fifo = -1,  /* use coreconsultant fifo size */
+	.data_fifo_size = -1,
+	.dev_rx_fifo_size = -1,
+	.dev_nperio_tx_fifo_size = -1,
+	.dev_perio_tx_fifo_size = {
+				   /* dev_perio_tx_fifo_size_1 */
+				   -1,
+				   -1,
+				   -1,
+				   -1,
+				   -1,
+				   -1,
+				   -1,
+				   -1,
+				   -1,
+				   -1,
+				   -1,
+				   -1,
+				   -1,
+				   -1,
+				   -1
+				   /* 15 */
+				   },
+	.host_rx_fifo_size = -1,
+	.host_nperio_tx_fifo_size = -1,
+	.host_perio_tx_fifo_size = -1,
+	.max_transfer_size = -1,
+	.max_packet_count = -1,
+	.host_channels = -1,
+	.dev_endpoints = -1,
+	.phy_type = -1,/*utmi+*/
+	.phy_utmi_width = 8,
+	.phy_ulpi_ddr = -1,
+	.phy_ulpi_ext_vbus = -1,
+	.i2c_enable = -1,
+	.ulpi_fs_ls = -1,
+	.ts_dline = -1,
+	.en_multiple_tx_fifo = -1,
+	.dev_tx_fifo_size = {
+			     /* dev_tx_fifo_size */
+			     -1,
+			     -1,
+			     -1,
+			     -1,
+			     -1,
+			     -1,
+			     -1,
+			     -1,
+			     -1,
+			     -1,
+			     -1,
+			     -1,
+			     -1,
+			     -1,
+			     -1
+			     /* 15 */
+			     },
+	.thr_ctl = -1,
+	.tx_thr_length = -1,
+	.rx_thr_length = -1,
+	.pti_enable = -1,
+	.mpi_enable = -1,
+	.lpm_enable = -1,
+	.besl_enable = -1,
+	.baseline_besl = -1,
+	.deep_besl = -1,
+	.ic_usb_cap = -1,
+	.ahb_thr_ratio = -1,
+	.power_down = -1,
+	.reload_ctl = -1,
+	.dev_out_nak = -1,
+	.cont_on_bna = -1,
+	.ahb_single = -1,
+	.otg_ver = -1,
+	.adp_enable = -1,
+};
+/******************************************************************************/
+
+/**
+ * This function is called during module intialization
+ * to pass module parameters to the DWC_OTG CORE.
+ */
+static int set_parameters(dwc_otg_core_if_t * core_if)
+{
+	int retval = 0;
+	int i;
+
+	if (dwc_otg_module_params.otg_cap != -1) {
+		retval +=
+		    dwc_otg_set_param_otg_cap(core_if,
+					      dwc_otg_module_params.otg_cap);
+	}
+	if (dwc_otg_module_params.dma_enable != -1) {
+		retval +=
+		    dwc_otg_set_param_dma_enable(core_if,
+						 dwc_otg_module_params.
+						 dma_enable);
+	}
+	if (dwc_otg_module_params.dma_desc_enable != -1) {
+		retval +=
+		    dwc_otg_set_param_dma_desc_enable(core_if,
+						      dwc_otg_module_params.
+						      dma_desc_enable);
+	}
+	if (dwc_otg_module_params.opt != -1) {
+		retval +=
+		    dwc_otg_set_param_opt(core_if, dwc_otg_module_params.opt);
+	}
+	if (dwc_otg_module_params.dma_burst_size != -1) {
+		retval +=
+		    dwc_otg_set_param_dma_burst_size(core_if,
+						     dwc_otg_module_params.
+						     dma_burst_size);
+	}
+	if (dwc_otg_module_params.host_support_fs_ls_low_power != -1) {
+		retval +=
+		    dwc_otg_set_param_host_support_fs_ls_low_power(core_if,
+								   dwc_otg_module_params.
+								   host_support_fs_ls_low_power);
+	}
+	if (dwc_otg_module_params.enable_dynamic_fifo != -1) {
+		retval +=
+		    dwc_otg_set_param_enable_dynamic_fifo(core_if,
+							  dwc_otg_module_params.
+							  enable_dynamic_fifo);
+	}
+	if (dwc_otg_module_params.data_fifo_size != -1) {
+		retval +=
+		    dwc_otg_set_param_data_fifo_size(core_if,
+						     dwc_otg_module_params.
+						     data_fifo_size);
+	}
+	if (dwc_otg_module_params.dev_rx_fifo_size != -1) {
+		retval +=
+		    dwc_otg_set_param_dev_rx_fifo_size(core_if,
+						       dwc_otg_module_params.
+						       dev_rx_fifo_size);
+	}
+	if (dwc_otg_module_params.dev_nperio_tx_fifo_size != -1) {
+		retval +=
+		    dwc_otg_set_param_dev_nperio_tx_fifo_size(core_if,
+							      dwc_otg_module_params.
+							      dev_nperio_tx_fifo_size);
+	}
+	if (dwc_otg_module_params.host_rx_fifo_size != -1) {
+		retval +=
+		    dwc_otg_set_param_host_rx_fifo_size(core_if,
+							dwc_otg_module_params.host_rx_fifo_size);
+	}
+	if (dwc_otg_module_params.host_nperio_tx_fifo_size != -1) {
+		retval +=
+		    dwc_otg_set_param_host_nperio_tx_fifo_size(core_if,
+							       dwc_otg_module_params.
+							       host_nperio_tx_fifo_size);
+	}
+	if (dwc_otg_module_params.host_perio_tx_fifo_size != -1) {
+		retval +=
+		    dwc_otg_set_param_host_perio_tx_fifo_size(core_if,
+							      dwc_otg_module_params.
+							      host_perio_tx_fifo_size);
+	}
+	if (dwc_otg_module_params.max_transfer_size != -1) {
+		retval +=
+		    dwc_otg_set_param_max_transfer_size(core_if,
+							dwc_otg_module_params.
+							max_transfer_size);
+	}
+	if (dwc_otg_module_params.max_packet_count != -1) {
+		retval +=
+		    dwc_otg_set_param_max_packet_count(core_if,
+						       dwc_otg_module_params.
+						       max_packet_count);
+	}
+	if (dwc_otg_module_params.host_channels != -1) {
+		retval +=
+		    dwc_otg_set_param_host_channels(core_if,
+						    dwc_otg_module_params.
+						    host_channels);
+	}
+	if (dwc_otg_module_params.dev_endpoints != -1) {
+		retval +=
+		    dwc_otg_set_param_dev_endpoints(core_if,
+						    dwc_otg_module_params.
+						    dev_endpoints);
+	}
+	if (dwc_otg_module_params.phy_type != -1) {
+		retval +=
+		    dwc_otg_set_param_phy_type(core_if,
+					       dwc_otg_module_params.phy_type);
+	}
+	if (dwc_otg_module_params.speed != -1) {
+		retval +=
+		    dwc_otg_set_param_speed(core_if,
+					    dwc_otg_module_params.speed);
+	}
+	if (dwc_otg_module_params.host_ls_low_power_phy_clk != -1) {
+		retval +=
+		    dwc_otg_set_param_host_ls_low_power_phy_clk(core_if,
+								dwc_otg_module_params.
+								host_ls_low_power_phy_clk);
+	}
+	if (dwc_otg_module_params.phy_ulpi_ddr != -1) {
+		retval +=
+		    dwc_otg_set_param_phy_ulpi_ddr(core_if,
+						   dwc_otg_module_params.
+						   phy_ulpi_ddr);
+	}
+	if (dwc_otg_module_params.phy_ulpi_ext_vbus != -1) {
+		retval +=
+		    dwc_otg_set_param_phy_ulpi_ext_vbus(core_if,
+							dwc_otg_module_params.
+							phy_ulpi_ext_vbus);
+	}
+	if (dwc_otg_module_params.phy_utmi_width != -1) {
+		retval +=
+		    dwc_otg_set_param_phy_utmi_width(core_if,
+						     dwc_otg_module_params.
+						     phy_utmi_width);
+	}
+	if (dwc_otg_module_params.ulpi_fs_ls != -1) {
+		retval +=
+		    dwc_otg_set_param_ulpi_fs_ls(core_if,
+						 dwc_otg_module_params.ulpi_fs_ls);
+	}
+	if (dwc_otg_module_params.ts_dline != -1) {
+		retval +=
+		    dwc_otg_set_param_ts_dline(core_if,
+					       dwc_otg_module_params.ts_dline);
+	}
+	if (dwc_otg_module_params.i2c_enable != -1) {
+		retval +=
+		    dwc_otg_set_param_i2c_enable(core_if,
+						 dwc_otg_module_params.
+						 i2c_enable);
+	}
+	if (dwc_otg_module_params.en_multiple_tx_fifo != -1) {
+		retval +=
+		    dwc_otg_set_param_en_multiple_tx_fifo(core_if,
+							  dwc_otg_module_params.
+							  en_multiple_tx_fifo);
+	}
+	for (i = 0; i < 15; i++) {
+		if (dwc_otg_module_params.dev_perio_tx_fifo_size[i] != -1) {
+			retval +=
+			    dwc_otg_set_param_dev_perio_tx_fifo_size(core_if,
+								     dwc_otg_module_params.
+								     dev_perio_tx_fifo_size
+								     [i], i);
+		}
+	}
+
+	for (i = 0; i < 15; i++) {
+		if (dwc_otg_module_params.dev_tx_fifo_size[i] != -1) {
+			retval += dwc_otg_set_param_dev_tx_fifo_size(core_if,
+								     dwc_otg_module_params.
+								     dev_tx_fifo_size
+								     [i], i);
+		}
+	}
+	if (dwc_otg_module_params.thr_ctl != -1) {
+		retval +=
+		    dwc_otg_set_param_thr_ctl(core_if,
+					      dwc_otg_module_params.thr_ctl);
+	}
+	if (dwc_otg_module_params.mpi_enable != -1) {
+		retval +=
+		    dwc_otg_set_param_mpi_enable(core_if,
+						 dwc_otg_module_params.
+						 mpi_enable);
+	}
+	if (dwc_otg_module_params.pti_enable != -1) {
+		retval +=
+		    dwc_otg_set_param_pti_enable(core_if,
+						 dwc_otg_module_params.
+						 pti_enable);
+	}
+	if (dwc_otg_module_params.lpm_enable != -1) {
+		retval +=
+		    dwc_otg_set_param_lpm_enable(core_if,
+						 dwc_otg_module_params.
+						 lpm_enable);
+	}
+	if (dwc_otg_module_params.besl_enable != -1) {
+		retval +=
+		    dwc_otg_set_param_besl_enable(core_if,
+						 dwc_otg_module_params.
+						 besl_enable);
+	}
+	if (dwc_otg_module_params.baseline_besl != -1) {
+		retval +=
+		    dwc_otg_set_param_baseline_besl(core_if,
+						 dwc_otg_module_params.
+						 baseline_besl);
+	}
+	if (dwc_otg_module_params.deep_besl != -1) {
+		retval +=
+		    dwc_otg_set_param_deep_besl(core_if,
+						 dwc_otg_module_params.
+						 deep_besl);
+	}
+	if (dwc_otg_module_params.ic_usb_cap != -1) {
+		retval +=
+		    dwc_otg_set_param_ic_usb_cap(core_if,
+						 dwc_otg_module_params.
+						 ic_usb_cap);
+	}
+	if (dwc_otg_module_params.tx_thr_length != -1) {
+		retval +=
+		    dwc_otg_set_param_tx_thr_length(core_if,
+						    dwc_otg_module_params.tx_thr_length);
+	}
+	if (dwc_otg_module_params.rx_thr_length != -1) {
+		retval +=
+		    dwc_otg_set_param_rx_thr_length(core_if,
+						    dwc_otg_module_params.
+						    rx_thr_length);
+	}
+	if (dwc_otg_module_params.ahb_thr_ratio != -1) {
+		retval +=
+		    dwc_otg_set_param_ahb_thr_ratio(core_if,
+						    dwc_otg_module_params.ahb_thr_ratio);
+	}
+	if (dwc_otg_module_params.power_down != -1) {
+		retval +=
+		    dwc_otg_set_param_power_down(core_if,
+						 dwc_otg_module_params.power_down);
+	}
+	if (dwc_otg_module_params.reload_ctl != -1) {
+		retval +=
+		    dwc_otg_set_param_reload_ctl(core_if,
+						 dwc_otg_module_params.reload_ctl);
+	}
+
+	if (dwc_otg_module_params.dev_out_nak != -1) {
+		retval +=
+			dwc_otg_set_param_dev_out_nak(core_if,
+			dwc_otg_module_params.dev_out_nak);
+	}
+
+	if (dwc_otg_module_params.cont_on_bna != -1) {
+		retval +=
+			dwc_otg_set_param_cont_on_bna(core_if,
+			dwc_otg_module_params.cont_on_bna);
+	}
+
+	if (dwc_otg_module_params.ahb_single != -1) {
+		retval +=
+			dwc_otg_set_param_ahb_single(core_if,
+			dwc_otg_module_params.ahb_single);
+	}
+
+	if (dwc_otg_module_params.otg_ver != -1) {
+		retval +=
+		    dwc_otg_set_param_otg_ver(core_if,
+					      dwc_otg_module_params.otg_ver);
+	}
+	if (dwc_otg_module_params.adp_enable != -1) {
+		retval +=
+		    dwc_otg_set_param_adp_enable(core_if,
+						 dwc_otg_module_params.
+						 adp_enable);
+	}
+	return retval;
+}
+/******************************************************************************/
+
+/**
+ * This function is the top level interrupt handler for the Common
+ * (Device and host modes) interrupts.
+ */
+static irqreturn_t dwc_otg_common_irq(int irq, void *dev)
+{
+	int32_t retval = IRQ_NONE;
+
+	retval = dwc_otg_handle_common_intr(dev);
+
+	return IRQ_RETVAL(retval);
+}
+/******************************************************************************/
+
+static int  hisi_udc_remove( struct platform_device *_dev)
+{
+
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(_dev);
+
+	DWC_DEBUGPL(DBG_ANY, "%s(%p)\n", __func__, _dev);
+
+	if (!otg_dev) {
+		/* Memory allocation for the dwc_otg_device failed. */
+		DWC_DEBUGPL(DBG_ANY, "%s: otg_dev NULL!\n", __func__);
+		return -1;
+	}
+
+	if (otg_dev->pcd) {
+		pcd_remove(_dev);
+	} else {
+		DWC_DEBUGPL(DBG_ANY, "%s: otg_dev->pcd NULL!\n", __func__);
+		return -1;
+	}
+
+	/*
+	 * Free the IRQ
+	 */
+	if (otg_dev->common_irq_installed) {
+		free_irq(_dev->resource[1].start, otg_dev);
+	} else {
+		DWC_DEBUGPL(DBG_ANY, "%s: There is no installed irq!\n", __func__);
+		return -1;
+	}
+
+	if (otg_dev->core_if) {
+		dwc_otg_cil_remove(otg_dev->core_if);
+	} else {
+		DWC_DEBUGPL(DBG_ANY, "%s: otg_dev->core_if NULL!\n", __func__);
+		return -1;
+	}
+
+	/*
+	 * Return the memory.
+	 */
+	if (otg_dev->os_dep.base) {
+		iounmap(otg_dev->os_dep.base);
+	}
+	DWC_FREE(otg_dev);
+
+	clk_disable_unprepare(otg_dev->clk);
+	/*
+	 * Clear the drvdata pointer.
+	 */
+	platform_set_drvdata(_dev, NULL);
+
+	return 0;
+
+}
+/******************************************************************************/
+
+static int hisi_udc_probe(struct platform_device *pdev)
+{
+	struct resource *res;
+	dwc_otg_device_t *dwc_otg_device;
+	int irq;
+	int ret;
+
+	irq = platform_get_irq(pdev, 0);
+	if (irq < 0) {
+		dev_err(&pdev->dev, "no irq provided");
+		return irq;
+	}
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(&pdev->dev, "no memory resource provided");
+		return -ENXIO;
+	}
+
+	dwc_otg_device = DWC_ALLOC(sizeof(dwc_otg_device_t));
+
+	if (!dwc_otg_device) {
+		dev_err(&pdev->dev, "kmalloc of dwc_otg_device failed\n");
+		return -ENOMEM;
+	}
+
+	memset(dwc_otg_device, 0, sizeof(*dwc_otg_device));
+	dwc_otg_device->os_dep.reg_offset = 0xFFFFFFFF;
+
+	/*
+	 * Map the DWC_otg Core memory into virtual address space.
+	 */
+	dwc_otg_device->os_dep.res_start = res->start;
+	dwc_otg_device->os_dep.base = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(dwc_otg_device->os_dep.base)) {
+		DWC_FREE(dwc_otg_device);
+		return -ENOMEM;
+	}
+
+	dev_dbg(&pdev->dev, "base=0x%08x\n",(unsigned)dwc_otg_device->os_dep.base);
+
+	/*
+	 * Initialize driver data to point to the global DWC_otg
+	 * Device structure.
+	 */
+	platform_set_drvdata(pdev, dwc_otg_device);
+
+
+	dwc_otg_device->core_if = dwc_otg_cil_init(dwc_otg_device->os_dep.base);
+	if (!dwc_otg_device->core_if) {
+		dev_err(&pdev->dev, "CIL initialization failed!\n");
+		ret = -ENOMEM;
+		goto fail;
+
+	}
+
+	/*
+	 * Attempt to ensure this device is really a DWC_otg Controller.
+	 * Read and verify the SNPSID register contents. The value should be
+	 * 0x45F42XXX or 0x45F42XXX, which corresponds to either "OT2" or "OTG3",
+	 * as in "OTG version 2.XX" or "OTG version 3.XX".
+	 */
+
+	if (((dwc_otg_get_gsnpsid(dwc_otg_device->core_if) & 0xFFFFF000) !=	0x4F542000) &&
+		((dwc_otg_get_gsnpsid(dwc_otg_device->core_if) & 0xFFFFF000) != 0x4F543000)) {
+		dev_err(&pdev->dev, "Bad value for SNPSID: 0x%08x\n",
+			dwc_otg_get_gsnpsid(dwc_otg_device->core_if));
+		ret = -EINVAL;
+		goto fail;
+	}
+
+	/*
+	 * Validate parameter values.
+	 */
+	if (set_parameters(dwc_otg_device->core_if)) {
+		ret = -EINVAL;
+		goto fail;
+	}
+
+
+	/*
+	 * Disable the global interrupt until all the interrupt
+	 * handlers are installed.
+	 */
+	dwc_otg_disable_global_interrupts(dwc_otg_device->core_if);
+
+
+	/*
+	 * Install the interrupt handler for the common interrupts before
+	 * enabling common interrupts in core_init below.
+	 */
+	DWC_DEBUGPL(DBG_CIL, "registering (common) handler for irq%d\n",
+		    pdev->resource[1].start);
+	ret = request_irq(irq, dwc_otg_common_irq,
+			     IRQF_SHARED | IRQ_LEVEL, "dwc_otg",
+			     dwc_otg_device);
+	if (ret) {
+		dev_err(&pdev->dev,"request of irq%d failed\n",irq);
+		ret = -EBUSY;
+		goto fail;
+	} else {
+		dwc_otg_device->common_irq_installed = 1;
+	}
+
+
+	/*
+	 * Initialize the DWC_otg core.
+	 */
+	dwc_otg_core_init(dwc_otg_device->core_if);
+
+	/*
+	 * Initialize the PCD
+	 */
+	ret = pcd_init(pdev, irq);
+	if (ret != 0) {
+		dev_err(&pdev->dev,"pcd_init failed\n");
+		dwc_otg_device->pcd = NULL;
+		goto fail;
+	}
+
+
+	/*
+	 * Enable the global interrupt after all the interrupt
+	 * handlers are installed if there is no ADP support else
+	 * perform initial actions required for Internal ADP logic.
+	 */
+	if (!dwc_otg_get_param_adp_enable(dwc_otg_device->core_if))
+		dwc_otg_enable_global_interrupts(dwc_otg_device->core_if);
+	else
+		dwc_otg_adp_start(dwc_otg_device->core_if,
+							dwc_otg_is_host_mode(dwc_otg_device->core_if));
+
+	return 0;
+
+fail:
+	hisi_udc_remove(pdev);
+	return ret;
+}
+/******************************************************************************/
+
+#ifdef CONFIG_PM
+static int hisi_udc_suspend(struct device *dev)
+{
+	dwc_otg_device_t *dwc_otg_device = dev_get_drvdata(dev);
+	int rc = 0;
+
+	dwc_otg_disable_global_interrupts(dwc_otg_device->core_if);
+	clk_disable_unprepare(dwc_otg_device->clk);
+
+	return rc;
+}
+/******************************************************************************/
+
+static int hisi_udc_resume(struct device *dev)
+{
+	dwc_otg_device_t *dwc_otg_device = dev_get_drvdata(dev);
+
+	clk_prepare_enable(dwc_otg_device->clk);
+	dwc_otg_core_init(dwc_otg_device->core_if);
+	dwc_otg_enable_global_interrupts(dwc_otg_device->core_if);
+	return 0;
+}
+#else
+#define hisi_udc_suspend NULL;
+#define hisi_udc_resume NULL;
+#endif
+/******************************************************************************/
+
+static const struct dev_pm_ops hisi_udc_pmops = {
+	.suspend = hisi_udc_suspend,
+	.resume  = hisi_udc_resume,
+#if defined(CONFIG_PM_HIBERNATE) || defined(CONFIG_HISI_SNAPSHOT_BOOT)
+	.freeze = hisi_udc_suspend,
+	.thaw = hisi_udc_resume,
+	.poweroff = hisi_udc_suspend,
+	.restore = hisi_udc_resume,
+#endif
+};
+
+static const struct of_device_id hisi_udc_ids[] = {
+	{ .compatible = "hiudc", },
+	{ /* null */ }
+};
+MODULE_DEVICE_TABLE(of, hisi_udc_ids);
+
+static struct platform_driver  hisi_udc_pltfrm_driver = {
+	.probe = hisi_udc_probe,
+	.remove = hisi_udc_remove,
+	.driver = {
+		.name  = (char *)driver_name,
+		.owner = THIS_MODULE,
+		.of_match_table = hisi_udc_ids,
+		.pm    = &hisi_udc_pmops,
+	},
+};
+/******************************************************************************/
+
+static int __init hisi_udc_module_init(void)
+{
+	int ret;
+
+	printk(KERN_INFO "%s: version %s\n", driver_name,
+	       DWC_DRIVER_VERSION);
+
+	ret = platform_driver_register(&hisi_udc_pltfrm_driver);
+
+	return ret;
+}
+module_init(hisi_udc_module_init);
+/******************************************************************************/
+
+static void __exit hisi_udc_module_exit (void)
+{
+
+	platform_driver_unregister(&hisi_udc_pltfrm_driver);
+
+	printk(KERN_INFO "%s module removed\n", driver_name);
+}
+module_exit(hisi_udc_module_exit);
+
+MODULE_AUTHOR("Hisilicon");
+MODULE_DESCRIPTION("Hisilcon USB Device Controller driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_driver.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_driver.h
new file mode 100644
index 0000000..63df919
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_driver.h
@@ -0,0 +1,89 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_driver.h $
+ * $Revision: #19 $
+ * $Date: 2010/11/15 $
+ * $Change: 1627671 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#ifndef __DWC_OTG_DRIVER_H__
+#define __DWC_OTG_DRIVER_H__
+
+/** @file
+ * This file contains the interface to the Linux driver.
+ */
+#include "dwc_otg_os_dep.h"
+#include "dwc_otg_core_if.h"
+#include <linux/platform_device.h>
+
+/* Type declarations */
+struct dwc_otg_pcd;
+struct dwc_otg_hcd;
+
+/**
+ * This structure is a wrapper that encapsulates the driver components used to
+ * manage a single DWC_otg controller.
+ */
+typedef struct dwc_otg_device {
+	/** Structure containing OS-dependent stuff. KEEP THIS STRUCT AT THE
+	 * VERY BEGINNING OF THE DEVICE STRUCT. OSes such as FreeBSD and NetBSD
+	 * require this. */
+	struct os_dependent os_dep;
+
+	/** Pointer to the core interface structure. */
+	dwc_otg_core_if_t *core_if;
+
+	/** Pointer to the PCD structure. */
+	struct dwc_otg_pcd *pcd;
+
+	/** Pointer to the HCD structure. */
+	struct dwc_otg_hcd *hcd;
+
+	struct clk *clk;
+
+	/** Flag to indicate whether the common IRQ handler is installed. */
+	uint8_t common_irq_installed;
+
+} dwc_otg_device_t;
+
+/*We must clear S3C24XX_EINTPEND external interrupt register
+ * because after clearing in this register trigerred IRQ from
+ * H/W core in kernel interrupt can be occured again before OTG
+ * handlers clear all IRQ sources of Core registers because of
+ * timing latencies and Low Level IRQ Type.
+ */
+#ifdef CONFIG_MACH_IPMATE
+#define  S3C2410X_CLEAR_EINTPEND()   \
+do { \
+	__raw_writel(1UL << 11,S3C24XX_EINTPEND); \
+} while (0)
+#else
+#define  S3C2410X_CLEAR_EINTPEND()   do { } while (0)
+#endif
+
+#endif
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd.c
new file mode 100644
index 0000000..3402e12
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd.c
@@ -0,0 +1,3331 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_hcd.c $
+ * $Revision: #110 $
+ * $Date: 2013/05/19 $
+ * $Change: 2234022 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef DWC_DEVICE_ONLY
+
+/** @file
+ * This file implements HCD Core. All code in this file is portable and doesn't
+ * use any OS specific functions.
+ * Interface provided by HCD Core is defined in <code><hcd_if.h></code>
+ * header file.
+ */
+
+#include "dwc_otg_hcd.h"
+#include "dwc_otg_regs.h"
+
+dwc_otg_hcd_t *dwc_otg_hcd_alloc_hcd(void)
+{
+	return DWC_ALLOC(sizeof(dwc_otg_hcd_t));
+}
+
+/**
+ * Connection timeout function.  An OTG host is required to display a
+ * message if the device does not connect within 10 seconds.
+ */
+void dwc_otg_hcd_connect_timeout(void *ptr)
+{
+	dwc_otg_hcd_t *hcd;
+	gpwrdn_data_t gpwrdn;
+	DWC_DEBUGPL(DBG_HCDV, "%s(%p)\n", __func__, ptr);
+	DWC_PRINTF("Connect Timeout\n");
+	__DWC_ERROR("Device Not Connected/Responding\n");
+	/** Remove buspower after 10s */
+	hcd = ptr;
+	if (hcd->core_if->otg_ver)
+		dwc_otg_set_prtpower(hcd->core_if, 0);
+	if (hcd->core_if->adp_enable && !hcd->core_if->adp.probe_enabled) {
+		cil_hcd_disconnect(hcd->core_if);
+		gpwrdn.d32 = 0;
+		/* Enable Power Down Logic */
+		gpwrdn.b.pmuintsel = 1;
+		gpwrdn.b.pmuactv = 1;
+		gpwrdn.b.dis_vbus = 1;
+		DWC_MODIFY_REG32(&hcd->core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+
+		/* Unmask SRP detected interrupt from Power Down Logic */
+		gpwrdn.d32 = 0;
+		gpwrdn.b.srp_det_msk = 1;
+		DWC_MODIFY_REG32(&hcd->core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+
+		dwc_mdelay(220);
+		dwc_otg_adp_probe_start(hcd->core_if);
+	}
+}
+
+#ifdef DEBUG
+static void dump_channel_info(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	if (qh->channel != NULL) {
+		dwc_hc_t *hc = qh->channel;
+		dwc_list_link_t *item;
+		dwc_otg_qh_t *qh_item;
+		int num_channels = hcd->core_if->core_params->host_channels;
+		int i;
+
+		dwc_otg_hc_regs_t *hc_regs;
+		hcchar_data_t hcchar;
+		hcsplt_data_t hcsplt;
+		hctsiz_data_t hctsiz;
+		uint32_t hcdma;
+
+		hc_regs = hcd->core_if->host_if->hc_regs[hc->hc_num];
+		hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+		hcsplt.d32 = DWC_READ_REG32(&hc_regs->hcsplt);
+		hctsiz.d32 = DWC_READ_REG32(&hc_regs->hctsiz);
+		hcdma = DWC_READ_REG32(&hc_regs->hcdma);
+
+		DWC_PRINTF("  Assigned to channel %p:\n", hc);
+		DWC_PRINTF("    hcchar 0x%08x, hcsplt 0x%08x\n", hcchar.d32,
+			   hcsplt.d32);
+		DWC_PRINTF("    hctsiz 0x%08x, hcdma 0x%08x\n", hctsiz.d32,
+			   hcdma);
+		DWC_PRINTF("    dev_addr: %d, ep_num: %d, ep_is_in: %d\n",
+			   hc->dev_addr, hc->ep_num, hc->ep_is_in);
+		DWC_PRINTF("    ep_type: %d\n", hc->ep_type);
+		DWC_PRINTF("    max_packet: %d\n", hc->max_packet);
+		DWC_PRINTF("    data_pid_start: %d\n", hc->data_pid_start);
+		DWC_PRINTF("    xfer_started: %d\n", hc->xfer_started);
+		DWC_PRINTF("    halt_status: %d\n", hc->halt_status);
+		DWC_PRINTF("    xfer_buff: %p\n", hc->xfer_buff);
+		DWC_PRINTF("    xfer_len: %d\n", hc->xfer_len);
+		DWC_PRINTF("    qh: %p\n", hc->qh);
+		DWC_PRINTF("  NP inactive sched:\n");
+		DWC_LIST_FOREACH(item, &hcd->non_periodic_sched_inactive) {
+			qh_item =
+			    DWC_LIST_ENTRY(item, dwc_otg_qh_t, qh_list_entry);
+			DWC_PRINTF("    %p\n", qh_item);
+		}
+		DWC_PRINTF("  NP active sched:\n");
+		DWC_LIST_FOREACH(item, &hcd->non_periodic_sched_active) {
+			qh_item =
+			    DWC_LIST_ENTRY(item, dwc_otg_qh_t, qh_list_entry);
+			DWC_PRINTF("    %p\n", qh_item);
+		}
+		DWC_PRINTF("  Channels: \n");
+		for (i = 0; i < num_channels; i++) {
+			dwc_hc_t *hc = hcd->hc_ptr_array[i];
+			DWC_PRINTF("    %2d: %p\n", i, hc);
+		}
+	}
+}
+#endif /* DEBUG */
+
+/**
+ * Work queue function for starting the HCD when A-Cable is connected.
+ * The hcd_start() must be called in a process context.
+ */
+static void hcd_start_func(void *_vp)
+{
+	dwc_otg_hcd_t *hcd = (dwc_otg_hcd_t *) _vp;
+
+	DWC_DEBUGPL(DBG_HCDV, "%s() %p\n", __func__, hcd);
+	if (hcd) {
+		hcd->fops->start(hcd);
+	}
+}
+
+static void del_xfer_timers(dwc_otg_hcd_t * hcd)
+{
+#ifdef DEBUG
+	int i;
+	int num_channels = hcd->core_if->core_params->host_channels;
+	for (i = 0; i < num_channels; i++) {
+		DWC_TIMER_CANCEL(hcd->core_if->hc_xfer_timer[i]);
+	}
+#endif
+}
+
+static void del_timers(dwc_otg_hcd_t * hcd)
+{
+	del_xfer_timers(hcd);
+	DWC_TIMER_CANCEL(hcd->conn_timer);
+}
+
+/**
+ * Processes all the URBs in a single list of QHs. Completes them with
+ * -ETIMEDOUT and frees the QTD.
+ */
+static void kill_urbs_in_qh_list(dwc_otg_hcd_t * hcd, dwc_list_link_t * qh_list)
+{
+	dwc_list_link_t *qh_item;
+	dwc_otg_qh_t *qh;
+	dwc_otg_qtd_t *qtd, *qtd_tmp;
+
+	DWC_LIST_FOREACH(qh_item, qh_list) {
+		qh = DWC_LIST_ENTRY(qh_item, dwc_otg_qh_t, qh_list_entry);
+		DWC_CIRCLEQ_FOREACH_SAFE(qtd, qtd_tmp,
+					 &qh->qtd_list, qtd_list_entry) {
+			qtd = DWC_CIRCLEQ_FIRST(&qh->qtd_list);
+			if (qtd->urb != NULL) {
+				if(!qtd->urb->priv) {
+					DWC_ERROR("urb->priv is NULL !!!!\n");
+					return;
+				}
+				if(!hcd->fops)
+					DWC_ERROR("hcd->fops is NULL !!!!!\n");
+				if(!hcd->fops->complete)
+					DWC_ERROR("fops->complete is NULL !!!!\n");
+				hcd->fops->complete(hcd, qtd->urb->priv,
+						    qtd->urb, -DWC_E_TIMEOUT);
+				dwc_otg_hcd_qtd_remove_and_free(hcd, qtd, qh);
+			}
+
+		}
+	}
+}
+
+/**
+ * Responds with an error status of ETIMEDOUT to all URBs in the non-periodic
+ * and periodic schedules. The QTD associated with each URB is removed from
+ * the schedule and freed. This function may be called when a disconnect is
+ * detected or when the HCD is being stopped.
+ */
+static void kill_all_urbs(dwc_otg_hcd_t * hcd)
+{
+	kill_urbs_in_qh_list(hcd, &hcd->non_periodic_sched_inactive);
+	kill_urbs_in_qh_list(hcd, &hcd->non_periodic_sched_active);
+	kill_urbs_in_qh_list(hcd, &hcd->periodic_sched_inactive);
+	kill_urbs_in_qh_list(hcd, &hcd->periodic_sched_ready);
+	kill_urbs_in_qh_list(hcd, &hcd->periodic_sched_assigned);
+	kill_urbs_in_qh_list(hcd, &hcd->periodic_sched_queued);
+}
+
+/**
+ * Start the connection timer.  An OTG host is required to display a
+ * message if the device does not connect within 10 seconds.  The
+ * timer is deleted if a port connect interrupt occurs before the
+ * timer expires.
+ */
+static void dwc_otg_hcd_start_connect_timer(dwc_otg_hcd_t * hcd)
+{
+	DWC_TIMER_SCHEDULE(hcd->conn_timer, 10000 /* 10 secs */ );
+}
+
+/**
+ * HCD Callback function for disconnect of the HCD.
+ *
+ * @param p void pointer to the <code>struct usb_hcd</code>
+ */
+static int32_t dwc_otg_hcd_session_start_cb(void *p)
+{
+	dwc_otg_hcd_t *dwc_otg_hcd;
+	DWC_DEBUGPL(DBG_HCDV, "%s(%p)\n", __func__, p);
+	dwc_otg_hcd = p;
+	dwc_otg_hcd_start_connect_timer(dwc_otg_hcd);
+	return 1;
+}
+
+/**
+ * HCD Callback function for starting the HCD when A-Cable is
+ * connected.
+ *
+ * @param p void pointer to the <code>struct usb_hcd</code>
+ */
+static int32_t dwc_otg_hcd_start_cb(void *p)
+{
+	dwc_otg_hcd_t *dwc_otg_hcd = p;
+	dwc_otg_core_if_t *core_if;
+	hprt0_data_t hprt0;
+	uint32_t timeout = 50;
+
+	core_if = dwc_otg_hcd->core_if;
+	/**@todo vahrama: Check the timeout value for OTG 2.0 */
+	if (core_if->otg_ver)
+		timeout = 25;
+	if (core_if->op_state == B_HOST) {
+		/*
+		 * Reset the port.  During a HNP mode switch the reset
+		 * needs to occur within 1ms and have a duration of at
+		 * least 50ms.
+		 */
+		hprt0.d32 = dwc_otg_read_hprt0(core_if);
+		hprt0.b.prtrst = 1;
+		DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+		if (core_if->otg_ver) {
+			dwc_mdelay(60);
+			hprt0.d32 = dwc_otg_read_hprt0(core_if);
+			hprt0.b.prtrst = 0;
+			DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+		}
+	}
+	DWC_WORKQ_SCHEDULE_DELAYED(core_if->wq_otg,
+				hcd_start_func, dwc_otg_hcd, timeout,
+				"start hcd");
+
+	return 1;
+}
+
+/**
+ * HCD Callback function for disconnect of the HCD.
+ *
+ * @param p void pointer to the <code>struct usb_hcd</code>
+ */
+static int32_t dwc_otg_hcd_disconnect_cb(void *p)
+{
+	gintsts_data_t intr;
+	dwc_otg_hcd_t *dwc_otg_hcd = p;
+
+	/*
+	 * Set status flags for the hub driver.
+	 */
+	dwc_otg_hcd->flags.b.port_connect_status_change = 1;
+	dwc_otg_hcd->flags.b.port_connect_status = 0;
+
+	/*
+	 * Shutdown any transfers in process by clearing the Tx FIFO Empty
+	 * interrupt mask and status bits and disabling subsequent host
+	 * channel interrupts.
+	 */
+	intr.d32 = 0;
+	intr.b.nptxfempty = 1;
+	intr.b.ptxfempty = 1;
+	intr.b.hcintr = 1;
+	DWC_MODIFY_REG32(&dwc_otg_hcd->core_if->core_global_regs->gintmsk,
+			 intr.d32, 0);
+	DWC_MODIFY_REG32(&dwc_otg_hcd->core_if->core_global_regs->gintsts,
+			 intr.d32, 0);
+
+	/*
+	 * Turn off the vbus power only if the core has transitioned to device
+	 * mode. If still in host mode, need to keep power on to detect a
+	 * reconnection.
+	 */
+	if (dwc_otg_is_device_mode(dwc_otg_hcd->core_if)) {
+		if (dwc_otg_hcd->core_if->op_state != A_SUSPEND) {
+			hprt0_data_t hprt0 = {.d32 = 0 };
+			DWC_PRINTF("Disconnect: PortPower off\n");
+			hprt0.b.prtpwr = 0;
+			DWC_WRITE_REG32(dwc_otg_hcd->core_if->host_if->hprt0,
+					hprt0.d32);
+		}
+		/** Delete timers if become device */
+		del_timers(dwc_otg_hcd);
+		dwc_otg_disable_host_interrupts(dwc_otg_hcd->core_if);
+	}
+
+	/* Respond with an error status to all URBs in the schedule. */
+	kill_all_urbs(dwc_otg_hcd);
+
+	if (dwc_otg_is_host_mode(dwc_otg_hcd->core_if)) {
+		/* Clean up any host channels that were in use. */
+		int num_channels;
+		int i;
+		dwc_hc_t *channel;
+		dwc_otg_hc_regs_t *hc_regs;
+		hcchar_data_t hcchar;
+
+		if (dwc_otg_hcd->core_if->otg_ver == 1)
+			del_xfer_timers(dwc_otg_hcd);
+		else
+			del_timers(dwc_otg_hcd);
+
+		num_channels = dwc_otg_hcd->core_if->core_params->host_channels;
+
+		if (!dwc_otg_hcd->core_if->dma_enable) {
+			/* Flush out any channel requests in slave mode. */
+			for (i = 0; i < num_channels; i++) {
+				channel = dwc_otg_hcd->hc_ptr_array[i];
+				if (DWC_CIRCLEQ_EMPTY_ENTRY
+				    (channel, hc_list_entry)) {
+					hc_regs =
+					    dwc_otg_hcd->core_if->
+					    host_if->hc_regs[i];
+					hcchar.d32 =
+					    DWC_READ_REG32(&hc_regs->hcchar);
+					if (hcchar.b.chen) {
+						hcchar.b.chen = 0;
+						hcchar.b.chdis = 1;
+						hcchar.b.epdir = 0;
+						DWC_WRITE_REG32
+						    (&hc_regs->hcchar,
+						     hcchar.d32);
+					}
+				}
+			}
+		}
+
+		for (i = 0; i < num_channels; i++) {
+			channel = dwc_otg_hcd->hc_ptr_array[i];
+			if (DWC_CIRCLEQ_EMPTY_ENTRY(channel, hc_list_entry)) {
+				hc_regs =
+				    dwc_otg_hcd->core_if->host_if->hc_regs[i];
+				hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+				if (hcchar.b.chen) {
+					/* Halt the channel. */
+					hcchar.b.chdis = 1;
+					DWC_WRITE_REG32(&hc_regs->hcchar,
+							hcchar.d32);
+				}
+
+				dwc_otg_hc_cleanup(dwc_otg_hcd->core_if,
+						   channel);
+				DWC_CIRCLEQ_INSERT_TAIL
+				    (&dwc_otg_hcd->free_hc_list, channel,
+				     hc_list_entry);
+				/*
+				 * Added for Descriptor DMA to prevent channel double cleanup
+				 * in release_channel_ddma(). Which called from ep_disable
+				 * when device disconnect.
+				 */
+				channel->qh = NULL;
+			}
+		}
+	}
+
+	if (dwc_otg_hcd->fops->disconnect) {
+		dwc_otg_hcd->fops->disconnect(dwc_otg_hcd);
+	}
+
+	return 1;
+}
+
+/**
+ * HCD Callback function for stopping the HCD.
+ *
+ * @param p void pointer to the <code>struct usb_hcd</code>
+ */
+static int32_t dwc_otg_hcd_stop_cb(void *p)
+{
+	dwc_otg_hcd_t *dwc_otg_hcd = p;
+
+	DWC_DEBUGPL(DBG_HCDV, "%s(%p)\n", __func__, p);
+	dwc_otg_hcd_stop(dwc_otg_hcd);
+	return 1;
+}
+
+#ifdef CONFIG_USB_DWC_OTG_LPM
+/**
+ * HCD Callback function for sleep of HCD.
+ *
+ * @param p void pointer to the <code>struct usb_hcd</code>
+ */
+static int dwc_otg_hcd_sleep_cb(void *p)
+{
+	dwc_otg_hcd_t *hcd = p;
+
+	dwc_otg_hcd_free_hc_from_lpm(hcd);
+
+	return 0;
+}
+#endif
+
+/**
+ * HCD Callback function for Remote Wakeup.
+ *
+ * @param p void pointer to the <code>struct usb_hcd</code>
+ */
+static int dwc_otg_hcd_rem_wakeup_cb(void *p)
+{
+	dwc_otg_hcd_t *hcd = p;
+
+	if (hcd->core_if->lx_state == DWC_OTG_L2) {
+		hcd->flags.b.port_suspend_change = 1;
+	}
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	else {
+		hcd->flags.b.port_l1_change = 1;
+	}
+#endif
+	return 0;
+}
+
+/**
+ * Halts the DWC_otg host mode operations in a clean manner. USB transfers are
+ * stopped.
+ */
+void dwc_otg_hcd_stop(dwc_otg_hcd_t * hcd)
+{
+	hprt0_data_t hprt0 = {.d32 = 0 };
+
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD STOP\n");
+
+	/*
+	 * The root hub should be disconnected before this function is called.
+	 * The disconnect will clear the QTD lists (via ..._hcd_urb_dequeue)
+	 * and the QH lists (via ..._hcd_endpoint_disable).
+	 */
+
+	/* Turn off all host-specific interrupts. */
+	dwc_otg_disable_host_interrupts(hcd->core_if);
+
+	/* Turn off the vbus power */
+	DWC_PRINTF("PortPower off\n");
+	hprt0.b.prtpwr = 0;
+	DWC_WRITE_REG32(hcd->core_if->host_if->hprt0, hprt0.d32);
+	dwc_mdelay(1);
+}
+
+int dwc_otg_hcd_urb_enqueue(dwc_otg_hcd_t * hcd,
+			    dwc_otg_hcd_urb_t * dwc_otg_urb, void **ep_handle,
+			    int atomic_alloc)
+{
+	dwc_irqflags_t flags;
+	int retval = 0;
+	dwc_otg_qtd_t *qtd;
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+
+	if (!hcd->flags.b.port_connect_status) {
+		/* No longer connected. */
+		DWC_ERROR("Not connected\n");
+		return -DWC_E_NO_DEVICE;
+	}
+
+	qtd = dwc_otg_hcd_qtd_create(dwc_otg_urb, atomic_alloc);
+	if (qtd == NULL) {
+		DWC_ERROR("DWC OTG HCD URB Enqueue failed creating QTD\n");
+		return -DWC_E_NO_MEMORY;
+	}
+
+	retval =
+	    dwc_otg_hcd_qtd_add(qtd, hcd, (dwc_otg_qh_t **) ep_handle, atomic_alloc);
+	if (retval < 0) {
+		DWC_ERROR("DWC OTG HCD URB Enqueue failed adding QTD. "
+			  "Error status %d\n", retval);
+		dwc_otg_hcd_qtd_free(qtd);
+	} else {
+		qtd->qh = *ep_handle;
+	}
+	intr_mask.d32 = DWC_READ_REG32(&hcd->core_if->core_global_regs->gintmsk);
+	if (!intr_mask.b.sofintr && retval == 0) {
+		dwc_otg_transaction_type_e tr_type;
+		if ((qtd->qh->ep_type == UE_BULK)
+		    && !(qtd->urb->flags & URB_GIVEBACK_ASAP)) {
+			/* Do not schedule SG transactions until qtd has URB_GIVEBACK_ASAP set */
+			return 0;
+		}
+		DWC_SPINLOCK_IRQSAVE(hcd->lock, &flags);
+		tr_type = dwc_otg_hcd_select_transactions(hcd);
+		if (tr_type != DWC_OTG_TRANSACTION_NONE) {
+			dwc_otg_hcd_queue_transactions(hcd, tr_type);
+		}
+		DWC_SPINUNLOCK_IRQRESTORE(hcd->lock, flags);
+	}
+
+	return retval;
+}
+
+int dwc_otg_hcd_urb_dequeue(dwc_otg_hcd_t * hcd,
+			    dwc_otg_hcd_urb_t * dwc_otg_urb)
+{
+	dwc_otg_qh_t *qh;
+	dwc_otg_qtd_t *urb_qtd;
+
+	urb_qtd = dwc_otg_urb->qtd;
+	qh = urb_qtd->qh;
+#ifdef DEBUG
+	if (CHK_DEBUG_LEVEL(DBG_HCDV | DBG_HCD_URB)) {
+		if (urb_qtd->in_process) {
+			dump_channel_info(hcd, qh);
+		}
+	}
+#endif
+	if (urb_qtd->in_process && qh->channel) {
+		/* The QTD is in process (it has been assigned to a channel). */
+		if (hcd->flags.b.port_connect_status) {
+			/*
+			 * If still connected (i.e. in host mode), halt the
+			 * channel so it can be used for other transfers. If
+			 * no longer connected, the host registers can't be
+			 * written to halt the channel since the core is in
+			 * device mode.
+			 */
+			dwc_otg_hc_halt(hcd->core_if, qh->channel,
+					DWC_OTG_HC_XFER_URB_DEQUEUE);
+		}
+	}
+
+	/*
+	 * Free the QTD and clean up the associated QH. Leave the QH in the
+	 * schedule if it has any remaining QTDs.
+	 */
+
+	if (!hcd->core_if->dma_desc_enable) {
+		uint8_t b = urb_qtd->in_process;
+		dwc_otg_hcd_qtd_remove_and_free(hcd, urb_qtd, qh);
+		if (b) {
+			dwc_otg_hcd_qh_deactivate(hcd, qh, 0);
+			qh->channel = NULL;
+		} else if (DWC_CIRCLEQ_EMPTY(&qh->qtd_list)) {
+			dwc_otg_hcd_qh_remove(hcd, qh);
+		}
+	} else {
+		dwc_otg_hcd_qtd_remove_and_free(hcd, urb_qtd, qh);
+	}
+	return 0;
+}
+
+int dwc_otg_hcd_endpoint_disable(dwc_otg_hcd_t * hcd, void *ep_handle,
+				 int retry)
+{
+	dwc_otg_qh_t *qh = (dwc_otg_qh_t *) ep_handle;
+	int retval = 0;
+	dwc_irqflags_t flags;
+
+	if (retry < 0) {
+		retval = -DWC_E_INVALID;
+		goto done;
+	}
+
+	if (!qh) {
+		retval = -DWC_E_INVALID;
+		goto done;
+	}
+
+	DWC_SPINLOCK_IRQSAVE(hcd->lock, &flags);
+
+	while (!DWC_CIRCLEQ_EMPTY(&qh->qtd_list) && retry) {
+		DWC_SPINUNLOCK_IRQRESTORE(hcd->lock, flags);
+		retry--;
+		dwc_msleep(5);
+		DWC_SPINLOCK_IRQSAVE(hcd->lock, &flags);
+	}
+
+	dwc_otg_hcd_qh_remove(hcd, qh);
+
+	DWC_SPINUNLOCK_IRQRESTORE(hcd->lock, flags);
+	/*
+	 * Split dwc_otg_hcd_qh_remove_and_free() into qh_remove
+	 * and qh_free to prevent stack dump on DWC_DMA_FREE() with
+	 * irq_disabled (spinlock_irqsave) in dwc_otg_hcd_desc_list_free()
+	 * and dwc_otg_hcd_frame_list_alloc().
+	 */
+	dwc_otg_hcd_qh_free(hcd, qh);
+
+done:
+	return retval;
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,30)
+int dwc_otg_hcd_endpoint_reset(dwc_otg_hcd_t * hcd, void *ep_handle)
+{
+	int retval = 0;
+	dwc_otg_qh_t *qh = (dwc_otg_qh_t *) ep_handle;
+	if (!qh)
+		return -DWC_E_INVALID;
+
+	qh->data_toggle = DWC_OTG_HC_PID_DATA0;
+	return retval;
+}
+#endif
+
+/**
+ * HCD Callback structure for handling mode switching.
+ */
+static dwc_otg_cil_callbacks_t hcd_cil_callbacks = {
+	.start = dwc_otg_hcd_start_cb,
+	.stop = dwc_otg_hcd_stop_cb,
+	.disconnect = dwc_otg_hcd_disconnect_cb,
+	.session_start = dwc_otg_hcd_session_start_cb,
+	.resume_wakeup = dwc_otg_hcd_rem_wakeup_cb,
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	.sleep = dwc_otg_hcd_sleep_cb,
+#endif
+	.p = 0,
+};
+
+/**
+ * Reset tasklet function
+ */
+static void reset_tasklet_func(void *data)
+{
+	dwc_otg_hcd_t *dwc_otg_hcd = (dwc_otg_hcd_t *) data;
+	dwc_otg_core_if_t *core_if = dwc_otg_hcd->core_if;
+	hprt0_data_t hprt0;
+
+	DWC_DEBUGPL(DBG_HCDV, "USB RESET tasklet called\n");
+
+	hprt0.d32 = dwc_otg_read_hprt0(core_if);
+	hprt0.b.prtrst = 1;
+	DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+	dwc_mdelay(60);
+
+	hprt0.b.prtrst = 0;
+	DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+	dwc_otg_hcd->flags.b.port_reset_change = 1;
+}
+
+static void qh_list_free(dwc_otg_hcd_t * hcd, dwc_list_link_t * qh_list)
+{
+	dwc_list_link_t *item;
+	dwc_otg_qh_t *qh;
+	dwc_irqflags_t flags;
+
+	if (!qh_list->next) {
+		/* The list hasn't been initialized yet. */
+		return;
+	}
+	/*
+	 * Hold spinlock here. Not needed in that case if bellow
+	 * function is being called from ISR
+	 */
+	DWC_SPINLOCK_IRQSAVE(hcd->lock, &flags);
+	/* Ensure there are no QTDs or URBs left. */
+	kill_urbs_in_qh_list(hcd, qh_list);
+	DWC_SPINUNLOCK_IRQRESTORE(hcd->lock, flags);
+
+	DWC_LIST_FOREACH(item, qh_list) {
+		qh = DWC_LIST_ENTRY(item, dwc_otg_qh_t, qh_list_entry);
+		dwc_otg_hcd_qh_remove_and_free(hcd, qh);
+	}
+}
+
+/**
+ * Exit from Hibernation if Host did not detect SRP from connected SRP capable
+ * Device during SRP time by host power up.
+ */
+void dwc_otg_hcd_power_up(void *ptr)
+{
+	gpwrdn_data_t gpwrdn = {.d32 = 0 };
+	dwc_otg_core_if_t *core_if = (dwc_otg_core_if_t *) ptr;
+
+	DWC_PRINTF("%s called\n", __FUNCTION__);
+
+	if (!core_if->hibernation_suspend) {
+		DWC_PRINTF("Already exited from Hibernation\n");
+		return;
+	}
+
+	/* Switch on the voltage to the core */
+	gpwrdn.b.pwrdnswtch = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	/* Reset the core */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pwrdnrstn = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	/* Disable power clamps */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pwrdnclmp = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+	/* Remove reset the core signal */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pwrdnrstn = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, 0, gpwrdn.d32);
+	dwc_udelay(10);
+
+	/* Disable PMU interrupt */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pmuintsel = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+	core_if->hibernation_suspend = 0;
+
+	/* Disable PMU */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.pmuactv = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+	dwc_udelay(10);
+
+	/* Enable VBUS */
+	gpwrdn.d32 = 0;
+	gpwrdn.b.dis_vbus = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gpwrdn, gpwrdn.d32, 0);
+
+	core_if->op_state = A_HOST;
+	dwc_otg_core_init(core_if);
+	dwc_otg_enable_global_interrupts(core_if);
+	cil_hcd_start(core_if);
+}
+
+/**
+ * Frees secondary storage associated with the dwc_otg_hcd structure contained
+ * in the struct usb_hcd field.
+ */
+static void dwc_otg_hcd_free(dwc_otg_hcd_t * dwc_otg_hcd)
+{
+	int i;
+
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD FREE\n");
+
+	del_timers(dwc_otg_hcd);
+
+	/* Free memory for QH/QTD lists */
+	qh_list_free(dwc_otg_hcd, &dwc_otg_hcd->non_periodic_sched_inactive);
+	qh_list_free(dwc_otg_hcd, &dwc_otg_hcd->non_periodic_sched_active);
+	qh_list_free(dwc_otg_hcd, &dwc_otg_hcd->periodic_sched_inactive);
+	qh_list_free(dwc_otg_hcd, &dwc_otg_hcd->periodic_sched_ready);
+	qh_list_free(dwc_otg_hcd, &dwc_otg_hcd->periodic_sched_assigned);
+	qh_list_free(dwc_otg_hcd, &dwc_otg_hcd->periodic_sched_queued);
+
+	/* Free memory for the host channels. */
+	for (i = 0; i < MAX_EPS_CHANNELS; i++) {
+		dwc_hc_t *hc = dwc_otg_hcd->hc_ptr_array[i];
+
+#ifdef DEBUG
+		if (dwc_otg_hcd->core_if->hc_xfer_timer[i]) {
+			DWC_TIMER_FREE(dwc_otg_hcd->core_if->hc_xfer_timer[i]);
+		}
+#endif
+		if (hc != NULL) {
+			DWC_DEBUGPL(DBG_HCDV, "HCD Free channel #%i, hc=%p\n",
+				    i, hc);
+			DWC_FREE(hc);
+		}
+	}
+
+	if (dwc_otg_hcd->core_if->dma_enable) {
+		if (dwc_otg_hcd->status_buf_dma) {
+			DWC_DMA_FREE(DWC_OTG_HCD_STATUS_BUF_SIZE,
+				     dwc_otg_hcd->status_buf,
+				     dwc_otg_hcd->status_buf_dma);
+		}
+	} else if (dwc_otg_hcd->status_buf != NULL) {
+		DWC_FREE(dwc_otg_hcd->status_buf);
+	}
+	DWC_SPINLOCK_FREE(dwc_otg_hcd->lock);
+	/* Set core_if's lock pointer to NULL */
+	dwc_otg_hcd->core_if->lock = NULL;
+
+	DWC_TIMER_FREE(dwc_otg_hcd->conn_timer);
+	DWC_TASK_FREE(dwc_otg_hcd->reset_tasklet);
+
+#ifdef DWC_DEV_SRPCAP
+	if (dwc_otg_hcd->core_if->power_down == 2 &&
+	    dwc_otg_hcd->core_if->pwron_timer) {
+		DWC_TIMER_FREE(dwc_otg_hcd->core_if->pwron_timer);
+	}
+#endif
+	DWC_FREE(dwc_otg_hcd);
+}
+
+int dwc_otg_hcd_init(dwc_otg_hcd_t * hcd, dwc_otg_core_if_t * core_if)
+{
+	int retval = 0;
+	int num_channels;
+	int i;
+	dwc_hc_t *channel;
+
+	hcd->lock = DWC_SPINLOCK_ALLOC();
+	if (!hcd->lock) {
+		DWC_ERROR("Could not allocate lock for pcd");
+		DWC_FREE(hcd);
+		retval = -DWC_E_NO_MEMORY;
+		goto out;
+	}
+	hcd->core_if = core_if;
+
+	/* Register the HCD CIL Callbacks */
+	dwc_otg_cil_register_hcd_callbacks(hcd->core_if,
+					   &hcd_cil_callbacks, hcd);
+
+	/* Initialize the non-periodic schedule. */
+	DWC_LIST_INIT(&hcd->non_periodic_sched_inactive);
+	DWC_LIST_INIT(&hcd->non_periodic_sched_active);
+
+	/* Initialize the periodic schedule. */
+	DWC_LIST_INIT(&hcd->periodic_sched_inactive);
+	DWC_LIST_INIT(&hcd->periodic_sched_ready);
+	DWC_LIST_INIT(&hcd->periodic_sched_assigned);
+	DWC_LIST_INIT(&hcd->periodic_sched_queued);
+
+	/*
+	 * Create a host channel descriptor for each host channel implemented
+	 * in the controller. Initialize the channel descriptor array.
+	 */
+	DWC_CIRCLEQ_INIT(&hcd->free_hc_list);
+	num_channels = hcd->core_if->core_params->host_channels;
+	DWC_MEMSET(hcd->hc_ptr_array, 0, sizeof(hcd->hc_ptr_array));
+	for (i = 0; i < num_channels; i++) {
+		channel = DWC_ALLOC(sizeof(dwc_hc_t));
+		if (channel == NULL) {
+			retval = -DWC_E_NO_MEMORY;
+			DWC_ERROR("%s: host channel allocation failed\n",
+				  __func__);
+			dwc_otg_hcd_free(hcd);
+			goto out;
+		}
+		channel->hc_num = i;
+		hcd->hc_ptr_array[i] = channel;
+#ifdef DEBUG
+		hcd->core_if->hc_xfer_timer[i] =
+		    DWC_TIMER_ALLOC("hc timer", hc_xfer_timeout,
+				    &hcd->core_if->hc_xfer_info[i]);
+#endif
+		DWC_DEBUGPL(DBG_HCDV, "HCD Added channel #%d, hc=%p\n", i,
+			    channel);
+	}
+
+	/* Initialize the Connection timeout timer. */
+	hcd->conn_timer = DWC_TIMER_ALLOC("Connection timer",
+					  dwc_otg_hcd_connect_timeout, hcd);
+
+	/* Initialize reset tasklet. */
+	hcd->reset_tasklet = DWC_TASK_ALLOC("reset_tasklet", reset_tasklet_func, hcd);
+#ifdef DWC_DEV_SRPCAP
+	if (hcd->core_if->power_down == 2) {
+		/* Initialize Power on timer for Host power up in case hibernation */
+		hcd->core_if->pwron_timer = DWC_TIMER_ALLOC("PWRON TIMER",
+									dwc_otg_hcd_power_up, core_if);
+	}
+#endif
+
+	/*
+	 * Allocate space for storing data on status transactions. Normally no
+	 * data is sent, but this space acts as a bit bucket. This must be
+	 * done after usb_add_hcd since that function allocates the DMA buffer
+	 * pool.
+	 */
+	if (hcd->core_if->dma_enable) {
+		hcd->status_buf =
+		    DWC_DMA_ALLOC(DWC_OTG_HCD_STATUS_BUF_SIZE,
+				  &hcd->status_buf_dma);
+	} else {
+		hcd->status_buf = DWC_ALLOC(DWC_OTG_HCD_STATUS_BUF_SIZE);
+	}
+	if (!hcd->status_buf) {
+		retval = -DWC_E_NO_MEMORY;
+		DWC_ERROR("%s: status_buf allocation failed\n", __func__);
+		dwc_otg_hcd_free(hcd);
+		goto out;
+	}
+
+	hcd->otg_port = 1;
+	hcd->frame_list = NULL;
+	hcd->frame_list_dma = 0;
+	hcd->periodic_qh_count = 0;
+out:
+	return retval;
+}
+
+void dwc_otg_hcd_remove(dwc_otg_hcd_t * hcd)
+{
+	/* Turn off all host-specific interrupts. */
+	dwc_otg_disable_host_interrupts(hcd->core_if);
+
+	dwc_otg_hcd_free(hcd);
+}
+
+/**
+ * Initializes dynamic portions of the DWC_otg HCD state.
+ */
+static void dwc_otg_hcd_reinit(dwc_otg_hcd_t * hcd)
+{
+	int num_channels;
+	int i;
+	dwc_hc_t *channel;
+	dwc_hc_t *channel_tmp;
+
+	hcd->flags.d32 = 0;
+
+	hcd->non_periodic_qh_ptr = &hcd->non_periodic_sched_active;
+	hcd->non_periodic_channels = 0;
+	hcd->periodic_channels = 0;
+
+	/*
+	 * Put all channels in the free channel list and clean up channel
+	 * states.
+	 */
+	DWC_CIRCLEQ_FOREACH_SAFE(channel, channel_tmp,
+				 &hcd->free_hc_list, hc_list_entry) {
+		DWC_CIRCLEQ_REMOVE(&hcd->free_hc_list, channel, hc_list_entry);
+	}
+
+	num_channels = hcd->core_if->core_params->host_channels;
+	for (i = 0; i < num_channels; i++) {
+		channel = hcd->hc_ptr_array[i];
+		DWC_CIRCLEQ_INSERT_TAIL(&hcd->free_hc_list, channel,
+					hc_list_entry);
+		dwc_otg_hc_cleanup(hcd->core_if, channel);
+	}
+
+	/* Initialize the DWC core for host mode operation. */
+	dwc_otg_core_host_init(hcd->core_if);
+
+	/* Set core_if's lock pointer to the hcd->lock */
+	hcd->core_if->lock = hcd->lock;
+}
+
+/**
+ * Assigns transactions from a QTD to a free host channel and initializes the
+ * host channel to perform the transactions. The host channel is removed from
+ * the free list.
+ *
+ * @param hcd The HCD state structure.
+ * @param qh Transactions from the first QTD for this QH are selected and
+ * assigned to a free host channel.
+ */
+static void assign_and_init_hc(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	dwc_hc_t *hc = NULL;
+	dwc_otg_qtd_t *qtd;
+	dwc_otg_hcd_urb_t *urb;
+	void* ptr = NULL;
+	hcchar_data_t hcchar;
+	int num_channels;
+	int i;
+
+	DWC_DEBUGPL(DBG_HCDV, "%s(%p,%p)\n", __func__, hcd, qh);
+
+	num_channels = hcd->core_if->core_params->host_channels;
+
+	/* WA to not select channel with chdis bit set, this was
+	 * observed after role switch as part of OTG 2.0 HNP
+	 */
+	for (i = 0; i < num_channels; i++) {
+		hc = DWC_CIRCLEQ_FIRST(&hcd->free_hc_list);
+		hcchar.d32 = DWC_READ_REG32(&hcd->core_if->host_if->hc_regs[hc->hc_num]->hcchar);
+		DWC_DEBUGPL(DBG_HCDV, "HC num = %d HCCHAR %08x\n", hc->hc_num, hcchar.d32);
+		if(!hcchar.b.chdis && !hcchar.b.chen)
+			break;
+		DWC_CIRCLEQ_REMOVE_INIT(&hcd->free_hc_list, hc, hc_list_entry);
+		DWC_CIRCLEQ_INSERT_TAIL(&hcd->free_hc_list, hc, hc_list_entry);
+		hc = NULL;
+	}
+	if (!hc) {
+		DWC_ERROR("No free channel with en and dis bits 0\n");
+		return;
+	}
+
+
+
+	/* Remove the host channel from the free list. */
+	DWC_CIRCLEQ_REMOVE_INIT(&hcd->free_hc_list, hc, hc_list_entry);
+
+	qtd = DWC_CIRCLEQ_FIRST(&qh->qtd_list);
+
+	urb = qtd->urb;
+	qh->channel = hc;
+
+	qtd->in_process = 1;
+
+	/*
+	 * Use usb_pipedevice to determine device address. This address is
+	 * 0 before the SET_ADDRESS command and the correct address afterward.
+	 */
+	hc->dev_addr = dwc_otg_hcd_get_dev_addr(&urb->pipe_info);
+	hc->ep_num = dwc_otg_hcd_get_ep_num(&urb->pipe_info);
+	hc->speed = qh->dev_speed;
+	hc->max_packet = dwc_max_packet(qh->maxp);
+
+	hc->xfer_started = 0;
+	hc->halt_status = DWC_OTG_HC_XFER_NO_HALT_STATUS;
+	hc->error_state = (qtd->error_count > 0);
+	hc->halt_on_queue = 0;
+	hc->halt_pending = 0;
+	hc->requests = 0;
+
+	/*
+	 * The following values may be modified in the transfer type section
+	 * below. The xfer_len value may be reduced when the transfer is
+	 * started to accommodate the max widths of the XferSize and PktCnt
+	 * fields in the HCTSIZn register.
+	 */
+
+	hc->ep_is_in = (dwc_otg_hcd_is_pipe_in(&urb->pipe_info) != 0);
+	if (hc->ep_is_in) {
+		hc->do_ping = 0;
+	} else {
+		hc->do_ping = qh->ping_state;
+	}
+
+	hc->data_pid_start = qh->data_toggle;
+	hc->multi_count = 1;
+
+	if (hcd->core_if->dma_enable) {
+		hc->xfer_buff = (uint8_t *) urb->dma + urb->actual_length;
+
+		/* For non-dword aligned case */
+		if (((unsigned long)hc->xfer_buff & 0x3)
+		    && !hcd->core_if->dma_desc_enable) {
+			ptr = (uint8_t *) urb->buf + urb->actual_length;
+		}
+	} else {
+		hc->xfer_buff = (uint8_t *) urb->buf + urb->actual_length;
+	}
+	hc->xfer_len = urb->length - urb->actual_length;
+	hc->xfer_count = 0;
+
+	/*
+	 * Set the split attributes
+	 */
+	hc->do_split = 0;
+	if (qh->do_split) {
+		uint32_t hub_addr, port_addr;
+		hc->do_split = 1;
+		hc->xact_pos = qtd->isoc_split_pos;
+		hc->complete_split = qtd->complete_split;
+		hcd->fops->hub_info(hcd, urb->priv, &hub_addr, &port_addr);
+		hc->hub_addr = (uint8_t) hub_addr;
+		hc->port_addr = (uint8_t) port_addr;
+	}
+
+	switch (dwc_otg_hcd_get_pipe_type(&urb->pipe_info)) {
+	case UE_CONTROL:
+		hc->ep_type = DWC_OTG_EP_TYPE_CONTROL;
+		switch (qtd->control_phase) {
+		case DWC_OTG_CONTROL_SETUP:
+			DWC_DEBUGPL(DBG_HCDV, "  Control setup transaction\n");
+			hc->do_ping = 0;
+			hc->ep_is_in = 0;
+			hc->data_pid_start = DWC_OTG_HC_PID_SETUP;
+			if (hcd->core_if->dma_enable) {
+				hc->xfer_buff = (uint8_t *) urb->setup_dma;
+			} else {
+				hc->xfer_buff = (uint8_t *) urb->setup_packet;
+			}
+			hc->xfer_len = 8;
+			ptr = NULL;
+			break;
+		case DWC_OTG_CONTROL_DATA:
+			DWC_DEBUGPL(DBG_HCDV, "  Control data transaction\n");
+			hc->data_pid_start = qtd->data_toggle;
+			break;
+		case DWC_OTG_CONTROL_STATUS:
+			/*
+			 * Direction is opposite of data direction or IN if no
+			 * data.
+			 */
+			DWC_DEBUGPL(DBG_HCDV, "  Control status transaction\n");
+			if (urb->length == 0) {
+				hc->ep_is_in = 1;
+			} else {
+				hc->ep_is_in =
+				    dwc_otg_hcd_is_pipe_out(&urb->pipe_info);
+			}
+			if (hc->ep_is_in) {
+				hc->do_ping = 0;
+			}
+
+			hc->data_pid_start = DWC_OTG_HC_PID_DATA1;
+
+			hc->xfer_len = 0;
+			if (hcd->core_if->dma_enable) {
+				hc->xfer_buff = (uint8_t *) hcd->status_buf_dma;
+			} else {
+				hc->xfer_buff = (uint8_t *) hcd->status_buf;
+			}
+			ptr = NULL;
+			break;
+		}
+		break;
+	case UE_BULK:
+		hc->ep_type = DWC_OTG_EP_TYPE_BULK;
+		break;
+	case UE_INTERRUPT:
+		hc->ep_type = DWC_OTG_EP_TYPE_INTR;
+		break;
+	case UE_ISOCHRONOUS:
+		{
+			struct dwc_otg_hcd_iso_packet_desc *frame_desc;
+
+			hc->ep_type = DWC_OTG_EP_TYPE_ISOC;
+
+			if (hcd->core_if->dma_desc_enable)
+				break;
+
+			frame_desc = &urb->iso_descs[qtd->isoc_frame_index];
+
+			frame_desc->status = 0;
+
+			if (hcd->core_if->dma_enable) {
+				hc->xfer_buff = (uint8_t *) urb->dma;
+			} else {
+				hc->xfer_buff = (uint8_t *) urb->buf;
+			}
+			hc->xfer_buff +=
+			    frame_desc->offset + qtd->isoc_split_offset;
+			hc->xfer_len =
+			    frame_desc->length - qtd->isoc_split_offset;
+
+			/* For non-dword aligned buffers */
+			if (((unsigned long)hc->xfer_buff & 0x3)
+			    && hcd->core_if->dma_enable) {
+				ptr =
+				    (uint8_t *) urb->buf + frame_desc->offset +
+				    qtd->isoc_split_offset;
+			} else
+				ptr = NULL;
+
+			if (hc->xact_pos == DWC_HCSPLIT_XACTPOS_ALL) {
+				if (hc->xfer_len <= 188) {
+					hc->xact_pos = DWC_HCSPLIT_XACTPOS_ALL;
+				} else {
+					hc->xact_pos =
+					    DWC_HCSPLIT_XACTPOS_BEGIN;
+				}
+			}
+		}
+		break;
+	}
+	/* non DWORD-aligned buffer case */
+	if (ptr) {
+		uint32_t buf_size;
+		if (hc->ep_type != DWC_OTG_EP_TYPE_ISOC) {
+			buf_size = hcd->core_if->core_params->max_transfer_size;
+		} else {
+			buf_size = 4096;
+		}
+		if (!qh->dw_align_buf) {
+			qh->dw_align_buf = DWC_DMA_ALLOC_ATOMIC(buf_size,
+							 &qh->dw_align_buf_dma);
+			if (!qh->dw_align_buf) {
+				DWC_ERROR
+				    ("%s: Failed to allocate memory to handle "
+				     "non-dword aligned buffer case\n",
+				     __func__);
+				return;
+			}
+		}
+		if (!hc->ep_is_in) {
+			dwc_memcpy(qh->dw_align_buf, ptr, hc->xfer_len);
+		}
+		hc->align_buff = qh->dw_align_buf_dma;
+	} else {
+		hc->align_buff = 0;
+	}
+
+	if (hc->ep_type == DWC_OTG_EP_TYPE_INTR ||
+	    hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+		/*
+		 * This value may be modified when the transfer is started to
+		 * reflect the actual transfer length.
+		 */
+		hc->multi_count = dwc_hb_mult(qh->maxp);
+	}
+
+	if (hcd->core_if->dma_desc_enable)
+		hc->desc_list_addr = qh->desc_list_dma;
+
+	dwc_otg_hc_init(hcd->core_if, hc);
+	hc->qh = qh;
+}
+
+/**
+ * This function selects transactions from the HCD transfer schedule and
+ * assigns them to available host channels. It is called from HCD interrupt
+ * handler functions.
+ *
+ * @param hcd The HCD state structure.
+ *
+ * @return The types of new transactions that were assigned to host channels.
+ */
+dwc_otg_transaction_type_e dwc_otg_hcd_select_transactions(dwc_otg_hcd_t * hcd)
+{
+	dwc_list_link_t *qh_ptr;
+	dwc_otg_qh_t *qh;
+	int num_channels;
+	dwc_otg_transaction_type_e ret_val = DWC_OTG_TRANSACTION_NONE;
+
+#ifdef DEBUG_SOF
+	DWC_DEBUGPL(DBG_HCD, "  Select Transactions\n");
+#endif
+
+	/* Process entries in the periodic ready list. */
+	qh_ptr = DWC_LIST_FIRST(&hcd->periodic_sched_ready);
+
+	while (qh_ptr != &hcd->periodic_sched_ready &&
+	       !DWC_CIRCLEQ_EMPTY(&hcd->free_hc_list)) {
+
+		qh = DWC_LIST_ENTRY(qh_ptr, dwc_otg_qh_t, qh_list_entry);
+		assign_and_init_hc(hcd, qh);
+
+		/*
+		 * Move the QH from the periodic ready schedule to the
+		 * periodic assigned schedule.
+		 */
+		qh_ptr = DWC_LIST_NEXT(qh_ptr);
+		DWC_LIST_MOVE_HEAD(&hcd->periodic_sched_assigned,
+				   &qh->qh_list_entry);
+
+		ret_val = DWC_OTG_TRANSACTION_PERIODIC;
+	}
+
+	/*
+	 * Process entries in the inactive portion of the non-periodic
+	 * schedule. Some free host channels may not be used if they are
+	 * reserved for periodic transfers.
+	 */
+	qh_ptr = hcd->non_periodic_sched_inactive.next;
+	num_channels = hcd->core_if->core_params->host_channels;
+	while (qh_ptr != &hcd->non_periodic_sched_inactive &&
+	       (hcd->non_periodic_channels <
+		num_channels - hcd->periodic_channels) &&
+	       !DWC_CIRCLEQ_EMPTY(&hcd->free_hc_list)) {
+
+		qh = DWC_LIST_ENTRY(qh_ptr, dwc_otg_qh_t, qh_list_entry);
+
+		assign_and_init_hc(hcd, qh);
+
+		/*
+		 * Move the QH from the non-periodic inactive schedule to the
+		 * non-periodic active schedule.
+		 */
+		qh_ptr = DWC_LIST_NEXT(qh_ptr);
+		DWC_LIST_MOVE_HEAD(&hcd->non_periodic_sched_active,
+				   &qh->qh_list_entry);
+
+		if (ret_val == DWC_OTG_TRANSACTION_NONE) {
+			ret_val = DWC_OTG_TRANSACTION_NON_PERIODIC;
+		} else {
+			ret_val = DWC_OTG_TRANSACTION_ALL;
+		}
+
+		hcd->non_periodic_channels++;
+	}
+
+	return ret_val;
+}
+
+/**
+ * Attempts to queue a single transaction request for a host channel
+ * associated with either a periodic or non-periodic transfer. This function
+ * assumes that there is space available in the appropriate request queue. For
+ * an OUT transfer or SETUP transaction in Slave mode, it checks whether space
+ * is available in the appropriate Tx FIFO.
+ *
+ * @param hcd The HCD state structure.
+ * @param hc Host channel descriptor associated with either a periodic or
+ * non-periodic transfer.
+ * @param fifo_dwords_avail Number of DWORDs available in the periodic Tx
+ * FIFO for periodic transfers or the non-periodic Tx FIFO for non-periodic
+ * transfers.
+ *
+ * @return 1 if a request is queued and more requests may be needed to
+ * complete the transfer, 0 if no more requests are required for this
+ * transfer, -1 if there is insufficient space in the Tx FIFO.
+ */
+static int queue_transaction(dwc_otg_hcd_t * hcd,
+			     dwc_hc_t * hc, uint16_t fifo_dwords_avail)
+{
+	int retval;
+
+	if (hcd->core_if->dma_enable) {
+		if (hcd->core_if->dma_desc_enable) {
+			if (!hc->xfer_started
+			    || (hc->ep_type == DWC_OTG_EP_TYPE_ISOC)) {
+				dwc_otg_hcd_start_xfer_ddma(hcd, hc->qh);
+				hc->qh->ping_state = 0;
+			}
+		} else if (!hc->xfer_started) {
+			dwc_otg_hc_start_transfer(hcd->core_if, hc);
+			hc->qh->ping_state = 0;
+		}
+		retval = 0;
+	} else if (hc->halt_pending) {
+		/* Don't queue a request if the channel has been halted. */
+		retval = 0;
+	} else if (hc->halt_on_queue) {
+		dwc_otg_hc_halt(hcd->core_if, hc, hc->halt_status);
+		retval = 0;
+	} else if (hc->do_ping) {
+		if (!hc->xfer_started) {
+			dwc_otg_hc_start_transfer(hcd->core_if, hc);
+		}
+		retval = 0;
+	} else if (!hc->ep_is_in || hc->data_pid_start == DWC_OTG_HC_PID_SETUP) {
+		if ((fifo_dwords_avail * 4) >= hc->max_packet) {
+			if (!hc->xfer_started) {
+				dwc_otg_hc_start_transfer(hcd->core_if, hc);
+				retval = 1;
+			} else {
+				retval =
+				    dwc_otg_hc_continue_transfer(hcd->core_if,
+								 hc);
+			}
+		} else {
+			retval = -1;
+		}
+	} else {
+		if (!hc->xfer_started) {
+			dwc_otg_hc_start_transfer(hcd->core_if, hc);
+			retval = 1;
+		} else {
+			retval = dwc_otg_hc_continue_transfer(hcd->core_if, hc);
+		}
+	}
+
+	return retval;
+}
+
+/**
+ * Processes periodic channels for the next frame and queues transactions for
+ * these channels to the DWC_otg controller. After queueing transactions, the
+ * Periodic Tx FIFO Empty interrupt is enabled if there are more transactions
+ * to queue as Periodic Tx FIFO or request queue space becomes available.
+ * Otherwise, the Periodic Tx FIFO Empty interrupt is disabled.
+ */
+static void process_periodic_channels(dwc_otg_hcd_t * hcd)
+{
+	hptxsts_data_t tx_status;
+	dwc_list_link_t *qh_ptr;
+	dwc_otg_qh_t *qh;
+	int status;
+	int no_queue_space = 0;
+	int no_fifo_space = 0;
+
+	dwc_otg_host_global_regs_t *host_regs;
+	host_regs = hcd->core_if->host_if->host_global_regs;
+
+	DWC_DEBUGPL(DBG_HCDV, "Queue periodic transactions\n");
+#ifdef DEBUG
+	tx_status.d32 = DWC_READ_REG32(&host_regs->hptxsts);
+	DWC_DEBUGPL(DBG_HCDV,
+		    "  P Tx Req Queue Space Avail (before queue): %d\n",
+		    tx_status.b.ptxqspcavail);
+	DWC_DEBUGPL(DBG_HCDV, "  P Tx FIFO Space Avail (before queue): %d\n",
+		    tx_status.b.ptxfspcavail);
+#endif
+
+	qh_ptr = hcd->periodic_sched_assigned.next;
+	while (qh_ptr != &hcd->periodic_sched_assigned) {
+		tx_status.d32 = DWC_READ_REG32(&host_regs->hptxsts);
+		if (tx_status.b.ptxqspcavail == 0) {
+			no_queue_space = 1;
+			break;
+		}
+
+		qh = DWC_LIST_ENTRY(qh_ptr, dwc_otg_qh_t, qh_list_entry);
+
+		/*
+		 * Set a flag if we're queuing high-bandwidth in slave mode.
+		 * The flag prevents any halts to get into the request queue in
+		 * the middle of multiple high-bandwidth packets getting queued.
+		 */
+		if (!hcd->core_if->dma_enable && qh->channel->multi_count > 1) {
+			hcd->core_if->queuing_high_bandwidth = 1;
+		}
+		status =
+		    queue_transaction(hcd, qh->channel,
+				      tx_status.b.ptxfspcavail);
+		if (status < 0) {
+			no_fifo_space = 1;
+			break;
+		}
+
+		/*
+		 * In Slave mode, stay on the current transfer until there is
+		 * nothing more to do or the high-bandwidth request count is
+		 * reached. In DMA mode, only need to queue one request. The
+		 * controller automatically handles multiple packets for
+		 * high-bandwidth transfers.
+		 */
+		if (hcd->core_if->dma_enable || status == 0 ||
+		    qh->channel->requests == qh->channel->multi_count) {
+			qh_ptr = qh_ptr->next;
+			/*
+			 * Move the QH from the periodic assigned schedule to
+			 * the periodic queued schedule.
+			 */
+			DWC_LIST_MOVE_HEAD(&hcd->periodic_sched_queued,
+					   &qh->qh_list_entry);
+
+			/* done queuing high bandwidth */
+			hcd->core_if->queuing_high_bandwidth = 0;
+		}
+	}
+
+	if (!hcd->core_if->dma_enable) {
+		dwc_otg_core_global_regs_t *global_regs;
+		gintmsk_data_t intr_mask = {.d32 = 0 };
+
+		global_regs = hcd->core_if->core_global_regs;
+		intr_mask.b.ptxfempty = 1;
+#ifdef DEBUG
+		tx_status.d32 = DWC_READ_REG32(&host_regs->hptxsts);
+		DWC_DEBUGPL(DBG_HCDV,
+			    "  P Tx Req Queue Space Avail (after queue): %d\n",
+			    tx_status.b.ptxqspcavail);
+		DWC_DEBUGPL(DBG_HCDV,
+			    "  P Tx FIFO Space Avail (after queue): %d\n",
+			    tx_status.b.ptxfspcavail);
+#endif
+		if (!DWC_LIST_EMPTY(&hcd->periodic_sched_assigned) ||
+		    no_queue_space || no_fifo_space) {
+			/*
+			 * May need to queue more transactions as the request
+			 * queue or Tx FIFO empties. Enable the periodic Tx
+			 * FIFO empty interrupt. (Always use the half-empty
+			 * level to ensure that new requests are loaded as
+			 * soon as possible.)
+			 */
+			DWC_MODIFY_REG32(&global_regs->gintmsk, 0,
+					 intr_mask.d32);
+		} else {
+			/*
+			 * Disable the Tx FIFO empty interrupt since there are
+			 * no more transactions that need to be queued right
+			 * now. This function is called from interrupt
+			 * handlers to queue more transactions as transfer
+			 * states change.
+			 */
+			DWC_MODIFY_REG32(&global_regs->gintmsk, intr_mask.d32,
+					 0);
+		}
+	}
+}
+
+/**
+ * Processes active non-periodic channels and queues transactions for these
+ * channels to the DWC_otg controller. After queueing transactions, the NP Tx
+ * FIFO Empty interrupt is enabled if there are more transactions to queue as
+ * NP Tx FIFO or request queue space becomes available. Otherwise, the NP Tx
+ * FIFO Empty interrupt is disabled.
+ */
+static void process_non_periodic_channels(dwc_otg_hcd_t * hcd)
+{
+	gnptxsts_data_t tx_status;
+	dwc_list_link_t *orig_qh_ptr;
+	dwc_otg_qh_t *qh;
+	int status;
+	int no_queue_space = 0;
+	int no_fifo_space = 0;
+	int more_to_do = 0;
+
+	dwc_otg_core_global_regs_t *global_regs =
+	    hcd->core_if->core_global_regs;
+
+	DWC_DEBUGPL(DBG_HCDV, "Queue non-periodic transactions\n");
+#ifdef DEBUG
+	tx_status.d32 = DWC_READ_REG32(&global_regs->gnptxsts);
+	DWC_DEBUGPL(DBG_HCDV,
+		    "  NP Tx Req Queue Space Avail (before queue): %d\n",
+		    tx_status.b.nptxqspcavail);
+	DWC_DEBUGPL(DBG_HCDV, "  NP Tx FIFO Space Avail (before queue): %d\n",
+		    tx_status.b.nptxfspcavail);
+#endif
+	/*
+	 * Keep track of the starting point. Skip over the start-of-list
+	 * entry.
+	 */
+	if (hcd->non_periodic_qh_ptr == &hcd->non_periodic_sched_active) {
+		hcd->non_periodic_qh_ptr = hcd->non_periodic_qh_ptr->next;
+	}
+	orig_qh_ptr = hcd->non_periodic_qh_ptr;
+
+	/*
+	 * Process once through the active list or until no more space is
+	 * available in the request queue or the Tx FIFO.
+	 */
+	do {
+		tx_status.d32 = DWC_READ_REG32(&global_regs->gnptxsts);
+		if (!hcd->core_if->dma_enable && tx_status.b.nptxqspcavail == 0) {
+			no_queue_space = 1;
+			break;
+		}
+
+		qh = DWC_LIST_ENTRY(hcd->non_periodic_qh_ptr, dwc_otg_qh_t,
+				    qh_list_entry);
+		status =
+		    queue_transaction(hcd, qh->channel,
+				      tx_status.b.nptxfspcavail);
+
+		if (status > 0) {
+			more_to_do = 1;
+		} else if (status < 0) {
+			no_fifo_space = 1;
+			break;
+		}
+
+		/* Advance to next QH, skipping start-of-list entry. */
+		hcd->non_periodic_qh_ptr = hcd->non_periodic_qh_ptr->next;
+		if (hcd->non_periodic_qh_ptr == &hcd->non_periodic_sched_active) {
+			hcd->non_periodic_qh_ptr =
+			    hcd->non_periodic_qh_ptr->next;
+		}
+
+	} while (hcd->non_periodic_qh_ptr != orig_qh_ptr);
+
+	if (!hcd->core_if->dma_enable) {
+		gintmsk_data_t intr_mask = {.d32 = 0 };
+		intr_mask.b.nptxfempty = 1;
+
+#ifdef DEBUG
+		tx_status.d32 = DWC_READ_REG32(&global_regs->gnptxsts);
+		DWC_DEBUGPL(DBG_HCDV,
+			    "  NP Tx Req Queue Space Avail (after queue): %d\n",
+			    tx_status.b.nptxqspcavail);
+		DWC_DEBUGPL(DBG_HCDV,
+			    "  NP Tx FIFO Space Avail (after queue): %d\n",
+			    tx_status.b.nptxfspcavail);
+#endif
+		if (more_to_do || no_queue_space || no_fifo_space) {
+			/*
+			 * May need to queue more transactions as the request
+			 * queue or Tx FIFO empties. Enable the non-periodic
+			 * Tx FIFO empty interrupt. (Always use the half-empty
+			 * level to ensure that new requests are loaded as
+			 * soon as possible.)
+			 */
+			DWC_MODIFY_REG32(&global_regs->gintmsk, 0,
+					 intr_mask.d32);
+		} else {
+			/*
+			 * Disable the Tx FIFO empty interrupt since there are
+			 * no more transactions that need to be queued right
+			 * now. This function is called from interrupt
+			 * handlers to queue more transactions as transfer
+			 * states change.
+			 */
+			DWC_MODIFY_REG32(&global_regs->gintmsk, intr_mask.d32,
+					 0);
+		}
+	}
+}
+
+/**
+ * This function processes the currently active host channels and queues
+ * transactions for these channels to the DWC_otg controller. It is called
+ * from HCD interrupt handler functions.
+ *
+ * @param hcd The HCD state structure.
+ * @param tr_type The type(s) of transactions to queue (non-periodic,
+ * periodic, or both).
+ */
+void dwc_otg_hcd_queue_transactions(dwc_otg_hcd_t * hcd,
+				    dwc_otg_transaction_type_e tr_type)
+{
+#ifdef DEBUG_SOF
+	DWC_DEBUGPL(DBG_HCD, "Queue Transactions\n");
+#endif
+	/* Process host channels associated with periodic transfers. */
+	if ((tr_type == DWC_OTG_TRANSACTION_PERIODIC ||
+	     tr_type == DWC_OTG_TRANSACTION_ALL) &&
+	    !DWC_LIST_EMPTY(&hcd->periodic_sched_assigned)) {
+
+		process_periodic_channels(hcd);
+	}
+
+	/* Process host channels associated with non-periodic transfers. */
+	if (tr_type == DWC_OTG_TRANSACTION_NON_PERIODIC ||
+	    tr_type == DWC_OTG_TRANSACTION_ALL) {
+		if (!DWC_LIST_EMPTY(&hcd->non_periodic_sched_active)) {
+			process_non_periodic_channels(hcd);
+		} else {
+			/*
+			 * Ensure NP Tx FIFO empty interrupt is disabled when
+			 * there are no non-periodic transfers to process.
+			 */
+			gintmsk_data_t gintmsk = {.d32 = 0 };
+			gintmsk.b.nptxfempty = 1;
+			DWC_MODIFY_REG32(&hcd->core_if->
+					 core_global_regs->gintmsk, gintmsk.d32,
+					 0);
+		}
+	}
+}
+
+#ifdef DWC_HS_ELECT_TST
+/*
+ * Quick and dirty hack to implement the HS Electrical Test
+ * SINGLE_STEP_GET_DEVICE_DESCRIPTOR feature.
+ *
+ * This code was copied from our userspace app "hset". It sends a
+ * Get Device Descriptor control sequence in two parts, first the
+ * Setup packet by itself, followed some time later by the In and
+ * Ack packets. Rather than trying to figure out how to add this
+ * functionality to the normal driver code, we just hijack the
+ * hardware, using these two function to drive the hardware
+ * directly.
+ */
+
+static dwc_otg_core_global_regs_t *global_regs;
+static dwc_otg_host_global_regs_t *hc_global_regs;
+static dwc_otg_hc_regs_t *hc_regs;
+static uint32_t *data_fifo;
+
+static void do_setup(void)
+{
+	gintsts_data_t gintsts;
+	hctsiz_data_t hctsiz;
+	hcchar_data_t hcchar;
+	haint_data_t haint;
+	hcint_data_t hcint;
+
+	/* Enable HAINTs */
+	DWC_WRITE_REG32(&hc_global_regs->haintmsk, 0x0001);
+
+	/* Enable HCINTs */
+	DWC_WRITE_REG32(&hc_regs->hcintmsk, 0x04a3);
+
+	/* Read GINTSTS */
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+	/* Read HAINT */
+	haint.d32 = DWC_READ_REG32(&hc_global_regs->haint);
+
+	/* Read HCINT */
+	hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+
+	/* Read HCCHAR */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+
+	/* Clear HCINT */
+	DWC_WRITE_REG32(&hc_regs->hcint, hcint.d32);
+
+	/* Clear HAINT */
+	DWC_WRITE_REG32(&hc_global_regs->haint, haint.d32);
+
+	/* Clear GINTSTS */
+	DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+	/* Read GINTSTS */
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+	/*
+	 * Send Setup packet (Get Device Descriptor)
+	 */
+
+	/* Make sure channel is disabled */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	if (hcchar.b.chen) {
+		hcchar.b.chdis = 1;
+//              hcchar.b.chen = 1;
+		DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+		//sleep(1);
+		dwc_mdelay(1000);
+
+		/* Read GINTSTS */
+		gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+		/* Read HAINT */
+		haint.d32 = DWC_READ_REG32(&hc_global_regs->haint);
+
+		/* Read HCINT */
+		hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+
+		/* Read HCCHAR */
+		hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+
+		/* Clear HCINT */
+		DWC_WRITE_REG32(&hc_regs->hcint, hcint.d32);
+
+		/* Clear HAINT */
+		DWC_WRITE_REG32(&hc_global_regs->haint, haint.d32);
+
+		/* Clear GINTSTS */
+		DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+		hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	}
+
+	/* Set HCTSIZ */
+	hctsiz.d32 = 0;
+	hctsiz.b.xfersize = 8;
+	hctsiz.b.pktcnt = 1;
+	hctsiz.b.pid = DWC_OTG_HC_PID_SETUP;
+	DWC_WRITE_REG32(&hc_regs->hctsiz, hctsiz.d32);
+
+	/* Set HCCHAR */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	hcchar.b.eptype = DWC_OTG_EP_TYPE_CONTROL;
+	hcchar.b.epdir = 0;
+	hcchar.b.epnum = 0;
+	hcchar.b.mps = 8;
+	hcchar.b.chen = 1;
+	DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+
+	/* Fill FIFO with Setup data for Get Device Descriptor */
+	data_fifo = (uint32_t *) ((char *)global_regs + 0x1000);
+	DWC_WRITE_REG32(data_fifo++, 0x01000680);
+	DWC_WRITE_REG32(data_fifo++, 0x00080000);
+
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+	/* Wait for host channel interrupt */
+	do {
+		gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+	} while (gintsts.b.hcintr == 0);
+
+	/* Disable HCINTs */
+	DWC_WRITE_REG32(&hc_regs->hcintmsk, 0x0000);
+
+	/* Disable HAINTs */
+	DWC_WRITE_REG32(&hc_global_regs->haintmsk, 0x0000);
+
+	/* Read HAINT */
+	haint.d32 = DWC_READ_REG32(&hc_global_regs->haint);
+
+	/* Read HCINT */
+	hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+
+	/* Read HCCHAR */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+
+	/* Clear HCINT */
+	DWC_WRITE_REG32(&hc_regs->hcint, hcint.d32);
+
+	/* Clear HAINT */
+	DWC_WRITE_REG32(&hc_global_regs->haint, haint.d32);
+
+	/* Clear GINTSTS */
+	DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+	/* Read GINTSTS */
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+}
+
+static void do_in_ack(void)
+{
+	gintsts_data_t gintsts;
+	hctsiz_data_t hctsiz;
+	hcchar_data_t hcchar;
+	haint_data_t haint;
+	hcint_data_t hcint;
+	host_grxsts_data_t grxsts;
+
+	/* Enable HAINTs */
+	DWC_WRITE_REG32(&hc_global_regs->haintmsk, 0x0001);
+
+	/* Enable HCINTs */
+	DWC_WRITE_REG32(&hc_regs->hcintmsk, 0x04a3);
+
+	/* Read GINTSTS */
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+	/* Read HAINT */
+	haint.d32 = DWC_READ_REG32(&hc_global_regs->haint);
+
+	/* Read HCINT */
+	hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+
+	/* Read HCCHAR */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+
+	/* Clear HCINT */
+	DWC_WRITE_REG32(&hc_regs->hcint, hcint.d32);
+
+	/* Clear HAINT */
+	DWC_WRITE_REG32(&hc_global_regs->haint, haint.d32);
+
+	/* Clear GINTSTS */
+	DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+	/* Read GINTSTS */
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+	/*
+	 * Receive Control In packet
+	 */
+
+	/* Make sure channel is disabled */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	if (hcchar.b.chen) {
+		hcchar.b.chdis = 1;
+		hcchar.b.chen = 1;
+		DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+		//sleep(1);
+		dwc_mdelay(1000);
+
+		/* Read GINTSTS */
+		gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+		/* Read HAINT */
+		haint.d32 = DWC_READ_REG32(&hc_global_regs->haint);
+
+		/* Read HCINT */
+		hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+
+		/* Read HCCHAR */
+		hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+
+		/* Clear HCINT */
+		DWC_WRITE_REG32(&hc_regs->hcint, hcint.d32);
+
+		/* Clear HAINT */
+		DWC_WRITE_REG32(&hc_global_regs->haint, haint.d32);
+
+		/* Clear GINTSTS */
+		DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+		hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	}
+
+	/* Set HCTSIZ */
+	hctsiz.d32 = 0;
+	hctsiz.b.xfersize = 8;
+	hctsiz.b.pktcnt = 1;
+	hctsiz.b.pid = DWC_OTG_HC_PID_DATA1;
+	DWC_WRITE_REG32(&hc_regs->hctsiz, hctsiz.d32);
+
+	/* Set HCCHAR */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	hcchar.b.eptype = DWC_OTG_EP_TYPE_CONTROL;
+	hcchar.b.epdir = 1;
+	hcchar.b.epnum = 0;
+	hcchar.b.mps = 8;
+	hcchar.b.chen = 1;
+	DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+	/* Wait for receive status queue interrupt */
+	do {
+		gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+	} while (gintsts.b.rxstsqlvl == 0);
+
+	/* Read RXSTS */
+	grxsts.d32 = DWC_READ_REG32(&global_regs->grxstsp);
+
+	/* Clear RXSTSQLVL in GINTSTS */
+	gintsts.d32 = 0;
+	gintsts.b.rxstsqlvl = 1;
+	DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+	switch (grxsts.b.pktsts) {
+	case DWC_GRXSTS_PKTSTS_IN:
+		/* Read the data into the host buffer */
+		if (grxsts.b.bcnt > 0) {
+			int i;
+			int word_count = (grxsts.b.bcnt + 3) / 4;
+
+			data_fifo = (uint32_t *) ((char *)global_regs + 0x1000);
+
+			for (i = 0; i < word_count; i++) {
+				(void)DWC_READ_REG32(data_fifo++);
+			}
+		}
+		break;
+
+	default:
+		break;
+	}
+
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+	/* Wait for receive status queue interrupt */
+	do {
+		gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+	} while (gintsts.b.rxstsqlvl == 0);
+
+	/* Read RXSTS */
+	grxsts.d32 = DWC_READ_REG32(&global_regs->grxstsp);
+
+	/* Clear RXSTSQLVL in GINTSTS */
+	gintsts.d32 = 0;
+	gintsts.b.rxstsqlvl = 1;
+	DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+	switch (grxsts.b.pktsts) {
+	case DWC_GRXSTS_PKTSTS_IN_XFER_COMP:
+		break;
+
+	default:
+		break;
+	}
+
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+	/* Wait for host channel interrupt */
+	do {
+		gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+	} while (gintsts.b.hcintr == 0);
+
+	/* Read HAINT */
+	haint.d32 = DWC_READ_REG32(&hc_global_regs->haint);
+
+	/* Read HCINT */
+	hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+
+	/* Read HCCHAR */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+
+	/* Clear HCINT */
+	DWC_WRITE_REG32(&hc_regs->hcint, hcint.d32);
+
+	/* Clear HAINT */
+	DWC_WRITE_REG32(&hc_global_regs->haint, haint.d32);
+
+	/* Clear GINTSTS */
+	DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+	/* Read GINTSTS */
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+//      usleep(100000);
+//      mdelay(100);
+	dwc_mdelay(1);
+
+	/*
+	 * Send handshake packet
+	 */
+
+	/* Read HAINT */
+	haint.d32 = DWC_READ_REG32(&hc_global_regs->haint);
+
+	/* Read HCINT */
+	hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+
+	/* Read HCCHAR */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+
+	/* Clear HCINT */
+	DWC_WRITE_REG32(&hc_regs->hcint, hcint.d32);
+
+	/* Clear HAINT */
+	DWC_WRITE_REG32(&hc_global_regs->haint, haint.d32);
+
+	/* Clear GINTSTS */
+	DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+	/* Read GINTSTS */
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+	/* Make sure channel is disabled */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	if (hcchar.b.chen) {
+		hcchar.b.chdis = 1;
+		hcchar.b.chen = 1;
+		DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+		//sleep(1);
+		dwc_mdelay(1000);
+
+		/* Read GINTSTS */
+		gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+		/* Read HAINT */
+		haint.d32 = DWC_READ_REG32(&hc_global_regs->haint);
+
+		/* Read HCINT */
+		hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+
+		/* Read HCCHAR */
+		hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+
+		/* Clear HCINT */
+		DWC_WRITE_REG32(&hc_regs->hcint, hcint.d32);
+
+		/* Clear HAINT */
+		DWC_WRITE_REG32(&hc_global_regs->haint, haint.d32);
+
+		/* Clear GINTSTS */
+		DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+		hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	}
+
+	/* Set HCTSIZ */
+	hctsiz.d32 = 0;
+	hctsiz.b.xfersize = 0;
+	hctsiz.b.pktcnt = 1;
+	hctsiz.b.pid = DWC_OTG_HC_PID_DATA1;
+	DWC_WRITE_REG32(&hc_regs->hctsiz, hctsiz.d32);
+
+	/* Set HCCHAR */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	hcchar.b.eptype = DWC_OTG_EP_TYPE_CONTROL;
+	hcchar.b.epdir = 0;
+	hcchar.b.epnum = 0;
+	hcchar.b.mps = 8;
+	hcchar.b.chen = 1;
+	DWC_WRITE_REG32(&hc_regs->hcchar, hcchar.d32);
+
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+
+	/* Wait for host channel interrupt */
+	do {
+		gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+	} while (gintsts.b.hcintr == 0);
+
+	/* Disable HCINTs */
+	DWC_WRITE_REG32(&hc_regs->hcintmsk, 0x0000);
+
+	/* Disable HAINTs */
+	DWC_WRITE_REG32(&hc_global_regs->haintmsk, 0x0000);
+
+	/* Read HAINT */
+	haint.d32 = DWC_READ_REG32(&hc_global_regs->haint);
+
+	/* Read HCINT */
+	hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+
+	/* Read HCCHAR */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+
+	/* Clear HCINT */
+	DWC_WRITE_REG32(&hc_regs->hcint, hcint.d32);
+
+	/* Clear HAINT */
+	DWC_WRITE_REG32(&hc_global_regs->haint, haint.d32);
+
+	/* Clear GINTSTS */
+	DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+	/* Read GINTSTS */
+	gintsts.d32 = DWC_READ_REG32(&global_regs->gintsts);
+}
+#endif
+
+/** Handles hub class-specific requests. */
+int dwc_otg_hcd_hub_control(dwc_otg_hcd_t * dwc_otg_hcd,
+			    uint16_t typeReq,
+			    uint16_t wValue,
+			    uint16_t wIndex, uint8_t * buf, uint16_t wLength)
+{
+	int retval = 0;
+
+	dwc_otg_core_if_t *core_if = dwc_otg_hcd->core_if;
+	usb_hub_descriptor_t *hub_desc;
+	hprt0_data_t hprt0 = {.d32 = 0 };
+
+	uint32_t port_status;
+
+	switch (typeReq) {
+	case UCR_CLEAR_HUB_FEATURE:
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+			    "ClearHubFeature 0x%x\n", wValue);
+		switch (wValue) {
+		case UHF_C_HUB_LOCAL_POWER:
+		case UHF_C_HUB_OVER_CURRENT:
+			/* Nothing required here */
+			break;
+		default:
+			retval = -DWC_E_INVALID;
+			DWC_ERROR("DWC OTG HCD - "
+				  "ClearHubFeature request %xh unknown\n",
+				  wValue);
+		}
+		break;
+	case UCR_CLEAR_PORT_FEATURE:
+#ifdef CONFIG_USB_DWC_OTG_LPM
+		if (wValue != UHF_PORT_L1)
+#endif
+			if (!wIndex || wIndex > 1)
+				goto error;
+
+		switch (wValue) {
+		case UHF_PORT_ENABLE:
+			DWC_DEBUGPL(DBG_ANY, "DWC OTG HCD HUB CONTROL - "
+				    "ClearPortFeature USB_PORT_FEAT_ENABLE\n");
+			hprt0.d32 = dwc_otg_read_hprt0(core_if);
+			hprt0.b.prtena = 1;
+			DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+			break;
+		case UHF_PORT_SUSPEND:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				    "ClearPortFeature USB_PORT_FEAT_SUSPEND\n");
+
+			if (core_if->power_down == 2) {
+				dwc_otg_host_hibernation_restore(core_if, 0, 0);
+			} else {
+				DWC_WRITE_REG32(core_if->pcgcctl, 0);
+				dwc_mdelay(5);
+
+				hprt0.d32 = dwc_otg_read_hprt0(core_if);
+				hprt0.b.prtres = 1;
+				DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+				hprt0.b.prtsusp = 0;
+				/* Clear Resume bit */
+				dwc_mdelay(100);
+				hprt0.b.prtres = 0;
+				DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+			}
+			break;
+#ifdef CONFIG_USB_DWC_OTG_LPM
+		case UHF_PORT_L1:
+			{
+				pcgcctl_data_t pcgcctl = {.d32 = 0 };
+				glpmcfg_data_t lpmcfg = {.d32 = 0 };
+
+				lpmcfg.d32 =
+				    DWC_READ_REG32(&core_if->
+						   core_global_regs->glpmcfg);
+				lpmcfg.b.en_utmi_sleep = 0;
+				lpmcfg.b.hird_thres &= (~(1 << 4));
+				lpmcfg.b.prt_sleep_sts = 1;
+				DWC_WRITE_REG32(&core_if->
+						core_global_regs->glpmcfg,
+						lpmcfg.d32);
+
+				/* Clear Enbl_L1Gating bit. */
+				pcgcctl.b.enbl_sleep_gating = 1;
+				DWC_MODIFY_REG32(core_if->pcgcctl, pcgcctl.d32,
+						 0);
+
+				dwc_mdelay(5);
+
+				hprt0.d32 = dwc_otg_read_hprt0(core_if);
+				hprt0.b.prtres = 1;
+				DWC_WRITE_REG32(core_if->host_if->hprt0,
+						hprt0.d32);
+				/* This bit will be cleared in wakeup interrupt handle */
+				break;
+			}
+#endif
+		case UHF_PORT_POWER:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				    "ClearPortFeature USB_PORT_FEAT_POWER\n");
+			hprt0.d32 = dwc_otg_read_hprt0(core_if);
+			hprt0.b.prtpwr = 0;
+			DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+			break;
+		case UHF_PORT_INDICATOR:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				    "ClearPortFeature USB_PORT_FEAT_INDICATOR\n");
+			/* Port inidicator not supported */
+			break;
+		case UHF_C_PORT_CONNECTION:
+			/* Clears drivers internal connect status change
+			 * flag */
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				    "ClearPortFeature USB_PORT_FEAT_C_CONNECTION\n");
+			dwc_otg_hcd->flags.b.port_connect_status_change = 0;
+			break;
+		case UHF_C_PORT_RESET:
+			/* Clears the driver's internal Port Reset Change
+			 * flag */
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				    "ClearPortFeature USB_PORT_FEAT_C_RESET\n");
+			dwc_otg_hcd->flags.b.port_reset_change = 0;
+			break;
+		case UHF_C_PORT_ENABLE:
+			/* Clears the driver's internal Port
+			 * Enable/Disable Change flag */
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				    "ClearPortFeature USB_PORT_FEAT_C_ENABLE\n");
+			dwc_otg_hcd->flags.b.port_enable_change = 0;
+			break;
+		case UHF_C_PORT_SUSPEND:
+			/* Clears the driver's internal Port Suspend
+			 * Change flag, which is set when resume signaling on
+			 * the host port is complete */
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				    "ClearPortFeature USB_PORT_FEAT_C_SUSPEND\n");
+			dwc_otg_hcd->flags.b.port_suspend_change = 0;
+			break;
+#ifdef CONFIG_USB_DWC_OTG_LPM
+		case UHF_C_PORT_L1:
+			dwc_otg_hcd->flags.b.port_l1_change = 0;
+			break;
+#endif
+		case UHF_C_PORT_OVER_CURRENT:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				    "ClearPortFeature USB_PORT_FEAT_C_OVER_CURRENT\n");
+			dwc_otg_hcd->flags.b.port_over_current_change = 0;
+			break;
+		default:
+			retval = -DWC_E_INVALID;
+			DWC_ERROR("DWC OTG HCD - "
+				  "ClearPortFeature request %xh "
+				  "unknown or unsupported\n", wValue);
+		}
+		break;
+	case UCR_GET_HUB_DESCRIPTOR:
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+			    "GetHubDescriptor\n");
+		hub_desc = (usb_hub_descriptor_t *) buf;
+		hub_desc->bDescLength = 9;
+		hub_desc->bDescriptorType = 0x29;
+		hub_desc->bNbrPorts = 1;
+		USETW(hub_desc->wHubCharacteristics, 0x08);
+		hub_desc->bPwrOn2PwrGood = 1;
+		hub_desc->bHubContrCurrent = 0;
+		hub_desc->DeviceRemovable[0] = 0;
+		hub_desc->DeviceRemovable[1] = 0xff;
+		break;
+	case UCR_GET_HUB_STATUS:
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+			    "GetHubStatus\n");
+		DWC_MEMSET(buf, 0, 4);
+		break;
+	case UCR_GET_PORT_STATUS:
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+			    "GetPortStatus wIndex = 0x%04x FLAGS=0x%08x\n",
+			    wIndex, dwc_otg_hcd->flags.d32);
+		if (!wIndex || wIndex > 1)
+			goto error;
+
+		port_status = 0;
+
+		if (dwc_otg_hcd->flags.b.port_connect_status_change)
+			port_status |= (1 << UHF_C_PORT_CONNECTION);
+
+		if (dwc_otg_hcd->flags.b.port_enable_change)
+			port_status |= (1 << UHF_C_PORT_ENABLE);
+
+		if (dwc_otg_hcd->flags.b.port_suspend_change)
+			port_status |= (1 << UHF_C_PORT_SUSPEND);
+
+		if (dwc_otg_hcd->flags.b.port_l1_change)
+			port_status |= (1 << UHF_C_PORT_L1);
+
+		if (dwc_otg_hcd->flags.b.port_reset_change) {
+			port_status |= (1 << UHF_C_PORT_RESET);
+		}
+
+		if (dwc_otg_hcd->flags.b.port_over_current_change) {
+			DWC_WARN("Overcurrent change detected\n");
+			port_status |= (1 << UHF_C_PORT_OVER_CURRENT);
+		}
+
+		if (!dwc_otg_hcd->flags.b.port_connect_status) {
+			/*
+			 * The port is disconnected, which means the core is
+			 * either in device mode or it soon will be. Just
+			 * return 0's for the remainder of the port status
+			 * since the port register can't be read if the core
+			 * is in device mode.
+			 */
+			*((__le32 *) buf) = dwc_cpu_to_le32(&port_status);
+			break;
+		}
+
+		hprt0.d32 = DWC_READ_REG32(core_if->host_if->hprt0);
+		DWC_DEBUGPL(DBG_HCDV, "  HPRT0: 0x%08x\n", hprt0.d32);
+
+		if (hprt0.b.prtconnsts)
+			port_status |= (1 << UHF_PORT_CONNECTION);
+
+		if (hprt0.b.prtena)
+			port_status |= (1 << UHF_PORT_ENABLE);
+
+		if (hprt0.b.prtsusp)
+			port_status |= (1 << UHF_PORT_SUSPEND);
+
+		if (hprt0.b.prtovrcurract)
+			port_status |= (1 << UHF_PORT_OVER_CURRENT);
+
+		if (hprt0.b.prtrst)
+			port_status |= (1 << UHF_PORT_RESET);
+
+		if (hprt0.b.prtpwr)
+			port_status |= (1 << UHF_PORT_POWER);
+
+		if (hprt0.b.prtspd == DWC_HPRT0_PRTSPD_HIGH_SPEED)
+			port_status |= (1 << UHF_PORT_HIGH_SPEED);
+		else if (hprt0.b.prtspd == DWC_HPRT0_PRTSPD_LOW_SPEED)
+			port_status |= (1 << UHF_PORT_LOW_SPEED);
+
+		if (hprt0.b.prttstctl)
+			port_status |= (1 << UHF_PORT_TEST);
+		if (dwc_otg_get_lpm_portsleepstatus(dwc_otg_hcd->core_if)) {
+			port_status |= (1 << UHF_PORT_L1);
+		}
+		/*
+		   For Synopsys HW emulation of Power down wkup_control asserts the
+		   hreset_n and prst_n on suspned. This causes the HPRT0 to be zero.
+		   We intentionally tell the software that port is in L2Suspend state.
+		   Only for STE.
+		*/
+		if ((core_if->power_down == 2)
+		    && (core_if->hibernation_suspend == 1)) {
+			port_status |= (1 << UHF_PORT_SUSPEND);
+		}
+		/* USB_PORT_FEAT_INDICATOR unsupported always 0 */
+
+		*((__le32 *) buf) = dwc_cpu_to_le32(&port_status);
+
+		break;
+	case UCR_SET_HUB_FEATURE:
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+			    "SetHubFeature\n");
+		/* No HUB features supported */
+		break;
+	case UCR_SET_PORT_FEATURE:
+		if (wValue != UHF_PORT_TEST && (!wIndex || wIndex > 1))
+			goto error;
+
+		if (!dwc_otg_hcd->flags.b.port_connect_status) {
+			/*
+			 * The port is disconnected, which means the core is
+			 * either in device mode or it soon will be. Just
+			 * return without doing anything since the port
+			 * register can't be written if the core is in device
+			 * mode.
+			 */
+			break;
+		}
+
+		switch (wValue) {
+		case UHF_PORT_SUSPEND:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				    "SetPortFeature - USB_PORT_FEAT_SUSPEND\n");
+			if (dwc_otg_hcd_otg_port(dwc_otg_hcd) != wIndex) {
+				goto error;
+			}
+			if (core_if->power_down == 2) {
+				int timeout = 300;
+				dwc_irqflags_t flags;
+				pcgcctl_data_t pcgcctl = {.d32 = 0 };
+				gpwrdn_data_t gpwrdn = {.d32 = 0 };
+				gusbcfg_data_t gusbcfg = {.d32 = 0 };
+#ifdef DWC_DEV_SRPCAP
+				int32_t otg_cap_param = core_if->core_params->otg_cap;
+#endif
+				DWC_PRINTF("Preparing for complete power-off\n");
+
+				/* Save registers before hibernation */
+				dwc_otg_save_global_regs(core_if);
+				dwc_otg_save_host_regs(core_if);
+
+				hprt0.d32 = dwc_otg_read_hprt0(core_if);
+				hprt0.b.prtsusp = 1;
+				hprt0.b.prtena = 0;
+				DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+				/* Spin hprt0.b.prtsusp to became 1 */
+				do {
+					hprt0.d32 = dwc_otg_read_hprt0(core_if);
+					if (hprt0.b.prtsusp) {
+						break;
+					}
+					dwc_mdelay(1);
+				} while (--timeout);
+				if (!timeout) {
+					DWC_WARN("Suspend wasn't genereted\n");
+				}
+				dwc_udelay(10);
+
+				/*
+				 * We need to disable interrupts to prevent servicing of any IRQ
+				 * during going to hibernation
+				 */
+				DWC_SPINLOCK_IRQSAVE(dwc_otg_hcd->lock, &flags);
+				core_if->lx_state = DWC_OTG_L2;
+#ifdef DWC_DEV_SRPCAP
+				hprt0.d32 = dwc_otg_read_hprt0(core_if);
+				hprt0.b.prtpwr = 0;
+				hprt0.b.prtena = 0;
+				DWC_WRITE_REG32(core_if->host_if->hprt0,
+						hprt0.d32);
+#endif
+				gusbcfg.d32 =
+				    DWC_READ_REG32(&core_if->core_global_regs->
+						   gusbcfg);
+				if (gusbcfg.b.ulpi_utmi_sel == 1) {
+					/* ULPI interface */
+					/* Suspend the Phy Clock */
+					pcgcctl.d32 = 0;
+					pcgcctl.b.stoppclk = 1;
+					DWC_MODIFY_REG32(core_if->pcgcctl, 0,
+							 pcgcctl.d32);
+					dwc_udelay(10);
+					gpwrdn.b.pmuactv = 1;
+					DWC_MODIFY_REG32(&core_if->
+							 core_global_regs->
+							 gpwrdn, 0, gpwrdn.d32);
+				} else {
+					/* UTMI+ Interface */
+					gpwrdn.b.pmuactv = 1;
+					DWC_MODIFY_REG32(&core_if->
+							 core_global_regs->
+							 gpwrdn, 0, gpwrdn.d32);
+					dwc_udelay(10);
+					pcgcctl.b.stoppclk = 1;
+					DWC_MODIFY_REG32(core_if->pcgcctl, 0, pcgcctl.d32);
+					dwc_udelay(10);
+				}
+#ifdef DWC_DEV_SRPCAP
+				gpwrdn.d32 = 0;
+				gpwrdn.b.dis_vbus = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+#endif
+				gpwrdn.d32 = 0;
+				gpwrdn.b.pmuintsel = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+				dwc_udelay(10);
+
+				gpwrdn.d32 = 0;
+#ifdef DWC_DEV_SRPCAP
+				gpwrdn.b.srp_det_msk = 1;
+#endif
+				gpwrdn.b.disconn_det_msk = 1;
+				gpwrdn.b.lnstchng_msk = 1;
+				gpwrdn.b.sts_chngint_msk = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+				dwc_udelay(10);
+
+				/* Enable Power Down Clamp and all interrupts in GPWRDN */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.pwrdnclmp = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+				dwc_udelay(10);
+
+				/* Switch off VDD */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.pwrdnswtch = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gpwrdn, 0, gpwrdn.d32);
+
+#ifdef DWC_DEV_SRPCAP
+				if (otg_cap_param == DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE)
+				{
+					core_if->pwron_timer_started = 1;
+					DWC_TIMER_SCHEDULE(core_if->pwron_timer, 6000 /* 6 secs */ );
+				}
+#endif
+				/* Save gpwrdn register for further usage if stschng interrupt */
+				core_if->gr_backup->gpwrdn_local =
+						DWC_READ_REG32(&core_if->core_global_regs->gpwrdn);
+
+				/* Set flag to indicate that we are in hibernation */
+				core_if->hibernation_suspend = 1;
+				DWC_SPINUNLOCK_IRQRESTORE(dwc_otg_hcd->lock,flags);
+
+				DWC_PRINTF("Host hibernation completed\n");
+				// Exit from case statement
+				break;
+
+			}
+			if (dwc_otg_hcd_otg_port(dwc_otg_hcd) == wIndex &&
+			    dwc_otg_hcd->fops->get_b_hnp_enable(dwc_otg_hcd)) {
+				gotgctl_data_t gotgctl = {.d32 = 0 };
+				gotgctl.b.hstsethnpen = 1;
+				DWC_MODIFY_REG32(&core_if->core_global_regs->
+						 gotgctl, 0, gotgctl.d32);
+				core_if->op_state = A_SUSPEND;
+			}
+			hprt0.d32 = dwc_otg_read_hprt0(core_if);
+			hprt0.b.prtsusp = 1;
+			DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+			{
+				dwc_irqflags_t flags;
+				/* Update lx_state */
+				DWC_SPINLOCK_IRQSAVE(dwc_otg_hcd->lock, &flags);
+				core_if->lx_state = DWC_OTG_L2;
+				DWC_SPINUNLOCK_IRQRESTORE(dwc_otg_hcd->lock, flags);
+			}
+			/* Suspend the Phy Clock */
+			if (core_if->otg_ver == 0) {
+				pcgcctl_data_t pcgcctl = {.d32 = 0 };
+				pcgcctl.b.stoppclk = 1;
+				DWC_MODIFY_REG32(core_if->pcgcctl, 0,
+						 pcgcctl.d32);
+				dwc_udelay(10);
+			}
+
+			/* For HNP the bus must be suspended for at least 200ms. */
+			if (dwc_otg_hcd->fops->get_b_hnp_enable(dwc_otg_hcd)) {
+				if (core_if->otg_ver) {
+					pcgcctl_data_t pcgcctl = {.d32 = 0 };
+					pcgcctl.b.stoppclk = 1;
+					DWC_MODIFY_REG32(core_if->pcgcctl, pcgcctl.d32, 0);
+				}
+				dwc_mdelay(200);
+			}
+
+			break;
+		case UHF_PORT_POWER:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				    "SetPortFeature - USB_PORT_FEAT_POWER\n");
+			hprt0.d32 = dwc_otg_read_hprt0(core_if);
+			hprt0.b.prtpwr = 1;
+			DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+			break;
+		case UHF_PORT_RESET:
+			if ((core_if->power_down == 2)
+			    && (core_if->hibernation_suspend == 1)) {
+				/* If we are going to exit from Hibernated
+				 * state via USB RESET.
+				 */
+				dwc_otg_host_hibernation_restore(core_if, 0, 1);
+			} else {
+				hprt0.d32 = dwc_otg_read_hprt0(core_if);
+
+				DWC_DEBUGPL(DBG_HCD,
+					    "DWC OTG HCD HUB CONTROL - "
+					    "SetPortFeature - USB_PORT_FEAT_RESET\n");
+				{
+					pcgcctl_data_t pcgcctl = {.d32 = 0 };
+					pcgcctl.b.enbl_sleep_gating = 1;
+					pcgcctl.b.stoppclk = 1;
+					DWC_MODIFY_REG32(core_if->pcgcctl, pcgcctl.d32, 0);
+					DWC_WRITE_REG32(core_if->pcgcctl, 0);
+				}
+#ifdef CONFIG_USB_DWC_OTG_LPM
+				{
+					glpmcfg_data_t lpmcfg;
+					lpmcfg.d32 =
+						DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+					if (lpmcfg.b.prt_sleep_sts) {
+						lpmcfg.b.en_utmi_sleep = 0;
+						lpmcfg.b.hird_thres &= (~(1 << 4));
+						DWC_WRITE_REG32
+						    (&core_if->core_global_regs->glpmcfg,
+						     lpmcfg.d32);
+						dwc_mdelay(1);
+					}
+				}
+#endif
+				hprt0.d32 = dwc_otg_read_hprt0(core_if);
+				/* Clear suspend bit if resetting from suspended state. */
+				hprt0.b.prtsusp = 0;
+				/* When B-Host the Port reset bit is set in
+				 * the Start HCD Callback function, so that
+				 * the reset is started within 1ms of the HNP
+				 * success interrupt. */
+				if (!dwc_otg_hcd_is_b_host(dwc_otg_hcd)) {
+					hprt0.b.prtpwr = 1;
+					hprt0.b.prtrst = 1;
+					DWC_PRINTF("Indeed it is in host mode hprt0 = %08x\n",hprt0.d32);
+					DWC_WRITE_REG32(core_if->host_if->hprt0,
+							hprt0.d32);
+				}
+				/* Clear reset bit in 10ms (FS/LS) or 50ms (HS) */
+				dwc_mdelay(60);
+				hprt0.b.prtrst = 0;
+				DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+				core_if->lx_state = DWC_OTG_L0;	/* Now back to the on state */
+			}
+			break;
+#ifdef DWC_HS_ELECT_TST
+		case UHF_PORT_TEST:
+			{
+				uint32_t t;
+				gintmsk_data_t gintmsk;
+
+				t = (wIndex >> 8);	/* MSB wIndex USB */
+				DWC_DEBUGPL(DBG_HCD,
+					    "DWC OTG HCD HUB CONTROL - "
+					    "SetPortFeature - USB_PORT_FEAT_TEST %d\n",
+					    t);
+				DWC_WARN("USB_PORT_FEAT_TEST %d\n", t);
+				if (t < 6) {
+					hprt0.d32 = dwc_otg_read_hprt0(core_if);
+					hprt0.b.prttstctl = t;
+					DWC_WRITE_REG32(core_if->host_if->hprt0,
+							hprt0.d32);
+				} else {
+					/* Setup global vars with reg addresses (quick and
+					 * dirty hack, should be cleaned up)
+					 */
+					global_regs = core_if->core_global_regs;
+					hc_global_regs =
+					    core_if->host_if->host_global_regs;
+					hc_regs =
+					    (dwc_otg_hc_regs_t *) ((char *)
+								   global_regs +
+								   0x500);
+					data_fifo =
+					    (uint32_t *) ((char *)global_regs +
+							  0x1000);
+
+					if (t == 6) {	/* HS_HOST_PORT_SUSPEND_RESUME */
+						/* Save current interrupt mask */
+						gintmsk.d32 =
+						    DWC_READ_REG32
+						    (&global_regs->gintmsk);
+
+						/* Disable all interrupts while we muck with
+						 * the hardware directly
+						 */
+						DWC_WRITE_REG32(&global_regs->gintmsk, 0);
+
+						/* 15 second delay per the test spec */
+						dwc_mdelay(15000);
+
+						/* Drive suspend on the root port */
+						hprt0.d32 =
+						    dwc_otg_read_hprt0(core_if);
+						hprt0.b.prtsusp = 1;
+						hprt0.b.prtres = 0;
+						DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+
+						/* 15 second delay per the test spec */
+						dwc_mdelay(15000);
+
+						/* Drive resume on the root port */
+						hprt0.d32 =
+						    dwc_otg_read_hprt0(core_if);
+						hprt0.b.prtsusp = 0;
+						hprt0.b.prtres = 1;
+						DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+						dwc_mdelay(100);
+
+						/* Clear the resume bit */
+						hprt0.b.prtres = 0;
+						DWC_WRITE_REG32(core_if->host_if->hprt0, hprt0.d32);
+
+						/* Restore interrupts */
+						DWC_WRITE_REG32(&global_regs->gintmsk, gintmsk.d32);
+					} else if (t == 7) {	/* SINGLE_STEP_GET_DEVICE_DESCRIPTOR setup */
+						/* Save current interrupt mask */
+						gintmsk.d32 =
+						    DWC_READ_REG32
+						    (&global_regs->gintmsk);
+
+						/* Disable all interrupts while we muck with
+						 * the hardware directly
+						 */
+						DWC_WRITE_REG32(&global_regs->gintmsk, 0);
+
+						/* 15 second delay per the test spec */
+						dwc_mdelay(15000);
+
+						/* Send the Setup packet */
+						do_setup();
+
+						/* 15 second delay so nothing else happens for awhile */
+						dwc_mdelay(15000);
+
+						/* Restore interrupts */
+						DWC_WRITE_REG32(&global_regs->gintmsk, gintmsk.d32);
+					} else if (t == 8) {	/* SINGLE_STEP_GET_DEVICE_DESCRIPTOR execute */
+						/* Save current interrupt mask */
+						gintmsk.d32 =
+						    DWC_READ_REG32
+						    (&global_regs->gintmsk);
+
+						/* Disable all interrupts while we muck with
+						 * the hardware directly
+						 */
+						DWC_WRITE_REG32(&global_regs->gintmsk, 0);
+
+						/* Send the Setup packet */
+						do_setup();
+
+						/* 15 second delay so nothing else happens for awhile */
+						dwc_mdelay(15000);
+
+						/* Send the In and Ack packets */
+						do_in_ack();
+
+						/* 15 second delay so nothing else happens for awhile */
+						dwc_mdelay(15000);
+
+						/* Restore interrupts */
+						DWC_WRITE_REG32(&global_regs->gintmsk, gintmsk.d32);
+					}
+				}
+				break;
+			}
+#endif /* DWC_HS_ELECT_TST */
+
+		case UHF_PORT_INDICATOR:
+			DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB CONTROL - "
+				    "SetPortFeature - USB_PORT_FEAT_INDICATOR\n");
+			/* Not supported */
+			break;
+		default:
+			retval = -DWC_E_INVALID;
+			DWC_ERROR("DWC OTG HCD - "
+				  "SetPortFeature request %xh "
+				  "unknown or unsupported\n", wValue);
+			break;
+		}
+		break;
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	case UCR_SET_AND_TEST_PORT_FEATURE:
+		if (wValue != UHF_PORT_L1) {
+			goto error;
+		}
+		{
+			int portnum, hird, devaddr, remwake;
+			glpmcfg_data_t lpmcfg;
+			uint32_t time_usecs;
+			gintsts_data_t gintsts;
+			gintmsk_data_t gintmsk;
+
+			if (!dwc_otg_get_param_lpm_enable(core_if)) {
+				goto error;
+			}
+			if (wValue != UHF_PORT_L1 || wLength != 1) {
+				goto error;
+			}
+			/* Check if the port currently is in SLEEP state */
+			lpmcfg.d32 =
+			    DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+			if (lpmcfg.b.prt_sleep_sts) {
+				DWC_INFO("Port is already in sleep mode\n");
+				buf[0] = 0;	/* Return success */
+				break;
+			}
+
+			portnum = wIndex & 0xf;
+			hird = (wIndex >> 4) & 0xf;
+			devaddr = (wIndex >> 8) & 0x7f;
+			remwake = (wIndex >> 15);
+
+			if (portnum != 1) {
+				retval = -DWC_E_INVALID;
+				DWC_WARN
+				    ("Wrong port number(%d) in SetandTestPortFeature request\n",
+				     portnum);
+				break;
+			}
+
+			DWC_PRINTF
+			    ("SetandTestPortFeature request: portnum = %d, hird = %d, devaddr = %d, rewake = %d\n",
+			     portnum, hird, devaddr, remwake);
+			/* Disable LPM interrupt */
+			gintmsk.d32 = 0;
+			gintmsk.b.lpmtranrcvd = 1;
+			DWC_MODIFY_REG32(&core_if->core_global_regs->gintmsk,
+					 gintmsk.d32, 0);
+
+			if (dwc_otg_hcd_send_lpm
+			    (dwc_otg_hcd, devaddr, hird, remwake)) {
+				retval = -DWC_E_INVALID;
+				break;
+			}
+
+			time_usecs = 10 * (lpmcfg.b.retry_count + 1);
+			/* We will consider timeout if time_usecs microseconds pass,
+			 * and we don't receive LPM transaction status.
+			 * After receiving non-error responce(ACK/NYET/STALL) from device,
+			 *  core will set lpmtranrcvd bit.
+			 */
+			do {
+				gintsts.d32 =
+				    DWC_READ_REG32(&core_if->core_global_regs->gintsts);
+				if (gintsts.b.lpmtranrcvd) {
+					break;
+				}
+				dwc_udelay(1);
+			} while (--time_usecs);
+			/* lpm_int bit will be cleared in LPM interrupt handler */
+
+			/* Now fill status
+			 * 0x00 - Success
+			 * 0x10 - NYET
+			 * 0x11 - Timeout
+			 */
+			if (!gintsts.b.lpmtranrcvd) {
+				buf[0] = 0x3;	/* Completion code is Timeout */
+				dwc_otg_hcd_free_hc_from_lpm(dwc_otg_hcd);
+			} else {
+				lpmcfg.d32 =
+				    DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+				if (lpmcfg.b.lpm_resp == 0x3) {
+					/* ACK responce from the device */
+					buf[0] = 0x00;	/* Success */
+				} else if (lpmcfg.b.lpm_resp == 0x2) {
+					/* NYET responce from the device */
+					buf[0] = 0x2;
+				} else {
+					/* Otherwise responce with Timeout */
+					buf[0] = 0x3;
+				}
+			}
+			DWC_PRINTF("Device responce to LPM trans is %x\n",
+				   lpmcfg.b.lpm_resp);
+			DWC_MODIFY_REG32(&core_if->core_global_regs->gintmsk, 0,
+					 gintmsk.d32);
+
+			break;
+		}
+#endif /* CONFIG_USB_DWC_OTG_LPM */
+	default:
+error:
+		retval = -DWC_E_INVALID;
+		DWC_WARN("DWC OTG HCD - "
+			 "Unknown hub control request type or invalid typeReq: %xh wIndex: %xh wValue: %xh\n",
+			 typeReq, wIndex, wValue);
+		break;
+	}
+
+	return retval;
+}
+
+#ifdef CONFIG_USB_DWC_OTG_LPM
+/** Returns index of host channel to perform LPM transaction. */
+int dwc_otg_hcd_get_hc_for_lpm_tran(dwc_otg_hcd_t * hcd, uint8_t devaddr)
+{
+	dwc_otg_core_if_t *core_if = hcd->core_if;
+	dwc_hc_t *hc;
+	hcchar_data_t hcchar;
+	gintmsk_data_t gintmsk = {.d32 = 0 };
+
+	if (DWC_CIRCLEQ_EMPTY(&hcd->free_hc_list)) {
+		DWC_PRINTF("No free channel to select for LPM transaction\n");
+		return -1;
+	}
+
+	hc = DWC_CIRCLEQ_FIRST(&hcd->free_hc_list);
+
+	/* Mask host channel interrupts. */
+	gintmsk.b.hcintr = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gintmsk, gintmsk.d32, 0);
+
+	/* Fill fields that core needs for LPM transaction */
+	hcchar.b.devaddr = devaddr;
+	hcchar.b.epnum = 0;
+	hcchar.b.eptype = DWC_OTG_EP_TYPE_CONTROL;
+	hcchar.b.mps = 64;
+	hcchar.b.lspddev = (hc->speed == DWC_OTG_EP_SPEED_LOW);
+	hcchar.b.epdir = 0;	/* OUT */
+	DWC_WRITE_REG32(&core_if->host_if->hc_regs[hc->hc_num]->hcchar,
+			hcchar.d32);
+
+	/* Remove the host channel from the free list. */
+	DWC_CIRCLEQ_REMOVE_INIT(&hcd->free_hc_list, hc, hc_list_entry);
+
+	DWC_PRINTF("hcnum = %d devaddr = %d\n", hc->hc_num, devaddr);
+
+	return hc->hc_num;
+}
+
+/** Release hc after performing LPM transaction */
+void dwc_otg_hcd_free_hc_from_lpm(dwc_otg_hcd_t * hcd)
+{
+	dwc_hc_t *hc;
+	glpmcfg_data_t lpmcfg;
+	uint8_t hc_num;
+
+	lpmcfg.d32 = DWC_READ_REG32(&hcd->core_if->core_global_regs->glpmcfg);
+	hc_num = lpmcfg.b.lpm_chan_index;
+
+	hc = hcd->hc_ptr_array[hc_num];
+
+	DWC_PRINTF("Freeing channel %d after LPM\n", hc_num);
+	/* Return host channel to free list */
+	DWC_CIRCLEQ_INSERT_TAIL(&hcd->free_hc_list, hc, hc_list_entry);
+}
+
+int dwc_otg_hcd_send_lpm(dwc_otg_hcd_t * hcd, uint8_t devaddr, uint8_t hird,
+			 uint8_t bRemoteWake)
+{
+	glpmcfg_data_t lpmcfg;
+	pcgcctl_data_t pcgcctl = {.d32 = 0 };
+	int channel;
+
+	channel = dwc_otg_hcd_get_hc_for_lpm_tran(hcd, devaddr);
+	if (channel < 0) {
+		return channel;
+	}
+
+	pcgcctl.b.enbl_sleep_gating = 1;
+	DWC_MODIFY_REG32(hcd->core_if->pcgcctl, 0, pcgcctl.d32);
+
+	/* Read LPM config register */
+	lpmcfg.d32 = DWC_READ_REG32(&hcd->core_if->core_global_regs->glpmcfg);
+
+	/* Program LPM transaction fields */
+	lpmcfg.b.rem_wkup_en = bRemoteWake;
+	lpmcfg.b.hird = hird;
+
+	if(dwc_otg_get_param_besl_enable(hcd->core_if)) {
+		lpmcfg.b.hird_thres = 0x16;
+		lpmcfg.b.en_besl = 1;
+	} else {
+		lpmcfg.b.hird_thres = 0x1c;
+	}
+
+	lpmcfg.b.lpm_chan_index = channel;
+	lpmcfg.b.en_utmi_sleep = 1;
+	/* Program LPM config register */
+	DWC_WRITE_REG32(&hcd->core_if->core_global_regs->glpmcfg, lpmcfg.d32);
+
+	/* Send LPM transaction */
+	lpmcfg.b.send_lpm = 1;
+	DWC_WRITE_REG32(&hcd->core_if->core_global_regs->glpmcfg, lpmcfg.d32);
+
+	return 0;
+}
+
+#endif /* CONFIG_USB_DWC_OTG_LPM */
+
+int dwc_otg_hcd_is_status_changed(dwc_otg_hcd_t * hcd, int port)
+{
+	int retval;
+
+	if (port != 1) {
+		return -DWC_E_INVALID;
+	}
+
+	retval = (hcd->flags.b.port_connect_status_change ||
+		  hcd->flags.b.port_reset_change ||
+		  hcd->flags.b.port_enable_change ||
+		  hcd->flags.b.port_suspend_change ||
+		  hcd->flags.b.port_over_current_change);
+#ifdef DEBUG
+	if (retval) {
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD HUB STATUS DATA:"
+			    " Root port status changed\n");
+		DWC_DEBUGPL(DBG_HCDV, "  port_connect_status_change: %d\n",
+			    hcd->flags.b.port_connect_status_change);
+		DWC_DEBUGPL(DBG_HCDV, "  port_reset_change: %d\n",
+			    hcd->flags.b.port_reset_change);
+		DWC_DEBUGPL(DBG_HCDV, "  port_enable_change: %d\n",
+			    hcd->flags.b.port_enable_change);
+		DWC_DEBUGPL(DBG_HCDV, "  port_suspend_change: %d\n",
+			    hcd->flags.b.port_suspend_change);
+		DWC_DEBUGPL(DBG_HCDV, "  port_over_current_change: %d\n",
+			    hcd->flags.b.port_over_current_change);
+	}
+#endif
+	return retval;
+}
+
+int dwc_otg_hcd_get_frame_number(dwc_otg_hcd_t * dwc_otg_hcd)
+{
+	hfnum_data_t hfnum;
+	hfnum.d32 =
+	    DWC_READ_REG32(&dwc_otg_hcd->core_if->host_if->host_global_regs->
+			   hfnum);
+
+#ifdef DEBUG_SOF
+	DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD GET FRAME NUMBER %d\n",
+		    hfnum.b.frnum);
+#endif
+	return hfnum.b.frnum;
+}
+
+int dwc_otg_hcd_start(dwc_otg_hcd_t * hcd,
+		      struct dwc_otg_hcd_function_ops *fops)
+{
+	int retval = 0;
+	hprt0_data_t hprt0;
+
+	hcd->fops = fops;
+	if (!dwc_otg_is_device_mode(hcd->core_if) &&
+		(!hcd->core_if->adp_enable || hcd->core_if->adp.adp_started)) {
+		dwc_otg_hcd_reinit(hcd);
+	} else {
+		if (hcd->core_if->adp_enable) {
+			/* Clear any interrupt pending in the HPRT, sometimes
+			 * Port Connect Detected is not being cleared*/
+			hprt0.d32 = DWC_READ_REG32(hcd->core_if->host_if->hprt0);
+			DWC_WRITE_REG32(hcd->core_if->host_if->hprt0, hprt0.d32);
+		}
+		retval = -DWC_E_NO_DEVICE;
+	}
+
+	return retval;
+}
+
+void *dwc_otg_hcd_get_priv_data(dwc_otg_hcd_t * hcd)
+{
+	return hcd->priv;
+}
+
+void dwc_otg_hcd_set_priv_data(dwc_otg_hcd_t * hcd, void *priv_data)
+{
+	hcd->priv = priv_data;
+}
+
+uint32_t dwc_otg_hcd_otg_port(dwc_otg_hcd_t * hcd)
+{
+	return hcd->otg_port;
+}
+
+uint32_t dwc_otg_hcd_is_b_host(dwc_otg_hcd_t * hcd)
+{
+	uint32_t is_b_host;
+	if (hcd->core_if->op_state == B_HOST) {
+		is_b_host = 1;
+	} else {
+		is_b_host = 0;
+	}
+
+	return is_b_host;
+}
+
+dwc_otg_hcd_urb_t *dwc_otg_hcd_urb_alloc(dwc_otg_hcd_t * hcd,
+					 int iso_desc_count, int atomic_alloc)
+{
+	dwc_otg_hcd_urb_t *dwc_otg_urb;
+	uint32_t size;
+
+	size =
+	    sizeof(*dwc_otg_urb) +
+	    iso_desc_count * sizeof(struct dwc_otg_hcd_iso_packet_desc);
+	if (atomic_alloc)
+		dwc_otg_urb = DWC_ALLOC_ATOMIC(size);
+	else
+		dwc_otg_urb = DWC_ALLOC(size);
+
+	dwc_otg_urb->packet_count = iso_desc_count;
+
+	return dwc_otg_urb;
+}
+
+void dwc_otg_hcd_urb_set_pipeinfo(dwc_otg_hcd_urb_t * dwc_otg_urb,
+				  uint8_t dev_addr, uint8_t ep_num,
+				  uint8_t ep_type, uint8_t ep_dir, uint16_t mps)
+{
+	dwc_otg_hcd_fill_pipe(&dwc_otg_urb->pipe_info, dev_addr, ep_num,
+			      ep_type, ep_dir, mps);
+}
+
+void dwc_otg_hcd_urb_set_params(dwc_otg_hcd_urb_t * dwc_otg_urb,
+				void *urb_handle, void *buf, dwc_dma_t dma,
+				uint32_t buflen, void *setup_packet,
+				dwc_dma_t setup_dma, uint32_t flags,
+				uint16_t interval)
+{
+	dwc_otg_urb->priv = urb_handle;
+	dwc_otg_urb->buf = buf;
+	dwc_otg_urb->dma = dma;
+	dwc_otg_urb->length = buflen;
+	dwc_otg_urb->setup_packet = setup_packet;
+	dwc_otg_urb->setup_dma = setup_dma;
+	dwc_otg_urb->flags = flags;
+	dwc_otg_urb->interval = interval;
+	dwc_otg_urb->status = -DWC_E_IN_PROGRESS;
+}
+
+uint32_t dwc_otg_hcd_urb_get_status(dwc_otg_hcd_urb_t * dwc_otg_urb)
+{
+	return dwc_otg_urb->status;
+}
+
+uint32_t dwc_otg_hcd_urb_get_actual_length(dwc_otg_hcd_urb_t * dwc_otg_urb)
+{
+	return dwc_otg_urb->actual_length;
+}
+
+uint32_t dwc_otg_hcd_urb_get_error_count(dwc_otg_hcd_urb_t * dwc_otg_urb)
+{
+	return dwc_otg_urb->error_count;
+}
+
+void dwc_otg_hcd_urb_set_iso_desc_params(dwc_otg_hcd_urb_t * dwc_otg_urb,
+					 int desc_num, uint32_t offset,
+					 uint32_t length)
+{
+	dwc_otg_urb->iso_descs[desc_num].offset = offset;
+	dwc_otg_urb->iso_descs[desc_num].length = length;
+}
+
+uint32_t dwc_otg_hcd_urb_get_iso_desc_status(dwc_otg_hcd_urb_t * dwc_otg_urb,
+					     int desc_num)
+{
+	return dwc_otg_urb->iso_descs[desc_num].status;
+}
+
+uint32_t dwc_otg_hcd_urb_get_iso_desc_actual_length(dwc_otg_hcd_urb_t *
+						    dwc_otg_urb, int desc_num)
+{
+	return dwc_otg_urb->iso_descs[desc_num].actual_length;
+}
+
+int dwc_otg_hcd_is_bandwidth_allocated(dwc_otg_hcd_t * hcd, void *ep_handle)
+{
+	int allocated = 0;
+	dwc_otg_qh_t *qh = (dwc_otg_qh_t *) ep_handle;
+
+	if (qh) {
+		if (!DWC_LIST_EMPTY(&qh->qh_list_entry)) {
+			allocated = 1;
+		}
+	}
+	return allocated;
+}
+
+int dwc_otg_hcd_is_bandwidth_freed(dwc_otg_hcd_t * hcd, void *ep_handle)
+{
+	dwc_otg_qh_t *qh = (dwc_otg_qh_t *) ep_handle;
+	int freed = 0;
+	DWC_ASSERT(qh, "qh is not allocated\n");
+
+	if (DWC_LIST_EMPTY(&qh->qh_list_entry)) {
+		freed = 1;
+	}
+
+	return freed;
+}
+
+uint8_t dwc_otg_hcd_get_ep_bandwidth(dwc_otg_hcd_t * hcd, void *ep_handle)
+{
+	dwc_otg_qh_t *qh = (dwc_otg_qh_t *) ep_handle;
+	DWC_ASSERT(qh, "qh is not allocated\n");
+	return qh->usecs;
+}
+
+void dwc_otg_hcd_dump_state(dwc_otg_hcd_t * hcd)
+{
+#ifdef DEBUG
+	int num_channels;
+	int i;
+	gnptxsts_data_t np_tx_status;
+	hptxsts_data_t p_tx_status;
+
+	num_channels = hcd->core_if->core_params->host_channels;
+	DWC_PRINTF("\n");
+	DWC_PRINTF
+	    ("************************************************************\n");
+	DWC_PRINTF("HCD State:\n");
+	DWC_PRINTF("  Num channels: %d\n", num_channels);
+	for (i = 0; i < num_channels; i++) {
+		dwc_hc_t *hc = hcd->hc_ptr_array[i];
+		DWC_PRINTF("  Channel %d:\n", i);
+		DWC_PRINTF("    dev_addr: %d, ep_num: %d, ep_is_in: %d\n",
+			   hc->dev_addr, hc->ep_num, hc->ep_is_in);
+		DWC_PRINTF("    speed: %d\n", hc->speed);
+		DWC_PRINTF("    ep_type: %d\n", hc->ep_type);
+		DWC_PRINTF("    max_packet: %d\n", hc->max_packet);
+		DWC_PRINTF("    data_pid_start: %d\n", hc->data_pid_start);
+		DWC_PRINTF("    multi_count: %d\n", hc->multi_count);
+		DWC_PRINTF("    xfer_started: %d\n", hc->xfer_started);
+		DWC_PRINTF("    xfer_buff: %p\n", hc->xfer_buff);
+		DWC_PRINTF("    xfer_len: %d\n", hc->xfer_len);
+		DWC_PRINTF("    xfer_count: %d\n", hc->xfer_count);
+		DWC_PRINTF("    halt_on_queue: %d\n", hc->halt_on_queue);
+		DWC_PRINTF("    halt_pending: %d\n", hc->halt_pending);
+		DWC_PRINTF("    halt_status: %d\n", hc->halt_status);
+		DWC_PRINTF("    do_split: %d\n", hc->do_split);
+		DWC_PRINTF("    complete_split: %d\n", hc->complete_split);
+		DWC_PRINTF("    hub_addr: %d\n", hc->hub_addr);
+		DWC_PRINTF("    port_addr: %d\n", hc->port_addr);
+		DWC_PRINTF("    xact_pos: %d\n", hc->xact_pos);
+		DWC_PRINTF("    requests: %d\n", hc->requests);
+		DWC_PRINTF("    qh: %p\n", hc->qh);
+		if (hc->xfer_started) {
+			hfnum_data_t hfnum;
+			hcchar_data_t hcchar;
+			hctsiz_data_t hctsiz;
+			hcint_data_t hcint;
+			hcintmsk_data_t hcintmsk;
+			hfnum.d32 =
+			    DWC_READ_REG32(&hcd->core_if->
+					   host_if->host_global_regs->hfnum);
+			hcchar.d32 =
+			    DWC_READ_REG32(&hcd->core_if->host_if->
+					   hc_regs[i]->hcchar);
+			hctsiz.d32 =
+			    DWC_READ_REG32(&hcd->core_if->host_if->
+					   hc_regs[i]->hctsiz);
+			hcint.d32 =
+			    DWC_READ_REG32(&hcd->core_if->host_if->
+					   hc_regs[i]->hcint);
+			hcintmsk.d32 =
+			    DWC_READ_REG32(&hcd->core_if->host_if->
+					   hc_regs[i]->hcintmsk);
+			DWC_PRINTF("    hfnum: 0x%08x\n", hfnum.d32);
+			DWC_PRINTF("    hcchar: 0x%08x\n", hcchar.d32);
+			DWC_PRINTF("    hctsiz: 0x%08x\n", hctsiz.d32);
+			DWC_PRINTF("    hcint: 0x%08x\n", hcint.d32);
+			DWC_PRINTF("    hcintmsk: 0x%08x\n", hcintmsk.d32);
+		}
+		if (hc->xfer_started && hc->qh) {
+			dwc_otg_qtd_t *qtd;
+			dwc_otg_hcd_urb_t *urb;
+
+			DWC_CIRCLEQ_FOREACH(qtd, &hc->qh->qtd_list, qtd_list_entry) {
+				if (!qtd->in_process)
+					break;
+
+				urb = qtd->urb;
+			DWC_PRINTF("    URB Info:\n");
+			DWC_PRINTF("      qtd: %p, urb: %p\n", qtd, urb);
+			if (urb) {
+				DWC_PRINTF("      Dev: %d, EP: %d %s\n",
+					   dwc_otg_hcd_get_dev_addr(&urb->
+								    pipe_info),
+					   dwc_otg_hcd_get_ep_num(&urb->
+								  pipe_info),
+					   dwc_otg_hcd_is_pipe_in(&urb->
+								  pipe_info) ?
+					   "IN" : "OUT");
+				DWC_PRINTF("      Max packet size: %d\n",
+					   dwc_otg_hcd_get_mps(&urb->
+							       pipe_info));
+				DWC_PRINTF("      transfer_buffer: %p\n",
+					   urb->buf);
+				DWC_PRINTF("      transfer_dma: %p\n",
+					   (void *)urb->dma);
+				DWC_PRINTF("      transfer_buffer_length: %d\n",
+					   urb->length);
+					DWC_PRINTF("      actual_length: %d\n",
+						   urb->actual_length);
+				}
+			}
+		}
+	}
+	DWC_PRINTF("  non_periodic_channels: %d\n", hcd->non_periodic_channels);
+	DWC_PRINTF("  periodic_channels: %d\n", hcd->periodic_channels);
+	DWC_PRINTF("  periodic_usecs: %d\n", hcd->periodic_usecs);
+	np_tx_status.d32 =
+	    DWC_READ_REG32(&hcd->core_if->core_global_regs->gnptxsts);
+	DWC_PRINTF("  NP Tx Req Queue Space Avail: %d\n",
+		   np_tx_status.b.nptxqspcavail);
+	DWC_PRINTF("  NP Tx FIFO Space Avail: %d\n",
+		   np_tx_status.b.nptxfspcavail);
+	p_tx_status.d32 =
+	    DWC_READ_REG32(&hcd->core_if->host_if->host_global_regs->hptxsts);
+	DWC_PRINTF("  P Tx Req Queue Space Avail: %d\n",
+		   p_tx_status.b.ptxqspcavail);
+	DWC_PRINTF("  P Tx FIFO Space Avail: %d\n", p_tx_status.b.ptxfspcavail);
+	dwc_otg_hcd_dump_frrem(hcd);
+	dwc_otg_dump_global_registers(hcd->core_if);
+	dwc_otg_dump_host_registers(hcd->core_if);
+	DWC_PRINTF
+	    ("************************************************************\n");
+	DWC_PRINTF("\n");
+#endif
+}
+
+#ifdef DEBUG
+void dwc_print_setup_data(uint8_t * setup)
+{
+	int i;
+	if (CHK_DEBUG_LEVEL(DBG_HCD)) {
+		DWC_PRINTF("Setup Data = MSB ");
+		for (i = 7; i >= 0; i--)
+			DWC_PRINTF("%02x ", setup[i]);
+		DWC_PRINTF("\n");
+		DWC_PRINTF("  bmRequestType Tranfer = %s\n",
+			   (setup[0] & 0x80) ? "Device-to-Host" :
+			   "Host-to-Device");
+		DWC_PRINTF("  bmRequestType Type = ");
+		switch ((setup[0] & 0x60) >> 5) {
+		case 0:
+			DWC_PRINTF("Standard\n");
+			break;
+		case 1:
+			DWC_PRINTF("Class\n");
+			break;
+		case 2:
+			DWC_PRINTF("Vendor\n");
+			break;
+		case 3:
+			DWC_PRINTF("Reserved\n");
+			break;
+		}
+		DWC_PRINTF("  bmRequestType Recipient = ");
+		switch (setup[0] & 0x1f) {
+		case 0:
+			DWC_PRINTF("Device\n");
+			break;
+		case 1:
+			DWC_PRINTF("Interface\n");
+			break;
+		case 2:
+			DWC_PRINTF("Endpoint\n");
+			break;
+		case 3:
+			DWC_PRINTF("Other\n");
+			break;
+		default:
+			DWC_PRINTF("Reserved\n");
+			break;
+		}
+		DWC_PRINTF("  bRequest = 0x%0x\n", setup[1]);
+		DWC_PRINTF("  wValue = 0x%0x\n", *((uint16_t *) & setup[2]));
+		DWC_PRINTF("  wIndex = 0x%0x\n", *((uint16_t *) & setup[4]));
+		DWC_PRINTF("  wLength = 0x%0x\n\n", *((uint16_t *) & setup[6]));
+	}
+}
+#endif
+
+void dwc_otg_hcd_dump_frrem(dwc_otg_hcd_t * hcd)
+{
+}
+
+#endif /* DWC_DEVICE_ONLY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd.h
new file mode 100644
index 0000000..23eea36
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd.h
@@ -0,0 +1,803 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_hcd.h $
+ * $Revision: #58 $
+ * $Date: 2011/09/15 $
+ * $Change: 1846647 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef DWC_DEVICE_ONLY
+#ifndef __DWC_HCD_H__
+#define __DWC_HCD_H__
+
+#include "dwc_otg_os_dep.h"
+#include "usb.h"
+#include "dwc_otg_hcd_if.h"
+#include "dwc_otg_core_if.h"
+#include "dwc_list.h"
+#include "dwc_otg_cil.h"
+
+/**
+ * @file
+ *
+ * This file contains the structures, constants, and interfaces for
+ * the Host Contoller Driver (HCD).
+ *
+ * The Host Controller Driver (HCD) is responsible for translating requests
+ * from the USB Driver into the appropriate actions on the DWC_otg controller.
+ * It isolates the USBD from the specifics of the controller by providing an
+ * API to the USBD.
+ */
+
+struct dwc_otg_hcd_pipe_info {
+	uint8_t dev_addr;
+	uint8_t ep_num;
+	uint8_t pipe_type;
+	uint8_t pipe_dir;
+	uint16_t mps;
+};
+
+struct dwc_otg_hcd_iso_packet_desc {
+	uint32_t offset;
+	uint32_t length;
+	uint32_t actual_length;
+	uint32_t status;
+};
+
+struct dwc_otg_qtd;
+
+struct dwc_otg_hcd_urb {
+	void *priv;
+	struct dwc_otg_qtd *qtd;
+	void *buf;
+	dwc_dma_t dma;
+	void *setup_packet;
+	dwc_dma_t setup_dma;
+	uint32_t length;
+	uint32_t actual_length;
+	uint32_t status;
+	uint32_t error_count;
+	uint32_t packet_count;
+	uint32_t flags;
+	uint16_t interval;
+	struct dwc_otg_hcd_pipe_info pipe_info;
+	struct dwc_otg_hcd_iso_packet_desc iso_descs[0];
+};
+
+static inline uint8_t dwc_otg_hcd_get_ep_num(struct dwc_otg_hcd_pipe_info *pipe)
+{
+	return pipe->ep_num;
+}
+
+static inline uint8_t dwc_otg_hcd_get_pipe_type(struct dwc_otg_hcd_pipe_info
+						*pipe)
+{
+	return pipe->pipe_type;
+}
+
+static inline uint16_t dwc_otg_hcd_get_mps(struct dwc_otg_hcd_pipe_info *pipe)
+{
+	return pipe->mps;
+}
+
+static inline uint8_t dwc_otg_hcd_get_dev_addr(struct dwc_otg_hcd_pipe_info
+					       *pipe)
+{
+	return pipe->dev_addr;
+}
+
+static inline uint8_t dwc_otg_hcd_is_pipe_isoc(struct dwc_otg_hcd_pipe_info
+					       *pipe)
+{
+	return (pipe->pipe_type == UE_ISOCHRONOUS);
+}
+
+static inline uint8_t dwc_otg_hcd_is_pipe_int(struct dwc_otg_hcd_pipe_info
+					      *pipe)
+{
+	return (pipe->pipe_type == UE_INTERRUPT);
+}
+
+static inline uint8_t dwc_otg_hcd_is_pipe_bulk(struct dwc_otg_hcd_pipe_info
+					       *pipe)
+{
+	return (pipe->pipe_type == UE_BULK);
+}
+
+static inline uint8_t dwc_otg_hcd_is_pipe_control(struct dwc_otg_hcd_pipe_info
+						  *pipe)
+{
+	return (pipe->pipe_type == UE_CONTROL);
+}
+
+static inline uint8_t dwc_otg_hcd_is_pipe_in(struct dwc_otg_hcd_pipe_info *pipe)
+{
+	return (pipe->pipe_dir == UE_DIR_IN);
+}
+
+static inline uint8_t dwc_otg_hcd_is_pipe_out(struct dwc_otg_hcd_pipe_info
+					      *pipe)
+{
+	return (!dwc_otg_hcd_is_pipe_in(pipe));
+}
+
+static inline void dwc_otg_hcd_fill_pipe(struct dwc_otg_hcd_pipe_info *pipe,
+					 uint8_t devaddr, uint8_t ep_num,
+					 uint8_t pipe_type, uint8_t pipe_dir,
+					 uint16_t mps)
+{
+	pipe->dev_addr = devaddr;
+	pipe->ep_num = ep_num;
+	pipe->pipe_type = pipe_type;
+	pipe->pipe_dir = pipe_dir;
+	pipe->mps = mps;
+}
+
+/**
+ * Phases for control transfers.
+ */
+typedef enum dwc_otg_control_phase {
+	DWC_OTG_CONTROL_SETUP,
+	DWC_OTG_CONTROL_DATA,
+	DWC_OTG_CONTROL_STATUS
+} dwc_otg_control_phase_e;
+
+/** Transaction types. */
+typedef enum dwc_otg_transaction_type {
+	DWC_OTG_TRANSACTION_NONE,
+	DWC_OTG_TRANSACTION_PERIODIC,
+	DWC_OTG_TRANSACTION_NON_PERIODIC,
+	DWC_OTG_TRANSACTION_ALL
+} dwc_otg_transaction_type_e;
+
+struct dwc_otg_qh;
+
+/**
+ * A Queue Transfer Descriptor (QTD) holds the state of a bulk, control,
+ * interrupt, or isochronous transfer. A single QTD is created for each URB
+ * (of one of these types) submitted to the HCD. The transfer associated with
+ * a QTD may require one or multiple transactions.
+ *
+ * A QTD is linked to a Queue Head, which is entered in either the
+ * non-periodic or periodic schedule for execution. When a QTD is chosen for
+ * execution, some or all of its transactions may be executed. After
+ * execution, the state of the QTD is updated. The QTD may be retired if all
+ * its transactions are complete or if an error occurred. Otherwise, it
+ * remains in the schedule so more transactions can be executed later.
+ */
+typedef struct dwc_otg_qtd {
+	/**
+	 * Determines the PID of the next data packet for the data phase of
+	 * control transfers. Ignored for other transfer types.<br>
+	 * One of the following values:
+	 *	- DWC_OTG_HC_PID_DATA0
+	 *	- DWC_OTG_HC_PID_DATA1
+	 */
+	uint8_t data_toggle;
+
+	/** Current phase for control transfers (Setup, Data, or Status). */
+	dwc_otg_control_phase_e control_phase;
+
+	/** Keep track of the current split type
+	 * for FS/LS endpoints on a HS Hub */
+	uint8_t complete_split;
+
+	/** How many bytes transferred during SSPLIT OUT */
+	uint32_t ssplit_out_xfer_count;
+
+	/**
+	 * Holds the number of bus errors that have occurred for a transaction
+	 * within this transfer.
+	 */
+	uint8_t error_count;
+
+	/**
+	 * Index of the next frame descriptor for an isochronous transfer. A
+	 * frame descriptor describes the buffer position and length of the
+	 * data to be transferred in the next scheduled (micro)frame of an
+	 * isochronous transfer. It also holds status for that transaction.
+	 * The frame index starts at 0.
+	 */
+	uint16_t isoc_frame_index;
+
+	/** Position of the ISOC split on full/low speed */
+	uint8_t isoc_split_pos;
+
+	/** Position of the ISOC split in the buffer for the current frame */
+	uint16_t isoc_split_offset;
+
+	/** URB for this transfer */
+	struct dwc_otg_hcd_urb *urb;
+
+	struct dwc_otg_qh *qh;
+
+	/** This list of QTDs */
+	 DWC_CIRCLEQ_ENTRY(dwc_otg_qtd) qtd_list_entry;
+
+	/** Indicates if this QTD is currently processed by HW. */
+	uint8_t in_process;
+
+	/** Number of DMA descriptors for this QTD */
+	uint8_t n_desc;
+
+	/**
+	 * Last activated frame(packet) index.
+	 * Used in Descriptor DMA mode only.
+	 */
+	uint16_t isoc_frame_index_last;
+
+} dwc_otg_qtd_t;
+
+DWC_CIRCLEQ_HEAD(dwc_otg_qtd_list, dwc_otg_qtd);
+
+/**
+ * A Queue Head (QH) holds the static characteristics of an endpoint and
+ * maintains a list of transfers (QTDs) for that endpoint. A QH structure may
+ * be entered in either the non-periodic or periodic schedule.
+ */
+typedef struct dwc_otg_qh {
+	/**
+	 * Endpoint type.
+	 * One of the following values:
+	 *	- UE_CONTROL
+	 *	- UE_BULK
+	 *	- UE_INTERRUPT
+	 *	- UE_ISOCHRONOUS
+	 */
+	uint8_t ep_type;
+	uint8_t ep_is_in;
+
+	/** wMaxPacketSize Field of Endpoint Descriptor. */
+	uint16_t maxp;
+
+	/**
+	 * Device speed.
+	 * One of the following values:
+	 *	- DWC_OTG_EP_SPEED_LOW
+	 *	- DWC_OTG_EP_SPEED_FULL
+	 *	- DWC_OTG_EP_SPEED_HIGH
+	 */
+	uint8_t dev_speed;
+
+	/**
+	 * Determines the PID of the next data packet for non-control
+	 * transfers. Ignored for control transfers.<br>
+	 * One of the following values:
+	 *	- DWC_OTG_HC_PID_DATA0
+	 *	- DWC_OTG_HC_PID_DATA1
+	 */
+	uint8_t data_toggle;
+
+	/** Ping state if 1. */
+	uint8_t ping_state;
+
+	/**
+	 * List of QTDs for this QH.
+	 */
+	struct dwc_otg_qtd_list qtd_list;
+
+	/** Host channel currently processing transfers for this QH. */
+	struct dwc_hc *channel;
+
+	/** Full/low speed endpoint on high-speed hub requires split. */
+	uint8_t do_split;
+
+	/** @name Periodic schedule information */
+	/** @{ */
+
+	/** Bandwidth in microseconds per (micro)frame. */
+	uint16_t usecs;
+
+	/** Interval between transfers in (micro)frames. */
+	uint16_t interval;
+
+	/**
+	 * (micro)frame to initialize a periodic transfer. The transfer
+	 * executes in the following (micro)frame.
+	 */
+	uint16_t sched_frame;
+
+	/** (micro)frame at which last start split was initialized. */
+	uint16_t start_split_frame;
+
+	/** @} */
+
+	/**
+	 * Used instead of original buffer if
+	 * it(physical address) is not dword-aligned.
+	 */
+	uint8_t *dw_align_buf;
+	dwc_dma_t dw_align_buf_dma;
+
+	/** Entry for QH in either the periodic or non-periodic schedule. */
+	dwc_list_link_t qh_list_entry;
+
+	/** @name Descriptor DMA support */
+	/** @{ */
+
+	/** Descriptor List. */
+	dwc_otg_host_dma_desc_t *desc_list;
+
+	/** Descriptor List physical address. */
+	dwc_dma_t desc_list_dma;
+
+	/**
+	 * Xfer Bytes array.
+	 * Each element corresponds to a descriptor and indicates
+	 * original XferSize size value for the descriptor.
+	 */
+	uint32_t *n_bytes;
+
+	/** Actual number of transfer descriptors in a list. */
+	uint16_t ntd;
+
+	/** First activated isochronous transfer descriptor index. */
+	uint8_t td_first;
+	/** Last activated isochronous transfer descriptor index. */
+	uint8_t td_last;
+
+	/** @} */
+
+} dwc_otg_qh_t;
+
+DWC_CIRCLEQ_HEAD(hc_list, dwc_hc);
+
+/**
+ * This structure holds the state of the HCD, including the non-periodic and
+ * periodic schedules.
+ */
+struct dwc_otg_hcd {
+	/** The DWC otg device pointer */
+	struct dwc_otg_device *otg_dev;
+	/** DWC OTG Core Interface Layer */
+	dwc_otg_core_if_t *core_if;
+
+	/** Function HCD driver callbacks */
+	struct dwc_otg_hcd_function_ops *fops;
+
+	/** Internal DWC HCD Flags */
+	volatile union dwc_otg_hcd_internal_flags {
+		uint32_t d32;
+		struct {
+			unsigned port_connect_status_change:1;
+			unsigned port_connect_status:1;
+			unsigned port_reset_change:1;
+			unsigned port_enable_change:1;
+			unsigned port_suspend_change:1;
+			unsigned port_over_current_change:1;
+			unsigned port_l1_change:1;
+			unsigned reserved:26;
+		} b;
+	} flags;
+
+	/**
+	 * Inactive items in the non-periodic schedule. This is a list of
+	 * Queue Heads. Transfers associated with these Queue Heads are not
+	 * currently assigned to a host channel.
+	 */
+	dwc_list_link_t non_periodic_sched_inactive;
+
+	/**
+	 * Active items in the non-periodic schedule. This is a list of
+	 * Queue Heads. Transfers associated with these Queue Heads are
+	 * currently assigned to a host channel.
+	 */
+	dwc_list_link_t non_periodic_sched_active;
+
+	/**
+	 * Pointer to the next Queue Head to process in the active
+	 * non-periodic schedule.
+	 */
+	dwc_list_link_t *non_periodic_qh_ptr;
+
+	/**
+	 * Inactive items in the periodic schedule. This is a list of QHs for
+	 * periodic transfers that are _not_ scheduled for the next frame.
+	 * Each QH in the list has an interval counter that determines when it
+	 * needs to be scheduled for execution. This scheduling mechanism
+	 * allows only a simple calculation for periodic bandwidth used (i.e.
+	 * must assume that all periodic transfers may need to execute in the
+	 * same frame). However, it greatly simplifies scheduling and should
+	 * be sufficient for the vast majority of OTG hosts, which need to
+	 * connect to a small number of peripherals at one time.
+	 *
+	 * Items move from this list to periodic_sched_ready when the QH
+	 * interval counter is 0 at SOF.
+	 */
+	dwc_list_link_t periodic_sched_inactive;
+
+	/**
+	 * List of periodic QHs that are ready for execution in the next
+	 * frame, but have not yet been assigned to host channels.
+	 *
+	 * Items move from this list to periodic_sched_assigned as host
+	 * channels become available during the current frame.
+	 */
+	dwc_list_link_t periodic_sched_ready;
+
+	/**
+	 * List of periodic QHs to be executed in the next frame that are
+	 * assigned to host channels.
+	 *
+	 * Items move from this list to periodic_sched_queued as the
+	 * transactions for the QH are queued to the DWC_otg controller.
+	 */
+	dwc_list_link_t periodic_sched_assigned;
+
+	/**
+	 * List of periodic QHs that have been queued for execution.
+	 *
+	 * Items move from this list to either periodic_sched_inactive or
+	 * periodic_sched_ready when the channel associated with the transfer
+	 * is released. If the interval for the QH is 1, the item moves to
+	 * periodic_sched_ready because it must be rescheduled for the next
+	 * frame. Otherwise, the item moves to periodic_sched_inactive.
+	 */
+	dwc_list_link_t periodic_sched_queued;
+
+	/**
+	 * Total bandwidth claimed so far for periodic transfers. This value
+	 * is in microseconds per (micro)frame. The assumption is that all
+	 * periodic transfers may occur in the same (micro)frame.
+	 */
+	uint16_t periodic_usecs;
+
+	/**
+	 * Frame number read from the core at SOF. The value ranges from 0 to
+	 * DWC_HFNUM_MAX_FRNUM.
+	 */
+	uint16_t frame_number;
+
+	/**
+	 * Count of periodic QHs, if using several eps. For SOF enable/disable.
+	 */
+	uint16_t periodic_qh_count;
+
+	/**
+	 * Free host channels in the controller. This is a list of
+	 * dwc_hc_t items.
+	 */
+	struct hc_list free_hc_list;
+	/**
+	 * Number of host channels assigned to periodic transfers. Currently
+	 * assuming that there is a dedicated host channel for each periodic
+	 * transaction and at least one host channel available for
+	 * non-periodic transactions.
+	 */
+	int periodic_channels;
+
+	/**
+	 * Number of host channels assigned to non-periodic transfers.
+	 */
+	int non_periodic_channels;
+
+	/**
+	 * Array of pointers to the host channel descriptors. Allows accessing
+	 * a host channel descriptor given the host channel number. This is
+	 * useful in interrupt handlers.
+	 */
+	struct dwc_hc *hc_ptr_array[MAX_EPS_CHANNELS];
+
+	/**
+	 * Buffer to use for any data received during the status phase of a
+	 * control transfer. Normally no data is transferred during the status
+	 * phase. This buffer is used as a bit bucket.
+	 */
+	uint8_t *status_buf;
+
+	/**
+	 * DMA address for status_buf.
+	 */
+	dma_addr_t status_buf_dma;
+#define DWC_OTG_HCD_STATUS_BUF_SIZE 64
+
+	/**
+	 * Connection timer. An OTG host must display a message if the device
+	 * does not connect. Started when the VBus power is turned on via
+	 * sysfs attribute "buspower".
+	 */
+	dwc_timer_t *conn_timer;
+
+	/* Tasket to do a reset */
+	dwc_tasklet_t *reset_tasklet;
+
+	/*  */
+	dwc_spinlock_t *lock;
+
+	/**
+	 * Private data that could be used by OS wrapper.
+	 */
+	void *priv;
+
+	uint8_t otg_port;
+
+	/** Frame List */
+	uint32_t *frame_list;
+
+	/** Frame List DMA address */
+	dma_addr_t frame_list_dma;
+
+#ifdef DEBUG
+	uint32_t frrem_samples;
+	uint64_t frrem_accum;
+
+	uint32_t hfnum_7_samples_a;
+	uint64_t hfnum_7_frrem_accum_a;
+	uint32_t hfnum_0_samples_a;
+	uint64_t hfnum_0_frrem_accum_a;
+	uint32_t hfnum_other_samples_a;
+	uint64_t hfnum_other_frrem_accum_a;
+
+	uint32_t hfnum_7_samples_b;
+	uint64_t hfnum_7_frrem_accum_b;
+	uint32_t hfnum_0_samples_b;
+	uint64_t hfnum_0_frrem_accum_b;
+	uint32_t hfnum_other_samples_b;
+	uint64_t hfnum_other_frrem_accum_b;
+#endif
+};
+
+/** @name Transaction Execution Functions */
+/** @{ */
+extern dwc_otg_transaction_type_e dwc_otg_hcd_select_transactions(dwc_otg_hcd_t
+								  * hcd);
+extern void dwc_otg_hcd_queue_transactions(dwc_otg_hcd_t * hcd,
+					   dwc_otg_transaction_type_e tr_type);
+
+/** @} */
+
+/** @name Interrupt Handler Functions */
+/** @{ */
+extern int32_t dwc_otg_hcd_handle_intr(dwc_otg_hcd_t * dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_sof_intr(dwc_otg_hcd_t * dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_rx_status_q_level_intr(dwc_otg_hcd_t *
+							 dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_np_tx_fifo_empty_intr(dwc_otg_hcd_t *
+							dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_perio_tx_fifo_empty_intr(dwc_otg_hcd_t *
+							   dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_incomplete_periodic_intr(dwc_otg_hcd_t *
+							   dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_port_intr(dwc_otg_hcd_t * dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_conn_id_status_change_intr(dwc_otg_hcd_t *
+							     dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_disconnect_intr(dwc_otg_hcd_t * dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_hc_intr(dwc_otg_hcd_t * dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_hc_n_intr(dwc_otg_hcd_t * dwc_otg_hcd,
+					    uint32_t num);
+extern int32_t dwc_otg_hcd_handle_session_req_intr(dwc_otg_hcd_t * dwc_otg_hcd);
+extern int32_t dwc_otg_hcd_handle_wakeup_detected_intr(dwc_otg_hcd_t *
+						       dwc_otg_hcd);
+/** @} */
+
+/** @name Schedule Queue Functions */
+/** @{ */
+
+/* Implemented in dwc_otg_hcd_queue.c */
+extern dwc_otg_qh_t *dwc_otg_hcd_qh_create(dwc_otg_hcd_t * hcd,
+					   dwc_otg_hcd_urb_t * urb, int atomic_alloc);
+extern void dwc_otg_hcd_qh_free(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh);
+extern int dwc_otg_hcd_qh_add(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh);
+extern void dwc_otg_hcd_qh_remove(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh);
+extern void dwc_otg_hcd_qh_deactivate(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh,
+				      int sched_csplit);
+
+/** Remove and free a QH */
+static inline void dwc_otg_hcd_qh_remove_and_free(dwc_otg_hcd_t * hcd,
+						  dwc_otg_qh_t * qh)
+{
+	dwc_irqflags_t flags;
+	DWC_SPINLOCK_IRQSAVE(hcd->lock, &flags);
+	dwc_otg_hcd_qh_remove(hcd, qh);
+	DWC_SPINUNLOCK_IRQRESTORE(hcd->lock, flags);
+	dwc_otg_hcd_qh_free(hcd, qh);
+}
+
+/** Allocates memory for a QH structure.
+ * @return Returns the memory allocate or NULL on error. */
+static inline dwc_otg_qh_t *dwc_otg_hcd_qh_alloc(int atomic_alloc)
+{
+	if (atomic_alloc)
+		return (dwc_otg_qh_t *) DWC_ALLOC_ATOMIC(sizeof(dwc_otg_qh_t));
+	else
+		return (dwc_otg_qh_t *) DWC_ALLOC(sizeof(dwc_otg_qh_t));
+}
+
+extern dwc_otg_qtd_t *dwc_otg_hcd_qtd_create(dwc_otg_hcd_urb_t * urb,
+					     int atomic_alloc);
+extern void dwc_otg_hcd_qtd_init(dwc_otg_qtd_t * qtd, dwc_otg_hcd_urb_t * urb);
+extern int dwc_otg_hcd_qtd_add(dwc_otg_qtd_t * qtd, dwc_otg_hcd_t * dwc_otg_hcd,
+			       dwc_otg_qh_t ** qh, int atomic_alloc);
+
+/** Allocates memory for a QTD structure.
+ * @return Returns the memory allocate or NULL on error. */
+static inline dwc_otg_qtd_t *dwc_otg_hcd_qtd_alloc(int atomic_alloc)
+{
+	if (atomic_alloc)
+		return (dwc_otg_qtd_t *) DWC_ALLOC_ATOMIC(sizeof(dwc_otg_qtd_t));
+	else
+		return (dwc_otg_qtd_t *) DWC_ALLOC(sizeof(dwc_otg_qtd_t));
+}
+
+/** Frees the memory for a QTD structure.  QTD should already be removed from
+ * list.
+ * @param qtd QTD to free.*/
+static inline void dwc_otg_hcd_qtd_free(dwc_otg_qtd_t * qtd)
+{
+	DWC_FREE(qtd);
+}
+
+/** Removes a QTD from list.
+ * @param hcd HCD instance.
+ * @param qtd QTD to remove from list.
+ * @param qh QTD belongs to.
+ */
+static inline void dwc_otg_hcd_qtd_remove(dwc_otg_hcd_t * hcd,
+					  dwc_otg_qtd_t * qtd,
+					  dwc_otg_qh_t * qh)
+{
+	DWC_CIRCLEQ_REMOVE(&qh->qtd_list, qtd, qtd_list_entry);
+}
+
+/** Remove and free a QTD
+  * Need to disable IRQ and hold hcd lock while calling this function out of
+  * interrupt servicing chain */
+static inline void dwc_otg_hcd_qtd_remove_and_free(dwc_otg_hcd_t * hcd,
+						   dwc_otg_qtd_t * qtd,
+						   dwc_otg_qh_t * qh)
+{
+	dwc_otg_hcd_qtd_remove(hcd, qtd, qh);
+	dwc_otg_hcd_qtd_free(qtd);
+}
+
+/** @} */
+
+/** @name Descriptor DMA Supporting Functions */
+/** @{ */
+
+extern void dwc_otg_hcd_start_xfer_ddma(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh);
+extern void dwc_otg_hcd_complete_xfer_ddma(dwc_otg_hcd_t * hcd,
+					   dwc_hc_t * hc,
+					   dwc_otg_hc_regs_t * hc_regs,
+					   dwc_otg_halt_status_e halt_status);
+
+extern int dwc_otg_hcd_qh_init_ddma(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh);
+extern void dwc_otg_hcd_qh_free_ddma(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh);
+
+/** @} */
+
+/** @name Internal Functions */
+/** @{ */
+dwc_otg_qh_t *dwc_urb_to_qh(dwc_otg_hcd_urb_t * urb);
+/** @} */
+
+#ifdef CONFIG_USB_DWC_OTG_LPM
+extern int dwc_otg_hcd_get_hc_for_lpm_tran(dwc_otg_hcd_t * hcd,
+					   uint8_t devaddr);
+extern void dwc_otg_hcd_free_hc_from_lpm(dwc_otg_hcd_t * hcd);
+#endif
+
+/** Gets the QH that contains the list_head */
+#define dwc_list_to_qh(_list_head_ptr_) container_of(_list_head_ptr_, dwc_otg_qh_t, qh_list_entry)
+
+/** Gets the QTD that contains the list_head */
+#define dwc_list_to_qtd(_list_head_ptr_) container_of(_list_head_ptr_, dwc_otg_qtd_t, qtd_list_entry)
+
+/** Check if QH is non-periodic  */
+#define dwc_qh_is_non_per(_qh_ptr_) ((_qh_ptr_->ep_type == UE_BULK) || \
+				     (_qh_ptr_->ep_type == UE_CONTROL))
+
+/** High bandwidth multiplier as encoded in highspeed endpoint descriptors */
+#define dwc_hb_mult(wMaxPacketSize) (1 + (((wMaxPacketSize) >> 11) & 0x03))
+
+/** Packet size for any kind of endpoint descriptor */
+#define dwc_max_packet(wMaxPacketSize) ((wMaxPacketSize) & 0x07ff)
+
+/**
+ * Returns true if _frame1 is less than or equal to _frame2. The comparison is
+ * done modulo DWC_HFNUM_MAX_FRNUM. This accounts for the rollover of the
+ * frame number when the max frame number is reached.
+ */
+static inline int dwc_frame_num_le(uint16_t frame1, uint16_t frame2)
+{
+	return ((frame2 - frame1) & DWC_HFNUM_MAX_FRNUM) <=
+	    (DWC_HFNUM_MAX_FRNUM >> 1);
+}
+
+/**
+ * Returns true if _frame1 is greater than _frame2. The comparison is done
+ * modulo DWC_HFNUM_MAX_FRNUM. This accounts for the rollover of the frame
+ * number when the max frame number is reached.
+ */
+static inline int dwc_frame_num_gt(uint16_t frame1, uint16_t frame2)
+{
+	return (frame1 != frame2) &&
+	    (((frame1 - frame2) & DWC_HFNUM_MAX_FRNUM) <
+	     (DWC_HFNUM_MAX_FRNUM >> 1));
+}
+
+/**
+ * Increments _frame by the amount specified by _inc. The addition is done
+ * modulo DWC_HFNUM_MAX_FRNUM. Returns the incremented value.
+ */
+static inline uint16_t dwc_frame_num_inc(uint16_t frame, uint16_t inc)
+{
+	return (frame + inc) & DWC_HFNUM_MAX_FRNUM;
+}
+
+static inline uint16_t dwc_full_frame_num(uint16_t frame)
+{
+	return (frame & DWC_HFNUM_MAX_FRNUM) >> 3;
+}
+
+static inline uint16_t dwc_micro_frame_num(uint16_t frame)
+{
+	return frame & 0x7;
+}
+
+void dwc_otg_hcd_save_data_toggle(dwc_hc_t * hc,
+				  dwc_otg_hc_regs_t * hc_regs,
+				  dwc_otg_qtd_t * qtd);
+
+#ifdef DEBUG
+/**
+ * Macro to sample the remaining PHY clocks left in the current frame. This
+ * may be used during debugging to determine the average time it takes to
+ * execute sections of code. There are two possible sample points, "a" and
+ * "b", so the _letter argument must be one of these values.
+ *
+ * To dump the average sample times, read the "hcd_frrem" sysfs attribute. For
+ * example, "cat /sys/devices/lm0/hcd_frrem".
+ */
+#define dwc_sample_frrem(_hcd, _qh, _letter) \
+{ \
+	hfnum_data_t hfnum; \
+	dwc_otg_qtd_t *qtd; \
+	qtd = list_entry(_qh->qtd_list.next, dwc_otg_qtd_t, qtd_list_entry); \
+	if (usb_pipeint(qtd->urb->pipe) && _qh->start_split_frame != 0 && !qtd->complete_split) { \
+		hfnum.d32 = DWC_READ_REG32(&_hcd->core_if->host_if->host_global_regs->hfnum); \
+		switch (hfnum.b.frnum & 0x7) { \
+		case 7: \
+			_hcd->hfnum_7_samples_##_letter++; \
+			_hcd->hfnum_7_frrem_accum_##_letter += hfnum.b.frrem; \
+			break; \
+		case 0: \
+			_hcd->hfnum_0_samples_##_letter++; \
+			_hcd->hfnum_0_frrem_accum_##_letter += hfnum.b.frrem; \
+			break; \
+		default: \
+			_hcd->hfnum_other_samples_##_letter++; \
+			_hcd->hfnum_other_frrem_accum_##_letter += hfnum.b.frrem; \
+			break; \
+		} \
+	} \
+}
+#else
+#define dwc_sample_frrem(_hcd, _qh, _letter)
+#endif
+#endif
+#endif /* DWC_DEVICE_ONLY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_ddma.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_ddma.c
new file mode 100644
index 0000000..fd20354
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_ddma.c
@@ -0,0 +1,1122 @@
+/*==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_hcd_ddma.c $
+ * $Revision: #11 $
+ * $Date: 2013/01/24 $
+ * $Change: 2150761 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef DWC_DEVICE_ONLY
+
+/** @file
+ * This file contains Descriptor DMA support implementation for host mode.
+ */
+
+#include "dwc_otg_hcd.h"
+#include "dwc_otg_regs.h"
+
+static inline uint8_t frame_list_idx(uint16_t frame)
+{
+	return (frame & (MAX_FRLIST_EN_NUM - 1));
+}
+
+static inline uint16_t desclist_idx_inc(uint16_t idx, uint16_t inc, uint8_t speed)
+{
+	return (idx + inc) &
+	    (((speed ==
+	       DWC_OTG_EP_SPEED_HIGH) ? MAX_DMA_DESC_NUM_HS_ISOC :
+	      MAX_DMA_DESC_NUM_GENERIC) - 1);
+}
+
+static inline uint16_t desclist_idx_dec(uint16_t idx, uint16_t inc, uint8_t speed)
+{
+	return (idx - inc) &
+	    (((speed ==
+	       DWC_OTG_EP_SPEED_HIGH) ? MAX_DMA_DESC_NUM_HS_ISOC :
+	      MAX_DMA_DESC_NUM_GENERIC) - 1);
+}
+
+static inline uint16_t max_desc_num(dwc_otg_qh_t * qh)
+{
+	return (((qh->ep_type == UE_ISOCHRONOUS)
+		 && (qh->dev_speed == DWC_OTG_EP_SPEED_HIGH))
+		? MAX_DMA_DESC_NUM_HS_ISOC : MAX_DMA_DESC_NUM_GENERIC);
+}
+static inline uint16_t frame_incr_val(dwc_otg_qh_t * qh)
+{
+	return ((qh->dev_speed == DWC_OTG_EP_SPEED_HIGH)
+		? ((qh->interval + 8 - 1) / 8)
+		: qh->interval);
+}
+
+static int desc_list_alloc(dwc_otg_qh_t * qh)
+{
+	int retval = 0;
+
+	qh->desc_list = (dwc_otg_host_dma_desc_t *)
+	    DWC_DMA_ALLOC(sizeof(dwc_otg_host_dma_desc_t) * max_desc_num(qh),
+			  &qh->desc_list_dma);
+
+	if (!qh->desc_list) {
+		retval = -DWC_E_NO_MEMORY;
+		DWC_ERROR("%s: DMA descriptor list allocation failed\n", __func__);
+
+	}
+
+	dwc_memset(qh->desc_list, 0x00,
+		   sizeof(dwc_otg_host_dma_desc_t) * max_desc_num(qh));
+
+	qh->n_bytes =
+	    (uint32_t *) DWC_ALLOC(sizeof(uint32_t) * max_desc_num(qh));
+
+	if (!qh->n_bytes) {
+		retval = -DWC_E_NO_MEMORY;
+		DWC_ERROR
+		    ("%s: Failed to allocate array for descriptors' size actual values\n",
+		     __func__);
+
+	}
+	return retval;
+
+}
+
+static void desc_list_free(dwc_otg_qh_t * qh)
+{
+	if (qh->desc_list) {
+		DWC_DMA_FREE(max_desc_num(qh), qh->desc_list,
+			     qh->desc_list_dma);
+		qh->desc_list = NULL;
+	}
+
+	if (qh->n_bytes) {
+		DWC_FREE(qh->n_bytes);
+		qh->n_bytes = NULL;
+	}
+}
+
+static int frame_list_alloc(dwc_otg_hcd_t * hcd)
+{
+	int retval = 0;
+	if (hcd->frame_list)
+		return 0;
+
+	hcd->frame_list = DWC_DMA_ALLOC(4 * MAX_FRLIST_EN_NUM,
+					&hcd->frame_list_dma);
+	if (!hcd->frame_list) {
+		retval = -DWC_E_NO_MEMORY;
+		DWC_ERROR("%s: Frame List allocation failed\n", __func__);
+	}
+
+	dwc_memset(hcd->frame_list, 0x00, 4 * MAX_FRLIST_EN_NUM);
+
+	return retval;
+}
+
+static void frame_list_free(dwc_otg_hcd_t * hcd)
+{
+	if (!hcd->frame_list)
+		return;
+
+	DWC_DMA_FREE(4 * MAX_FRLIST_EN_NUM, hcd->frame_list, hcd->frame_list_dma);
+	hcd->frame_list = NULL;
+}
+
+static void per_sched_enable(dwc_otg_hcd_t * hcd, uint16_t fr_list_en)
+{
+
+	hcfg_data_t hcfg;
+
+	hcfg.d32 = DWC_READ_REG32(&hcd->core_if->host_if->host_global_regs->hcfg);
+
+	if (hcfg.b.perschedena) {
+		/* already enabled */
+		return;
+	}
+
+	DWC_WRITE_REG32(&hcd->core_if->host_if->host_global_regs->hflbaddr,
+			hcd->frame_list_dma);
+
+	switch (fr_list_en) {
+	case 64:
+		hcfg.b.frlisten = 3;
+		break;
+	case 32:
+		hcfg.b.frlisten = 2;
+		break;
+	case 16:
+		hcfg.b.frlisten = 1;
+		break;
+	case 8:
+		hcfg.b.frlisten = 0;
+		break;
+	default:
+		break;
+	}
+
+	hcfg.b.perschedena = 1;
+
+	DWC_DEBUGPL(DBG_HCD, "Enabling Periodic schedule\n");
+	DWC_WRITE_REG32(&hcd->core_if->host_if->host_global_regs->hcfg, hcfg.d32);
+
+}
+
+static void per_sched_disable(dwc_otg_hcd_t * hcd)
+{
+	hcfg_data_t hcfg;
+
+	hcfg.d32 = DWC_READ_REG32(&hcd->core_if->host_if->host_global_regs->hcfg);
+
+	if (!hcfg.b.perschedena) {
+		/* already disabled */
+		return;
+	}
+	hcfg.b.perschedena = 0;
+
+	DWC_DEBUGPL(DBG_HCD, "Disabling Periodic schedule\n");
+	DWC_WRITE_REG32(&hcd->core_if->host_if->host_global_regs->hcfg, hcfg.d32);
+}
+
+/*
+ * Activates/Deactivates FrameList entries for the channel
+ * based on endpoint servicing period.
+ */
+void update_frame_list(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh, uint8_t enable)
+{
+	uint16_t i, j, inc;
+	dwc_hc_t *hc = NULL;
+
+	if (!qh->channel) {
+		DWC_ERROR("qh->channel = %p", qh->channel);
+		return;
+	}
+
+	if (!hcd) {
+		DWC_ERROR("------hcd = %p", hcd);
+		return;
+	}
+
+	if (!hcd->frame_list) {
+		DWC_ERROR("-------hcd->frame_list = %p", hcd->frame_list);
+		return;
+	}
+
+	hc = qh->channel;
+	inc = frame_incr_val(qh);
+	if (qh->ep_type == UE_ISOCHRONOUS)
+		i = frame_list_idx(qh->sched_frame);
+	else
+		i = 0;
+
+	j = i;
+	do {
+		if (enable)
+			hcd->frame_list[j] |= (1 << hc->hc_num);
+		else
+			hcd->frame_list[j] &= ~(1 << hc->hc_num);
+		j = (j + inc) & (MAX_FRLIST_EN_NUM - 1);
+	}
+	while (j != i);
+	if (!enable)
+		return;
+	hc->schinfo = 0;
+	if (qh->channel->speed == DWC_OTG_EP_SPEED_HIGH) {
+		j = 1;
+		/* TODO - check this */
+		inc = (8 + qh->interval - 1) / qh->interval;
+		for (i = 0; i < inc; i++) {
+			hc->schinfo |= j;
+			j = j << qh->interval;
+		}
+	} else {
+		hc->schinfo = 0xff;
+	}
+}
+
+#if 1
+void dump_frame_list(dwc_otg_hcd_t * hcd)
+{
+	int i = 0;
+	DWC_PRINTF("--FRAME LIST (hex) --\n");
+	for (i = 0; i < MAX_FRLIST_EN_NUM; i++) {
+		DWC_PRINTF("%x\t", hcd->frame_list[i]);
+		if (!(i % 8) && i)
+			DWC_PRINTF("\n");
+	}
+	DWC_PRINTF("\n----\n");
+
+}
+#endif
+
+static void release_channel_ddma(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	dwc_hc_t *hc = qh->channel;
+	if (dwc_qh_is_non_per(qh))
+		hcd->non_periodic_channels--;
+	else
+		update_frame_list(hcd, qh, 0);
+
+	/*
+	 * The condition is added to prevent double cleanup try in case of device
+	 * disconnect. See channel cleanup in dwc_otg_hcd_disconnect_cb().
+	 */
+	if (hc->qh) {
+		dwc_otg_hc_cleanup(hcd->core_if, hc);
+		DWC_CIRCLEQ_INSERT_TAIL(&hcd->free_hc_list, hc, hc_list_entry);
+		hc->qh = NULL;
+	}
+
+	qh->channel = NULL;
+	qh->ntd = 0;
+
+	if (qh->desc_list) {
+		dwc_memset(qh->desc_list, 0x00,
+			   sizeof(dwc_otg_host_dma_desc_t) * max_desc_num(qh));
+	}
+}
+
+/**
+ * Initializes a QH structure's Descriptor DMA related members.
+ * Allocates memory for descriptor list.
+ * On first periodic QH, allocates memory for FrameList
+ * and enables periodic scheduling.
+ *
+ * @param hcd The HCD state structure for the DWC OTG controller.
+ * @param qh The QH to init.
+ *
+ * @return 0 if successful, negative error code otherwise.
+ */
+int dwc_otg_hcd_qh_init_ddma(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	int retval = 0;
+
+	if (qh->do_split) {
+		DWC_ERROR("SPLIT Transfers are not supported in Descriptor DMA.\n");
+		return -1;
+	}
+
+	retval = desc_list_alloc(qh);
+
+	if ((retval == 0)
+	    && (qh->ep_type == UE_ISOCHRONOUS || qh->ep_type == UE_INTERRUPT)) {
+		if (!hcd->frame_list) {
+			retval = frame_list_alloc(hcd);
+			/* Enable periodic schedule on first periodic QH */
+			if (retval == 0)
+				per_sched_enable(hcd, MAX_FRLIST_EN_NUM);
+		}
+	}
+
+	qh->ntd = 0;
+
+	return retval;
+}
+
+/**
+ * Frees descriptor list memory associated with the QH.
+ * If QH is periodic and the last, frees FrameList memory
+ * and disables periodic scheduling.
+ *
+ * @param hcd The HCD state structure for the DWC OTG controller.
+ * @param qh The QH to init.
+ */
+void dwc_otg_hcd_qh_free_ddma(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	desc_list_free(qh);
+
+	/*
+	 * Channel still assigned due to some reasons.
+	 * Seen on Isoc URB dequeue. Channel halted but no subsequent
+	 * ChHalted interrupt to release the channel. Afterwards
+	 * when it comes here from endpoint disable routine
+	 * channel remains assigned.
+	 */
+	if (qh->channel)
+		release_channel_ddma(hcd, qh);
+
+	if ((qh->ep_type == UE_ISOCHRONOUS || qh->ep_type == UE_INTERRUPT)
+	    && !hcd->periodic_channels && hcd->frame_list) {
+
+		per_sched_disable(hcd);
+		frame_list_free(hcd);
+	}
+}
+
+static uint8_t frame_to_desc_idx(dwc_otg_qh_t * qh, uint16_t frame_idx)
+{
+	if (qh->dev_speed == DWC_OTG_EP_SPEED_HIGH) {
+		/*
+		 * Descriptor set(8 descriptors) index
+		 * which is 8-aligned.
+		 */
+		return (frame_idx & ((MAX_DMA_DESC_NUM_HS_ISOC / 8) - 1)) * 8;
+	} else {
+		return (frame_idx & (MAX_DMA_DESC_NUM_GENERIC - 1));
+	}
+}
+
+/*
+ * Determine starting frame for Isochronous transfer.
+ * Few frames skipped to prevent race condition with HC.
+ */
+static uint8_t calc_starting_frame(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh,
+				   uint8_t * skip_frames)
+{
+	uint16_t frame = 0;
+	hcd->frame_number = dwc_otg_hcd_get_frame_number(hcd);
+
+	/* sched_frame is always frame number(not uFrame) both in FS and HS !! */
+
+	/*
+	 * skip_frames is used to limit activated descriptors number
+	 * to avoid the situation when HC services the last activated
+	 * descriptor firstly.
+	 * Example for FS:
+	 * Current frame is 1, scheduled frame is 3. Since HC always fetches the descriptor
+	 * corresponding to curr_frame+1, the descriptor corresponding to frame 2
+	 * will be fetched. If the number of descriptors is max=64 (or greather) the
+	 * list will be fully programmed with Active descriptors and it is possible
+	 * case(rare) that the latest descriptor(considering rollback) corresponding
+	 * to frame 2 will be serviced first. HS case is more probable because, in fact,
+	 * up to 11 uframes(16 in the code) may be skipped.
+	 */
+	if (qh->dev_speed == DWC_OTG_EP_SPEED_HIGH) {
+		/*
+		 * Consider uframe counter also, to start xfer asap.
+		 * If half of the frame elapsed skip 2 frames otherwise
+		 * just 1 frame.
+		 * Starting descriptor index must be 8-aligned, so
+		 * if the current frame is near to complete the next one
+		 * is skipped as well.
+		 */
+
+		if (dwc_micro_frame_num(hcd->frame_number) >= 5) {
+			*skip_frames = 2 * 8;
+			frame = dwc_frame_num_inc(hcd->frame_number, *skip_frames);
+		} else {
+			*skip_frames = 1 * 8;
+			frame = dwc_frame_num_inc(hcd->frame_number, *skip_frames);
+		}
+
+		frame = dwc_full_frame_num(frame);
+	} else {
+		/*
+		 * Two frames are skipped for FS - the current and the next.
+		 * But for descriptor programming, 1 frame(descriptor) is enough,
+		 * see example above.
+		 */
+		*skip_frames = 1;
+		frame = dwc_frame_num_inc(hcd->frame_number, 2);
+	}
+
+	return frame;
+}
+
+/*
+ * Calculate initial descriptor index for isochronous transfer
+ * based on scheduled frame.
+ */
+static uint8_t recalc_initial_desc_idx(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	uint16_t frame = 0, fr_idx, fr_idx_tmp;
+	uint8_t skip_frames = 0;
+	/*
+	 * With current ISOC processing algorithm the channel is being
+	 * released when no more QTDs in the list(qh->ntd == 0).
+	 * Thus this function is called only when qh->ntd == 0 and qh->channel == 0.
+	 *
+	 * So qh->channel != NULL branch is not used and just not removed from the
+	 * source file. It is required for another possible approach which is,
+	 * do not disable and release the channel when ISOC session completed,
+	 * just move QH to inactive schedule until new QTD arrives.
+	 * On new QTD, the QH moved back to 'ready' schedule,
+	 * starting frame and therefore starting desc_index are recalculated.
+	 * In this case channel is released only on ep_disable.
+	 */
+
+	/* Calculate starting descriptor index. For INTERRUPT endpoint it is always 0. */
+	if (qh->channel) {
+		frame = calc_starting_frame(hcd, qh, &skip_frames);
+		/*
+		 * Calculate initial descriptor index based on FrameList current bitmap
+		 * and servicing period.
+		 */
+		fr_idx_tmp = frame_list_idx(frame);
+		fr_idx =
+		    (MAX_FRLIST_EN_NUM + frame_list_idx(qh->sched_frame) -
+		     fr_idx_tmp)
+		    % frame_incr_val(qh);
+		fr_idx = (fr_idx + fr_idx_tmp) % MAX_FRLIST_EN_NUM;
+	} else {
+		qh->sched_frame = calc_starting_frame(hcd, qh, &skip_frames);
+		fr_idx = frame_list_idx(qh->sched_frame);
+	}
+
+	qh->td_first = qh->td_last = frame_to_desc_idx(qh, fr_idx);
+
+	return skip_frames;
+}
+
+#define	ISOC_URB_GIVEBACK_ASAP
+
+#define MAX_ISOC_XFER_SIZE_FS 1023
+#define MAX_ISOC_XFER_SIZE_HS 3072
+#define DESCNUM_THRESHOLD 4
+
+static void init_isoc_dma_desc(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh,
+			       uint8_t skip_frames)
+{
+	struct dwc_otg_hcd_iso_packet_desc *frame_desc;
+	dwc_otg_qtd_t *qtd;
+	dwc_otg_host_dma_desc_t *dma_desc;
+	uint16_t idx, inc, n_desc, ntd_max, max_xfer_size;
+
+	idx = qh->td_last;
+	inc = qh->interval;
+	n_desc = 0;
+
+	ntd_max = (max_desc_num(qh) + qh->interval - 1) / qh->interval;
+	if (skip_frames && !qh->channel)
+		ntd_max = ntd_max - skip_frames / qh->interval;
+
+	max_xfer_size =
+	    (qh->dev_speed ==
+	     DWC_OTG_EP_SPEED_HIGH) ? MAX_ISOC_XFER_SIZE_HS :
+	    MAX_ISOC_XFER_SIZE_FS;
+
+	DWC_CIRCLEQ_FOREACH(qtd, &qh->qtd_list, qtd_list_entry) {
+		while ((qh->ntd < ntd_max)
+		       && (qtd->isoc_frame_index_last <
+			   qtd->urb->packet_count)) {
+
+			dma_desc = &qh->desc_list[idx];
+			dwc_memset(dma_desc, 0x00, sizeof(dwc_otg_host_dma_desc_t));
+
+			frame_desc = &qtd->urb->iso_descs[qtd->isoc_frame_index_last];
+
+			if (frame_desc->length > max_xfer_size)
+				qh->n_bytes[idx] = max_xfer_size;
+			else
+				qh->n_bytes[idx] = frame_desc->length;
+			dma_desc->status.b_isoc.n_bytes = qh->n_bytes[idx];
+			dma_desc->status.b_isoc.a = 1;
+			dma_desc->status.b_isoc.sts = 0;
+
+			dma_desc->buf = qtd->urb->dma + frame_desc->offset;
+
+			qh->ntd++;
+
+			qtd->isoc_frame_index_last++;
+
+#ifdef	ISOC_URB_GIVEBACK_ASAP
+			/*
+			 * Set IOC for each descriptor corresponding to the
+			 * last frame of the URB.
+			 */
+			if (qtd->isoc_frame_index_last ==
+			    qtd->urb->packet_count)
+				dma_desc->status.b_isoc.ioc = 1;
+
+#endif
+			idx = desclist_idx_inc(idx, inc, qh->dev_speed);
+			n_desc++;
+
+		}
+		qtd->in_process = 1;
+	}
+
+	qh->td_last = idx;
+
+#ifdef	ISOC_URB_GIVEBACK_ASAP
+	/* Set IOC for the last descriptor if descriptor list is full */
+	if (qh->ntd == ntd_max) {
+		idx = desclist_idx_dec(qh->td_last, inc, qh->dev_speed);
+		qh->desc_list[idx].status.b_isoc.ioc = 1;
+	}
+#else
+	/*
+	 * Set IOC bit only for one descriptor.
+	 * Always try to be ahead of HW processing,
+	 * i.e. on IOC generation driver activates next descriptors but
+	 * core continues to process descriptors followed the one with IOC set.
+	 */
+
+	if (n_desc > DESCNUM_THRESHOLD) {
+		/*
+		 * Move IOC "up". Required even if there is only one QTD
+		 * in the list, cause QTDs migth continue to be queued,
+		 * but during the activation it was only one queued.
+		 * Actually more than one QTD might be in the list if this function called
+		 * from XferCompletion - QTDs was queued during HW processing of the previous
+		 * descriptor chunk.
+		 */
+		idx = dwc_desclist_idx_dec(idx, inc * ((qh->ntd + 1) / 2), qh->dev_speed);
+	} else {
+		/*
+		 * Set the IOC for the latest descriptor
+		 * if either number of descriptor is not greather than threshold
+		 * or no more new descriptors activated.
+		 */
+		idx = dwc_desclist_idx_dec(qh->td_last, inc, qh->dev_speed);
+	}
+
+	qh->desc_list[idx].status.b_isoc.ioc = 1;
+#endif
+}
+
+static void init_non_isoc_dma_desc(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+
+	dwc_hc_t *hc;
+	dwc_otg_host_dma_desc_t *dma_desc;
+	dwc_otg_qtd_t *qtd;
+	int num_packets, len, n_desc = 0;
+
+	hc = qh->channel;
+
+	/*
+	 * Start with hc->xfer_buff initialized in
+	 * assign_and_init_hc(), then if SG transfer consists of multiple URBs,
+	 * this pointer re-assigned to the buffer of the currently processed QTD.
+	 * For non-SG request there is always one QTD active.
+	 */
+
+	DWC_CIRCLEQ_FOREACH(qtd, &qh->qtd_list, qtd_list_entry) {
+
+		if (n_desc) {
+			/* SG request - more than 1 QTDs */
+			hc->xfer_buff = (uint8_t *)qtd->urb->dma + qtd->urb->actual_length;
+			hc->xfer_len = qtd->urb->length - qtd->urb->actual_length;
+		}
+
+		qtd->n_desc = 0;
+
+		do {
+			dma_desc = &qh->desc_list[n_desc];
+			len = hc->xfer_len;
+
+			if (len > MAX_DMA_DESC_SIZE)
+				len = MAX_DMA_DESC_SIZE - hc->max_packet + 1;
+
+			if (hc->ep_is_in) {
+				if (len > 0) {
+					num_packets = (len + hc->max_packet - 1) / hc->max_packet;
+				} else {
+					/* Need 1 packet for transfer length of 0. */
+					num_packets = 1;
+				}
+				/* Always program an integral # of max packets for IN transfers. */
+				len = num_packets * hc->max_packet;
+			}
+
+			dma_desc->status.b.n_bytes = len;
+
+			qh->n_bytes[n_desc] = len;
+
+			if ((qh->ep_type == UE_CONTROL)
+			    && (qtd->control_phase == DWC_OTG_CONTROL_SETUP))
+				dma_desc->status.b.sup = 1;	/* Setup Packet */
+
+			dma_desc->status.b.a = 1;	/* Active descriptor */
+			dma_desc->status.b.sts = 0;
+
+			dma_desc->buf =
+			    ((unsigned long)hc->xfer_buff & 0xffffffff);
+
+			/*
+			 * Last descriptor(or single) of IN transfer
+			 * with actual size less than MaxPacket.
+			 */
+			if (len > hc->xfer_len) {
+				hc->xfer_len = 0;
+			} else {
+				hc->xfer_buff += len;
+				hc->xfer_len -= len;
+			}
+
+			qtd->n_desc++;
+			n_desc++;
+		}
+		while ((hc->xfer_len > 0) && (n_desc != MAX_DMA_DESC_NUM_GENERIC));
+
+
+		qtd->in_process = 1;
+
+		if (qh->ep_type == UE_CONTROL)
+			break;
+
+		if (n_desc == MAX_DMA_DESC_NUM_GENERIC)
+			break;
+	}
+
+	if (n_desc) {
+		/* Request Transfer Complete interrupt for the last descriptor */
+		qh->desc_list[n_desc - 1].status.b.ioc = 1;
+		/* End of List indicator */
+		qh->desc_list[n_desc - 1].status.b.eol = 1;
+
+		hc->ntd = n_desc;
+	}
+}
+
+/**
+ * For Control and Bulk endpoints initializes descriptor list
+ * and starts the transfer.
+ *
+ * For Interrupt and Isochronous endpoints initializes descriptor list
+ * then updates FrameList, marking appropriate entries as active.
+ * In case of Isochronous, the starting descriptor index is calculated based
+ * on the scheduled frame, but only on the first transfer descriptor within a session.
+ * Then starts the transfer via enabling the channel.
+ * For Isochronous endpoint the channel is not halted on XferComplete
+ * interrupt so remains assigned to the endpoint(QH) until session is done.
+ *
+ * @param hcd The HCD state structure for the DWC OTG controller.
+ * @param qh The QH to init.
+ *
+ * @return 0 if successful, negative error code otherwise.
+ */
+void dwc_otg_hcd_start_xfer_ddma(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	/* Channel is already assigned */
+	dwc_hc_t *hc = qh->channel;
+	uint8_t skip_frames = 0;
+
+	switch (hc->ep_type) {
+	case DWC_OTG_EP_TYPE_CONTROL:
+	case DWC_OTG_EP_TYPE_BULK:
+		init_non_isoc_dma_desc(hcd, qh);
+
+		dwc_otg_hc_start_transfer_ddma(hcd->core_if, hc);
+		break;
+	case DWC_OTG_EP_TYPE_INTR:
+		init_non_isoc_dma_desc(hcd, qh);
+
+		update_frame_list(hcd, qh, 1);
+
+		dwc_otg_hc_start_transfer_ddma(hcd->core_if, hc);
+		break;
+	case DWC_OTG_EP_TYPE_ISOC:
+
+		if (!qh->ntd)
+			skip_frames = recalc_initial_desc_idx(hcd, qh);
+
+		init_isoc_dma_desc(hcd, qh, skip_frames);
+
+		if (!hc->xfer_started) {
+
+			update_frame_list(hcd, qh, 1);
+
+			/*
+			 * Always set to max, instead of actual size.
+			 * Otherwise ntd will be changed with
+			 * channel being enabled. Not recommended.
+			 *
+			 */
+			hc->ntd = max_desc_num(qh);
+			/* Enable channel only once for ISOC */
+			dwc_otg_hc_start_transfer_ddma(hcd->core_if, hc);
+		}
+
+		break;
+	default:
+
+		break;
+	}
+}
+
+static void complete_isoc_xfer_ddma(dwc_otg_hcd_t * hcd,
+				    dwc_hc_t * hc,
+				    dwc_otg_hc_regs_t * hc_regs,
+				    dwc_otg_halt_status_e halt_status)
+{
+	struct dwc_otg_hcd_iso_packet_desc *frame_desc;
+	dwc_otg_qtd_t *qtd, *qtd_tmp;
+	dwc_otg_qh_t *qh;
+	dwc_otg_host_dma_desc_t *dma_desc;
+	uint16_t idx, remain;
+	uint8_t urb_compl;
+
+	qh = hc->qh;
+	idx = qh->td_first;
+
+	if (hc->halt_status == DWC_OTG_HC_XFER_URB_DEQUEUE) {
+		DWC_CIRCLEQ_FOREACH_SAFE(qtd, qtd_tmp, &hc->qh->qtd_list, qtd_list_entry)
+		    qtd->in_process = 0;
+		return;
+	} else if ((halt_status == DWC_OTG_HC_XFER_AHB_ERR) ||
+		   (halt_status == DWC_OTG_HC_XFER_BABBLE_ERR)) {
+		/*
+		 * Channel is halted in these error cases.
+		 * Considered as serious issues.
+		 * Complete all URBs marking all frames as failed,
+		 * irrespective whether some of the descriptors(frames) succeeded or no.
+		 * Pass error code to completion routine as well, to
+		 * update urb->status, some of class drivers might use it to stop
+		 * queing transfer requests.
+		 */
+		int err = (halt_status == DWC_OTG_HC_XFER_AHB_ERR)
+		    ? (-DWC_E_IO)
+		    : (-DWC_E_OVERFLOW);
+
+		DWC_CIRCLEQ_FOREACH_SAFE(qtd, qtd_tmp, &hc->qh->qtd_list, qtd_list_entry) {
+			for (idx = 0; idx < qtd->urb->packet_count; idx++) {
+				frame_desc = &qtd->urb->iso_descs[idx];
+				frame_desc->status = err;
+			}
+			hcd->fops->complete(hcd, qtd->urb->priv, qtd->urb, err);
+			dwc_otg_hcd_qtd_remove_and_free(hcd, qtd, qh);
+		}
+		return;
+	}
+
+	DWC_CIRCLEQ_FOREACH_SAFE(qtd, qtd_tmp, &hc->qh->qtd_list, qtd_list_entry) {
+
+		if (!qtd->in_process)
+			break;
+
+		urb_compl = 0;
+
+		do {
+
+			dma_desc = &qh->desc_list[idx];
+
+			frame_desc = &qtd->urb->iso_descs[qtd->isoc_frame_index];
+			remain = hc->ep_is_in ? dma_desc->status.b_isoc.n_bytes : 0;
+
+			if (dma_desc->status.b_isoc.sts == DMA_DESC_STS_PKTERR) {
+				/*
+				 * XactError or, unable to complete all the transactions
+				 * in the scheduled micro-frame/frame,
+				 * both indicated by DMA_DESC_STS_PKTERR.
+				 */
+				qtd->urb->error_count++;
+				frame_desc->actual_length = qh->n_bytes[idx] - remain;
+				frame_desc->status = -DWC_E_PROTOCOL;
+			} else {
+				/* Success */
+
+				frame_desc->actual_length = qh->n_bytes[idx] - remain;
+				frame_desc->status = 0;
+			}
+
+			if (++qtd->isoc_frame_index == qtd->urb->packet_count) {
+				/*
+				 * urb->status is not used for isoc transfers here.
+				 * The individual frame_desc status are used instead.
+				 */
+
+				hcd->fops->complete(hcd, qtd->urb->priv, qtd->urb, 0);
+				dwc_otg_hcd_qtd_remove_and_free(hcd, qtd, qh);
+
+				/*
+				 * This check is necessary because urb_dequeue can be called
+				 * from urb complete callback(sound driver example).
+				 * All pending URBs are dequeued there, so no need for
+				 * further processing.
+				 */
+				if (hc->halt_status == DWC_OTG_HC_XFER_URB_DEQUEUE) {
+					return;
+				}
+
+				urb_compl = 1;
+
+			}
+
+			qh->ntd--;
+
+			/* Stop if IOC requested descriptor reached */
+			if (dma_desc->status.b_isoc.ioc) {
+				idx = desclist_idx_inc(idx, qh->interval, hc->speed);
+				goto stop_scan;
+			}
+
+			idx = desclist_idx_inc(idx, qh->interval, hc->speed);
+
+			if (urb_compl)
+				break;
+		}
+		while (idx != qh->td_first);
+	}
+stop_scan:
+	qh->td_first = idx;
+}
+
+uint8_t update_non_isoc_urb_state_ddma(dwc_otg_hcd_t * hcd,
+				       dwc_hc_t * hc,
+				       dwc_otg_qtd_t * qtd,
+				       dwc_otg_host_dma_desc_t * dma_desc,
+				       dwc_otg_halt_status_e halt_status,
+				       uint32_t n_bytes, uint8_t * xfer_done)
+{
+
+	uint16_t remain = hc->ep_is_in ? dma_desc->status.b.n_bytes : 0;
+	dwc_otg_hcd_urb_t *urb = qtd->urb;
+
+	if (halt_status == DWC_OTG_HC_XFER_AHB_ERR) {
+		urb->status = -DWC_E_IO;
+		return 1;
+	}
+	if (dma_desc->status.b.sts == DMA_DESC_STS_PKTERR) {
+		switch (halt_status) {
+		case DWC_OTG_HC_XFER_STALL:
+			urb->status = -DWC_E_PIPE;
+			break;
+		case DWC_OTG_HC_XFER_BABBLE_ERR:
+			urb->status = -DWC_E_OVERFLOW;
+			break;
+		case DWC_OTG_HC_XFER_XACT_ERR:
+			urb->status = -DWC_E_PROTOCOL;
+			break;
+		default:
+			DWC_ERROR("%s: Unhandled descriptor error status (%d)\n", __func__,
+				  halt_status);
+			break;
+		}
+		return 1;
+	}
+
+	if (dma_desc->status.b.a == 1) {
+		DWC_DEBUGPL(DBG_HCDV,
+			    "Active descriptor encountered on channel %d\n",
+			    hc->hc_num);
+		return 0;
+	}
+
+	if (hc->ep_type == DWC_OTG_EP_TYPE_CONTROL) {
+		if (qtd->control_phase == DWC_OTG_CONTROL_DATA) {
+			urb->actual_length += n_bytes - remain;
+			if (remain || urb->actual_length == urb->length) {
+				/*
+				 * For Control Data stage do not set urb->status=0 to prevent
+				 * URB callback. Set it when Status phase done. See below.
+				 */
+				*xfer_done = 1;
+			}
+
+		} else if (qtd->control_phase == DWC_OTG_CONTROL_STATUS) {
+			urb->status = 0;
+			*xfer_done = 1;
+		}
+		/* No handling for SETUP stage */
+	} else {
+		/* BULK and INTR */
+		urb->actual_length += n_bytes - remain;
+		if (remain || urb->actual_length == urb->length) {
+			urb->status = 0;
+			*xfer_done = 1;
+		}
+	}
+
+	return 0;
+}
+
+static void complete_non_isoc_xfer_ddma(dwc_otg_hcd_t * hcd,
+					dwc_hc_t * hc,
+					dwc_otg_hc_regs_t * hc_regs,
+					dwc_otg_halt_status_e halt_status)
+{
+	dwc_otg_hcd_urb_t *urb = NULL;
+	dwc_otg_qtd_t *qtd, *qtd_tmp;
+	dwc_otg_qh_t *qh;
+	dwc_otg_host_dma_desc_t *dma_desc;
+	uint32_t n_bytes, n_desc, i;
+	uint8_t failed = 0, xfer_done;
+
+	n_desc = 0;
+
+	qh = hc->qh;
+
+	if (hc->halt_status == DWC_OTG_HC_XFER_URB_DEQUEUE) {
+		DWC_CIRCLEQ_FOREACH_SAFE(qtd, qtd_tmp, &hc->qh->qtd_list, qtd_list_entry) {
+			qtd->in_process = 0;
+		}
+		return;
+	}
+
+	DWC_CIRCLEQ_FOREACH_SAFE(qtd, qtd_tmp, &qh->qtd_list, qtd_list_entry) {
+
+		urb = qtd->urb;
+
+		n_bytes = 0;
+		xfer_done = 0;
+
+		for (i = 0; i < qtd->n_desc; i++) {
+			dma_desc = &qh->desc_list[n_desc];
+
+			n_bytes = qh->n_bytes[n_desc];
+
+			failed =
+			    update_non_isoc_urb_state_ddma(hcd, hc, qtd,
+							   dma_desc,
+							   halt_status, n_bytes,
+							   &xfer_done);
+
+			if (failed
+			    || (xfer_done
+				&& (urb->status != -DWC_E_IN_PROGRESS))) {
+
+				hcd->fops->complete(hcd, urb->priv, urb,
+						    urb->status);
+				dwc_otg_hcd_qtd_remove_and_free(hcd, qtd, qh);
+
+				if (failed)
+					goto stop_scan;
+			} else if (qh->ep_type == UE_CONTROL) {
+				if (qtd->control_phase == DWC_OTG_CONTROL_SETUP) {
+					if (urb->length > 0) {
+						qtd->control_phase = DWC_OTG_CONTROL_DATA;
+					} else {
+						qtd->control_phase = DWC_OTG_CONTROL_STATUS;
+					}
+					DWC_DEBUGPL(DBG_HCDV, "  Control setup transaction done\n");
+				} else if (qtd->control_phase == DWC_OTG_CONTROL_DATA) {
+					if (xfer_done) {
+						qtd->control_phase = DWC_OTG_CONTROL_STATUS;
+						DWC_DEBUGPL(DBG_HCDV, "  Control data transfer done\n");
+					} else if (i + 1 == qtd->n_desc) {
+						/*
+						 * Last descriptor for Control data stage which is
+						 * not completed yet.
+						 */
+						dwc_otg_hcd_save_data_toggle(hc, hc_regs, qtd);
+					}
+				}
+			}
+
+			n_desc++;
+		}
+
+	}
+
+stop_scan:
+
+	if (qh->ep_type != UE_CONTROL) {
+		/*
+		 * Resetting the data toggle for bulk
+		 * and interrupt endpoints in case of stall. See handle_hc_stall_intr()
+		 */
+		if (halt_status == DWC_OTG_HC_XFER_STALL)
+			qh->data_toggle = DWC_OTG_HC_PID_DATA0;
+		else
+			dwc_otg_hcd_save_data_toggle(hc, hc_regs, qtd);
+	}
+
+	if (halt_status == DWC_OTG_HC_XFER_COMPLETE) {
+		hcint_data_t hcint;
+		hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+		if (hcint.b.nyet) {
+			/*
+			 * Got a NYET on the last transaction of the transfer. It
+			 * means that the endpoint should be in the PING state at the
+			 * beginning of the next transfer.
+			 */
+			qh->ping_state = 1;
+			clear_hc_int(hc_regs, nyet);
+		}
+
+	}
+
+}
+
+/**
+ * This function is called from interrupt handlers.
+ * Scans the descriptor list, updates URB's status and
+ * calls completion routine for the URB if it's done.
+ * Releases the channel to be used by other transfers.
+ * In case of Isochronous endpoint the channel is not halted until
+ * the end of the session, i.e. QTD list is empty.
+ * If periodic channel released the FrameList is updated accordingly.
+ *
+ * Calls transaction selection routines to activate pending transfers.
+ *
+ * @param hcd The HCD state structure for the DWC OTG controller.
+ * @param hc Host channel, the transfer is completed on.
+ * @param hc_regs Host channel registers.
+ * @param halt_status Reason the channel is being halted,
+ *		      or just XferComplete for isochronous transfer
+ */
+void dwc_otg_hcd_complete_xfer_ddma(dwc_otg_hcd_t * hcd,
+				    dwc_hc_t * hc,
+				    dwc_otg_hc_regs_t * hc_regs,
+				    dwc_otg_halt_status_e halt_status)
+{
+	uint8_t continue_isoc_xfer = 0;
+	dwc_otg_transaction_type_e tr_type;
+	dwc_otg_qh_t *qh = hc->qh;
+
+	if (hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+
+		complete_isoc_xfer_ddma(hcd, hc, hc_regs, halt_status);
+
+		/* Release the channel if halted or session completed */
+		if (halt_status != DWC_OTG_HC_XFER_COMPLETE ||
+		    DWC_CIRCLEQ_EMPTY(&qh->qtd_list)) {
+
+			/* Halt the channel if session completed */
+			if (halt_status == DWC_OTG_HC_XFER_COMPLETE) {
+				dwc_otg_hc_halt(hcd->core_if, hc, halt_status);
+			}
+
+			release_channel_ddma(hcd, qh);
+			dwc_otg_hcd_qh_remove(hcd, qh);
+		} else {
+			/* Keep in assigned schedule to continue transfer */
+			DWC_LIST_MOVE_HEAD(&hcd->periodic_sched_assigned,
+					   &qh->qh_list_entry);
+			continue_isoc_xfer = 1;
+
+		}
+		/** @todo Consider the case when period exceeds FrameList size.
+		 *  Frame Rollover interrupt should be used.
+		 */
+	} else {
+		/* Scan descriptor list to complete the URB(s), then release the channel */
+		complete_non_isoc_xfer_ddma(hcd, hc, hc_regs, halt_status);
+
+		release_channel_ddma(hcd, qh);
+		dwc_otg_hcd_qh_remove(hcd, qh);
+
+		if (!DWC_CIRCLEQ_EMPTY(&qh->qtd_list)) {
+			/* Add back to inactive non-periodic schedule on normal completion */
+			dwc_otg_hcd_qh_add(hcd, qh);
+		}
+
+	}
+	tr_type = dwc_otg_hcd_select_transactions(hcd);
+	if (tr_type != DWC_OTG_TRANSACTION_NONE || continue_isoc_xfer) {
+		if (continue_isoc_xfer) {
+			if (tr_type == DWC_OTG_TRANSACTION_NONE) {
+				tr_type = DWC_OTG_TRANSACTION_PERIODIC;
+			} else if (tr_type == DWC_OTG_TRANSACTION_NON_PERIODIC) {
+				tr_type = DWC_OTG_TRANSACTION_ALL;
+			}
+		}
+		dwc_otg_hcd_queue_transactions(hcd, tr_type);
+	}
+}
+
+#endif /* DWC_DEVICE_ONLY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_if.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_if.h
new file mode 100644
index 0000000..4823167
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_if.h
@@ -0,0 +1,412 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_hcd_if.h $
+ * $Revision: #12 $
+ * $Date: 2011/10/26 $
+ * $Change: 1873028 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef DWC_DEVICE_ONLY
+#ifndef __DWC_HCD_IF_H__
+#define __DWC_HCD_IF_H__
+
+#include "dwc_otg_core_if.h"
+
+/** @file
+ * This file defines DWC_OTG HCD Core API.
+ */
+
+struct dwc_otg_hcd;
+typedef struct dwc_otg_hcd dwc_otg_hcd_t;
+
+struct dwc_otg_hcd_urb;
+typedef struct dwc_otg_hcd_urb dwc_otg_hcd_urb_t;
+
+/** @name HCD Function Driver Callbacks */
+/** @{ */
+
+/** This function is called whenever core switches to host mode. */
+typedef int (*dwc_otg_hcd_start_cb_t) (dwc_otg_hcd_t * hcd);
+
+/** This function is called when device has been disconnected */
+typedef int (*dwc_otg_hcd_disconnect_cb_t) (dwc_otg_hcd_t * hcd);
+
+/** Wrapper provides this function to HCD to core, so it can get hub information to which device is connected */
+typedef int (*dwc_otg_hcd_hub_info_from_urb_cb_t) (dwc_otg_hcd_t * hcd,
+						   void *urb_handle,
+						   uint32_t * hub_addr,
+						   uint32_t * port_addr);
+/** Via this function HCD core gets device speed */
+typedef int (*dwc_otg_hcd_speed_from_urb_cb_t) (dwc_otg_hcd_t * hcd,
+						void *urb_handle);
+
+/** This function is called when urb is completed */
+typedef int (*dwc_otg_hcd_complete_urb_cb_t) (dwc_otg_hcd_t * hcd,
+					      void *urb_handle,
+					      dwc_otg_hcd_urb_t * dwc_otg_urb,
+					      int32_t status);
+
+/** Via this function HCD core gets b_hnp_enable parameter */
+typedef int (*dwc_otg_hcd_get_b_hnp_enable) (dwc_otg_hcd_t * hcd);
+
+struct dwc_otg_hcd_function_ops {
+	dwc_otg_hcd_start_cb_t start;
+	dwc_otg_hcd_disconnect_cb_t disconnect;
+	dwc_otg_hcd_hub_info_from_urb_cb_t hub_info;
+	dwc_otg_hcd_speed_from_urb_cb_t speed;
+	dwc_otg_hcd_complete_urb_cb_t complete;
+	dwc_otg_hcd_get_b_hnp_enable get_b_hnp_enable;
+};
+/** @} */
+
+/** @name HCD Core API */
+/** @{ */
+/** This function allocates dwc_otg_hcd structure and returns pointer on it. */
+extern dwc_otg_hcd_t *dwc_otg_hcd_alloc_hcd(void);
+
+/** This function should be called to initiate HCD Core.
+ *
+ * @param hcd The HCD
+ * @param core_if The DWC_OTG Core
+ *
+ * Returns -DWC_E_NO_MEMORY if no enough memory.
+ * Returns 0 on success
+ */
+extern int dwc_otg_hcd_init(dwc_otg_hcd_t * hcd, dwc_otg_core_if_t * core_if);
+
+/** Frees HCD
+ *
+ * @param hcd The HCD
+ */
+extern void dwc_otg_hcd_remove(dwc_otg_hcd_t * hcd);
+
+/** This function should be called on every hardware interrupt.
+ *
+ * @param dwc_otg_hcd The HCD
+ *
+ * Returns non zero if interrupt is handled
+ * Return 0 if interrupt is not handled
+ */
+extern int32_t dwc_otg_hcd_handle_intr(dwc_otg_hcd_t * dwc_otg_hcd);
+
+/**
+ * Returns private data set by
+ * dwc_otg_hcd_set_priv_data function.
+ *
+ * @param hcd The HCD
+ */
+extern void *dwc_otg_hcd_get_priv_data(dwc_otg_hcd_t * hcd);
+
+/**
+ * Set private data.
+ *
+ * @param hcd The HCD
+ * @param priv_data pointer to be stored in private data
+ */
+extern void dwc_otg_hcd_set_priv_data(dwc_otg_hcd_t * hcd, void *priv_data);
+
+/**
+ * This function initializes the HCD Core.
+ *
+ * @param hcd The HCD
+ * @param fops The Function Driver Operations data structure containing pointers to all callbacks.
+ *
+ * Returns -DWC_E_NO_DEVICE if Core is currently is in device mode.
+ * Returns 0 on success
+ */
+extern int dwc_otg_hcd_start(dwc_otg_hcd_t * hcd,
+			     struct dwc_otg_hcd_function_ops *fops);
+
+/**
+ * Halts the DWC_otg host mode operations in a clean manner. USB transfers are
+ * stopped.
+ *
+ * @param hcd The HCD
+ */
+extern void dwc_otg_hcd_stop(dwc_otg_hcd_t * hcd);
+
+/**
+ * Handles hub class-specific requests.
+ *
+ * @param dwc_otg_hcd The HCD
+ * @param typeReq Request Type
+ * @param wValue wValue from control request
+ * @param wIndex wIndex from control request
+ * @param buf data buffer
+ * @param wLength data buffer length
+ *
+ * Returns -DWC_E_INVALID if invalid argument is passed
+ * Returns 0 on success
+ */
+extern int dwc_otg_hcd_hub_control(dwc_otg_hcd_t * dwc_otg_hcd,
+				   uint16_t typeReq, uint16_t wValue,
+				   uint16_t wIndex, uint8_t * buf,
+				   uint16_t wLength);
+
+/**
+ * Returns otg port number.
+ *
+ * @param hcd The HCD
+ */
+extern uint32_t dwc_otg_hcd_otg_port(dwc_otg_hcd_t * hcd);
+
+/**
+ * Returns OTG version - either 1.3 or 2.0.
+ *
+ * @param core_if The core_if structure pointer
+ */
+extern uint16_t dwc_otg_get_otg_version(dwc_otg_core_if_t * core_if);
+
+/**
+ * Returns 1 if currently core is acting as B host, and 0 otherwise.
+ *
+ * @param hcd The HCD
+ */
+extern uint32_t dwc_otg_hcd_is_b_host(dwc_otg_hcd_t * hcd);
+
+/**
+ * Returns current frame number.
+ *
+ * @param hcd The HCD
+ */
+extern int dwc_otg_hcd_get_frame_number(dwc_otg_hcd_t * hcd);
+
+/**
+ * Dumps hcd state.
+ *
+ * @param hcd The HCD
+ */
+extern void dwc_otg_hcd_dump_state(dwc_otg_hcd_t * hcd);
+
+/**
+ * Dump the average frame remaining at SOF. This can be used to
+ * determine average interrupt latency. Frame remaining is also shown for
+ * start transfer and two additional sample points.
+ * Currently this function is not implemented.
+ *
+ * @param hcd The HCD
+ */
+extern void dwc_otg_hcd_dump_frrem(dwc_otg_hcd_t * hcd);
+
+/**
+ * Sends LPM transaction to the local device.
+ *
+ * @param hcd The HCD
+ * @param devaddr Device Address
+ * @param hird Host initiated resume duration
+ * @param bRemoteWake Value of bRemoteWake field in LPM transaction
+ *
+ * Returns negative value if sending LPM transaction was not succeeded.
+ * Returns 0 on success.
+ */
+extern int dwc_otg_hcd_send_lpm(dwc_otg_hcd_t * hcd, uint8_t devaddr,
+				uint8_t hird, uint8_t bRemoteWake);
+
+/* URB interface */
+
+/**
+ * Allocates memory for dwc_otg_hcd_urb structure.
+ * Allocated memory should be freed by call of DWC_FREE.
+ *
+ * @param hcd The HCD
+ * @param iso_desc_count Count of ISOC descriptors
+ * @param atomic_alloc Specefies whether to perform atomic allocation.
+ */
+extern dwc_otg_hcd_urb_t *dwc_otg_hcd_urb_alloc(dwc_otg_hcd_t * hcd,
+						int iso_desc_count,
+						int atomic_alloc);
+
+/**
+ * Set pipe information in URB.
+ *
+ * @param hcd_urb DWC_OTG URB
+ * @param devaddr Device Address
+ * @param ep_num Endpoint Number
+ * @param ep_type Endpoint Type
+ * @param ep_dir Endpoint Direction
+ * @param mps Max Packet Size
+ */
+extern void dwc_otg_hcd_urb_set_pipeinfo(dwc_otg_hcd_urb_t * hcd_urb,
+					 uint8_t devaddr, uint8_t ep_num,
+					 uint8_t ep_type, uint8_t ep_dir,
+					 uint16_t mps);
+
+/* Transfer flags */
+#define URB_GIVEBACK_ASAP 0x1
+#define URB_SEND_ZERO_PACKET 0x2
+
+/**
+ * Sets dwc_otg_hcd_urb parameters.
+ *
+ * @param urb DWC_OTG URB allocated by dwc_otg_hcd_urb_alloc function.
+ * @param urb_handle Unique handle for request, this will be passed back
+ * to function driver in completion callback.
+ * @param buf The buffer for the data
+ * @param dma The DMA buffer for the data
+ * @param buflen Transfer length
+ * @param sp Buffer for setup data
+ * @param sp_dma DMA address of setup data buffer
+ * @param flags Transfer flags
+ * @param interval Polling interval for interrupt or isochronous transfers.
+ */
+extern void dwc_otg_hcd_urb_set_params(dwc_otg_hcd_urb_t * urb,
+				       void *urb_handle, void *buf,
+				       dwc_dma_t dma, uint32_t buflen, void *sp,
+				       dwc_dma_t sp_dma, uint32_t flags,
+				       uint16_t interval);
+
+/** Gets status from dwc_otg_hcd_urb
+ *
+ * @param dwc_otg_urb DWC_OTG URB
+ */
+extern uint32_t dwc_otg_hcd_urb_get_status(dwc_otg_hcd_urb_t * dwc_otg_urb);
+
+/** Gets actual length from dwc_otg_hcd_urb
+ *
+ * @param dwc_otg_urb DWC_OTG URB
+ */
+extern uint32_t dwc_otg_hcd_urb_get_actual_length(dwc_otg_hcd_urb_t *
+						  dwc_otg_urb);
+
+/** Gets error count from dwc_otg_hcd_urb. Only for ISOC URBs
+ *
+ * @param dwc_otg_urb DWC_OTG URB
+ */
+extern uint32_t dwc_otg_hcd_urb_get_error_count(dwc_otg_hcd_urb_t *
+						dwc_otg_urb);
+
+/** Set ISOC descriptor offset and length
+ *
+ * @param dwc_otg_urb DWC_OTG URB
+ * @param desc_num ISOC descriptor number
+ * @param offset Offset from beginig of buffer.
+ * @param length Transaction length
+ */
+extern void dwc_otg_hcd_urb_set_iso_desc_params(dwc_otg_hcd_urb_t * dwc_otg_urb,
+						int desc_num, uint32_t offset,
+						uint32_t length);
+
+/** Get status of ISOC descriptor, specified by desc_num
+ *
+ * @param dwc_otg_urb DWC_OTG URB
+ * @param desc_num ISOC descriptor number
+ */
+extern uint32_t dwc_otg_hcd_urb_get_iso_desc_status(dwc_otg_hcd_urb_t *
+						    dwc_otg_urb, int desc_num);
+
+/** Get actual length of ISOC descriptor, specified by desc_num
+ *
+ * @param dwc_otg_urb DWC_OTG URB
+ * @param desc_num ISOC descriptor number
+ */
+extern uint32_t dwc_otg_hcd_urb_get_iso_desc_actual_length(dwc_otg_hcd_urb_t *
+							   dwc_otg_urb,
+							   int desc_num);
+
+/** Queue URB. After transfer is completes, the complete callback will be called with the URB status
+ *
+ * @param dwc_otg_hcd The HCD
+ * @param dwc_otg_urb DWC_OTG URB
+ * @param ep_handle Out parameter for returning endpoint handle
+ * @param atomic_alloc Flag to do atomic allocation if needed
+ *
+ * Returns -DWC_E_NO_DEVICE if no device is connected.
+ * Returns -DWC_E_NO_MEMORY if there is no enough memory.
+ * Returns 0 on success.
+ */
+extern int dwc_otg_hcd_urb_enqueue(dwc_otg_hcd_t * dwc_otg_hcd,
+				   dwc_otg_hcd_urb_t * dwc_otg_urb,
+				   void **ep_handle, int atomic_alloc);
+
+/** De-queue the specified URB
+ *
+ * @param dwc_otg_hcd The HCD
+ * @param dwc_otg_urb DWC_OTG URB
+ */
+extern int dwc_otg_hcd_urb_dequeue(dwc_otg_hcd_t * dwc_otg_hcd,
+				   dwc_otg_hcd_urb_t * dwc_otg_urb);
+
+/** Frees resources in the DWC_otg controller related to a given endpoint.
+ * Any URBs for the endpoint must already be dequeued.
+ *
+ * @param hcd The HCD
+ * @param ep_handle Endpoint handle, returned by dwc_otg_hcd_urb_enqueue function
+ * @param retry Number of retries if there are queued transfers.
+ *
+ * Returns -DWC_E_INVALID if invalid arguments are passed.
+ * Returns 0 on success
+ */
+extern int dwc_otg_hcd_endpoint_disable(dwc_otg_hcd_t * hcd, void *ep_handle,
+					int retry);
+
+/* Resets the data toggle in qh structure. This function can be called from
+ * usb_clear_halt routine.
+ *
+ * @param hcd The HCD
+ * @param ep_handle Endpoint handle, returned by dwc_otg_hcd_urb_enqueue function
+ *
+ * Returns -DWC_E_INVALID if invalid arguments are passed.
+ * Returns 0 on success
+ */
+extern int dwc_otg_hcd_endpoint_reset(dwc_otg_hcd_t * hcd, void *ep_handle);
+
+/** Returns 1 if status of specified port is changed and 0 otherwise.
+ *
+ * @param hcd The HCD
+ * @param port Port number
+ */
+extern int dwc_otg_hcd_is_status_changed(dwc_otg_hcd_t * hcd, int port);
+
+/** Call this function to check if bandwidth was allocated for specified endpoint.
+ * Only for ISOC and INTERRUPT endpoints.
+ *
+ * @param hcd The HCD
+ * @param ep_handle Endpoint handle
+ */
+extern int dwc_otg_hcd_is_bandwidth_allocated(dwc_otg_hcd_t * hcd,
+					      void *ep_handle);
+
+/** Call this function to check if bandwidth was freed for specified endpoint.
+ *
+ * @param hcd The HCD
+ * @param ep_handle Endpoint handle
+ */
+extern int dwc_otg_hcd_is_bandwidth_freed(dwc_otg_hcd_t * hcd, void *ep_handle);
+
+/** Returns bandwidth allocated for specified endpoint in microseconds.
+ * Only for ISOC and INTERRUPT endpoints.
+ *
+ * @param hcd The HCD
+ * @param ep_handle Endpoint handle
+ */
+extern uint8_t dwc_otg_hcd_get_ep_bandwidth(dwc_otg_hcd_t * hcd,
+					    void *ep_handle);
+
+/** @} */
+
+#endif /* __DWC_HCD_IF_H__ */
+#endif /* DWC_DEVICE_ONLY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_intr.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_intr.c
new file mode 100644
index 0000000..f843e65
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_intr.c
@@ -0,0 +1,2096 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_hcd_intr.c $
+ * $Revision: #94 $
+ * $Date: 2013/01/31 $
+ * $Change: 2155605 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef DWC_DEVICE_ONLY
+
+#include "dwc_otg_hcd.h"
+#include "dwc_otg_regs.h"
+
+/** @file
+ * This file contains the implementation of the HCD Interrupt handlers.
+ */
+
+/** This function handles interrupts for the HCD. */
+int32_t dwc_otg_hcd_handle_intr(dwc_otg_hcd_t * dwc_otg_hcd)
+{
+	int retval = 0;
+
+	dwc_otg_core_if_t *core_if = dwc_otg_hcd->core_if;
+	gintsts_data_t gintsts;
+#ifdef DEBUG
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+#endif
+
+	if (dwc_otg_check_haps_status(core_if) == -1 ) {
+		DWC_WARN("HAPS is disconnected");
+		return retval;
+	}
+
+	/* Exit from ISR if core is hibernated */
+	if (core_if->hibernation_suspend == 1) {
+		return retval;
+	}
+	DWC_SPINLOCK(dwc_otg_hcd->lock);
+	/* Check if HOST Mode */
+	if (dwc_otg_is_host_mode(core_if)) {
+		gintsts.d32 = dwc_otg_read_core_intr(core_if);
+		if (!gintsts.d32) {
+			DWC_SPINUNLOCK(dwc_otg_hcd->lock);
+			return 0;
+		}
+#ifdef DEBUG
+		/* Don't print debug message in the interrupt handler on SOF */
+#ifndef DEBUG_SOF
+		if (gintsts.d32 != DWC_SOF_INTR_MASK)
+#endif
+			DWC_DEBUGPL(DBG_HCD, "\n");
+#endif
+
+#ifdef DEBUG
+#ifndef DEBUG_SOF
+		if (gintsts.d32 != DWC_SOF_INTR_MASK)
+#endif
+			DWC_DEBUGPL(DBG_HCD,
+				    "DWC OTG HCD Interrupt Detected gintsts&gintmsk=0x%08x\n",
+				    gintsts.d32);
+#endif
+
+		if (gintsts.b.sofintr) {
+			retval |= dwc_otg_hcd_handle_sof_intr(dwc_otg_hcd);
+		}
+		if (gintsts.b.rxstsqlvl) {
+			retval |=
+			    dwc_otg_hcd_handle_rx_status_q_level_intr
+			    (dwc_otg_hcd);
+		}
+		if (gintsts.b.nptxfempty) {
+			retval |=
+			    dwc_otg_hcd_handle_np_tx_fifo_empty_intr
+			    (dwc_otg_hcd);
+		}
+		if (gintsts.b.i2cintr) {
+			/** @todo Implement i2cintr handler. */
+		}
+		if (gintsts.b.portintr) {
+			retval |= dwc_otg_hcd_handle_port_intr(dwc_otg_hcd);
+		}
+		if (gintsts.b.hcintr) {
+			retval |= dwc_otg_hcd_handle_hc_intr(dwc_otg_hcd);
+		}
+		if (gintsts.b.ptxfempty) {
+			retval |=
+			    dwc_otg_hcd_handle_perio_tx_fifo_empty_intr
+			    (dwc_otg_hcd);
+		}
+#ifdef DEBUG
+#ifndef DEBUG_SOF
+		if (gintsts.d32 != DWC_SOF_INTR_MASK)
+#endif
+		{
+			DWC_DEBUGPL(DBG_HCD,
+				    "DWC OTG HCD Finished Servicing Interrupts\n");
+			DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD gintsts=0x%08x\n",
+				    DWC_READ_REG32(&global_regs->gintsts));
+			DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD gintmsk=0x%08x\n",
+				    DWC_READ_REG32(&global_regs->gintmsk));
+		}
+#endif
+
+#ifdef DEBUG
+#ifndef DEBUG_SOF
+		if (gintsts.d32 != DWC_SOF_INTR_MASK)
+#endif
+			DWC_DEBUGPL(DBG_HCD, "\n");
+#endif
+
+	}
+	DWC_SPINUNLOCK(dwc_otg_hcd->lock);
+	return retval;
+}
+
+#ifdef DWC_TRACK_MISSED_SOFS
+#warning Compiling code to track missed SOFs
+#define FRAME_NUM_ARRAY_SIZE 1000
+/**
+ * This function is for debug only.
+ */
+static inline void track_missed_sofs(uint16_t curr_frame_number)
+{
+	static uint16_t frame_num_array[FRAME_NUM_ARRAY_SIZE];
+	static uint16_t last_frame_num_array[FRAME_NUM_ARRAY_SIZE];
+	static int frame_num_idx = 0;
+	static uint16_t last_frame_num = DWC_HFNUM_MAX_FRNUM;
+	static int dumped_frame_num_array = 0;
+
+	if (frame_num_idx < FRAME_NUM_ARRAY_SIZE) {
+		if (((last_frame_num + 1) & DWC_HFNUM_MAX_FRNUM) !=
+		    curr_frame_number) {
+			frame_num_array[frame_num_idx] = curr_frame_number;
+			last_frame_num_array[frame_num_idx++] = last_frame_num;
+		}
+	} else if (!dumped_frame_num_array) {
+		int i;
+		DWC_PRINTF("Frame     Last Frame\n");
+		DWC_PRINTF("-----     ----------\n");
+		for (i = 0; i < FRAME_NUM_ARRAY_SIZE; i++) {
+			DWC_PRINTF("0x%04x    0x%04x\n",
+				   frame_num_array[i], last_frame_num_array[i]);
+		}
+		dumped_frame_num_array = 1;
+	}
+	last_frame_num = curr_frame_number;
+}
+#endif
+
+/**
+ * Handles the start-of-frame interrupt in host mode. Non-periodic
+ * transactions may be queued to the DWC_otg controller for the current
+ * (micro)frame. Periodic transactions may be queued to the controller for the
+ * next (micro)frame.
+ */
+int32_t dwc_otg_hcd_handle_sof_intr(dwc_otg_hcd_t * hcd)
+{
+	hfnum_data_t hfnum;
+	dwc_list_link_t *qh_entry;
+	dwc_otg_qh_t *qh;
+	dwc_otg_transaction_type_e tr_type;
+	gintsts_data_t gintsts = {.d32 = 0 };
+
+	hfnum.d32 =
+	    DWC_READ_REG32(&hcd->core_if->host_if->host_global_regs->hfnum);
+
+#ifdef DEBUG_SOF
+	DWC_DEBUGPL(DBG_HCD, "--Start of Frame Interrupt--\n");
+#endif
+	hcd->frame_number = hfnum.b.frnum;
+
+#ifdef DEBUG
+	hcd->frrem_accum += hfnum.b.frrem;
+	hcd->frrem_samples++;
+#endif
+
+#ifdef DWC_TRACK_MISSED_SOFS
+	track_missed_sofs(hcd->frame_number);
+#endif
+	/* Determine whether any periodic QHs should be executed. */
+	qh_entry = DWC_LIST_FIRST(&hcd->periodic_sched_inactive);
+	while (qh_entry != &hcd->periodic_sched_inactive) {
+		qh = DWC_LIST_ENTRY(qh_entry, dwc_otg_qh_t, qh_list_entry);
+		qh_entry = qh_entry->next;
+		if (dwc_frame_num_le(qh->sched_frame, hcd->frame_number)) {
+			/*
+			 * Move QH to the ready list to be executed next
+			 * (micro)frame.
+			 */
+			DWC_LIST_MOVE_HEAD(&hcd->periodic_sched_ready,
+					   &qh->qh_list_entry);
+		}
+	}
+	tr_type = dwc_otg_hcd_select_transactions(hcd);
+	if (tr_type != DWC_OTG_TRANSACTION_NONE) {
+		dwc_otg_hcd_queue_transactions(hcd, tr_type);
+	}
+
+	/* Clear interrupt */
+	gintsts.b.sofintr = 1;
+	DWC_WRITE_REG32(&hcd->core_if->core_global_regs->gintsts, gintsts.d32);
+
+	return 1;
+}
+
+/** Handles the Rx Status Queue Level Interrupt, which indicates that there is at
+ * least one packet in the Rx FIFO.  The packets are moved from the FIFO to
+ * memory if the DWC_otg controller is operating in Slave mode. */
+int32_t dwc_otg_hcd_handle_rx_status_q_level_intr(dwc_otg_hcd_t * dwc_otg_hcd)
+{
+	host_grxsts_data_t grxsts;
+	dwc_hc_t *hc = NULL;
+
+	DWC_DEBUGPL(DBG_HCD, "--RxStsQ Level Interrupt--\n");
+
+	grxsts.d32 =
+	    DWC_READ_REG32(&dwc_otg_hcd->core_if->core_global_regs->grxstsp);
+
+	hc = dwc_otg_hcd->hc_ptr_array[grxsts.b.chnum];
+	if (!hc) {
+		DWC_ERROR("Unable to get corresponding channel\n");
+		return 0;
+	}
+
+	/* Packet Status */
+	DWC_DEBUGPL(DBG_HCDV, "    Ch num = %d\n", grxsts.b.chnum);
+	DWC_DEBUGPL(DBG_HCDV, "    Count = %d\n", grxsts.b.bcnt);
+	DWC_DEBUGPL(DBG_HCDV, "    DPID = %d, hc.dpid = %d\n", grxsts.b.dpid,
+		    hc->data_pid_start);
+	DWC_DEBUGPL(DBG_HCDV, "    PStatus = %d\n", grxsts.b.pktsts);
+
+	switch (grxsts.b.pktsts) {
+	case DWC_GRXSTS_PKTSTS_IN:
+		/* Read the data into the host buffer. */
+		if (grxsts.b.bcnt > 0) {
+			dwc_otg_read_packet(dwc_otg_hcd->core_if,
+					    hc->xfer_buff, grxsts.b.bcnt);
+
+			/* Update the HC fields for the next packet received. */
+			hc->xfer_count += grxsts.b.bcnt;
+			hc->xfer_buff += grxsts.b.bcnt;
+		}
+
+	case DWC_GRXSTS_PKTSTS_IN_XFER_COMP:
+	case DWC_GRXSTS_PKTSTS_DATA_TOGGLE_ERR:
+	case DWC_GRXSTS_PKTSTS_CH_HALTED:
+		/* Handled in interrupt, just ignore data */
+		break;
+	default:
+		DWC_ERROR("RX_STS_Q Interrupt: Unknown status %d\n",
+			  grxsts.b.pktsts);
+		break;
+	}
+
+	return 1;
+}
+
+/** This interrupt occurs when the non-periodic Tx FIFO is half-empty. More
+ * data packets may be written to the FIFO for OUT transfers. More requests
+ * may be written to the non-periodic request queue for IN transfers. This
+ * interrupt is enabled only in Slave mode. */
+int32_t dwc_otg_hcd_handle_np_tx_fifo_empty_intr(dwc_otg_hcd_t * dwc_otg_hcd)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Non-Periodic TxFIFO Empty Interrupt--\n");
+	dwc_otg_hcd_queue_transactions(dwc_otg_hcd,
+				       DWC_OTG_TRANSACTION_NON_PERIODIC);
+	return 1;
+}
+
+/** This interrupt occurs when the periodic Tx FIFO is half-empty. More data
+ * packets may be written to the FIFO for OUT transfers. More requests may be
+ * written to the periodic request queue for IN transfers. This interrupt is
+ * enabled only in Slave mode. */
+int32_t dwc_otg_hcd_handle_perio_tx_fifo_empty_intr(dwc_otg_hcd_t * dwc_otg_hcd)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Periodic TxFIFO Empty Interrupt--\n");
+	dwc_otg_hcd_queue_transactions(dwc_otg_hcd,
+				       DWC_OTG_TRANSACTION_PERIODIC);
+	return 1;
+}
+
+/** There are multiple conditions that can cause a port interrupt. This function
+ * determines which interrupt conditions have occurred and handles them
+ * appropriately. */
+int32_t dwc_otg_hcd_handle_port_intr(dwc_otg_hcd_t * dwc_otg_hcd)
+{
+	int retval = 0;
+	hprt0_data_t hprt0;
+	hprt0_data_t hprt0_modify;
+
+	hprt0.d32 = DWC_READ_REG32(dwc_otg_hcd->core_if->host_if->hprt0);
+	hprt0_modify.d32 = DWC_READ_REG32(dwc_otg_hcd->core_if->host_if->hprt0);
+
+	/* Clear appropriate bits in HPRT0 to clear the interrupt bit in
+	 * GINTSTS */
+
+	hprt0_modify.b.prtena = 0;
+	hprt0_modify.b.prtconndet = 0;
+	hprt0_modify.b.prtenchng = 0;
+	hprt0_modify.b.prtovrcurrchng = 0;
+
+	/* Port Connect Detected
+	 * Set flag and clear if detected */
+	if (dwc_otg_hcd->core_if->hibernation_suspend == 1) {
+		// Dont modify port status if we are in hibernation state
+		hprt0_modify.b.prtconndet = 1;
+		hprt0_modify.b.prtenchng = 1;
+		DWC_WRITE_REG32(dwc_otg_hcd->core_if->host_if->hprt0, hprt0_modify.d32);
+		hprt0.d32 = DWC_READ_REG32(dwc_otg_hcd->core_if->host_if->hprt0);
+		return retval;
+	}
+
+	if (hprt0.b.prtconndet) {
+		/** @todo - check if steps performed in 'else' block should be perfromed regardles adp */
+		if (dwc_otg_hcd->core_if->adp_enable &&
+				dwc_otg_hcd->core_if->adp.vbuson_timer_started == 1) {
+			DWC_PRINTF("PORT CONNECT DETECTED ----------------\n");
+			DWC_TIMER_CANCEL(dwc_otg_hcd->core_if->adp.vbuson_timer);
+			dwc_otg_hcd->core_if->adp.vbuson_timer_started = 0;
+			/* TODO - check if this is required, as
+			 * host initialization was already performed
+			 * after initial ADP probing
+			 */
+			/*dwc_otg_hcd->core_if->adp.vbuson_timer_started = 0;
+			dwc_otg_core_init(dwc_otg_hcd->core_if);
+			dwc_otg_enable_global_interrupts(dwc_otg_hcd->core_if);
+			cil_hcd_start(dwc_otg_hcd->core_if);*/
+		} else {
+			hprt0_data_t hprt0_local;
+			DWC_DEBUGPL(DBG_HCD, "--Port Interrupt HPRT0=0x%08x "
+				    "Port Connect Detected--\n", hprt0.d32);
+			dwc_otg_hcd->flags.b.port_connect_status_change = 1;
+			dwc_otg_hcd->flags.b.port_connect_status = 1;
+			hprt0_modify.b.prtconndet = 1;
+			/* PET testing */
+			if (dwc_otg_hcd->core_if->otg_ver && (dwc_otg_hcd->core_if->test_mode == 7)) {
+				hprt0_local.d32 = dwc_otg_read_hprt0(dwc_otg_hcd->core_if);
+				hprt0_local.b.prtrst = 1;
+				DWC_WRITE_REG32(dwc_otg_hcd->core_if->host_if->hprt0, hprt0_local.d32);
+				dwc_mdelay(60);
+				hprt0.d32 = dwc_otg_read_hprt0(dwc_otg_hcd->core_if);
+				hprt0.b.prtrst = 0;
+				DWC_WRITE_REG32(dwc_otg_hcd->core_if->host_if->hprt0, hprt0.d32);
+			}
+
+			/* B-Device has connected, Delete the connection timer. */
+			DWC_TIMER_CANCEL(dwc_otg_hcd->conn_timer);
+		}
+		/* The Hub driver asserts a reset when it sees port connect
+		 * status change flag */
+		retval |= 1;
+	}
+
+	/* Port Enable Changed
+	 * Clear if detected - Set internal flag if disabled */
+	if (hprt0.b.prtenchng) {
+		DWC_DEBUGPL(DBG_HCD, "  --Port Interrupt HPRT0=0x%08x "
+			    "Port Enable Changed--\n", hprt0.d32);
+		hprt0_modify.b.prtenchng = 1;
+		if (hprt0.b.prtena == 1) {
+			hfir_data_t hfir;
+			int do_reset = 0;
+			dwc_otg_core_params_t *params =
+			    dwc_otg_hcd->core_if->core_params;
+			dwc_otg_core_global_regs_t *global_regs =
+			    dwc_otg_hcd->core_if->core_global_regs;
+			dwc_otg_host_if_t *host_if =
+			    dwc_otg_hcd->core_if->host_if;
+
+			/* Every time when port enables calculate
+			 * HFIR.FrInterval
+			 */
+			hfir.d32 = DWC_READ_REG32(&host_if->host_global_regs->hfir);
+			hfir.b.frint = calc_frame_interval(dwc_otg_hcd->core_if);
+			DWC_WRITE_REG32(&host_if->host_global_regs->hfir, hfir.d32);
+
+			/* Check if we need to adjust the PHY clock speed for
+			 * low power and adjust it */
+			if (params->host_support_fs_ls_low_power) {
+				gusbcfg_data_t usbcfg;
+
+				usbcfg.d32 =
+				    DWC_READ_REG32(&global_regs->gusbcfg);
+
+				if (hprt0.b.prtspd == DWC_HPRT0_PRTSPD_LOW_SPEED
+				    || hprt0.b.prtspd ==
+				    DWC_HPRT0_PRTSPD_FULL_SPEED) {
+					/*
+					 * Low power
+					 */
+					hcfg_data_t hcfg;
+					if (usbcfg.b.phylpwrclksel == 0) {
+						/* Set PHY low power clock select for FS/LS devices */
+						usbcfg.b.phylpwrclksel = 1;
+						DWC_WRITE_REG32
+						    (&global_regs->gusbcfg,
+						     usbcfg.d32);
+						do_reset = 1;
+					}
+
+					hcfg.d32 =
+					    DWC_READ_REG32
+					    (&host_if->host_global_regs->hcfg);
+
+					if (hprt0.b.prtspd ==
+					    DWC_HPRT0_PRTSPD_LOW_SPEED
+					    && params->host_ls_low_power_phy_clk
+					    ==
+					    DWC_HOST_LS_LOW_POWER_PHY_CLK_PARAM_6MHZ)
+					{
+						/* 6 MHZ */
+						DWC_DEBUGPL(DBG_CIL,
+							    "FS_PHY programming HCFG to 6 MHz (Low Power)\n");
+						if (hcfg.b.fslspclksel !=
+						    DWC_HCFG_6_MHZ) {
+							hcfg.b.fslspclksel =
+							    DWC_HCFG_6_MHZ;
+							DWC_WRITE_REG32
+							    (&host_if->host_global_regs->hcfg,
+							     hcfg.d32);
+							do_reset = 1;
+						}
+					} else {
+						/* 48 MHZ */
+						DWC_DEBUGPL(DBG_CIL,
+							    "FS_PHY programming HCFG to 48 MHz ()\n");
+						if (hcfg.b.fslspclksel !=
+						    DWC_HCFG_48_MHZ) {
+							hcfg.b.fslspclksel =
+							    DWC_HCFG_48_MHZ;
+							DWC_WRITE_REG32
+							    (&host_if->host_global_regs->hcfg,
+							     hcfg.d32);
+							do_reset = 1;
+						}
+					}
+				} else {
+					/*
+					 * Not low power
+					 */
+					if (usbcfg.b.phylpwrclksel == 1) {
+						usbcfg.b.phylpwrclksel = 0;
+						DWC_WRITE_REG32
+						    (&global_regs->gusbcfg,
+						     usbcfg.d32);
+						do_reset = 1;
+					}
+				}
+
+				if (do_reset) {
+					DWC_TASK_SCHEDULE(dwc_otg_hcd->reset_tasklet);
+				}
+			}
+
+			if (!do_reset) {
+				/* Port has been enabled set the reset change flag */
+				dwc_otg_hcd->flags.b.port_reset_change = 1;
+			}
+		} else {
+			dwc_otg_hcd->flags.b.port_enable_change = 1;
+		}
+		retval |= 1;
+	}
+
+	/** Overcurrent Change Interrupt */
+	if (hprt0.b.prtovrcurrchng) {
+		DWC_DEBUGPL(DBG_HCD, "  --Port Interrupt HPRT0=0x%08x "
+			    "Port Overcurrent Changed--\n", hprt0.d32);
+		dwc_otg_hcd->flags.b.port_over_current_change = 1;
+		hprt0_modify.b.prtovrcurrchng = 1;
+		retval |= 1;
+	}
+
+	/* Clear Port Interrupts */
+	DWC_WRITE_REG32(dwc_otg_hcd->core_if->host_if->hprt0, hprt0_modify.d32);
+
+	return retval;
+}
+
+/** This interrupt indicates that one or more host channels has a pending
+ * interrupt. There are multiple conditions that can cause each host channel
+ * interrupt. This function determines which conditions have occurred for each
+ * host channel interrupt and handles them appropriately. */
+int32_t dwc_otg_hcd_handle_hc_intr(dwc_otg_hcd_t * dwc_otg_hcd)
+{
+	int i;
+	int retval = 0;
+	haint_data_t haint;
+
+	/* Clear appropriate bits in HCINTn to clear the interrupt bit in
+	 * GINTSTS */
+
+	haint.d32 = dwc_otg_read_host_all_channels_intr(dwc_otg_hcd->core_if);
+
+	for (i = 0; i < dwc_otg_hcd->core_if->core_params->host_channels; i++) {
+		if (haint.b2.chint & (1 << i)) {
+			retval |= dwc_otg_hcd_handle_hc_n_intr(dwc_otg_hcd, i);
+		}
+	}
+
+	return retval;
+}
+
+/**
+ * Gets the actual length of a transfer after the transfer halts. _halt_status
+ * holds the reason for the halt.
+ *
+ * For IN transfers where halt_status is DWC_OTG_HC_XFER_COMPLETE,
+ * *short_read is set to 1 upon return if less than the requested
+ * number of bytes were transferred. Otherwise, *short_read is set to 0 upon
+ * return. short_read may also be NULL on entry, in which case it remains
+ * unchanged.
+ */
+static uint32_t get_actual_xfer_length(dwc_hc_t * hc,
+				       dwc_otg_hc_regs_t * hc_regs,
+				       dwc_otg_qtd_t * qtd,
+				       dwc_otg_halt_status_e halt_status,
+				       int *short_read)
+{
+	hctsiz_data_t hctsiz;
+	uint32_t length;
+
+	if (short_read != NULL) {
+		*short_read = 0;
+	}
+	hctsiz.d32 = DWC_READ_REG32(&hc_regs->hctsiz);
+
+	if (halt_status == DWC_OTG_HC_XFER_COMPLETE) {
+		if (hc->ep_is_in) {
+			length = hc->xfer_len - hctsiz.b.xfersize;
+			if (short_read != NULL) {
+				*short_read = (hctsiz.b.xfersize != 0);
+			}
+		} else if (hc->qh->do_split) {
+			length = qtd->ssplit_out_xfer_count;
+		} else {
+			length = hc->xfer_len;
+		}
+	} else {
+		/*
+		 * Must use the hctsiz.pktcnt field to determine how much data
+		 * has been transferred. This field reflects the number of
+		 * packets that have been transferred via the USB. This is
+		 * always an integral number of packets if the transfer was
+		 * halted before its normal completion. (Can't use the
+		 * hctsiz.xfersize field because that reflects the number of
+		 * bytes transferred via the AHB, not the USB).
+		 */
+		length =
+		    (hc->start_pkt_count - hctsiz.b.pktcnt) * hc->max_packet;
+	}
+
+	return length;
+}
+
+/**
+ * Updates the state of the URB after a Transfer Complete interrupt on the
+ * host channel. Updates the actual_length field of the URB based on the
+ * number of bytes transferred via the host channel. Sets the URB status
+ * if the data transfer is finished.
+ *
+ * @return 1 if the data transfer specified by the URB is completely finished,
+ * 0 otherwise.
+ */
+static int update_urb_state_xfer_comp(dwc_hc_t * hc,
+				      dwc_otg_hc_regs_t * hc_regs,
+				      dwc_otg_hcd_urb_t * urb,
+				      dwc_otg_qtd_t * qtd)
+{
+	int xfer_done = 0;
+	int short_read = 0;
+
+	int xfer_length;
+
+	xfer_length = get_actual_xfer_length(hc, hc_regs, qtd,
+					     DWC_OTG_HC_XFER_COMPLETE,
+					     &short_read);
+
+
+	/* non DWORD-aligned buffer case handling. */
+	if (hc->align_buff && xfer_length && hc->ep_is_in) {
+		dwc_memcpy(urb->buf + urb->actual_length, hc->qh->dw_align_buf,
+			   xfer_length);
+	}
+
+	urb->actual_length += xfer_length;
+
+	if (xfer_length && (hc->ep_type == DWC_OTG_EP_TYPE_BULK) &&
+	    (urb->flags & URB_SEND_ZERO_PACKET)
+	    && (urb->actual_length == urb->length)
+	    && !(urb->length % hc->max_packet)) {
+		xfer_done = 0;
+	} else if (short_read || urb->actual_length == urb->length) {
+		xfer_done = 1;
+		urb->status = 0;
+	}
+
+#ifdef DEBUG
+	{
+		hctsiz_data_t hctsiz;
+		hctsiz.d32 = DWC_READ_REG32(&hc_regs->hctsiz);
+		DWC_DEBUGPL(DBG_HCDV, "DWC_otg: %s: %s, channel %d\n",
+			    __func__, (hc->ep_is_in ? "IN" : "OUT"),
+			    hc->hc_num);
+		DWC_DEBUGPL(DBG_HCDV, "  hc->xfer_len %d\n", hc->xfer_len);
+		DWC_DEBUGPL(DBG_HCDV, "  hctsiz.xfersize %d\n",
+			    hctsiz.b.xfersize);
+		DWC_DEBUGPL(DBG_HCDV, "  urb->transfer_buffer_length %d\n",
+			    urb->length);
+		DWC_DEBUGPL(DBG_HCDV, "  urb->actual_length %d\n",
+			    urb->actual_length);
+		DWC_DEBUGPL(DBG_HCDV, "  short_read %d, xfer_done %d\n",
+			    short_read, xfer_done);
+	}
+#endif
+
+	return xfer_done;
+}
+
+/*
+ * Save the starting data toggle for the next transfer. The data toggle is
+ * saved in the QH for non-control transfers and it's saved in the QTD for
+ * control transfers.
+ */
+void dwc_otg_hcd_save_data_toggle(dwc_hc_t * hc,
+			     dwc_otg_hc_regs_t * hc_regs, dwc_otg_qtd_t * qtd)
+{
+	hctsiz_data_t hctsiz;
+	hctsiz.d32 = DWC_READ_REG32(&hc_regs->hctsiz);
+
+	if (hc->ep_type != DWC_OTG_EP_TYPE_CONTROL) {
+		dwc_otg_qh_t *qh = hc->qh;
+		if (hctsiz.b.pid == DWC_HCTSIZ_DATA0) {
+			qh->data_toggle = DWC_OTG_HC_PID_DATA0;
+		} else {
+			qh->data_toggle = DWC_OTG_HC_PID_DATA1;
+		}
+	} else {
+		if (hctsiz.b.pid == DWC_HCTSIZ_DATA0) {
+			qtd->data_toggle = DWC_OTG_HC_PID_DATA0;
+		} else {
+			qtd->data_toggle = DWC_OTG_HC_PID_DATA1;
+		}
+	}
+}
+
+/**
+ * Updates the state of an Isochronous URB when the transfer is stopped for
+ * any reason. The fields of the current entry in the frame descriptor array
+ * are set based on the transfer state and the input _halt_status. Completes
+ * the Isochronous URB if all the URB frames have been completed.
+ *
+ * @return DWC_OTG_HC_XFER_COMPLETE if there are more frames remaining to be
+ * transferred in the URB. Otherwise return DWC_OTG_HC_XFER_URB_COMPLETE.
+ */
+static dwc_otg_halt_status_e
+update_isoc_urb_state(dwc_otg_hcd_t * hcd,
+		      dwc_hc_t * hc,
+		      dwc_otg_hc_regs_t * hc_regs,
+		      dwc_otg_qtd_t * qtd, dwc_otg_halt_status_e halt_status)
+{
+	dwc_otg_hcd_urb_t *urb = qtd->urb;
+	dwc_otg_halt_status_e ret_val = halt_status;
+	struct dwc_otg_hcd_iso_packet_desc *frame_desc;
+
+	frame_desc = &urb->iso_descs[qtd->isoc_frame_index];
+	switch (halt_status) {
+	case DWC_OTG_HC_XFER_COMPLETE:
+		frame_desc->status = 0;
+		frame_desc->actual_length =
+		    get_actual_xfer_length(hc, hc_regs, qtd, halt_status, NULL);
+
+		/* non DWORD-aligned buffer case handling. */
+		if (hc->align_buff && frame_desc->actual_length && hc->ep_is_in) {
+			dwc_memcpy(urb->buf + frame_desc->offset + qtd->isoc_split_offset,
+				   hc->qh->dw_align_buf, frame_desc->actual_length);
+		}
+
+		break;
+	case DWC_OTG_HC_XFER_FRAME_OVERRUN:
+		urb->error_count++;
+		if (hc->ep_is_in) {
+			frame_desc->status = -DWC_E_NO_STREAM_RES;
+		} else {
+			frame_desc->status = -DWC_E_COMMUNICATION;
+		}
+		frame_desc->actual_length = 0;
+		break;
+	case DWC_OTG_HC_XFER_BABBLE_ERR:
+		urb->error_count++;
+		frame_desc->status = -DWC_E_OVERFLOW;
+		/* Don't need to update actual_length in this case. */
+		break;
+	case DWC_OTG_HC_XFER_XACT_ERR:
+		urb->error_count++;
+		frame_desc->status = -DWC_E_PROTOCOL;
+		frame_desc->actual_length =
+		    get_actual_xfer_length(hc, hc_regs, qtd, halt_status, NULL);
+
+		/* non DWORD-aligned buffer case handling. */
+		if (hc->align_buff && frame_desc->actual_length && hc->ep_is_in) {
+			dwc_memcpy(urb->buf + frame_desc->offset + qtd->isoc_split_offset,
+				   hc->qh->dw_align_buf, frame_desc->actual_length);
+		}
+		/* Skip whole frame */
+		if (hc->qh->do_split && (hc->ep_type == DWC_OTG_EP_TYPE_ISOC) &&
+		    hc->ep_is_in && hcd->core_if->dma_enable) {
+			qtd->complete_split = 0;
+			qtd->isoc_split_offset = 0;
+		}
+
+		break;
+	default:
+		DWC_ASSERT(1, "Unhandled _halt_status (%d)\n", halt_status);
+		break;
+	}
+	if (++qtd->isoc_frame_index == urb->packet_count) {
+		/*
+		 * urb->status is not used for isoc transfers.
+		 * The individual frame_desc statuses are used instead.
+		 */
+		hcd->fops->complete(hcd, urb->priv, urb, 0);
+		ret_val = DWC_OTG_HC_XFER_URB_COMPLETE;
+	} else {
+		ret_val = DWC_OTG_HC_XFER_COMPLETE;
+	}
+	return ret_val;
+}
+
+/**
+ * Frees the first QTD in the QH's list if free_qtd is 1. For non-periodic
+ * QHs, removes the QH from the active non-periodic schedule. If any QTDs are
+ * still linked to the QH, the QH is added to the end of the inactive
+ * non-periodic schedule. For periodic QHs, removes the QH from the periodic
+ * schedule if no more QTDs are linked to the QH.
+ */
+static void deactivate_qh(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh, int free_qtd)
+{
+	int continue_split = 0;
+	dwc_otg_qtd_t *qtd;
+
+	DWC_DEBUGPL(DBG_HCDV, "  %s(%p,%p,%d)\n", __func__, hcd, qh, free_qtd);
+
+	qtd = DWC_CIRCLEQ_FIRST(&qh->qtd_list);
+
+	if (qtd->complete_split) {
+		continue_split = 1;
+	} else if (qtd->isoc_split_pos == DWC_HCSPLIT_XACTPOS_MID ||
+		   qtd->isoc_split_pos == DWC_HCSPLIT_XACTPOS_END) {
+		continue_split = 1;
+	}
+
+	if (free_qtd) {
+		dwc_otg_hcd_qtd_remove_and_free(hcd, qtd, qh);
+		continue_split = 0;
+	}
+
+	qh->channel = NULL;
+	dwc_otg_hcd_qh_deactivate(hcd, qh, continue_split);
+}
+
+/**
+ * Releases a host channel for use by other transfers. Attempts to select and
+ * queue more transactions since at least one host channel is available.
+ *
+ * @param hcd The HCD state structure.
+ * @param hc The host channel to release.
+ * @param qtd The QTD associated with the host channel. This QTD may be freed
+ * if the transfer is complete or an error has occurred.
+ * @param halt_status Reason the channel is being released. This status
+ * determines the actions taken by this function.
+ */
+static void release_channel(dwc_otg_hcd_t * hcd,
+			    dwc_hc_t * hc,
+			    dwc_otg_qtd_t * qtd,
+			    dwc_otg_halt_status_e halt_status)
+{
+	dwc_otg_transaction_type_e tr_type;
+	int free_qtd;
+
+	DWC_DEBUGPL(DBG_HCDV, "  %s: channel %d, halt_status %d\n",
+		    __func__, hc->hc_num, halt_status);
+
+	switch (halt_status) {
+	case DWC_OTG_HC_XFER_URB_COMPLETE:
+		free_qtd = 1;
+		break;
+	case DWC_OTG_HC_XFER_AHB_ERR:
+	case DWC_OTG_HC_XFER_STALL:
+	case DWC_OTG_HC_XFER_BABBLE_ERR:
+		free_qtd = 1;
+		break;
+	case DWC_OTG_HC_XFER_XACT_ERR:
+		if (qtd->error_count >= 3) {
+			DWC_DEBUGPL(DBG_HCDV,
+				    "  Complete URB with transaction error\n");
+			free_qtd = 1;
+			qtd->urb->status = -DWC_E_PROTOCOL;
+			hcd->fops->complete(hcd, qtd->urb->priv,
+					    qtd->urb, -DWC_E_PROTOCOL);
+		} else {
+			free_qtd = 0;
+		}
+		break;
+	case DWC_OTG_HC_XFER_URB_DEQUEUE:
+		/*
+		 * The QTD has already been removed and the QH has been
+		 * deactivated. Don't want to do anything except release the
+		 * host channel and try to queue more transfers.
+		 */
+		goto cleanup;
+	case DWC_OTG_HC_XFER_NO_HALT_STATUS:
+		free_qtd = 0;
+		break;
+	case DWC_OTG_HC_XFER_PERIODIC_INCOMPLETE:
+		DWC_DEBUGPL(DBG_HCDV,
+			"  Complete URB with I/O error\n");
+		free_qtd = 1;
+		qtd->urb->status = -DWC_E_IO;
+		hcd->fops->complete(hcd, qtd->urb->priv,
+			qtd->urb, -DWC_E_IO);
+		break;
+	default:
+		free_qtd = 0;
+		break;
+	}
+
+	deactivate_qh(hcd, hc->qh, free_qtd);
+
+cleanup:
+	/*
+	 * Release the host channel for use by other transfers. The cleanup
+	 * function clears the channel interrupt enables and conditions, so
+	 * there's no need to clear the Channel Halted interrupt separately.
+	 */
+	dwc_otg_hc_cleanup(hcd->core_if, hc);
+	DWC_CIRCLEQ_INSERT_TAIL(&hcd->free_hc_list, hc, hc_list_entry);
+
+	switch (hc->ep_type) {
+	case DWC_OTG_EP_TYPE_CONTROL:
+	case DWC_OTG_EP_TYPE_BULK:
+		hcd->non_periodic_channels--;
+		break;
+
+	default:
+		/*
+		 * Don't release reservations for periodic channels here.
+		 * That's done when a periodic transfer is descheduled (i.e.
+		 * when the QH is removed from the periodic schedule).
+		 */
+		break;
+	}
+
+	/* Try to queue more transfers now that there's a free channel. */
+	tr_type = dwc_otg_hcd_select_transactions(hcd);
+	if (tr_type != DWC_OTG_TRANSACTION_NONE) {
+		dwc_otg_hcd_queue_transactions(hcd, tr_type);
+	}
+}
+
+/**
+ * Halts a host channel. If the channel cannot be halted immediately because
+ * the request queue is full, this function ensures that the FIFO empty
+ * interrupt for the appropriate queue is enabled so that the halt request can
+ * be queued when there is space in the request queue.
+ *
+ * This function may also be called in DMA mode. In that case, the channel is
+ * simply released since the core always halts the channel automatically in
+ * DMA mode.
+ */
+static void halt_channel(dwc_otg_hcd_t * hcd,
+			 dwc_hc_t * hc,
+			 dwc_otg_qtd_t * qtd, dwc_otg_halt_status_e halt_status)
+{
+	if (hcd->core_if->dma_enable) {
+		release_channel(hcd, hc, qtd, halt_status);
+		return;
+	}
+
+	/* Slave mode processing... */
+	dwc_otg_hc_halt(hcd->core_if, hc, halt_status);
+
+	if (hc->halt_on_queue) {
+		gintmsk_data_t gintmsk = {.d32 = 0 };
+		dwc_otg_core_global_regs_t *global_regs;
+		global_regs = hcd->core_if->core_global_regs;
+
+		if (hc->ep_type == DWC_OTG_EP_TYPE_CONTROL ||
+		    hc->ep_type == DWC_OTG_EP_TYPE_BULK) {
+			/*
+			 * Make sure the Non-periodic Tx FIFO empty interrupt
+			 * is enabled so that the non-periodic schedule will
+			 * be processed.
+			 */
+			gintmsk.b.nptxfempty = 1;
+			DWC_MODIFY_REG32(&global_regs->gintmsk, 0, gintmsk.d32);
+		} else {
+			/*
+			 * Move the QH from the periodic queued schedule to
+			 * the periodic assigned schedule. This allows the
+			 * halt to be queued when the periodic schedule is
+			 * processed.
+			 */
+			DWC_LIST_MOVE_HEAD(&hcd->periodic_sched_assigned,
+					   &hc->qh->qh_list_entry);
+
+			/*
+			 * Make sure the Periodic Tx FIFO Empty interrupt is
+			 * enabled so that the periodic schedule will be
+			 * processed.
+			 */
+			gintmsk.b.ptxfempty = 1;
+			DWC_MODIFY_REG32(&global_regs->gintmsk, 0, gintmsk.d32);
+		}
+	}
+}
+
+/**
+ * Performs common cleanup for non-periodic transfers after a Transfer
+ * Complete interrupt. This function should be called after any endpoint type
+ * specific handling is finished to release the host channel.
+ */
+static void complete_non_periodic_xfer(dwc_otg_hcd_t * hcd,
+				       dwc_hc_t * hc,
+				       dwc_otg_hc_regs_t * hc_regs,
+				       dwc_otg_qtd_t * qtd,
+				       dwc_otg_halt_status_e halt_status)
+{
+	hcint_data_t hcint;
+
+	qtd->error_count = 0;
+
+	hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+	if (hcint.b.nyet) {
+		/*
+		 * Got a NYET on the last transaction of the transfer. This
+		 * means that the endpoint should be in the PING state at the
+		 * beginning of the next transfer.
+		 */
+		hc->qh->ping_state = 1;
+		clear_hc_int(hc_regs, nyet);
+	}
+
+	/*
+	 * Always halt and release the host channel to make it available for
+	 * more transfers. There may still be more phases for a control
+	 * transfer or more data packets for a bulk transfer at this point,
+	 * but the host channel is still halted. A channel will be reassigned
+	 * to the transfer when the non-periodic schedule is processed after
+	 * the channel is released. This allows transactions to be queued
+	 * properly via dwc_otg_hcd_queue_transactions, which also enables the
+	 * Tx FIFO Empty interrupt if necessary.
+	 */
+	if (hc->ep_is_in) {
+		/*
+		 * IN transfers in Slave mode require an explicit disable to
+		 * halt the channel. (In DMA mode, this call simply releases
+		 * the channel.)
+		 */
+		halt_channel(hcd, hc, qtd, halt_status);
+	} else {
+		/*
+		 * The channel is automatically disabled by the core for OUT
+		 * transfers in Slave mode.
+		 */
+		release_channel(hcd, hc, qtd, halt_status);
+	}
+}
+
+/**
+ * Performs common cleanup for periodic transfers after a Transfer Complete
+ * interrupt. This function should be called after any endpoint type specific
+ * handling is finished to release the host channel.
+ */
+static void complete_periodic_xfer(dwc_otg_hcd_t * hcd,
+				   dwc_hc_t * hc,
+				   dwc_otg_hc_regs_t * hc_regs,
+				   dwc_otg_qtd_t * qtd,
+				   dwc_otg_halt_status_e halt_status)
+{
+	hctsiz_data_t hctsiz;
+	qtd->error_count = 0;
+
+	hctsiz.d32 = DWC_READ_REG32(&hc_regs->hctsiz);
+	if (!hc->ep_is_in || hctsiz.b.pktcnt == 0) {
+		/* Core halts channel in these cases. */
+		release_channel(hcd, hc, qtd, halt_status);
+	} else {
+		/* Flush any outstanding requests from the Tx queue. */
+		halt_channel(hcd, hc, qtd, halt_status);
+	}
+}
+
+static int32_t handle_xfercomp_isoc_split_in(dwc_otg_hcd_t * hcd,
+					     dwc_hc_t * hc,
+					     dwc_otg_hc_regs_t * hc_regs,
+					     dwc_otg_qtd_t * qtd)
+{
+	uint32_t len;
+	struct dwc_otg_hcd_iso_packet_desc *frame_desc;
+	frame_desc = &qtd->urb->iso_descs[qtd->isoc_frame_index];
+
+	len = get_actual_xfer_length(hc, hc_regs, qtd,
+				     DWC_OTG_HC_XFER_COMPLETE, NULL);
+
+	if (!len) {
+		qtd->complete_split = 0;
+		qtd->isoc_split_offset = 0;
+		return 0;
+	}
+	frame_desc->actual_length += len;
+
+	if (hc->align_buff && len)
+		dwc_memcpy(qtd->urb->buf + frame_desc->offset +
+			   qtd->isoc_split_offset, hc->qh->dw_align_buf, len);
+	qtd->isoc_split_offset += len;
+
+	if (frame_desc->length == frame_desc->actual_length) {
+		frame_desc->status = 0;
+		qtd->isoc_frame_index++;
+		qtd->complete_split = 0;
+		qtd->isoc_split_offset = 0;
+	}
+
+	if (qtd->isoc_frame_index == qtd->urb->packet_count) {
+		hcd->fops->complete(hcd, qtd->urb->priv, qtd->urb, 0);
+		release_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_URB_COMPLETE);
+	} else {
+		release_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_NO_HALT_STATUS);
+	}
+
+	return 1;		/* Indicates that channel released */
+}
+
+/**
+ * Handles a host channel Transfer Complete interrupt. This handler may be
+ * called in either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_xfercomp_intr(dwc_otg_hcd_t * hcd,
+				       dwc_hc_t * hc,
+				       dwc_otg_hc_regs_t * hc_regs,
+				       dwc_otg_qtd_t * qtd)
+{
+	int urb_xfer_done;
+	dwc_otg_halt_status_e halt_status = DWC_OTG_HC_XFER_COMPLETE;
+	dwc_otg_hcd_urb_t *urb = qtd->urb;
+	int pipe_type = dwc_otg_hcd_get_pipe_type(&urb->pipe_info);
+
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		    "Transfer Complete--\n", hc->hc_num);
+
+	if (hcd->core_if->dma_desc_enable) {
+		dwc_otg_hcd_complete_xfer_ddma(hcd, hc, hc_regs, halt_status);
+		if (pipe_type == UE_ISOCHRONOUS) {
+			/* Do not disable the interrupt, just clear it */
+			clear_hc_int(hc_regs, xfercomp);
+			return 1;
+		}
+		goto handle_xfercomp_done;
+	}
+
+	/*
+	 * Handle xfer complete on CSPLIT.
+	 */
+
+	if (hc->qh->do_split) {
+		if ((hc->ep_type == DWC_OTG_EP_TYPE_ISOC) && hc->ep_is_in
+		    && hcd->core_if->dma_enable) {
+			if (qtd->complete_split
+			    && handle_xfercomp_isoc_split_in(hcd, hc, hc_regs,
+							     qtd))
+				goto handle_xfercomp_done;
+		} else {
+			qtd->complete_split = 0;
+		}
+	}
+
+	/* Update the QTD and URB states. */
+	switch (pipe_type) {
+	case UE_CONTROL:
+		switch (qtd->control_phase) {
+		case DWC_OTG_CONTROL_SETUP:
+			if (urb->length > 0) {
+				qtd->control_phase = DWC_OTG_CONTROL_DATA;
+			} else {
+				qtd->control_phase = DWC_OTG_CONTROL_STATUS;
+			}
+			DWC_DEBUGPL(DBG_HCDV,
+				    "  Control setup transaction done\n");
+			halt_status = DWC_OTG_HC_XFER_COMPLETE;
+			break;
+		case DWC_OTG_CONTROL_DATA:{
+				urb_xfer_done =
+				    update_urb_state_xfer_comp(hc, hc_regs, urb,
+							       qtd);
+				if (urb_xfer_done) {
+					qtd->control_phase =
+					    DWC_OTG_CONTROL_STATUS;
+					DWC_DEBUGPL(DBG_HCDV,
+						    "  Control data transfer done\n");
+				} else {
+					dwc_otg_hcd_save_data_toggle(hc, hc_regs, qtd);
+				}
+				halt_status = DWC_OTG_HC_XFER_COMPLETE;
+				break;
+			}
+		case DWC_OTG_CONTROL_STATUS:
+			DWC_DEBUGPL(DBG_HCDV, "  Control transfer complete\n");
+			if (urb->status == -DWC_E_IN_PROGRESS) {
+				urb->status = 0;
+			}
+			hcd->fops->complete(hcd, urb->priv, urb, urb->status);
+			halt_status = DWC_OTG_HC_XFER_URB_COMPLETE;
+			if (!hcd->core_if->dma_enable && hcd->core_if->otg_ver == 1)
+				qtd->urb = NULL;
+			break;
+		}
+
+		complete_non_periodic_xfer(hcd, hc, hc_regs, qtd, halt_status);
+		break;
+	case UE_BULK:
+		DWC_DEBUGPL(DBG_HCDV, "  Bulk transfer complete\n");
+		urb_xfer_done =
+		    update_urb_state_xfer_comp(hc, hc_regs, urb, qtd);
+		if (urb_xfer_done) {
+			hcd->fops->complete(hcd, urb->priv, urb, urb->status);
+			halt_status = DWC_OTG_HC_XFER_URB_COMPLETE;
+		} else {
+			halt_status = DWC_OTG_HC_XFER_COMPLETE;
+		}
+
+		dwc_otg_hcd_save_data_toggle(hc, hc_regs, qtd);
+		complete_non_periodic_xfer(hcd, hc, hc_regs, qtd, halt_status);
+		break;
+	case UE_INTERRUPT:
+		DWC_DEBUGPL(DBG_HCDV, "  Interrupt transfer complete\n");
+		urb_xfer_done =
+			update_urb_state_xfer_comp(hc, hc_regs, urb, qtd);
+
+		/*
+		 * Interrupt URB is done on the first transfer complete
+		 * interrupt.
+		 */
+		if (urb_xfer_done) {
+				hcd->fops->complete(hcd, urb->priv, urb, urb->status);
+				halt_status = DWC_OTG_HC_XFER_URB_COMPLETE;
+		} else {
+				halt_status = DWC_OTG_HC_XFER_COMPLETE;
+		}
+
+		dwc_otg_hcd_save_data_toggle(hc, hc_regs, qtd);
+		complete_periodic_xfer(hcd, hc, hc_regs, qtd, halt_status);
+		break;
+	case UE_ISOCHRONOUS:
+		DWC_DEBUGPL(DBG_HCDV, "  Isochronous transfer complete\n");
+		if (qtd->isoc_split_pos == DWC_HCSPLIT_XACTPOS_ALL) {
+			halt_status =
+			    update_isoc_urb_state(hcd, hc, hc_regs, qtd,
+						  DWC_OTG_HC_XFER_COMPLETE);
+		}
+		complete_periodic_xfer(hcd, hc, hc_regs, qtd, halt_status);
+		break;
+	}
+
+handle_xfercomp_done:
+	disable_hc_int(hc_regs, xfercompl);
+
+	return 1;
+}
+
+/**
+ * Handles a host channel STALL interrupt. This handler may be called in
+ * either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_stall_intr(dwc_otg_hcd_t * hcd,
+				    dwc_hc_t * hc,
+				    dwc_otg_hc_regs_t * hc_regs,
+				    dwc_otg_qtd_t * qtd)
+{
+	dwc_otg_hcd_urb_t *urb = qtd->urb;
+	int pipe_type = dwc_otg_hcd_get_pipe_type(&urb->pipe_info);
+
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		    "STALL Received--\n", hc->hc_num);
+
+	if (hcd->core_if->dma_desc_enable) {
+		dwc_otg_hcd_complete_xfer_ddma(hcd, hc, hc_regs, DWC_OTG_HC_XFER_STALL);
+		goto handle_stall_done;
+	}
+
+	if (pipe_type == UE_CONTROL) {
+		hcd->fops->complete(hcd, urb->priv, urb, -DWC_E_PIPE);
+	}
+
+	if (pipe_type == UE_BULK || pipe_type == UE_INTERRUPT) {
+		hcd->fops->complete(hcd, urb->priv, urb, -DWC_E_PIPE);
+		/*
+		 * USB protocol requires resetting the data toggle for bulk
+		 * and interrupt endpoints when a CLEAR_FEATURE(ENDPOINT_HALT)
+		 * setup command is issued to the endpoint. Anticipate the
+		 * CLEAR_FEATURE command since a STALL has occurred and reset
+		 * the data toggle now.
+		 */
+		hc->qh->data_toggle = 0;
+	}
+
+	halt_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_STALL);
+
+handle_stall_done:
+	disable_hc_int(hc_regs, stall);
+
+	return 1;
+}
+
+/*
+ * Updates the state of the URB when a transfer has been stopped due to an
+ * abnormal condition before the transfer completes. Modifies the
+ * actual_length field of the URB to reflect the number of bytes that have
+ * actually been transferred via the host channel.
+ */
+static void update_urb_state_xfer_intr(dwc_hc_t * hc,
+				       dwc_otg_hc_regs_t * hc_regs,
+				       dwc_otg_hcd_urb_t * urb,
+				       dwc_otg_qtd_t * qtd,
+				       dwc_otg_halt_status_e halt_status)
+{
+	uint32_t bytes_transferred = get_actual_xfer_length(hc, hc_regs, qtd,
+							    halt_status, NULL);
+	/* non DWORD-aligned buffer case handling. */
+	if (hc->align_buff && bytes_transferred && hc->ep_is_in) {
+		dwc_memcpy(urb->buf + urb->actual_length, hc->qh->dw_align_buf,
+			   bytes_transferred);
+	}
+
+	urb->actual_length += bytes_transferred;
+
+#ifdef DEBUG
+	{
+		hctsiz_data_t hctsiz;
+		hctsiz.d32 = DWC_READ_REG32(&hc_regs->hctsiz);
+		DWC_DEBUGPL(DBG_HCDV, "DWC_otg: %s: %s, channel %d\n",
+			    __func__, (hc->ep_is_in ? "IN" : "OUT"),
+			    hc->hc_num);
+		DWC_DEBUGPL(DBG_HCDV, "  hc->start_pkt_count %d\n",
+			    hc->start_pkt_count);
+		DWC_DEBUGPL(DBG_HCDV, "  hctsiz.pktcnt %d\n", hctsiz.b.pktcnt);
+		DWC_DEBUGPL(DBG_HCDV, "  hc->max_packet %d\n", hc->max_packet);
+		DWC_DEBUGPL(DBG_HCDV, "  bytes_transferred %d\n",
+			    bytes_transferred);
+		DWC_DEBUGPL(DBG_HCDV, "  urb->actual_length %d\n",
+			    urb->actual_length);
+		DWC_DEBUGPL(DBG_HCDV, "  urb->transfer_buffer_length %d\n",
+			    urb->length);
+	}
+#endif
+}
+
+/**
+ * Handles a host channel NAK interrupt. This handler may be called in either
+ * DMA mode or Slave mode.
+ */
+static int32_t handle_hc_nak_intr(dwc_otg_hcd_t * hcd,
+				  dwc_hc_t * hc,
+				  dwc_otg_hc_regs_t * hc_regs,
+				  dwc_otg_qtd_t * qtd)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		    "NAK Received--\n", hc->hc_num);
+
+	/*
+	 * Handle NAK for IN/OUT SSPLIT/CSPLIT transfers, bulk, control, and
+	 * interrupt.  Re-start the SSPLIT transfer.
+	 */
+	if (hc->do_split) {
+		if (hc->complete_split) {
+			qtd->error_count = 0;
+		}
+		qtd->complete_split = 0;
+		halt_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_NAK);
+		goto handle_nak_done;
+	}
+
+	switch (dwc_otg_hcd_get_pipe_type(&qtd->urb->pipe_info)) {
+	case UE_CONTROL:
+	case UE_BULK:
+		if (hcd->core_if->dma_enable && hc->ep_is_in) {
+			/*
+			 * NAK interrupts are enabled on bulk/control IN
+			 * transfers in DMA mode for the sole purpose of
+			 * resetting the error count after a transaction error
+			 * occurs. The core will continue transferring data.
+			 */
+			qtd->error_count = 0;
+			goto handle_nak_done;
+		}
+
+		/*
+		 * NAK interrupts normally occur during OUT transfers in DMA
+		 * or Slave mode. For IN transfers, more requests will be
+		 * queued as request queue space is available.
+		 */
+		qtd->error_count = 0;
+
+		if (!hc->qh->ping_state) {
+			update_urb_state_xfer_intr(hc, hc_regs,
+						   qtd->urb, qtd,
+						   DWC_OTG_HC_XFER_NAK);
+			dwc_otg_hcd_save_data_toggle(hc, hc_regs, qtd);
+
+			if (hc->speed == DWC_OTG_EP_SPEED_HIGH)
+				hc->qh->ping_state = 1;
+		}
+
+		/*
+		 * Halt the channel so the transfer can be re-started from
+		 * the appropriate point or the PING protocol will
+		 * start/continue.
+		 */
+		halt_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_NAK);
+		break;
+	case UE_INTERRUPT:
+		qtd->error_count = 0;
+		halt_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_NAK);
+		break;
+	case UE_ISOCHRONOUS:
+		/* Should never get called for isochronous transfers. */
+		DWC_ASSERT(1, "NACK interrupt for ISOC transfer\n");
+		break;
+	}
+
+handle_nak_done:
+	disable_hc_int(hc_regs, nak);
+
+	return 1;
+}
+
+/**
+ * Handles a host channel ACK interrupt. This interrupt is enabled when
+ * performing the PING protocol in Slave mode, when errors occur during
+ * either Slave mode or DMA mode, and during Start Split transactions.
+ */
+static int32_t handle_hc_ack_intr(dwc_otg_hcd_t * hcd,
+				  dwc_hc_t * hc,
+				  dwc_otg_hc_regs_t * hc_regs,
+				  dwc_otg_qtd_t * qtd)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		    "ACK Received--\n", hc->hc_num);
+
+	if (hc->do_split) {
+		/*
+		 * Handle ACK on SSPLIT.
+		 * ACK should not occur in CSPLIT.
+		 */
+		if (!hc->ep_is_in && hc->data_pid_start != DWC_OTG_HC_PID_SETUP) {
+			qtd->ssplit_out_xfer_count = hc->xfer_len;
+		}
+		if (!(hc->ep_type == DWC_OTG_EP_TYPE_ISOC && !hc->ep_is_in)) {
+			/* Don't need complete for isochronous out transfers. */
+			qtd->complete_split = 1;
+		}
+
+		/* ISOC OUT */
+		if (hc->ep_type == DWC_OTG_EP_TYPE_ISOC && !hc->ep_is_in) {
+			switch (hc->xact_pos) {
+			case DWC_HCSPLIT_XACTPOS_ALL:
+				break;
+			case DWC_HCSPLIT_XACTPOS_END:
+				qtd->isoc_split_pos = DWC_HCSPLIT_XACTPOS_ALL;
+				qtd->isoc_split_offset = 0;
+				break;
+			case DWC_HCSPLIT_XACTPOS_BEGIN:
+			case DWC_HCSPLIT_XACTPOS_MID:
+				/*
+				 * For BEGIN or MID, calculate the length for
+				 * the next microframe to determine the correct
+				 * SSPLIT token, either MID or END.
+				 */
+				{
+					struct dwc_otg_hcd_iso_packet_desc
+					*frame_desc;
+
+					frame_desc =
+					    &qtd->urb->
+					    iso_descs[qtd->isoc_frame_index];
+					qtd->isoc_split_offset += 188;
+
+					if ((frame_desc->length -
+					     qtd->isoc_split_offset) <= 188) {
+						qtd->isoc_split_pos =
+						    DWC_HCSPLIT_XACTPOS_END;
+					} else {
+						qtd->isoc_split_pos =
+						    DWC_HCSPLIT_XACTPOS_MID;
+					}
+
+				}
+				break;
+			}
+		} else {
+			halt_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_ACK);
+		}
+	} else {
+		qtd->error_count = 0;
+
+		if (hc->qh->ping_state) {
+			hc->qh->ping_state = 0;
+			/*
+			 * Halt the channel so the transfer can be re-started
+			 * from the appropriate point. This only happens in
+			 * Slave mode. In DMA mode, the ping_state is cleared
+			 * when the transfer is started because the core
+			 * automatically executes the PING, then the transfer.
+			 */
+			halt_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_ACK);
+		}
+	}
+
+	/*
+	 * If the ACK occurred when _not_ in the PING state, let the channel
+	 * continue transferring data after clearing the error count.
+	 */
+
+	disable_hc_int(hc_regs, ack);
+
+	return 1;
+}
+
+/**
+ * Handles a host channel NYET interrupt. This interrupt should only occur on
+ * Bulk and Control OUT endpoints and for complete split transactions. If a
+ * NYET occurs at the same time as a Transfer Complete interrupt, it is
+ * handled in the xfercomp interrupt handler, not here. This handler may be
+ * called in either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_nyet_intr(dwc_otg_hcd_t * hcd,
+				   dwc_hc_t * hc,
+				   dwc_otg_hc_regs_t * hc_regs,
+				   dwc_otg_qtd_t * qtd)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		    "NYET Received--\n", hc->hc_num);
+
+	/*
+	 * NYET on CSPLIT
+	 * re-do the CSPLIT immediately on non-periodic
+	 */
+	if (hc->do_split && hc->complete_split) {
+		if (hc->ep_is_in && (hc->ep_type == DWC_OTG_EP_TYPE_ISOC)
+		    && hcd->core_if->dma_enable) {
+			qtd->complete_split = 0;
+			qtd->isoc_split_offset = 0;
+			if (++qtd->isoc_frame_index == qtd->urb->packet_count) {
+				hcd->fops->complete(hcd, qtd->urb->priv, qtd->urb, 0);
+				release_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_URB_COMPLETE);
+			}
+			else
+				release_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_NO_HALT_STATUS);
+			goto handle_nyet_done;
+		}
+
+		if (hc->ep_type == DWC_OTG_EP_TYPE_INTR ||
+		    hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+			int frnum = dwc_otg_hcd_get_frame_number(hcd);
+
+			if (dwc_full_frame_num(frnum) !=
+			    dwc_full_frame_num(hc->qh->sched_frame)) {
+				/*
+				 * No longer in the same full speed frame.
+				 * Treat this as a transaction error.
+				 */
+				qtd->complete_split = 0;
+				halt_channel(hcd, hc, qtd,
+					     DWC_OTG_HC_XFER_XACT_ERR);
+				/** @todo add support for isoc release */
+				goto handle_nyet_done;
+			}
+		}
+
+		halt_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_NYET);
+		goto handle_nyet_done;
+	}
+
+	hc->qh->ping_state = 1;
+	qtd->error_count = 0;
+
+	update_urb_state_xfer_intr(hc, hc_regs, qtd->urb, qtd,
+				   DWC_OTG_HC_XFER_NYET);
+	dwc_otg_hcd_save_data_toggle(hc, hc_regs, qtd);
+
+	/*
+	 * Halt the channel and re-start the transfer so the PING
+	 * protocol will start.
+	 */
+	halt_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_NYET);
+
+handle_nyet_done:
+	disable_hc_int(hc_regs, nyet);
+	return 1;
+}
+
+/**
+ * Handles a host channel babble interrupt. This handler may be called in
+ * either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_babble_intr(dwc_otg_hcd_t * hcd,
+				     dwc_hc_t * hc,
+				     dwc_otg_hc_regs_t * hc_regs,
+				     dwc_otg_qtd_t * qtd)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		    "Babble Error--\n", hc->hc_num);
+
+	if (hcd->core_if->dma_desc_enable) {
+		dwc_otg_hcd_complete_xfer_ddma(hcd, hc, hc_regs,
+					       DWC_OTG_HC_XFER_BABBLE_ERR);
+		goto handle_babble_done;
+	}
+
+	if (hc->ep_type != DWC_OTG_EP_TYPE_ISOC) {
+		hcd->fops->complete(hcd, qtd->urb->priv,
+				    qtd->urb, -DWC_E_OVERFLOW);
+		halt_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_BABBLE_ERR);
+	} else {
+		dwc_otg_halt_status_e halt_status;
+		halt_status = update_isoc_urb_state(hcd, hc, hc_regs, qtd,
+						    DWC_OTG_HC_XFER_BABBLE_ERR);
+		halt_channel(hcd, hc, qtd, halt_status);
+	}
+
+handle_babble_done:
+	disable_hc_int(hc_regs, bblerr);
+	return 1;
+}
+
+/**
+ * Handles a host channel AHB error interrupt. This handler is only called in
+ * DMA mode.
+ */
+static int32_t handle_hc_ahberr_intr(dwc_otg_hcd_t * hcd,
+				     dwc_hc_t * hc,
+				     dwc_otg_hc_regs_t * hc_regs,
+				     dwc_otg_qtd_t * qtd)
+{
+	hcchar_data_t hcchar;
+	hcsplt_data_t hcsplt;
+	hctsiz_data_t hctsiz;
+	uint32_t hcdma;
+	char *pipetype, *speed;
+
+	dwc_otg_hcd_urb_t *urb = qtd->urb;
+
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		    "AHB Error--\n", hc->hc_num);
+
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	hcsplt.d32 = DWC_READ_REG32(&hc_regs->hcsplt);
+	hctsiz.d32 = DWC_READ_REG32(&hc_regs->hctsiz);
+	hcdma = DWC_READ_REG32(&hc_regs->hcdma);
+
+	DWC_ERROR("AHB ERROR, Channel %d\n", hc->hc_num);
+	DWC_ERROR("  hcchar 0x%08x, hcsplt 0x%08x\n", hcchar.d32, hcsplt.d32);
+	DWC_ERROR("  hctsiz 0x%08x, hcdma 0x%08x\n", hctsiz.d32, hcdma);
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD URB Enqueue\n");
+	DWC_ERROR("  Device address: %d\n",
+		  dwc_otg_hcd_get_dev_addr(&urb->pipe_info));
+	DWC_ERROR("  Endpoint: %d, %s\n",
+		  dwc_otg_hcd_get_ep_num(&urb->pipe_info),
+		  (dwc_otg_hcd_is_pipe_in(&urb->pipe_info) ? "IN" : "OUT"));
+
+	switch (dwc_otg_hcd_get_pipe_type(&urb->pipe_info)) {
+	case UE_CONTROL:
+		pipetype = "CONTROL";
+		break;
+	case UE_BULK:
+		pipetype = "BULK";
+		break;
+	case UE_INTERRUPT:
+		pipetype = "INTERRUPT";
+		break;
+	case UE_ISOCHRONOUS:
+		pipetype = "ISOCHRONOUS";
+		break;
+	default:
+		pipetype = "UNKNOWN";
+		break;
+	}
+
+	DWC_ERROR("  Endpoint type: %s\n", pipetype);
+
+	switch (hc->speed) {
+	case DWC_OTG_EP_SPEED_HIGH:
+		speed = "HIGH";
+		break;
+	case DWC_OTG_EP_SPEED_FULL:
+		speed = "FULL";
+		break;
+	case DWC_OTG_EP_SPEED_LOW:
+		speed = "LOW";
+		break;
+	default:
+		speed = "UNKNOWN";
+		break;
+	};
+
+	DWC_ERROR("  Speed: %s\n", speed);
+
+	DWC_ERROR("  Max packet size: %d\n",
+		  dwc_otg_hcd_get_mps(&urb->pipe_info));
+	DWC_ERROR("  Data buffer length: %d\n", urb->length);
+	DWC_ERROR("  Transfer buffer: %p, Transfer DMA: %p\n",
+		  urb->buf, (void *)urb->dma);
+	DWC_ERROR("  Setup buffer: %p, Setup DMA: %p\n",
+		  urb->setup_packet, (void *)urb->setup_dma);
+	DWC_ERROR("  Interval: %d\n", urb->interval);
+
+	/* Core haltes the channel for Descriptor DMA mode */
+	if (hcd->core_if->dma_desc_enable) {
+		dwc_otg_hcd_complete_xfer_ddma(hcd, hc, hc_regs,
+					       DWC_OTG_HC_XFER_AHB_ERR);
+		goto handle_ahberr_done;
+	}
+
+	hcd->fops->complete(hcd, urb->priv, urb, -DWC_E_IO);
+
+	/*
+	 * Force a channel halt. Don't call halt_channel because that won't
+	 * write to the HCCHARn register in DMA mode to force the halt.
+	 */
+	dwc_otg_hc_halt(hcd->core_if, hc, DWC_OTG_HC_XFER_AHB_ERR);
+handle_ahberr_done:
+	disable_hc_int(hc_regs, ahberr);
+	return 1;
+}
+
+/**
+ * Handles a host channel transaction error interrupt. This handler may be
+ * called in either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_xacterr_intr(dwc_otg_hcd_t * hcd,
+				      dwc_hc_t * hc,
+				      dwc_otg_hc_regs_t * hc_regs,
+				      dwc_otg_qtd_t * qtd)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		    "Transaction Error--\n", hc->hc_num);
+
+	if (hcd->core_if->dma_desc_enable) {
+		dwc_otg_hcd_complete_xfer_ddma(hcd, hc, hc_regs,
+					       DWC_OTG_HC_XFER_XACT_ERR);
+		goto handle_xacterr_done;
+	}
+
+	switch (dwc_otg_hcd_get_pipe_type(&qtd->urb->pipe_info)) {
+	case UE_CONTROL:
+	case UE_BULK:
+		qtd->error_count++;
+		if (!hc->qh->ping_state) {
+
+			update_urb_state_xfer_intr(hc, hc_regs,
+						   qtd->urb, qtd,
+						   DWC_OTG_HC_XFER_XACT_ERR);
+			dwc_otg_hcd_save_data_toggle(hc, hc_regs, qtd);
+			if (!hc->ep_is_in && hc->speed == DWC_OTG_EP_SPEED_HIGH) {
+				hc->qh->ping_state = 1;
+			}
+		}
+
+		/*
+		 * Halt the channel so the transfer can be re-started from
+		 * the appropriate point or the PING protocol will start.
+		 */
+		halt_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_XACT_ERR);
+		break;
+	case UE_INTERRUPT:
+		qtd->error_count++;
+		if (hc->do_split && hc->complete_split) {
+			qtd->complete_split = 0;
+		}
+		halt_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_XACT_ERR);
+		break;
+	case UE_ISOCHRONOUS:
+		{
+			dwc_otg_halt_status_e halt_status;
+			halt_status =
+			    update_isoc_urb_state(hcd, hc, hc_regs, qtd,
+						  DWC_OTG_HC_XFER_XACT_ERR);
+
+			halt_channel(hcd, hc, qtd, halt_status);
+		}
+		break;
+	}
+handle_xacterr_done:
+	disable_hc_int(hc_regs, xacterr);
+
+	return 1;
+}
+
+/**
+ * Handles a host channel frame overrun interrupt. This handler may be called
+ * in either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_frmovrun_intr(dwc_otg_hcd_t * hcd,
+				       dwc_hc_t * hc,
+				       dwc_otg_hc_regs_t * hc_regs,
+				       dwc_otg_qtd_t * qtd)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		    "Frame Overrun--\n", hc->hc_num);
+
+	switch (dwc_otg_hcd_get_pipe_type(&qtd->urb->pipe_info)) {
+	case UE_CONTROL:
+	case UE_BULK:
+		break;
+	case UE_INTERRUPT:
+		halt_channel(hcd, hc, qtd, DWC_OTG_HC_XFER_FRAME_OVERRUN);
+		break;
+	case UE_ISOCHRONOUS:
+		{
+			dwc_otg_halt_status_e halt_status;
+			halt_status =
+			    update_isoc_urb_state(hcd, hc, hc_regs, qtd,
+						  DWC_OTG_HC_XFER_FRAME_OVERRUN);
+
+			halt_channel(hcd, hc, qtd, halt_status);
+		}
+		break;
+	}
+
+	disable_hc_int(hc_regs, frmovrun);
+
+	return 1;
+}
+
+/**
+ * Handles a host channel data toggle error interrupt. This handler may be
+ * called in either DMA mode or Slave mode.
+ */
+static int32_t handle_hc_datatglerr_intr(dwc_otg_hcd_t * hcd,
+					 dwc_hc_t * hc,
+					 dwc_otg_hc_regs_t * hc_regs,
+					 dwc_otg_qtd_t * qtd)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		    "Data Toggle Error--\n", hc->hc_num);
+
+	if (hc->ep_is_in) {
+		qtd->error_count = 0;
+	} else {
+		DWC_ERROR("Data Toggle Error on OUT transfer,"
+			  "channel %d\n", hc->hc_num);
+	}
+
+	disable_hc_int(hc_regs, datatglerr);
+
+	return 1;
+}
+
+#ifdef DEBUG
+/**
+ * This function is for debug only. It checks that a valid halt status is set
+ * and that HCCHARn.chdis is clear. If there's a problem, corrective action is
+ * taken and a warning is issued.
+ * @return 1 if halt status is ok, 0 otherwise.
+ */
+static inline int halt_status_ok(dwc_otg_hcd_t * hcd,
+				 dwc_hc_t * hc,
+				 dwc_otg_hc_regs_t * hc_regs,
+				 dwc_otg_qtd_t * qtd)
+{
+	hcchar_data_t hcchar;
+	hctsiz_data_t hctsiz;
+	hcint_data_t hcint;
+	hcintmsk_data_t hcintmsk;
+	hcsplt_data_t hcsplt;
+
+	if (hc->halt_status == DWC_OTG_HC_XFER_NO_HALT_STATUS) {
+		/*
+		 * This code is here only as a check. This condition should
+		 * never happen. Ignore the halt if it does occur.
+		 */
+		hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+		hctsiz.d32 = DWC_READ_REG32(&hc_regs->hctsiz);
+		hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+		hcintmsk.d32 = DWC_READ_REG32(&hc_regs->hcintmsk);
+		hcsplt.d32 = DWC_READ_REG32(&hc_regs->hcsplt);
+		DWC_WARN
+		    ("%s: hc->halt_status == DWC_OTG_HC_XFER_NO_HALT_STATUS, "
+		     "channel %d, hcchar 0x%08x, hctsiz 0x%08x, "
+		     "hcint 0x%08x, hcintmsk 0x%08x, "
+		     "hcsplt 0x%08x, qtd->complete_split %d\n", __func__,
+		     hc->hc_num, hcchar.d32, hctsiz.d32, hcint.d32,
+		     hcintmsk.d32, hcsplt.d32, qtd->complete_split);
+
+		DWC_WARN("%s: no halt status, channel %d, ignoring interrupt\n",
+			 __func__, hc->hc_num);
+		DWC_WARN("\n");
+		clear_hc_int(hc_regs, chhltd);
+		return 0;
+	}
+
+	/*
+	 * This code is here only as a check. hcchar.chdis should
+	 * never be set when the halt interrupt occurs. Halt the
+	 * channel again if it does occur.
+	 */
+	hcchar.d32 = DWC_READ_REG32(&hc_regs->hcchar);
+	if (hcchar.b.chdis) {
+		DWC_WARN("%s: hcchar.chdis set unexpectedly, "
+			 "hcchar 0x%08x, trying to halt again\n",
+			 __func__, hcchar.d32);
+		clear_hc_int(hc_regs, chhltd);
+		hc->halt_pending = 0;
+		halt_channel(hcd, hc, qtd, hc->halt_status);
+		return 0;
+	}
+
+	return 1;
+}
+#endif
+
+/**
+ * Handles a host Channel Halted interrupt in DMA mode. This handler
+ * determines the reason the channel halted and proceeds accordingly.
+ */
+static void handle_hc_chhltd_intr_dma(dwc_otg_hcd_t * hcd,
+				      dwc_hc_t * hc,
+				      dwc_otg_hc_regs_t * hc_regs,
+				      dwc_otg_qtd_t * qtd)
+{
+	hcint_data_t hcint;
+	hcintmsk_data_t hcintmsk;
+	int out_nak_enh = 0;
+
+	/* For core with OUT NAK enhancement, the flow for high-
+	 * speed CONTROL/BULK OUT is handled a little differently.
+	 */
+	if (hcd->core_if->snpsid >= OTG_CORE_REV_2_71a) {
+		if (hc->speed == DWC_OTG_EP_SPEED_HIGH && !hc->ep_is_in &&
+		    (hc->ep_type == DWC_OTG_EP_TYPE_CONTROL ||
+		     hc->ep_type == DWC_OTG_EP_TYPE_BULK)) {
+			out_nak_enh = 1;
+		}
+	}
+
+	if (hc->halt_status == DWC_OTG_HC_XFER_URB_DEQUEUE ||
+	    (hc->halt_status == DWC_OTG_HC_XFER_AHB_ERR
+	     && !hcd->core_if->dma_desc_enable)) {
+		/*
+		 * Just release the channel. A dequeue can happen on a
+		 * transfer timeout. In the case of an AHB Error, the channel
+		 * was forced to halt because there's no way to gracefully
+		 * recover.
+		 */
+		if (hcd->core_if->dma_desc_enable)
+			dwc_otg_hcd_complete_xfer_ddma(hcd, hc, hc_regs,
+						       hc->halt_status);
+		else
+			release_channel(hcd, hc, qtd, hc->halt_status);
+		return;
+	}
+
+	/* Read the HCINTn register to determine the cause for the halt. */
+	hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+	hcintmsk.d32 = DWC_READ_REG32(&hc_regs->hcintmsk);
+
+	if (hcint.b.xfercomp) {
+		/** @todo This is here because of a possible hardware bug.  Spec
+		 * says that on SPLIT-ISOC OUT transfers in DMA mode that a HALT
+		 * interrupt w/ACK bit set should occur, but I only see the
+		 * XFERCOMP bit, even with it masked out.  This is a workaround
+		 * for that behavior.  Should fix this when hardware is fixed.
+		 */
+		if (hc->ep_type == DWC_OTG_EP_TYPE_ISOC && !hc->ep_is_in) {
+			handle_hc_ack_intr(hcd, hc, hc_regs, qtd);
+		}
+		handle_hc_xfercomp_intr(hcd, hc, hc_regs, qtd);
+	} else if (hcint.b.stall) {
+		handle_hc_stall_intr(hcd, hc, hc_regs, qtd);
+	} else if (hcint.b.xacterr && !hcd->core_if->dma_desc_enable) {
+		if (out_nak_enh) {
+			if (hcint.b.nyet || hcint.b.nak || hcint.b.ack) {
+				DWC_DEBUG("XactErr with NYET/NAK/ACK\n");
+				qtd->error_count = 0;
+			} else {
+				DWC_DEBUG("XactErr without NYET/NAK/ACK\n");
+			}
+		}
+
+		/*
+		 * Must handle xacterr before nak or ack. Could get a xacterr
+		 * at the same time as either of these on a BULK/CONTROL OUT
+		 * that started with a PING. The xacterr takes precedence.
+		 */
+		handle_hc_xacterr_intr(hcd, hc, hc_regs, qtd);
+	} else if (hcint.b.xcs_xact && hcd->core_if->dma_desc_enable) {
+		handle_hc_xacterr_intr(hcd, hc, hc_regs, qtd);
+	} else if (hcint.b.ahberr && hcd->core_if->dma_desc_enable) {
+		handle_hc_ahberr_intr(hcd, hc, hc_regs, qtd);
+	} else if (hcint.b.bblerr) {
+		handle_hc_babble_intr(hcd, hc, hc_regs, qtd);
+	} else if (hcint.b.frmovrun) {
+		handle_hc_frmovrun_intr(hcd, hc, hc_regs, qtd);
+	} else if (!out_nak_enh) {
+		if (hcint.b.nyet) {
+			/*
+			 * Must handle nyet before nak or ack. Could get a nyet at the
+			 * same time as either of those on a BULK/CONTROL OUT that
+			 * started with a PING. The nyet takes precedence.
+			 */
+			handle_hc_nyet_intr(hcd, hc, hc_regs, qtd);
+		} else if (hcint.b.nak && !hcintmsk.b.nak) {
+			/*
+			 * If nak is not masked, it's because a non-split IN transfer
+			 * is in an error state. In that case, the nak is handled by
+			 * the nak interrupt handler, not here. Handle nak here for
+			 * BULK/CONTROL OUT transfers, which halt on a NAK to allow
+			 * rewinding the buffer pointer.
+			 */
+			handle_hc_nak_intr(hcd, hc, hc_regs, qtd);
+		} else if (hcint.b.ack && !hcintmsk.b.ack) {
+			/*
+			 * If ack is not masked, it's because a non-split IN transfer
+			 * is in an error state. In that case, the ack is handled by
+			 * the ack interrupt handler, not here. Handle ack here for
+			 * split transfers. Start splits halt on ACK.
+			 */
+			handle_hc_ack_intr(hcd, hc, hc_regs, qtd);
+		} else {
+			if (hc->ep_type == DWC_OTG_EP_TYPE_INTR ||
+			    hc->ep_type == DWC_OTG_EP_TYPE_ISOC) {
+				/*
+				 * A periodic transfer halted with no other channel
+				 * interrupts set. Assume it was halted by the core
+				 * because it could not be completed in its scheduled
+				 * (micro)frame.
+				 */
+#ifdef DEBUG
+				DWC_PRINTF
+				    ("%s: Halt channel %d (assume incomplete periodic transfer)\n",
+				     __func__, hc->hc_num);
+#endif
+				halt_channel(hcd, hc, qtd,
+					     DWC_OTG_HC_XFER_PERIODIC_INCOMPLETE);
+			} else {
+				DWC_ERROR
+				    ("%s: Channel %d, DMA Mode -- ChHltd set, but reason "
+				     "for halting is unknown, hcint 0x%08x, intsts 0x%08x\n",
+				     __func__, hc->hc_num, hcint.d32,
+				     DWC_READ_REG32(&hcd->
+						    core_if->core_global_regs->
+						    gintsts));
+				disable_hc_int(hc_regs, chhltd);
+			}
+
+		}
+	} else {
+		DWC_PRINTF("NYET/NAK/ACK/other in non-error case, 0x%08x\n",
+			   hcint.d32);
+		disable_hc_int(hc_regs, chhltd);
+	}
+}
+
+/**
+ * Handles a host channel Channel Halted interrupt.
+ *
+ * In slave mode, this handler is called only when the driver specifically
+ * requests a halt. This occurs during handling other host channel interrupts
+ * (e.g. nak, xacterr, stall, nyet, etc.).
+ *
+ * In DMA mode, this is the interrupt that occurs when the core has finished
+ * processing a transfer on a channel. Other host channel interrupts (except
+ * ahberr) are disabled in DMA mode.
+ */
+static int32_t handle_hc_chhltd_intr(dwc_otg_hcd_t * hcd,
+				     dwc_hc_t * hc,
+				     dwc_otg_hc_regs_t * hc_regs,
+				     dwc_otg_qtd_t * qtd)
+{
+	DWC_DEBUGPL(DBG_HCD, "--Host Channel %d Interrupt: "
+		    "Channel Halted--\n", hc->hc_num);
+
+	if (hcd->core_if->dma_enable) {
+		handle_hc_chhltd_intr_dma(hcd, hc, hc_regs, qtd);
+	} else {
+#ifdef DEBUG
+		if (!halt_status_ok(hcd, hc, hc_regs, qtd)) {
+			return 1;
+		}
+#endif
+		release_channel(hcd, hc, qtd, hc->halt_status);
+	}
+
+	return 1;
+}
+
+/** Handles interrupt for a specific Host Channel */
+int32_t dwc_otg_hcd_handle_hc_n_intr(dwc_otg_hcd_t * dwc_otg_hcd, uint32_t num)
+{
+	int retval = 0;
+	hcint_data_t hcint;
+	hcintmsk_data_t hcintmsk;
+	dwc_hc_t *hc;
+	dwc_otg_hc_regs_t *hc_regs;
+	dwc_otg_qtd_t *qtd;
+
+	DWC_DEBUGPL(DBG_HCDV, "--Host Channel Interrupt--, Channel %d\n", num);
+
+	hc = dwc_otg_hcd->hc_ptr_array[num];
+	hc_regs = dwc_otg_hcd->core_if->host_if->hc_regs[num];
+	qtd = DWC_CIRCLEQ_FIRST(&hc->qh->qtd_list);
+
+	hcint.d32 = DWC_READ_REG32(&hc_regs->hcint);
+	hcintmsk.d32 = DWC_READ_REG32(&hc_regs->hcintmsk);
+	DWC_DEBUGPL(DBG_HCDV,
+		    "  hcint 0x%08x, hcintmsk 0x%08x, hcint&hcintmsk 0x%08x\n",
+		    hcint.d32, hcintmsk.d32, (hcint.d32 & hcintmsk.d32));
+	hcint.d32 = hcint.d32 & hcintmsk.d32;
+
+	if (!dwc_otg_hcd->core_if->dma_enable) {
+		if (hcint.b.chhltd && hcint.d32 != 0x2) {
+			hcint.b.chhltd = 0;
+		}
+	}
+
+	if (hcint.b.xfercomp) {
+		retval |=
+		    handle_hc_xfercomp_intr(dwc_otg_hcd, hc, hc_regs, qtd);
+		/*
+		 * If NYET occurred at same time as Xfer Complete, the NYET is
+		 * handled by the Xfer Complete interrupt handler. Don't want
+		 * to call the NYET interrupt handler in this case.
+		 */
+		hcint.b.nyet = 0;
+	}
+	if (hcint.b.chhltd) {
+		retval |= handle_hc_chhltd_intr(dwc_otg_hcd, hc, hc_regs, qtd);
+	}
+	if (hcint.b.ahberr) {
+		retval |= handle_hc_ahberr_intr(dwc_otg_hcd, hc, hc_regs, qtd);
+	}
+	if (hcint.b.stall) {
+		retval |= handle_hc_stall_intr(dwc_otg_hcd, hc, hc_regs, qtd);
+	}
+	if (hcint.b.nak) {
+		retval |= handle_hc_nak_intr(dwc_otg_hcd, hc, hc_regs, qtd);
+	}
+	if (hcint.b.ack) {
+		retval |= handle_hc_ack_intr(dwc_otg_hcd, hc, hc_regs, qtd);
+	}
+	if (hcint.b.nyet) {
+		retval |= handle_hc_nyet_intr(dwc_otg_hcd, hc, hc_regs, qtd);
+	}
+	if (hcint.b.xacterr) {
+		retval |= handle_hc_xacterr_intr(dwc_otg_hcd, hc, hc_regs, qtd);
+	}
+	if (hcint.b.bblerr) {
+		retval |= handle_hc_babble_intr(dwc_otg_hcd, hc, hc_regs, qtd);
+	}
+	if (hcint.b.frmovrun) {
+		retval |=
+		    handle_hc_frmovrun_intr(dwc_otg_hcd, hc, hc_regs, qtd);
+	}
+	if (hcint.b.datatglerr) {
+		retval |=
+		    handle_hc_datatglerr_intr(dwc_otg_hcd, hc, hc_regs, qtd);
+	}
+
+	return retval;
+}
+
+#endif /* DWC_DEVICE_ONLY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_linux.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_linux.c
new file mode 100644
index 0000000..2e94f6e
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_linux.c
@@ -0,0 +1,840 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_hcd_linux.c $
+ * $Revision: #23 $
+ * $Date: 2013/04/22 $
+ * $Change: 2211149 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef DWC_DEVICE_ONLY
+
+/**
+ * @file
+ *
+ * This file contains the implementation of the HCD. In Linux, the HCD
+ * implements the hc_driver API.
+ */
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/list.h>
+#include <linux/interrupt.h>
+#include <linux/string.h>
+#include <linux/dma-mapping.h>
+#include <linux/version.h>
+#include <asm/io.h>
+#include <linux/usb.h>
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,35)
+#include <../drivers/usb/core/hcd.h>
+#else
+#include <linux/usb/hcd.h>
+#endif
+
+#include "dwc_otg_hcd_if.h"
+#include "dwc_otg_dbg.h"
+#include "dwc_otg_driver.h"
+#include "dwc_otg_hcd.h"
+/**
+ * Gets the endpoint number from a _bEndpointAddress argument. The endpoint is
+ * qualified with its direction (possible 32 endpoints per device).
+ */
+#define dwc_ep_addr_to_endpoint(_bEndpointAddress_) ((_bEndpointAddress_ & USB_ENDPOINT_NUMBER_MASK) | \
+						     ((_bEndpointAddress_ & USB_DIR_IN) != 0) << 4)
+
+static const char dwc_otg_hcd_name[] = "dwc_otg_hcd";
+
+/** @name Linux HC Driver API Functions */
+/** @{ */
+static int urb_enqueue(struct usb_hcd *hcd,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,28)
+		       struct usb_host_endpoint *ep,
+#endif
+		       struct urb *urb, gfp_t mem_flags);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,28)
+static int urb_dequeue(struct usb_hcd *hcd, struct urb *urb);
+#else
+static int urb_dequeue(struct usb_hcd *hcd, struct urb *urb, int status);
+#endif
+
+static void endpoint_disable(struct usb_hcd *hcd, struct usb_host_endpoint *ep);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,30)
+static void endpoint_reset(struct usb_hcd *hcd, struct usb_host_endpoint *ep);
+#endif
+static irqreturn_t dwc_otg_hcd_irq(struct usb_hcd *hcd);
+extern int hcd_start(struct usb_hcd *hcd);
+extern void hcd_stop(struct usb_hcd *hcd);
+static int get_frame_number(struct usb_hcd *hcd);
+extern int hub_status_data(struct usb_hcd *hcd, char *buf);
+extern int hub_control(struct usb_hcd *hcd,
+		       u16 typeReq,
+		       u16 wValue, u16 wIndex, char *buf, u16 wLength);
+
+struct wrapper_priv_data {
+	dwc_otg_hcd_t *dwc_otg_hcd;
+};
+
+/** @} */
+
+static struct hc_driver dwc_otg_hc_driver = {
+
+	.description = dwc_otg_hcd_name,
+	.product_desc = "DWC OTG Controller",
+	.hcd_priv_size = sizeof(struct wrapper_priv_data),
+
+	.irq = dwc_otg_hcd_irq,
+
+	.flags = HCD_MEMORY | HCD_USB2,
+
+	//.reset =
+	.start = hcd_start,
+	//.suspend =
+	//.resume =
+	.stop = hcd_stop,
+
+	.urb_enqueue = urb_enqueue,
+	.urb_dequeue = urb_dequeue,
+	.endpoint_disable = endpoint_disable,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,30)
+	.endpoint_reset = endpoint_reset,
+#endif
+	.get_frame_number = get_frame_number,
+
+	.hub_status_data = hub_status_data,
+	.hub_control = hub_control,
+	//.bus_suspend =
+	//.bus_resume =
+};
+
+/** Gets the dwc_otg_hcd from a struct usb_hcd */
+static inline dwc_otg_hcd_t *hcd_to_dwc_otg_hcd(struct usb_hcd *hcd)
+{
+	struct wrapper_priv_data *p;
+	p = (struct wrapper_priv_data *)(hcd->hcd_priv);
+	return p->dwc_otg_hcd;
+}
+
+/** Gets the struct usb_hcd that contains a dwc_otg_hcd_t. */
+static inline struct usb_hcd *dwc_otg_hcd_to_hcd(dwc_otg_hcd_t * dwc_otg_hcd)
+{
+	return dwc_otg_hcd_get_priv_data(dwc_otg_hcd);
+}
+
+/** Gets the usb_host_endpoint associated with an URB. */
+inline struct usb_host_endpoint *dwc_urb_to_endpoint(struct urb *urb)
+{
+	struct usb_device *dev = urb->dev;
+	int ep_num = usb_pipeendpoint(urb->pipe);
+
+	if (usb_pipein(urb->pipe))
+		return dev->ep_in[ep_num];
+	else
+		return dev->ep_out[ep_num];
+}
+
+static int _disconnect(dwc_otg_hcd_t * hcd)
+{
+	struct usb_hcd *usb_hcd = dwc_otg_hcd_to_hcd(hcd);
+
+	usb_hcd->self.is_b_host = 0;
+	return 0;
+}
+
+static int _start(dwc_otg_hcd_t * hcd)
+{
+	struct usb_hcd *usb_hcd = dwc_otg_hcd_to_hcd(hcd);
+
+	usb_hcd->self.is_b_host = dwc_otg_hcd_is_b_host(hcd);
+	hcd_start(usb_hcd);
+
+	return 0;
+}
+
+static int _hub_info(dwc_otg_hcd_t * hcd, void *urb_handle, uint32_t * hub_addr,
+		     uint32_t * port_addr)
+{
+	struct urb *urb = (struct urb *)urb_handle;
+	if (urb->dev->tt) {
+		*hub_addr = urb->dev->tt->hub->devnum;
+	} else {
+		*hub_addr = 0;
+	}
+	*port_addr = urb->dev->ttport;
+	return 0;
+}
+
+static int _speed(dwc_otg_hcd_t * hcd, void *urb_handle)
+{
+	struct urb *urb = (struct urb *)urb_handle;
+	return urb->dev->speed;
+}
+
+static int _get_b_hnp_enable(dwc_otg_hcd_t * hcd)
+{
+	struct usb_hcd *usb_hcd = dwc_otg_hcd_to_hcd(hcd);
+	return usb_hcd->self.b_hnp_enable;
+}
+
+static void allocate_bus_bandwidth(struct usb_hcd *hcd, uint32_t bw,
+				   struct urb *urb)
+{
+	hcd_to_bus(hcd)->bandwidth_allocated += bw / urb->interval;
+	if (usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS) {
+		hcd_to_bus(hcd)->bandwidth_isoc_reqs++;
+	} else {
+		hcd_to_bus(hcd)->bandwidth_int_reqs++;
+	}
+}
+
+static void free_bus_bandwidth(struct usb_hcd *hcd, uint32_t bw,
+			       struct urb *urb)
+{
+	hcd_to_bus(hcd)->bandwidth_allocated -= bw / urb->interval;
+	if (usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS) {
+		hcd_to_bus(hcd)->bandwidth_isoc_reqs--;
+	} else {
+		hcd_to_bus(hcd)->bandwidth_int_reqs--;
+	}
+}
+
+/**
+ * Sets the final status of an URB and returns it to the device driver. Any
+ * required cleanup of the URB is performed.
+ */
+static int _complete(dwc_otg_hcd_t * hcd, void *urb_handle,
+		     dwc_otg_hcd_urb_t * dwc_otg_urb, int32_t status)
+{
+	struct urb *urb = (struct urb *)urb_handle;
+#ifdef DEBUG
+	if (CHK_DEBUG_LEVEL(DBG_HCDV | DBG_HCD_URB)) {
+		DWC_PRINTF("%s: urb %p, device %d, ep %d %s, status=%d\n",
+			   __func__, urb, usb_pipedevice(urb->pipe),
+			   usb_pipeendpoint(urb->pipe),
+			   usb_pipein(urb->pipe) ? "IN" : "OUT", status);
+		if (usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS) {
+			int i;
+			for (i = 0; i < urb->number_of_packets; i++) {
+				DWC_PRINTF("  ISO Desc %d status: %d\n",
+					   i, urb->iso_frame_desc[i].status);
+			}
+		}
+	}
+#endif
+
+	urb->actual_length = dwc_otg_hcd_urb_get_actual_length(dwc_otg_urb);
+	/* Convert status value. */
+	switch (status) {
+	case -DWC_E_PROTOCOL:
+		status = -EPROTO;
+		break;
+	case -DWC_E_IN_PROGRESS:
+		status = -EINPROGRESS;
+		break;
+	case -DWC_E_PIPE:
+		status = -EPIPE;
+		break;
+	case -DWC_E_IO:
+		status = -EIO;
+		break;
+	case -DWC_E_TIMEOUT:
+		status = -ETIMEDOUT;
+		break;
+	case -DWC_E_OVERFLOW:
+		status = -EOVERFLOW;
+		break;
+	default:
+		if (status) {
+			DWC_PRINTF("Uknown urb status %d\n", status);
+
+		}
+	}
+
+	if (usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS) {
+		int i;
+
+		urb->error_count = dwc_otg_hcd_urb_get_error_count(dwc_otg_urb);
+		for (i = 0; i < urb->number_of_packets; ++i) {
+			urb->iso_frame_desc[i].actual_length =
+			    dwc_otg_hcd_urb_get_iso_desc_actual_length
+			    (dwc_otg_urb, i);
+			urb->iso_frame_desc[i].status =
+			    dwc_otg_hcd_urb_get_iso_desc_status(dwc_otg_urb, i);
+		}
+	}
+
+	urb->status = status;
+	urb->hcpriv = NULL;
+	if (!status) {
+		if ((urb->transfer_flags & URB_SHORT_NOT_OK) &&
+		    (urb->actual_length < urb->transfer_buffer_length)) {
+			urb->status = -EREMOTEIO;
+		}
+	}
+
+	if ((usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS) ||
+	    (usb_pipetype(urb->pipe) == PIPE_INTERRUPT)) {
+		struct usb_host_endpoint *ep = dwc_urb_to_endpoint(urb);
+		if (ep) {
+			free_bus_bandwidth(dwc_otg_hcd_to_hcd(hcd),
+					   dwc_otg_hcd_get_ep_bandwidth(hcd,
+									ep->hcpriv),
+					   urb);
+		}
+	}
+
+	DWC_FREE(dwc_otg_urb);
+
+	DWC_SPINUNLOCK(hcd->lock);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,28)
+	usb_hcd_giveback_urb(dwc_otg_hcd_to_hcd(hcd), urb);
+#else
+	usb_hcd_giveback_urb(dwc_otg_hcd_to_hcd(hcd), urb, status);
+#endif
+	DWC_SPINLOCK(hcd->lock);
+
+	return 0;
+}
+
+static struct dwc_otg_hcd_function_ops hcd_fops = {
+	.start = _start,
+	.disconnect = _disconnect,
+	.hub_info = _hub_info,
+	.speed = _speed,
+	.complete = _complete,
+	.get_b_hnp_enable = _get_b_hnp_enable,
+};
+
+/**
+ * Initializes the HCD. This function allocates memory for and initializes the
+ * static parts of the usb_hcd and dwc_otg_hcd structures. It also registers the
+ * USB bus with the core and calls the hc_driver->start() function. It returns
+ * a negative error on failure.
+ */
+int hcd_init(
+#ifdef LM_INTERFACE
+		    struct lm_device *_dev
+#elif  defined(PCI_INTERFACE)
+		    struct pci_dev *_dev
+#endif
+    )
+{
+	struct usb_hcd *hcd = NULL;
+	dwc_otg_hcd_t *dwc_otg_hcd = NULL;
+#ifdef LM_INTERFACE
+	dwc_otg_device_t *otg_dev = lm_get_drvdata(_dev);
+#elif  defined(PCI_INTERFACE)
+	dwc_otg_device_t *otg_dev = pci_get_drvdata(_dev);
+#endif
+
+	int retval = 0;
+
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD INIT\n");
+
+	/* Set device flags indicating whether the HCD supports DMA. */
+	if (dwc_otg_is_dma_enable(otg_dev->core_if)) {
+#ifdef LM_INTERFACE
+		_dev->dev.dma_mask = (void *)~0;
+		_dev->dev.coherent_dma_mask = ~0;
+#elif  defined(PCI_INTERFACE)
+		pci_set_dma_mask(_dev, DMA_BIT_MASK(32));
+		pci_set_consistent_dma_mask(_dev, DMA_BIT_MASK(32));
+#endif
+
+	} else {
+#ifdef LM_INTERFACE
+		_dev->dev.dma_mask = (void *)0;
+		_dev->dev.coherent_dma_mask = 0;
+#elif  defined(PCI_INTERFACE)
+		pci_set_dma_mask(_dev, 0);
+		pci_set_consistent_dma_mask(_dev, 0);
+#endif
+	}
+
+	/*
+	 * Allocate memory for the base HCD plus the DWC OTG HCD.
+	 * Initialize the base HCD.
+	 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,30)
+	hcd = usb_create_hcd(&dwc_otg_hc_driver, &_dev->dev, _dev->dev.bus_id);
+#else
+	hcd = usb_create_hcd(&dwc_otg_hc_driver, &_dev->dev, dev_name(&_dev->dev));
+	hcd->has_tt = 1;
+//      hcd->uses_new_polling = 1;
+//      hcd->poll_rh = 0;
+#endif
+	if (!hcd) {
+		retval = -ENOMEM;
+		goto error1;
+	}
+
+	hcd->regs = otg_dev->os_dep.base;
+
+	/* Initialize the DWC OTG HCD. */
+	dwc_otg_hcd = dwc_otg_hcd_alloc_hcd();
+	if (!dwc_otg_hcd) {
+		goto error2;
+	}
+	((struct wrapper_priv_data *)(hcd->hcd_priv))->dwc_otg_hcd =
+	    dwc_otg_hcd;
+	otg_dev->hcd = dwc_otg_hcd;
+
+	if (dwc_otg_hcd_init(dwc_otg_hcd, otg_dev->core_if)) {
+		goto error2;
+	}
+
+	otg_dev->hcd->otg_dev = otg_dev;
+	hcd->self.otg_port = dwc_otg_hcd_otg_port(dwc_otg_hcd);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,33) //don't support for LM(with 2.6.20.1 kernel)
+	hcd->self.otg_version = dwc_otg_get_otg_version(otg_dev->core_if);
+	/* Don't support SG list at this point */
+	hcd->self.sg_tablesize = 0;
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
+	/* Do not to do HNP polling if not capable */
+	if (otg_dev->core_if->otg_ver)
+		hcd->self.is_hnp_cap = dwc_otg_get_hnpcapable(otg_dev->core_if);
+#endif
+	/*
+	 * Finish generic HCD initialization and start the HCD. This function
+	 * allocates the DMA buffer pool, registers the USB bus, requests the
+	 * IRQ line, and calls hcd_start method.
+	 */
+	retval = usb_add_hcd(hcd, _dev->irq, IRQF_SHARED);
+	if (retval < 0) {
+		goto error2;
+	}
+
+	dwc_otg_hcd_set_priv_data(dwc_otg_hcd, hcd);
+	return 0;
+
+error2:
+	usb_put_hcd(hcd);
+error1:
+	return retval;
+}
+
+/**
+ * Removes the HCD.
+ * Frees memory and resources associated with the HCD and deregisters the bus.
+ */
+void hcd_remove(
+#ifdef LM_INTERFACE
+		       struct lm_device *_dev
+#elif  defined(PCI_INTERFACE)
+		       struct pci_dev *_dev
+#endif
+    )
+{
+#ifdef LM_INTERFACE
+	dwc_otg_device_t *otg_dev = lm_get_drvdata(_dev);
+#elif  defined(PCI_INTERFACE)
+	dwc_otg_device_t *otg_dev = pci_get_drvdata(_dev);
+#endif
+
+	dwc_otg_hcd_t *dwc_otg_hcd;
+	struct usb_hcd *hcd;
+
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD REMOVE\n");
+
+	if (!otg_dev) {
+		DWC_DEBUGPL(DBG_ANY, "%s: otg_dev NULL!\n", __func__);
+		return;
+	}
+
+	dwc_otg_hcd = otg_dev->hcd;
+
+	if (!dwc_otg_hcd) {
+		DWC_DEBUGPL(DBG_ANY, "%s: otg_dev->hcd NULL!\n", __func__);
+		return;
+	}
+
+	hcd = dwc_otg_hcd_to_hcd(dwc_otg_hcd);
+
+	if (!hcd) {
+		DWC_DEBUGPL(DBG_ANY,
+			    "%s: dwc_otg_hcd_to_hcd(dwc_otg_hcd) NULL!\n",
+			    __func__);
+		return;
+	}
+	usb_remove_hcd(hcd);
+	dwc_otg_hcd_set_priv_data(dwc_otg_hcd, NULL);
+	dwc_otg_hcd_remove(dwc_otg_hcd);
+	usb_put_hcd(hcd);
+}
+
+/* =========================================================================
+ *  Linux HC Driver Functions
+ * ========================================================================= */
+
+/** Initializes the DWC_otg controller and its root hub and prepares it for host
+ * mode operation. Activates the root port. Returns 0 on success and a negative
+ * error code on failure. */
+int hcd_start(struct usb_hcd *hcd)
+{
+	dwc_otg_hcd_t *dwc_otg_hcd = hcd_to_dwc_otg_hcd(hcd);
+	struct usb_bus *bus;
+
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD START\n");
+	bus = hcd_to_bus(hcd);
+
+	hcd->state = HC_STATE_RUNNING;
+	if (dwc_otg_hcd_start(dwc_otg_hcd, &hcd_fops)) {
+		if (dwc_otg_hcd->core_if->otg_ver && dwc_otg_is_device_mode(dwc_otg_hcd->core_if))
+			dwc_otg_hcd->core_if->op_state = B_PERIPHERAL;
+		return 0;
+	}
+
+	/* Initialize and connect root hub if one is not already attached */
+	if (bus->root_hub) {
+		DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD Has Root Hub\n");
+		/* Inform the HUB driver to resume. */
+		usb_hcd_resume_root_hub(hcd);
+	}
+
+	return 0;
+}
+
+/**
+ * Halts the DWC_otg host mode operations in a clean manner. USB transfers are
+ * stopped.
+ */
+void hcd_stop(struct usb_hcd *hcd)
+{
+	dwc_otg_hcd_t *dwc_otg_hcd = hcd_to_dwc_otg_hcd(hcd);
+
+	dwc_otg_hcd_stop(dwc_otg_hcd);
+}
+
+/** Returns the current frame number. */
+static int get_frame_number(struct usb_hcd *hcd)
+{
+	dwc_otg_hcd_t *dwc_otg_hcd = hcd_to_dwc_otg_hcd(hcd);
+
+	return dwc_otg_hcd_get_frame_number(dwc_otg_hcd);
+}
+
+#ifdef DEBUG
+static void dump_urb_info(struct urb *urb, char *fn_name)
+{
+	DWC_PRINTF("%s, urb %p\n", fn_name, urb);
+	DWC_PRINTF("  Device address: %d\n", usb_pipedevice(urb->pipe));
+	DWC_PRINTF("  Endpoint: %d, %s\n", usb_pipeendpoint(urb->pipe),
+		   (usb_pipein(urb->pipe) ? "IN" : "OUT"));
+	DWC_PRINTF("  Endpoint type: %s\n", ( {
+					     char *pipetype;
+					     switch (usb_pipetype(urb->pipe)) {
+case PIPE_CONTROL:
+pipetype = "CONTROL"; break; case PIPE_BULK:
+pipetype = "BULK"; break; case PIPE_INTERRUPT:
+pipetype = "INTERRUPT"; break; case PIPE_ISOCHRONOUS:
+pipetype = "ISOCHRONOUS"; break; default:
+					     pipetype = "UNKNOWN"; break;};
+					     pipetype;}
+		   )) ;
+	DWC_PRINTF("  Speed: %s\n", ( {
+				     char *speed; switch (urb->dev->speed) {
+case USB_SPEED_HIGH:
+speed = "HIGH"; break; case USB_SPEED_FULL:
+speed = "FULL"; break; case USB_SPEED_LOW:
+speed = "LOW"; break; default:
+				     speed = "UNKNOWN"; break;};
+				     speed;}
+		   )) ;
+	DWC_PRINTF("  Max packet size: %d\n",
+		   usb_maxpacket(urb->dev, urb->pipe, usb_pipeout(urb->pipe)));
+	DWC_PRINTF("  Data buffer length: %d\n", urb->transfer_buffer_length);
+	DWC_PRINTF("  Transfer buffer: %p, Transfer DMA: %p\n",
+		   urb->transfer_buffer, (void *)urb->transfer_dma);
+	DWC_PRINTF("  Setup buffer: %p, Setup DMA: %p\n",
+		   urb->setup_packet, (void *)urb->setup_dma);
+	DWC_PRINTF("  Interval: %d\n", urb->interval);
+	if (usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS) {
+		int i;
+		for (i = 0; i < urb->number_of_packets; i++) {
+			DWC_PRINTF("  ISO Desc %d:\n", i);
+			DWC_PRINTF("    offset: %d, length %d\n",
+				   urb->iso_frame_desc[i].offset,
+				   urb->iso_frame_desc[i].length);
+		}
+	}
+}
+
+#endif
+
+/** Starts processing a USB transfer request specified by a USB Request Block
+ * (URB). mem_flags indicates the type of memory allocation to use while
+ * processing this URB. */
+static int urb_enqueue(struct usb_hcd *hcd,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,28)
+		       struct usb_host_endpoint *ep,
+#endif
+		       struct urb *urb, gfp_t mem_flags)
+{
+	int retval = 0;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,28)
+	struct usb_host_endpoint *ep = urb->ep;
+#endif
+	dwc_otg_hcd_t *dwc_otg_hcd = hcd_to_dwc_otg_hcd(hcd);
+	dwc_otg_hcd_urb_t *dwc_otg_urb;
+	int i;
+	int alloc_bandwidth = 0;
+	uint8_t ep_type = 0;
+	uint32_t flags = 0;
+	void *buf;
+
+#ifdef DEBUG
+	if (CHK_DEBUG_LEVEL(DBG_HCDV | DBG_HCD_URB)) {
+		dump_urb_info(urb, "urb_enqueue");
+	}
+#endif
+
+	if ((usb_pipetype(urb->pipe) == PIPE_ISOCHRONOUS)
+	    || (usb_pipetype(urb->pipe) == PIPE_INTERRUPT)) {
+		if (!dwc_otg_hcd_is_bandwidth_allocated
+		    (dwc_otg_hcd, &ep->hcpriv)) {
+			alloc_bandwidth = 1;
+		}
+	}
+
+	switch (usb_pipetype(urb->pipe)) {
+	case PIPE_CONTROL:
+		ep_type = USB_ENDPOINT_XFER_CONTROL;
+		break;
+	case PIPE_ISOCHRONOUS:
+		ep_type = USB_ENDPOINT_XFER_ISOC;
+		break;
+	case PIPE_BULK:
+		ep_type = USB_ENDPOINT_XFER_BULK;
+		break;
+	case PIPE_INTERRUPT:
+		ep_type = USB_ENDPOINT_XFER_INT;
+		break;
+	default:
+		DWC_WARN("Wrong ep type\n");
+	}
+
+	dwc_otg_urb = dwc_otg_hcd_urb_alloc(dwc_otg_hcd,
+					    urb->number_of_packets,
+					    mem_flags == GFP_ATOMIC ? 1 : 0);
+
+	dwc_otg_hcd_urb_set_pipeinfo(dwc_otg_urb, usb_pipedevice(urb->pipe),
+				     usb_pipeendpoint(urb->pipe), ep_type,
+				     usb_pipein(urb->pipe),
+				     usb_maxpacket(urb->dev, urb->pipe,
+						   !(usb_pipein(urb->pipe))));
+
+	buf = urb->transfer_buffer;
+	if (hcd->self.uses_dma) {
+		/*
+		 * Calculate virtual address from physical address,
+		 * because some class driver may not fill transfer_buffer.
+		 * In Buffer DMA mode virual address is used,
+		 * when handling non DWORD aligned buffers.
+		 */
+		buf = phys_to_virt(urb->transfer_dma);
+	}
+
+	if (!(urb->transfer_flags & URB_NO_INTERRUPT))
+		flags |= URB_GIVEBACK_ASAP;
+	if (urb->transfer_flags & URB_ZERO_PACKET)
+		flags |= URB_SEND_ZERO_PACKET;
+
+	dwc_otg_hcd_urb_set_params(dwc_otg_urb, urb, buf,
+				   urb->transfer_dma,
+				   urb->transfer_buffer_length,
+				   urb->setup_packet,
+				   urb->setup_dma, flags, urb->interval);
+
+	for (i = 0; i < urb->number_of_packets; ++i) {
+		dwc_otg_hcd_urb_set_iso_desc_params(dwc_otg_urb, i,
+						    urb->
+						    iso_frame_desc[i].offset,
+						    urb->
+						    iso_frame_desc[i].length);
+	}
+
+	urb->hcpriv = dwc_otg_urb;
+	retval = dwc_otg_hcd_urb_enqueue(dwc_otg_hcd, dwc_otg_urb, &ep->hcpriv,
+					 mem_flags == GFP_ATOMIC ? 1 : 0);
+	if (!retval) {
+		if (alloc_bandwidth) {
+			allocate_bus_bandwidth(hcd,
+					       dwc_otg_hcd_get_ep_bandwidth
+					       (dwc_otg_hcd, ep->hcpriv), urb);
+		}
+	} else {
+		if (retval == -DWC_E_NO_DEVICE) {
+			retval = -ENODEV;
+		}
+	}
+
+	return retval;
+}
+
+/** Aborts/cancels a USB transfer request. Always returns 0 to indicate
+ * success.  */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,28)
+static int urb_dequeue(struct usb_hcd *hcd, struct urb *urb)
+#else
+static int urb_dequeue(struct usb_hcd *hcd, struct urb *urb, int status)
+#endif
+{
+	dwc_irqflags_t flags;
+	dwc_otg_hcd_t *dwc_otg_hcd;
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD URB Dequeue\n");
+
+	dwc_otg_hcd = hcd_to_dwc_otg_hcd(hcd);
+
+#ifdef DEBUG
+	if (CHK_DEBUG_LEVEL(DBG_HCDV | DBG_HCD_URB)) {
+		dump_urb_info(urb, "urb_dequeue");
+	}
+#endif
+
+	DWC_SPINLOCK_IRQSAVE(dwc_otg_hcd->lock, &flags);
+
+	dwc_otg_hcd_urb_dequeue(dwc_otg_hcd, urb->hcpriv);
+
+	DWC_FREE(urb->hcpriv);
+	urb->hcpriv = NULL;
+	DWC_SPINUNLOCK_IRQRESTORE(dwc_otg_hcd->lock, flags);
+
+	/* Higher layer software sets URB status. */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,28)
+	usb_hcd_giveback_urb(hcd, urb);
+#else
+	usb_hcd_giveback_urb(hcd, urb, status);
+#endif
+	if (CHK_DEBUG_LEVEL(DBG_HCDV | DBG_HCD_URB)) {
+		DWC_PRINTF("Called usb_hcd_giveback_urb()\n");
+		DWC_PRINTF("  urb->status = %d\n", urb->status);
+	}
+
+	return 0;
+}
+
+/* Frees resources in the DWC_otg controller related to a given endpoint. Also
+ * clears state in the HCD related to the endpoint. Any URBs for the endpoint
+ * must already be dequeued. */
+static void endpoint_disable(struct usb_hcd *hcd, struct usb_host_endpoint *ep)
+{
+	dwc_otg_hcd_t *dwc_otg_hcd = hcd_to_dwc_otg_hcd(hcd);
+
+	DWC_DEBUGPL(DBG_HCD,
+		    "DWC OTG HCD EP DISABLE: _bEndpointAddress=0x%02x, "
+		    "endpoint=%d\n", ep->desc.bEndpointAddress,
+		    dwc_ep_addr_to_endpoint(ep->desc.bEndpointAddress));
+	dwc_otg_hcd_endpoint_disable(dwc_otg_hcd, ep->hcpriv, 250);
+	ep->hcpriv = NULL;
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,30)
+/* Resets endpoint specific parameter values, in current version used to reset
+ * the data toggle(as a WA). This function can be called from usb_clear_halt routine */
+static void endpoint_reset(struct usb_hcd *hcd, struct usb_host_endpoint *ep)
+{
+	dwc_irqflags_t flags;
+	struct usb_device *udev = NULL;
+	int epnum = usb_endpoint_num(&ep->desc);
+	int is_out = usb_endpoint_dir_out(&ep->desc);
+	int is_control = usb_endpoint_xfer_control(&ep->desc);
+	dwc_otg_hcd_t *dwc_otg_hcd = hcd_to_dwc_otg_hcd(hcd);
+#ifdef LM_INTERFACE
+	struct lm_device *_dev = dwc_otg_hcd->otg_dev->os_dep.lmdev;
+#elif defined(PCI_INTERFACE)
+	struct pci_dev *_dev = dwc_otg_hcd->otg_dev->os_dep.pcidev;
+#endif
+
+	if (_dev)
+		udev = to_usb_device(&_dev->dev);
+	else
+		return;
+
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD EP RESET: Endpoint Num=0x%02d\n", epnum);
+
+	DWC_SPINLOCK_IRQSAVE(dwc_otg_hcd->lock, &flags);
+	usb_settoggle(udev, epnum, is_out, 0);
+	if (is_control)
+		usb_settoggle(udev, epnum, !is_out, 0);
+
+	if (ep->hcpriv) {
+		dwc_otg_hcd_endpoint_reset(dwc_otg_hcd, ep->hcpriv);
+	}
+	DWC_SPINUNLOCK_IRQRESTORE(dwc_otg_hcd->lock, flags);
+}
+#endif
+
+/** Handles host mode interrupts for the DWC_otg controller. Returns IRQ_NONE if
+ * there was no interrupt to handle. Returns IRQ_HANDLED if there was a valid
+ * interrupt.
+ *
+ * This function is called by the USB core when an interrupt occurs */
+static irqreturn_t dwc_otg_hcd_irq(struct usb_hcd *hcd)
+{
+	dwc_otg_hcd_t *dwc_otg_hcd = hcd_to_dwc_otg_hcd(hcd);
+	int32_t retval = dwc_otg_hcd_handle_intr(dwc_otg_hcd);
+	if (retval != 0) {
+		S3C2410X_CLEAR_EINTPEND();
+	}
+	return IRQ_RETVAL(retval);
+}
+
+/** Creates Status Change bitmap for the root hub and root port. The bitmap is
+ * returned in buf. Bit 0 is the status change indicator for the root hub. Bit 1
+ * is the status change indicator for the single root port. Returns 1 if either
+ * change indicator is 1, otherwise returns 0. */
+int hub_status_data(struct usb_hcd *hcd, char *buf)
+{
+	dwc_otg_hcd_t *dwc_otg_hcd = hcd_to_dwc_otg_hcd(hcd);
+
+	buf[0] = 0;
+	buf[0] |= (dwc_otg_hcd_is_status_changed(dwc_otg_hcd, 1)) << 1;
+
+	return (buf[0] != 0);
+}
+
+/** Handles hub class-specific requests. */
+int hub_control(struct usb_hcd *hcd,
+		u16 typeReq, u16 wValue, u16 wIndex, char *buf, u16 wLength)
+{
+	int retval;
+
+	retval = dwc_otg_hcd_hub_control(hcd_to_dwc_otg_hcd(hcd),
+					 typeReq, wValue, wIndex, buf, wLength);
+
+	switch (retval) {
+	case -DWC_E_INVALID:
+		retval = -EINVAL;
+		break;
+	}
+
+	return retval;
+}
+
+#endif /* DWC_DEVICE_ONLY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_queue.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_queue.c
new file mode 100644
index 0000000..be55ebb
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_hcd_queue.c
@@ -0,0 +1,721 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_hcd_queue.c $
+ * $Revision: #45 $
+ * $Date: 2013/01/24 $
+ * $Change: 2150293 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef DWC_DEVICE_ONLY
+
+/**
+ * @file
+ *
+ * This file contains the functions to manage Queue Heads and Queue
+ * Transfer Descriptors.
+ */
+
+#include "dwc_otg_hcd.h"
+#include "dwc_otg_regs.h"
+
+/**
+ * Free each QTD in the QH's QTD-list then free the QH.  QH should already be
+ * removed from a list.  QTD list should already be empty if called from URB
+ * Dequeue.
+ *
+ * @param hcd HCD instance.
+ * @param qh The QH to free.
+ */
+void dwc_otg_hcd_qh_free(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	dwc_otg_qtd_t *qtd, *qtd_tmp;
+	dwc_irqflags_t flags;
+
+	/* Free each QTD in the QTD list */
+	DWC_SPINLOCK_IRQSAVE(hcd->lock, &flags);
+	DWC_CIRCLEQ_FOREACH_SAFE(qtd, qtd_tmp, &qh->qtd_list, qtd_list_entry) {
+		DWC_CIRCLEQ_REMOVE(&qh->qtd_list, qtd, qtd_list_entry);
+		dwc_otg_hcd_qtd_free(qtd);
+	}
+
+	if (hcd->core_if->dma_desc_enable) {
+		dwc_otg_hcd_qh_free_ddma(hcd, qh);
+	} else if (qh->dw_align_buf) {
+		uint32_t buf_size;
+		if (qh->ep_type == UE_ISOCHRONOUS) {
+			buf_size = 4096;
+		} else {
+			buf_size = hcd->core_if->core_params->max_transfer_size;
+		}
+		DWC_DMA_FREE(buf_size, qh->dw_align_buf, qh->dw_align_buf_dma);
+	}
+
+	DWC_FREE(qh);
+	DWC_SPINUNLOCK_IRQRESTORE(hcd->lock, flags);
+	return;
+}
+
+#define BitStuffTime(bytecount)  ((8 * 7* bytecount) / 6)
+#define HS_HOST_DELAY		5	/* nanoseconds */
+#define FS_LS_HOST_DELAY	1000	/* nanoseconds */
+#define HUB_LS_SETUP		333	/* nanoseconds */
+#define NS_TO_US(ns)		((ns + 500) / 1000)
+				/* convert & round nanoseconds to microseconds */
+
+static uint32_t calc_bus_time(int speed, int is_in, int is_isoc, int bytecount)
+{
+	unsigned long retval;
+
+	switch (speed) {
+	case USB_SPEED_HIGH:
+		if (is_isoc) {
+			retval =
+			    ((38 * 8 * 2083) +
+			     (2083 * (3 + BitStuffTime(bytecount)))) / 1000 +
+			    HS_HOST_DELAY;
+		} else {
+			retval =
+			    ((55 * 8 * 2083) +
+			     (2083 * (3 + BitStuffTime(bytecount)))) / 1000 +
+			    HS_HOST_DELAY;
+		}
+		break;
+	case USB_SPEED_FULL:
+		if (is_isoc) {
+			retval =
+			    (8354 * (31 + 10 * BitStuffTime(bytecount))) / 1000;
+			if (is_in) {
+				retval = 7268 + FS_LS_HOST_DELAY + retval;
+			} else {
+				retval = 6265 + FS_LS_HOST_DELAY + retval;
+			}
+		} else {
+			retval =
+			    (8354 * (31 + 10 * BitStuffTime(bytecount))) / 1000;
+			retval = 9107 + FS_LS_HOST_DELAY + retval;
+		}
+		break;
+	case USB_SPEED_LOW:
+		if (is_in) {
+			retval =
+			    (67667 * (31 + 10 * BitStuffTime(bytecount))) /
+			    1000;
+			retval =
+			    64060 + (2 * HUB_LS_SETUP) + FS_LS_HOST_DELAY +
+			    retval;
+		} else {
+			retval =
+			    (66700 * (31 + 10 * BitStuffTime(bytecount))) /
+			    1000;
+			retval =
+			    64107 + (2 * HUB_LS_SETUP) + FS_LS_HOST_DELAY +
+			    retval;
+		}
+		break;
+	default:
+		DWC_WARN("Unknown device speed\n");
+		retval = -1;
+	}
+
+	return NS_TO_US(retval);
+}
+
+/**
+ * Initializes a QH structure.
+ *
+ * @param hcd The HCD state structure for the DWC OTG controller.
+ * @param qh  The QH to init.
+ * @param urb Holds the information about the device/endpoint that we need
+ *	      to initialize the QH.
+ */
+#define SCHEDULE_SLOP 10
+void qh_init(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh, dwc_otg_hcd_urb_t * urb)
+{
+	char *speed, *type;
+	int dev_speed;
+	uint32_t hub_addr, hub_port;
+
+	dwc_memset(qh, 0, sizeof(dwc_otg_qh_t));
+
+	/* Initialize QH */
+	qh->ep_type = dwc_otg_hcd_get_pipe_type(&urb->pipe_info);
+	qh->ep_is_in = dwc_otg_hcd_is_pipe_in(&urb->pipe_info) ? 1 : 0;
+
+	qh->data_toggle = DWC_OTG_HC_PID_DATA0;
+	qh->maxp = dwc_otg_hcd_get_mps(&urb->pipe_info);
+	DWC_CIRCLEQ_INIT(&qh->qtd_list);
+	DWC_LIST_INIT(&qh->qh_list_entry);
+	qh->channel = NULL;
+
+	/* FS/LS Enpoint on HS Hub
+	 * NOT virtual root hub */
+	dev_speed = hcd->fops->speed(hcd, urb->priv);
+
+	hcd->fops->hub_info(hcd, urb->priv, &hub_addr, &hub_port);
+	qh->do_split = 0;
+
+	if (((dev_speed == USB_SPEED_LOW) ||
+	     (dev_speed == USB_SPEED_FULL)) &&
+	    (hub_addr != 0 && hub_addr != 1)) {
+		DWC_DEBUGPL(DBG_HCD,
+			    "QH init: EP %d: TT found at hub addr %d, for port %d\n",
+			    dwc_otg_hcd_get_ep_num(&urb->pipe_info), hub_addr,
+			    hub_port);
+		qh->do_split = 1;
+	}
+
+	if (qh->ep_type == UE_INTERRUPT || qh->ep_type == UE_ISOCHRONOUS) {
+		/* Compute scheduling parameters once and save them. */
+		hprt0_data_t hprt;
+
+		/** @todo Account for split transfers in the bus time. */
+		int bytecount =
+		    dwc_hb_mult(qh->maxp) * dwc_max_packet(qh->maxp);
+
+		qh->usecs =
+		    calc_bus_time((qh->do_split ? USB_SPEED_HIGH : dev_speed),
+				  qh->ep_is_in, (qh->ep_type == UE_ISOCHRONOUS),
+				  bytecount);
+		/* Start in a slightly future (micro)frame. */
+		qh->sched_frame = dwc_frame_num_inc(hcd->frame_number,
+						    SCHEDULE_SLOP);
+		qh->interval = urb->interval;
+
+		hprt.d32 = DWC_READ_REG32(hcd->core_if->host_if->hprt0);
+		if ((hprt.b.prtspd == DWC_HPRT0_PRTSPD_HIGH_SPEED) &&
+		    ((dev_speed == USB_SPEED_LOW) ||
+		     (dev_speed == USB_SPEED_FULL))) {
+			qh->interval *= 8;
+			qh->sched_frame |= 0x7;
+			qh->start_split_frame = qh->sched_frame;
+		}
+
+	}
+
+	DWC_DEBUGPL(DBG_HCD, "DWC OTG HCD QH Initialized\n");
+	DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH  - qh = %p\n", qh);
+	DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH  - Device Address = %d\n",
+		    dwc_otg_hcd_get_dev_addr(&urb->pipe_info));
+	DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH  - Endpoint %d, %s\n",
+		    dwc_otg_hcd_get_ep_num(&urb->pipe_info),
+		    dwc_otg_hcd_is_pipe_in(&urb->pipe_info) ? "IN" : "OUT");
+	switch (dev_speed) {
+	case USB_SPEED_LOW:
+		qh->dev_speed = DWC_OTG_EP_SPEED_LOW;
+		speed = "low";
+		break;
+	case USB_SPEED_FULL:
+		qh->dev_speed = DWC_OTG_EP_SPEED_FULL;
+		speed = "full";
+		break;
+	case USB_SPEED_HIGH:
+		qh->dev_speed = DWC_OTG_EP_SPEED_HIGH;
+		speed = "high";
+		break;
+	default:
+		speed = "?";
+		break;
+	}
+	DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH  - Speed = %s\n", speed);
+
+	switch (qh->ep_type) {
+	case UE_ISOCHRONOUS:
+		type = "isochronous";
+		break;
+	case UE_INTERRUPT:
+		type = "interrupt";
+		break;
+	case UE_CONTROL:
+		type = "control";
+		break;
+	case UE_BULK:
+		type = "bulk";
+		break;
+	default:
+		type = "?";
+		break;
+	}
+
+	DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH  - Type = %s\n", type);
+
+#ifdef DEBUG
+	if (qh->ep_type == UE_INTERRUPT) {
+		DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH - usecs = %d\n",
+			    qh->usecs);
+		DWC_DEBUGPL(DBG_HCDV, "DWC OTG HCD QH - interval = %d\n",
+			    qh->interval);
+	}
+#endif
+
+}
+
+/**
+ * This function allocates and initializes a QH.
+ *
+ * @param hcd The HCD state structure for the DWC OTG controller.
+ * @param urb Holds the information about the device/endpoint that we need
+ *	      to initialize the QH.
+ * @param atomic_alloc Flag to do atomic allocation if needed
+ *
+ * @return Returns pointer to the newly allocated QH, or NULL on error. */
+dwc_otg_qh_t *dwc_otg_hcd_qh_create(dwc_otg_hcd_t * hcd,
+				    dwc_otg_hcd_urb_t * urb, int atomic_alloc)
+{
+	dwc_otg_qh_t *qh;
+
+	/* Allocate memory */
+	/** @todo add memflags argument */
+	qh = dwc_otg_hcd_qh_alloc(atomic_alloc);
+	if (qh == NULL) {
+		DWC_ERROR("qh allocation failed");
+		return NULL;
+	}
+
+	qh_init(hcd, qh, urb);
+
+	if (hcd->core_if->dma_desc_enable
+	    && (dwc_otg_hcd_qh_init_ddma(hcd, qh) < 0)) {
+		dwc_otg_hcd_qh_free(hcd, qh);
+		return NULL;
+	}
+
+	return qh;
+}
+
+/**
+ * Checks that a channel is available for a periodic transfer.
+ *
+ * @return 0 if successful, negative error code otherise.
+ */
+static int periodic_channel_available(dwc_otg_hcd_t * hcd)
+{
+	/*
+	 * Currently assuming that there is a dedicated host channnel for each
+	 * periodic transaction plus at least one host channel for
+	 * non-periodic transactions.
+	 */
+	int status;
+	int num_channels;
+
+	num_channels = hcd->core_if->core_params->host_channels;
+	if ((hcd->periodic_channels + hcd->non_periodic_channels < num_channels)
+	    && (hcd->periodic_channels < num_channels - 1)) {
+		status = 0;
+	} else {
+		DWC_INFO("%s: Total channels: %d, Periodic: %d, Non-periodic: %d\n",
+			__func__, num_channels, hcd->periodic_channels, hcd->non_periodic_channels);	//NOTICE
+		status = -DWC_E_NO_SPACE;
+	}
+
+	return status;
+}
+
+/**
+ * Checks that there is sufficient bandwidth for the specified QH in the
+ * periodic schedule. For simplicity, this calculation assumes that all the
+ * transfers in the periodic schedule may occur in the same (micro)frame.
+ *
+ * @param hcd The HCD state structure for the DWC OTG controller.
+ * @param qh QH containing periodic bandwidth required.
+ *
+ * @return 0 if successful, negative error code otherwise.
+ */
+static int check_periodic_bandwidth(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	int status;
+	int16_t max_claimed_usecs;
+
+	status = 0;
+
+	if ((qh->dev_speed == DWC_OTG_EP_SPEED_HIGH) || qh->do_split) {
+		/*
+		 * High speed mode.
+		 * Max periodic usecs is 80% x 125 usec = 100 usec.
+		 */
+
+		max_claimed_usecs = 100 - qh->usecs;
+	} else {
+		/*
+		 * Full speed mode.
+		 * Max periodic usecs is 90% x 1000 usec = 900 usec.
+		 */
+		max_claimed_usecs = 900 - qh->usecs;
+	}
+
+	if (hcd->periodic_usecs > max_claimed_usecs) {
+		DWC_INFO("%s: already claimed usecs %d, required usecs %d\n", __func__, hcd->periodic_usecs, qh->usecs);	//NOTICE
+		status = -DWC_E_NO_SPACE;
+	}
+
+	return status;
+}
+
+/**
+ * Checks that the max transfer size allowed in a host channel is large enough
+ * to handle the maximum data transfer in a single (micro)frame for a periodic
+ * transfer.
+ *
+ * @param hcd The HCD state structure for the DWC OTG controller.
+ * @param qh QH for a periodic endpoint.
+ *
+ * @return 0 if successful, negative error code otherwise.
+ */
+static int check_max_xfer_size(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	int status;
+	uint32_t max_xfer_size;
+	uint32_t max_channel_xfer_size;
+
+	status = 0;
+
+	max_xfer_size = dwc_max_packet(qh->maxp) * dwc_hb_mult(qh->maxp);
+	max_channel_xfer_size = hcd->core_if->core_params->max_transfer_size;
+
+	if (max_xfer_size > max_channel_xfer_size) {
+		DWC_INFO("%s: Periodic xfer length %d > " "max xfer length for channel %d\n",
+				__func__, max_xfer_size, max_channel_xfer_size);	//NOTICE
+		status = -DWC_E_NO_SPACE;
+	}
+
+	return status;
+}
+
+/**
+ * Schedules an interrupt or isochronous transfer in the periodic schedule.
+ *
+ * @param hcd The HCD state structure for the DWC OTG controller.
+ * @param qh QH for the periodic transfer. The QH should already contain the
+ * scheduling information.
+ *
+ * @return 0 if successful, negative error code otherwise.
+ */
+static int schedule_periodic(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	int status = 0;
+
+	status = periodic_channel_available(hcd);
+	if (status) {
+		DWC_INFO("%s: No host channel available for periodic " "transfer.\n", __func__);	//NOTICE
+		return status;
+	}
+
+	status = check_periodic_bandwidth(hcd, qh);
+	if (status) {
+		DWC_INFO("%s: Insufficient periodic bandwidth for " "periodic transfer.\n", __func__);	//NOTICE
+		return status;
+	}
+
+	status = check_max_xfer_size(hcd, qh);
+	if (status) {
+		DWC_INFO("%s: Channel max transfer size too small " "for periodic transfer.\n", __func__);	//NOTICE
+		return status;
+	}
+
+	if (hcd->core_if->dma_desc_enable) {
+		/* Don't rely on SOF and start in ready schedule */
+		DWC_LIST_INSERT_TAIL(&hcd->periodic_sched_ready, &qh->qh_list_entry);
+	}
+	else {
+	/* Always start in the inactive schedule. */
+	DWC_LIST_INSERT_TAIL(&hcd->periodic_sched_inactive, &qh->qh_list_entry);
+	}
+
+	/* Reserve the periodic channel. */
+	hcd->periodic_channels++;
+
+	/* Update claimed usecs per (micro)frame. */
+	hcd->periodic_usecs += qh->usecs;
+
+	return status;
+}
+
+/**
+ * This function adds a QH to either the non periodic or periodic schedule if
+ * it is not already in the schedule. If the QH is already in the schedule, no
+ * action is taken.
+ *
+ * @return 0 if successful, negative error code otherwise.
+ */
+int dwc_otg_hcd_qh_add(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	int status = 0;
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+
+	if (!DWC_LIST_EMPTY(&qh->qh_list_entry)) {
+		/* QH already in a schedule. */
+		return status;
+	}
+
+	/* Add the new QH to the appropriate schedule */
+	if (dwc_qh_is_non_per(qh)) {
+		/* Always start in the inactive schedule. */
+		DWC_LIST_INSERT_TAIL(&hcd->non_periodic_sched_inactive,
+				     &qh->qh_list_entry);
+	} else {
+		status = schedule_periodic(hcd, qh);
+		if ( !hcd->periodic_qh_count ) {
+			intr_mask.b.sofintr = 1;
+			DWC_MODIFY_REG32(&hcd->core_if->core_global_regs->gintmsk,
+								intr_mask.d32, intr_mask.d32);
+		}
+		hcd->periodic_qh_count++;
+	}
+
+	return status;
+}
+
+/**
+ * Removes an interrupt or isochronous transfer from the periodic schedule.
+ *
+ * @param hcd The HCD state structure for the DWC OTG controller.
+ * @param qh QH for the periodic transfer.
+ */
+static void deschedule_periodic(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	DWC_LIST_REMOVE_INIT(&qh->qh_list_entry);
+
+	/* Release the periodic channel reservation. */
+	hcd->periodic_channels--;
+
+	/* Update claimed usecs per (micro)frame. */
+	hcd->periodic_usecs -= qh->usecs;
+}
+
+/**
+ * Removes a QH from either the non-periodic or periodic schedule.  Memory is
+ * not freed.
+ *
+ * @param hcd The HCD state structure.
+ * @param qh QH to remove from schedule. */
+void dwc_otg_hcd_qh_remove(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh)
+{
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+
+	if (DWC_LIST_EMPTY(&qh->qh_list_entry)) {
+		/* QH is not in a schedule. */
+		return;
+	}
+
+	if (dwc_qh_is_non_per(qh)) {
+		if (hcd->non_periodic_qh_ptr == &qh->qh_list_entry) {
+			hcd->non_periodic_qh_ptr =
+			    hcd->non_periodic_qh_ptr->next;
+		}
+		DWC_LIST_REMOVE_INIT(&qh->qh_list_entry);
+	} else {
+		deschedule_periodic(hcd, qh);
+		hcd->periodic_qh_count--;
+		if( !hcd->periodic_qh_count ) {
+			intr_mask.b.sofintr = 1;
+				DWC_MODIFY_REG32(&hcd->core_if->core_global_regs->gintmsk,
+									intr_mask.d32, 0);
+		}
+	}
+}
+
+/**
+ * Deactivates a QH. For non-periodic QHs, removes the QH from the active
+ * non-periodic schedule. The QH is added to the inactive non-periodic
+ * schedule if any QTDs are still attached to the QH.
+ *
+ * For periodic QHs, the QH is removed from the periodic queued schedule. If
+ * there are any QTDs still attached to the QH, the QH is added to either the
+ * periodic inactive schedule or the periodic ready schedule and its next
+ * scheduled frame is calculated. The QH is placed in the ready schedule if
+ * the scheduled frame has been reached already. Otherwise it's placed in the
+ * inactive schedule. If there are no QTDs attached to the QH, the QH is
+ * completely removed from the periodic schedule.
+ */
+void dwc_otg_hcd_qh_deactivate(dwc_otg_hcd_t * hcd, dwc_otg_qh_t * qh,
+			       int sched_next_periodic_split)
+{
+	if (dwc_qh_is_non_per(qh)) {
+		dwc_otg_hcd_qh_remove(hcd, qh);
+		if (!DWC_CIRCLEQ_EMPTY(&qh->qtd_list)) {
+			/* Add back to inactive non-periodic schedule. */
+			dwc_otg_hcd_qh_add(hcd, qh);
+		}
+	} else {
+		uint16_t frame_number = dwc_otg_hcd_get_frame_number(hcd);
+
+		if (qh->do_split) {
+			/* Schedule the next continuing periodic split transfer */
+			if (sched_next_periodic_split) {
+
+				qh->sched_frame = frame_number;
+				if (dwc_frame_num_le(frame_number,
+						     dwc_frame_num_inc
+						     (qh->start_split_frame,
+						      1))) {
+					/*
+					 * Allow one frame to elapse after start
+					 * split microframe before scheduling
+					 * complete split, but DONT if we are
+					 * doing the next start split in the
+					 * same frame for an ISOC out.
+					 */
+					if ((qh->ep_type != UE_ISOCHRONOUS) ||
+					    (qh->ep_is_in != 0)) {
+						qh->sched_frame =
+						    dwc_frame_num_inc(qh->sched_frame, 1);
+					}
+				}
+			} else {
+				qh->sched_frame =
+				    dwc_frame_num_inc(qh->start_split_frame,
+						      qh->interval);
+				if (dwc_frame_num_le
+				    (qh->sched_frame, frame_number)) {
+					qh->sched_frame = frame_number;
+				}
+				qh->sched_frame |= 0x7;
+				qh->start_split_frame = qh->sched_frame;
+			}
+		} else {
+			qh->sched_frame =
+			    dwc_frame_num_inc(qh->sched_frame, qh->interval);
+			if (dwc_frame_num_le(qh->sched_frame, frame_number)) {
+				qh->sched_frame = frame_number;
+			}
+		}
+
+		if (DWC_CIRCLEQ_EMPTY(&qh->qtd_list)) {
+			dwc_otg_hcd_qh_remove(hcd, qh);
+		} else {
+			/*
+			 * Remove from periodic_sched_queued and move to
+			 * appropriate queue.
+			 */
+			if (qh->sched_frame == frame_number) {
+				DWC_LIST_MOVE_HEAD(&hcd->periodic_sched_ready,
+						   &qh->qh_list_entry);
+			} else {
+				DWC_LIST_MOVE_HEAD
+				    (&hcd->periodic_sched_inactive,
+				     &qh->qh_list_entry);
+			}
+		}
+	}
+}
+
+/**
+ * This function allocates and initializes a QTD.
+ *
+ * @param urb The URB to create a QTD from.  Each URB-QTD pair will end up
+ *	      pointing to each other so each pair should have a unique correlation.
+ * @param atomic_alloc Flag to do atomic alloc if needed
+ *
+ * @return Returns pointer to the newly allocated QTD, or NULL on error. */
+dwc_otg_qtd_t *dwc_otg_hcd_qtd_create(dwc_otg_hcd_urb_t * urb, int atomic_alloc)
+{
+	dwc_otg_qtd_t *qtd;
+
+	qtd = dwc_otg_hcd_qtd_alloc(atomic_alloc);
+	if (qtd == NULL) {
+		return NULL;
+	}
+
+	dwc_otg_hcd_qtd_init(qtd, urb);
+	return qtd;
+}
+
+/**
+ * Initializes a QTD structure.
+ *
+ * @param qtd The QTD to initialize.
+ * @param urb The URB to use for initialization.  */
+void dwc_otg_hcd_qtd_init(dwc_otg_qtd_t * qtd, dwc_otg_hcd_urb_t * urb)
+{
+	dwc_memset(qtd, 0, sizeof(dwc_otg_qtd_t));
+	qtd->urb = urb;
+	if (dwc_otg_hcd_get_pipe_type(&urb->pipe_info) == UE_CONTROL) {
+		/*
+		 * The only time the QTD data toggle is used is on the data
+		 * phase of control transfers. This phase always starts with
+		 * DATA1.
+		 */
+		qtd->data_toggle = DWC_OTG_HC_PID_DATA1;
+		qtd->control_phase = DWC_OTG_CONTROL_SETUP;
+	}
+
+	/* start split */
+	qtd->complete_split = 0;
+	qtd->isoc_split_pos = DWC_HCSPLIT_XACTPOS_ALL;
+	qtd->isoc_split_offset = 0;
+	qtd->in_process = 0;
+
+	/* Store the qtd ptr in the urb to reference what QTD. */
+	urb->qtd = qtd;
+	return;
+}
+
+/**
+ * This function adds a QTD to the QTD-list of a QH.  It will find the correct
+ * QH to place the QTD into.  If it does not find a QH, then it will create a
+ * new QH. If the QH to which the QTD is added is not currently scheduled, it
+ * is placed into the proper schedule based on its EP type.
+ *
+ * @param[in] qtd The QTD to add
+ * @param[in] hcd The DWC HCD structure
+ * @param[out] qh out parameter to return queue head
+ * @param atomic_alloc Flag to do atomic alloc if needed
+ *
+ * @return 0 if successful, negative error code otherwise.
+ */
+int dwc_otg_hcd_qtd_add(dwc_otg_qtd_t * qtd,
+			dwc_otg_hcd_t * hcd, dwc_otg_qh_t ** qh, int atomic_alloc)
+{
+	int retval = 0;
+	dwc_irqflags_t flags;
+
+	dwc_otg_hcd_urb_t *urb = qtd->urb;
+
+	/*
+	 * Get the QH which holds the QTD-list to insert to. Create QH if it
+	 * doesn't exist.
+	 */
+	if (*qh == NULL) {
+		*qh = dwc_otg_hcd_qh_create(hcd, urb, atomic_alloc);
+		if (*qh == NULL) {
+			retval = -1;
+			goto done;
+		}
+	}
+	DWC_SPINLOCK_IRQSAVE(hcd->lock, &flags);
+	retval = dwc_otg_hcd_qh_add(hcd, *qh);
+	if (retval == 0) {
+		DWC_CIRCLEQ_INSERT_TAIL(&((*qh)->qtd_list), qtd,
+					qtd_list_entry);
+	}
+	DWC_SPINUNLOCK_IRQRESTORE(hcd->lock, flags);
+
+done:
+
+	return retval;
+}
+
+#endif /* DWC_DEVICE_ONLY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_os_dep.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_os_dep.h
new file mode 100644
index 0000000..7e491fe
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_os_dep.h
@@ -0,0 +1,88 @@
+#ifndef _DWC_OS_DEP_H_
+#define _DWC_OS_DEP_H_
+
+/**
+ * @file
+ *
+ * This file contains OS dependent structures.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/list.h>
+#include <linux/interrupt.h>
+#include <linux/ctype.h>
+#include <linux/string.h>
+#include <linux/dma-mapping.h>
+#include <linux/jiffies.h>
+#include <linux/delay.h>
+#include <linux/timer.h>
+#include <linux/workqueue.h>
+#include <linux/stat.h>
+#include <linux/pci.h>
+
+#include <linux/version.h>
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,20)
+# include <linux/irq.h>
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,21)
+# include <linux/usb/ch9.h>
+#else
+# include <linux/usb_ch9.h>
+#endif
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,24)
+# include <linux/usb/gadget.h>
+#else
+# include <linux/usb_gadget.h>
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,20)
+# include <asm/irq.h>
+#endif
+
+
+#include <asm/unaligned.h>
+#include <asm/sizes.h>
+#include <asm/param.h>
+#include <asm/io.h>
+
+
+/** The OS page size */
+#define DWC_OS_PAGE_SIZE	PAGE_SIZE
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,14)
+typedef int gfp_t;
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,18)
+# define IRQF_SHARED SA_SHIRQ
+#endif
+
+typedef struct os_dependent {
+	/** Base address returned from ioremap() */
+	void *base;
+
+	/** Register offset for Diagnostic API */
+	uint32_t reg_offset;
+
+	uint32_t res_start;
+
+	struct platform_device *lmdev;
+
+} os_dependent_t;
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _DWC_OS_DEP_H_ */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd.c
new file mode 100644
index 0000000..36b52d5
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd.c
@@ -0,0 +1,2838 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_pcd.c $
+ * $Revision: #105 $
+ * $Date: 2013/05/16 $
+ * $Change: 2231774 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef DWC_HOST_ONLY
+
+/** @file
+ * This file implements PCD Core. All code in this file is portable and doesn't
+ * use any OS specific functions.
+ * PCD Core provides Interface, defined in <code><dwc_otg_pcd_if.h></code>
+ * header file, which can be used to implement OS specific PCD interface.
+ *
+ * An important function of the PCD is managing interrupts generated
+ * by the DWC_otg controller. The implementation of the DWC_otg device
+ * mode interrupt service routines is in dwc_otg_pcd_intr.c.
+ *
+ * @todo Add Device Mode test modes (Test J mode, Test K mode, etc).
+ * @todo Does it work when the request size is greater than DEPTSIZ
+ * transfer size
+ *
+ */
+
+#include "dwc_otg_pcd.h"
+
+#ifdef DWC_UTE_CFI
+#include "dwc_otg_cfi.h"
+
+extern int init_cfi(cfiobject_t * cfiobj);
+#endif
+static int bulk_num = 0;
+/**
+ * Choose endpoint from ep arrays using usb_ep structure.
+ */
+static dwc_otg_pcd_ep_t *get_ep_from_handle(dwc_otg_pcd_t * pcd, void *handle)
+{
+	int i;
+	if (pcd->ep0.priv == handle) {
+		return &pcd->ep0;
+	}
+	for (i = 0; i < MAX_EPS_CHANNELS - 1; i++) {
+		if (pcd->in_ep[i].priv == handle)
+			return &pcd->in_ep[i];
+		if (pcd->out_ep[i].priv == handle)
+			return &pcd->out_ep[i];
+	}
+
+	return NULL;
+}
+
+/**
+ * This function completes a request.  It call's the request call back.
+ */
+void dwc_otg_request_done(dwc_otg_pcd_ep_t * ep, dwc_otg_pcd_request_t * req,
+			  int32_t status)
+{
+	unsigned stopped = ep->stopped;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(ep %p req %p)\n", __func__, ep, req);
+	DWC_CIRCLEQ_REMOVE_INIT(&ep->queue, req, queue_entry);
+
+	/* don't modify queue heads during completion callback */
+	ep->stopped = 1;
+	/* spin_unlock/spin_lock now done in fops->complete() */
+	ep->pcd->fops->complete(ep->pcd, ep->priv, req->priv, status,
+				req->actual);
+
+	if (ep->pcd->request_pending > 0) {
+		--ep->pcd->request_pending;
+	}
+
+	ep->stopped = stopped;
+	DWC_FREE(req);
+}
+
+/**
+ * This function terminates all the requsts in the EP request queue.
+ */
+void dwc_otg_request_nuke(dwc_otg_pcd_ep_t * ep)
+{
+	dwc_otg_pcd_request_t *req;
+
+	ep->stopped = 1;
+
+	/* called with irqs blocked?? */
+	while (!DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+		req = DWC_CIRCLEQ_FIRST(&ep->queue);
+		dwc_otg_request_done(ep, req, -DWC_E_SHUTDOWN);
+	}
+}
+
+void dwc_otg_pcd_start(dwc_otg_pcd_t * pcd,
+		       const struct dwc_otg_pcd_function_ops *fops)
+{
+	pcd->fops = fops;
+}
+
+/**
+ * PCD Callback function for initializing the PCD when switching to
+ * device mode.
+ *
+ * @param p void pointer to the <code>dwc_otg_pcd_t</code>
+ */
+static int32_t dwc_otg_pcd_start_cb(void *p)
+{
+	dwc_otg_pcd_t *pcd = (dwc_otg_pcd_t *) p;
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+
+	/*
+	 * Initialized the Core for Device mode.
+	 */
+	if (dwc_otg_is_device_mode(core_if)) {
+		dwc_otg_core_dev_init(core_if);
+		/* Set core_if's lock pointer to the pcd->lock */
+		core_if->lock = pcd->lock;
+	}
+	return 1;
+}
+
+/** CFI-specific buffer allocation function for EP */
+#ifdef DWC_UTE_CFI
+uint8_t *cfiw_ep_alloc_buffer(dwc_otg_pcd_t * pcd, void *pep, dwc_dma_t * addr,
+			      size_t buflen, int flags)
+{
+	dwc_otg_pcd_ep_t *ep;
+	ep = get_ep_from_handle(pcd, pep);
+	if (!ep) {
+		DWC_WARN("bad ep\n");
+		return -DWC_E_INVALID;
+	}
+
+	return pcd->cfi->ops.ep_alloc_buf(pcd->cfi, pcd, ep, addr, buflen,
+					  flags);
+}
+#else
+uint8_t *cfiw_ep_alloc_buffer(dwc_otg_pcd_t * pcd, void *pep, dwc_dma_t * addr,
+			      size_t buflen, int flags);
+#endif
+
+/**
+ * PCD Callback function for notifying the PCD when resuming from
+ * suspend.
+ *
+ * @param p void pointer to the <code>dwc_otg_pcd_t</code>
+ */
+static int32_t dwc_otg_pcd_resume_cb(void *p)
+{
+	dwc_otg_pcd_t *pcd = (dwc_otg_pcd_t *) p;
+
+	if (pcd->fops->resume) {
+		pcd->fops->resume(pcd);
+	}
+
+	/* Stop the SRP timeout timer. */
+	if ((GET_CORE_IF(pcd)->core_params->phy_type != DWC_PHY_TYPE_PARAM_FS)
+	    || (!GET_CORE_IF(pcd)->core_params->i2c_enable)) {
+		if (GET_CORE_IF(pcd)->srp_timer_started) {
+			GET_CORE_IF(pcd)->srp_timer_started = 0;
+			DWC_TIMER_CANCEL(GET_CORE_IF(pcd)->srp_timer);
+		}
+	}
+	return 1;
+}
+
+/**
+ * PCD Callback function for notifying the PCD device is suspended.
+ *
+ * @param p void pointer to the <code>dwc_otg_pcd_t</code>
+ */
+static int32_t dwc_otg_pcd_suspend_cb(void *p)
+{
+	dwc_otg_pcd_t *pcd = (dwc_otg_pcd_t *) p;
+
+	if (pcd->fops->suspend) {
+		DWC_SPINUNLOCK(pcd->lock);
+		pcd->fops->suspend(pcd);
+		DWC_SPINLOCK(pcd->lock);
+	}
+
+	return 1;
+}
+
+/**
+ * PCD Callback function for stopping the PCD when switching to Host
+ * mode.
+ *
+ * @param p void pointer to the <code>dwc_otg_pcd_t</code>
+ */
+static int32_t dwc_otg_pcd_stop_cb(void *p)
+{
+	dwc_otg_pcd_t *pcd = (dwc_otg_pcd_t *) p;
+	extern void dwc_otg_pcd_stop(dwc_otg_pcd_t * _pcd);
+
+	dwc_otg_pcd_stop(pcd);
+	return 1;
+}
+
+/**
+ * PCD Callback structure for handling mode switching.
+ */
+static dwc_otg_cil_callbacks_t pcd_callbacks = {
+	.start = dwc_otg_pcd_start_cb,
+	.stop = dwc_otg_pcd_stop_cb,
+	.suspend = dwc_otg_pcd_suspend_cb,
+	.resume_wakeup = dwc_otg_pcd_resume_cb,
+	.p = 0,			/* Set at registration */
+};
+
+/**
+ * This function allocates a DMA Descriptor chain for the Endpoint
+ * buffer to be used for a transfer to/from the specified endpoint.
+ */
+dwc_otg_dev_dma_desc_t *dwc_otg_ep_alloc_desc_chain(dwc_dma_t * dma_desc_addr,
+						    uint32_t count)
+{
+	return DWC_DMA_ALLOC_ATOMIC(count * sizeof(dwc_otg_dev_dma_desc_t),
+				    dma_desc_addr);
+}
+
+/**
+ * This function frees a DMA Descriptor chain that was allocated by ep_alloc_desc.
+ */
+void dwc_otg_ep_free_desc_chain(dwc_otg_dev_dma_desc_t * desc_addr,
+				uint32_t dma_desc_addr, uint32_t count)
+{
+	DWC_DMA_FREE(count * sizeof(dwc_otg_dev_dma_desc_t), desc_addr,
+		     dma_desc_addr);
+}
+
+#ifdef DWC_EN_ISOC
+
+/**
+ * This function initializes a descriptor chain for Isochronous transfer
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param dwc_ep The EP to start the transfer on.
+ *
+ */
+void dwc_otg_iso_ep_start_ddma_transfer(dwc_otg_core_if_t * core_if,
+					dwc_ep_t * dwc_ep)
+{
+
+	dsts_data_t dsts = {.d32 = 0 };
+	depctl_data_t depctl = {.d32 = 0 };
+	volatile uint32_t *addr;
+	int i, j;
+	uint32_t len;
+
+	if (dwc_ep->is_in)
+		dwc_ep->desc_cnt = dwc_ep->buf_proc_intrvl / dwc_ep->bInterval;
+	else
+		dwc_ep->desc_cnt =
+		    dwc_ep->buf_proc_intrvl * dwc_ep->pkt_per_frm /
+		    dwc_ep->bInterval;
+
+	/** Allocate descriptors for double buffering */
+	dwc_ep->iso_desc_addr =
+	    dwc_otg_ep_alloc_desc_chain(&dwc_ep->iso_dma_desc_addr,
+					dwc_ep->desc_cnt * 2);
+	if (dwc_ep->desc_addr) {
+		DWC_WARN("%s, can't allocate DMA descriptor chain\n", __func__);
+		return;
+	}
+
+	dsts.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dsts);
+
+	/** ISO OUT EP */
+	if (dwc_ep->is_in == 0) {
+		dev_dma_desc_sts_t sts = {.d32 = 0 };
+		dwc_otg_dev_dma_desc_t *dma_desc = dwc_ep->iso_desc_addr;
+		dma_addr_t dma_ad;
+		uint32_t data_per_desc;
+		dwc_otg_dev_out_ep_regs_t *out_regs =
+		    core_if->dev_if->out_ep_regs[dwc_ep->num];
+		int offset;
+
+		addr = &core_if->dev_if->out_ep_regs[dwc_ep->num]->doepctl;
+
+		/** Buffer 0 descriptors setup */
+		dma_ad = dwc_ep->dma_addr0;
+
+		sts.b_iso_out.bs = BS_HOST_READY;
+		sts.b_iso_out.rxsts = 0;
+		sts.b_iso_out.l = 0;
+		sts.b_iso_out.sp = 0;
+		sts.b_iso_out.ioc = 0;
+		sts.b_iso_out.pid = 0;
+		sts.b_iso_out.framenum = 0;
+
+		offset = 0;
+		for (i = 0; i < dwc_ep->desc_cnt - dwc_ep->pkt_per_frm;
+		     i += dwc_ep->pkt_per_frm) {
+
+			for (j = 0; j < dwc_ep->pkt_per_frm; ++j) {
+				uint32_t len = (j + 1) * dwc_ep->maxpacket;
+				if (len > dwc_ep->data_per_frame)
+					data_per_desc =
+					    dwc_ep->data_per_frame -
+					    j * dwc_ep->maxpacket;
+				else
+					data_per_desc = dwc_ep->maxpacket;
+				len = data_per_desc % 4;
+				if (len)
+					data_per_desc += 4 - len;
+
+				sts.b_iso_out.rxbytes = data_per_desc;
+				dma_desc->buf = dma_ad;
+				dma_desc->status.d32 = sts.d32;
+
+				offset += data_per_desc;
+				dma_desc++;
+				dma_ad += data_per_desc;
+			}
+		}
+
+		for (j = 0; j < dwc_ep->pkt_per_frm - 1; ++j) {
+			uint32_t len = (j + 1) * dwc_ep->maxpacket;
+			if (len > dwc_ep->data_per_frame)
+				data_per_desc =
+				    dwc_ep->data_per_frame -
+				    j * dwc_ep->maxpacket;
+			else
+				data_per_desc = dwc_ep->maxpacket;
+			len = data_per_desc % 4;
+			if (len)
+				data_per_desc += 4 - len;
+			sts.b_iso_out.rxbytes = data_per_desc;
+			dma_desc->buf = dma_ad;
+			dma_desc->status.d32 = sts.d32;
+
+			offset += data_per_desc;
+			dma_desc++;
+			dma_ad += data_per_desc;
+		}
+
+		sts.b_iso_out.ioc = 1;
+		len = (j + 1) * dwc_ep->maxpacket;
+		if (len > dwc_ep->data_per_frame)
+			data_per_desc =
+			    dwc_ep->data_per_frame - j * dwc_ep->maxpacket;
+		else
+			data_per_desc = dwc_ep->maxpacket;
+		len = data_per_desc % 4;
+		if (len)
+			data_per_desc += 4 - len;
+		sts.b_iso_out.rxbytes = data_per_desc;
+
+		dma_desc->buf = dma_ad;
+		dma_desc->status.d32 = sts.d32;
+		dma_desc++;
+
+		/** Buffer 1 descriptors setup */
+		sts.b_iso_out.ioc = 0;
+		dma_ad = dwc_ep->dma_addr1;
+
+		offset = 0;
+		for (i = 0; i < dwc_ep->desc_cnt - dwc_ep->pkt_per_frm;
+		     i += dwc_ep->pkt_per_frm) {
+			for (j = 0; j < dwc_ep->pkt_per_frm; ++j) {
+				uint32_t len = (j + 1) * dwc_ep->maxpacket;
+				if (len > dwc_ep->data_per_frame)
+					data_per_desc =
+					    dwc_ep->data_per_frame -
+					    j * dwc_ep->maxpacket;
+				else
+					data_per_desc = dwc_ep->maxpacket;
+				len = data_per_desc % 4;
+				if (len)
+					data_per_desc += 4 - len;
+
+				data_per_desc =
+				    sts.b_iso_out.rxbytes = data_per_desc;
+				dma_desc->buf = dma_ad;
+				dma_desc->status.d32 = sts.d32;
+
+				offset += data_per_desc;
+				dma_desc++;
+				dma_ad += data_per_desc;
+			}
+		}
+		for (j = 0; j < dwc_ep->pkt_per_frm - 1; ++j) {
+			data_per_desc =
+			    ((j + 1) * dwc_ep->maxpacket >
+			     dwc_ep->data_per_frame) ? dwc_ep->data_per_frame -
+			    j * dwc_ep->maxpacket : dwc_ep->maxpacket;
+			data_per_desc +=
+			    (data_per_desc % 4) ? (4 - data_per_desc % 4) : 0;
+			sts.b_iso_out.rxbytes = data_per_desc;
+			dma_desc->buf = dma_ad;
+			dma_desc->status.d32 = sts.d32;
+
+			offset += data_per_desc;
+			dma_desc++;
+			dma_ad += data_per_desc;
+		}
+
+		sts.b_iso_out.ioc = 1;
+		sts.b_iso_out.l = 1;
+		data_per_desc =
+		    ((j + 1) * dwc_ep->maxpacket >
+		     dwc_ep->data_per_frame) ? dwc_ep->data_per_frame -
+		    j * dwc_ep->maxpacket : dwc_ep->maxpacket;
+		data_per_desc +=
+		    (data_per_desc % 4) ? (4 - data_per_desc % 4) : 0;
+		sts.b_iso_out.rxbytes = data_per_desc;
+
+		dma_desc->buf = dma_ad;
+		dma_desc->status.d32 = sts.d32;
+
+		dwc_ep->next_frame = 0;
+
+		/** Write dma_ad into DOEPDMA register */
+		DWC_WRITE_REG32(&(out_regs->doepdma),
+				(uint32_t) dwc_ep->iso_dma_desc_addr);
+
+	}
+	/** ISO IN EP */
+	else {
+		dev_dma_desc_sts_t sts = {.d32 = 0 };
+		dwc_otg_dev_dma_desc_t *dma_desc = dwc_ep->iso_desc_addr;
+		dma_addr_t dma_ad;
+		dwc_otg_dev_in_ep_regs_t *in_regs =
+		    core_if->dev_if->in_ep_regs[dwc_ep->num];
+		unsigned int frmnumber;
+		fifosize_data_t txfifosize, rxfifosize;
+
+		txfifosize.d32 =
+		    DWC_READ_REG32(&core_if->dev_if->in_ep_regs[dwc_ep->num]->
+				   dtxfsts);
+		rxfifosize.d32 =
+		    DWC_READ_REG32(&core_if->core_global_regs->grxfsiz);
+
+		addr = &core_if->dev_if->in_ep_regs[dwc_ep->num]->diepctl;
+
+		dma_ad = dwc_ep->dma_addr0;
+
+		dsts.d32 =
+		    DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dsts);
+
+		sts.b_iso_in.bs = BS_HOST_READY;
+		sts.b_iso_in.txsts = 0;
+		sts.b_iso_in.sp =
+		    (dwc_ep->data_per_frame % dwc_ep->maxpacket) ? 1 : 0;
+		sts.b_iso_in.ioc = 0;
+		sts.b_iso_in.pid = dwc_ep->pkt_per_frm;
+
+		frmnumber = dwc_ep->next_frame;
+
+		sts.b_iso_in.framenum = frmnumber;
+		sts.b_iso_in.txbytes = dwc_ep->data_per_frame;
+		sts.b_iso_in.l = 0;
+
+		/** Buffer 0 descriptors setup */
+		for (i = 0; i < dwc_ep->desc_cnt - 1; i++) {
+			dma_desc->buf = dma_ad;
+			dma_desc->status.d32 = sts.d32;
+			dma_desc++;
+
+			dma_ad += dwc_ep->data_per_frame;
+			sts.b_iso_in.framenum += dwc_ep->bInterval;
+		}
+
+		sts.b_iso_in.ioc = 1;
+		dma_desc->buf = dma_ad;
+		dma_desc->status.d32 = sts.d32;
+		++dma_desc;
+
+		/** Buffer 1 descriptors setup */
+		sts.b_iso_in.ioc = 0;
+		dma_ad = dwc_ep->dma_addr1;
+
+		for (i = 0; i < dwc_ep->desc_cnt - dwc_ep->pkt_per_frm;
+		     i += dwc_ep->pkt_per_frm) {
+			dma_desc->buf = dma_ad;
+			dma_desc->status.d32 = sts.d32;
+			dma_desc++;
+
+			dma_ad += dwc_ep->data_per_frame;
+			sts.b_iso_in.framenum += dwc_ep->bInterval;
+
+			sts.b_iso_in.ioc = 0;
+		}
+		sts.b_iso_in.ioc = 1;
+		sts.b_iso_in.l = 1;
+
+		dma_desc->buf = dma_ad;
+		dma_desc->status.d32 = sts.d32;
+
+		dwc_ep->next_frame = sts.b_iso_in.framenum + dwc_ep->bInterval;
+
+		/** Write dma_ad into diepdma register */
+		DWC_WRITE_REG32(&(in_regs->diepdma),
+				(uint32_t) dwc_ep->iso_dma_desc_addr);
+	}
+	/** Enable endpoint, clear nak  */
+	depctl.d32 = 0;
+	depctl.b.epena = 1;
+	depctl.b.usbactep = 1;
+	depctl.b.cnak = 1;
+
+	DWC_MODIFY_REG32(addr, depctl.d32, depctl.d32);
+	depctl.d32 = DWC_READ_REG32(addr);
+}
+
+/**
+ * This function initializes a descriptor chain for Isochronous transfer
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to start the transfer on.
+ *
+ */
+void dwc_otg_iso_ep_start_buf_transfer(dwc_otg_core_if_t * core_if,
+				       dwc_ep_t * ep)
+{
+	depctl_data_t depctl = {.d32 = 0 };
+	volatile uint32_t *addr;
+
+	if (ep->is_in) {
+		addr = &core_if->dev_if->in_ep_regs[ep->num]->diepctl;
+	} else {
+		addr = &core_if->dev_if->out_ep_regs[ep->num]->doepctl;
+	}
+
+	if (core_if->dma_enable == 0 || core_if->dma_desc_enable != 0) {
+		return;
+	} else {
+		deptsiz_data_t deptsiz = {.d32 = 0 };
+
+		ep->xfer_len =
+		    ep->data_per_frame * ep->buf_proc_intrvl / ep->bInterval;
+		ep->pkt_cnt =
+		    (ep->xfer_len - 1 + ep->maxpacket) / ep->maxpacket;
+		ep->xfer_count = 0;
+		ep->xfer_buff =
+		    (ep->proc_buf_num) ? ep->xfer_buff1 : ep->xfer_buff0;
+		ep->dma_addr =
+		    (ep->proc_buf_num) ? ep->dma_addr1 : ep->dma_addr0;
+
+		if (ep->is_in) {
+			/* Program the transfer size and packet count
+			 *      as follows: xfersize = N * maxpacket +
+			 *      short_packet pktcnt = N + (short_packet
+			 *      exist ? 1 : 0)
+			 */
+			deptsiz.b.mc = ep->pkt_per_frm;
+			deptsiz.b.xfersize = ep->xfer_len;
+			deptsiz.b.pktcnt =
+			    (ep->xfer_len - 1 + ep->maxpacket) / ep->maxpacket;
+			DWC_WRITE_REG32(&core_if->dev_if->in_ep_regs[ep->num]->
+					dieptsiz, deptsiz.d32);
+
+			/* Write the DMA register */
+			DWC_WRITE_REG32(&
+					(core_if->dev_if->in_ep_regs[ep->num]->
+					 diepdma), (uint32_t) ep->dma_addr);
+
+		} else {
+			deptsiz.b.pktcnt =
+			    (ep->xfer_len + (ep->maxpacket - 1)) /
+			    ep->maxpacket;
+			deptsiz.b.xfersize = deptsiz.b.pktcnt * ep->maxpacket;
+
+			DWC_WRITE_REG32(&core_if->dev_if->out_ep_regs[ep->num]->
+					doeptsiz, deptsiz.d32);
+
+			/* Write the DMA register */
+			DWC_WRITE_REG32(&
+					(core_if->dev_if->out_ep_regs[ep->num]->
+					 doepdma), (uint32_t) ep->dma_addr);
+
+		}
+		/** Enable endpoint, clear nak  */
+		depctl.d32 = 0;
+		depctl.b.epena = 1;
+		depctl.b.cnak = 1;
+
+		DWC_MODIFY_REG32(addr, depctl.d32, depctl.d32);
+	}
+}
+
+/**
+ * This function does the setup for a data transfer for an EP and
+ * starts the transfer. For an IN transfer, the packets will be
+ * loaded into the appropriate Tx FIFO in the ISR. For OUT transfers,
+ * the packets are unloaded from the Rx FIFO in the ISR.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to start the transfer on.
+ */
+
+static void dwc_otg_iso_ep_start_transfer(dwc_otg_core_if_t * core_if,
+					  dwc_ep_t * ep)
+{
+	if (core_if->dma_enable) {
+		if (core_if->dma_desc_enable) {
+			if (ep->is_in) {
+				ep->desc_cnt = ep->pkt_cnt / ep->pkt_per_frm;
+			} else {
+				ep->desc_cnt = ep->pkt_cnt;
+			}
+			dwc_otg_iso_ep_start_ddma_transfer(core_if, ep);
+		} else {
+			if (core_if->pti_enh_enable) {
+				dwc_otg_iso_ep_start_buf_transfer(core_if, ep);
+			} else {
+				ep->cur_pkt_addr =
+				    (ep->proc_buf_num) ? ep->xfer_buff1 : ep->
+				    xfer_buff0;
+				ep->cur_pkt_dma_addr =
+				    (ep->proc_buf_num) ? ep->dma_addr1 : ep->
+				    dma_addr0;
+				dwc_otg_iso_ep_start_frm_transfer(core_if, ep);
+			}
+		}
+	} else {
+		ep->cur_pkt_addr =
+		    (ep->proc_buf_num) ? ep->xfer_buff1 : ep->xfer_buff0;
+		ep->cur_pkt_dma_addr =
+		    (ep->proc_buf_num) ? ep->dma_addr1 : ep->dma_addr0;
+		dwc_otg_iso_ep_start_frm_transfer(core_if, ep);
+	}
+}
+
+/**
+ * This function stops transfer for an EP and
+ * resets the ep's variables.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to start the transfer on.
+ */
+
+void dwc_otg_iso_ep_stop_transfer(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	depctl_data_t depctl = {.d32 = 0 };
+	volatile uint32_t *addr;
+
+	if (ep->is_in == 1) {
+		addr = &core_if->dev_if->in_ep_regs[ep->num]->diepctl;
+	} else {
+		addr = &core_if->dev_if->out_ep_regs[ep->num]->doepctl;
+	}
+
+	/* disable the ep */
+	depctl.d32 = DWC_READ_REG32(addr);
+
+	depctl.b.epdis = 1;
+	depctl.b.snak = 1;
+
+	DWC_WRITE_REG32(addr, depctl.d32);
+
+	if (core_if->dma_desc_enable &&
+	    ep->iso_desc_addr && ep->iso_dma_desc_addr) {
+		dwc_otg_ep_free_desc_chain(ep->iso_desc_addr,
+					   ep->iso_dma_desc_addr,
+					   ep->desc_cnt * 2);
+	}
+
+	/* reset varibales */
+	ep->dma_addr0 = 0;
+	ep->dma_addr1 = 0;
+	ep->xfer_buff0 = 0;
+	ep->xfer_buff1 = 0;
+	ep->data_per_frame = 0;
+	ep->data_pattern_frame = 0;
+	ep->sync_frame = 0;
+	ep->buf_proc_intrvl = 0;
+	ep->bInterval = 0;
+	ep->proc_buf_num = 0;
+	ep->pkt_per_frm = 0;
+	ep->desc_cnt = 0;
+	ep->iso_desc_addr = 0;
+	ep->iso_dma_desc_addr = 0;
+}
+
+int dwc_otg_pcd_iso_ep_start(dwc_otg_pcd_t * pcd, void *ep_handle,
+			     uint8_t * buf0, uint8_t * buf1, dwc_dma_t dma0,
+			     dwc_dma_t dma1, int sync_frame, int dp_frame,
+			     int data_per_frame, int start_frame,
+			     int buf_proc_intrvl, void *req_handle,
+			     int atomic_alloc)
+{
+	dwc_otg_pcd_ep_t *ep;
+	dwc_irqflags_t flags = 0;
+	dwc_ep_t *dwc_ep;
+	int32_t frm_data;
+	dsts_data_t dsts;
+	dwc_otg_core_if_t *core_if;
+
+	ep = get_ep_from_handle(pcd, ep_handle);
+
+	if (!ep || !ep->desc || ep->dwc_ep.num == 0) {
+		DWC_WARN("bad ep\n");
+		return -DWC_E_INVALID;
+	}
+
+	DWC_SPINLOCK_IRQSAVE(pcd->lock, &flags);
+	core_if = GET_CORE_IF(pcd);
+	dwc_ep = &ep->dwc_ep;
+
+	if (ep->iso_req_handle) {
+		DWC_WARN("ISO request in progress\n");
+	}
+
+	dwc_ep->dma_addr0 = dma0;
+	dwc_ep->dma_addr1 = dma1;
+
+	dwc_ep->xfer_buff0 = buf0;
+	dwc_ep->xfer_buff1 = buf1;
+
+	dwc_ep->data_per_frame = data_per_frame;
+
+	/** @todo - pattern data support is to be implemented in the future */
+	dwc_ep->data_pattern_frame = dp_frame;
+	dwc_ep->sync_frame = sync_frame;
+
+	dwc_ep->buf_proc_intrvl = buf_proc_intrvl;
+
+	dwc_ep->bInterval = 1 << (ep->desc->bInterval - 1);
+
+	dwc_ep->proc_buf_num = 0;
+
+	dwc_ep->pkt_per_frm = 0;
+	frm_data = ep->dwc_ep.data_per_frame;
+	while (frm_data > 0) {
+		dwc_ep->pkt_per_frm++;
+		frm_data -= ep->dwc_ep.maxpacket;
+	}
+
+	dsts.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dsts);
+
+	if (start_frame == -1) {
+		dwc_ep->next_frame = dsts.b.soffn + 1;
+		if (dwc_ep->bInterval != 1) {
+			dwc_ep->next_frame =
+			    dwc_ep->next_frame + (dwc_ep->bInterval - 1 -
+						  dwc_ep->next_frame %
+						  dwc_ep->bInterval);
+		}
+	} else {
+		dwc_ep->next_frame = start_frame;
+	}
+
+	if (!core_if->pti_enh_enable) {
+		dwc_ep->pkt_cnt =
+		    dwc_ep->buf_proc_intrvl * dwc_ep->pkt_per_frm /
+		    dwc_ep->bInterval;
+	} else {
+		dwc_ep->pkt_cnt =
+		    (dwc_ep->data_per_frame *
+		     (dwc_ep->buf_proc_intrvl / dwc_ep->bInterval)
+		     - 1 + dwc_ep->maxpacket) / dwc_ep->maxpacket;
+	}
+
+	if (core_if->dma_desc_enable) {
+		dwc_ep->desc_cnt =
+		    dwc_ep->buf_proc_intrvl * dwc_ep->pkt_per_frm /
+		    dwc_ep->bInterval;
+	}
+
+	if (atomic_alloc) {
+		dwc_ep->pkt_info =
+		    DWC_ALLOC_ATOMIC(sizeof(iso_pkt_info_t) * dwc_ep->pkt_cnt);
+	} else {
+		dwc_ep->pkt_info =
+		    DWC_ALLOC(sizeof(iso_pkt_info_t) * dwc_ep->pkt_cnt);
+	}
+	if (!dwc_ep->pkt_info) {
+		DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+		return -DWC_E_NO_MEMORY;
+	}
+	if (core_if->pti_enh_enable) {
+		dwc_memset(dwc_ep->pkt_info, 0,
+			   sizeof(iso_pkt_info_t) * dwc_ep->pkt_cnt);
+	}
+
+	dwc_ep->cur_pkt = 0;
+	ep->iso_req_handle = req_handle;
+
+	DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+	dwc_otg_iso_ep_start_transfer(core_if, dwc_ep);
+	return 0;
+}
+
+int dwc_otg_pcd_iso_ep_stop(dwc_otg_pcd_t * pcd, void *ep_handle,
+			    void *req_handle)
+{
+	dwc_irqflags_t flags = 0;
+	dwc_otg_pcd_ep_t *ep;
+	dwc_ep_t *dwc_ep;
+
+	ep = get_ep_from_handle(pcd, ep_handle);
+	if (!ep || !ep->desc || ep->dwc_ep.num == 0) {
+		DWC_WARN("bad ep\n");
+		return -DWC_E_INVALID;
+	}
+	dwc_ep = &ep->dwc_ep;
+
+	dwc_otg_iso_ep_stop_transfer(GET_CORE_IF(pcd), dwc_ep);
+
+	DWC_FREE(dwc_ep->pkt_info);
+	DWC_SPINLOCK_IRQSAVE(pcd->lock, &flags);
+	if (ep->iso_req_handle != req_handle) {
+		DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+		return -DWC_E_INVALID;
+	}
+
+	DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+
+	ep->iso_req_handle = 0;
+	return 0;
+}
+
+/**
+ * This function is used for perodical data exchnage between PCD and gadget drivers.
+ * for Isochronous EPs
+ *
+ *	- Every time a sync period completes this function is called to
+ *	  perform data exchange between PCD and gadget
+ */
+void dwc_otg_iso_buffer_done(dwc_otg_pcd_t * pcd, dwc_otg_pcd_ep_t * ep,
+			     void *req_handle)
+{
+	int i;
+	dwc_ep_t *dwc_ep;
+
+	dwc_ep = &ep->dwc_ep;
+
+	DWC_SPINUNLOCK(ep->pcd->lock);
+	pcd->fops->isoc_complete(pcd, ep->priv, ep->iso_req_handle,
+				 dwc_ep->proc_buf_num ^ 0x1);
+	DWC_SPINLOCK(ep->pcd->lock);
+
+	for (i = 0; i < dwc_ep->pkt_cnt; ++i) {
+		dwc_ep->pkt_info[i].status = 0;
+		dwc_ep->pkt_info[i].offset = 0;
+		dwc_ep->pkt_info[i].length = 0;
+	}
+}
+
+int dwc_otg_pcd_get_iso_packet_count(dwc_otg_pcd_t * pcd, void *ep_handle,
+				     void *iso_req_handle)
+{
+	dwc_otg_pcd_ep_t *ep;
+	dwc_ep_t *dwc_ep;
+
+	ep = get_ep_from_handle(pcd, ep_handle);
+	if (!ep->desc || ep->dwc_ep.num == 0) {
+		DWC_WARN("bad ep\n");
+		return -DWC_E_INVALID;
+	}
+	dwc_ep = &ep->dwc_ep;
+
+	return dwc_ep->pkt_cnt;
+}
+
+void dwc_otg_pcd_get_iso_packet_params(dwc_otg_pcd_t * pcd, void *ep_handle,
+				       void *iso_req_handle, int packet,
+				       int *status, int *actual, int *offset)
+{
+	dwc_otg_pcd_ep_t *ep;
+	dwc_ep_t *dwc_ep;
+
+	ep = get_ep_from_handle(pcd, ep_handle);
+	if (!ep)
+		DWC_WARN("bad ep\n");
+
+	dwc_ep = &ep->dwc_ep;
+
+	*status = dwc_ep->pkt_info[packet].status;
+	*actual = dwc_ep->pkt_info[packet].length;
+	*offset = dwc_ep->pkt_info[packet].offset;
+}
+
+#endif /* DWC_EN_ISOC */
+
+static void dwc_otg_pcd_init_ep(dwc_otg_pcd_t * pcd, dwc_otg_pcd_ep_t * pcd_ep,
+				uint32_t is_in, uint32_t ep_num)
+{
+	/* Init EP structure */
+	pcd_ep->desc = 0;
+	pcd_ep->pcd = pcd;
+	pcd_ep->stopped = 1;
+	pcd_ep->queue_sof = 0;
+
+	/* Init DWC ep structure */
+	pcd_ep->dwc_ep.is_in = is_in;
+	pcd_ep->dwc_ep.num = ep_num;
+	pcd_ep->dwc_ep.active = 0;
+	pcd_ep->dwc_ep.tx_fifo_num = 0;
+	/* Control until ep is actvated */
+	pcd_ep->dwc_ep.type = DWC_OTG_EP_TYPE_CONTROL;
+	pcd_ep->dwc_ep.maxpacket = MAX_PACKET_SIZE;
+	pcd_ep->dwc_ep.dma_addr = 0;
+	pcd_ep->dwc_ep.start_xfer_buff = 0;
+	pcd_ep->dwc_ep.xfer_buff = 0;
+	pcd_ep->dwc_ep.xfer_len = 0;
+	pcd_ep->dwc_ep.xfer_count = 0;
+	pcd_ep->dwc_ep.sent_zlp = 0;
+	pcd_ep->dwc_ep.total_len = 0;
+	pcd_ep->dwc_ep.desc_addr = 0;
+	pcd_ep->dwc_ep.dma_desc_addr = 0;
+	DWC_CIRCLEQ_INIT(&pcd_ep->queue);
+}
+
+/**
+ * Initialize ep's
+ */
+static void dwc_otg_pcd_reinit(dwc_otg_pcd_t * pcd)
+{
+	int i;
+	uint32_t hwcfg1;
+	dwc_otg_pcd_ep_t *ep;
+	int in_ep_cntr, out_ep_cntr;
+	uint32_t num_in_eps = (GET_CORE_IF(pcd))->dev_if->num_in_eps;
+	uint32_t num_out_eps = (GET_CORE_IF(pcd))->dev_if->num_out_eps;
+
+	/**
+	 * Initialize the EP0 structure.
+	 */
+	ep = &pcd->ep0;
+	dwc_otg_pcd_init_ep(pcd, ep, 0, 0);
+
+	in_ep_cntr = 0;
+	hwcfg1 = (GET_CORE_IF(pcd))->hwcfg1.d32 >> 3;
+	for (i = 1; in_ep_cntr < num_in_eps; i++) {
+		if ((hwcfg1 & 0x1) == 0) {
+			dwc_otg_pcd_ep_t *ep = &pcd->in_ep[in_ep_cntr];
+			in_ep_cntr++;
+			/**
+			 * @todo NGS: Add direction to EP, based on contents
+			 * of HWCFG1.  Need a copy of HWCFG1 in pcd structure?
+			 * sprintf(";r
+			 */
+			dwc_otg_pcd_init_ep(pcd, ep, 1 /* IN */ , i);
+
+			DWC_CIRCLEQ_INIT(&ep->queue);
+		}
+		hwcfg1 >>= 2;
+	}
+
+	out_ep_cntr = 0;
+	hwcfg1 = (GET_CORE_IF(pcd))->hwcfg1.d32 >> 2;
+	for (i = 1; out_ep_cntr < num_out_eps; i++) {
+		if ((hwcfg1 & 0x1) == 0) {
+			dwc_otg_pcd_ep_t *ep = &pcd->out_ep[out_ep_cntr];
+			out_ep_cntr++;
+			/**
+			 * @todo NGS: Add direction to EP, based on contents
+			 * of HWCFG1.  Need a copy of HWCFG1 in pcd structure?
+			 * sprintf(";r
+			 */
+			dwc_otg_pcd_init_ep(pcd, ep, 0 /* OUT */ , i);
+			DWC_CIRCLEQ_INIT(&ep->queue);
+		}
+		hwcfg1 >>= 2;
+	}
+
+	pcd->ep0state = EP0_DISCONNECT;
+	pcd->ep0.dwc_ep.maxpacket = MAX_EP0_SIZE;
+	pcd->ep0.dwc_ep.type = DWC_OTG_EP_TYPE_CONTROL;
+}
+
+/**
+ * Tasklet
+ *
+ */
+extern void start_next_request(dwc_otg_pcd_ep_t * ep);
+
+static void start_xfer_tasklet_func(void *data)
+{
+	dwc_otg_pcd_t *pcd = (dwc_otg_pcd_t *) data;
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+
+	int i;
+	depctl_data_t diepctl;
+
+	DWC_DEBUGPL(DBG_PCDV, "Start xfer tasklet\n");
+
+	diepctl.d32 = DWC_READ_REG32(&core_if->dev_if->in_ep_regs[0]->diepctl);
+
+	if (pcd->ep0.queue_sof) {
+		pcd->ep0.queue_sof = 0;
+		start_next_request(&pcd->ep0);
+		// break;
+	}
+
+	for (i = 0; i < core_if->dev_if->num_in_eps; i++) {
+		depctl_data_t diepctl;
+		diepctl.d32 =
+		    DWC_READ_REG32(&core_if->dev_if->in_ep_regs[i]->diepctl);
+
+		if (pcd->in_ep[i].queue_sof) {
+			pcd->in_ep[i].queue_sof = 0;
+			start_next_request(&pcd->in_ep[i]);
+			// break;
+		}
+	}
+
+	return;
+}
+
+/**
+ * This function initialized the PCD portion of the driver.
+ *
+ */
+dwc_otg_pcd_t *dwc_otg_pcd_init(dwc_otg_core_if_t * core_if)
+{
+	dwc_otg_pcd_t *pcd = NULL;
+	dwc_otg_dev_if_t *dev_if;
+
+	/*
+	 * Allocate PCD structure
+	 */
+	pcd = DWC_ALLOC(sizeof(dwc_otg_pcd_t));
+
+	if (pcd == NULL) {
+		return NULL;
+	}
+
+	pcd->lock = DWC_SPINLOCK_ALLOC();
+	if (!pcd->lock) {
+		DWC_ERROR("Could not allocate lock for pcd");
+		DWC_FREE(pcd);
+		return NULL;
+	}
+	/* Set core_if's lock pointer to hcd->lock */
+	core_if->lock = pcd->lock;
+	pcd->core_if = core_if;
+
+	dev_if = core_if->dev_if;
+	dev_if->isoc_ep = NULL;
+
+	if (core_if->hwcfg4.b.ded_fifo_en) {
+		DWC_PRINTF("Dedicated Tx FIFOs mode\n");
+	} else {
+		DWC_PRINTF("Shared Tx FIFO mode\n");
+	}
+
+	/*
+	 * Initialized the Core for Device mode here if there is nod ADP support.
+	 * Otherwise it will be done later in dwc_otg_adp_start routine.
+	 */
+	if (dwc_otg_is_device_mode(core_if) /*&& !core_if->adp_enable */ ) {
+		dwc_otg_core_dev_init(core_if);
+	}
+
+	/*
+	 * Register the PCD Callbacks.
+	 */
+	dwc_otg_cil_register_pcd_callbacks(core_if, &pcd_callbacks, pcd);
+
+	/*
+	 * Initialize the DMA buffer for SETUP packets
+	 */
+	if (GET_CORE_IF(pcd)->dma_enable) {
+		pcd->setup_pkt =
+		    DWC_DMA_ALLOC(sizeof(*pcd->setup_pkt) * 5,
+				  &pcd->setup_pkt_dma_handle);
+		if (pcd->setup_pkt == NULL) {
+			DWC_FREE(pcd);
+			return NULL;
+		}
+
+		pcd->status_buf =
+		    DWC_DMA_ALLOC(sizeof(uint16_t),
+				  &pcd->status_buf_dma_handle);
+		if (pcd->status_buf == NULL) {
+			DWC_DMA_FREE(sizeof(*pcd->setup_pkt) * 5,
+				     pcd->setup_pkt, pcd->setup_pkt_dma_handle);
+			DWC_FREE(pcd);
+			return NULL;
+		}
+
+		if (GET_CORE_IF(pcd)->dma_desc_enable) {
+			dev_if->setup_desc_addr[0] =
+			    dwc_otg_ep_alloc_desc_chain
+			    (&dev_if->dma_setup_desc_addr[0], 1);
+			dev_if->setup_desc_addr[1] =
+			    dwc_otg_ep_alloc_desc_chain
+			    (&dev_if->dma_setup_desc_addr[1], 1);
+			dev_if->in_desc_addr =
+			    dwc_otg_ep_alloc_desc_chain
+			    (&dev_if->dma_in_desc_addr, 1);
+			dev_if->out_desc_addr =
+			    dwc_otg_ep_alloc_desc_chain
+			    (&dev_if->dma_out_desc_addr, 1);
+			pcd->data_terminated = 0;
+
+			if (dev_if->setup_desc_addr[0] == 0
+			    || dev_if->setup_desc_addr[1] == 0
+			    || dev_if->in_desc_addr == 0
+			    || dev_if->out_desc_addr == 0) {
+
+				if (dev_if->out_desc_addr)
+					dwc_otg_ep_free_desc_chain
+					    (dev_if->out_desc_addr,
+					     dev_if->dma_out_desc_addr, 1);
+				if (dev_if->in_desc_addr)
+					dwc_otg_ep_free_desc_chain
+					    (dev_if->in_desc_addr,
+					     dev_if->dma_in_desc_addr, 1);
+				if (dev_if->setup_desc_addr[1])
+					dwc_otg_ep_free_desc_chain
+					    (dev_if->setup_desc_addr[1],
+					     dev_if->dma_setup_desc_addr[1], 1);
+				if (dev_if->setup_desc_addr[0])
+					dwc_otg_ep_free_desc_chain
+					    (dev_if->setup_desc_addr[0],
+					     dev_if->dma_setup_desc_addr[0], 1);
+
+				DWC_DMA_FREE(sizeof(*pcd->setup_pkt) * 5,
+					     pcd->setup_pkt,
+					     pcd->setup_pkt_dma_handle);
+				DWC_DMA_FREE(sizeof(*pcd->status_buf),
+					     pcd->status_buf,
+					     pcd->status_buf_dma_handle);
+
+				DWC_FREE(pcd);
+
+				return NULL;
+			}
+		}
+	} else {
+		pcd->setup_pkt = DWC_ALLOC(sizeof(*pcd->setup_pkt) * 5);
+		if (pcd->setup_pkt == NULL) {
+			DWC_FREE(pcd);
+			return NULL;
+		}
+
+		pcd->status_buf = DWC_ALLOC(sizeof(uint16_t));
+		if (pcd->status_buf == NULL) {
+			DWC_FREE(pcd->setup_pkt);
+			DWC_FREE(pcd);
+			return NULL;
+		}
+	}
+
+	dwc_otg_pcd_reinit(pcd);
+
+	/* Allocate the cfi object for the PCD */
+#ifdef DWC_UTE_CFI
+	pcd->cfi = DWC_ALLOC(sizeof(cfiobject_t));
+	if (NULL == pcd->cfi)
+		goto fail;
+	if (init_cfi(pcd->cfi)) {
+		CFI_INFO("%s: Failed to init the CFI object\n", __func__);
+		goto fail;
+	}
+#endif
+
+	/* Initialize tasklets */
+	pcd->start_xfer_tasklet = DWC_TASK_ALLOC("xfer_tasklet",
+						 start_xfer_tasklet_func, pcd);
+	pcd->test_mode_tasklet = DWC_TASK_ALLOC("test_mode_tasklet",
+						do_test_mode, pcd);
+
+	return pcd;
+#ifdef DWC_UTE_CFI
+fail:
+#endif
+	if (pcd->setup_pkt)
+		DWC_FREE(pcd->setup_pkt);
+	if (pcd->status_buf)
+		DWC_FREE(pcd->status_buf);
+#ifdef DWC_UTE_CFI
+	if (pcd->cfi)
+		DWC_FREE(pcd->cfi);
+#endif
+	if (pcd)
+		DWC_FREE(pcd);
+	return NULL;
+
+}
+
+/**
+ * Remove PCD specific data
+ */
+void dwc_otg_pcd_remove(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_dev_if_t *dev_if = GET_CORE_IF(pcd)->dev_if;
+	int i;
+	if (pcd->core_if->core_params->dev_out_nak) {
+		for (i = 0; i < MAX_EPS_CHANNELS; i++) {
+			DWC_TIMER_CANCEL(pcd->core_if->ep_xfer_timer[i]);
+			pcd->core_if->ep_xfer_info[i].state = 0;
+		}
+	}
+
+	if (GET_CORE_IF(pcd)->dma_enable) {
+		DWC_DMA_FREE(sizeof(*pcd->setup_pkt) * 5, pcd->setup_pkt,
+			     pcd->setup_pkt_dma_handle);
+		DWC_DMA_FREE(sizeof(uint16_t), pcd->status_buf,
+			     pcd->status_buf_dma_handle);
+		if (GET_CORE_IF(pcd)->dma_desc_enable) {
+			dwc_otg_ep_free_desc_chain(dev_if->setup_desc_addr[0],
+						   dev_if->dma_setup_desc_addr
+						   [0], 1);
+			dwc_otg_ep_free_desc_chain(dev_if->setup_desc_addr[1],
+						   dev_if->dma_setup_desc_addr
+						   [1], 1);
+			dwc_otg_ep_free_desc_chain(dev_if->in_desc_addr,
+						   dev_if->dma_in_desc_addr, 1);
+			dwc_otg_ep_free_desc_chain(dev_if->out_desc_addr,
+						   dev_if->dma_out_desc_addr,
+						   1);
+		}
+	} else {
+		DWC_FREE(pcd->setup_pkt);
+		DWC_FREE(pcd->status_buf);
+	}
+	DWC_SPINLOCK_FREE(pcd->lock);
+	/* Set core_if's lock pointer to NULL */
+	pcd->core_if->lock = NULL;
+
+	DWC_TASK_FREE(pcd->start_xfer_tasklet);
+	DWC_TASK_FREE(pcd->test_mode_tasklet);
+	if (pcd->core_if->core_params->dev_out_nak) {
+		for (i = 0; i < MAX_EPS_CHANNELS; i++) {
+			if (pcd->core_if->ep_xfer_timer[i]) {
+				DWC_TIMER_FREE(pcd->core_if->ep_xfer_timer[i]);
+			}
+		}
+	}
+
+/* Release the CFI object's dynamic memory */
+#ifdef DWC_UTE_CFI
+	if (pcd->cfi->ops.release) {
+		pcd->cfi->ops.release(pcd->cfi);
+	}
+#endif
+
+	DWC_FREE(pcd);
+}
+
+/**
+ * Returns whether registered pcd is dual speed or not
+ */
+uint32_t dwc_otg_pcd_is_dualspeed(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+
+	if ((core_if->core_params->speed == DWC_SPEED_PARAM_FULL) ||
+	    ((core_if->hwcfg2.b.hs_phy_type == 2) &&
+	     (core_if->hwcfg2.b.fs_phy_type == 1) &&
+	     (core_if->core_params->ulpi_fs_ls))) {
+		return 0;
+	}
+
+	return 1;
+}
+
+/**
+ * Returns whether registered pcd is OTG capable or not
+ */
+uint32_t dwc_otg_pcd_is_otg(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	gusbcfg_data_t usbcfg = {.d32 = 0 };
+	uint32_t retval = 0;
+
+	usbcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->gusbcfg);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3,6,0)
+	if (!usbcfg.b.srpcap || !usbcfg.b.hnpcap)
+		return 0;
+	else
+		return 1;
+# else
+	if (!usbcfg.b.srpcap)
+		return 0;
+	else
+		retval |= 1;
+
+	if (usbcfg.b.hnpcap)
+		retval |= 2;
+
+	if (core_if->adp_enable)
+		retval |= 4;
+#endif
+
+	return retval;
+}
+
+/**
+ * This function assigns periodic Tx FIFO to an periodic EP
+ * in shared Tx FIFO mode
+ */
+static uint32_t assign_tx_fifo(dwc_otg_core_if_t * core_if)
+{
+	uint32_t TxMsk = 1;
+	int i;
+
+	for (i = 0; i < core_if->hwcfg4.b.num_in_eps; ++i) {
+		if ((TxMsk & core_if->tx_msk) == 0) {
+			core_if->tx_msk |= TxMsk;
+			return i + 1;
+		}
+		TxMsk <<= 1;
+	}
+	return 0;
+}
+
+/**
+ * This function assigns periodic Tx FIFO to an periodic EP
+ * in shared Tx FIFO mode
+ */
+static uint32_t assign_perio_tx_fifo(dwc_otg_core_if_t * core_if)
+{
+	uint32_t PerTxMsk = 1;
+	int i;
+	for (i = 0; i < core_if->hwcfg4.b.num_dev_perio_in_ep; ++i) {
+		if ((PerTxMsk & core_if->p_tx_msk) == 0) {
+			core_if->p_tx_msk |= PerTxMsk;
+			return i + 1;
+		}
+		PerTxMsk <<= 1;
+	}
+	return 0;
+}
+
+/**
+ * This function releases periodic Tx FIFO
+ * in shared Tx FIFO mode
+ */
+static void release_perio_tx_fifo(dwc_otg_core_if_t * core_if,
+				  uint32_t fifo_num)
+{
+	core_if->p_tx_msk =
+	    (core_if->p_tx_msk & (1 << (fifo_num - 1))) ^ core_if->p_tx_msk;
+}
+
+/**
+ * This function releases periodic Tx FIFO
+ * in shared Tx FIFO mode
+ */
+static void release_tx_fifo(dwc_otg_core_if_t * core_if, uint32_t fifo_num)
+{
+	core_if->tx_msk =
+	    (core_if->tx_msk & (1 << (fifo_num - 1))) ^ core_if->tx_msk;
+}
+
+/**
+ * This function is being called from gadget
+ * to enable PCD endpoint.
+ */
+int dwc_otg_pcd_ep_enable(dwc_otg_pcd_t * pcd,
+			  const uint8_t * ep_desc, void *usb_ep)
+{
+	int num, dir;
+	dwc_otg_pcd_ep_t *ep = NULL;
+	const usb_endpoint_descriptor_t *desc;
+	dwc_irqflags_t flags;
+	fifosize_data_t dptxfsiz = {.d32 = 0 };
+	gdfifocfg_data_t gdfifocfg = {.d32 = 0 };
+	gdfifocfg_data_t gdfifocfgbase = {.d32 = 0 };
+	int retval = 0;
+	int i, epcount;
+
+	desc = (const usb_endpoint_descriptor_t *)ep_desc;
+
+	if (!desc) {
+		pcd->ep0.priv = usb_ep;
+		ep = &pcd->ep0;
+		retval = -DWC_E_INVALID;
+		goto out;
+	}
+
+	num = UE_GET_ADDR(desc->bEndpointAddress);
+	dir = UE_GET_DIR(desc->bEndpointAddress);
+	if (!desc->wMaxPacketSize) {
+		DWC_WARN("bad maxpacketsize\n");
+		retval = -DWC_E_INVALID;
+		goto out;
+	}
+
+	if (dir == UE_DIR_IN) {
+		epcount = pcd->core_if->dev_if->num_in_eps;
+		for (i = 0; i < epcount; i++) {
+			if (num == pcd->in_ep[i].dwc_ep.num) {
+				ep = &pcd->in_ep[i];
+				break;
+			}
+		}
+	} else {
+		epcount = pcd->core_if->dev_if->num_out_eps;
+		for (i = 0; i < epcount; i++) {
+			if (num == pcd->out_ep[i].dwc_ep.num) {
+				ep = &pcd->out_ep[i];
+				break;
+			}
+		}
+	}
+
+	if (!ep) {
+		DWC_WARN("bad address\n");
+		retval = -DWC_E_INVALID;
+		goto out;
+	}
+
+	DWC_SPINLOCK_IRQSAVE(pcd->lock, &flags);
+
+	ep->desc = desc;
+	ep->priv = usb_ep;
+
+	/*
+	 * Activate the EP
+	 */
+	ep->stopped = 0;
+
+	ep->dwc_ep.is_in = (dir == UE_DIR_IN);
+	ep->dwc_ep.maxpacket = UGETW(desc->wMaxPacketSize);
+
+	ep->dwc_ep.type = desc->bmAttributes & UE_XFERTYPE;
+
+	if (ep->dwc_ep.is_in) {
+		if (!GET_CORE_IF(pcd)->en_multiple_tx_fifo) {
+			ep->dwc_ep.tx_fifo_num = 0;
+
+			if (ep->dwc_ep.type == UE_ISOCHRONOUS) {
+				/*
+				 * if ISOC EP then assign a Periodic Tx FIFO.
+				 */
+				ep->dwc_ep.tx_fifo_num =
+				    assign_perio_tx_fifo(GET_CORE_IF(pcd));
+			}
+		} else {
+			/*
+			 * if Dedicated FIFOs mode is on then assign a Tx FIFO.
+			 */
+			ep->dwc_ep.tx_fifo_num =
+			    assign_tx_fifo(GET_CORE_IF(pcd));
+		}
+
+		/* Calculating EP info controller base address */
+		if (ep->dwc_ep.tx_fifo_num
+		    && GET_CORE_IF(pcd)->en_multiple_tx_fifo) {
+			gdfifocfg.d32 =
+			    DWC_READ_REG32(&GET_CORE_IF(pcd)->
+					   core_global_regs->gdfifocfg);
+			gdfifocfgbase.d32 = gdfifocfg.d32 >> 16;
+			dptxfsiz.d32 =
+			    (DWC_READ_REG32
+			     (&GET_CORE_IF(pcd)->core_global_regs->
+			      dtxfsiz[ep->dwc_ep.tx_fifo_num - 1]) >> 16);
+			gdfifocfg.b.epinfobase =
+			    gdfifocfgbase.d32 + dptxfsiz.d32;
+			if (GET_CORE_IF(pcd)->snpsid <= OTG_CORE_REV_2_94a) {
+				DWC_WRITE_REG32(&GET_CORE_IF(pcd)->
+						core_global_regs->gdfifocfg,
+						gdfifocfg.d32);
+			}
+		}
+	}
+	/* Set initial data PID. */
+	if (ep->dwc_ep.type == UE_BULK) {
+		ep->dwc_ep.data_pid_start = 0;
+	}
+
+	/* Alloc DMA Descriptors */
+	if (GET_CORE_IF(pcd)->dma_desc_enable) {
+#ifndef DWC_UTE_PER_IO
+		if (ep->dwc_ep.type != UE_ISOCHRONOUS) {
+#endif
+			ep->dwc_ep.desc_addr =
+			    dwc_otg_ep_alloc_desc_chain(&ep->
+							dwc_ep.dma_desc_addr,
+							MAX_DMA_DESC_CNT);
+			if (!ep->dwc_ep.desc_addr) {
+				DWC_WARN("%s, can't allocate DMA descriptor\n",
+					 __func__);
+				retval = -DWC_E_SHUTDOWN;
+				DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+				goto out;
+			}
+#ifndef DWC_UTE_PER_IO
+		} else {
+			ep->dwc_ep.desc_addr =
+				dwc_otg_ep_alloc_desc_chain(&ep->
+				dwc_ep.dma_desc_addr,
+				MAX_DMA_DESC_CNT/2);
+			ep->dwc_ep.desc_addr1 =
+				dwc_otg_ep_alloc_desc_chain(&ep->
+				dwc_ep.dma_desc_addr1,
+				MAX_DMA_DESC_CNT/2);
+			if (!ep->dwc_ep.desc_addr || !ep->dwc_ep.desc_addr1) {
+				DWC_WARN("%s, can't allocate DMA descriptor\n",
+					__func__);
+				retval = -DWC_E_SHUTDOWN;
+				DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+				goto out;
+			}
+			/* Set initial data PID. */
+			if (ep->dwc_ep.type == UE_ISOCHRONOUS) {
+				ep->dwc_ep.iso_desc_first = 0;
+				ep->dwc_ep.iso_desc_second = 0;
+				ep->dwc_ep.iso_transfer_started = 0;
+			}
+		}
+#endif
+	}
+
+	DWC_DEBUGPL(DBG_PCD, "Activate %s: type=%d, mps=%d desc=%p\n",
+		    (ep->dwc_ep.is_in ? "IN" : "OUT"),
+		    ep->dwc_ep.type, ep->dwc_ep.maxpacket, ep->desc);
+#ifdef DWC_UTE_PER_IO
+	ep->dwc_ep.xiso_bInterval = 1 << (ep->desc->bInterval - 1);
+#endif
+	if (ep->dwc_ep.type == DWC_OTG_EP_TYPE_ISOC) {
+		ep->dwc_ep.bInterval = 1 << (ep->desc->bInterval - 1);
+		ep->dwc_ep.frame_num = 0xFFFFFFFF;
+	}
+
+	dwc_otg_ep_activate(GET_CORE_IF(pcd), &ep->dwc_ep);
+
+#ifdef DWC_UTE_CFI
+	if (pcd->cfi->ops.ep_enable) {
+		pcd->cfi->ops.ep_enable(pcd->cfi, pcd, ep);
+	}
+#endif
+
+	DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+
+out:
+	return retval;
+}
+
+/**
+ * This function is being called from gadget
+ * to disable PCD endpoint.
+ */
+int dwc_otg_pcd_ep_disable(dwc_otg_pcd_t * pcd, void *ep_handle)
+{
+	dwc_otg_pcd_ep_t *ep;
+	dwc_irqflags_t flags;
+	dwc_otg_dev_dma_desc_t *desc_addr;
+	dwc_dma_t dma_desc_addr;
+	gdfifocfg_data_t gdfifocfgbase = {.d32 = 0 };
+	gdfifocfg_data_t gdfifocfg = {.d32 = 0 };
+	fifosize_data_t dptxfsiz = {.d32 = 0 };
+
+	ep = get_ep_from_handle(pcd, ep_handle);
+
+	if (!ep || !ep->desc) {
+		DWC_DEBUGPL(DBG_PCD, "bad ep address\n");
+		return -DWC_E_INVALID;
+	}
+
+	DWC_SPINLOCK_IRQSAVE(pcd->lock, &flags);
+
+	dwc_otg_request_nuke(ep);
+
+	dwc_otg_ep_deactivate(GET_CORE_IF(pcd), &ep->dwc_ep);
+	if (pcd->core_if->core_params->dev_out_nak) {
+		DWC_TIMER_CANCEL(pcd->core_if->ep_xfer_timer[ep->dwc_ep.num]);
+		pcd->core_if->ep_xfer_info[ep->dwc_ep.num].state = 0;
+	}
+	ep->desc = NULL;
+	ep->stopped = 1;
+
+	gdfifocfg.d32 =
+	    DWC_READ_REG32(&GET_CORE_IF(pcd)->core_global_regs->gdfifocfg);
+	gdfifocfgbase.d32 = gdfifocfg.d32 >> 16;
+
+	if (ep->dwc_ep.is_in) {
+		if (GET_CORE_IF(pcd)->en_multiple_tx_fifo) {
+			/* Flush the Tx FIFO */
+			dwc_otg_flush_tx_fifo(GET_CORE_IF(pcd),
+					      ep->dwc_ep.tx_fifo_num);
+		}
+		release_perio_tx_fifo(GET_CORE_IF(pcd), ep->dwc_ep.tx_fifo_num);
+		release_tx_fifo(GET_CORE_IF(pcd), ep->dwc_ep.tx_fifo_num);
+		if (GET_CORE_IF(pcd)->en_multiple_tx_fifo) {
+			/* Decreasing EPinfo Base Addr */
+			dptxfsiz.d32 =
+			    (DWC_READ_REG32
+			     (&GET_CORE_IF(pcd)->
+				core_global_regs->dtxfsiz[ep->dwc_ep.tx_fifo_num-1]) >> 16);
+			gdfifocfg.b.epinfobase = gdfifocfgbase.d32 - dptxfsiz.d32;
+			if (GET_CORE_IF(pcd)->snpsid <= OTG_CORE_REV_2_94a) {
+				DWC_WRITE_REG32(&GET_CORE_IF(pcd)->core_global_regs->gdfifocfg,
+						gdfifocfg.d32);
+			}
+		}
+	}
+
+	/* Free DMA Descriptors */
+	if (GET_CORE_IF(pcd)->dma_desc_enable) {
+		if (ep->dwc_ep.type != UE_ISOCHRONOUS) {
+			desc_addr = ep->dwc_ep.desc_addr;
+			dma_desc_addr = ep->dwc_ep.dma_desc_addr;
+
+			/* Cannot call dma_free_coherent() with IRQs disabled */
+			DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+			dwc_otg_ep_free_desc_chain(desc_addr, dma_desc_addr,
+						   MAX_DMA_DESC_CNT);
+
+		} else {
+			desc_addr = ep->dwc_ep.desc_addr;
+			dma_desc_addr = ep->dwc_ep.dma_desc_addr;
+
+			/* Cannot call dma_free_coherent() with IRQs disabled */
+			DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+			dwc_otg_ep_free_desc_chain(desc_addr, dma_desc_addr,
+				MAX_DMA_DESC_CNT/2);
+			desc_addr = ep->dwc_ep.desc_addr1;
+			dma_desc_addr = ep->dwc_ep.dma_desc_addr1;
+			dwc_otg_ep_free_desc_chain(desc_addr, dma_desc_addr,
+				MAX_DMA_DESC_CNT/2);
+		}
+		goto out_unlocked;
+	}
+	DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+
+out_unlocked:
+	DWC_DEBUGPL(DBG_PCD, "%d %s disabled\n", ep->dwc_ep.num,
+		    ep->dwc_ep.is_in ? "IN" : "OUT");
+	return 0;
+
+}
+
+/**
+ * This function initializes dma descriptor chain for ISOC transfers.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to start the transfer on.
+ */
+void dwc_otg_pcd_start_iso_ddma(dwc_otg_core_if_t * core_if, dwc_otg_pcd_ep_t * ep)
+{
+	dwc_otg_dev_dma_desc_t *dma_desc;
+	dwc_otg_pcd_request_t *req = NULL;
+	dwc_ep_t *dwcep = NULL;
+	uint32_t frame_num = 0;
+	int i = 0;
+	int j;
+	int sync_request = 4;
+	uint16_t nat;
+	depctl_data_t depctl;
+
+	dwcep = &ep->dwc_ep;
+	dma_desc = dwcep->desc_addr;
+
+	nat = UGETW(ep->desc->wMaxPacketSize);
+	nat = (nat >> 11) & 0x03;
+	DWC_DEBUGPL(DBG_PCD, "nat=%u binterval =%02x\n",nat, dwcep->bInterval);
+	DWC_DEBUGPL(DBG_PCD, "frame_num =  %d\n", dwcep->frame_num);
+
+	/* Complete first three IN EP requests for the synchronization */
+	if (dwcep->is_in) {
+		if (!DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+			for (j = 0; j < sync_request; j++) {
+				req = DWC_CIRCLEQ_FIRST(&ep->queue);
+				if (!req) {
+					DWC_PRINTF("ISOC 0x%p, req = NULL!\n", ep);
+					return;
+				} else {
+					/* Complete first request */
+					req->actual = 0;
+					dwc_otg_request_done(ep, req, 0);
+				}
+			}
+		} else {
+			DWC_PRINTF("ISOC ep 0x%p, ep->queue empty!\n", ep);
+			return;
+		}
+
+		frame_num = dwcep->frame_num + (sync_request -1)*dwcep->bInterval;
+
+		DWC_CIRCLEQ_FOREACH(req, &ep->queue, queue_entry) {
+			i = i+1;
+			frame_num = (frame_num + dwcep->bInterval) & 0x3FFF;
+			/** DMA Descriptor Setup */
+			dma_desc->status.b_iso_in.bs = BS_HOST_BUSY;
+			dma_desc->buf = req->dma;
+			dma_desc->status.b_iso_in.txbytes = req->length;
+			dma_desc->status.b_iso_in.framenum = frame_num;
+			dma_desc->status.b_iso_in.txsts = 0;
+			dma_desc->status.b_iso_in.sp = (req->length % dwcep->maxpacket) ? 1 : 0;
+			dma_desc->status.b_iso_in.ioc = 1;
+			dma_desc->status.b_iso_in.pid = nat + 1;
+			dma_desc->status.b_iso_in.l = 0;
+
+			if (req == DWC_CIRCLEQ_LAST(&ep->queue)) {
+				dma_desc->status.b_iso_in.l = 1;
+			}
+			dma_desc->status.b_iso_in.bs = BS_HOST_READY;
+			DWC_DEBUGPL(DBG_PCD, "ISO_DESC #%d %p status = %08x\n", i, dma_desc, dma_desc->status.d32);
+			if (i == MAX_DMA_DESC_CNT/2 - 1) {
+				dma_desc->status.b_iso_in.l = 1;
+				break;
+			}
+			dma_desc++;
+		}
+		DWC_WRITE_REG32(&core_if->dev_if->in_ep_regs[dwcep->num]->diepdma, dwcep->dma_desc_addr);
+		DWC_DEBUGPL(DBG_PCD, "%d ISOC IN descs were programmed\n", i-1);
+		depctl.d32 = 0;
+		depctl.b.epena = 1;
+		depctl.b.cnak = 1;
+		DWC_MODIFY_REG32(&core_if->dev_if->in_ep_regs[dwcep->num]->diepctl, 0, depctl.d32);
+	} else {
+		DWC_CIRCLEQ_FOREACH(req, &ep->queue, queue_entry) {
+			i = i+1;
+			frame_num = (frame_num + dwcep->bInterval) & 0x3FFF;
+			/** DMA Descriptor Setup */
+			dma_desc->status.b_iso_out.bs = BS_HOST_BUSY;
+			dma_desc->buf = req->dma;
+			dma_desc->status.b_iso_out.rxbytes = req->length;
+			dma_desc->status.b_iso_out.rxsts = 0;
+			dma_desc->status.b_iso_out.sp = (req->length % dwcep->maxpacket) ? 1 : 0;
+			dma_desc->status.b_iso_out.ioc = 1;
+			dma_desc->status.b_iso_out.pid = nat + 1;
+			dma_desc->status.b_iso_out.l = 0;
+
+			if (req == DWC_CIRCLEQ_LAST(&ep->queue)) {
+				dma_desc->status.b_iso_out.l = 1;
+			}
+			dma_desc->status.b_iso_in.bs = BS_HOST_READY;
+			DWC_DEBUGPL(DBG_PCD, "ISO_DESC #%d %p status = %08x\n", i, dma_desc, dma_desc->status.d32);
+			if (i == MAX_DMA_DESC_CNT/2 - 1) {
+				dma_desc->status.b_iso_out.l = 1;
+				break;
+			}
+			dma_desc++;
+		}
+		DWC_WRITE_REG32(&core_if->dev_if->out_ep_regs[dwcep->num]->doepdma, dwcep->dma_desc_addr);
+		DWC_DEBUGPL(DBG_PCD, "%d ISOC OUT descs were programmed\n", i-1);
+		depctl.d32 = 0;
+		depctl.b.epena = 1;
+		depctl.b.cnak = 1;
+		DWC_MODIFY_REG32(&core_if->dev_if->out_ep_regs[dwcep->num]->doepctl, 0, depctl.d32);
+	}
+	dwcep->iso_desc_first = i; //vahrama - pay attention previous one was i-1
+	dwcep->iso_transfer_started = 1;
+	dwcep->frame_num = frame_num;
+	dwcep->use_add_buf = 1;
+}
+/**
+ * Program next ISO request to the DMA chain
+ *
+ */
+static void program_next_iso_request_ddma (dwc_otg_pcd_ep_t * ep, dwc_otg_pcd_request_t * req)
+{
+	dwc_otg_dev_dma_desc_t *dma_desc;
+	dwc_dma_t dma_desc_addr;
+	uint32_t frame_num = 0;
+	uint32_t nat;
+	uint32_t index;
+
+	DWC_DEBUGPL(DBG_PCD, "%s", __FUNCTION__);
+
+	if (ep->dwc_ep.use_add_buf) {
+		index =	ep->dwc_ep.iso_desc_second + 1;
+	} else {
+		index =	ep->dwc_ep.iso_desc_first + 1;
+	}
+
+	if (index > MAX_DMA_DESC_CNT/2) {
+		DWC_PRINTF("There are no free descs in the chain!\n");
+		return;
+	}
+
+	if (ep->dwc_ep.use_add_buf) {
+		dma_desc = &ep->dwc_ep.desc_addr1[ep->dwc_ep.iso_desc_second];
+		dma_desc_addr = ep->dwc_ep.dma_desc_addr1;
+		ep->dwc_ep.iso_desc_second += 1;
+	}  else {
+		dma_desc = &ep->dwc_ep.desc_addr[ep->dwc_ep.iso_desc_first];
+		dma_desc_addr = ep->dwc_ep.dma_desc_addr;
+		ep->dwc_ep.iso_desc_first += 1;
+	}
+	nat = UGETW(ep->desc->wMaxPacketSize);
+	nat = (nat >> 11) & 0x03;
+
+	frame_num = (ep->dwc_ep.frame_num + ep->dwc_ep.bInterval) & 0x3FFF;
+	if (ep->dwc_ep.is_in) {
+		/** DMA Descriptor Setup */
+		dma_desc->status.b_iso_in.bs = BS_HOST_BUSY;
+		dma_desc->buf = req->dma;
+		dma_desc->status.b_iso_in.txbytes = req->length;
+		dma_desc->status.b_iso_in.framenum = frame_num;
+		dma_desc->status.b_iso_in.txsts = 0;
+		dma_desc->status.b_iso_in.sp = (req->length % ep->dwc_ep.maxpacket) ? 1 : 0;
+		dma_desc->status.b_iso_in.ioc = 1;
+		dma_desc->status.b_iso_in.pid = nat + 1;
+		dma_desc->status.b_iso_in.l = 1;
+
+		dma_desc->status.b_iso_in.bs = BS_HOST_READY;
+
+		/* Clear L bit on the previous desc of the chain */
+		if (index > 1) {
+			dma_desc--;
+			dma_desc->status.b_iso_in.l = 0;
+		}
+	}  else {
+		/** DMA Descriptor Setup */
+		dma_desc->status.b_iso_out.bs = BS_HOST_BUSY;
+		dma_desc->buf = req->dma;
+		dma_desc->status.b_iso_out.rxbytes = req->length;
+		dma_desc->status.b_iso_out.rxsts = 0;
+		dma_desc->status.b_iso_out.sp = (req->length % ep->dwc_ep.maxpacket) ? 1 : 0;
+		dma_desc->status.b_iso_out.ioc = 1;
+		dma_desc->status.b_iso_out.pid = nat + 1;
+		dma_desc->status.b_iso_out.l = 1;
+
+		dma_desc->status.b_iso_out.bs = BS_HOST_READY;
+
+		/* Clear L bit on the previous desc of the chain */
+		if (index > 1) {
+			dma_desc--;
+			dma_desc->status.b_iso_out.l = 0;
+		}
+	}
+	ep->dwc_ep.frame_num = frame_num;
+
+}
+
+/******************************************************************************/
+#ifdef DWC_UTE_PER_IO
+
+/**
+ * Free the request and its extended parts
+ *
+ */
+void dwc_pcd_xiso_ereq_free(dwc_otg_pcd_ep_t * ep, dwc_otg_pcd_request_t * req)
+{
+	DWC_FREE(req->ext_req.per_io_frame_descs);
+	DWC_FREE(req);
+}
+
+/**
+ * Start the next request in the endpoint's queue.
+ *
+ */
+int dwc_otg_pcd_xiso_start_next_request(dwc_otg_pcd_t * pcd,
+					dwc_otg_pcd_ep_t * ep)
+{
+	int i;
+	dwc_otg_pcd_request_t *req = NULL;
+	dwc_ep_t *dwcep = NULL;
+	struct dwc_iso_xreq_port *ereq = NULL;
+	struct dwc_iso_pkt_desc_port *ddesc_iso;
+	uint16_t nat;
+	depctl_data_t diepctl;
+
+	dwcep = &ep->dwc_ep;
+
+	if (dwcep->xiso_active_xfers > 0)
+		return 0;
+
+	nat = UGETW(ep->desc->wMaxPacketSize);
+	nat = (nat >> 11) & 0x03;
+
+	if (!DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+		req = DWC_CIRCLEQ_FIRST(&ep->queue);
+		ereq = &req->ext_req;
+		ep->stopped = 0;
+
+		/* Get the frame number */
+		dwcep->xiso_frame_num =
+		    dwc_otg_get_frame_number(GET_CORE_IF(pcd));
+		DWC_DEBUG("FRM_NUM=%d", dwcep->xiso_frame_num);
+
+		ddesc_iso = ereq->per_io_frame_descs;
+
+		if (dwcep->is_in) {
+			/* Setup DMA Descriptor chain for IN Isoc request */
+			for (i = 0; i < ereq->pio_pkt_count; i++) {
+				//if ((i % (nat + 1)) == 0)
+				if (i > 0)
+					dwcep->xiso_frame_num =
+					    (dwcep->xiso_bInterval +
+					     dwcep->xiso_frame_num) & 0x3FFF;
+				dwcep->desc_addr[i].buf =
+				    req->dma + ddesc_iso[i].offset;
+				dwcep->desc_addr[i].status.b_iso_in.txbytes =
+				    ddesc_iso[i].length;
+				dwcep->desc_addr[i].status.b_iso_in.framenum =
+				    dwcep->xiso_frame_num;
+				dwcep->desc_addr[i].status.b_iso_in.bs =
+				    BS_HOST_READY;
+				dwcep->desc_addr[i].status.b_iso_in.txsts = 0;
+				dwcep->desc_addr[i].status.b_iso_in.sp =
+				    (ddesc_iso[i].length %
+				     dwcep->maxpacket) ? 1 : 0;
+				dwcep->desc_addr[i].status.b_iso_in.ioc = 0;
+				dwcep->desc_addr[i].status.b_iso_in.pid = nat + 1;
+				dwcep->desc_addr[i].status.b_iso_in.l = 0;
+
+				/* Process the last descriptor */
+				if (i == ereq->pio_pkt_count - 1) {
+					dwcep->desc_addr[i].status.b_iso_in.ioc = 1;
+					dwcep->desc_addr[i].status.b_iso_in.l = 1;
+				}
+			}
+
+			/* Setup and start the transfer for this endpoint */
+			dwcep->xiso_active_xfers++;
+			DWC_WRITE_REG32(&GET_CORE_IF(pcd)->dev_if->
+					in_ep_regs[dwcep->num]->diepdma,
+					dwcep->dma_desc_addr);
+			diepctl.d32 = 0;
+			diepctl.b.epena = 1;
+			diepctl.b.cnak = 1;
+			DWC_MODIFY_REG32(&GET_CORE_IF(pcd)->dev_if->
+					 in_ep_regs[dwcep->num]->diepctl, 0,
+					 diepctl.d32);
+		} else {
+			/* Setup DMA Descriptor chain for OUT Isoc request */
+			for (i = 0; i < ereq->pio_pkt_count; i++) {
+				//if ((i % (nat + 1)) == 0)
+				dwcep->xiso_frame_num = (dwcep->xiso_bInterval +
+										dwcep->xiso_frame_num) & 0x3FFF;
+				dwcep->desc_addr[i].buf =
+				    req->dma + ddesc_iso[i].offset;
+				dwcep->desc_addr[i].status.b_iso_out.rxbytes =
+				    ddesc_iso[i].length;
+				dwcep->desc_addr[i].status.b_iso_out.framenum =
+				    dwcep->xiso_frame_num;
+				dwcep->desc_addr[i].status.b_iso_out.bs =
+				    BS_HOST_READY;
+				dwcep->desc_addr[i].status.b_iso_out.rxsts = 0;
+				dwcep->desc_addr[i].status.b_iso_out.sp =
+				    (ddesc_iso[i].length %
+				     dwcep->maxpacket) ? 1 : 0;
+				dwcep->desc_addr[i].status.b_iso_out.ioc = 0;
+				dwcep->desc_addr[i].status.b_iso_out.pid = nat + 1;
+				dwcep->desc_addr[i].status.b_iso_out.l = 0;
+
+				/* Process the last descriptor */
+				if (i == ereq->pio_pkt_count - 1) {
+					dwcep->desc_addr[i].status.b_iso_out.ioc = 1;
+					dwcep->desc_addr[i].status.b_iso_out.l = 1;
+				}
+			}
+
+			/* Setup and start the transfer for this endpoint */
+			dwcep->xiso_active_xfers++;
+			DWC_WRITE_REG32(&GET_CORE_IF(pcd)->
+					dev_if->out_ep_regs[dwcep->num]->
+					doepdma, dwcep->dma_desc_addr);
+			diepctl.d32 = 0;
+			diepctl.b.epena = 1;
+			diepctl.b.cnak = 1;
+			DWC_MODIFY_REG32(&GET_CORE_IF(pcd)->
+					 dev_if->out_ep_regs[dwcep->num]->
+					 doepctl, 0, diepctl.d32);
+		}
+
+	} else {
+		ep->stopped = 1;
+	}
+
+	return 0;
+}
+
+/**
+ *	- Remove the request from the queue
+ */
+void complete_xiso_ep(dwc_otg_pcd_ep_t * ep)
+{
+	dwc_otg_pcd_request_t *req = NULL;
+	struct dwc_iso_xreq_port *ereq = NULL;
+	struct dwc_iso_pkt_desc_port *ddesc_iso = NULL;
+	dwc_ep_t *dwcep = NULL;
+	int i;
+
+	//DWC_DEBUG();
+	dwcep = &ep->dwc_ep;
+
+	/* Get the first pending request from the queue */
+	if (!DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+		req = DWC_CIRCLEQ_FIRST(&ep->queue);
+		if (!req) {
+			DWC_PRINTF("complete_ep 0x%p, req = NULL!\n", ep);
+			return;
+		}
+		dwcep->xiso_active_xfers--;
+		dwcep->xiso_queued_xfers--;
+		/* Remove this request from the queue */
+		DWC_CIRCLEQ_REMOVE_INIT(&ep->queue, req, queue_entry);
+	} else {
+		DWC_PRINTF("complete_ep 0x%p, ep->queue empty!\n", ep);
+		return;
+	}
+
+	ep->stopped = 1;
+	ereq = &req->ext_req;
+	ddesc_iso = ereq->per_io_frame_descs;
+
+	if (dwcep->xiso_active_xfers < 0) {
+		DWC_WARN("EP#%d (xiso_active_xfers=%d)", dwcep->num,
+			 dwcep->xiso_active_xfers);
+	}
+
+	/* Fill the Isoc descs of portable extended req from dma descriptors */
+	for (i = 0; i < ereq->pio_pkt_count; i++) {
+		if (dwcep->is_in) {	/* IN endpoints */
+			ddesc_iso[i].actual_length = ddesc_iso[i].length -
+			    dwcep->desc_addr[i].status.b_iso_in.txbytes;
+			ddesc_iso[i].status =
+			    dwcep->desc_addr[i].status.b_iso_in.txsts;
+		} else {	/* OUT endpoints */
+			ddesc_iso[i].actual_length = ddesc_iso[i].length -
+			    dwcep->desc_addr[i].status.b_iso_out.rxbytes;
+			ddesc_iso[i].status =
+			    dwcep->desc_addr[i].status.b_iso_out.rxsts;
+		}
+	}
+
+	DWC_SPINUNLOCK(ep->pcd->lock);
+
+	/* Call the completion function in the non-portable logic */
+	ep->pcd->fops->xisoc_complete(ep->pcd, ep->priv, req->priv, 0,
+				      &req->ext_req);
+
+	DWC_SPINLOCK(ep->pcd->lock);
+
+	/* Free the request - specific freeing needed for extended request object */
+	dwc_pcd_xiso_ereq_free(ep, req);
+
+	/* Start the next request */
+	dwc_otg_pcd_xiso_start_next_request(ep->pcd, ep);
+
+	return;
+}
+
+/**
+ * Create and initialize the Isoc pkt descriptors of the extended request.
+ *
+ */
+static int dwc_otg_pcd_xiso_create_pkt_descs(dwc_otg_pcd_request_t * req,
+					     void *ereq_nonport,
+					     int atomic_alloc)
+{
+	struct dwc_iso_xreq_port *ereq = NULL;
+	struct dwc_iso_xreq_port *req_mapped = NULL;
+	struct dwc_iso_pkt_desc_port *ipds = NULL;	/* To be created in this function */
+	uint32_t pkt_count;
+	int i;
+
+	ereq = &req->ext_req;
+	req_mapped = (struct dwc_iso_xreq_port *)ereq_nonport;
+	pkt_count = req_mapped->pio_pkt_count;
+
+	/* Create the isoc descs */
+	if (atomic_alloc) {
+		ipds = DWC_ALLOC_ATOMIC(sizeof(*ipds) * pkt_count);
+	} else {
+		ipds = DWC_ALLOC(sizeof(*ipds) * pkt_count);
+	}
+
+	if (!ipds) {
+		DWC_ERROR("Failed to allocate isoc descriptors");
+		return -DWC_E_NO_MEMORY;
+	}
+
+	/* Initialize the extended request fields */
+	ereq->per_io_frame_descs = ipds;
+	ereq->error_count = 0;
+	ereq->pio_alloc_pkt_count = pkt_count;
+	ereq->pio_pkt_count = pkt_count;
+	ereq->tr_sub_flags = req_mapped->tr_sub_flags;
+
+	/* Init the Isoc descriptors */
+	for (i = 0; i < pkt_count; i++) {
+		ipds[i].length = req_mapped->per_io_frame_descs[i].length;
+		ipds[i].offset = req_mapped->per_io_frame_descs[i].offset;
+		ipds[i].status = req_mapped->per_io_frame_descs[i].status;	/* 0 */
+		ipds[i].actual_length =
+		    req_mapped->per_io_frame_descs[i].actual_length;
+	}
+
+	return 0;
+}
+
+static void prn_ext_request(struct dwc_iso_xreq_port *ereq)
+{
+	struct dwc_iso_pkt_desc_port *xfd = NULL;
+	int i;
+
+	DWC_DEBUG("per_io_frame_descs=%p", ereq->per_io_frame_descs);
+	DWC_DEBUG("tr_sub_flags=%d", ereq->tr_sub_flags);
+	DWC_DEBUG("error_count=%d", ereq->error_count);
+	DWC_DEBUG("pio_alloc_pkt_count=%d", ereq->pio_alloc_pkt_count);
+	DWC_DEBUG("pio_pkt_count=%d", ereq->pio_pkt_count);
+	DWC_DEBUG("res=%d", ereq->res);
+
+	for (i = 0; i < ereq->pio_pkt_count; i++) {
+		xfd = &ereq->per_io_frame_descs[0];
+		DWC_DEBUG("FD #%d", i);
+
+		DWC_DEBUG("xfd->actual_length=%d", xfd->actual_length);
+		DWC_DEBUG("xfd->length=%d", xfd->length);
+		DWC_DEBUG("xfd->offset=%d", xfd->offset);
+		DWC_DEBUG("xfd->status=%d", xfd->status);
+	}
+}
+
+/**
+ *
+ */
+int dwc_otg_pcd_xiso_ep_queue(dwc_otg_pcd_t * pcd, void *ep_handle,
+			      uint8_t * buf, dwc_dma_t dma_buf, uint32_t buflen,
+			      int zero, void *req_handle, int atomic_alloc,
+			      void *ereq_nonport)
+{
+	dwc_otg_pcd_request_t *req = NULL;
+	dwc_otg_pcd_ep_t *ep;
+	dwc_irqflags_t flags;
+	int res;
+
+	ep = get_ep_from_handle(pcd, ep_handle);
+	if (!ep) {
+		DWC_WARN("bad ep\n");
+		return -DWC_E_INVALID;
+	}
+
+	/* We support this extension only for DDMA mode */
+	if (ep->dwc_ep.type == DWC_OTG_EP_TYPE_ISOC)
+		if (!GET_CORE_IF(pcd)->dma_desc_enable)
+			return -DWC_E_INVALID;
+
+	/* Create a dwc_otg_pcd_request_t object */
+	if (atomic_alloc) {
+		req = DWC_ALLOC_ATOMIC(sizeof(*req));
+	} else {
+		req = DWC_ALLOC(sizeof(*req));
+	}
+
+	if (!req) {
+		return -DWC_E_NO_MEMORY;
+	}
+
+	/* Create the Isoc descs for this request which shall be the exact match
+	 * of the structure sent to us from the non-portable logic */
+	res =
+	    dwc_otg_pcd_xiso_create_pkt_descs(req, ereq_nonport, atomic_alloc);
+	if (res) {
+		DWC_WARN("Failed to init the Isoc descriptors");
+		DWC_FREE(req);
+		return res;
+	}
+
+	DWC_SPINLOCK_IRQSAVE(pcd->lock, &flags);
+
+	DWC_CIRCLEQ_INIT_ENTRY(req, queue_entry);
+	req->buf = buf;
+	req->dma = dma_buf;
+	req->length = buflen;
+	req->sent_zlp = zero;
+	req->priv = req_handle;
+
+	//DWC_SPINLOCK_IRQSAVE(pcd->lock, &flags);
+	ep->dwc_ep.dma_addr = dma_buf;
+	ep->dwc_ep.start_xfer_buff = buf;
+	ep->dwc_ep.xfer_buff = buf;
+	ep->dwc_ep.xfer_len = 0;
+	ep->dwc_ep.xfer_count = 0;
+	ep->dwc_ep.sent_zlp = 0;
+	ep->dwc_ep.total_len = buflen;
+
+	/* Add this request to the tail */
+	DWC_CIRCLEQ_INSERT_TAIL(&ep->queue, req, queue_entry);
+	ep->dwc_ep.xiso_queued_xfers++;
+
+//DWC_DEBUG("CP_0");
+//DWC_DEBUG("req->ext_req.tr_sub_flags=%d", req->ext_req.tr_sub_flags);
+//prn_ext_request((struct dwc_iso_xreq_port *) ereq_nonport);
+//prn_ext_request(&req->ext_req);
+
+	//DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+
+	/* If the req->status == ASAP  then check if there is any active transfer
+	 * for this endpoint. If no active transfers, then get the first entry
+	 * from the queue and start that transfer
+	 */
+	if (req->ext_req.tr_sub_flags == DWC_EREQ_TF_ASAP) {
+		res = dwc_otg_pcd_xiso_start_next_request(pcd, ep);
+		if (res) {
+			DWC_WARN("Failed to start the next Isoc transfer");
+			DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+			DWC_FREE(req);
+			return res;
+		}
+	}
+
+	DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+	return 0;
+}
+
+#endif
+/* END ifdef DWC_UTE_PER_IO ***************************************************/
+int dwc_otg_pcd_ep_queue(dwc_otg_pcd_t * pcd, void *ep_handle,
+			 uint8_t * buf, dwc_dma_t dma_buf, uint32_t buflen,
+			 int zero, void *req_handle, int atomic_alloc)
+{
+	dwc_irqflags_t flags;
+	dwc_otg_pcd_request_t *req;
+	dwc_otg_pcd_ep_t *ep;
+	uint32_t max_transfer;
+
+	ep = get_ep_from_handle(pcd, ep_handle);
+	if (!ep || (!ep->desc && ep->dwc_ep.num != 0)) {
+		DWC_WARN("bad ep\n");
+		return -DWC_E_INVALID;
+	}
+
+	if (atomic_alloc) {
+		req = DWC_ALLOC_ATOMIC(sizeof(*req));
+	} else {
+		req = DWC_ALLOC(sizeof(*req));
+	}
+
+	if (!req) {
+		return -DWC_E_NO_MEMORY;
+	}
+	DWC_CIRCLEQ_INIT_ENTRY(req, queue_entry);
+	if (!GET_CORE_IF(pcd)->core_params->opt) {
+		if (ep->dwc_ep.num != 0) {
+			DWC_ERROR("queue req %p, len %d buf %p\n",
+				  req_handle, buflen, buf);
+		}
+	}
+
+	req->buf = buf;
+	req->dma = dma_buf;
+	req->length = buflen;
+	req->sent_zlp = zero;
+	req->priv = req_handle;
+	req->dw_align_buf = NULL;
+	if ((dma_buf & 0x3) && GET_CORE_IF(pcd)->dma_enable
+	    && !GET_CORE_IF(pcd)->dma_desc_enable)
+		req->dw_align_buf = DWC_DMA_ALLOC(buflen,
+						  &req->dw_align_buf_dma);
+	DWC_SPINLOCK_IRQSAVE(pcd->lock, &flags);
+
+	/*
+	 * After adding request to the queue for IN ISOC wait for In Token Received
+	 * when TX FIFO is empty interrupt and for OUT ISOC wait for OUT Token
+	 * Received when EP is disabled interrupt to obtain starting microframe
+	 * (odd/even) start transfer
+	 */
+	if (ep->dwc_ep.type == DWC_OTG_EP_TYPE_ISOC) {
+		if (req != 0) {
+			depctl_data_t depctl = {.d32 =
+				    DWC_READ_REG32(&pcd->core_if->dev_if->
+						   in_ep_regs[ep->dwc_ep.num]->
+						   diepctl) };
+			++pcd->request_pending;
+
+			DWC_CIRCLEQ_INSERT_TAIL(&ep->queue, req, queue_entry);
+			if (ep->dwc_ep.is_in) {
+				depctl.b.cnak = 1;
+				DWC_WRITE_REG32(&pcd->core_if->dev_if->
+						in_ep_regs[ep->dwc_ep.num]->
+						diepctl, depctl.d32);
+			}
+			if (GET_CORE_IF(pcd)->dma_desc_enable) {
+				if (ep->dwc_ep.iso_transfer_started) {
+					/*
+					 * Add next request to the descriptor chain
+					 * currently not in use by HW
+					 */
+					program_next_iso_request_ddma(ep, req);
+				} else if (!ep->dwc_ep.is_in)
+					/* For OUT start first request immediately after queue */
+					dwc_otg_pcd_start_iso_ddma(GET_CORE_IF(pcd), ep);
+			}
+
+			DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+		}
+		return 0;
+	}
+
+	/*
+	 * For EP0 IN without premature status, zlp is required?
+	 */
+	if (ep->dwc_ep.num == 0 && ep->dwc_ep.is_in) {
+		DWC_DEBUGPL(DBG_PCDV, "%d-OUT ZLP\n", ep->dwc_ep.num);
+		//_req->zero = 1;
+	}
+
+	/* Start the transfer */
+	if (DWC_CIRCLEQ_EMPTY(&ep->queue) && !ep->stopped) {
+		/* EP0 Transfer? */
+		if (ep->dwc_ep.num == 0) {
+			switch (pcd->ep0state) {
+			case EP0_IN_DATA_PHASE:
+				DWC_DEBUGPL(DBG_PCD,
+					    "%s ep0: EP0_IN_DATA_PHASE\n",
+					    __func__);
+				break;
+
+			case EP0_OUT_DATA_PHASE:
+				DWC_DEBUGPL(DBG_PCD,
+					    "%s ep0: EP0_OUT_DATA_PHASE\n",
+					    __func__);
+				if (pcd->request_config) {
+					/* Complete STATUS PHASE */
+					ep->dwc_ep.is_in = 1;
+					pcd->ep0state = EP0_IN_STATUS_PHASE;
+				}
+				break;
+
+			case EP0_IN_STATUS_PHASE:
+				DWC_DEBUGPL(DBG_PCD,
+					    "%s ep0: EP0_IN_STATUS_PHASE\n",
+					    __func__);
+				break;
+
+			default:
+				DWC_DEBUGPL(DBG_ANY, "ep0: odd state %d\n",
+					    pcd->ep0state);
+				DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+				return -DWC_E_SHUTDOWN;
+			}
+
+			ep->dwc_ep.dma_addr = dma_buf;
+			ep->dwc_ep.start_xfer_buff = buf;
+			ep->dwc_ep.xfer_buff = buf;
+			ep->dwc_ep.xfer_len = buflen;
+			ep->dwc_ep.xfer_count = 0;
+			ep->dwc_ep.sent_zlp = 0;
+			ep->dwc_ep.total_len = ep->dwc_ep.xfer_len;
+
+			if (zero) {
+				if ((ep->dwc_ep.xfer_len %
+				     ep->dwc_ep.maxpacket == 0)
+				    && (ep->dwc_ep.xfer_len != 0)) {
+					ep->dwc_ep.sent_zlp = 1;
+				}
+
+			}
+
+			dwc_otg_ep0_start_transfer(GET_CORE_IF(pcd),
+						   &ep->dwc_ep);
+		}		// non-ep0 endpoints
+		else {
+#ifdef DWC_UTE_CFI
+			if (ep->dwc_ep.buff_mode != BM_STANDARD) {
+				/* store the request length */
+				ep->dwc_ep.cfi_req_len = buflen;
+				pcd->cfi->ops.build_descriptors(pcd->cfi, pcd,
+								ep, req);
+			} else {
+#endif
+				max_transfer =
+				    GET_CORE_IF(ep->pcd)->core_params->
+				    max_transfer_size;
+
+				/* Setup and start the Transfer */
+				if (req->dw_align_buf) {
+					if (ep->dwc_ep.is_in)
+						dwc_memcpy(req->dw_align_buf,
+							   buf, buflen);
+					ep->dwc_ep.dma_addr =
+					    req->dw_align_buf_dma;
+					ep->dwc_ep.start_xfer_buff =
+					    req->dw_align_buf;
+					ep->dwc_ep.xfer_buff =
+					    req->dw_align_buf;
+				} else {
+					ep->dwc_ep.dma_addr = dma_buf;
+					ep->dwc_ep.start_xfer_buff = buf;
+					ep->dwc_ep.xfer_buff = buf;
+				}
+				ep->dwc_ep.xfer_len = 0;
+				ep->dwc_ep.xfer_count = 0;
+				ep->dwc_ep.sent_zlp = 0;
+				ep->dwc_ep.total_len = buflen;
+
+				ep->dwc_ep.maxxfer = max_transfer;
+				if (GET_CORE_IF(pcd)->dma_desc_enable) {
+					uint32_t out_max_xfer =
+					    DDMA_MAX_TRANSFER_SIZE -
+					    (DDMA_MAX_TRANSFER_SIZE % 4);
+					if (ep->dwc_ep.is_in) {
+						if (ep->dwc_ep.maxxfer >
+						    DDMA_MAX_TRANSFER_SIZE) {
+							ep->dwc_ep.maxxfer =
+							    DDMA_MAX_TRANSFER_SIZE;
+						}
+					} else {
+						if (ep->dwc_ep.maxxfer >
+						    out_max_xfer) {
+							ep->dwc_ep.maxxfer =
+							    out_max_xfer;
+						}
+					}
+				}
+				if (ep->dwc_ep.maxxfer < ep->dwc_ep.total_len) {
+					ep->dwc_ep.maxxfer -=
+					    (ep->dwc_ep.maxxfer %
+					     ep->dwc_ep.maxpacket);
+				}
+
+				if (zero) {
+					if ((ep->dwc_ep.total_len %
+					     ep->dwc_ep.maxpacket == 0)
+					    && (ep->dwc_ep.total_len != 0)) {
+						ep->dwc_ep.sent_zlp = 1;
+					}
+				}
+#ifdef DWC_UTE_CFI
+			}
+#endif
+			dwc_otg_ep_start_transfer(GET_CORE_IF(pcd),
+						  &ep->dwc_ep);
+		}
+	}
+
+	if (req != 0) {
+		++pcd->request_pending;
+		DWC_CIRCLEQ_INSERT_TAIL(&ep->queue, req, queue_entry);
+		if (ep->dwc_ep.is_in && ep->stopped
+		    && !(GET_CORE_IF(pcd)->dma_enable)) {
+			/** @todo NGS Create a function for this. */
+			diepmsk_data_t diepmsk = {.d32 = 0 };
+			diepmsk.b.intktxfemp = 1;
+			if (GET_CORE_IF(pcd)->multiproc_int_enable) {
+				DWC_MODIFY_REG32(&GET_CORE_IF(pcd)->
+						 dev_if->dev_global_regs->diepeachintmsk
+						 [ep->dwc_ep.num], 0,
+						 diepmsk.d32);
+			} else {
+				DWC_MODIFY_REG32(&GET_CORE_IF(pcd)->
+						 dev_if->dev_global_regs->
+						 diepmsk, 0, diepmsk.d32);
+			}
+
+		}
+	}
+	DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+
+	return 0;
+}
+
+int dwc_otg_pcd_ep_dequeue(dwc_otg_pcd_t * pcd, void *ep_handle,
+			   void *req_handle)
+{
+	dwc_irqflags_t flags;
+	dwc_otg_pcd_request_t *req;
+	dwc_otg_pcd_ep_t *ep;
+
+	ep = get_ep_from_handle(pcd, ep_handle);
+	if (!ep || (!ep->desc && ep->dwc_ep.num != 0)) {
+		DWC_WARN("bad argument\n");
+		return -DWC_E_INVALID;
+	}
+
+	DWC_SPINLOCK_IRQSAVE(pcd->lock, &flags);
+
+	/* make sure it's actually queued on this endpoint */
+	DWC_CIRCLEQ_FOREACH(req, &ep->queue, queue_entry) {
+		if (req->priv == (void *)req_handle) {
+			break;
+		}
+	}
+
+	if (req->priv != (void *)req_handle) {
+		DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+		return -DWC_E_INVALID;
+	}
+
+	if (!DWC_CIRCLEQ_EMPTY_ENTRY(req, queue_entry)) {
+		if(( ep != &pcd->ep0)&&(!ep->dwc_ep.is_in)) {
+			ep->dwc_ep.xfer_buff =NULL;
+		}
+		dwc_otg_request_done(ep, req, -DWC_E_RESTART);
+	} else {
+		req = NULL;
+	}
+
+	DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+
+	return req ? 0 : -DWC_E_SHUTDOWN;
+
+}
+
+int dwc_otg_pcd_ep_halt(dwc_otg_pcd_t * pcd, void *ep_handle, int value)
+{
+	dwc_otg_pcd_ep_t *ep;
+	dwc_irqflags_t flags;
+	int retval = 0;
+
+	ep = get_ep_from_handle(pcd, ep_handle);
+
+	if (!ep || (!ep->desc && ep != &pcd->ep0) ||
+	    (ep->desc && (ep->desc->bmAttributes == UE_ISOCHRONOUS))) {
+		DWC_WARN("%s, bad ep\n", __func__);
+		return -DWC_E_INVALID;
+	}
+
+	DWC_SPINLOCK_IRQSAVE(pcd->lock, &flags);
+	if (!DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+		DWC_WARN("%d %s XFer In process\n", ep->dwc_ep.num,
+			 ep->dwc_ep.is_in ? "IN" : "OUT");
+		retval = -DWC_E_AGAIN;
+	} else if (value == 0) {
+	    ep->dwc_ep.stall_clear_flag = 0;
+		dwc_otg_ep_clear_stall(GET_CORE_IF(pcd), &ep->dwc_ep);
+	} else if (value == 1) {
+	stall:
+		if (ep->dwc_ep.is_in == 1 && GET_CORE_IF(pcd)->dma_desc_enable) {
+			dtxfsts_data_t txstatus;
+			fifosize_data_t txfifosize;
+
+			txfifosize.d32 =
+			    DWC_READ_REG32(&GET_CORE_IF(pcd)->
+					   core_global_regs->dtxfsiz[ep->dwc_ep.
+								     tx_fifo_num]);
+			txstatus.d32 =
+			    DWC_READ_REG32(&GET_CORE_IF(pcd)->
+					   dev_if->in_ep_regs[ep->dwc_ep.num]->
+					   dtxfsts);
+
+			if (txstatus.b.txfspcavail < txfifosize.b.depth) {
+				DWC_WARN("%s() Data In Tx Fifo\n", __func__);
+				retval = -DWC_E_AGAIN;
+			} else {
+				if (ep->dwc_ep.num == 0) {
+					pcd->ep0state = EP0_STALL;
+				}
+
+				ep->stopped = 1;
+				dwc_otg_ep_set_stall(GET_CORE_IF(pcd),
+						     &ep->dwc_ep);
+			}
+		} else {
+			if (ep->dwc_ep.num == 0) {
+				pcd->ep0state = EP0_STALL;
+			}
+
+			ep->stopped = 1;
+			dwc_otg_ep_set_stall(GET_CORE_IF(pcd), &ep->dwc_ep);
+		}
+	} else if (value == 2) {
+		ep->dwc_ep.stall_clear_flag = 0;
+	} else if (value == 3) {
+		ep->dwc_ep.stall_clear_flag = 1;
+		goto stall;
+	}
+
+	DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+
+	return retval;
+}
+
+/**
+ * This function initiates remote wakeup of the host from suspend state.
+ */
+void dwc_otg_pcd_rem_wkup_from_suspend(dwc_otg_pcd_t * pcd, int set)
+{
+	dctl_data_t dctl = { 0 };
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dsts_data_t dsts;
+
+	dsts.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dsts);
+	if (!dsts.b.suspsts) {
+		DWC_WARN("Remote wakeup while is not in suspend state\n");
+	}
+	/* Check if DEVICE_REMOTE_WAKEUP feature enabled */
+	if (pcd->remote_wakeup_enable) {
+		if (set) {
+
+			if (core_if->adp_enable) {
+				gpwrdn_data_t gpwrdn;
+
+				dwc_otg_adp_probe_stop(core_if);
+
+				/* Mask SRP detected interrupt from Power Down Logic */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.srp_det_msk = 1;
+				DWC_MODIFY_REG32(&core_if->
+						 core_global_regs->gpwrdn,
+						 gpwrdn.d32, 0);
+
+				/* Disable Power Down Logic */
+				gpwrdn.d32 = 0;
+				gpwrdn.b.pmuactv = 1;
+				DWC_MODIFY_REG32(&core_if->
+						 core_global_regs->gpwrdn,
+						 gpwrdn.d32, 0);
+
+				/*
+				 * Initialize the Core for Device mode.
+				 */
+				core_if->op_state = B_PERIPHERAL;
+				dwc_otg_core_init(core_if);
+				dwc_otg_enable_global_interrupts(core_if);
+				cil_pcd_start(core_if);
+
+				dwc_otg_initiate_srp(core_if);
+			}
+
+			dctl.b.rmtwkupsig = 1;
+			DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->
+					 dctl, 0, dctl.d32);
+			DWC_DEBUGPL(DBG_PCD, "Set Remote Wakeup\n");
+
+			dwc_mdelay(2);
+			DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->
+					 dctl, dctl.d32, 0);
+			DWC_DEBUGPL(DBG_PCD, "Clear Remote Wakeup\n");
+		}
+	} else {
+		DWC_DEBUGPL(DBG_PCD, "Remote Wakeup is disabled\n");
+	}
+}
+
+#ifdef CONFIG_USB_DWC_OTG_LPM
+/**
+ * This function initiates remote wakeup of the host from L1 sleep state.
+ */
+void dwc_otg_pcd_rem_wkup_from_sleep(dwc_otg_pcd_t * pcd, int set)
+{
+	glpmcfg_data_t lpmcfg;
+	pcgcctl_data_t pcgcctl = {.d32 = 0 };
+
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+
+	/* Check if we are in L1 state */
+	if (!lpmcfg.b.prt_sleep_sts) {
+		DWC_DEBUGPL(DBG_PCD, "Device is not in sleep state\n");
+		return;
+	}
+
+	/* Check if host allows remote wakeup */
+	if (!lpmcfg.b.rem_wkup_en) {
+		DWC_DEBUGPL(DBG_PCD, "Host does not allow remote wakeup\n");
+		return;
+	}
+
+	/* Check if Resume OK */
+	if (!lpmcfg.b.sleep_state_resumeok) {
+		DWC_DEBUGPL(DBG_PCD, "Sleep state resume is not OK\n");
+		return;
+	}
+
+	lpmcfg.d32 = DWC_READ_REG32(&core_if->core_global_regs->glpmcfg);
+	lpmcfg.b.en_utmi_sleep = 0;
+	lpmcfg.b.hird_thres &= (~(1 << 4));
+
+	/* Clear Enbl_L1Gating bit. */
+	pcgcctl.b.enbl_sleep_gating = 1;
+	DWC_MODIFY_REG32(core_if->pcgcctl, pcgcctl.d32,0);
+
+	DWC_WRITE_REG32(&core_if->core_global_regs->glpmcfg, lpmcfg.d32);
+
+	if (set) {
+		dctl_data_t dctl = {.d32 = 0 };
+		dctl.b.rmtwkupsig = 1;
+		/* Set RmtWkUpSig bit to start remote wakup signaling.
+		 * Hardware will automatically clear this bit.
+		 */
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl,
+				 0, dctl.d32);
+		DWC_DEBUGPL(DBG_PCD, "Set Remote Wakeup\n");
+	}
+
+}
+#endif
+
+/**
+ * Performs remote wakeup.
+ */
+void dwc_otg_pcd_remote_wakeup(dwc_otg_pcd_t * pcd, int set)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_irqflags_t flags;
+	if (dwc_otg_is_device_mode(core_if)) {
+		DWC_SPINLOCK_IRQSAVE(pcd->lock, &flags);
+#ifdef CONFIG_USB_DWC_OTG_LPM
+		if (core_if->lx_state == DWC_OTG_L1) {
+			dwc_otg_pcd_rem_wkup_from_sleep(pcd, set);
+		} else {
+#endif
+			dwc_otg_pcd_rem_wkup_from_suspend(pcd, set);
+#ifdef CONFIG_USB_DWC_OTG_LPM
+		}
+#endif
+		DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+	}
+	return;
+}
+
+void dwc_otg_pcd_disconnect_us(dwc_otg_pcd_t * pcd, int no_of_usecs)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dctl_data_t dctl = { 0 };
+
+	if (dwc_otg_is_device_mode(core_if)) {
+		dctl.b.sftdiscon = 1;
+		DWC_PRINTF("Soft disconnect for %d useconds\n",no_of_usecs);
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl, 0, dctl.d32);
+		dwc_udelay(no_of_usecs);
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl, dctl.d32,0);
+
+	} else{
+		DWC_PRINTF("NOT SUPPORTED IN HOST MODE\n");
+	}
+	return;
+
+}
+
+int dwc_otg_pcd_wakeup(dwc_otg_pcd_t * pcd)
+{
+	dsts_data_t dsts;
+	gotgctl_data_t gotgctl;
+
+	/*
+	 * This function starts the Protocol if no session is in progress. If
+	 * a session is already in progress, but the device is suspended,
+	 * remote wakeup signaling is started.
+	 */
+
+	/* Check if valid session */
+	gotgctl.d32 =
+	    DWC_READ_REG32(&(GET_CORE_IF(pcd)->core_global_regs->gotgctl));
+	if (gotgctl.b.bsesvld) {
+		/* Check if suspend state */
+		dsts.d32 =
+		    DWC_READ_REG32(&
+				   (GET_CORE_IF(pcd)->dev_if->
+				    dev_global_regs->dsts));
+		if (dsts.b.suspsts) {
+			dwc_otg_pcd_remote_wakeup(pcd, 1);
+		}
+	} else {
+		dwc_otg_pcd_initiate_srp(pcd);
+	}
+
+	return 0;
+
+}
+
+void dwc_otg_pcd_pullup(dwc_otg_pcd_t *pcd)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	depctl_data_t depctl;
+
+	depctl.d32 = 0; 
+	depctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[bulk_num]->diepctl);
+
+	depctl.b.setd1pid = 0; 
+	depctl.b.setd0pid = 1; 
+	DWC_WRITE_REG32(&dev_if->in_ep_regs[bulk_num]->diepctl, depctl.d32);
+	depctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[3]->diepctl);
+}
+
+/**
+ * Start the SRP timer to detect when the SRP does not complete within
+ * 6 seconds.
+ *
+ * @param pcd the pcd structure.
+ */
+void dwc_otg_pcd_initiate_srp(dwc_otg_pcd_t * pcd)
+{
+	dwc_irqflags_t flags;
+	DWC_SPINLOCK_IRQSAVE(pcd->lock, &flags);
+	dwc_otg_initiate_srp(GET_CORE_IF(pcd));
+	DWC_SPINUNLOCK_IRQRESTORE(pcd->lock, flags);
+}
+
+int dwc_otg_pcd_get_frame_number(dwc_otg_pcd_t * pcd)
+{
+	return dwc_otg_get_frame_number(GET_CORE_IF(pcd));
+}
+
+int dwc_otg_pcd_is_lpm_enabled(dwc_otg_pcd_t * pcd)
+{
+	return GET_CORE_IF(pcd)->core_params->lpm_enable;
+}
+
+int dwc_otg_pcd_is_besl_enabled(dwc_otg_pcd_t * pcd)
+{
+	return GET_CORE_IF(pcd)->core_params->besl_enable;
+}
+
+int dwc_otg_pcd_get_param_baseline_besl(dwc_otg_pcd_t * pcd)
+{
+	return GET_CORE_IF(pcd)->core_params->baseline_besl;
+}
+
+int dwc_otg_pcd_get_param_deep_besl(dwc_otg_pcd_t * pcd)
+{
+	return GET_CORE_IF(pcd)->core_params->deep_besl;
+}
+
+uint32_t get_b_hnp_enable(dwc_otg_pcd_t * pcd)
+{
+	return pcd->b_hnp_enable;
+}
+
+uint32_t get_a_hnp_support(dwc_otg_pcd_t * pcd)
+{
+	return pcd->a_hnp_support;
+}
+
+uint32_t get_a_alt_hnp_support(dwc_otg_pcd_t * pcd)
+{
+	return pcd->a_alt_hnp_support;
+}
+
+int dwc_otg_pcd_get_rmwkup_enable(dwc_otg_pcd_t * pcd)
+{
+	return pcd->remote_wakeup_enable;
+}
+
+#endif /* DWC_HOST_ONLY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd.h
new file mode 100644
index 0000000..54ced23
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd.h
@@ -0,0 +1,268 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_pcd.h $
+ * $Revision: #49 $
+ * $Date: 2013/05/16 $
+ * $Change: 2231774 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef DWC_HOST_ONLY
+#if !defined(__DWC_PCD_H__)
+#define __DWC_PCD_H__
+
+#include "dwc_otg_os_dep.h"
+#include "usb.h"
+#include "dwc_otg_cil.h"
+#include "dwc_otg_pcd_if.h"
+struct cfiobject;
+
+/**
+ * @file
+ *
+ * This file contains the structures, constants, and interfaces for
+ * the Perpherial Contoller Driver (PCD).
+ *
+ * The Peripheral Controller Driver (PCD) for Linux will implement the
+ * Gadget API, so that the existing Gadget drivers can be used. For
+ * the Mass Storage Function driver the File-backed USB Storage Gadget
+ * (FBS) driver will be used.  The FBS driver supports the
+ * Control-Bulk (CB), Control-Bulk-Interrupt (CBI), and Bulk-Only
+ * transports.
+ *
+ */
+
+/** Invalid DMA Address */
+#define DWC_DMA_ADDR_INVALID	(~(dwc_dma_t)0)
+
+/** Max Transfer size for any EP */
+#define DDMA_MAX_TRANSFER_SIZE 65535
+
+/**
+ * Get the pointer to the core_if from the pcd pointer.
+ */
+#define GET_CORE_IF( _pcd ) (_pcd->core_if)
+
+/**
+ * States of EP0.
+ */
+typedef enum ep0_state {
+	EP0_DISCONNECT,		/* no host */
+	EP0_IDLE,
+	EP0_IN_DATA_PHASE,
+	EP0_OUT_DATA_PHASE,
+	EP0_IN_STATUS_PHASE,
+	EP0_OUT_STATUS_PHASE,
+	EP0_STALL,
+} ep0state_e;
+
+/** Fordward declaration.*/
+struct dwc_otg_pcd;
+
+/** DWC_otg iso request structure.
+ *
+ */
+typedef struct usb_iso_request dwc_otg_pcd_iso_request_t;
+
+#ifdef DWC_UTE_PER_IO
+
+/**
+ * This shall be the exact analogy of the same type structure defined in the
+ * usb_gadget.h. Each descriptor contains
+ */
+struct dwc_iso_pkt_desc_port {
+	uint32_t offset;
+	uint32_t length;	/* expected length */
+	uint32_t actual_length;
+	uint32_t status;
+};
+
+struct dwc_iso_xreq_port {
+	/** transfer/submission flag */
+	uint32_t tr_sub_flags;
+	/** Start the request ASAP */
+#define DWC_EREQ_TF_ASAP		0x00000002
+	/** Just enqueue the request w/o initiating a transfer */
+#define DWC_EREQ_TF_ENQUEUE		0x00000004
+
+	/**
+	* count of ISO packets attached to this request - shall
+	* not exceed the pio_alloc_pkt_count
+	*/
+	uint32_t pio_pkt_count;
+	/** count of ISO packets allocated for this request */
+	uint32_t pio_alloc_pkt_count;
+	/** number of ISO packet errors */
+	uint32_t error_count;
+	/** reserved for future extension */
+	uint32_t res;
+	/** Will be allocated and freed in the UTE gadget and based on the CFC value */
+	struct dwc_iso_pkt_desc_port *per_io_frame_descs;
+};
+#endif
+/** DWC_otg request structure.
+ * This structure is a list of requests.
+ */
+typedef struct dwc_otg_pcd_request {
+	void *priv;
+	void *buf;
+	dwc_dma_t dma;
+	uint32_t length;
+	uint32_t actual;
+	unsigned sent_zlp:1;
+    /**
+     * Used instead of original buffer if
+     * it(physical address) is not dword-aligned.
+     **/
+	uint8_t *dw_align_buf;
+	dwc_dma_t dw_align_buf_dma;
+
+	 DWC_CIRCLEQ_ENTRY(dwc_otg_pcd_request) queue_entry;
+#ifdef DWC_UTE_PER_IO
+	struct dwc_iso_xreq_port ext_req;
+	//void *priv_ereq_nport; /*  */
+#endif
+} dwc_otg_pcd_request_t;
+
+DWC_CIRCLEQ_HEAD(req_list, dwc_otg_pcd_request);
+
+/**	  PCD EP structure.
+ * This structure describes an EP, there is an array of EPs in the PCD
+ * structure.
+ */
+typedef struct dwc_otg_pcd_ep {
+	/** USB EP Descriptor */
+	const usb_endpoint_descriptor_t *desc;
+
+	/** queue of dwc_otg_pcd_requests. */
+	struct req_list queue;
+	unsigned stopped:1;
+	unsigned disabling:1;
+	unsigned dma:1;
+	unsigned queue_sof:1;
+
+#ifdef DWC_EN_ISOC
+	/** ISOC req handle passed */
+	void *iso_req_handle;
+#endif				//_EN_ISOC_
+
+	/** DWC_otg ep data. */
+	dwc_ep_t dwc_ep;
+
+	/** Pointer to PCD */
+	struct dwc_otg_pcd *pcd;
+
+	void *priv;
+} dwc_otg_pcd_ep_t;
+
+/** DWC_otg PCD Structure.
+ * This structure encapsulates the data for the dwc_otg PCD.
+ */
+struct dwc_otg_pcd {
+	const struct dwc_otg_pcd_function_ops *fops;
+	/** The DWC otg device pointer */
+	struct dwc_otg_device *otg_dev;
+	/** Core Interface */
+	dwc_otg_core_if_t *core_if;
+	/** State of EP0 */
+	ep0state_e ep0state;
+	/** EP0 Request is pending */
+	unsigned ep0_pending:1;
+	/** Indicates when SET CONFIGURATION Request is in process */
+	unsigned request_config:1;
+	/** The state of the Remote Wakeup Enable. */
+	unsigned remote_wakeup_enable:1;
+	/** The state of the B-Device HNP Enable. */
+	unsigned b_hnp_enable:1;
+	/** The state of A-Device HNP Support. */
+	unsigned a_hnp_support:1;
+	/** The state of the A-Device Alt HNP support. */
+	unsigned a_alt_hnp_support:1;
+	/** Count of pending Requests */
+	unsigned request_pending;
+
+	/** SETUP packet for EP0
+	 * This structure is allocated as a DMA buffer on PCD initialization
+	 * with enough space for up to 3 setup packets.
+	 */
+	union {
+		usb_device_request_t req;
+		uint32_t d32[2];
+	} *setup_pkt;
+
+	dwc_dma_t setup_pkt_dma_handle;
+
+	/* Additional buffer and flag for CTRL_WR premature case */
+	uint8_t *backup_buf;
+	unsigned data_terminated;
+
+	/** 2-byte dma buffer used to return status from GET_STATUS */
+	uint16_t *status_buf;
+	dwc_dma_t status_buf_dma_handle;
+
+	/** EP0 */
+	dwc_otg_pcd_ep_t ep0;
+
+	/** Array of IN EPs. */
+	dwc_otg_pcd_ep_t in_ep[MAX_EPS_CHANNELS - 1];
+	/** Array of OUT EPs. */
+	dwc_otg_pcd_ep_t out_ep[MAX_EPS_CHANNELS - 1];
+	/** number of valid EPs in the above array. */
+//        unsigned      num_eps : 4;
+	dwc_spinlock_t *lock;
+
+	/** Tasklet to defer starting of TEST mode transmissions until
+	 *	Status Phase has been completed.
+	 */
+	dwc_tasklet_t *test_mode_tasklet;
+
+	/** Tasklet to delay starting of xfer in DMA mode */
+	dwc_tasklet_t *start_xfer_tasklet;
+
+	/** The test mode to enter when the tasklet is executed. */
+	unsigned test_mode;
+	/** The cfi_api structure that implements most of the CFI API
+	 * and OTG specific core configuration functionality
+	 */
+#ifdef DWC_UTE_CFI
+	struct cfiobject *cfi;
+#endif
+
+};
+
+//FIXME this functions should be static, and this prototypes should be removed
+extern void dwc_otg_request_nuke(dwc_otg_pcd_ep_t * ep);
+extern void dwc_otg_request_done(dwc_otg_pcd_ep_t * ep,
+				dwc_otg_pcd_request_t * req, int32_t status);
+
+void dwc_otg_iso_buffer_done(dwc_otg_pcd_t * pcd, dwc_otg_pcd_ep_t * ep,
+			    void *req_handle);
+extern void dwc_otg_pcd_start_iso_ddma(dwc_otg_core_if_t * core_if,
+				dwc_otg_pcd_ep_t * ep);
+
+extern void do_test_mode(void *data);
+#endif
+#endif /* DWC_HOST_ONLY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd_if.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd_if.h
new file mode 100644
index 0000000..6cd75fa
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd_if.h
@@ -0,0 +1,368 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_pcd_if.h $
+ * $Revision: #13 $
+ * $Date: 2012/12/12 $
+ * $Change: 2125019 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef DWC_HOST_ONLY
+
+#if !defined(__DWC_PCD_IF_H__)
+#define __DWC_PCD_IF_H__
+
+//#include "dwc_os.h"
+#include "dwc_otg_core_if.h"
+
+/** @file
+ * This file defines DWC_OTG PCD Core API.
+ */
+
+struct dwc_otg_pcd;
+typedef struct dwc_otg_pcd dwc_otg_pcd_t;
+
+/** Maxpacket size for EP0 */
+#define MAX_EP0_SIZE	64
+/** Maxpacket size for any EP */
+#define MAX_PACKET_SIZE 1024
+
+/** @name Function Driver Callbacks */
+/** @{ */
+
+/** This function will be called whenever a previously queued request has
+ * completed.  The status value will be set to -DWC_E_SHUTDOWN to indicated a
+ * failed or aborted transfer, or -DWC_E_RESTART to indicate the device was reset,
+ * or -DWC_E_TIMEOUT to indicate it timed out, or -DWC_E_INVALID to indicate invalid
+ * parameters. */
+typedef int (*dwc_completion_cb_t) (dwc_otg_pcd_t * pcd, void *ep_handle,
+				    void *req_handle, int32_t status,
+				    uint32_t actual);
+/**
+ * This function will be called whenever a previousle queued ISOC request has
+ * completed. Count of ISOC packets could be read using dwc_otg_pcd_get_iso_packet_count
+ * function.
+ * The status of each ISOC packet could be read using dwc_otg_pcd_get_iso_packet_*
+ * functions.
+ */
+typedef int (*dwc_isoc_completion_cb_t) (dwc_otg_pcd_t * pcd, void *ep_handle,
+					 void *req_handle, int proc_buf_num);
+/** This function should handle any SETUP request that cannot be handled by the
+ * PCD Core.  This includes most GET_DESCRIPTORs, SET_CONFIGS, Any
+ * class-specific requests, etc.  The function must non-blocking.
+ *
+ * Returns 0 on success.
+ * Returns -DWC_E_NOT_SUPPORTED if the request is not supported.
+ * Returns -DWC_E_INVALID if the setup request had invalid parameters or bytes.
+ * Returns -DWC_E_SHUTDOWN on any other error. */
+typedef int (*dwc_setup_cb_t) (dwc_otg_pcd_t * pcd, uint8_t * bytes);
+/** This is called whenever the device has been disconnected.  The function
+ * driver should take appropriate action to clean up all pending requests in the
+ * PCD Core, remove all endpoints (except ep0), and initialize back to reset
+ * state. */
+typedef int (*dwc_disconnect_cb_t) (dwc_otg_pcd_t * pcd);
+/** This function is called when device has been connected. */
+typedef int (*dwc_connect_cb_t) (dwc_otg_pcd_t * pcd, int speed);
+/** This function is called when device has been suspended */
+typedef int (*dwc_suspend_cb_t) (dwc_otg_pcd_t * pcd);
+/** This function is called when device has received LPM tokens, i.e.
+ * device has been sent to sleep state. */
+typedef int (*dwc_sleep_cb_t) (dwc_otg_pcd_t * pcd);
+/** This function is called when device has been resumed
+ * from suspend(L2) or L1 sleep state. */
+typedef int (*dwc_resume_cb_t) (dwc_otg_pcd_t * pcd);
+/** This function is called whenever hnp params has been changed.
+ * User can call get_b_hnp_enable, get_a_hnp_support, get_a_alt_hnp_support functions
+ * to get hnp parameters. */
+typedef int (*dwc_hnp_params_changed_cb_t) (dwc_otg_pcd_t * pcd);
+/** This function is called whenever USB RESET is detected. */
+typedef int (*dwc_reset_cb_t) (dwc_otg_pcd_t * pcd);
+
+typedef int (*cfi_setup_cb_t) (dwc_otg_pcd_t * pcd, void *ctrl_req_bytes);
+
+/**
+ *
+ * @param ep_handle	Void pointer to the usb_ep structure
+ * @param ereq_port Pointer to the extended request structure created in the
+ *					portable part.
+ */
+typedef int (*xiso_completion_cb_t) (dwc_otg_pcd_t * pcd, void *ep_handle,
+				     void *req_handle, int32_t status,
+				     void *ereq_port);
+/** Function Driver Ops Data Structure */
+struct dwc_otg_pcd_function_ops {
+	dwc_connect_cb_t connect;
+	dwc_disconnect_cb_t disconnect;
+	dwc_setup_cb_t setup;
+	dwc_completion_cb_t complete;
+	dwc_isoc_completion_cb_t isoc_complete;
+	dwc_suspend_cb_t suspend;
+	dwc_sleep_cb_t sleep;
+	dwc_resume_cb_t resume;
+	dwc_reset_cb_t reset;
+	dwc_hnp_params_changed_cb_t hnp_changed;
+	cfi_setup_cb_t cfi_setup;
+#ifdef DWC_UTE_PER_IO
+	xiso_completion_cb_t xisoc_complete;
+#endif
+};
+/** @} */
+
+/** @name Function Driver Functions */
+/** @{ */
+
+/** Call this function to get pointer on dwc_otg_pcd_t,
+ * this pointer will be used for all PCD API functions.
+ *
+ * @param core_if The DWC_OTG Core
+ */
+extern dwc_otg_pcd_t *dwc_otg_pcd_init(dwc_otg_core_if_t * core_if);
+
+/** Frees PCD allocated by dwc_otg_pcd_init
+ *
+ * @param pcd The PCD
+ */
+extern void dwc_otg_pcd_remove(dwc_otg_pcd_t * pcd);
+
+/** Call this to bind the function driver to the PCD Core.
+ *
+ * @param pcd Pointer on dwc_otg_pcd_t returned by dwc_otg_pcd_init function.
+ * @param fops The Function Driver Ops data structure containing pointers to all callbacks.
+ */
+extern void dwc_otg_pcd_start(dwc_otg_pcd_t * pcd,
+			      const struct dwc_otg_pcd_function_ops *fops);
+
+/** Enables an endpoint for use.  This function enables an endpoint in
+ * the PCD.  The endpoint is described by the ep_desc which has the
+ * same format as a USB ep descriptor.  The ep_handle parameter is used to refer
+ * to the endpoint from other API functions and in callbacks.  Normally this
+ * should be called after a SET_CONFIGURATION/SET_INTERFACE to configure the
+ * core for that interface.
+ *
+ * Returns -DWC_E_INVALID if invalid parameters were passed.
+ * Returns -DWC_E_SHUTDOWN if any other error ocurred.
+ * Returns 0 on success.
+ *
+ * @param pcd The PCD
+ * @param ep_desc Endpoint descriptor
+ * @param ep_handle Handle on endpoint, that will be used to identify endpoint.
+ */
+extern int dwc_otg_pcd_ep_enable(dwc_otg_pcd_t * pcd,
+				 const uint8_t * ep_desc, void *ep_handle);
+
+/** Disable the endpoint referenced by ep_handle.
+ *
+ * Returns -DWC_E_INVALID if invalid parameters were passed.
+ * Returns -DWC_E_SHUTDOWN if any other error occurred.
+ * Returns 0 on success. */
+extern int dwc_otg_pcd_ep_disable(dwc_otg_pcd_t * pcd, void *ep_handle);
+
+/** Queue a data transfer request on the endpoint referenced by ep_handle.
+ * After the transfer is completes, the complete callback will be called with
+ * the request status.
+ *
+ * @param pcd The PCD
+ * @param ep_handle The handle of the endpoint
+ * @param buf The buffer for the data
+ * @param dma_buf The DMA buffer for the data
+ * @param buflen The length of the data transfer
+ * @param zero Specifies whether to send zero length last packet.
+ * @param req_handle Set this handle to any value to use to reference this
+ * request in the ep_dequeue function or from the complete callback
+ * @param atomic_alloc If driver need to perform atomic allocations
+ * for internal data structures.
+ *
+ * Returns -DWC_E_INVALID if invalid parameters were passed.
+ * Returns -DWC_E_SHUTDOWN if any other error ocurred.
+ * Returns 0 on success. */
+extern int dwc_otg_pcd_ep_queue(dwc_otg_pcd_t * pcd, void *ep_handle,
+				uint8_t * buf, dwc_dma_t dma_buf,
+				uint32_t buflen, int zero, void *req_handle,
+				int atomic_alloc);
+#ifdef DWC_UTE_PER_IO
+/**
+ *
+ * @param ereq_nonport	Pointer to the extended request part of the
+ *						usb_request structure defined in usb_gadget.h file.
+ */
+extern int dwc_otg_pcd_xiso_ep_queue(dwc_otg_pcd_t * pcd, void *ep_handle,
+				     uint8_t * buf, dwc_dma_t dma_buf,
+				     uint32_t buflen, int zero,
+				     void *req_handle, int atomic_alloc,
+				     void *ereq_nonport);
+
+#endif
+
+/** De-queue the specified data transfer that has not yet completed.
+ *
+ * Returns -DWC_E_INVALID if invalid parameters were passed.
+ * Returns -DWC_E_SHUTDOWN if any other error ocurred.
+ * Returns 0 on success. */
+extern int dwc_otg_pcd_ep_dequeue(dwc_otg_pcd_t * pcd, void *ep_handle,
+				  void *req_handle);
+
+/** Halt (STALL) an endpoint or clear it.
+ *
+ * Returns -DWC_E_INVALID if invalid parameters were passed.
+ * Returns -DWC_E_SHUTDOWN if any other error ocurred.
+ * Returns -DWC_E_AGAIN if the STALL cannot be sent and must be tried again later
+ * Returns 0 on success. */
+extern int dwc_otg_pcd_ep_halt(dwc_otg_pcd_t * pcd, void *ep_handle, int value);
+
+/** This function should be called on every hardware interrupt */
+extern int32_t dwc_otg_pcd_handle_intr(dwc_otg_pcd_t * pcd);
+
+/** This function returns current frame number */
+extern int dwc_otg_pcd_get_frame_number(dwc_otg_pcd_t * pcd);
+
+/**
+ * Start isochronous transfers on the endpoint referenced by ep_handle.
+ * For isochronous transfers duble buffering is used.
+ * After processing each of buffers comlete callback will be called with
+ * status for each transaction.
+ *
+ * @param pcd The PCD
+ * @param ep_handle The handle of the endpoint
+ * @param buf0 The virtual address of first data buffer
+ * @param buf1 The virtual address of second data buffer
+ * @param dma0 The DMA address of first data buffer
+ * @param dma1 The DMA address of second data buffer
+ * @param sync_frame Data pattern frame number
+ * @param dp_frame Data size for pattern frame
+ * @param data_per_frame Data size for regular frame
+ * @param start_frame Frame number to start transfers, if -1 then start transfers ASAP.
+ * @param buf_proc_intrvl Interval of ISOC Buffer processing
+ * @param req_handle Handle of ISOC request
+ * @param atomic_alloc Specefies whether to perform atomic allocation for
+ *			internal data structures.
+ *
+ * Returns -DWC_E_NO_MEMORY if there is no enough memory.
+ * Returns -DWC_E_INVALID if incorrect arguments are passed to the function.
+ * Returns -DW_E_SHUTDOWN for any other error.
+ * Returns 0 on success
+ */
+extern int dwc_otg_pcd_iso_ep_start(dwc_otg_pcd_t * pcd, void *ep_handle,
+				    uint8_t * buf0, uint8_t * buf1,
+				    dwc_dma_t dma0, dwc_dma_t dma1,
+				    int sync_frame, int dp_frame,
+				    int data_per_frame, int start_frame,
+				    int buf_proc_intrvl, void *req_handle,
+				    int atomic_alloc);
+
+/** Stop ISOC transfers on endpoint referenced by ep_handle.
+ *
+ * @param pcd The PCD
+ * @param ep_handle The handle of the endpoint
+ * @param req_handle Handle of ISOC request
+ *
+ * Returns -DWC_E_INVALID if incorrect arguments are passed to the function
+ * Returns 0 on success
+ */
+int dwc_otg_pcd_iso_ep_stop(dwc_otg_pcd_t * pcd, void *ep_handle,
+			    void *req_handle);
+
+/** Get ISOC packet status.
+ *
+ * @param pcd The PCD
+ * @param ep_handle The handle of the endpoint
+ * @param iso_req_handle Isochronoush request handle
+ * @param packet Number of packet
+ * @param status Out parameter for returning status
+ * @param actual Out parameter for returning actual length
+ * @param offset Out parameter for returning offset
+ *
+ */
+extern void dwc_otg_pcd_get_iso_packet_params(dwc_otg_pcd_t * pcd,
+					      void *ep_handle,
+					      void *iso_req_handle, int packet,
+					      int *status, int *actual,
+					      int *offset);
+
+/** Get ISOC packet count.
+ *
+ * @param pcd The PCD
+ * @param ep_handle The handle of the endpoint
+ * @param iso_req_handle
+ */
+extern int dwc_otg_pcd_get_iso_packet_count(dwc_otg_pcd_t * pcd,
+					    void *ep_handle,
+					    void *iso_req_handle);
+
+/** This function starts the SRP Protocol if no session is in progress. If
+ * a session is already in progress, but the device is suspended,
+ * remote wakeup signaling is started.
+ */
+extern int dwc_otg_pcd_wakeup(dwc_otg_pcd_t * pcd);
+
+extern void dwc_otg_pcd_pullup(dwc_otg_pcd_t *pcd);
+
+/** This function returns 1 if LPM support is enabled, and 0 otherwise. */
+extern int dwc_otg_pcd_is_lpm_enabled(dwc_otg_pcd_t * pcd);
+
+/** This function returns 1 if LPM Errata support is enabled, and 0 otherwise. */
+extern int dwc_otg_pcd_is_besl_enabled(dwc_otg_pcd_t * pcd);
+
+/** This function returns baseline_besl module parametr. */
+extern int dwc_otg_pcd_get_param_baseline_besl(dwc_otg_pcd_t * pcd);
+
+/** This function returns deep_besl module parametr. */
+extern int dwc_otg_pcd_get_param_deep_besl(dwc_otg_pcd_t * pcd);
+
+/** This function returns 1 if remote wakeup is allowed and 0, otherwise. */
+extern int dwc_otg_pcd_get_rmwkup_enable(dwc_otg_pcd_t * pcd);
+
+/** Initiate SRP */
+extern void dwc_otg_pcd_initiate_srp(dwc_otg_pcd_t * pcd);
+
+/** Starts remote wakeup signaling. */
+extern void dwc_otg_pcd_remote_wakeup(dwc_otg_pcd_t * pcd, int set);
+
+/** Starts micorsecond soft disconnect. */
+extern void dwc_otg_pcd_disconnect_us(dwc_otg_pcd_t * pcd, int no_of_usecs);
+/** This function returns whether device is dualspeed.*/
+extern uint32_t dwc_otg_pcd_is_dualspeed(dwc_otg_pcd_t * pcd);
+
+/** This function returns whether device is otg. */
+extern uint32_t dwc_otg_pcd_is_otg(dwc_otg_pcd_t * pcd);
+
+/** These functions allow to get hnp parameters */
+extern uint32_t get_b_hnp_enable(dwc_otg_pcd_t * pcd);
+extern uint32_t get_a_hnp_support(dwc_otg_pcd_t * pcd);
+extern uint32_t get_a_alt_hnp_support(dwc_otg_pcd_t * pcd);
+
+/** CFI specific Interface functions */
+/** Allocate a cfi buffer */
+extern uint8_t *cfiw_ep_alloc_buffer(dwc_otg_pcd_t * pcd, void *pep,
+				     dwc_dma_t * addr, size_t buflen,
+				     int flags);
+
+/******************************************************************************/
+
+/** @} */
+
+#endif				/* __DWC_PCD_IF_H__ */
+
+#endif				/* DWC_HOST_ONLY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd_intr.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd_intr.c
new file mode 100644
index 0000000..b0f0ef1
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd_intr.c
@@ -0,0 +1,5427 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_pcd_intr.c $
+ * $Revision: #125 $
+ * $Date: 2013/05/20 $
+ * $Change: 2234037 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+#ifndef DWC_HOST_ONLY
+
+#include "dwc_otg_pcd.h"
+
+#ifdef DWC_UTE_CFI
+#include "dwc_otg_cfi.h"
+#endif
+
+//#include <linux/hisilicon/hiotg.h>
+
+#ifdef DWC_UTE_PER_IO
+extern void complete_xiso_ep(dwc_otg_pcd_ep_t * ep);
+#endif
+//#define PRINT_CFI_DMA_DESCS
+
+#define DEBUG_EP0
+
+/* avoid null point */
+uint8_t readpacket_buf[1024];
+
+/**
+ * This function updates OTG.
+ */
+extern void hisi_switch_func(int otg);
+static void dwc_otg_pcd_update_otg(dwc_otg_pcd_t * pcd, const unsigned reset)
+{
+
+	if (reset) {
+		pcd->b_hnp_enable = 0;
+		pcd->a_hnp_support = 0;
+		pcd->a_alt_hnp_support = 0;
+	}
+
+	if (pcd->fops->hnp_changed) {
+		pcd->fops->hnp_changed(pcd);
+	}
+}
+
+/** @file
+ * This file contains the implementation of the PCD Interrupt handlers.
+ *
+ * The PCD handles the device interrupts.  Many conditions can cause a
+ * device interrupt. When an interrupt occurs, the device interrupt
+ * service routine determines the cause of the interrupt and
+ * dispatches handling to the appropriate function. These interrupt
+ * handling functions are described below.
+ * All interrupt registers are processed from LSB to MSB.
+ */
+
+/**
+ * This function prints the ep0 state for debug purposes.
+ */
+static inline void print_ep0_state(dwc_otg_pcd_t * pcd)
+{
+#ifdef DEBUG
+	char str[40];
+
+	switch (pcd->ep0state) {
+	case EP0_DISCONNECT:
+		dwc_strcpy(str, "EP0_DISCONNECT");
+		break;
+	case EP0_IDLE:
+		dwc_strcpy(str, "EP0_IDLE");
+		break;
+	case EP0_IN_DATA_PHASE:
+		dwc_strcpy(str, "EP0_IN_DATA_PHASE");
+		break;
+	case EP0_OUT_DATA_PHASE:
+		dwc_strcpy(str, "EP0_OUT_DATA_PHASE");
+		break;
+	case EP0_IN_STATUS_PHASE:
+		dwc_strcpy(str, "EP0_IN_STATUS_PHASE");
+		break;
+	case EP0_OUT_STATUS_PHASE:
+		dwc_strcpy(str, "EP0_OUT_STATUS_PHASE");
+		break;
+	case EP0_STALL:
+		dwc_strcpy(str, "EP0_STALL");
+		break;
+	default:
+		dwc_strcpy(str, "EP0_INVALID");
+	}
+
+	DWC_DEBUGPL(DBG_ANY, "%s(%d)\n", str, pcd->ep0state);
+#endif
+}
+
+/**
+ * This function calculate the size of the payload in the memory
+ * for out endpoints and prints size for debug purposes(used in
+ * 2.93a DevOutNak feature).
+ */
+static inline void print_memory_payload(dwc_otg_pcd_t * pcd,  dwc_ep_t * ep)
+{
+#ifdef DEBUG
+	deptsiz_data_t deptsiz_init = {.d32 = 0 };
+	deptsiz_data_t deptsiz_updt = {.d32 = 0 };
+	int pack_num;
+	unsigned payload;
+
+	deptsiz_init.d32 = pcd->core_if->start_doeptsiz_val[ep->num];
+	deptsiz_updt.d32 =
+		DWC_READ_REG32(&pcd->core_if->dev_if->
+						out_ep_regs[ep->num]->doeptsiz);
+	/* Payload will be */
+	payload = deptsiz_init.b.xfersize - deptsiz_updt.b.xfersize;
+	/* Packet count is decremented every time a packet
+	 * is written to the RxFIFO not in to the external memory
+	 * So, if payload == 0, then it means no packet was sent to ext memory*/
+	pack_num = (!payload) ? 0 : (deptsiz_init.b.pktcnt - deptsiz_updt.b.pktcnt);
+	DWC_DEBUGPL(DBG_PCDV,
+		"Payload for EP%d-%s\n",
+		ep->num, (ep->is_in ? "IN" : "OUT"));
+	DWC_DEBUGPL(DBG_PCDV,
+		"Number of transfered bytes = 0x%08x\n", payload);
+	DWC_DEBUGPL(DBG_PCDV,
+		"Number of transfered packets = %d\n", pack_num);
+#endif
+}
+
+
+#ifdef DWC_UTE_CFI
+static inline void print_desc(struct dwc_otg_dma_desc *ddesc,
+			      const uint8_t * epname, int descnum)
+{
+	CFI_INFO
+	    ("%s DMA_DESC(%d) buf=0x%08x bytes=0x%04x; sp=0x%x; l=0x%x; sts=0x%02x; bs=0x%02x\n",
+	     epname, descnum, ddesc->buf, ddesc->status.b.bytes,
+	     ddesc->status.b.sp, ddesc->status.b.l, ddesc->status.b.sts,
+	     ddesc->status.b.bs);
+}
+#endif
+
+/**
+ * This function returns pointer to in ep struct with number ep_num
+ */
+static inline dwc_otg_pcd_ep_t *get_in_ep(dwc_otg_pcd_t * pcd, uint32_t ep_num)
+{
+	int i;
+	int num_in_eps = GET_CORE_IF(pcd)->dev_if->num_in_eps;
+	if (ep_num == 0) {
+		return &pcd->ep0;
+	} else {
+		for (i = 0; i < num_in_eps; ++i) {
+			if (pcd->in_ep[i].dwc_ep.num == ep_num)
+				return &pcd->in_ep[i];
+		}
+		return 0;
+	}
+}
+
+/**
+ * This function returns pointer to out ep struct with number ep_num
+ */
+static inline dwc_otg_pcd_ep_t *get_out_ep(dwc_otg_pcd_t * pcd, uint32_t ep_num)
+{
+	int i;
+	int num_out_eps = GET_CORE_IF(pcd)->dev_if->num_out_eps;
+	if (ep_num == 0) {
+		return &pcd->ep0;
+	} else {
+		for (i = 0; i < num_out_eps; ++i) {
+			if (pcd->out_ep[i].dwc_ep.num == ep_num)
+				return &pcd->out_ep[i];
+		}
+		return 0;
+	}
+}
+
+/**
+ * This functions gets a pointer to an EP from the wIndex address
+ * value of the control request.
+ */
+dwc_otg_pcd_ep_t *get_ep_by_addr(dwc_otg_pcd_t * pcd, u16 wIndex)
+{
+	dwc_otg_pcd_ep_t *ep;
+	uint32_t ep_num = UE_GET_ADDR(wIndex);
+
+	if (ep_num == 0) {
+		ep = &pcd->ep0;
+	} else if (UE_GET_DIR(wIndex) == UE_DIR_IN) {	/* in ep */
+		ep = &pcd->in_ep[ep_num - 1];
+	} else {
+		ep = &pcd->out_ep[ep_num - 1];
+	}
+
+	return ep;
+}
+
+/**
+ * This function checks the EP request queue, if the queue is not
+ * empty the next request is started.
+ */
+void start_next_request(dwc_otg_pcd_ep_t * ep)
+{
+	dwc_otg_pcd_request_t *req = 0;
+	uint32_t max_transfer =
+	    GET_CORE_IF(ep->pcd)->core_params->max_transfer_size;
+
+#ifdef DWC_UTE_CFI
+	struct dwc_otg_pcd *pcd;
+	pcd = ep->pcd;
+#endif
+
+	if (!DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+		req = DWC_CIRCLEQ_FIRST(&ep->queue);
+
+#ifdef DWC_UTE_CFI
+		if (ep->dwc_ep.buff_mode != BM_STANDARD) {
+			ep->dwc_ep.cfi_req_len = req->length;
+			pcd->cfi->ops.build_descriptors(pcd->cfi, pcd, ep, req);
+		} else {
+#endif
+			/* Setup and start the Transfer */
+			if (req->dw_align_buf) {
+				ep->dwc_ep.dma_addr = req->dw_align_buf_dma;
+				ep->dwc_ep.start_xfer_buff = req->dw_align_buf;
+				ep->dwc_ep.xfer_buff = req->dw_align_buf;
+			} else {
+				ep->dwc_ep.dma_addr = req->dma;
+				ep->dwc_ep.start_xfer_buff = req->buf;
+				ep->dwc_ep.xfer_buff = req->buf;
+			}
+			ep->dwc_ep.sent_zlp = 0;
+			ep->dwc_ep.total_len = req->length;
+			ep->dwc_ep.xfer_len = 0;
+			ep->dwc_ep.xfer_count = 0;
+
+			ep->dwc_ep.maxxfer = max_transfer;
+			if (GET_CORE_IF(ep->pcd)->dma_desc_enable) {
+				uint32_t out_max_xfer = DDMA_MAX_TRANSFER_SIZE
+				    - (DDMA_MAX_TRANSFER_SIZE % 4);
+				if (ep->dwc_ep.is_in) {
+					if (ep->dwc_ep.maxxfer >
+					    DDMA_MAX_TRANSFER_SIZE) {
+						ep->dwc_ep.maxxfer =
+						    DDMA_MAX_TRANSFER_SIZE;
+					}
+				} else {
+					if (ep->dwc_ep.maxxfer > out_max_xfer) {
+						ep->dwc_ep.maxxfer =
+						    out_max_xfer;
+					}
+				}
+			}
+			if (ep->dwc_ep.maxxfer < ep->dwc_ep.total_len) {
+				ep->dwc_ep.maxxfer -=
+				    (ep->dwc_ep.maxxfer % ep->dwc_ep.maxpacket);
+			}
+			if (req->sent_zlp) {
+				if ((ep->dwc_ep.total_len %
+				     ep->dwc_ep.maxpacket == 0)
+				    && (ep->dwc_ep.total_len != 0)) {
+					ep->dwc_ep.sent_zlp = 1;
+				}
+
+			}
+#ifdef DWC_UTE_CFI
+		}
+#endif
+		dwc_otg_ep_start_transfer(GET_CORE_IF(ep->pcd), &ep->dwc_ep);
+	} else if (ep->dwc_ep.type == DWC_OTG_EP_TYPE_ISOC) {
+		diepmsk_data_t intr_mask = {.d32 = 0 };
+
+		intr_mask.b.nak = 1;
+
+		if (GET_CORE_IF(ep->pcd)->multiproc_int_enable) {
+			DWC_MODIFY_REG32(&GET_CORE_IF(ep->pcd)->dev_if->dev_global_regs->
+				diepeachintmsk[ep->dwc_ep.num], intr_mask.d32, 0);
+		} else {
+			DWC_MODIFY_REG32(&GET_CORE_IF(ep->pcd)->dev_if->dev_global_regs->diepmsk,
+				intr_mask.d32, 0);
+		}
+		DWC_PRINTF("There are no more ISOC requests \n");
+		ep->dwc_ep.frame_num = 0xFFFFFFFF;
+	}
+}
+
+/**
+ * This function handles the SOF Interrupts. At this time the SOF
+ * Interrupt is disabled.
+ */
+int32_t dwc_otg_pcd_handle_sof_intr(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+
+	gintsts_data_t gintsts;
+
+	DWC_DEBUGPL(DBG_PCD, "SOF\n");
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.sofintr = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * This function handles the Rx Status Queue Level Interrupt, which
+ * indicates that there is a least one packet in the Rx FIFO.  The
+ * packets are moved from the FIFO to memory, where they will be
+ * processed when the Endpoint Interrupt Register indicates Transfer
+ * Complete or SETUP Phase Done.
+ *
+ * Repeat the following until the Rx Status Queue is empty:
+ *	 -# Read the Receive Status Pop Register (GRXSTSP) to get Packet
+ *		info
+ *	 -# If Receive FIFO is empty then skip to step Clear the interrupt
+ *		and exit
+ *	 -# If SETUP Packet call dwc_otg_read_setup_packet to copy the
+ *		SETUP data to the buffer
+ *	 -# If OUT Data Packet call dwc_otg_read_packet to copy the data
+ *		to the destination buffer
+ */
+int32_t dwc_otg_pcd_handle_rx_status_q_level_intr(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	gintmsk_data_t gintmask = {.d32 = 0 };
+	device_grxsts_data_t status;
+	dwc_otg_pcd_ep_t *ep;
+	gintsts_data_t gintsts;
+#ifdef DEBUG
+	static char *dpid_str[] = { "D0", "D2", "D1", "MDATA" };
+#endif
+
+	//DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _pcd);
+	/* Disable the Rx Status Queue Level interrupt */
+	gintmask.b.rxstsqlvl = 1;
+	DWC_MODIFY_REG32(&global_regs->gintmsk, gintmask.d32, 0);
+
+	/* Get the Status from the top of the FIFO */
+	status.d32 = DWC_READ_REG32(&global_regs->grxstsp);
+
+	DWC_DEBUGPL(DBG_PCD, "EP:%d BCnt:%d DPID:%s "
+		    "pktsts:%x Frame:%d(0x%0x)\n",
+		    status.b.epnum, status.b.bcnt,
+		    dpid_str[status.b.dpid],
+		    status.b.pktsts, status.b.fn, status.b.fn);
+	/* Get pointer to EP structure */
+	ep = get_out_ep(pcd, status.b.epnum);
+
+	switch (status.b.pktsts) {
+	case DWC_DSTS_GOUT_NAK:
+		DWC_DEBUGPL(DBG_PCDV, "Global OUT NAK\n");
+		break;
+	case DWC_STS_DATA_UPDT:
+		DWC_DEBUGPL(DBG_PCDV, "OUT Data Packet\n");
+		if (status.b.bcnt && ep->dwc_ep.xfer_buff) {
+			/** @todo NGS Check for buffer overflow? */
+			dwc_otg_read_packet(core_if,
+					    ep->dwc_ep.xfer_buff,
+					    status.b.bcnt);
+			ep->dwc_ep.xfer_count += status.b.bcnt;
+			ep->dwc_ep.xfer_buff += status.b.bcnt;
+		}
+		if (status.b.bcnt &&(status.b.bcnt<1024)
+			&& !ep->dwc_ep.xfer_buff) {
+			dwc_otg_read_packet(core_if,
+					    readpacket_buf,
+					    status.b.bcnt);
+			ep->dwc_ep.xfer_count += status.b.bcnt;
+		}
+		break;
+	case DWC_STS_XFER_COMP:
+		DWC_DEBUGPL(DBG_PCDV, "OUT Complete\n");
+		break;
+	case DWC_DSTS_SETUP_COMP:
+#ifdef DEBUG_EP0
+		DWC_DEBUGPL(DBG_PCDV, "Setup Complete\n");
+#endif
+		break;
+	case DWC_DSTS_SETUP_UPDT:
+		dwc_otg_read_setup_packet(core_if, pcd->setup_pkt->d32);
+#ifdef DEBUG_EP0
+		DWC_DEBUGPL(DBG_PCD,
+			    "SETUP PKT: %02x.%02x v%04x i%04x l%04x\n",
+			    pcd->setup_pkt->req.bmRequestType,
+			    pcd->setup_pkt->req.bRequest,
+			    UGETW(pcd->setup_pkt->req.wValue),
+			    UGETW(pcd->setup_pkt->req.wIndex),
+			    UGETW(pcd->setup_pkt->req.wLength));
+#endif
+		ep->dwc_ep.xfer_count += status.b.bcnt;
+		break;
+	default:
+		DWC_DEBUGPL(DBG_PCDV, "Invalid Packet Status (0x%0x)\n",
+			    status.b.pktsts);
+		break;
+	}
+
+	/* Enable the Rx Status Queue Level interrupt */
+	DWC_MODIFY_REG32(&global_regs->gintmsk, 0, gintmask.d32);
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.rxstsqlvl = 1;
+	DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+	//DWC_DEBUGPL(DBG_PCDV, "EXIT: %s\n", __func__);
+	return 1;
+}
+
+/**
+ * This function examines the Device IN Token Learning Queue to
+ * determine the EP number of the last IN token received.  This
+ * implementation is for the Mass Storage device where there are only
+ * 2 IN EPs (Control-IN and BULK-IN).
+ *
+ * The EP numbers for the first six IN Tokens are in DTKNQR1 and there
+ * are 8 EP Numbers in each of the other possible DTKNQ Registers.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ *
+ */
+static inline int get_ep_of_last_in_token(dwc_otg_core_if_t * core_if)
+{
+	dwc_otg_device_global_regs_t *dev_global_regs =
+	    core_if->dev_if->dev_global_regs;
+	const uint32_t TOKEN_Q_DEPTH = core_if->hwcfg2.b.dev_token_q_depth;
+	/* Number of Token Queue Registers */
+	const int DTKNQ_REG_CNT = (TOKEN_Q_DEPTH + 7) / 8;
+	dtknq1_data_t dtknqr1;
+	uint32_t in_tkn_epnums[4];
+	int ndx = 0;
+	int i = 0;
+	volatile uint32_t *addr = &dev_global_regs->dtknqr1;
+	int epnum = 0;
+
+	//DWC_DEBUGPL(DBG_PCD,"dev_token_q_depth=%d\n",TOKEN_Q_DEPTH);
+
+	/* Read the DTKNQ Registers */
+	for (i = 0; i < DTKNQ_REG_CNT; i++) {
+		in_tkn_epnums[i] = DWC_READ_REG32(addr);
+		DWC_DEBUGPL(DBG_PCDV, "DTKNQR%d=0x%08x\n", i + 1,
+			    in_tkn_epnums[i]);
+		if (addr == &dev_global_regs->dvbusdis) {
+			addr = &dev_global_regs->dtknqr3_dthrctl;
+		} else {
+			++addr;
+		}
+
+	}
+
+	/* Copy the DTKNQR1 data to the bit field. */
+	dtknqr1.d32 = in_tkn_epnums[0];
+	/* Get the EP numbers */
+	in_tkn_epnums[0] = dtknqr1.b.epnums0_5;
+	ndx = dtknqr1.b.intknwptr - 1;
+
+	//DWC_DEBUGPL(DBG_PCDV,"ndx=%d\n",ndx);
+	if (ndx == -1) {
+		/** @todo Find a simpler way to calculate the max
+		 * queue position.*/
+		int cnt = TOKEN_Q_DEPTH;
+		if (TOKEN_Q_DEPTH <= 6) {
+			cnt = TOKEN_Q_DEPTH - 1;
+		} else if (TOKEN_Q_DEPTH <= 14) {
+			cnt = TOKEN_Q_DEPTH - 7;
+		} else if (TOKEN_Q_DEPTH <= 22) {
+			cnt = TOKEN_Q_DEPTH - 15;
+		} else {
+			cnt = TOKEN_Q_DEPTH - 23;
+		}
+		epnum = (in_tkn_epnums[DTKNQ_REG_CNT - 1] >> (cnt * 4)) & 0xF;
+	} else {
+		if (ndx <= 5) {
+			epnum = (in_tkn_epnums[0] >> (ndx * 4)) & 0xF;
+		} else if (ndx <= 13) {
+			ndx -= 6;
+			epnum = (in_tkn_epnums[1] >> (ndx * 4)) & 0xF;
+		} else if (ndx <= 21) {
+			ndx -= 14;
+			epnum = (in_tkn_epnums[2] >> (ndx * 4)) & 0xF;
+		} else if (ndx <= 29) {
+			ndx -= 22;
+			epnum = (in_tkn_epnums[3] >> (ndx * 4)) & 0xF;
+		}
+	}
+	//DWC_DEBUGPL(DBG_PCD,"epnum=%d\n",epnum);
+	return epnum;
+}
+
+/**
+ * This interrupt occurs when the non-periodic Tx FIFO is half-empty.
+ * The active request is checked for the next packet to be loaded into
+ * the non-periodic Tx FIFO.
+ */
+int32_t dwc_otg_pcd_handle_np_tx_fifo_empty_intr(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	dwc_otg_dev_in_ep_regs_t *ep_regs;
+	gnptxsts_data_t txstatus = {.d32 = 0 };
+	gintsts_data_t gintsts;
+
+	int epnum = 0;
+	dwc_otg_pcd_ep_t *ep = 0;
+	uint32_t len = 0;
+	int dwords;
+
+	/* Get the epnum from the IN Token Learning Queue. */
+	epnum = get_ep_of_last_in_token(core_if);
+	ep = get_in_ep(pcd, epnum);
+
+	DWC_DEBUGPL(DBG_PCD, "NP TxFifo Empty: %d \n", epnum);
+
+	ep_regs = core_if->dev_if->in_ep_regs[epnum];
+
+	len = ep->dwc_ep.xfer_len - ep->dwc_ep.xfer_count;
+	if (len > ep->dwc_ep.maxpacket) {
+		len = ep->dwc_ep.maxpacket;
+	}
+	dwords = (len + 3) / 4;
+
+	/* While there is space in the queue and space in the FIFO and
+	 * More data to tranfer, Write packets to the Tx FIFO */
+	txstatus.d32 = DWC_READ_REG32(&global_regs->gnptxsts);
+	DWC_DEBUGPL(DBG_PCDV, "b4 GNPTXSTS=0x%08x\n", txstatus.d32);
+
+	while (txstatus.b.nptxqspcavail > 0 &&
+	       txstatus.b.nptxfspcavail > dwords &&
+	       ep->dwc_ep.xfer_count < ep->dwc_ep.xfer_len) {
+		/* Write the FIFO */
+		dwc_otg_ep_write_packet(core_if, &ep->dwc_ep, 0);
+		len = ep->dwc_ep.xfer_len - ep->dwc_ep.xfer_count;
+
+		if (len > ep->dwc_ep.maxpacket) {
+			len = ep->dwc_ep.maxpacket;
+		}
+
+		dwords = (len + 3) / 4;
+		txstatus.d32 = DWC_READ_REG32(&global_regs->gnptxsts);
+		DWC_DEBUGPL(DBG_PCDV, "GNPTXSTS=0x%08x\n", txstatus.d32);
+	}
+
+	DWC_DEBUGPL(DBG_PCDV, "GNPTXSTS=0x%08x\n",
+		    DWC_READ_REG32(&global_regs->gnptxsts));
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.nptxfempty = 1;
+	DWC_WRITE_REG32(&global_regs->gintsts, gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * This function is called when dedicated Tx FIFO Empty interrupt occurs.
+ * The active request is checked for the next packet to be loaded into
+ * apropriate Tx FIFO.
+ */
+static int32_t write_empty_tx_fifo(dwc_otg_pcd_t * pcd, uint32_t epnum)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	dwc_otg_dev_in_ep_regs_t *ep_regs;
+	dtxfsts_data_t txstatus = {.d32 = 0 };
+	dwc_otg_pcd_ep_t *ep = 0;
+	uint32_t len = 0;
+	int dwords;
+
+	ep = get_in_ep(pcd, epnum);
+
+	DWC_DEBUGPL(DBG_PCD, "Dedicated TxFifo Empty: %d \n", epnum);
+
+	ep_regs = core_if->dev_if->in_ep_regs[epnum];
+
+	len = ep->dwc_ep.xfer_len - ep->dwc_ep.xfer_count;
+
+	if (len > ep->dwc_ep.maxpacket) {
+		len = ep->dwc_ep.maxpacket;
+	}
+
+	dwords = (len + 3) / 4;
+
+	/* While there is space in the queue and space in the FIFO and
+	 * More data to tranfer, Write packets to the Tx FIFO */
+	txstatus.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->dtxfsts);
+	DWC_DEBUGPL(DBG_PCDV, "b4 dtxfsts[%d]=0x%08x\n", epnum, txstatus.d32);
+
+	while (txstatus.b.txfspcavail >= dwords &&
+	       ep->dwc_ep.xfer_count < ep->dwc_ep.xfer_len &&
+	       ep->dwc_ep.xfer_len != 0) {
+		/* Write the FIFO */
+		dwc_otg_ep_write_packet(core_if, &ep->dwc_ep, 0);
+
+		len = ep->dwc_ep.xfer_len - ep->dwc_ep.xfer_count;
+		if (len > ep->dwc_ep.maxpacket) {
+			len = ep->dwc_ep.maxpacket;
+		}
+
+		dwords = (len + 3) / 4;
+		txstatus.d32 =
+		    DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->dtxfsts);
+		DWC_DEBUGPL(DBG_PCDV, "dtxfsts[%d]=0x%08x\n", epnum,
+			    txstatus.d32);
+	}
+
+	DWC_DEBUGPL(DBG_PCDV, "b4 dtxfsts[%d]=0x%08x\n", epnum,
+		    DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->dtxfsts));
+
+	return 1;
+}
+
+/**
+ * This function is called when the Device is disconnected. It stops
+ * any active requests and informs the Gadget driver of the
+ * disconnect.
+ */
+void dwc_otg_pcd_stop(dwc_otg_pcd_t * pcd)
+{
+	int i, num_in_eps, num_out_eps;
+	dwc_otg_pcd_ep_t *ep;
+
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+
+	DWC_SPINLOCK(pcd->lock);
+
+	num_in_eps = GET_CORE_IF(pcd)->dev_if->num_in_eps;
+	num_out_eps = GET_CORE_IF(pcd)->dev_if->num_out_eps;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s() \n", __func__);
+	/* don't disconnect drivers more than once */
+	if (pcd->ep0state == EP0_DISCONNECT) {
+		DWC_DEBUGPL(DBG_ANY, "%s() Already Disconnected\n", __func__);
+		DWC_SPINUNLOCK(pcd->lock);
+		return;
+	}
+	pcd->ep0state = EP0_DISCONNECT;
+
+	/* Reset the OTG state. */
+	dwc_otg_pcd_update_otg(pcd, 1);
+
+	/* Disable the NP Tx Fifo Empty Interrupt. */
+	intr_mask.b.nptxfempty = 1;
+	DWC_MODIFY_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintmsk,
+			 intr_mask.d32, 0);
+
+	/* Flush the FIFOs */
+	/**@todo NGS Flush Periodic FIFOs */
+	dwc_otg_flush_tx_fifo(GET_CORE_IF(pcd), 0x10);
+	dwc_otg_flush_rx_fifo(GET_CORE_IF(pcd));
+
+	/* prevent new request submissions, kill any outstanding requests  */
+	ep = &pcd->ep0;
+	dwc_otg_request_nuke(ep);
+	/* prevent new request submissions, kill any outstanding requests  */
+	for (i = 0; i < num_in_eps; i++) {
+		dwc_otg_pcd_ep_t *ep = &pcd->in_ep[i];
+		dwc_otg_request_nuke(ep);
+	}
+	/* prevent new request submissions, kill any outstanding requests  */
+	for (i = 0; i < num_out_eps; i++) {
+		dwc_otg_pcd_ep_t *ep = &pcd->out_ep[i];
+		dwc_otg_request_nuke(ep);
+	}
+
+	/* report disconnect; the driver is already quiesced */
+	if (pcd->fops->disconnect) {
+		DWC_SPINUNLOCK(pcd->lock);
+		pcd->fops->disconnect(pcd);
+		DWC_SPINLOCK(pcd->lock);
+	}
+	DWC_SPINUNLOCK(pcd->lock);
+}
+
+/**
+ * This interrupt indicates that ...
+ */
+int32_t dwc_otg_pcd_handle_i2c_intr(dwc_otg_pcd_t * pcd)
+{
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+	gintsts_data_t gintsts;
+
+	DWC_PRINTF("INTERRUPT Handler not implemented for %s\n", "i2cintr");
+	intr_mask.b.i2cintr = 1;
+	DWC_MODIFY_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintmsk,
+			 intr_mask.d32, 0);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.i2cintr = 1;
+	DWC_WRITE_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintsts,
+			gintsts.d32);
+	return 1;
+}
+
+/**
+ * This interrupt indicates that ...
+ */
+int32_t dwc_otg_pcd_handle_early_suspend_intr(dwc_otg_pcd_t * pcd)
+{
+	gintsts_data_t gintsts;
+
+	DWC_DEBUGPL(DBG_PCDV,"Early Suspend Detected\n");
+
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.erlysuspend = 1;
+	DWC_WRITE_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintsts,
+			gintsts.d32);
+
+	DWC_SPINUNLOCK(GET_CORE_IF(pcd)->lock);
+	cil_pcd_stop(GET_CORE_IF(pcd));
+	DWC_SPINLOCK(GET_CORE_IF(pcd)->lock);
+
+	return 1;
+}
+
+/**
+ * This function configures EPO to receive SETUP packets.
+ *
+ * @todo NGS: Update the comments from the HW FS.
+ *
+ *	-# Program the following fields in the endpoint specific registers
+ *	for Control OUT EP 0, in order to receive a setup packet
+ *	- DOEPTSIZ0.Packet Count = 3 (To receive up to 3 back to back
+ *	  setup packets)
+ *	- DOEPTSIZE0.Transfer Size = 24 Bytes (To receive up to 3 back
+ *	  to back setup packets)
+ *		- In DMA mode, DOEPDMA0 Register with a memory address to
+ *		  store any setup packets received
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param pcd	  Programming view of the PCD.
+ */
+static inline void ep0_out_start(dwc_otg_core_if_t * core_if,
+				 dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	deptsiz0_data_t doeptsize0 = {.d32 = 0 };
+	dwc_otg_dev_dma_desc_t *dma_desc;
+	depctl_data_t doepctl = {.d32 = 0 };
+
+#ifdef VERBOSE
+	DWC_DEBUGPL(DBG_PCDV, "%s() doepctl0=%0x\n", __func__,
+		    DWC_READ_REG32(&dev_if->out_ep_regs[0]->doepctl));
+#endif
+	if (core_if->snpsid >= OTG_CORE_REV_3_00a) {
+		doepctl.d32 = DWC_READ_REG32(&dev_if->out_ep_regs[0]->doepctl);
+		if (doepctl.b.epena) {
+			return;
+		}
+	}
+
+	doeptsize0.b.supcnt = 3;
+	doeptsize0.b.pktcnt = 1;
+	doeptsize0.b.xfersize = 8 * 3;
+
+	if (core_if->dma_enable) {
+		if (!core_if->dma_desc_enable) {
+			/** put here as for Hermes mode deptisz register should not be written */
+			DWC_WRITE_REG32(&dev_if->out_ep_regs[0]->doeptsiz,
+					doeptsize0.d32);
+
+			/** @todo dma needs to handle multiple setup packets (up to 3) */
+			DWC_WRITE_REG32(&dev_if->out_ep_regs[0]->doepdma,
+					pcd->setup_pkt_dma_handle);
+		} else {
+			dev_if->setup_desc_index =
+			    (dev_if->setup_desc_index + 1) & 1;
+			dma_desc =
+			    dev_if->setup_desc_addr[dev_if->setup_desc_index];
+
+			/** DMA Descriptor Setup */
+			dma_desc->status.b.bs = BS_HOST_BUSY;
+			if (core_if->snpsid >= OTG_CORE_REV_3_00a) {
+				dma_desc->status.b.sr = 0;
+				dma_desc->status.b.mtrf = 0;
+			}
+			dma_desc->status.b.l = 1;
+			dma_desc->status.b.ioc = 1;
+			dma_desc->status.b.bytes = pcd->ep0.dwc_ep.maxpacket;
+			dma_desc->buf = pcd->setup_pkt_dma_handle;
+			dma_desc->status.b.sts = 0;
+			dma_desc->status.b.bs = BS_HOST_READY;
+
+			/** DOEPDMA0 Register write */
+			DWC_WRITE_REG32(&dev_if->out_ep_regs[0]->doepdma,
+					dev_if->dma_setup_desc_addr
+					[dev_if->setup_desc_index]);
+		}
+
+	} else {
+		/** put here as for Hermes mode deptisz register should not be written */
+		DWC_WRITE_REG32(&dev_if->out_ep_regs[0]->doeptsiz,
+				doeptsize0.d32);
+	}
+
+	/** DOEPCTL0 Register write cnak will be set after setup interrupt */
+	doepctl.d32 = 0;
+	doepctl.b.epena = 1;
+	if (core_if->snpsid <= OTG_CORE_REV_2_94a) {
+		doepctl.b.cnak = 1;
+		DWC_WRITE_REG32(&dev_if->out_ep_regs[0]->doepctl, doepctl.d32);
+	} else {
+		DWC_MODIFY_REG32(&dev_if->out_ep_regs[0]->doepctl, 0, doepctl.d32);
+	}
+
+#ifdef VERBOSE
+	DWC_DEBUGPL(DBG_PCDV, "doepctl0=%0x\n",
+		    DWC_READ_REG32(&dev_if->out_ep_regs[0]->doepctl));
+	DWC_DEBUGPL(DBG_PCDV, "diepctl0=%0x\n",
+		    DWC_READ_REG32(&dev_if->in_ep_regs[0]->diepctl));
+#endif
+}
+
+/**
+ * This interrupt occurs when a USB Reset is detected. When the USB
+ * Reset Interrupt occurs the device state is set to DEFAULT and the
+ * EP0 state is set to IDLE.
+ *	-#	Set the NAK bit for all OUT endpoints (DOEPCTLn.SNAK = 1)
+ *	-#	Unmask the following interrupt bits
+ *		- DAINTMSK.INEP0 = 1 (Control 0 IN endpoint)
+ *	- DAINTMSK.OUTEP0 = 1 (Control 0 OUT endpoint)
+ *	- DOEPMSK.SETUP = 1
+ *	- DOEPMSK.XferCompl = 1
+ *	- DIEPMSK.XferCompl = 1
+ *	- DIEPMSK.TimeOut = 1
+ *	-# Program the following fields in the endpoint specific registers
+ *	for Control OUT EP 0, in order to receive a setup packet
+ *	- DOEPTSIZ0.Packet Count = 3 (To receive up to 3 back to back
+ *	  setup packets)
+ *	- DOEPTSIZE0.Transfer Size = 24 Bytes (To receive up to 3 back
+ *	  to back setup packets)
+ *		- In DMA mode, DOEPDMA0 Register with a memory address to
+ *		  store any setup packets received
+ * At this point, all the required initialization, except for enabling
+ * the control 0 OUT endpoint is done, for receiving SETUP packets.
+ */
+int32_t dwc_otg_pcd_handle_usb_reset_intr(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	depctl_data_t doepctl = {.d32 = 0 };
+	depctl_data_t diepctl = {.d32 = 0 };
+	daint_data_t daintmsk = {.d32 = 0 };
+	doepmsk_data_t doepmsk = {.d32 = 0 };
+	diepmsk_data_t diepmsk = {.d32 = 0 };
+	dcfg_data_t dcfg = {.d32 = 0 };
+	grstctl_t resetctl = {.d32 = 0 };
+	dctl_data_t dctl = {.d32 = 0 };
+	int i = 0;
+	gintsts_data_t gintsts;
+	pcgcctl_data_t power = {.d32 = 0 };
+
+	power.d32 = DWC_READ_REG32(core_if->pcgcctl);
+	if (power.b.stoppclk) {
+		power.d32 = 0;
+		power.b.stoppclk = 1;
+		DWC_MODIFY_REG32(core_if->pcgcctl, power.d32, 0);
+
+		power.b.pwrclmp = 1;
+		DWC_MODIFY_REG32(core_if->pcgcctl, power.d32, 0);
+
+		power.b.rstpdwnmodule = 1;
+		DWC_MODIFY_REG32(core_if->pcgcctl, power.d32, 0);
+	}
+
+	core_if->lx_state = DWC_OTG_L0;
+	core_if->otg_sts = 0;
+
+
+#ifdef DWC_EN_ISOC
+	for (i = 1; i < 16; ++i) {
+		dwc_otg_pcd_ep_t *ep;
+		dwc_ep_t *dwc_ep;
+		ep = get_in_ep(pcd, i);
+		if (ep != 0) {
+			dwc_ep = &ep->dwc_ep;
+			dwc_ep->next_frame = 0xffffffff;
+		}
+	}
+#endif /* DWC_EN_ISOC */
+
+	/* reset the HNP settings */
+	dwc_otg_pcd_update_otg(pcd, 1);
+
+	/* Clear the Remote Wakeup Signalling */
+	dctl.b.rmtwkupsig = 1;
+	DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl, dctl.d32, 0);
+
+	/* Set NAK for all OUT EPs */
+	doepctl.b.snak = 1;
+	for (i = 0; i <= dev_if->num_out_eps; i++) {
+		DWC_WRITE_REG32(&dev_if->out_ep_regs[i]->doepctl, doepctl.d32);
+	}
+
+	/* Flush the NP Tx FIFO */
+	dwc_otg_flush_tx_fifo(core_if, 0x10);
+	/* Flush the Learning Queue */
+	resetctl.b.intknqflsh = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->grstctl, resetctl.d32);
+
+	if (!core_if->core_params->en_multiple_tx_fifo && core_if->dma_enable) {
+		core_if->start_predict = 0;
+		for (i = 0; i <= core_if->dev_if->num_in_eps; ++i) {
+			core_if->nextep_seq[i] = 0xff;	// 0xff - EP not active
+		}
+		core_if->nextep_seq[0] = 0;
+		core_if->first_in_nextep_seq = 0;
+		diepctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[0]->diepctl);
+		diepctl.b.nextep = 0;
+		DWC_WRITE_REG32(&dev_if->in_ep_regs[0]->diepctl, diepctl.d32);
+
+		/* Update IN Endpoint Mismatch Count by active IN NP EP count + 1 */
+		dcfg.d32 = DWC_READ_REG32(&dev_if->dev_global_regs->dcfg);
+		dcfg.b.epmscnt = 2;
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->dcfg, dcfg.d32);
+
+		DWC_DEBUGPL(DBG_PCDV,
+			    "%s first_in_nextep_seq= %2d; nextep_seq[]:\n",
+			    __func__, core_if->first_in_nextep_seq);
+		for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+			DWC_DEBUGPL(DBG_PCDV, "%2d\n", core_if->nextep_seq[i]);
+		}
+	}
+
+	if (core_if->multiproc_int_enable) {
+		daintmsk.b.inep0 = 1;
+		daintmsk.b.outep0 = 1;
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->deachintmsk,
+				daintmsk.d32);
+
+		doepmsk.b.setup = 1;
+		doepmsk.b.xfercompl = 1;
+		doepmsk.b.ahberr = 1;
+		doepmsk.b.epdisabled = 1;
+
+		if ((core_if->dma_desc_enable) ||
+		    (core_if->dma_enable
+		     && core_if->snpsid >= OTG_CORE_REV_3_00a)) {
+			doepmsk.b.stsphsercvd = 1;
+		}
+		if (core_if->dma_desc_enable)
+			doepmsk.b.bna = 1;
+/*
+		doepmsk.b.babble = 1;
+		doepmsk.b.nyet = 1;
+
+		if (core_if->dma_enable) {
+			doepmsk.b.nak = 1;
+		}
+*/
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->doepeachintmsk[0],
+				doepmsk.d32);
+
+		diepmsk.b.xfercompl = 1;
+		diepmsk.b.timeout = 1;
+		diepmsk.b.epdisabled = 1;
+		diepmsk.b.ahberr = 1;
+		diepmsk.b.intknepmis = 1;
+		if (!core_if->en_multiple_tx_fifo && core_if->dma_enable)
+			diepmsk.b.intknepmis = 0;
+
+/*		if (core_if->dma_desc_enable) {
+			diepmsk.b.bna = 1;
+		}
+*/
+/*
+		if (core_if->dma_enable) {
+			diepmsk.b.nak = 1;
+		}
+*/
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->diepeachintmsk[0],
+				diepmsk.d32);
+	} else {
+		daintmsk.b.inep0 = 1;
+		daintmsk.b.outep0 = 1;
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->daintmsk,
+				daintmsk.d32);
+
+		doepmsk.b.setup = 1;
+		doepmsk.b.xfercompl = 1;
+		doepmsk.b.ahberr = 1;
+		doepmsk.b.epdisabled = 1;
+
+		if ((core_if->dma_desc_enable) ||
+		    (core_if->dma_enable
+		     && core_if->snpsid >= OTG_CORE_REV_3_00a)) {
+			doepmsk.b.stsphsercvd = 1;
+		}
+		if (core_if->dma_desc_enable)
+			doepmsk.b.bna = 1;
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->doepmsk, doepmsk.d32);
+
+		diepmsk.b.xfercompl = 1;
+		diepmsk.b.timeout = 1;
+		diepmsk.b.epdisabled = 1;
+		diepmsk.b.ahberr = 1;
+		if (!core_if->en_multiple_tx_fifo && core_if->dma_enable)
+			diepmsk.b.intknepmis = 0;
+/*
+		if (core_if->dma_desc_enable) {
+			diepmsk.b.bna = 1;
+		}
+*/
+
+		DWC_WRITE_REG32(&dev_if->dev_global_regs->diepmsk, diepmsk.d32);
+	}
+
+	/* Reset Device Address */
+	dcfg.d32 = DWC_READ_REG32(&dev_if->dev_global_regs->dcfg);
+	dcfg.b.devaddr = 0;
+	DWC_WRITE_REG32(&dev_if->dev_global_regs->dcfg, dcfg.d32);
+
+	/* setup EP0 to receive SETUP packets */
+	if (core_if->snpsid <= OTG_CORE_REV_2_94a)
+		ep0_out_start(core_if, pcd);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.usbreset = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * Get the device speed from the device status register and convert it
+ * to USB speed constant.
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ */
+static int get_device_speed(dwc_otg_core_if_t * core_if)
+{
+	dsts_data_t dsts;
+	int speed = 0;
+	dsts.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dsts);
+
+	switch (dsts.b.enumspd) {
+	case DWC_DSTS_ENUMSPD_HS_PHY_30MHZ_OR_60MHZ:
+		speed = USB_SPEED_HIGH;
+		break;
+	case DWC_DSTS_ENUMSPD_FS_PHY_30MHZ_OR_60MHZ:
+	case DWC_DSTS_ENUMSPD_FS_PHY_48MHZ:
+		speed = USB_SPEED_FULL;
+		break;
+
+	case DWC_DSTS_ENUMSPD_LS_PHY_6MHZ:
+		speed = USB_SPEED_LOW;
+		break;
+	}
+
+	return speed;
+}
+
+/**
+ * Read the device status register and set the device speed in the
+ * data structure.
+ * Set up EP0 to receive SETUP packets by calling dwc_ep0_activate.
+ */
+int32_t dwc_otg_pcd_handle_enum_done_intr(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_pcd_ep_t *ep0 = &pcd->ep0;
+	gintsts_data_t gintsts;
+	gusbcfg_data_t gusbcfg;
+	dwc_otg_core_global_regs_t *global_regs =
+	    GET_CORE_IF(pcd)->core_global_regs;
+	uint8_t utmi16b, utmi8b;
+	int speed;
+	dcfg_data_t dcfg;
+
+	DWC_DEBUGPL(DBG_PCD, "SPEED ENUM\n");
+
+	/* WA for the case when SW gets SPEED ENUM without first USB RESET case
+	* due to USB RESET issued by the host earlier. Anyways USB Reset routine
+	* needs to be called to at least program EP 0 OUT - vahrama
+	*/
+	dcfg.d32 = DWC_READ_REG32(&pcd->core_if->dev_if->dev_global_regs->dcfg);
+	if (pcd->core_if->otg_ver && dcfg.b.devaddr)
+		dwc_otg_pcd_handle_usb_reset_intr(pcd);
+
+
+	if (GET_CORE_IF(pcd)->snpsid >= OTG_CORE_REV_2_60a) {
+		utmi16b = 6;	//vahrama old value was 6;
+		utmi8b = 9;
+	} else {
+		utmi16b = 4;
+		utmi8b = 8;
+	}
+	dwc_otg_ep0_activate(GET_CORE_IF(pcd), &ep0->dwc_ep);
+	if (GET_CORE_IF(pcd)->snpsid >= OTG_CORE_REV_3_00a) {
+		ep0_out_start(GET_CORE_IF(pcd), pcd);
+	}
+
+#ifdef DEBUG_EP0
+	print_ep0_state(pcd);
+#endif
+
+	if (pcd->ep0state == EP0_DISCONNECT) {
+		pcd->ep0state = EP0_IDLE;
+	} else if (pcd->ep0state == EP0_STALL) {
+		pcd->ep0state = EP0_IDLE;
+	}
+
+	pcd->ep0state = EP0_IDLE;
+
+	ep0->stopped = 0;
+
+	speed = get_device_speed(GET_CORE_IF(pcd));
+	pcd->fops->connect(pcd, speed);
+
+	/* Set USB turnaround time based on device speed and PHY interface. */
+	gusbcfg.d32 = DWC_READ_REG32(&global_regs->gusbcfg);
+	if (speed == USB_SPEED_HIGH) {
+		if (GET_CORE_IF(pcd)->hwcfg2.b.hs_phy_type ==
+		    DWC_HWCFG2_HS_PHY_TYPE_ULPI) {
+			/* ULPI interface */
+			gusbcfg.b.usbtrdtim = 9;
+		}
+		if (GET_CORE_IF(pcd)->hwcfg2.b.hs_phy_type ==
+		    DWC_HWCFG2_HS_PHY_TYPE_UTMI) {
+			/* UTMI+ interface */
+			if (GET_CORE_IF(pcd)->hwcfg4.b.utmi_phy_data_width == 0) {
+				gusbcfg.b.usbtrdtim = utmi8b;
+			} else if (GET_CORE_IF(pcd)->hwcfg4.
+				   b.utmi_phy_data_width == 1) {
+				gusbcfg.b.usbtrdtim = utmi16b;
+			} else if (GET_CORE_IF(pcd)->
+				   core_params->phy_utmi_width == 8) {
+				gusbcfg.b.usbtrdtim = utmi8b;
+			} else {
+				gusbcfg.b.usbtrdtim = utmi16b;
+			}
+		}
+		if (GET_CORE_IF(pcd)->hwcfg2.b.hs_phy_type ==
+		    DWC_HWCFG2_HS_PHY_TYPE_UTMI_ULPI) {
+			/* UTMI+  OR  ULPI interface */
+			if (gusbcfg.b.ulpi_utmi_sel == 1) {
+				/* ULPI interface */
+				gusbcfg.b.usbtrdtim = 9;
+			} else {
+				/* UTMI+ interface */
+				if (GET_CORE_IF(pcd)->
+				    core_params->phy_utmi_width == 16) {
+					gusbcfg.b.usbtrdtim = utmi16b;
+				} else {
+					gusbcfg.b.usbtrdtim = utmi8b;
+				}
+			}
+		}
+	} else {
+		/* Full or low speed */
+		gusbcfg.b.usbtrdtim = 9;
+	}
+	DWC_WRITE_REG32(&global_regs->gusbcfg, gusbcfg.d32);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.enumdone = 1;
+	DWC_WRITE_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintsts,
+			gintsts.d32);
+	return 1;
+}
+
+/**
+ * This interrupt indicates that the ISO OUT Packet was dropped due to
+ * Rx FIFO full or Rx Status Queue Full.  If this interrupt occurs
+ * read all the data from the Rx FIFO.
+ */
+int32_t dwc_otg_pcd_handle_isoc_out_packet_dropped_intr(dwc_otg_pcd_t * pcd)
+{
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+	gintsts_data_t gintsts;
+
+	DWC_WARN("INTERRUPT Handler not implemented for %s\n",
+		 "ISOC Out Dropped");
+
+	intr_mask.b.isooutdrop = 1;
+	DWC_MODIFY_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintmsk,
+			 intr_mask.d32, 0);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.isooutdrop = 1;
+	DWC_WRITE_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintsts,
+			gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * This interrupt indicates the end of the portion of the micro-frame
+ * for periodic transactions.  If there is a periodic transaction for
+ * the next frame, load the packets into the EP periodic Tx FIFO.
+ */
+int32_t dwc_otg_pcd_handle_end_periodic_frame_intr(dwc_otg_pcd_t * pcd)
+{
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+	gintsts_data_t gintsts;
+	DWC_PRINTF("INTERRUPT Handler not implemented for %s\n", "EOP");
+
+	intr_mask.b.eopframe = 1;
+	DWC_MODIFY_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintmsk,
+			 intr_mask.d32, 0);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.eopframe = 1;
+	DWC_WRITE_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintsts,
+			gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * This interrupt indicates that EP of the packet on the top of the
+ * non-periodic Tx FIFO does not match EP of the IN Token received.
+ *
+ * The "Device IN Token Queue" Registers are read to determine the
+ * order the IN Tokens have been received. The non-periodic Tx FIFO
+ * is flushed, so it can be reloaded in the order seen in the IN Token
+ * Queue.
+ */
+int32_t dwc_otg_pcd_handle_ep_mismatch_intr(dwc_otg_pcd_t * pcd)
+{
+	gintsts_data_t gintsts;
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dctl_data_t dctl;
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+
+	if (!core_if->en_multiple_tx_fifo && core_if->dma_enable) {
+		core_if->start_predict = 1;
+
+		DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, core_if);
+
+		gintsts.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintsts);
+		if (!gintsts.b.ginnakeff) {
+			/* Disable EP Mismatch interrupt */
+			intr_mask.d32 = 0;
+			intr_mask.b.epmismatch = 1;
+			DWC_MODIFY_REG32(&core_if->core_global_regs->gintmsk, intr_mask.d32, 0);
+			/* Enable the Global IN NAK Effective Interrupt */
+			intr_mask.d32 = 0;
+			intr_mask.b.ginnakeff = 1;
+			DWC_MODIFY_REG32(&core_if->core_global_regs->gintmsk, 0, intr_mask.d32);
+			/* Set the global non-periodic IN NAK handshake */
+			dctl.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dctl);
+			dctl.b.sgnpinnak = 1;
+			DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dctl, dctl.d32);
+		} else {
+			DWC_PRINTF("gintsts.b.ginnakeff = 1! dctl.b.sgnpinnak not set\n");
+		}
+		/* Disabling of all EP's will be done in dwc_otg_pcd_handle_in_nak_effective()
+		 * handler after Global IN NAK Effective interrupt will be asserted */
+	}
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.epmismatch = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * This interrupt is valid only in DMA mode. This interrupt indicates that the
+ * core has stopped fetching data for IN endpoints due to the unavailability of
+ * TxFIFO space or Request Queue space. This interrupt is used by the
+ * application for an endpoint mismatch algorithm.
+ *
+ * @param pcd The PCD
+ */
+int32_t dwc_otg_pcd_handle_ep_fetsusp_intr(dwc_otg_pcd_t * pcd)
+{
+	gintsts_data_t gintsts;
+	gintmsk_data_t gintmsk_data;
+	dctl_data_t dctl;
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, core_if);
+
+	/* Clear the global non-periodic IN NAK handshake */
+	dctl.d32 = 0;
+	dctl.b.cgnpinnak = 1;
+	DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->dctl, dctl.d32, dctl.d32);
+
+	/* Mask GINTSTS.FETSUSP interrupt */
+	gintmsk_data.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintmsk);
+	gintmsk_data.b.fetsusp = 0;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintmsk, gintmsk_data.d32);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.fetsusp = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->gintsts, gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * This funcion stalls EP0.
+ */
+static inline void ep0_do_stall(dwc_otg_pcd_t * pcd, const int err_val)
+{
+	dwc_otg_pcd_ep_t *ep0 = &pcd->ep0;
+//	usb_device_request_t *ctrl = &pcd->setup_pkt->req;
+//	DWC_WARN("req %02x.%02x protocol STALL; err %d\n",
+//		 ctrl->bmRequestType, ctrl->bRequest, err_val);
+
+	ep0->dwc_ep.is_in = 1;
+	dwc_otg_ep_set_stall(GET_CORE_IF(pcd), &ep0->dwc_ep);
+	ep0->dwc_ep.is_in = 0;
+    dwc_otg_ep_set_stall(GET_CORE_IF(pcd), &ep0->dwc_ep);
+	pcd->ep0.stopped = 1;
+	pcd->ep0state = EP0_IDLE;
+	ep0_out_start(GET_CORE_IF(pcd), pcd);
+}
+
+/**
+ * This functions delegates the setup command to the gadget driver.
+ */
+static inline void do_gadget_setup(dwc_otg_pcd_t * pcd,
+				   usb_device_request_t * ctrl)
+{
+	int ret = 0;
+	DWC_SPINUNLOCK(pcd->lock);
+	ret = pcd->fops->setup(pcd, (uint8_t *) ctrl);
+	DWC_SPINLOCK(pcd->lock);
+	if (ret < 0) {
+		ep0_do_stall(pcd, ret);
+	}
+
+	/** @todo This is a g_file_storage gadget driver specific
+	 * workaround: a DELAYED_STATUS result from the fsg_setup
+	 * routine will result in the gadget queueing a EP0 IN status
+	 * phase for a two-stage control transfer. Exactly the same as
+	 * a SET_CONFIGURATION/SET_INTERFACE except that this is a class
+	 * specific request.  Need a generic way to know when the gadget
+	 * driver will queue the status phase. Can we assume when we
+	 * call the gadget driver setup() function that it will always
+	 * queue and require the following flag? Need to look into
+	 * this.
+	 */
+
+	if (ret == 256 + 999) {
+		pcd->request_config = 1;
+	}
+}
+
+#ifdef DWC_UTE_CFI
+/**
+ * This functions delegates the CFI setup commands to the gadget driver.
+ * This function will return a negative value to indicate a failure.
+ */
+static inline int cfi_gadget_setup(dwc_otg_pcd_t * pcd,
+				   struct cfi_usb_ctrlrequest *ctrl_req)
+{
+	int ret = 0;
+
+	if (pcd->fops && pcd->fops->cfi_setup) {
+		DWC_SPINUNLOCK(pcd->lock);
+		ret = pcd->fops->cfi_setup(pcd, ctrl_req);
+		DWC_SPINLOCK(pcd->lock);
+		if (ret < 0) {
+			ep0_do_stall(pcd, ret);
+			return ret;
+		}
+	}
+
+	return ret;
+}
+#endif
+
+/**
+ * This function starts the Zero-Length Packet for the IN status phase
+ * of a 2 stage control transfer.
+ */
+static inline void do_setup_in_status_phase(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_pcd_ep_t *ep0 = &pcd->ep0;
+	if (pcd->ep0state == EP0_STALL) {
+		return;
+	}
+
+	pcd->ep0state = EP0_IN_STATUS_PHASE;
+
+	/* Prepare for more SETUP Packets */
+	DWC_DEBUGPL(DBG_PCD, "EP0 IN ZLP\n");
+	if ((GET_CORE_IF(pcd)->snpsid >= OTG_CORE_REV_3_00a)
+	    && (pcd->core_if->dma_desc_enable)
+	    && (ep0->dwc_ep.xfer_count < ep0->dwc_ep.total_len)) {
+		DWC_DEBUGPL(DBG_PCDV,
+			    "Data terminated wait next packet in out_desc_addr\n");
+		pcd->backup_buf = phys_to_virt(ep0->dwc_ep.dma_addr);
+		pcd->data_terminated = 1;
+	}
+	ep0->dwc_ep.xfer_len = 0;
+	ep0->dwc_ep.xfer_count = 0;
+	ep0->dwc_ep.is_in = 1;
+	ep0->dwc_ep.dma_addr = pcd->setup_pkt_dma_handle;
+	dwc_otg_ep0_start_transfer(GET_CORE_IF(pcd), &ep0->dwc_ep);
+
+	/* Prepare for more SETUP Packets */
+	//ep0_out_start(GET_CORE_IF(pcd), pcd);
+}
+
+/**
+ * This function starts the Zero-Length Packet for the OUT status phase
+ * of a 2 stage control transfer.
+ */
+static inline void do_setup_out_status_phase(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_pcd_ep_t *ep0 = &pcd->ep0;
+	doepint_data_t doepint;
+	doepint.d32 = DWC_READ_REG32(&pcd->core_if->dev_if->out_ep_regs[0]->doepint);
+	if (pcd->ep0state == EP0_STALL) {
+		DWC_DEBUGPL(DBG_PCD, "EP0 STALLED\n");
+		return;
+	}
+	pcd->ep0state = EP0_OUT_STATUS_PHASE;
+
+	DWC_DEBUGPL(DBG_PCD, "EP0 OUT ZLP\n");
+	ep0->dwc_ep.xfer_len = 0;
+	ep0->dwc_ep.xfer_count = 0;
+	ep0->dwc_ep.is_in = 0;
+	ep0->dwc_ep.dma_addr = pcd->setup_pkt_dma_handle;
+	/* If there is xfercomplete on EP0 OUT do not start OUT Status stage.
+	 * xfercomplete means that ZLP was already received as EP0 OUT is enabled
+	 * during IN Data stage
+	 */
+	if ((doepint.b.xfercompl == 1) && (pcd->core_if->snpsid >= OTG_CORE_REV_3_00a)
+	    && (pcd->core_if->dma_enable == 1) && (pcd->core_if->dma_desc_enable == 0)) {
+		DWC_DEBUGPL(DBG_PCD, "Status stage already completed\n");
+		return;
+	}
+
+	dwc_otg_ep0_start_transfer(GET_CORE_IF(pcd), &ep0->dwc_ep);
+
+	/* Prepare for more SETUP Packets */
+	if (GET_CORE_IF(pcd)->dma_enable == 0) {
+		ep0_out_start(GET_CORE_IF(pcd), pcd);
+	}
+}
+
+/**
+ * Clear the EP halt (STALL) and if pending requests start the
+ * transfer.
+ */
+static inline void pcd_clear_halt(dwc_otg_pcd_t * pcd, dwc_otg_pcd_ep_t * ep)
+{
+	if (ep->dwc_ep.stall_clear_flag) {
+		/* Start Control Status Phase */
+		do_setup_in_status_phase(pcd);
+		return;
+	}
+
+	dwc_otg_ep_clear_stall(GET_CORE_IF(pcd), &ep->dwc_ep);
+
+	/* Reactive the EP */
+	dwc_otg_ep_activate(GET_CORE_IF(pcd), &ep->dwc_ep);
+	if (ep->stopped) {
+		ep->stopped = 0;
+		/* If there is a request in the EP queue start it */
+
+		/** @todo FIXME: this causes an EP mismatch in DMA mode.
+		 * epmismatch not yet implemented. */
+
+		/*
+		 * Above fixme is solved by implmenting a tasklet to call the
+		 * start_next_request(), outside of interrupt context at some
+		 * time after the current time, after a clear-halt setup packet.
+		 * Still need to implement ep mismatch in the future if a gadget
+		 * ever uses more than one endpoint at once
+		 */
+		ep->queue_sof = 1;
+		DWC_TASK_SCHEDULE(pcd->start_xfer_tasklet);
+	}
+	/* Start Control Status Phase */
+	do_setup_in_status_phase(pcd);
+}
+
+/**
+ * This function is called when the SET_FEATURE TEST_MODE Setup packet
+ * is sent from the host.  The Device Control register is written with
+ * the Test Mode bits set to the specified Test Mode.  This is done as
+ * a tasklet so that the "Status" phase of the control transfer
+ * completes before transmitting the TEST packets.
+ *
+ * @todo This has not been tested since the tasklet struct was put
+ * into the PCD struct!
+ *
+ */
+void do_test_mode(void *data)
+{
+	dctl_data_t dctl;
+	dwc_otg_pcd_t *pcd = (dwc_otg_pcd_t *) data;
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	int test_mode = pcd->test_mode;
+
+//        DWC_WARN("%s() has not been tested since being rewritten!\n", __func__);
+
+	dctl.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dctl);
+	switch (test_mode) {
+	case 1:		// TEST_J
+		dctl.b.tstctl = 1;
+		break;
+
+	case 2:		// TEST_K
+		dctl.b.tstctl = 2;
+		break;
+
+	case 3:		// TEST_SE0_NAK
+		dctl.b.tstctl = 3;
+		break;
+
+	case 4:		// TEST_PACKET
+		dctl.b.tstctl = 4;
+		break;
+
+	case 5:		// TEST_FORCE_ENABLE
+		dctl.b.tstctl = 5;
+		break;
+	case 7:
+		dwc_otg_set_hnpreq(core_if, 1);
+	}
+	DWC_PRINTF("test mode = %d\n",test_mode);
+	core_if->test_mode = test_mode;
+	DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dctl, dctl.d32);
+}
+
+/**
+ * This function process the GET_STATUS Setup Commands.
+ */
+static inline void do_get_status(dwc_otg_pcd_t * pcd)
+{
+	usb_device_request_t ctrl = pcd->setup_pkt->req;
+	dwc_otg_pcd_ep_t *ep;
+	dwc_otg_pcd_ep_t *ep0 = &pcd->ep0;
+	uint16_t *status = pcd->status_buf;
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+
+#ifdef DEBUG_EP0
+	DWC_DEBUGPL(DBG_PCD,
+		    "GET_STATUS %02x.%02x v%04x i%04x l%04x\n",
+		    ctrl.bmRequestType, ctrl.bRequest,
+		    UGETW(ctrl.wValue), UGETW(ctrl.wIndex),
+		    UGETW(ctrl.wLength));
+#endif
+
+	switch (UT_GET_RECIPIENT(ctrl.bmRequestType)) {
+	case UT_DEVICE:
+		if (UGETW(ctrl.wIndex) == 0xF000) {	/* OTG Status selector */
+			DWC_PRINTF("wIndex - %d\n", UGETW(ctrl.wIndex));
+			DWC_PRINTF("OTG VERSION - %d\n", core_if->otg_ver);
+			DWC_PRINTF("OTG CAP - %d, %d\n",
+				   core_if->core_params->otg_cap,
+				   DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE);
+			if (core_if->otg_ver == 1
+			    && core_if->core_params->otg_cap ==
+			    DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE) {
+				uint8_t *otgsts = (uint8_t *) pcd->status_buf;
+				*otgsts = (core_if->otg_sts & 0x1);
+				pcd->ep0_pending = 1;
+				ep0->dwc_ep.start_xfer_buff =
+				    (uint8_t *) otgsts;
+				ep0->dwc_ep.xfer_buff = (uint8_t *) otgsts;
+				ep0->dwc_ep.dma_addr =
+				    pcd->status_buf_dma_handle;
+				ep0->dwc_ep.xfer_len = 1;
+				ep0->dwc_ep.xfer_count = 0;
+				ep0->dwc_ep.total_len = ep0->dwc_ep.xfer_len;
+				dwc_otg_ep0_start_transfer(GET_CORE_IF(pcd),
+							   &ep0->dwc_ep);
+				return;
+			} else {
+				ep0_do_stall(pcd, -DWC_E_NOT_SUPPORTED);
+				return;
+			}
+			break;
+		} else {
+			*status = 0x1;	/* Self powered */
+			*status |= pcd->remote_wakeup_enable << 1;
+			break;
+		}
+	case UT_INTERFACE:
+		*status = 0;
+		break;
+
+	case UT_ENDPOINT:
+		ep = get_ep_by_addr(pcd, UGETW(ctrl.wIndex));
+		if (ep == 0 || UGETW(ctrl.wLength) > 2) {
+			ep0_do_stall(pcd, -DWC_E_NOT_SUPPORTED);
+			return;
+		}
+		/** @todo check for EP stall */
+		*status = ep->stopped;
+		break;
+	}
+	pcd->ep0_pending = 1;
+	ep0->dwc_ep.start_xfer_buff = (uint8_t *) status;
+	ep0->dwc_ep.xfer_buff = (uint8_t *) status;
+	ep0->dwc_ep.dma_addr = pcd->status_buf_dma_handle;
+	ep0->dwc_ep.xfer_len = 2;
+	ep0->dwc_ep.xfer_count = 0;
+	ep0->dwc_ep.total_len = ep0->dwc_ep.xfer_len;
+	dwc_otg_ep0_start_transfer(GET_CORE_IF(pcd), &ep0->dwc_ep);
+}
+
+/**
+ * This function process the SET_FEATURE Setup Commands.
+ */
+static inline void do_set_feature(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+	usb_device_request_t ctrl = pcd->setup_pkt->req;
+	dwc_otg_pcd_ep_t *ep = 0;
+	int32_t otg_cap_param = core_if->core_params->otg_cap;
+	gotgctl_data_t gotgctl = {.d32 = 0 };
+	gintmsk_data_t gintmsk = {.d32 = 0 };
+
+	DWC_DEBUGPL(DBG_PCD, "SET_FEATURE:%02x.%02x v%04x i%04x l%04x\n",
+		    ctrl.bmRequestType, ctrl.bRequest,
+		    UGETW(ctrl.wValue), UGETW(ctrl.wIndex),
+		    UGETW(ctrl.wLength));
+	DWC_DEBUGPL(DBG_PCD, "otg_cap=%d\n", otg_cap_param);
+
+	switch (UT_GET_RECIPIENT(ctrl.bmRequestType)) {
+	case UT_DEVICE:
+		switch (UGETW(ctrl.wValue)) {
+		case UF_DEVICE_REMOTE_WAKEUP:
+			pcd->remote_wakeup_enable = 1;
+			break;
+
+		case UF_TEST_MODE:
+			/* Setup the Test Mode tasklet to do the Test
+			 * Packet generation after the SETUP Status
+			 * phase has completed. */
+
+			/** @todo This has not been tested since the
+			 * tasklet struct was put into the PCD
+			 * struct! */
+			pcd->test_mode = UGETW(ctrl.wIndex) >> 8;
+			DWC_TASK_SCHEDULE(pcd->test_mode_tasklet);
+			break;
+
+		case UF_DEVICE_B_HNP_ENABLE:
+			DWC_DEBUGPL(DBG_PCDV,
+				    "SET_FEATURE: USB_DEVICE_B_HNP_ENABLE\n");
+
+			/* dev may initiate HNP */
+			if (otg_cap_param == DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE) {
+				gotgctl.b.devhnpen = 1;
+				if (core_if->otg_ver) {
+					DWC_MODIFY_REG32(&global_regs->gotgctl, 0, gotgctl.d32);
+					/* Ensure that USB Suspend interrupt is unmasked */
+					gintmsk.b.usbsuspend = 1;
+					DWC_MODIFY_REG32(&global_regs->gintmsk, 0, gintmsk.d32);
+				}
+				else {
+					pcd->b_hnp_enable = 1;
+					dwc_otg_pcd_update_otg(pcd, 0);
+					DWC_DEBUGPL(DBG_PCD, "Request B HNP\n");
+					/**@todo Is the gotgctl.devhnpen cleared
+					 * by a USB Reset? */
+					gotgctl.b.hnpreq = 1;
+					DWC_WRITE_REG32(&global_regs->gotgctl, gotgctl.d32);
+				}
+			} else {
+				ep0_do_stall(pcd, -DWC_E_NOT_SUPPORTED);
+				return;
+			}
+			break;
+
+		case UF_DEVICE_A_HNP_SUPPORT:
+			/* RH port supports HNP */
+			DWC_DEBUGPL(DBG_PCDV,
+				    "SET_FEATURE: USB_DEVICE_A_HNP_SUPPORT\n");
+			if (otg_cap_param == DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE) {
+				pcd->a_hnp_support = 1;
+				dwc_otg_pcd_update_otg(pcd, 0);
+			} else {
+				ep0_do_stall(pcd, -DWC_E_NOT_SUPPORTED);
+				return;
+			}
+			break;
+
+		case UF_DEVICE_A_ALT_HNP_SUPPORT:
+			/* other RH port does */
+			DWC_DEBUGPL(DBG_PCDV,
+				    "SET_FEATURE: USB_DEVICE_A_ALT_HNP_SUPPORT\n");
+			if (otg_cap_param == DWC_OTG_CAP_PARAM_HNP_SRP_CAPABLE) {
+				pcd->a_alt_hnp_support = 1;
+				dwc_otg_pcd_update_otg(pcd, 0);
+			} else {
+				ep0_do_stall(pcd, -DWC_E_NOT_SUPPORTED);
+				return;
+			}
+			break;
+
+		default:
+			ep0_do_stall(pcd, -DWC_E_NOT_SUPPORTED);
+			return;
+
+		}
+		do_setup_in_status_phase(pcd);
+		break;
+
+	case UT_INTERFACE:
+		do_gadget_setup(pcd, &ctrl);
+		break;
+
+	case UT_ENDPOINT:
+		if (UGETW(ctrl.wValue) == UF_ENDPOINT_HALT) {
+			ep = get_ep_by_addr(pcd, UGETW(ctrl.wIndex));
+			if (ep == 0) {
+				ep0_do_stall(pcd, -DWC_E_NOT_SUPPORTED);
+				return;
+			}
+			ep->stopped = 1;
+			dwc_otg_ep_set_stall(core_if, &ep->dwc_ep);
+		}
+		do_setup_in_status_phase(pcd);
+		break;
+	}
+}
+
+/**
+ * This function process the CLEAR_FEATURE Setup Commands.
+ */
+static inline void do_clear_feature(dwc_otg_pcd_t * pcd)
+{
+	usb_device_request_t ctrl = pcd->setup_pkt->req;
+	dwc_otg_pcd_ep_t *ep = 0;
+
+	DWC_DEBUGPL(DBG_PCD,
+		    "CLEAR_FEATURE:%02x.%02x v%04x i%04x l%04x\n",
+		    ctrl.bmRequestType, ctrl.bRequest,
+		    UGETW(ctrl.wValue), UGETW(ctrl.wIndex),
+		    UGETW(ctrl.wLength));
+
+	switch (UT_GET_RECIPIENT(ctrl.bmRequestType)) {
+	case UT_DEVICE:
+		switch (UGETW(ctrl.wValue)) {
+		case UF_DEVICE_REMOTE_WAKEUP:
+			pcd->remote_wakeup_enable = 0;
+			break;
+
+		case UF_TEST_MODE:
+			/** @todo Add CLEAR_FEATURE for TEST modes. */
+			break;
+
+		default:
+			ep0_do_stall(pcd, -DWC_E_NOT_SUPPORTED);
+			return;
+		}
+		do_setup_in_status_phase(pcd);
+		break;
+
+	case UT_ENDPOINT:
+		ep = get_ep_by_addr(pcd, UGETW(ctrl.wIndex));
+		if (ep == 0) {
+			ep0_do_stall(pcd, -DWC_E_NOT_SUPPORTED);
+			return;
+		}
+
+		pcd_clear_halt(pcd, ep);
+
+		break;
+	}
+}
+
+/**
+ * This function process the SET_ADDRESS Setup Commands.
+ */
+static inline void do_set_address(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_dev_if_t *dev_if = GET_CORE_IF(pcd)->dev_if;
+	usb_device_request_t ctrl = pcd->setup_pkt->req;
+
+	if (ctrl.bmRequestType == UT_DEVICE) {
+		dcfg_data_t dcfg = {.d32 = 0 };
+
+#ifdef DEBUG_EP0
+//                      DWC_DEBUGPL(DBG_PCDV, "SET_ADDRESS:%d\n", ctrl.wValue);
+#endif
+		dcfg.b.devaddr = UGETW(ctrl.wValue);
+		DWC_MODIFY_REG32(&dev_if->dev_global_regs->dcfg, 0, dcfg.d32);
+		do_setup_in_status_phase(pcd);
+	}
+}
+
+/**
+ *	This function processes SETUP commands. In Linux, the USB Command
+ *	processing is done in two places - the first being the PCD and the
+ *	second in the Gadget Driver (for example, the File-Backed Storage
+ *	Gadget Driver).
+ *
+ * <table>
+ * <tr><td>Command	</td><td>Driver </td><td>Description</td></tr>
+ *
+ * <tr><td>GET_STATUS </td><td>PCD </td><td>Command is processed as
+ * defined in chapter 9 of the USB 2.0 Specification chapter 9
+ * </td></tr>
+ *
+ * <tr><td>CLEAR_FEATURE </td><td>PCD </td><td>The Device and Endpoint
+ * requests are the ENDPOINT_HALT feature is procesed, all others the
+ * interface requests are ignored.</td></tr>
+ *
+ * <tr><td>SET_FEATURE </td><td>PCD </td><td>The Device and Endpoint
+ * requests are processed by the PCD.  Interface requests are passed
+ * to the Gadget Driver.</td></tr>
+ *
+ * <tr><td>SET_ADDRESS </td><td>PCD </td><td>Program the DCFG reg,
+ * with device address received </td></tr>
+ *
+ * <tr><td>GET_DESCRIPTOR </td><td>Gadget Driver </td><td>Return the
+ * requested descriptor</td></tr>
+ *
+ * <tr><td>SET_DESCRIPTOR </td><td>Gadget Driver </td><td>Optional -
+ * not implemented by any of the existing Gadget Drivers.</td></tr>
+ *
+ * <tr><td>SET_CONFIGURATION </td><td>Gadget Driver </td><td>Disable
+ * all EPs and enable EPs for new configuration.</td></tr>
+ *
+ * <tr><td>GET_CONFIGURATION </td><td>Gadget Driver </td><td>Return
+ * the current configuration</td></tr>
+ *
+ * <tr><td>SET_INTERFACE </td><td>Gadget Driver </td><td>Disable all
+ * EPs and enable EPs for new configuration.</td></tr>
+ *
+ * <tr><td>GET_INTERFACE </td><td>Gadget Driver </td><td>Return the
+ * current interface.</td></tr>
+ *
+ * <tr><td>SYNC_FRAME </td><td>PCD </td><td>Display debug
+ * message.</td></tr>
+ * </table>
+ *
+ * When the SETUP Phase Done interrupt occurs, the PCD SETUP commands are
+ * processed by pcd_setup. Calling the Function Driver's setup function from
+ * pcd_setup processes the gadget SETUP commands.
+ */
+static inline void pcd_setup(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	usb_device_request_t ctrl = pcd->setup_pkt->req;
+	dwc_otg_pcd_ep_t *ep0 = &pcd->ep0;
+
+	deptsiz0_data_t doeptsize0 = {.d32 = 0 };
+
+#ifdef DWC_UTE_CFI
+	int retval = 0;
+	struct cfi_usb_ctrlrequest cfi_req;
+#endif
+
+	doeptsize0.d32 = DWC_READ_REG32(&dev_if->out_ep_regs[0]->doeptsiz);
+
+	/** In BDMA more then 1 setup packet is not supported till 3.00a */
+	if (core_if->dma_enable && core_if->dma_desc_enable == 0
+	    && (doeptsize0.b.supcnt < 2)
+	    && (core_if->snpsid < OTG_CORE_REV_2_94a)) {
+		DWC_ERROR
+		    ("\n\n-----------	 CANNOT handle > 1 setup packet in DMA mode\n\n");
+	}
+	if ((core_if->snpsid >= OTG_CORE_REV_3_00a)
+	    && (core_if->dma_enable == 1) && (core_if->dma_desc_enable == 0)) {
+		if (doeptsize0.b.supcnt == 3 && ep0->dwc_ep.stp_rollover == 0) {
+			DWC_ERROR(" !!! Setup packet count was not updated by the core\n");
+			return;
+		}
+		ctrl =
+		    (pcd->setup_pkt +
+		     (3 - doeptsize0.b.supcnt - 1 +
+		      ep0->dwc_ep.stp_rollover))->req;
+	}
+#ifdef DEBUG_EP0
+	DWC_DEBUGPL(DBG_PCD, "SETUP %02x.%02x v%04x i%04x l%04x\n",
+		    ctrl.bmRequestType, ctrl.bRequest,
+		    UGETW(ctrl.wValue), UGETW(ctrl.wIndex),
+		    UGETW(ctrl.wLength));
+#endif
+
+	/* Clean up the request queue */
+	dwc_otg_request_nuke(ep0);
+	ep0->stopped = 0;
+
+	if (ctrl.bmRequestType & UE_DIR_IN) {
+		ep0->dwc_ep.is_in = 1;
+		pcd->ep0state = EP0_IN_DATA_PHASE;
+	} else {
+		ep0->dwc_ep.is_in = 0;
+		pcd->ep0state = EP0_OUT_DATA_PHASE;
+	}
+
+	if (UGETW(ctrl.wLength) == 0) {
+		ep0->dwc_ep.is_in = 1;
+		pcd->ep0state = EP0_IN_STATUS_PHASE;
+	}
+
+	if (UT_GET_TYPE(ctrl.bmRequestType) != UT_STANDARD) {
+
+#ifdef DWC_UTE_CFI
+		DWC_MEMCPY(&cfi_req, &ctrl, sizeof(usb_device_request_t));
+
+		//printk(KERN_ALERT "CFI: req_type=0x%02x; req=0x%02x\n",
+		ctrl.bRequestType, ctrl.bRequest);
+		if (UT_GET_TYPE(cfi_req.bRequestType) == UT_VENDOR) {
+			if (cfi_req.bRequest > 0xB0 && cfi_req.bRequest < 0xBF) {
+				retval = cfi_setup(pcd, &cfi_req);
+				if (retval < 0) {
+					ep0_do_stall(pcd, retval);
+					pcd->ep0_pending = 0;
+					return;
+				}
+
+				/* if need gadget setup then call it and check the retval */
+				if (pcd->cfi->need_gadget_att) {
+					retval =
+					    cfi_gadget_setup(pcd,
+							     &pcd->
+							     cfi->ctrl_req);
+					if (retval < 0) {
+						pcd->ep0_pending = 0;
+						return;
+					}
+				}
+
+				if (pcd->cfi->need_status_in_complete) {
+					do_setup_in_status_phase(pcd);
+				}
+				return;
+			}
+		}
+#endif
+
+		/* handle non-standard (class/vendor) requests in the gadget driver */
+		do_gadget_setup(pcd, &ctrl);
+		return;
+	}
+
+	/** @todo NGS: Handle bad setup packet? */
+
+///////////////////////////////////////////
+//// --- Standard Request handling --- ////
+
+	switch (ctrl.bRequest) {
+	case UR_GET_STATUS:
+		do_get_status(pcd);
+		break;
+
+	case UR_CLEAR_FEATURE:
+		do_clear_feature(pcd);
+		break;
+
+	case UR_SET_FEATURE:
+		do_set_feature(pcd);
+		break;
+
+	case UR_SET_ADDRESS:
+		do_set_address(pcd);
+		break;
+
+	case UR_SET_INTERFACE:
+	case UR_SET_CONFIG:
+//              _pcd->request_config = 1;       /* Configuration changed */
+		do_gadget_setup(pcd, &ctrl);
+		break;
+
+	case UR_SYNCH_FRAME:
+		do_gadget_setup(pcd, &ctrl);
+		break;
+
+	default:
+		/* Call the Gadget Driver's setup functions */
+		do_gadget_setup(pcd, &ctrl);
+		break;
+	}
+}
+
+/**
+ * This function completes the ep0 control transfer.
+ */
+static int32_t ep0_complete_request(dwc_otg_pcd_ep_t * ep)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(ep->pcd);
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	dwc_otg_dev_in_ep_regs_t *in_ep_regs =
+	    dev_if->in_ep_regs[ep->dwc_ep.num];
+#ifdef DEBUG_EP0
+	dwc_otg_dev_out_ep_regs_t *out_ep_regs =
+	    dev_if->out_ep_regs[ep->dwc_ep.num];
+#endif
+	deptsiz0_data_t deptsiz;
+	dev_dma_desc_sts_t desc_sts = {.d32 = 0 };
+	dwc_otg_pcd_request_t *req;
+	int is_last = 0;
+	dwc_otg_pcd_t *pcd = ep->pcd;
+
+#ifdef DWC_UTE_CFI
+	struct cfi_usb_ctrlrequest *ctrlreq;
+	int retval = -DWC_E_NOT_SUPPORTED;
+#endif
+
+	if (pcd->ep0_pending && DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+		if (ep->dwc_ep.is_in) {
+#ifdef DEBUG_EP0
+			DWC_DEBUGPL(DBG_PCDV, "Do setup OUT status phase\n");
+#endif
+			do_setup_out_status_phase(pcd);
+		} else {
+#ifdef DEBUG_EP0
+			DWC_DEBUGPL(DBG_PCDV, "Do setup IN status phase\n");
+#endif
+
+#ifdef DWC_UTE_CFI
+			ctrlreq = &pcd->cfi->ctrl_req;
+
+			if (UT_GET_TYPE(ctrlreq->bRequestType) == UT_VENDOR) {
+				if (ctrlreq->bRequest > 0xB0
+				    && ctrlreq->bRequest < 0xBF) {
+
+					/* Return if the PCD failed to handle the request */
+					if ((retval =
+					     pcd->cfi->ops.
+					     ctrl_write_complete(pcd->cfi,
+								 pcd)) < 0) {
+						CFI_INFO
+						    ("ERROR setting a new value in the PCD(%d)\n",
+						     retval);
+						ep0_do_stall(pcd, retval);
+						pcd->ep0_pending = 0;
+						return 0;
+					}
+
+					/* If the gadget needs to be notified on the request */
+					if (pcd->cfi->need_gadget_att == 1) {
+						//retval = do_gadget_setup(pcd, &pcd->cfi->ctrl_req);
+						retval =
+						    cfi_gadget_setup(pcd,
+								     &pcd->cfi->
+								     ctrl_req);
+
+						/* Return from the function if the gadget failed to process
+						 * the request properly - this should never happen !!!
+						 */
+						if (retval < 0) {
+							CFI_INFO
+							    ("ERROR setting a new value in the gadget(%d)\n",
+							     retval);
+							pcd->ep0_pending = 0;
+							return 0;
+						}
+					}
+
+					CFI_INFO("%s: RETVAL=%d\n", __func__,
+						 retval);
+					/* If we hit here then the PCD and the gadget has properly
+					 * handled the request - so send the ZLP IN to the host.
+					 */
+					/* @todo: MAS - decide whether we need to start the setup
+					 * stage based on the need_setup value of the cfi object
+					 */
+					do_setup_in_status_phase(pcd);
+					pcd->ep0_pending = 0;
+					return 1;
+				}
+			}
+#endif
+
+			do_setup_in_status_phase(pcd);
+		}
+		pcd->ep0_pending = 0;
+		return 1;
+	}
+
+	if (DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+		return 0;
+	}
+	req = DWC_CIRCLEQ_FIRST(&ep->queue);
+
+	if (pcd->ep0state == EP0_OUT_STATUS_PHASE
+	    || pcd->ep0state == EP0_IN_STATUS_PHASE) {
+		is_last = 1;
+	} else if (ep->dwc_ep.is_in) {
+		deptsiz.d32 = DWC_READ_REG32(&in_ep_regs->dieptsiz);
+		if (core_if->dma_desc_enable != 0)
+			desc_sts = dev_if->in_desc_addr->status;
+#ifdef DEBUG_EP0
+		DWC_DEBUGPL(DBG_PCDV, "%d len=%d  xfersize=%d pktcnt=%d\n",
+			    ep->dwc_ep.num, ep->dwc_ep.xfer_len,
+			    deptsiz.b.xfersize, deptsiz.b.pktcnt);
+#endif
+
+		if (((core_if->dma_desc_enable == 0)
+		     && (deptsiz.b.xfersize == 0))
+		    || ((core_if->dma_desc_enable != 0)
+			&& (desc_sts.b.bytes == 0))) {
+			req->actual = ep->dwc_ep.xfer_count;
+			/* Is a Zero Len Packet needed? */
+			if (req->sent_zlp) {
+#ifdef DEBUG_EP0
+				DWC_DEBUGPL(DBG_PCD, "Setup Rx ZLP\n");
+#endif
+				req->sent_zlp = 0;
+			}
+			do_setup_out_status_phase(pcd);
+		}
+	} else {
+		/* ep0-OUT */
+#ifdef DEBUG_EP0
+		deptsiz.d32 = DWC_READ_REG32(&out_ep_regs->doeptsiz);
+		DWC_DEBUGPL(DBG_PCDV, "%d len=%d xsize=%d pktcnt=%d\n",
+			    ep->dwc_ep.num, ep->dwc_ep.xfer_len,
+			    deptsiz.b.xfersize, deptsiz.b.pktcnt);
+#endif
+		req->actual = ep->dwc_ep.xfer_count;
+
+		/* Is a Zero Len Packet needed? */
+		if (req->sent_zlp) {
+#ifdef DEBUG_EP0
+			DWC_DEBUGPL(DBG_PCDV, "Setup Tx ZLP\n");
+#endif
+			req->sent_zlp = 0;
+		}
+		/* For older cores do setup in status phase in Slave/BDMA modes,
+		 * starting from 3.00 do that only in slave, and for DMA modes
+		 * just re-enable ep 0 OUT here*/
+		if (core_if->dma_enable == 0
+		    || (core_if->dma_desc_enable == 0
+			&& core_if->snpsid <= OTG_CORE_REV_2_94a)) {
+			do_setup_in_status_phase(pcd);
+		} else if (core_if->snpsid >= OTG_CORE_REV_3_00a) {
+			DWC_DEBUGPL(DBG_PCDV,
+				    "Enable out ep before in status phase\n");
+			ep0_out_start(core_if, pcd);
+		}
+	}
+
+	/* Complete the request */
+	if (is_last) {
+		dwc_otg_request_done(ep, req, 0);
+		ep->dwc_ep.start_xfer_buff = 0;
+		ep->dwc_ep.xfer_buff = 0;
+		ep->dwc_ep.xfer_len = 0;
+		return 1;
+	}
+	return 0;
+}
+
+#ifdef DWC_UTE_CFI
+/**
+ * This function calculates traverses all the CFI DMA descriptors and
+ * and accumulates the bytes that are left to be transfered.
+ *
+ * @return The total bytes left to transfered, or a negative value as failure
+ */
+static inline int cfi_calc_desc_residue(dwc_otg_pcd_ep_t * ep)
+{
+	int32_t ret = 0;
+	int i;
+	struct dwc_otg_dma_desc *ddesc = NULL;
+	struct cfi_ep *cfiep;
+
+	/* See if the pcd_ep has its respective cfi_ep mapped */
+	cfiep = get_cfi_ep_by_pcd_ep(ep->pcd->cfi, ep);
+	if (!cfiep) {
+		CFI_INFO("%s: Failed to find ep\n", __func__);
+		return -1;
+	}
+
+	ddesc = ep->dwc_ep.descs;
+
+	for (i = 0; (i < cfiep->desc_count) && (i < MAX_DMA_DESCS_PER_EP); i++) {
+
+#if defined(PRINT_CFI_DMA_DESCS)
+		print_desc(ddesc, ep->ep.name, i);
+#endif
+		ret += ddesc->status.b.bytes;
+		ddesc++;
+	}
+
+	if (ret)
+		CFI_INFO("!!!!!!!!!! WARNING (%s) - residue=%d\n", __func__,
+			 ret);
+
+	return ret;
+}
+#endif
+
+/**
+ * This function completes the request for the EP. If there are
+ * additional requests for the EP in the queue they will be started.
+ */
+static void complete_ep(dwc_otg_pcd_ep_t * ep)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(ep->pcd);
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	dwc_otg_dev_in_ep_regs_t *in_ep_regs =
+	    dev_if->in_ep_regs[ep->dwc_ep.num];
+	deptsiz_data_t deptsiz;
+	dev_dma_desc_sts_t desc_sts;
+	dwc_otg_pcd_request_t *req = 0;
+	dwc_otg_dev_dma_desc_t *dma_desc;
+	uint32_t byte_count = 0;
+	int is_last = 0;
+	int i;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s() %d-%s\n", __func__, ep->dwc_ep.num,
+		    (ep->dwc_ep.is_in ? "IN" : "OUT"));
+
+	/* Get any pending requests */
+	if (!DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+		req = DWC_CIRCLEQ_FIRST(&ep->queue);
+		if (!req) {
+			DWC_PRINTF("complete_ep 0x%p, req = NULL!\n", ep);
+			return;
+		}
+	} else {
+		DWC_PRINTF("complete_ep 0x%p, ep->queue empty!\n", ep);
+		return;
+	}
+
+	DWC_DEBUGPL(DBG_PCD, "Requests %d\n", ep->pcd->request_pending);
+
+	if (ep->dwc_ep.is_in) {
+		deptsiz.d32 = DWC_READ_REG32(&in_ep_regs->dieptsiz);
+
+		if (core_if->dma_enable) {
+			if (core_if->dma_desc_enable == 0) {
+				if (deptsiz.b.xfersize == 0
+				    && deptsiz.b.pktcnt == 0) {
+					byte_count =
+					    ep->dwc_ep.xfer_len -
+					    ep->dwc_ep.xfer_count;
+
+					ep->dwc_ep.xfer_buff += byte_count;
+					ep->dwc_ep.dma_addr += byte_count;
+					ep->dwc_ep.xfer_count += byte_count;
+
+					DWC_DEBUGPL(DBG_PCDV,
+						    "%d-%s len=%d  xfersize=%d pktcnt=%d\n",
+						    ep->dwc_ep.num,
+						    (ep->dwc_ep.
+						     is_in ? "IN" : "OUT"),
+						    ep->dwc_ep.xfer_len,
+						    deptsiz.b.xfersize,
+						    deptsiz.b.pktcnt);
+
+					if (ep->dwc_ep.xfer_len <
+					    ep->dwc_ep.total_len) {
+						dwc_otg_ep_start_transfer
+						    (core_if, &ep->dwc_ep);
+					} else if (ep->dwc_ep.sent_zlp) {
+						/*
+						 * This fragment of code should initiate 0
+						 * length transfer in case if it is queued
+						 * a transfer with size divisible to EPs max
+						 * packet size and with usb_request zero field
+						 * is set, which means that after data is transfered,
+						 * it is also should be transfered
+						 * a 0 length packet at the end. For Slave and
+						 * Buffer DMA modes in this case SW has
+						 * to initiate 2 transfers one with transfer size,
+						 * and the second with 0 size. For Descriptor
+						 * DMA mode SW is able to initiate a transfer,
+						 * which will handle all the packets including
+						 * the last  0 length.
+						 */
+						ep->dwc_ep.sent_zlp = 0;
+						dwc_otg_ep_start_zl_transfer
+						    (core_if, &ep->dwc_ep);
+					} else {
+						is_last = 1;
+					}
+				} else {
+					if (ep->dwc_ep.type ==
+					    DWC_OTG_EP_TYPE_ISOC) {
+						req->actual = 0;
+						dwc_otg_request_done(ep, req, 0);
+
+						ep->dwc_ep.start_xfer_buff = 0;
+						ep->dwc_ep.xfer_buff = 0;
+						ep->dwc_ep.xfer_len = 0;
+
+						/* If there is a request in the queue start it. */
+						start_next_request(ep);
+					} else
+						DWC_WARN
+						("Incomplete transfer (%d - %s [siz=%d pkt=%d])\n",
+						ep->dwc_ep.num,
+						(ep->dwc_ep.is_in ? "IN" : "OUT"),
+						deptsiz.b.xfersize,
+						deptsiz.b.pktcnt);
+				}
+			} else {
+				dma_desc = ep->dwc_ep.desc_addr;
+				byte_count = 0;
+				ep->dwc_ep.sent_zlp = 0;
+
+#ifdef DWC_UTE_CFI
+				CFI_INFO("%s: BUFFER_MODE=%d\n", __func__,
+					 ep->dwc_ep.buff_mode);
+				if (ep->dwc_ep.buff_mode != BM_STANDARD) {
+					int residue;
+
+					residue = cfi_calc_desc_residue(ep);
+					if (residue < 0)
+						return;
+
+					byte_count = residue;
+				} else {
+#endif
+					for (i = 0; i < ep->dwc_ep.desc_cnt;
+					     ++i) {
+						desc_sts = dma_desc->status;
+						byte_count += desc_sts.b.bytes;
+						dma_desc++;
+					}
+#ifdef DWC_UTE_CFI
+				}
+#endif
+				if (byte_count == 0) {
+					ep->dwc_ep.xfer_count =
+					    ep->dwc_ep.total_len;
+					is_last = 1;
+				} else {
+					DWC_WARN("Incomplete transfer\n");
+				}
+			}
+		} else {
+			if (deptsiz.b.xfersize == 0 && deptsiz.b.pktcnt == 0) {
+				DWC_DEBUGPL(DBG_PCDV,
+					    "%d-%s len=%d  xfersize=%d pktcnt=%d\n",
+					    ep->dwc_ep.num,
+					    ep->dwc_ep.is_in ? "IN" : "OUT",
+					    ep->dwc_ep.xfer_len,
+					    deptsiz.b.xfersize,
+					    deptsiz.b.pktcnt);
+
+				/*      Check if the whole transfer was completed,
+				 *      if no, setup transfer for next portion of data
+				 */
+				if (ep->dwc_ep.xfer_len < ep->dwc_ep.total_len) {
+					dwc_otg_ep_start_transfer(core_if,
+								  &ep->dwc_ep);
+				} else if (ep->dwc_ep.sent_zlp) {
+					/*
+					 * This fragment of code should initiate 0
+					 * length trasfer in case if it is queued
+					 * a trasfer with size divisible to EPs max
+					 * packet size and with usb_request zero field
+					 * is set, which means that after data is transfered,
+					 * it is also should be transfered
+					 * a 0 length packet at the end. For Slave and
+					 * Buffer DMA modes in this case SW has
+					 * to initiate 2 transfers one with transfer size,
+					 * and the second with 0 size. For Desriptor
+					 * DMA mode SW is able to initiate a transfer,
+					 * which will handle all the packets including
+					 * the last  0 legth.
+					 */
+					ep->dwc_ep.sent_zlp = 0;
+					dwc_otg_ep_start_zl_transfer(core_if,
+								     &ep->dwc_ep);
+				} else {
+					is_last = 1;
+				}
+			} else {
+				DWC_WARN
+				    ("Incomplete transfer (%d-%s [siz=%d pkt=%d])\n",
+				     ep->dwc_ep.num,
+				     (ep->dwc_ep.is_in ? "IN" : "OUT"),
+				     deptsiz.b.xfersize, deptsiz.b.pktcnt);
+			}
+		}
+	} else {
+		dwc_otg_dev_out_ep_regs_t *out_ep_regs =
+		    dev_if->out_ep_regs[ep->dwc_ep.num];
+		desc_sts.d32 = 0;
+		if (core_if->dma_enable) {
+			if (core_if->dma_desc_enable) {
+				dma_desc = ep->dwc_ep.desc_addr;
+				byte_count = 0;
+				ep->dwc_ep.sent_zlp = 0;
+
+#ifdef DWC_UTE_CFI
+				CFI_INFO("%s: BUFFER_MODE=%d\n", __func__,
+					 ep->dwc_ep.buff_mode);
+				if (ep->dwc_ep.buff_mode != BM_STANDARD) {
+					int residue;
+					residue = cfi_calc_desc_residue(ep);
+					if (residue < 0)
+						return;
+					byte_count = residue;
+				} else {
+#endif
+
+					for (i = 0; i < ep->dwc_ep.desc_cnt;
+					     ++i) {
+						desc_sts = dma_desc->status;
+						byte_count += desc_sts.b.bytes;
+						dma_desc++;
+					}
+
+#ifdef DWC_UTE_CFI
+				}
+#endif
+				/* Checking for interrupt Out transfers with not
+				 * dword aligned mps sizes
+				 */
+				if (ep->dwc_ep.type == DWC_OTG_EP_TYPE_INTR &&
+				    (ep->dwc_ep.maxpacket % 4)) {
+					ep->dwc_ep.xfer_count =
+					    ep->dwc_ep.total_len - byte_count;
+					if ((ep->dwc_ep.xfer_len %
+					     ep->dwc_ep.maxpacket)
+					    && (ep->dwc_ep.xfer_len /
+						ep->dwc_ep.maxpacket <
+						MAX_DMA_DESC_CNT))
+						ep->dwc_ep.xfer_len -=
+						    (ep->dwc_ep.desc_cnt -
+						     1) * ep->dwc_ep.maxpacket +
+						    ep->dwc_ep.xfer_len %
+						    ep->dwc_ep.maxpacket;
+					else
+						ep->dwc_ep.xfer_len -=
+						    ep->dwc_ep.desc_cnt *
+						    ep->dwc_ep.maxpacket;
+					if (ep->dwc_ep.xfer_len > 0) {
+						dwc_otg_ep_start_transfer
+						    (core_if, &ep->dwc_ep);
+					} else {
+						is_last = 1;
+					}
+				} else {
+					ep->dwc_ep.xfer_count =
+					    ep->dwc_ep.total_len - byte_count +
+					    ((4 -
+					      (ep->dwc_ep.
+					       total_len & 0x3)) & 0x3);
+					is_last = 1;
+				}
+			} else {
+				deptsiz.d32 = 0;
+				deptsiz.d32 =
+				    DWC_READ_REG32(&out_ep_regs->doeptsiz);
+
+				byte_count = (ep->dwc_ep.xfer_len -
+					      ep->dwc_ep.xfer_count -
+					      deptsiz.b.xfersize);
+				ep->dwc_ep.xfer_buff += byte_count;
+				ep->dwc_ep.dma_addr += byte_count;
+				ep->dwc_ep.xfer_count += byte_count;
+
+				/*      Check if the whole transfer was completed,
+				 *      if no, setup transfer for next portion of data
+				 */
+				if (ep->dwc_ep.xfer_len < ep->dwc_ep.total_len) {
+					dwc_otg_ep_start_transfer(core_if,
+								  &ep->dwc_ep);
+				} else if (ep->dwc_ep.sent_zlp) {
+					/*
+					 * This fragment of code should initiate 0
+					 * length trasfer in case if it is queued
+					 * a trasfer with size divisible to EPs max
+					 * packet size and with usb_request zero field
+					 * is set, which means that after data is transfered,
+					 * it is also should be transfered
+					 * a 0 length packet at the end. For Slave and
+					 * Buffer DMA modes in this case SW has
+					 * to initiate 2 transfers one with transfer size,
+					 * and the second with 0 size. For Desriptor
+					 * DMA mode SW is able to initiate a transfer,
+					 * which will handle all the packets including
+					 * the last  0 legth.
+					 */
+					ep->dwc_ep.sent_zlp = 0;
+					dwc_otg_ep_start_zl_transfer(core_if,
+								     &ep->dwc_ep);
+				} else {
+					is_last = 1;
+				}
+			}
+		} else {
+			/*      Check if the whole transfer was completed,
+			 *      if no, setup transfer for next portion of data
+			 */
+			if (ep->dwc_ep.xfer_len < ep->dwc_ep.total_len) {
+				dwc_otg_ep_start_transfer(core_if, &ep->dwc_ep);
+			} else if (ep->dwc_ep.sent_zlp) {
+				/*
+				 * This fragment of code should initiate 0
+				 * length transfer in case if it is queued
+				 * a transfer with size divisible to EPs max
+				 * packet size and with usb_request zero field
+				 * is set, which means that after data is transfered,
+				 * it is also should be transfered
+				 * a 0 length packet at the end. For Slave and
+				 * Buffer DMA modes in this case SW has
+				 * to initiate 2 transfers one with transfer size,
+				 * and the second with 0 size. For Descriptor
+				 * DMA mode SW is able to initiate a transfer,
+				 * which will handle all the packets including
+				 * the last  0 length.
+				 */
+				ep->dwc_ep.sent_zlp = 0;
+				dwc_otg_ep_start_zl_transfer(core_if,
+							     &ep->dwc_ep);
+			} else {
+				is_last = 1;
+			}
+		}
+
+		DWC_DEBUGPL(DBG_PCDV,
+			    "addr %p,	 %d-%s len=%d cnt=%d xsize=%d pktcnt=%d\n",
+			    &out_ep_regs->doeptsiz, ep->dwc_ep.num,
+			    ep->dwc_ep.is_in ? "IN" : "OUT",
+			    ep->dwc_ep.xfer_len, ep->dwc_ep.xfer_count,
+			    deptsiz.b.xfersize, deptsiz.b.pktcnt);
+	}
+
+	/* Complete the request */
+	if (is_last) {
+#ifdef DWC_UTE_CFI
+		if (ep->dwc_ep.buff_mode != BM_STANDARD) {
+			req->actual = ep->dwc_ep.cfi_req_len - byte_count;
+		} else {
+#endif
+			req->actual = ep->dwc_ep.xfer_count;
+#ifdef DWC_UTE_CFI
+		}
+#endif
+		if (req->dw_align_buf) {
+			if (!ep->dwc_ep.is_in) {
+				dwc_memcpy(req->buf, req->dw_align_buf, req->length);
+			}
+			DWC_DMA_FREE(req->length, req->dw_align_buf,
+				     req->dw_align_buf_dma);
+		}
+
+		dwc_otg_request_done(ep, req, 0);
+
+		ep->dwc_ep.start_xfer_buff = 0;
+		ep->dwc_ep.xfer_buff = 0;
+		ep->dwc_ep.xfer_len = 0;
+
+		/* If there is a request in the queue start it. */
+		start_next_request(ep);
+	}
+}
+/**
+ * This function completes the request for the ISO EP in DDMA. If it is last
+ * descriptor and ep was disabled, then program already prepared(during ep_queue)
+ * descriptor chain if there are more requests to process
+ */
+static void complete_ddma_iso_ep(dwc_otg_pcd_ep_t * ep)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(ep->pcd);
+	dev_dma_desc_sts_t desc_sts;
+	dwc_otg_pcd_request_t *req = 0;
+	dwc_otg_dev_dma_desc_t *dma_desc;
+	dwc_dma_t dma_desc_addr;
+	dwc_ep_t *dwc_ep;
+	uint32_t depdma;
+	uint32_t index;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s() %d-%s\n", __func__, ep->dwc_ep.num,
+		    (ep->dwc_ep.is_in ? "IN" : "OUT"));
+	dwc_ep = &ep->dwc_ep;
+	if (dwc_ep->use_add_buf) {
+		dma_desc_addr = dwc_ep->dma_desc_addr;
+		dma_desc = dwc_ep->desc_addr;
+	} else {
+		dma_desc_addr = dwc_ep->dma_desc_addr1;
+		dma_desc = dwc_ep->desc_addr1;
+	}
+	/* Get any pending requests */
+	if (!DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+		req = DWC_CIRCLEQ_FIRST(&ep->queue);
+		if (!req) {
+			DWC_PRINTF("complete_ep 0x%p, req = NULL!\n", ep);
+			return;
+		}
+	} else {
+		DWC_PRINTF("complete_ep 0x%p, ep->queue empty!\n", ep);
+		return;
+	}
+
+	if (dwc_ep->is_in) {
+		depdma = DWC_READ_REG32(&core_if->dev_if->in_ep_regs[dwc_ep->num]->diepdma);
+		index = (depdma - dma_desc_addr)/sizeof(dwc_otg_dev_dma_desc_t) - 1;
+		desc_sts = dma_desc[index].status;
+		req->actual = req->length - desc_sts.b_iso_in.txbytes;
+	} else {
+		depdma = DWC_READ_REG32(&core_if->dev_if->out_ep_regs[dwc_ep->num]->doepdma);
+		index = (depdma - dma_desc_addr)/sizeof(dwc_otg_dev_dma_desc_t) - 1;
+		desc_sts = dma_desc[index].status;
+		if (req->length%4)
+			req->actual = req->length - desc_sts.b_iso_out.rxbytes + (4 - req->length%4);
+		else
+			req->actual = req->length - desc_sts.b_iso_out.rxbytes;
+	}
+
+	/* Complete the request */
+	dwc_otg_request_done(ep, req, 0);
+}
+
+#ifdef DWC_EN_ISOC
+
+/**
+ * This function BNA interrupt for Isochronous EPs
+ *
+ */
+static void dwc_otg_pcd_handle_iso_bna(dwc_otg_pcd_ep_t * ep)
+{
+	dwc_ep_t *dwc_ep = &ep->dwc_ep;
+	volatile uint32_t *addr;
+	depctl_data_t depctl = {.d32 = 0 };
+	dwc_otg_pcd_t *pcd = ep->pcd;
+	dwc_otg_dev_dma_desc_t *dma_desc;
+	int i;
+
+	dma_desc =
+	    dwc_ep->iso_desc_addr + dwc_ep->desc_cnt * (dwc_ep->proc_buf_num);
+
+	if (dwc_ep->is_in) {
+		dev_dma_desc_sts_t sts = {.d32 = 0 };
+		for (i = 0; i < dwc_ep->desc_cnt; ++i, ++dma_desc) {
+			sts.d32 = dma_desc->status.d32;
+			sts.b_iso_in.bs = BS_HOST_READY;
+			dma_desc->status.d32 = sts.d32;
+		}
+	} else {
+		dev_dma_desc_sts_t sts = {.d32 = 0 };
+		for (i = 0; i < dwc_ep->desc_cnt; ++i, ++dma_desc) {
+			sts.d32 = dma_desc->status.d32;
+			sts.b_iso_out.bs = BS_HOST_READY;
+			dma_desc->status.d32 = sts.d32;
+		}
+	}
+
+	if (dwc_ep->is_in == 0) {
+		addr =
+		    &GET_CORE_IF(pcd)->dev_if->out_ep_regs[dwc_ep->
+							   num]->doepctl;
+	} else {
+		addr =
+		    &GET_CORE_IF(pcd)->dev_if->in_ep_regs[dwc_ep->num]->diepctl;
+	}
+	depctl.b.epena = 1;
+	DWC_MODIFY_REG32(addr, depctl.d32, depctl.d32);
+}
+
+/**
+ * This function sets latest iso packet information(non-PTI mode)
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to start the transfer on.
+ *
+ */
+void set_current_pkt_info(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	deptsiz_data_t deptsiz = {.d32 = 0 };
+	dma_addr_t dma_addr;
+	uint32_t offset;
+
+	if (ep->proc_buf_num)
+		dma_addr = ep->dma_addr1;
+	else
+		dma_addr = ep->dma_addr0;
+
+	if (ep->is_in) {
+		deptsiz.d32 =
+		    DWC_READ_REG32(&core_if->dev_if->
+				   in_ep_regs[ep->num]->dieptsiz);
+		offset = ep->data_per_frame;
+	} else {
+		deptsiz.d32 =
+		    DWC_READ_REG32(&core_if->dev_if->
+				   out_ep_regs[ep->num]->doeptsiz);
+		offset =
+		    ep->data_per_frame +
+		    (0x4 & (0x4 - (ep->data_per_frame & 0x3)));
+	}
+
+	if (!deptsiz.b.xfersize) {
+		ep->pkt_info[ep->cur_pkt].length = ep->data_per_frame;
+		ep->pkt_info[ep->cur_pkt].offset =
+		    ep->cur_pkt_dma_addr - dma_addr;
+		ep->pkt_info[ep->cur_pkt].status = 0;
+	} else {
+		ep->pkt_info[ep->cur_pkt].length = ep->data_per_frame;
+		ep->pkt_info[ep->cur_pkt].offset =
+		    ep->cur_pkt_dma_addr - dma_addr;
+		ep->pkt_info[ep->cur_pkt].status = -DWC_E_NO_DATA;
+	}
+	ep->cur_pkt_addr += offset;
+	ep->cur_pkt_dma_addr += offset;
+	ep->cur_pkt++;
+}
+
+/**
+ * This function sets latest iso packet information(DDMA mode)
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param dwc_ep The EP to start the transfer on.
+ *
+ */
+static void set_ddma_iso_pkts_info(dwc_otg_core_if_t * core_if,
+				   dwc_ep_t * dwc_ep)
+{
+	dwc_otg_dev_dma_desc_t *dma_desc;
+	dev_dma_desc_sts_t sts = {.d32 = 0 };
+	iso_pkt_info_t *iso_packet;
+	uint32_t data_per_desc;
+	uint32_t offset;
+	int i, j;
+
+	iso_packet = dwc_ep->pkt_info;
+
+	/** Reinit closed DMA Descriptors*/
+	/** ISO OUT EP */
+	if (dwc_ep->is_in == 0) {
+		dma_desc =
+		    dwc_ep->iso_desc_addr +
+		    dwc_ep->desc_cnt * dwc_ep->proc_buf_num;
+		offset = 0;
+
+		for (i = 0; i < dwc_ep->desc_cnt - dwc_ep->pkt_per_frm;
+		     i += dwc_ep->pkt_per_frm) {
+			for (j = 0; j < dwc_ep->pkt_per_frm; ++j) {
+				data_per_desc =
+				    ((j + 1) * dwc_ep->maxpacket >
+				     dwc_ep->
+				     data_per_frame) ? dwc_ep->data_per_frame -
+				    j * dwc_ep->maxpacket : dwc_ep->maxpacket;
+				data_per_desc +=
+				    (data_per_desc % 4) ? (4 -
+							   data_per_desc %
+							   4) : 0;
+
+				sts.d32 = dma_desc->status.d32;
+
+				/* Write status in iso_packet_decsriptor  */
+				iso_packet->status =
+				    sts.b_iso_out.rxsts +
+				    (sts.b_iso_out.bs ^ BS_DMA_DONE);
+				if (iso_packet->status) {
+					iso_packet->status = -DWC_E_NO_DATA;
+				}
+
+				/* Received data length */
+				if (!sts.b_iso_out.rxbytes) {
+					iso_packet->length =
+					    data_per_desc -
+					    sts.b_iso_out.rxbytes;
+				} else {
+					iso_packet->length =
+					    data_per_desc -
+					    sts.b_iso_out.rxbytes + (4 -
+								     dwc_ep->data_per_frame
+								     % 4);
+				}
+
+				iso_packet->offset = offset;
+
+				offset += data_per_desc;
+				dma_desc++;
+				iso_packet++;
+			}
+		}
+
+		for (j = 0; j < dwc_ep->pkt_per_frm - 1; ++j) {
+			data_per_desc =
+			    ((j + 1) * dwc_ep->maxpacket >
+			     dwc_ep->data_per_frame) ? dwc_ep->data_per_frame -
+			    j * dwc_ep->maxpacket : dwc_ep->maxpacket;
+			data_per_desc +=
+			    (data_per_desc % 4) ? (4 - data_per_desc % 4) : 0;
+
+			sts.d32 = dma_desc->status.d32;
+
+			/* Write status in iso_packet_decsriptor  */
+			iso_packet->status =
+			    sts.b_iso_out.rxsts +
+			    (sts.b_iso_out.bs ^ BS_DMA_DONE);
+			if (iso_packet->status) {
+				iso_packet->status = -DWC_E_NO_DATA;
+			}
+
+			/* Received data length */
+			iso_packet->length =
+			    dwc_ep->data_per_frame - sts.b_iso_out.rxbytes;
+
+			iso_packet->offset = offset;
+
+			offset += data_per_desc;
+			iso_packet++;
+			dma_desc++;
+		}
+
+		sts.d32 = dma_desc->status.d32;
+
+		/* Write status in iso_packet_decsriptor  */
+		iso_packet->status =
+		    sts.b_iso_out.rxsts + (sts.b_iso_out.bs ^ BS_DMA_DONE);
+		if (iso_packet->status) {
+			iso_packet->status = -DWC_E_NO_DATA;
+		}
+		/* Received data length */
+		if (!sts.b_iso_out.rxbytes) {
+			iso_packet->length =
+			    dwc_ep->data_per_frame - sts.b_iso_out.rxbytes;
+		} else {
+			iso_packet->length =
+			    dwc_ep->data_per_frame - sts.b_iso_out.rxbytes +
+			    (4 - dwc_ep->data_per_frame % 4);
+		}
+
+		iso_packet->offset = offset;
+	} else {
+/** ISO IN EP */
+
+		dma_desc =
+		    dwc_ep->iso_desc_addr +
+		    dwc_ep->desc_cnt * dwc_ep->proc_buf_num;
+
+		for (i = 0; i < dwc_ep->desc_cnt - 1; i++) {
+			sts.d32 = dma_desc->status.d32;
+
+			/* Write status in iso packet descriptor */
+			iso_packet->status =
+			    sts.b_iso_in.txsts +
+			    (sts.b_iso_in.bs ^ BS_DMA_DONE);
+			if (iso_packet->status != 0) {
+				iso_packet->status = -DWC_E_NO_DATA;
+
+			}
+			/* Bytes has been transfered */
+			iso_packet->length =
+			    dwc_ep->data_per_frame - sts.b_iso_in.txbytes;
+
+			dma_desc++;
+			iso_packet++;
+		}
+
+		sts.d32 = dma_desc->status.d32;
+		while (sts.b_iso_in.bs == BS_DMA_BUSY) {
+			sts.d32 = dma_desc->status.d32;
+		}
+
+		/* Write status in iso packet descriptor ??? do be done with ERROR codes */
+		iso_packet->status =
+		    sts.b_iso_in.txsts + (sts.b_iso_in.bs ^ BS_DMA_DONE);
+		if (iso_packet->status != 0) {
+			iso_packet->status = -DWC_E_NO_DATA;
+		}
+
+		/* Bytes has been transfered */
+		iso_packet->length =
+		    dwc_ep->data_per_frame - sts.b_iso_in.txbytes;
+	}
+}
+
+/**
+ * This function reinitialize DMA Descriptors for Isochronous transfer
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param dwc_ep The EP to start the transfer on.
+ *
+ */
+static void reinit_ddma_iso_xfer(dwc_otg_core_if_t * core_if, dwc_ep_t * dwc_ep)
+{
+	int i, j;
+	dwc_otg_dev_dma_desc_t *dma_desc;
+	dma_addr_t dma_ad;
+	volatile uint32_t *addr;
+	dev_dma_desc_sts_t sts = {.d32 = 0 };
+	uint32_t data_per_desc;
+
+	if (dwc_ep->is_in == 0) {
+		addr = &core_if->dev_if->out_ep_regs[dwc_ep->num]->doepctl;
+	} else {
+		addr = &core_if->dev_if->in_ep_regs[dwc_ep->num]->diepctl;
+	}
+
+	if (dwc_ep->proc_buf_num == 0) {
+		/** Buffer 0 descriptors setup */
+		dma_ad = dwc_ep->dma_addr0;
+	} else {
+		/** Buffer 1 descriptors setup */
+		dma_ad = dwc_ep->dma_addr1;
+	}
+
+	/** Reinit closed DMA Descriptors*/
+	/** ISO OUT EP */
+	if (dwc_ep->is_in == 0) {
+		dma_desc =
+		    dwc_ep->iso_desc_addr +
+		    dwc_ep->desc_cnt * dwc_ep->proc_buf_num;
+
+		sts.b_iso_out.bs = BS_HOST_READY;
+		sts.b_iso_out.rxsts = 0;
+		sts.b_iso_out.l = 0;
+		sts.b_iso_out.sp = 0;
+		sts.b_iso_out.ioc = 0;
+		sts.b_iso_out.pid = 0;
+		sts.b_iso_out.framenum = 0;
+
+		for (i = 0; i < dwc_ep->desc_cnt - dwc_ep->pkt_per_frm;
+		     i += dwc_ep->pkt_per_frm) {
+			for (j = 0; j < dwc_ep->pkt_per_frm; ++j) {
+				data_per_desc =
+				    ((j + 1) * dwc_ep->maxpacket >
+				     dwc_ep->
+				     data_per_frame) ? dwc_ep->data_per_frame -
+				    j * dwc_ep->maxpacket : dwc_ep->maxpacket;
+				data_per_desc +=
+				    (data_per_desc % 4) ? (4 -
+							   data_per_desc %
+							   4) : 0;
+				sts.b_iso_out.rxbytes = data_per_desc;
+				dma_desc->buf = dma_ad;
+				dma_desc->status.d32 = sts.d32;
+
+				dma_ad += data_per_desc;
+				dma_desc++;
+			}
+		}
+
+		for (j = 0; j < dwc_ep->pkt_per_frm - 1; ++j) {
+
+			data_per_desc =
+			    ((j + 1) * dwc_ep->maxpacket >
+			     dwc_ep->data_per_frame) ? dwc_ep->data_per_frame -
+			    j * dwc_ep->maxpacket : dwc_ep->maxpacket;
+			data_per_desc +=
+			    (data_per_desc % 4) ? (4 - data_per_desc % 4) : 0;
+			sts.b_iso_out.rxbytes = data_per_desc;
+
+			dma_desc->buf = dma_ad;
+			dma_desc->status.d32 = sts.d32;
+
+			dma_desc++;
+			dma_ad += data_per_desc;
+		}
+
+		sts.b_iso_out.ioc = 1;
+		sts.b_iso_out.l = dwc_ep->proc_buf_num;
+
+		data_per_desc =
+		    ((j + 1) * dwc_ep->maxpacket >
+		     dwc_ep->data_per_frame) ? dwc_ep->data_per_frame -
+		    j * dwc_ep->maxpacket : dwc_ep->maxpacket;
+		data_per_desc +=
+		    (data_per_desc % 4) ? (4 - data_per_desc % 4) : 0;
+		sts.b_iso_out.rxbytes = data_per_desc;
+
+		dma_desc->buf = dma_ad;
+		dma_desc->status.d32 = sts.d32;
+	} else {
+/** ISO IN EP */
+
+		dma_desc =
+		    dwc_ep->iso_desc_addr +
+		    dwc_ep->desc_cnt * dwc_ep->proc_buf_num;
+
+		sts.b_iso_in.bs = BS_HOST_READY;
+		sts.b_iso_in.txsts = 0;
+		sts.b_iso_in.sp = 0;
+		sts.b_iso_in.ioc = 0;
+		sts.b_iso_in.pid = dwc_ep->pkt_per_frm;
+		sts.b_iso_in.framenum = dwc_ep->next_frame;
+		sts.b_iso_in.txbytes = dwc_ep->data_per_frame;
+		sts.b_iso_in.l = 0;
+
+		for (i = 0; i < dwc_ep->desc_cnt - 1; i++) {
+			dma_desc->buf = dma_ad;
+			dma_desc->status.d32 = sts.d32;
+
+			sts.b_iso_in.framenum += dwc_ep->bInterval;
+			dma_ad += dwc_ep->data_per_frame;
+			dma_desc++;
+		}
+
+		sts.b_iso_in.ioc = 1;
+		sts.b_iso_in.l = dwc_ep->proc_buf_num;
+
+		dma_desc->buf = dma_ad;
+		dma_desc->status.d32 = sts.d32;
+
+		dwc_ep->next_frame =
+		    sts.b_iso_in.framenum + dwc_ep->bInterval * 1;
+	}
+	dwc_ep->proc_buf_num = (dwc_ep->proc_buf_num ^ 1) & 0x1;
+}
+
+/**
+ * This function is to handle Iso EP transfer complete interrupt
+ * in case Iso out packet was dropped
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param dwc_ep The EP for wihich transfer complete was asserted
+ *
+ */
+static uint32_t handle_iso_out_pkt_dropped(dwc_otg_core_if_t * core_if,
+					   dwc_ep_t * dwc_ep)
+{
+	uint32_t dma_addr;
+	uint32_t drp_pkt;
+	uint32_t drp_pkt_cnt;
+	deptsiz_data_t deptsiz = {.d32 = 0 };
+	depctl_data_t depctl = {.d32 = 0 };
+	int i;
+
+	deptsiz.d32 =
+	    DWC_READ_REG32(&core_if->dev_if->
+			   out_ep_regs[dwc_ep->num]->doeptsiz);
+
+	drp_pkt = dwc_ep->pkt_cnt - deptsiz.b.pktcnt;
+	drp_pkt_cnt = dwc_ep->pkt_per_frm - (drp_pkt % dwc_ep->pkt_per_frm);
+
+	/* Setting dropped packets status */
+	for (i = 0; i < drp_pkt_cnt; ++i) {
+		dwc_ep->pkt_info[drp_pkt].status = -DWC_E_NO_DATA;
+		drp_pkt++;
+		deptsiz.b.pktcnt--;
+	}
+
+	if (deptsiz.b.pktcnt > 0) {
+		deptsiz.b.xfersize =
+		    dwc_ep->xfer_len - (dwc_ep->pkt_cnt -
+					deptsiz.b.pktcnt) * dwc_ep->maxpacket;
+	} else {
+		deptsiz.b.xfersize = 0;
+		deptsiz.b.pktcnt = 0;
+	}
+
+	DWC_WRITE_REG32(&core_if->dev_if->out_ep_regs[dwc_ep->num]->doeptsiz,
+			deptsiz.d32);
+
+	if (deptsiz.b.pktcnt > 0) {
+		if (dwc_ep->proc_buf_num) {
+			dma_addr =
+			    dwc_ep->dma_addr1 + dwc_ep->xfer_len -
+			    deptsiz.b.xfersize;
+		} else {
+			dma_addr =
+			    dwc_ep->dma_addr0 + dwc_ep->xfer_len -
+			    deptsiz.b.xfersize;;
+		}
+
+		DWC_WRITE_REG32(&core_if->dev_if->
+				out_ep_regs[dwc_ep->num]->doepdma, dma_addr);
+
+		/** Re-enable endpoint, clear nak  */
+		depctl.d32 = 0;
+		depctl.b.epena = 1;
+		depctl.b.cnak = 1;
+
+		DWC_MODIFY_REG32(&core_if->dev_if->
+				 out_ep_regs[dwc_ep->num]->doepctl, depctl.d32,
+				 depctl.d32);
+		return 0;
+	} else {
+		return 1;
+	}
+}
+
+/**
+ * This function sets iso packets information(PTI mode)
+ *
+ * @param core_if Programming view of DWC_otg controller.
+ * @param ep The EP to start the transfer on.
+ *
+ */
+static uint32_t set_iso_pkts_info(dwc_otg_core_if_t * core_if, dwc_ep_t * ep)
+{
+	int i, j;
+	dma_addr_t dma_ad;
+	iso_pkt_info_t *packet_info = ep->pkt_info;
+	uint32_t offset;
+	uint32_t frame_data;
+	deptsiz_data_t deptsiz;
+
+	if (ep->proc_buf_num == 0) {
+		/** Buffer 0 descriptors setup */
+		dma_ad = ep->dma_addr0;
+	} else {
+		/** Buffer 1 descriptors setup */
+		dma_ad = ep->dma_addr1;
+	}
+
+	if (ep->is_in) {
+		deptsiz.d32 =
+		    DWC_READ_REG32(&core_if->dev_if->in_ep_regs[ep->num]->
+				   dieptsiz);
+	} else {
+		deptsiz.d32 =
+		    DWC_READ_REG32(&core_if->dev_if->out_ep_regs[ep->num]->
+				   doeptsiz);
+	}
+
+	if (!deptsiz.b.xfersize) {
+		offset = 0;
+		for (i = 0; i < ep->pkt_cnt; i += ep->pkt_per_frm) {
+			frame_data = ep->data_per_frame;
+			for (j = 0; j < ep->pkt_per_frm; ++j) {
+
+				/* Packet status - is not set as initially
+				 * it is set to 0 and if packet was sent
+				 successfully, status field will remain 0*/
+
+				/* Bytes has been transfered */
+				packet_info->length =
+				    (ep->maxpacket <
+				     frame_data) ? ep->maxpacket : frame_data;
+
+				/* Received packet offset */
+				packet_info->offset = offset;
+				offset += packet_info->length;
+				frame_data -= packet_info->length;
+
+				packet_info++;
+			}
+		}
+		return 1;
+	} else {
+		/* This is a workaround for in case of Transfer Complete with
+		 * PktDrpSts interrupts merging - in this case Transfer complete
+		 * interrupt for Isoc Out Endpoint is asserted without PktDrpSts
+		 * set and with DOEPTSIZ register non zero. Investigations showed,
+		 * that this happens when Out packet is dropped, but because of
+		 * interrupts merging during first interrupt handling PktDrpSts
+		 * bit is cleared and for next merged interrupts it is not reset.
+		 * In this case SW hadles the interrupt as if PktDrpSts bit is set.
+		 */
+		if (ep->is_in) {
+			return 1;
+		} else {
+			return handle_iso_out_pkt_dropped(core_if, ep);
+		}
+	}
+}
+
+/**
+ * This function is to handle Iso EP transfer complete interrupt
+ *
+ * @param pcd The PCD
+ * @param ep The EP for which transfer complete was asserted
+ *
+ */
+static void complete_iso_ep(dwc_otg_pcd_t * pcd, dwc_otg_pcd_ep_t * ep)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(ep->pcd);
+	dwc_ep_t *dwc_ep = &ep->dwc_ep;
+	uint8_t is_last = 0;
+
+	if (ep->dwc_ep.next_frame == 0xffffffff) {
+		DWC_WARN("Next frame is not set!\n");
+		return;
+	}
+
+	if (core_if->dma_enable) {
+		if (core_if->dma_desc_enable) {
+			set_ddma_iso_pkts_info(core_if, dwc_ep);
+			reinit_ddma_iso_xfer(core_if, dwc_ep);
+			is_last = 1;
+		} else {
+			if (core_if->pti_enh_enable) {
+				if (set_iso_pkts_info(core_if, dwc_ep)) {
+					dwc_ep->proc_buf_num =
+					    (dwc_ep->proc_buf_num ^ 1) & 0x1;
+					dwc_otg_iso_ep_start_buf_transfer
+					    (core_if, dwc_ep);
+					is_last = 1;
+				}
+			} else {
+				set_current_pkt_info(core_if, dwc_ep);
+				if (dwc_ep->cur_pkt >= dwc_ep->pkt_cnt) {
+					is_last = 1;
+					dwc_ep->cur_pkt = 0;
+					dwc_ep->proc_buf_num =
+					    (dwc_ep->proc_buf_num ^ 1) & 0x1;
+					if (dwc_ep->proc_buf_num) {
+						dwc_ep->cur_pkt_addr =
+						    dwc_ep->xfer_buff1;
+						dwc_ep->cur_pkt_dma_addr =
+						    dwc_ep->dma_addr1;
+					} else {
+						dwc_ep->cur_pkt_addr =
+						    dwc_ep->xfer_buff0;
+						dwc_ep->cur_pkt_dma_addr =
+						    dwc_ep->dma_addr0;
+					}
+
+				}
+				dwc_otg_iso_ep_start_frm_transfer(core_if,
+								  dwc_ep);
+			}
+		}
+	} else {
+		set_current_pkt_info(core_if, dwc_ep);
+		if (dwc_ep->cur_pkt >= dwc_ep->pkt_cnt) {
+			is_last = 1;
+			dwc_ep->cur_pkt = 0;
+			dwc_ep->proc_buf_num = (dwc_ep->proc_buf_num ^ 1) & 0x1;
+			if (dwc_ep->proc_buf_num) {
+				dwc_ep->cur_pkt_addr = dwc_ep->xfer_buff1;
+				dwc_ep->cur_pkt_dma_addr = dwc_ep->dma_addr1;
+			} else {
+				dwc_ep->cur_pkt_addr = dwc_ep->xfer_buff0;
+				dwc_ep->cur_pkt_dma_addr = dwc_ep->dma_addr0;
+			}
+
+		}
+		dwc_otg_iso_ep_start_frm_transfer(core_if, dwc_ep);
+	}
+	if (is_last)
+		dwc_otg_iso_buffer_done(pcd, ep, ep->iso_req_handle);
+}
+#endif /* DWC_EN_ISOC */
+
+/**
+ * This function handle BNA interrupt for Non Isochronous EPs
+ *
+ */
+static void dwc_otg_pcd_handle_noniso_bna(dwc_otg_pcd_ep_t * ep)
+{
+	dwc_ep_t *dwc_ep = &ep->dwc_ep;
+	volatile uint32_t *addr;
+	depctl_data_t depctl = {.d32 = 0 };
+	dwc_otg_pcd_t *pcd = ep->pcd;
+	dwc_otg_dev_dma_desc_t *dma_desc;
+	dev_dma_desc_sts_t sts = {.d32 = 0 };
+	dwc_otg_core_if_t *core_if = ep->pcd->core_if;
+	int i, start;
+
+	if (!dwc_ep->desc_cnt)
+		DWC_WARN("Ep%d %s Descriptor count = %d \n", dwc_ep->num,
+			 (dwc_ep->is_in ? "IN" : "OUT"), dwc_ep->desc_cnt);
+
+	if (core_if->core_params->cont_on_bna && !dwc_ep->is_in
+							&& dwc_ep->type != DWC_OTG_EP_TYPE_CONTROL) {
+		uint32_t doepdma;
+		dwc_otg_dev_out_ep_regs_t *out_regs =
+			core_if->dev_if->out_ep_regs[dwc_ep->num];
+		doepdma = DWC_READ_REG32(&(out_regs->doepdma));
+		start = (doepdma - dwc_ep->dma_desc_addr)/sizeof(dwc_otg_dev_dma_desc_t);
+		dma_desc = &(dwc_ep->desc_addr[start]);
+	} else {
+		start = 0;
+		dma_desc = dwc_ep->desc_addr;
+	}
+
+
+	for (i = start; i < dwc_ep->desc_cnt; ++i, ++dma_desc) {
+		sts.d32 = dma_desc->status.d32;
+		sts.b.bs = BS_HOST_READY;
+		dma_desc->status.d32 = sts.d32;
+	}
+
+	if (dwc_ep->is_in == 0) {
+		addr =
+		    &GET_CORE_IF(pcd)->dev_if->out_ep_regs[dwc_ep->num]->
+		    doepctl;
+	} else {
+		addr =
+		    &GET_CORE_IF(pcd)->dev_if->in_ep_regs[dwc_ep->num]->diepctl;
+	}
+	depctl.b.epena = 1;
+	depctl.b.cnak = 1;
+	DWC_MODIFY_REG32(addr, 0, depctl.d32);
+}
+
+/**
+ * This function handles EP0 Control transfers.
+ *
+ * The state of the control transfers are tracked in
+ * <code>ep0state</code>.
+ */
+static void handle_ep0(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_otg_pcd_ep_t *ep0 = &pcd->ep0;
+	dev_dma_desc_sts_t desc_sts;
+	deptsiz0_data_t deptsiz;
+	uint32_t byte_count;
+
+#ifdef DEBUG_EP0
+	DWC_DEBUGPL(DBG_PCDV, "%s()\n", __func__);
+	print_ep0_state(pcd);
+#endif
+
+	switch (pcd->ep0state) {
+	case EP0_DISCONNECT:
+		break;
+
+	case EP0_IDLE:
+		pcd->request_config = 0;
+
+		pcd_setup(pcd);
+		break;
+
+	case EP0_IN_DATA_PHASE:
+#ifdef DEBUG_EP0
+		DWC_DEBUGPL(DBG_PCD, "DATA_IN EP%d-%s: type=%d, mps=%d\n",
+			    ep0->dwc_ep.num, (ep0->dwc_ep.is_in ? "IN" : "OUT"),
+			    ep0->dwc_ep.type, ep0->dwc_ep.maxpacket);
+#endif
+
+		if (core_if->dma_enable != 0) {
+			/*
+			 * For EP0 we can only program 1 packet at a time so we
+			 * need to do the make calculations after each complete.
+			 * Call write_packet to make the calculations, as in
+			 * slave mode, and use those values to determine if we
+			 * can complete.
+			 */
+			if (core_if->dma_desc_enable == 0) {
+				deptsiz.d32 =
+				    DWC_READ_REG32(&core_if->
+						   dev_if->in_ep_regs[0]->
+						   dieptsiz);
+				byte_count =
+				    ep0->dwc_ep.xfer_len - deptsiz.b.xfersize;
+			} else {
+				desc_sts =
+				    core_if->dev_if->in_desc_addr->status;
+				byte_count =
+				    ep0->dwc_ep.xfer_len - desc_sts.b.bytes;
+			}
+			ep0->dwc_ep.xfer_count += byte_count;
+			ep0->dwc_ep.xfer_buff += byte_count;
+			ep0->dwc_ep.dma_addr += byte_count;
+		}
+		if (ep0->dwc_ep.xfer_count < ep0->dwc_ep.total_len) {
+			dwc_otg_ep0_continue_transfer(GET_CORE_IF(pcd),
+						      &ep0->dwc_ep);
+			DWC_DEBUGPL(DBG_PCD, "CONTINUE TRANSFER\n");
+		} else if (ep0->dwc_ep.sent_zlp) {
+			dwc_otg_ep0_continue_transfer(GET_CORE_IF(pcd),
+						      &ep0->dwc_ep);
+			ep0->dwc_ep.sent_zlp = 0;
+			DWC_DEBUGPL(DBG_PCD, "CONTINUE TRANSFER sent zlp\n");
+		} else {
+			ep0_complete_request(ep0);
+			DWC_DEBUGPL(DBG_PCD, "COMPLETE TRANSFER\n");
+		}
+		break;
+	case EP0_OUT_DATA_PHASE:
+#ifdef DEBUG_EP0
+		DWC_DEBUGPL(DBG_PCD, "DATA_OUT EP%d-%s: type=%d, mps=%d\n",
+			    ep0->dwc_ep.num, (ep0->dwc_ep.is_in ? "IN" : "OUT"),
+			    ep0->dwc_ep.type, ep0->dwc_ep.maxpacket);
+#endif
+		if (core_if->dma_enable != 0) {
+			if (core_if->dma_desc_enable == 0) {
+				deptsiz.d32 =
+				    DWC_READ_REG32(&core_if->
+						   dev_if->out_ep_regs[0]->
+						   doeptsiz);
+				byte_count =
+				    ep0->dwc_ep.maxpacket - deptsiz.b.xfersize;
+			} else {
+				desc_sts =
+				    core_if->dev_if->out_desc_addr->status;
+				byte_count =
+				    ep0->dwc_ep.maxpacket - desc_sts.b.bytes;
+			}
+			ep0->dwc_ep.xfer_count += byte_count;
+			ep0->dwc_ep.xfer_buff += byte_count;
+			ep0->dwc_ep.dma_addr += byte_count;
+		}
+		if (ep0->dwc_ep.xfer_count < ep0->dwc_ep.total_len) {
+			dwc_otg_ep0_continue_transfer(GET_CORE_IF(pcd),
+						      &ep0->dwc_ep);
+			DWC_DEBUGPL(DBG_PCD, "CONTINUE TRANSFER\n");
+		} else if (ep0->dwc_ep.sent_zlp) {
+			dwc_otg_ep0_continue_transfer(GET_CORE_IF(pcd),
+						      &ep0->dwc_ep);
+			ep0->dwc_ep.sent_zlp = 0;
+			DWC_DEBUGPL(DBG_PCD, "CONTINUE TRANSFER sent zlp\n");
+		} else {
+			ep0_complete_request(ep0);
+			DWC_DEBUGPL(DBG_PCD, "COMPLETE TRANSFER\n");
+		}
+		break;
+
+	case EP0_IN_STATUS_PHASE:
+	case EP0_OUT_STATUS_PHASE:
+		DWC_DEBUGPL(DBG_PCD, "CASE: EP0_STATUS\n");
+		ep0_complete_request(ep0);
+		pcd->ep0state = EP0_IDLE;
+		ep0->stopped = 1;
+		ep0->dwc_ep.is_in = 0;	/* OUT for next SETUP */
+
+		/* Prepare for more SETUP Packets */
+		if (core_if->dma_enable) {
+			ep0_out_start(core_if, pcd);
+		}
+		break;
+
+	case EP0_STALL:
+		DWC_ERROR("EP0 STALLed, should not get here pcd_setup()\n");
+		break;
+	}
+#ifdef DEBUG_EP0
+	print_ep0_state(pcd);
+#endif
+}
+
+/**
+ * Restart transfer
+ */
+static void restart_transfer(dwc_otg_pcd_t * pcd, const uint32_t epnum)
+{
+	dwc_otg_core_if_t *core_if;
+	dwc_otg_dev_if_t *dev_if;
+	deptsiz_data_t dieptsiz = {.d32 = 0 };
+	dwc_otg_pcd_ep_t *ep;
+
+	ep = get_in_ep(pcd, epnum);
+
+#ifdef DWC_EN_ISOC
+	if (ep->dwc_ep.type == DWC_OTG_EP_TYPE_ISOC) {
+		return;
+	}
+#endif /* DWC_EN_ISOC  */
+
+	core_if = GET_CORE_IF(pcd);
+	dev_if = core_if->dev_if;
+
+	dieptsiz.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->dieptsiz);
+
+	DWC_DEBUGPL(DBG_PCD, "xfer_buff=%p xfer_count=%0x xfer_len=%0x"
+		    " stopped=%d\n", ep->dwc_ep.xfer_buff,
+		    ep->dwc_ep.xfer_count, ep->dwc_ep.xfer_len, ep->stopped);
+	/*
+	 * If xfersize is 0 and pktcnt in not 0, resend the last packet.
+	 */
+	if (dieptsiz.b.pktcnt && dieptsiz.b.xfersize == 0 &&
+	    ep->dwc_ep.start_xfer_buff != 0) {
+		if (ep->dwc_ep.total_len <= ep->dwc_ep.maxpacket) {
+			ep->dwc_ep.xfer_count = 0;
+			ep->dwc_ep.xfer_buff = ep->dwc_ep.start_xfer_buff;
+			ep->dwc_ep.xfer_len = ep->dwc_ep.xfer_count;
+		} else {
+			ep->dwc_ep.xfer_count -= ep->dwc_ep.maxpacket;
+			/* convert packet size to dwords. */
+			ep->dwc_ep.xfer_buff -= ep->dwc_ep.maxpacket;
+			ep->dwc_ep.xfer_len = ep->dwc_ep.xfer_count;
+		}
+		ep->stopped = 0;
+		DWC_DEBUGPL(DBG_PCD, "xfer_buff=%p xfer_count=%0x "
+			    "xfer_len=%0x stopped=%d\n",
+			    ep->dwc_ep.xfer_buff,
+			    ep->dwc_ep.xfer_count, ep->dwc_ep.xfer_len,
+			    ep->stopped);
+		if (epnum == 0) {
+			dwc_otg_ep0_start_transfer(core_if, &ep->dwc_ep);
+		} else {
+			dwc_otg_ep_start_transfer(core_if, &ep->dwc_ep);
+		}
+	}
+}
+
+/*
+ * This function create new nextep sequnce based on Learn Queue.
+ *
+ * @param core_if Programming view of DWC_otg controller
+ */
+void predict_nextep_seq( dwc_otg_core_if_t * core_if)
+{
+	dwc_otg_device_global_regs_t *dev_global_regs =
+	    core_if->dev_if->dev_global_regs;
+	const uint32_t TOKEN_Q_DEPTH = core_if->hwcfg2.b.dev_token_q_depth;
+	/* Number of Token Queue Registers */
+	const int DTKNQ_REG_CNT = (TOKEN_Q_DEPTH + 7) / 8;
+	dtknq1_data_t dtknqr1;
+	uint32_t in_tkn_epnums[4];
+	uint8_t seqnum[MAX_EPS_CHANNELS];
+	uint8_t intkn_seq[TOKEN_Q_DEPTH];
+	grstctl_t resetctl = {.d32 = 0 };
+	uint8_t temp;
+	int ndx = 0;
+	int start = 0;
+	int end = 0;
+	int sort_done = 0;
+	int i = 0;
+	volatile uint32_t *addr = &dev_global_regs->dtknqr1;
+
+	DWC_DEBUGPL(DBG_PCD, "dev_token_q_depth=%d\n", TOKEN_Q_DEPTH);
+
+	/* Read the DTKNQ Registers */
+	for (i = 0; i < DTKNQ_REG_CNT; i++) {
+		in_tkn_epnums[i] = DWC_READ_REG32(addr);
+		DWC_DEBUGPL(DBG_PCDV, "DTKNQR%d=0x%08x\n", i + 1,
+			    in_tkn_epnums[i]);
+		if (addr == &dev_global_regs->dvbusdis) {
+			addr = &dev_global_regs->dtknqr3_dthrctl;
+		} else {
+			++addr;
+		}
+
+	}
+
+	/* Copy the DTKNQR1 data to the bit field. */
+	dtknqr1.d32 = in_tkn_epnums[0];
+	if (dtknqr1.b.wrap_bit) {
+		ndx = dtknqr1.b.intknwptr;
+		end = ndx - 1;
+		if (end < 0)
+			end = TOKEN_Q_DEPTH - 1;
+	} else {
+		ndx = 0;
+		end = dtknqr1.b.intknwptr - 1;
+		if (end < 0)
+			end = 0;
+	}
+	start = ndx;
+
+	/* Fill seqnum[] by initial values: EP number + 31 */
+	for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+		seqnum[i] = i + 31;
+	}
+
+	/* Fill intkn_seq[] from in_tkn_epnums[0] */
+	for (i = 0; i < 6; i++)
+		intkn_seq[i] = (in_tkn_epnums[0] >> ((7 - i) * 4)) & 0xf;
+
+	if (TOKEN_Q_DEPTH > 6) {
+		/* Fill intkn_seq[] from in_tkn_epnums[1] */
+		for (i = 6; i < 14; i++)
+			intkn_seq[i] =
+			    (in_tkn_epnums[1] >> ((7 - (i - 6)) * 4)) & 0xf;
+	}
+
+	if (TOKEN_Q_DEPTH > 14) {
+		/* Fill intkn_seq[] from in_tkn_epnums[1] */
+		for (i = 14; i < 22; i++)
+			intkn_seq[i] =
+			    (in_tkn_epnums[2] >> ((7 - (i - 14)) * 4)) & 0xf;
+	}
+
+	if (TOKEN_Q_DEPTH > 22) {
+		/* Fill intkn_seq[] from in_tkn_epnums[1] */
+		for (i = 22; i < 30; i++)
+			intkn_seq[i] =
+			    (in_tkn_epnums[3] >> ((7 - (i - 22)) * 4)) & 0xf;
+	}
+
+	DWC_DEBUGPL(DBG_PCDV, "%s start=%d end=%d intkn_seq[]:\n", __func__,
+		    start, end);
+	for (i = 0; i < TOKEN_Q_DEPTH; i++)
+		DWC_DEBUGPL(DBG_PCDV, "%d\n", intkn_seq[i]);
+
+	/* Update seqnum based on intkn_seq[] */
+	i = 0;
+	do {
+		seqnum[intkn_seq[ndx]] = i;
+		ndx++;
+		i++;
+		if (ndx == TOKEN_Q_DEPTH)
+			ndx = 0;
+	} while (i < TOKEN_Q_DEPTH);
+
+	/* Mark non active EP's in seqnum[] by 0xff */
+	for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+		if (core_if->nextep_seq[i] == 0xff)
+			seqnum[i] = 0xff;
+	}
+
+	/* Sort seqnum[] */
+	sort_done = 0;
+	while (!sort_done) {
+		sort_done = 1;
+		for (i = 0; i < core_if->dev_if->num_in_eps; i++) {
+			if (seqnum[i] > seqnum[i + 1]) {
+				temp = seqnum[i];
+				seqnum[i] = seqnum[i + 1];
+				seqnum[i + 1] = temp;
+				sort_done = 0;
+			}
+		}
+	}
+
+	ndx = start + seqnum[0];
+	if (ndx >= TOKEN_Q_DEPTH)
+		ndx = ndx % TOKEN_Q_DEPTH;
+	core_if->first_in_nextep_seq = intkn_seq[ndx];
+
+	/* Update seqnum[] by EP numbers  */
+	for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+		ndx = start + i;
+		if (seqnum[i] < 31) {
+			ndx = start + seqnum[i];
+			if (ndx >= TOKEN_Q_DEPTH)
+				ndx = ndx % TOKEN_Q_DEPTH;
+			seqnum[i] = intkn_seq[ndx];
+		} else {
+			if (seqnum[i] < 0xff) {
+				seqnum[i] = seqnum[i] - 31;
+			} else {
+				break;
+			}
+		}
+	}
+
+	/* Update nextep_seq[] based on seqnum[] */
+	for (i = 0; i < core_if->dev_if->num_in_eps; i++) {
+		if (seqnum[i] != 0xff) {
+			if (seqnum[i + 1] != 0xff) {
+				core_if->nextep_seq[seqnum[i]] = seqnum[i + 1];
+			} else {
+				core_if->nextep_seq[seqnum[i]] = core_if->first_in_nextep_seq;
+				break;
+			}
+		} else {
+			break;
+		}
+	}
+
+	DWC_DEBUGPL(DBG_PCDV, "%s first_in_nextep_seq= %2d; nextep_seq[]:\n",
+		    __func__, core_if->first_in_nextep_seq);
+	for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+		DWC_DEBUGPL(DBG_PCDV, "%2d\n", core_if->nextep_seq[i]);
+	}
+
+	/* Flush the Learning Queue */
+	resetctl.d32 = DWC_READ_REG32(&core_if->core_global_regs->grstctl);
+	resetctl.b.intknqflsh = 1;
+	DWC_WRITE_REG32(&core_if->core_global_regs->grstctl, resetctl.d32);
+
+
+}
+
+/**
+ * handle the IN EP disable interrupt.
+ */
+static inline void handle_in_ep_disable_intr(dwc_otg_pcd_t * pcd,
+					     const uint32_t epnum)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	deptsiz_data_t dieptsiz = {.d32 = 0 };
+	dctl_data_t dctl = {.d32 = 0 };
+	dwc_otg_pcd_ep_t *ep;
+	dwc_ep_t *dwc_ep;
+	gintmsk_data_t gintmsk_data;
+	depctl_data_t depctl;
+	uint32_t diepdma;
+	uint32_t remain_to_transfer = 0;
+	uint8_t i;
+	uint32_t xfer_size;
+
+	ep = get_in_ep(pcd, epnum);
+	dwc_ep = &ep->dwc_ep;
+
+	if (dwc_ep->type == DWC_OTG_EP_TYPE_ISOC) {
+		dwc_otg_flush_tx_fifo(core_if, dwc_ep->tx_fifo_num);
+		complete_ep(ep);
+		return;
+	}
+
+	DWC_DEBUGPL(DBG_PCD, "diepctl%d=%0x\n", epnum,
+		    DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->diepctl));
+	dieptsiz.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->dieptsiz);
+	depctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->diepctl);
+
+	DWC_DEBUGPL(DBG_ANY, "pktcnt=%d size=%d\n",
+		    dieptsiz.b.pktcnt, dieptsiz.b.xfersize);
+
+	if ((core_if->start_predict == 0) || (depctl.b.eptype & 1)) {
+		if (ep->stopped) {
+			if (core_if->en_multiple_tx_fifo)
+				/* Flush the Tx FIFO */
+				dwc_otg_flush_tx_fifo(core_if, dwc_ep->tx_fifo_num);
+			/* Clear the Global IN NP NAK */
+			dctl.d32 = 0;
+			dctl.b.cgnpinnak = 1;
+			DWC_MODIFY_REG32(&dev_if->dev_global_regs->dctl, dctl.d32, dctl.d32);
+			/* Restart the transaction */
+			if (dieptsiz.b.pktcnt != 0 || dieptsiz.b.xfersize != 0) {
+				restart_transfer(pcd, epnum);
+			}
+		} else {
+			/* Restart the transaction */
+			if (dieptsiz.b.pktcnt != 0 || dieptsiz.b.xfersize != 0) {
+				restart_transfer(pcd, epnum);
+			}
+			DWC_DEBUGPL(DBG_ANY, "STOPPED!!!\n");
+		}
+		return;
+	}
+
+	if (core_if->start_predict > 2) {	// NP IN EP
+		core_if->start_predict--;
+		return;
+	}
+
+	core_if->start_predict--;
+
+	if (core_if->start_predict == 1) {	// All NP IN Ep's disabled now
+
+		predict_nextep_seq(core_if);
+
+		/* Update all active IN EP's NextEP field based of nextep_seq[] */
+		for (i = 0; i <= core_if->dev_if->num_in_eps; i++) {
+			depctl.d32 =
+			    DWC_READ_REG32(&dev_if->in_ep_regs[i]->diepctl);
+			if (core_if->nextep_seq[i] != 0xff) {	// Active NP IN EP
+				depctl.b.nextep = core_if->nextep_seq[i];
+				DWC_WRITE_REG32(&dev_if->in_ep_regs[i]->diepctl, depctl.d32);
+			}
+		}
+		/* Flush Shared NP TxFIFO */
+		dwc_otg_flush_tx_fifo(core_if, 0);
+		/* Rewind buffers */
+		if (!core_if->dma_desc_enable) {
+			i = core_if->first_in_nextep_seq;
+			do {
+				ep = get_in_ep(pcd, i);
+				dieptsiz.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[i]->dieptsiz);
+				xfer_size = ep->dwc_ep.total_len - ep->dwc_ep.xfer_count;
+				if (xfer_size > ep->dwc_ep.maxxfer)
+					xfer_size = ep->dwc_ep.maxxfer;
+				depctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[i]->diepctl);
+				if (dieptsiz.b.pktcnt != 0) {
+					if (xfer_size == 0) {
+						remain_to_transfer = 0;
+					} else {
+						if ((xfer_size % ep->dwc_ep.maxpacket) == 0) {
+							remain_to_transfer =
+								dieptsiz.b.pktcnt * ep->dwc_ep.maxpacket;
+						} else {
+							remain_to_transfer = ((dieptsiz.b.pktcnt -1) * ep->dwc_ep.maxpacket)
+								+ (xfer_size % ep->dwc_ep.maxpacket);
+						}
+					}
+					diepdma = DWC_READ_REG32(&dev_if->in_ep_regs[i]->diepdma);
+					dieptsiz.b.xfersize = remain_to_transfer;
+					DWC_WRITE_REG32(&dev_if->in_ep_regs[i]->dieptsiz, dieptsiz.d32);
+					diepdma = ep->dwc_ep.dma_addr + (xfer_size - remain_to_transfer);
+					DWC_WRITE_REG32(&dev_if->in_ep_regs[i]->diepdma, diepdma);
+				}
+				i = core_if->nextep_seq[i];
+			} while (i != core_if->first_in_nextep_seq);
+		} else { // dma_desc_enable
+				DWC_PRINTF("%s Learning Queue not supported in DDMA\n", __func__);
+		}
+
+		/* Restart transfers in predicted sequences */
+		i = core_if->first_in_nextep_seq;
+		do {
+			dieptsiz.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[i]->dieptsiz);
+			depctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[i]->diepctl);
+			if (dieptsiz.b.pktcnt != 0) {
+				depctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[i]->diepctl);
+				depctl.b.epena = 1;
+				depctl.b.cnak = 1;
+				DWC_WRITE_REG32(&dev_if->in_ep_regs[i]->diepctl, depctl.d32);
+			}
+			i = core_if->nextep_seq[i];
+		} while (i != core_if->first_in_nextep_seq);
+
+		/* Clear the global non-periodic IN NAK handshake */
+		dctl.d32 = 0;
+		dctl.b.cgnpinnak = 1;
+		DWC_MODIFY_REG32(&dev_if->dev_global_regs->dctl, dctl.d32, dctl.d32);
+
+		/* Unmask EP Mismatch interrupt */
+		gintmsk_data.d32 = 0;
+		gintmsk_data.b.epmismatch = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gintmsk, 0, gintmsk_data.d32);
+
+		core_if->start_predict = 0;
+
+	}
+}
+
+/**
+ * Handler for the IN EP timeout handshake interrupt.
+ */
+static inline void handle_in_ep_timeout_intr(dwc_otg_pcd_t * pcd,
+					     const uint32_t epnum)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+
+#ifdef DEBUG
+	deptsiz_data_t dieptsiz = {.d32 = 0 };
+	uint32_t num = 0;
+#endif
+	dctl_data_t dctl = {.d32 = 0 };
+	dwc_otg_pcd_ep_t *ep;
+
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+
+	ep = get_in_ep(pcd, epnum);
+
+	/* Disable the NP Tx Fifo Empty Interrrupt */
+	if (!core_if->dma_enable) {
+		intr_mask.b.nptxfempty = 1;
+		DWC_MODIFY_REG32(&core_if->core_global_regs->gintmsk,
+				 intr_mask.d32, 0);
+	}
+	/** @todo NGS Check EP type.
+	 * Implement for Periodic EPs */
+	/*
+	 * Non-periodic EP
+	 */
+	/* Enable the Global IN NAK Effective Interrupt */
+	intr_mask.b.ginnakeff = 1;
+	DWC_MODIFY_REG32(&core_if->core_global_regs->gintmsk, 0, intr_mask.d32);
+
+	/* Set Global IN NAK */
+	dctl.b.sgnpinnak = 1;
+	DWC_MODIFY_REG32(&dev_if->dev_global_regs->dctl, dctl.d32, dctl.d32);
+
+	ep->stopped = 1;
+
+#ifdef DEBUG
+	dieptsiz.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[num]->dieptsiz);
+	DWC_DEBUGPL(DBG_ANY, "pktcnt=%d size=%d\n",
+		    dieptsiz.b.pktcnt, dieptsiz.b.xfersize);
+#endif
+
+#ifdef DISABLE_PERIODIC_EP
+	/*
+	 * Set the NAK bit for this EP to
+	 * start the disable process.
+	 */
+	diepctl.d32 = 0;
+	diepctl.b.snak = 1;
+	DWC_MODIFY_REG32(&dev_if->in_ep_regs[num]->diepctl, diepctl.d32,
+			 diepctl.d32);
+	ep->disabling = 1;
+	ep->stopped = 1;
+#endif
+}
+
+/**
+ * Handler for the IN EP NAK interrupt.
+ */
+static inline int32_t handle_in_ep_nak_intr(dwc_otg_pcd_t * pcd,
+					    const uint32_t epnum)
+{
+	/** @todo implement ISR */
+	dwc_otg_core_if_t *core_if;
+	diepmsk_data_t intr_mask = {.d32 = 0 };
+
+	DWC_PRINTF("INTERRUPT Handler not implemented for %s\n", "IN EP NAK");
+	core_if = GET_CORE_IF(pcd);
+	intr_mask.b.nak = 1;
+
+	if (core_if->multiproc_int_enable) {
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->
+				 diepeachintmsk[epnum], intr_mask.d32, 0);
+	} else {
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->diepmsk,
+				 intr_mask.d32, 0);
+	}
+
+	return 1;
+}
+
+/**
+ * Handler for the OUT EP Babble interrupt.
+ */
+static inline int32_t handle_out_ep_babble_intr(dwc_otg_pcd_t * pcd,
+						const uint32_t epnum)
+{
+	/** @todo implement ISR */
+	dwc_otg_core_if_t *core_if;
+	doepmsk_data_t intr_mask = {.d32 = 0 };
+
+	DWC_PRINTF("INTERRUPT Handler not implemented for %s\n",
+		   "OUT EP Babble");
+	core_if = GET_CORE_IF(pcd);
+	intr_mask.b.babble = 1;
+
+	if (core_if->multiproc_int_enable) {
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->
+				 doepeachintmsk[epnum], intr_mask.d32, 0);
+	} else {
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->doepmsk,
+				 intr_mask.d32, 0);
+	}
+
+	return 1;
+}
+
+/**
+ * Handler for the OUT EP NAK interrupt.
+ */
+static inline int32_t handle_out_ep_nak_intr(dwc_otg_pcd_t * pcd,
+					     const uint32_t epnum)
+{
+	/** @todo implement ISR */
+	dwc_otg_core_if_t *core_if;
+	doepmsk_data_t intr_mask = {.d32 = 0 };
+
+	DWC_DEBUGPL(DBG_ANY, "INTERRUPT Handler not implemented for %s\n", "OUT EP NAK");
+	core_if = GET_CORE_IF(pcd);
+	intr_mask.b.nak = 1;
+
+	if (core_if->multiproc_int_enable) {
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->
+				 doepeachintmsk[epnum], intr_mask.d32, 0);
+	} else {
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->doepmsk,
+				 intr_mask.d32, 0);
+	}
+
+	return 1;
+}
+
+/**
+ * Handler for the OUT EP NYET interrupt.
+ */
+static inline int32_t handle_out_ep_nyet_intr(dwc_otg_pcd_t * pcd,
+					      const uint32_t epnum)
+{
+	/** @todo implement ISR */
+	dwc_otg_core_if_t *core_if;
+	doepmsk_data_t intr_mask = {.d32 = 0 };
+
+	DWC_PRINTF("INTERRUPT Handler not implemented for %s\n", "OUT EP NYET");
+	core_if = GET_CORE_IF(pcd);
+	intr_mask.b.nyet = 1;
+
+	if (core_if->multiproc_int_enable) {
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->
+				 doepeachintmsk[epnum], intr_mask.d32, 0);
+	} else {
+		DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->doepmsk,
+				 intr_mask.d32, 0);
+	}
+
+	return 1;
+}
+static void handle_xfercompl_iso_ddma (dwc_otg_dev_if_t *dev_if, dwc_otg_pcd_ep_t *ep)
+{
+	 depctl_data_t depctl;
+	 dwc_ep_t *dwc_ep;
+	 uint32_t doepdma;
+	 dwc_dma_t dma_desc_addr;
+	 dwc_otg_dev_dma_desc_t *dma_desc;
+	 int index = 0;
+	 uint8_t epnum;
+
+	 dwc_ep = &ep->dwc_ep;
+	 epnum = dwc_ep->num;
+
+	 complete_ddma_iso_ep(ep);
+
+	 if (dwc_ep->is_in) {
+		 depctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->diepctl);
+		 if (!depctl.b.epena) {
+			 if (dwc_ep->use_add_buf) {
+				 DWC_DEBUGPL(DBG_PCD, "go to second buffer \n");
+				 dwc_ep->use_add_buf = 0;
+				 dwc_ep->iso_desc_first = 0;
+				 if (dwc_ep->iso_desc_second) {
+					 depctl_data_t diepctl;
+					 DWC_WRITE_REG32(&dev_if->in_ep_regs[epnum]->diepdma,
+						 dwc_ep->dma_desc_addr1);
+					 diepctl.d32 = 0;
+					 diepctl.b.epena = 1;
+					 diepctl.b.cnak = 1;
+					 DWC_MODIFY_REG32(&dev_if->in_ep_regs[epnum]->diepctl,
+						 0, diepctl.d32);
+				 } else {
+					 DWC_DEBUGPL(DBG_PCD, "DDMA: No more ISOC requests 1\n");
+				 }
+			 } else {
+				 DWC_DEBUGPL(DBG_PCD, "go to first buffer \n");
+				 dwc_ep->use_add_buf = 1;
+				 dwc_ep->iso_desc_second = 0;
+				 if (dwc_ep->iso_desc_first) {
+					 depctl_data_t diepctl;
+					 DWC_WRITE_REG32(&dev_if->in_ep_regs[epnum]->diepdma,
+						 dwc_ep->dma_desc_addr);
+					 diepctl.d32 = 0;
+					 diepctl.b.epena = 1;
+					 diepctl.b.cnak = 1;
+					 DWC_MODIFY_REG32(&dev_if->in_ep_regs[epnum]->diepctl,
+						 0, diepctl.d32);
+				 } else {
+					 DWC_DEBUGPL(DBG_PCD, "DDMA: No more ISOC requests 2\n");
+				 }
+			 }
+		 }
+	 } else {
+		 depctl.d32 = DWC_READ_REG32(&dev_if->out_ep_regs[epnum]->doepctl);
+		 doepdma = DWC_READ_REG32(&dev_if->out_ep_regs[epnum]->doepdma);
+
+		 if (dwc_ep->use_add_buf) {
+			 index = dwc_ep->iso_desc_first;
+			 dma_desc_addr = dwc_ep->dma_desc_addr;
+		 } else {
+			 index = dwc_ep->iso_desc_second;
+			 dma_desc_addr = dwc_ep->dma_desc_addr1;
+		 }
+
+		 if (index == (doepdma - dma_desc_addr)/sizeof(dwc_otg_dev_dma_desc_t)) {
+			 depctl.d32 = 0;
+			 depctl.b.epdis = 1;
+			 DWC_MODIFY_REG32(&dev_if->out_ep_regs[epnum]->doepctl, 0, depctl.d32);
+		 }
+		 dma_desc = dwc_ep->desc_addr + dwc_ep->iso_desc_first;
+		 if (!depctl.b.epena) {
+			 if (dwc_ep->use_add_buf) {
+				 DWC_DEBUGPL(DBG_PCD, "go to second buffer \n");
+				 dwc_ep->use_add_buf = 0;
+				 dwc_ep->iso_desc_first = 0;
+				 if (dwc_ep->iso_desc_second) {
+					 DWC_WRITE_REG32(&dev_if->out_ep_regs[epnum]->doepdma, dwc_ep->dma_desc_addr1);
+					 depctl.d32 = 0;
+					 depctl.b.epena = 1;
+					 depctl.b.cnak = 1;
+					 DWC_MODIFY_REG32(&dev_if->out_ep_regs[epnum]->doepctl, 0, depctl.d32);
+				 } else {
+					 DWC_DEBUGPL(DBG_PCD, "DDMA: There are no more ISOC requests 1!!! \n");
+				 }
+			 } else {
+				 dwc_ep->use_add_buf = 1;
+				 dwc_ep->iso_desc_second = 0;
+				 if (dwc_ep->iso_desc_first) {
+					 DWC_DEBUGPL(DBG_PCD, "go to first buffer");
+					 DWC_WRITE_REG32(&dev_if->out_ep_regs[epnum]->doepdma, dwc_ep->dma_desc_addr);
+					 depctl.d32 = 0;
+					 depctl.b.epena = 1;
+					 depctl.b.cnak = 1;
+					 DWC_MODIFY_REG32(&dev_if->out_ep_regs[epnum]->doepctl, 0, depctl.d32);
+				 } else {
+					 DWC_DEBUGPL(DBG_PCD, "DDMA: There are no more ISOC requests 2!!! \n");
+				 }
+			 }
+		 }
+	 }
+}
+/**
+ * This interrupt indicates that an IN EP has a pending Interrupt.
+ * The sequence for handling the IN EP interrupt is shown below:
+ * -#	Read the Device All Endpoint Interrupt register
+ * -#	Repeat the following for each IN EP interrupt bit set (from
+ *		LSB to MSB).
+ * -#	Read the Device Endpoint Interrupt (DIEPINTn) register
+ * -#	If "Transfer Complete" call the request complete function
+ * -#	If "Endpoint Disabled" complete the EP disable procedure.
+ * -#	If "AHB Error Interrupt" log error
+ * -#	If "Time-out Handshake" log error
+ * -#	If "IN Token Received when TxFIFO Empty" write packet to Tx
+ *		FIFO.
+ * -#	If "IN Token EP Mismatch" (disable, this is handled by EP
+ *		Mismatch Interrupt)
+ */
+static int32_t dwc_otg_pcd_handle_in_ep_intr(dwc_otg_pcd_t * pcd)
+{
+#define CLEAR_IN_EP_INTR(__core_if,__epnum,__intr) \
+do { \
+		diepint_data_t diepint = {.d32=0}; \
+		diepint.b.__intr = 1; \
+		DWC_WRITE_REG32(&__core_if->dev_if->in_ep_regs[__epnum]->diepint, \
+		diepint.d32); \
+} while (0)
+
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	dwc_otg_dev_if_t *dev_if = core_if->dev_if;
+	diepint_data_t diepint = {.d32 = 0 };
+	depctl_data_t depctl = {.d32 = 0 };
+	uint32_t ep_intr;
+	uint32_t epnum = 0;
+	dwc_otg_pcd_ep_t *ep;
+	dwc_ep_t *dwc_ep;
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, pcd);
+
+	/* Read in the device interrupt bits */
+	ep_intr = dwc_otg_read_dev_all_in_ep_intr(core_if);
+
+	/* Service the Device IN interrupts for each endpoint */
+	while (ep_intr) {
+		if (ep_intr & 0x1) {
+			uint32_t empty_msk;
+			/* Get EP pointer */
+			ep = get_in_ep(pcd, epnum);
+			dwc_ep = &ep->dwc_ep;
+
+			depctl.d32 =
+			    DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->diepctl);
+			empty_msk =
+			    DWC_READ_REG32(&dev_if->
+					   dev_global_regs->dtknqr4_fifoemptymsk);
+
+			DWC_DEBUGPL(DBG_PCDV,
+				    "IN EP INTERRUPT - %d\nepmty_msk - %8x  diepctl - %8x\n",
+				    epnum, empty_msk, depctl.d32);
+
+			DWC_DEBUGPL(DBG_PCD,
+				    "EP%d-%s: type=%d, mps=%d\n",
+				    dwc_ep->num, (dwc_ep->is_in ? "IN" : "OUT"),
+				    dwc_ep->type, dwc_ep->maxpacket);
+
+			diepint.d32 =
+			    dwc_otg_read_dev_in_ep_intr(core_if, dwc_ep);
+
+			DWC_DEBUGPL(DBG_PCDV,
+				    "EP %d Interrupt Register - 0x%x\n", epnum,
+				    diepint.d32);
+			/* Transfer complete */
+			if (diepint.b.xfercompl) {
+				/* Disable the NP Tx FIFO Empty
+				 * Interrupt */
+				if (core_if->en_multiple_tx_fifo == 0) {
+					intr_mask.b.nptxfempty = 1;
+					DWC_MODIFY_REG32
+					    (&core_if->core_global_regs->gintmsk,
+					     intr_mask.d32, 0);
+				} else {
+					/* Disable the Tx FIFO Empty Interrupt for this EP */
+					uint32_t fifoemptymsk =
+					    0x1 << dwc_ep->num;
+					DWC_MODIFY_REG32(&core_if->
+							 dev_if->dev_global_regs->dtknqr4_fifoemptymsk,
+							 fifoemptymsk, 0);
+				}
+				/* Clear the bit in DIEPINTn for this interrupt */
+				CLEAR_IN_EP_INTR(core_if, epnum, xfercompl);
+
+				/* Complete the transfer */
+				if (epnum == 0) {
+					handle_ep0(pcd);
+				}
+#ifdef DWC_EN_ISOC
+				else if (dwc_ep->type == DWC_OTG_EP_TYPE_ISOC) {
+					if (!ep->stopped)
+						complete_iso_ep(pcd, ep);
+				}
+#endif /* DWC_EN_ISOC */
+#ifdef DWC_UTE_PER_IO
+				else if (dwc_ep->type == DWC_OTG_EP_TYPE_ISOC) {
+					if (!ep->stopped)
+						complete_xiso_ep(ep);
+				}
+#endif /* DWC_UTE_PER_IO */
+				else {
+					if (core_if->dma_desc_enable && dwc_ep->type == DWC_OTG_EP_TYPE_ISOC) {
+						handle_xfercompl_iso_ddma(dev_if, ep);
+					} else {
+						if (dwc_ep->type == DWC_OTG_EP_TYPE_ISOC &&
+								dwc_ep->bInterval > 1) {
+							dwc_ep->frame_num += dwc_ep->bInterval;
+							if (dwc_ep->frame_num > 0x3FFF)
+							{
+								dwc_ep->frm_overrun = 1;
+								dwc_ep->frame_num &= 0x3FFF;
+							} else
+								dwc_ep->frm_overrun = 0;
+						}
+						complete_ep(ep);
+						if(diepint.b.nak)
+							CLEAR_IN_EP_INTR(core_if, epnum, nak);
+					}
+				}
+			}
+			/* Endpoint disable      */
+			if (diepint.b.epdisabled) {
+				DWC_DEBUGPL(DBG_ANY, "EP%d IN disabled\n",
+					    epnum);
+				handle_in_ep_disable_intr(pcd, epnum);
+
+				/* Clear the bit in DIEPINTn for this interrupt */
+				CLEAR_IN_EP_INTR(core_if, epnum, epdisabled);
+			}
+			/* AHB Error */
+			if (diepint.b.ahberr) {
+				DWC_ERROR("EP%d IN AHB Error\n", epnum);
+				/* Clear the bit in DIEPINTn for this interrupt */
+				CLEAR_IN_EP_INTR(core_if, epnum, ahberr);
+			}
+			/* TimeOUT Handshake (non-ISOC IN EPs) */
+			if (diepint.b.timeout) {
+				DWC_ERROR("EP%d IN Time-out\n", epnum);
+				handle_in_ep_timeout_intr(pcd, epnum);
+
+				CLEAR_IN_EP_INTR(core_if, epnum, timeout);
+			}
+			/** IN Token received with TxF Empty */
+			if (diepint.b.intktxfemp) {
+				DWC_DEBUGPL(DBG_ANY,
+					    "EP%d IN TKN TxFifo Empty\n",
+					    epnum);
+				if (!ep->stopped && epnum != 0) {
+
+					diepmsk_data_t diepmsk = {.d32 = 0 };
+					diepmsk.b.intktxfemp = 1;
+
+					if (core_if->multiproc_int_enable) {
+						DWC_MODIFY_REG32
+						    (&dev_if->dev_global_regs->diepeachintmsk
+						     [epnum], diepmsk.d32, 0);
+					} else {
+						DWC_MODIFY_REG32
+						    (&dev_if->dev_global_regs->diepmsk,
+						     diepmsk.d32, 0);
+					}
+				} else if (core_if->dma_desc_enable
+					   && epnum == 0
+					   && pcd->ep0state ==
+					   EP0_OUT_STATUS_PHASE) {
+					// EP0 IN set STALL
+					depctl.d32 =
+					    DWC_READ_REG32(&dev_if->in_ep_regs
+							   [epnum]->diepctl);
+
+					/* set the disable and stall bits */
+					if (depctl.b.epena) {
+						depctl.b.epdis = 1;
+					}
+					depctl.b.stall = 1;
+					DWC_WRITE_REG32(&dev_if->in_ep_regs
+							[epnum]->diepctl,
+							depctl.d32);
+				}
+				CLEAR_IN_EP_INTR(core_if, epnum, intktxfemp);
+			}
+			/** IN Token Received with EP mismatch */
+			if (diepint.b.intknepmis) {
+				DWC_DEBUGPL(DBG_ANY,
+					    "EP%d IN TKN EP Mismatch\n", epnum);
+				CLEAR_IN_EP_INTR(core_if, epnum, intknepmis);
+			}
+			/** IN Endpoint NAK Effective */
+			if (diepint.b.inepnakeff) {
+				DWC_DEBUGPL(DBG_ANY,
+					    "EP%d IN EP NAK Effective\n",
+					    epnum);
+				/* Periodic EP */
+				if (ep->disabling) {
+					depctl.d32 = 0;
+					depctl.b.snak = 1;
+					depctl.b.epdis = 1;
+					DWC_MODIFY_REG32(&dev_if->in_ep_regs
+							 [epnum]->diepctl,
+							 depctl.d32,
+							 depctl.d32);
+				}
+				CLEAR_IN_EP_INTR(core_if, epnum, inepnakeff);
+
+			}
+
+			/** IN EP Tx FIFO Empty Intr */
+			if (diepint.b.emptyintr) {
+				DWC_DEBUGPL(DBG_ANY,
+					    "EP%d Tx FIFO Empty Intr \n",
+					    epnum);
+				write_empty_tx_fifo(pcd, epnum);
+
+				CLEAR_IN_EP_INTR(core_if, epnum, emptyintr);
+
+			}
+
+			/** IN EP BNA Intr */
+			if (diepint.b.bna) {
+				CLEAR_IN_EP_INTR(core_if, epnum, bna);
+				if (core_if->dma_desc_enable) {
+#ifdef DWC_EN_ISOC
+					if (dwc_ep->type ==
+					    DWC_OTG_EP_TYPE_ISOC) {
+						/*
+						 * This checking is performed to prevent first "false" BNA
+						 * handling occuring right after reconnect
+						 */
+						if (dwc_ep->next_frame !=
+						    0xffffffff)
+							dwc_otg_pcd_handle_iso_bna(ep);
+					} else
+#endif				/* DWC_EN_ISOC */
+					{
+						dwc_otg_pcd_handle_noniso_bna(ep);
+					}
+				}
+			}
+			/* NAK Interrupt */
+			if (diepint.b.nak) {
+				DWC_DEBUGPL(DBG_ANY, "EP%d IN NAK Interrupt\n",
+					    epnum);
+				if (ep->dwc_ep.type == DWC_OTG_EP_TYPE_ISOC) {
+					if (core_if->dma_desc_enable) {
+						if (ep->dwc_ep.frame_num == 0xFFFFFFFF) {
+							ep->dwc_ep.frame_num = core_if->frame_num;
+							dwc_otg_pcd_start_iso_ddma(core_if, ep);
+						} else {
+							CLEAR_IN_EP_INTR(core_if, epnum, nak);
+						}
+					} else {
+						depctl_data_t depctl;
+						if (ep->dwc_ep.frame_num == 0xFFFFFFFF) {
+							ep->dwc_ep.frame_num = core_if->frame_num;
+							if (ep->dwc_ep.bInterval > 1) {
+								depctl.d32 = 0;
+								depctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[epnum]->diepctl);
+								if (ep->dwc_ep.frame_num & 0x1) {
+									depctl.b.setd1pid = 1;
+									depctl.b.setd0pid = 0;
+								} else {
+									depctl.b.setd0pid = 1;
+									depctl.b.setd1pid = 0;
+								}
+								DWC_WRITE_REG32(&dev_if->in_ep_regs[epnum]->diepctl, depctl.d32);
+							}
+							start_next_request(ep);
+						}
+						ep->dwc_ep.frame_num += ep->dwc_ep.bInterval;
+						if (dwc_ep->frame_num > 0x3FFF)	{
+							dwc_ep->frm_overrun = 1;
+							dwc_ep->frame_num &= 0x3FFF;
+						} else {
+							dwc_ep->frm_overrun = 0;
+						}
+					}
+				}
+
+				CLEAR_IN_EP_INTR(core_if, epnum, nak);
+			}
+		}
+		epnum++;
+		ep_intr >>= 1;
+	}
+
+	return 1;
+#undef CLEAR_IN_EP_INTR
+}
+
+/**
+ * This interrupt indicates that an OUT EP has a pending Interrupt.
+ * The sequence for handling the OUT EP interrupt is shown below:
+ * -#	Read the Device All Endpoint Interrupt register
+ * -#	Repeat the following for each OUT EP interrupt bit set (from
+ *		LSB to MSB).
+ * -#	Read the Device Endpoint Interrupt (DOEPINTn) register
+ * -#	If "Transfer Complete" call the request complete function
+ * -#	If "Endpoint Disabled" complete the EP disable procedure.
+ * -#	If "AHB Error Interrupt" log error
+ * -#	If "Setup Phase Done" process Setup Packet (See Standard USB
+ *		Command Processing)
+ */
+static int32_t dwc_otg_pcd_handle_out_ep_intr(dwc_otg_pcd_t * pcd)
+{
+#define CLEAR_OUT_EP_INTR(__core_if,__epnum,__intr) \
+do { \
+		doepint_data_t doepint = {.d32=0}; \
+		doepint.b.__intr = 1; \
+		DWC_WRITE_REG32(&__core_if->dev_if->out_ep_regs[__epnum]->doepint, \
+		doepint.d32); \
+} while (0)
+
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	uint32_t ep_intr;
+	doepint_data_t doepint = {.d32 = 0 };
+	uint32_t epnum = 0;
+	dwc_otg_pcd_ep_t *ep;
+	dwc_ep_t *dwc_ep;
+	dctl_data_t dctl = {.d32 = 0 };
+	gintmsk_data_t gintmsk = {.d32 = 0 };
+
+
+	DWC_DEBUGPL(DBG_PCDV, "%s()\n", __func__);
+
+	/* Read in the device interrupt bits */
+	ep_intr = dwc_otg_read_dev_all_out_ep_intr(core_if);
+
+	while (ep_intr) {
+		if (ep_intr & 0x1) {
+			/* Get EP pointer */
+			ep = get_out_ep(pcd, epnum);
+			dwc_ep = &ep->dwc_ep;
+
+#ifdef VERBOSE
+			DWC_DEBUGPL(DBG_PCDV,
+				    "EP%d-%s: type=%d, mps=%d\n",
+				    dwc_ep->num, (dwc_ep->is_in ? "IN" : "OUT"),
+				    dwc_ep->type, dwc_ep->maxpacket);
+#endif
+			doepint.d32 =
+			    dwc_otg_read_dev_out_ep_intr(core_if, dwc_ep);
+
+			/* Transfer complete */
+			if (doepint.b.xfercompl) {
+
+				if (epnum == 0) {
+					/* Clear the bit in DOEPINTn for this interrupt */
+					CLEAR_OUT_EP_INTR(core_if, epnum, xfercompl);
+					if (core_if->snpsid >= OTG_CORE_REV_3_00a) {
+						DWC_DEBUGPL(DBG_PCDV, "in xfer xomplete DOEPINT=%x doepint=%x\n",
+							DWC_READ_REG32(&core_if->dev_if->out_ep_regs[0]->doepint),
+							doepint.d32);
+						DWC_DEBUGPL(DBG_PCDV, "DOEPCTL=%x \n",
+							DWC_READ_REG32(&core_if->dev_if->out_ep_regs[0]->doepctl));
+
+						if (core_if->snpsid >= OTG_CORE_REV_3_00a
+							&& core_if->dma_enable == 0) {
+							doepint_data_t doepint;
+							doepint.d32 = DWC_READ_REG32(&core_if->dev_if->
+														out_ep_regs[0]->doepint);
+							if (pcd->ep0state == EP0_IDLE && doepint.b.sr) {
+								CLEAR_OUT_EP_INTR(core_if, epnum, sr);
+								if (doepint.b.stsphsercvd)
+									CLEAR_OUT_EP_INTR(core_if, epnum, stsphsercvd);
+								goto exit_xfercompl;
+							}
+						}
+						/* In case of DDMA  look at SR bit to go to the Data Stage */
+						if (core_if->dma_desc_enable) {
+							dev_dma_desc_sts_t status = {.d32 = 0};
+							if (pcd->ep0state == EP0_IDLE) {
+								status.d32 = core_if->dev_if->setup_desc_addr[core_if->
+											dev_if->setup_desc_index]->status.d32;
+								if(pcd->data_terminated) {
+									 pcd->data_terminated = 0;
+									 status.d32 = core_if->dev_if->out_desc_addr->status.d32;
+									 dwc_memcpy(&pcd->setup_pkt->req, pcd->backup_buf, 8);
+								}
+								if (status.b.sr) {
+									if (doepint.b.setup) {
+										DWC_DEBUGPL(DBG_PCDV, "DMA DESC EP0_IDLE SR=1 setup=1\n");
+										/* Already started data stage, clear setup */
+										CLEAR_OUT_EP_INTR(core_if, epnum, setup);
+										doepint.b.setup = 0;
+										handle_ep0(pcd);
+										/* Prepare for more setup packets */
+										if (pcd->ep0state == EP0_IN_STATUS_PHASE ||
+											pcd->ep0state == EP0_IN_DATA_PHASE) {
+											ep0_out_start(core_if, pcd);
+										}
+
+										goto exit_xfercompl;
+									} else {
+										/* Prepare for more setup packets */
+										DWC_DEBUGPL(DBG_PCDV,
+											"EP0_IDLE SR=1 setup=0 new setup comes\n");
+										ep0_out_start(core_if, pcd);
+									}
+								}
+							} else {
+								dwc_otg_pcd_request_t *req;
+								dev_dma_desc_sts_t status = {.d32 = 0};
+								diepint_data_t diepint0;
+								diepint0.d32 = DWC_READ_REG32(&core_if->dev_if->
+															in_ep_regs[0]->diepint);
+
+								if (pcd->ep0state == EP0_STALL || pcd->ep0state == EP0_DISCONNECT) {
+									DWC_ERROR("EP0 is stalled/disconnected\n");
+								}
+
+								/* Clear IN xfercompl if set */
+								if (diepint0.b.xfercompl && (pcd->ep0state == EP0_IN_STATUS_PHASE
+									|| pcd->ep0state == EP0_IN_DATA_PHASE)) {
+									DWC_WRITE_REG32(&core_if->dev_if->
+										in_ep_regs[0]->diepint, diepint0.d32);
+								}
+
+								status.d32 = core_if->dev_if->setup_desc_addr[core_if->
+									dev_if->setup_desc_index]->status.d32;
+
+								if ((pcd->ep0state == EP0_OUT_STATUS_PHASE) ||
+									(ep->dwc_ep.xfer_count != ep->dwc_ep.total_len
+									&& pcd->ep0state == EP0_OUT_DATA_PHASE))
+									status.d32 = core_if->dev_if->out_desc_addr->status.d32;
+								if (status.b.sr) {
+									if (DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+										DWC_DEBUGPL(DBG_PCDV, "Request queue empty!!\n");
+									} else {
+										DWC_DEBUGPL(DBG_PCDV, "complete req!!\n");
+										req = DWC_CIRCLEQ_FIRST(&ep->queue);
+										if (ep->dwc_ep.xfer_count != ep->dwc_ep.total_len &&
+											pcd->ep0state == EP0_OUT_DATA_PHASE) {
+												/* Read arrived setup packet from req->buf */
+												dwc_memcpy(&pcd->setup_pkt->req,
+													req->buf + ep->dwc_ep.xfer_count, 8);
+										}
+										req->actual = ep->dwc_ep.xfer_count;
+										dwc_otg_request_done(ep, req, -ECONNRESET);
+										ep->dwc_ep.start_xfer_buff = 0;
+										ep->dwc_ep.xfer_buff = 0;
+										ep->dwc_ep.xfer_len = 0;
+									}
+									pcd->ep0state = EP0_IDLE;
+									if (doepint.b.setup) {
+										DWC_DEBUGPL(DBG_PCDV, "EP0_IDLE SR=1 setup=1\n");
+										/* Data stage started, clear setup */
+										CLEAR_OUT_EP_INTR(core_if, epnum, setup);
+										doepint.b.setup = 0;
+										handle_ep0(pcd);
+										/* Prepare for setup packets if ep0in was enabled*/
+										if (pcd->ep0state == EP0_IN_STATUS_PHASE) {
+											ep0_out_start(core_if, pcd);
+										}
+
+										goto exit_xfercompl;
+									} else {
+										/* Prepare for more setup packets */
+										DWC_DEBUGPL(DBG_PCDV,
+											"EP0_IDLE SR=1 setup=0 new setup comes 2\n");
+										ep0_out_start(core_if, pcd);
+									}
+								}
+							}
+						}
+						if (core_if->snpsid >= OTG_CORE_REV_3_00a && core_if->dma_enable
+							&& core_if->dma_desc_enable == 0) {
+							doepint_data_t doepint_temp = {.d32 = 0};
+							deptsiz0_data_t doeptsize0 = {.d32 = 0 };
+							doepint_temp.d32 = DWC_READ_REG32(&core_if->dev_if->
+															out_ep_regs[ep->dwc_ep.num]->doepint);
+							doeptsize0.d32 = DWC_READ_REG32(&core_if->dev_if->
+															out_ep_regs[ep->dwc_ep.num]->doeptsiz);
+							if (((ep->dwc_ep.xfer_count == ep->dwc_ep.total_len || doeptsize0.b.xfersize == 64) &&
+								pcd->ep0state == EP0_OUT_DATA_PHASE && doepint.b.stsphsercvd) ||
+								(doeptsize0.b.xfersize == 24 && pcd->ep0state == EP0_IN_STATUS_PHASE)) {
+									CLEAR_OUT_EP_INTR(core_if, epnum, xfercompl);
+									DWC_DEBUGPL(DBG_PCDV, "WA for xfercompl along with stsphs \n");
+									doepint.b.xfercompl = 0;
+									ep0_out_start(core_if, pcd);
+									goto exit_xfercompl;
+							}
+
+							if (pcd->ep0state == EP0_IDLE) {
+								if (doepint_temp.b.sr) {
+									CLEAR_OUT_EP_INTR(core_if, epnum, sr);
+								}
+									/* Delay is needed for core to update setup
+									 * packet count from 3 to 2 after receiving
+									 * setup packet*/
+									dwc_udelay(100);
+									doepint.d32 = DWC_READ_REG32(&core_if->dev_if->
+																	out_ep_regs[0]->doepint);
+									if (doeptsize0.b.supcnt == 3) {
+										DWC_DEBUGPL(DBG_ANY, "Rolling over!!!!!!!\n");
+										ep->dwc_ep.stp_rollover = 1;
+									}
+									if (doepint.b.setup) {
+retry:
+										/* Already started data stage, clear setup */
+										CLEAR_OUT_EP_INTR(core_if, epnum, setup);
+										doepint.b.setup = 0;
+										handle_ep0(pcd);
+										ep->dwc_ep.stp_rollover = 0;
+										/* Prepare for more setup packets */
+										if (pcd->ep0state == EP0_IN_STATUS_PHASE ||
+											pcd->ep0state == EP0_IN_DATA_PHASE) {
+											depctl_data_t depctl = {.d32 = 0};
+											depctl.b.cnak = 1;
+											ep0_out_start(core_if, pcd);
+											/* Core not updating setup packet count
+											 * in case of PET testing - @TODO vahrama
+											 * to check with HW team further */
+											if (!core_if->otg_ver) {
+												DWC_MODIFY_REG32(&core_if->dev_if->
+													out_ep_regs[0]->doepctl, 0, depctl.d32);
+											}
+										}
+										goto exit_xfercompl;
+									} else {
+										/* Prepare for more setup packets */
+										DWC_DEBUGPL(DBG_ANY,
+											"EP0_IDLE SR=1 setup=0 new setup comes\n");
+										doepint.d32 = DWC_READ_REG32(&core_if->dev_if->
+																	out_ep_regs[0]->doepint);
+										if(doepint.b.setup)
+											goto retry;
+										ep0_out_start(core_if, pcd);
+									}
+							} else {
+								dwc_otg_pcd_request_t *req;
+								diepint_data_t diepint0 = {.d32 = 0};
+								doepint_data_t doepint_temp = {.d32 = 0};
+								depctl_data_t diepctl0;
+								diepint0.d32 = DWC_READ_REG32(&core_if->dev_if->
+																in_ep_regs[0]->diepint);
+								diepctl0.d32 = DWC_READ_REG32(&core_if->dev_if->
+																in_ep_regs[0]->diepctl);
+
+								if (pcd->ep0state == EP0_IN_DATA_PHASE
+									|| pcd->ep0state == EP0_IN_STATUS_PHASE) {
+									if (diepint0.b.xfercompl) {
+										DWC_WRITE_REG32(&core_if->dev_if->
+											in_ep_regs[0]->diepint, diepint0.d32);
+									}
+									if (diepctl0.b.epena) {
+										diepint_data_t diepint = {.d32 = 0};
+										diepctl0.b.snak = 1;
+										DWC_WRITE_REG32(&core_if->dev_if->
+														in_ep_regs[0]->diepctl, diepctl0.d32);
+										do {
+											dwc_udelay(10);
+											diepint.d32 = DWC_READ_REG32(&core_if->dev_if->
+												in_ep_regs[0]->diepint);
+										} while (!diepint.b.inepnakeff);
+										diepint.b.inepnakeff = 1;
+										DWC_WRITE_REG32(&core_if->dev_if->
+											in_ep_regs[0]->diepint, diepint.d32);
+										diepctl0.d32 = 0;
+										diepctl0.b.epdis = 1;
+										DWC_WRITE_REG32(&core_if->dev_if->in_ep_regs[0]->diepctl,
+														diepctl0.d32);
+										do {
+											dwc_udelay(10);
+											diepint.d32 = DWC_READ_REG32(&core_if->dev_if->
+												in_ep_regs[0]->diepint);
+										} while (!diepint.b.epdisabled);
+										diepint.b.epdisabled = 1;
+										DWC_WRITE_REG32(&core_if->dev_if->in_ep_regs[0]->diepint,
+															diepint.d32);
+									}
+								}
+								doepint_temp.d32 = DWC_READ_REG32(&core_if->dev_if->
+																out_ep_regs[ep->dwc_ep.num]->doepint);
+								if (doepint_temp.b.sr) {
+									CLEAR_OUT_EP_INTR(core_if, epnum, sr);
+									if (DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+										DWC_DEBUGPL(DBG_PCDV, "Request queue empty!!\n");
+									} else {
+										DWC_DEBUGPL(DBG_PCDV, "complete req!!\n");
+										req = DWC_CIRCLEQ_FIRST(&ep->queue);
+										if (ep->dwc_ep.xfer_count != ep->dwc_ep.total_len &&
+											pcd->ep0state == EP0_OUT_DATA_PHASE) {
+												/* Read arrived setup packet from req->buf */
+												dwc_memcpy(&pcd->setup_pkt->req,
+													req->buf + ep->dwc_ep.xfer_count, 8);
+										}
+										req->actual = ep->dwc_ep.xfer_count;
+										dwc_otg_request_done(ep, req, -ECONNRESET);
+										ep->dwc_ep.start_xfer_buff = 0;
+										ep->dwc_ep.xfer_buff = 0;
+										ep->dwc_ep.xfer_len = 0;
+									}
+									pcd->ep0state = EP0_IDLE;
+									if (doepint.b.setup) {
+										DWC_DEBUGPL(DBG_PCDV, "EP0_IDLE SR=1 setup=1\n");
+										/* Data stage started, clear setup */
+										CLEAR_OUT_EP_INTR(core_if, epnum, setup);
+										doepint.b.setup = 0;
+										handle_ep0(pcd);
+										/* Prepare for setup packets if ep0in was enabled*/
+										if (pcd->ep0state == EP0_IN_STATUS_PHASE) {
+											depctl_data_t depctl = {.d32 = 0};
+											depctl.b.cnak = 1;
+											ep0_out_start(core_if, pcd);
+											/* Core not updating setup packet count
+											* in case of PET testing - @TODO vahrama
+											* to check with HW team further */
+											if (!core_if->otg_ver) {
+												DWC_MODIFY_REG32(&core_if->dev_if->
+														out_ep_regs[0]->doepctl, 0, depctl.d32);
+											}
+										}
+										goto exit_xfercompl;
+									} else {
+										/* Prepare for more setup packets */
+										DWC_DEBUGPL(DBG_PCDV,
+											"EP0_IDLE SR=1 setup=0 new setup comes 2\n");
+										ep0_out_start(core_if, pcd);
+									}
+								}
+							}
+						}
+						if (core_if->dma_enable == 0 || pcd->ep0state != EP0_IDLE)
+							handle_ep0(pcd);
+exit_xfercompl:
+						DWC_DEBUGPL(DBG_PCDV, "after DOEPINT=%x doepint=%x\n",
+							dwc_otg_read_dev_out_ep_intr(core_if, dwc_ep), doepint.d32);
+					} else {
+						if (core_if->dma_desc_enable == 0
+							|| pcd->ep0state != EP0_IDLE)
+							handle_ep0(pcd);
+					}
+#ifdef DWC_EN_ISOC
+				} else if (dwc_ep->type == DWC_OTG_EP_TYPE_ISOC) {
+					if (doepint.b.pktdrpsts == 0) {
+						/* Clear the bit in DOEPINTn for this interrupt */
+						CLEAR_OUT_EP_INTR(core_if,
+								  epnum,
+								  xfercompl);
+						complete_iso_ep(pcd, ep);
+					} else {
+
+						doepint_data_t doepint = {.d32 = 0 };
+						doepint.b.xfercompl = 1;
+						doepint.b.pktdrpsts = 1;
+						DWC_WRITE_REG32
+						    (&core_if->dev_if->out_ep_regs
+						     [epnum]->doepint,
+						     doepint.d32);
+						if (handle_iso_out_pkt_dropped
+						    (core_if, dwc_ep)) {
+							complete_iso_ep(pcd,
+									ep);
+						}
+					}
+#endif /* DWC_EN_ISOC */
+#ifdef DWC_UTE_PER_IO
+				} else if (dwc_ep->type == DWC_OTG_EP_TYPE_ISOC) {
+					CLEAR_OUT_EP_INTR(core_if, epnum, xfercompl);
+					if (!ep->stopped)
+						complete_xiso_ep(ep);
+#endif /* DWC_UTE_PER_IO */
+				} else {
+					/* Clear the bit in DOEPINTn for this interrupt */
+					CLEAR_OUT_EP_INTR(core_if, epnum,
+							  xfercompl);
+
+					if (core_if->core_params->dev_out_nak) {
+						DWC_TIMER_CANCEL(pcd->core_if->ep_xfer_timer[epnum]);
+						pcd->core_if->ep_xfer_info[epnum].state = 0;
+#ifdef DEBUG
+						print_memory_payload(pcd, dwc_ep);
+#endif
+					}
+					if (core_if->dma_desc_enable && dwc_ep->type == DWC_OTG_EP_TYPE_ISOC) {
+						handle_xfercompl_iso_ddma(core_if->dev_if, ep);
+					} else {
+						complete_ep(ep);
+					}
+				}
+
+			}
+			if (doepint.b.stsphsercvd) {
+				deptsiz0_data_t deptsiz;
+				CLEAR_OUT_EP_INTR(core_if, epnum, stsphsercvd);
+				deptsiz.d32 =
+					DWC_READ_REG32(&core_if->dev_if->
+					out_ep_regs[0]->doeptsiz);
+				if ((core_if->dma_desc_enable) || (core_if->dma_enable &&
+					core_if->snpsid >= OTG_CORE_REV_3_00a)) {
+						do_setup_in_status_phase(pcd);
+				}
+			}
+
+			/* Endpoint disable      */
+			if (doepint.b.epdisabled) {
+
+				/* Clear the bit in DOEPINTn for this interrupt */
+				CLEAR_OUT_EP_INTR(core_if, epnum, epdisabled);
+				if (core_if->core_params->dev_out_nak) {
+#ifdef DEBUG
+					print_memory_payload(pcd, dwc_ep);
+#endif
+					/* In case of timeout condition */
+					if (core_if->ep_xfer_info[epnum].state == 2) {
+						dctl.d32 = DWC_READ_REG32(&core_if->dev_if->
+										dev_global_regs->dctl);
+						dctl.b.cgoutnak = 1;
+						DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dctl,
+																dctl.d32);
+						/* Unmask goutnakeff interrupt which was masked
+						 * during handle nak out interrupt */
+						gintmsk.b.goutnakeff = 1;
+						DWC_MODIFY_REG32(&core_if->core_global_regs->gintmsk,
+																0, gintmsk.d32);
+
+						complete_ep(ep);
+					}
+				}
+				if (ep->dwc_ep.type == DWC_OTG_EP_TYPE_ISOC)
+				{
+					dctl_data_t dctl;
+					gintmsk_data_t intr_mask = {.d32 = 0};
+					dwc_otg_pcd_request_t *req = 0;
+
+					dctl.d32 = DWC_READ_REG32(&core_if->dev_if->
+						dev_global_regs->dctl);
+					dctl.b.cgoutnak = 1;
+					DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dctl,
+						dctl.d32);
+
+					intr_mask.d32 = 0;
+					intr_mask.b.incomplisoout = 1;
+
+					/* Get any pending requests */
+					if (!DWC_CIRCLEQ_EMPTY(&ep->queue)) {
+						req = DWC_CIRCLEQ_FIRST(&ep->queue);
+						if (!req) {
+							DWC_PRINTF("complete_ep 0x%p, req = NULL!\n", ep);
+						} else {
+							dwc_otg_request_done(ep, req, 0);
+							start_next_request(ep);
+						}
+					} else {
+						DWC_PRINTF("complete_ep 0x%p, ep->queue empty!\n", ep);
+					}
+				}
+			}
+			/* AHB Error */
+			if (doepint.b.ahberr) {
+				DWC_ERROR("EP%d OUT AHB Error\n", epnum);
+				DWC_ERROR("EP%d DEPDMA=0x%08x \n",
+					  epnum, core_if->dev_if->out_ep_regs[epnum]->doepdma);
+				CLEAR_OUT_EP_INTR(core_if, epnum, ahberr);
+			}
+			/* Setup Phase Done (contorl EPs) */
+			if (doepint.b.setup) {
+#ifdef DEBUG_EP0
+				DWC_DEBUGPL(DBG_PCD, "EP%d SETUP Done\n", epnum);
+#endif
+				CLEAR_OUT_EP_INTR(core_if, epnum, setup);
+
+				handle_ep0(pcd);
+			}
+
+			/** OUT EP BNA Intr */
+			if (doepint.b.bna) {
+				CLEAR_OUT_EP_INTR(core_if, epnum, bna);
+				if (core_if->dma_desc_enable) {
+#ifdef DWC_EN_ISOC
+					if (dwc_ep->type ==
+					    DWC_OTG_EP_TYPE_ISOC) {
+						/*
+						 * This checking is performed to prevent first "false" BNA
+						 * handling occuring right after reconnect
+						 */
+						if (dwc_ep->next_frame !=
+						    0xffffffff)
+							dwc_otg_pcd_handle_iso_bna(ep);
+					} else
+#endif				/* DWC_EN_ISOC */
+					if (ep->dwc_ep.type != DWC_OTG_EP_TYPE_ISOC) {
+						dwc_otg_pcd_handle_noniso_bna(ep);
+					}
+				}
+			}
+			/* Babble Interrupt */
+			if (doepint.b.babble) {
+				DWC_DEBUGPL(DBG_ANY, "EP%d OUT Babble\n",
+					    epnum);
+				handle_out_ep_babble_intr(pcd, epnum);
+
+				CLEAR_OUT_EP_INTR(core_if, epnum, babble);
+			}
+			if (doepint.b.outtknepdis) {
+				DWC_DEBUGPL(DBG_ANY, "EP%d OUT Token received when EP is \
+					disabled\n",epnum);
+				if (ep->dwc_ep.type == DWC_OTG_EP_TYPE_ISOC) {
+					if (core_if->dma_desc_enable) {
+						if (!ep->dwc_ep.iso_transfer_started) {
+							ep->dwc_ep.frame_num = core_if->frame_num;
+							dwc_otg_pcd_start_iso_ddma(core_if, ep);
+						}
+					} else {
+						doepmsk_data_t doepmsk = {.d32 = 0};
+						ep->dwc_ep.frame_num = core_if->frame_num;
+						if (ep->dwc_ep.bInterval > 1) {
+							depctl_data_t depctl;
+							depctl.d32 = DWC_READ_REG32(&core_if->dev_if->
+														out_ep_regs[epnum]->doepctl);
+							if (ep->dwc_ep.frame_num & 0x1) {
+								depctl.b.setd1pid = 1;
+								depctl.b.setd0pid = 0;
+							} else {
+								depctl.b.setd0pid = 1;
+								depctl.b.setd1pid = 0;
+							}
+							DWC_WRITE_REG32(&core_if->dev_if->
+											out_ep_regs[epnum]->doepctl, depctl.d32);
+						}
+
+						start_next_request(ep);
+						doepmsk.b.outtknepdis = 1;
+						DWC_MODIFY_REG32(&core_if->dev_if->dev_global_regs->doepmsk,
+								 doepmsk.d32, 0);
+					}
+				}
+				CLEAR_OUT_EP_INTR(core_if, epnum, outtknepdis);
+			}
+
+			/* NAK Interrutp */
+			if (doepint.b.nak) {
+				DWC_DEBUGPL(DBG_ANY, "EP%d OUT NAK\n", epnum);
+				handle_out_ep_nak_intr(pcd, epnum);
+
+				CLEAR_OUT_EP_INTR(core_if, epnum, nak);
+			}
+			/* NYET Interrutp */
+			if (doepint.b.nyet) {
+				DWC_DEBUGPL(DBG_ANY, "EP%d OUT NYET\n", epnum);
+				handle_out_ep_nyet_intr(pcd, epnum);
+
+				CLEAR_OUT_EP_INTR(core_if, epnum, nyet);
+			}
+		}
+
+		epnum++;
+		ep_intr >>= 1;
+	}
+
+	return 1;
+
+#undef CLEAR_OUT_EP_INTR
+}
+static int drop_transfer(uint32_t trgt_fr, uint32_t curr_fr, uint8_t frm_overrun)
+{
+	int retval = 0;
+	if(!frm_overrun && curr_fr >= trgt_fr)
+		retval = 1;
+	else if (frm_overrun
+		 && (curr_fr >= trgt_fr && ((curr_fr - trgt_fr) < 0x3FFF / 2)))
+		retval = 1;
+	return retval;
+}
+
+/**
+ * Incomplete ISO IN Transfer Interrupt.
+ * This interrupt indicates one of the following conditions occurred
+ * while transmitting an ISOC transaction.
+ * - Corrupted IN Token for ISOC EP.
+ * - Packet not complete in FIFO.
+ * The follow actions will be taken:
+ *	-#	Determine the EP
+ *	-#	Set incomplete flag in dwc_ep structure
+ *	-#	Disable EP; when "Endpoint Disabled" interrupt is received
+ *		Flush FIFO
+ */
+int32_t dwc_otg_pcd_handle_incomplete_isoc_in_intr(dwc_otg_pcd_t * pcd)
+{
+	gintsts_data_t gintsts;
+
+#ifdef DWC_EN_ISOC
+	dwc_otg_dev_if_t *dev_if;
+	deptsiz_data_t deptsiz = {.d32 = 0 };
+	depctl_data_t depctl = {.d32 = 0 };
+	dsts_data_t dsts = {.d32 = 0 };
+	dwc_ep_t *dwc_ep;
+	int i;
+
+	dev_if = GET_CORE_IF(pcd)->dev_if;
+
+	for (i = 1; i <= dev_if->num_in_eps; ++i) {
+		dwc_ep = &pcd->in_ep[i].dwc_ep;
+		if (dwc_ep->active && dwc_ep->type == DWC_OTG_EP_TYPE_ISOC) {
+			deptsiz.d32 =
+			    DWC_READ_REG32(&dev_if->in_ep_regs[i]->dieptsiz);
+			depctl.d32 =
+			    DWC_READ_REG32(&dev_if->in_ep_regs[i]->diepctl);
+
+			if (depctl.b.epdis && deptsiz.d32) {
+				set_current_pkt_info(GET_CORE_IF(pcd), dwc_ep);
+				if (dwc_ep->cur_pkt >= dwc_ep->pkt_cnt) {
+					dwc_ep->cur_pkt = 0;
+					dwc_ep->proc_buf_num =
+					    (dwc_ep->proc_buf_num ^ 1) & 0x1;
+
+					if (dwc_ep->proc_buf_num) {
+						dwc_ep->cur_pkt_addr =
+						    dwc_ep->xfer_buff1;
+						dwc_ep->cur_pkt_dma_addr =
+						    dwc_ep->dma_addr1;
+					} else {
+						dwc_ep->cur_pkt_addr =
+						    dwc_ep->xfer_buff0;
+						dwc_ep->cur_pkt_dma_addr =
+						    dwc_ep->dma_addr0;
+					}
+
+				}
+
+				dsts.d32 =
+				    DWC_READ_REG32(&GET_CORE_IF(pcd)->dev_if->
+						   dev_global_regs->dsts);
+				dwc_ep->next_frame = dsts.b.soffn;
+
+				dwc_otg_iso_ep_start_frm_transfer(GET_CORE_IF
+								  (pcd),
+								  dwc_ep);
+			}
+		}
+	}
+
+#else
+	depctl_data_t depctl = {.d32 = 0 };
+	dwc_ep_t *dwc_ep;
+	dwc_otg_dev_if_t *dev_if;
+	int i;
+	dev_if = GET_CORE_IF(pcd)->dev_if;
+
+	DWC_DEBUGPL(DBG_PCD,"Incomplete ISO IN \n");
+
+	for (i = 1; i <= dev_if->num_in_eps; ++i) {
+		dwc_ep = &pcd->in_ep[i-1].dwc_ep;
+		depctl.d32 =
+			DWC_READ_REG32(&dev_if->in_ep_regs[i]->diepctl);
+		if (depctl.b.epena && dwc_ep->type == DWC_OTG_EP_TYPE_ISOC) {
+			if (drop_transfer(dwc_ep->frame_num, GET_CORE_IF(pcd)->frame_num,
+							dwc_ep->frm_overrun))
+			{
+				depctl.d32 =
+					DWC_READ_REG32(&dev_if->in_ep_regs[i]->diepctl);
+				depctl.b.snak = 1;
+				depctl.b.epdis = 1;
+				DWC_MODIFY_REG32(&dev_if->in_ep_regs[i]->diepctl, depctl.d32, depctl.d32);
+			}
+		}
+	}
+
+	/*intr_mask.b.incomplisoin = 1;
+	   DWC_MODIFY_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintmsk,
+	   intr_mask.d32, 0);    */
+#endif //DWC_EN_ISOC
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.incomplisoin = 1;
+	DWC_WRITE_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintsts,
+			gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * Incomplete ISO OUT Transfer Interrupt.
+ *
+ * This interrupt indicates that the core has dropped an ISO OUT
+ * packet. The following conditions can be the cause:
+ * - FIFO Full, the entire packet would not fit in the FIFO.
+ * - CRC Error
+ * - Corrupted Token
+ * The follow actions will be taken:
+ *	-#	Determine the EP
+ *	-#	Set incomplete flag in dwc_ep structure
+ *	-#	Read any data from the FIFO
+ *	-#	Disable EP. When "Endpoint Disabled" interrupt is received
+ *		re-enable EP.
+ */
+int32_t dwc_otg_pcd_handle_incomplete_isoc_out_intr(dwc_otg_pcd_t * pcd)
+{
+
+	gintsts_data_t gintsts;
+
+#ifdef DWC_EN_ISOC
+	dwc_otg_dev_if_t *dev_if;
+	deptsiz_data_t deptsiz = {.d32 = 0 };
+	depctl_data_t depctl = {.d32 = 0 };
+	dsts_data_t dsts = {.d32 = 0 };
+	dwc_ep_t *dwc_ep;
+	int i;
+
+	dev_if = GET_CORE_IF(pcd)->dev_if;
+
+	for (i = 1; i <= dev_if->num_out_eps; ++i) {
+		dwc_ep = &pcd->in_ep[i].dwc_ep;
+		if (pcd->out_ep[i].dwc_ep.active &&
+		    pcd->out_ep[i].dwc_ep.type == DWC_OTG_EP_TYPE_ISOC) {
+			deptsiz.d32 =
+			    DWC_READ_REG32(&dev_if->out_ep_regs[i]->doeptsiz);
+			depctl.d32 =
+			    DWC_READ_REG32(&dev_if->out_ep_regs[i]->doepctl);
+
+			if (depctl.b.epdis && deptsiz.d32) {
+				set_current_pkt_info(GET_CORE_IF(pcd),
+						     &pcd->out_ep[i].dwc_ep);
+				if (dwc_ep->cur_pkt >= dwc_ep->pkt_cnt) {
+					dwc_ep->cur_pkt = 0;
+					dwc_ep->proc_buf_num =
+					    (dwc_ep->proc_buf_num ^ 1) & 0x1;
+
+					if (dwc_ep->proc_buf_num) {
+						dwc_ep->cur_pkt_addr =
+						    dwc_ep->xfer_buff1;
+						dwc_ep->cur_pkt_dma_addr =
+						    dwc_ep->dma_addr1;
+					} else {
+						dwc_ep->cur_pkt_addr =
+						    dwc_ep->xfer_buff0;
+						dwc_ep->cur_pkt_dma_addr =
+						    dwc_ep->dma_addr0;
+					}
+
+				}
+
+				dsts.d32 =
+				    DWC_READ_REG32(&GET_CORE_IF(pcd)->dev_if->
+						   dev_global_regs->dsts);
+				dwc_ep->next_frame = dsts.b.soffn;
+
+				dwc_otg_iso_ep_start_frm_transfer(GET_CORE_IF
+								  (pcd),
+								  dwc_ep);
+			}
+		}
+	}
+#else
+	/** @todo implement ISR */
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+	dwc_otg_core_if_t *core_if;
+	deptsiz_data_t deptsiz = {.d32 = 0 };
+	depctl_data_t depctl = {.d32 = 0 };
+	dctl_data_t dctl = {.d32 = 0 };
+	dwc_ep_t *dwc_ep = NULL;
+	int i;
+	core_if = GET_CORE_IF(pcd);
+
+	for (i = 0; i < core_if->dev_if->num_out_eps; ++i) {
+		dwc_ep = &pcd->out_ep[i].dwc_ep;
+		depctl.d32 =
+			DWC_READ_REG32(&core_if->dev_if->out_ep_regs[dwc_ep->num]->doepctl);
+		if (depctl.b.epena && depctl.b.dpid == (core_if->frame_num & 0x1)) {
+			core_if->dev_if->isoc_ep = dwc_ep;
+			deptsiz.d32 =
+					DWC_READ_REG32(&core_if->dev_if->out_ep_regs[dwc_ep->num]->doeptsiz);
+				break;
+		}
+	}
+	dctl.d32 = DWC_READ_REG32(&core_if->dev_if->dev_global_regs->dctl);
+	gintsts.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintsts);
+	intr_mask.d32 = DWC_READ_REG32(&core_if->core_global_regs->gintmsk);
+
+	if (!intr_mask.b.goutnakeff) {
+		/* Unmask it */
+		intr_mask.b.goutnakeff = 1;
+		DWC_WRITE_REG32(&core_if->core_global_regs->gintmsk, intr_mask.d32);
+	}
+	if (!gintsts.b.goutnakeff) {
+		dctl.b.sgoutnak = 1;
+	}
+	DWC_WRITE_REG32(&core_if->dev_if->dev_global_regs->dctl, dctl.d32);
+
+	depctl.d32 = DWC_READ_REG32(&core_if->dev_if->out_ep_regs[dwc_ep->num]->doepctl);
+	if (depctl.b.epena) {
+		depctl.b.epdis = 1;
+		depctl.b.snak = 1;
+	}
+	DWC_WRITE_REG32(&core_if->dev_if->out_ep_regs[dwc_ep->num]->doepctl, depctl.d32);
+
+	intr_mask.d32 = 0;
+	intr_mask.b.incomplisoout = 1;
+
+#endif /* DWC_EN_ISOC */
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.incomplisoout = 1;
+	DWC_WRITE_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintsts,
+			gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * This function handles the Global IN NAK Effective interrupt.
+ *
+ */
+int32_t dwc_otg_pcd_handle_in_nak_effective(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_dev_if_t *dev_if = GET_CORE_IF(pcd)->dev_if;
+	depctl_data_t diepctl = {.d32 = 0 };
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+	gintsts_data_t gintsts;
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+	int i;
+
+	DWC_DEBUGPL(DBG_PCD, "Global IN NAK Effective\n");
+
+	/* Disable all active IN EPs */
+	for (i = 0; i <= dev_if->num_in_eps; i++) {
+		diepctl.d32 = DWC_READ_REG32(&dev_if->in_ep_regs[i]->diepctl);
+		if (!(diepctl.b.eptype & 1) && diepctl.b.epena) {
+			if (core_if->start_predict > 0)
+				core_if->start_predict++;
+			diepctl.b.epdis = 1;
+			diepctl.b.snak = 1;
+			DWC_WRITE_REG32(&dev_if->in_ep_regs[i]->diepctl, diepctl.d32);
+		}
+	}
+
+
+	/* Disable the Global IN NAK Effective Interrupt */
+	intr_mask.b.ginnakeff = 1;
+	DWC_MODIFY_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintmsk,
+			 intr_mask.d32, 0);
+
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.ginnakeff = 1;
+	DWC_WRITE_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintsts,
+			gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * OUT NAK Effective.
+ *
+ */
+int32_t dwc_otg_pcd_handle_out_nak_effective(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_dev_if_t *dev_if = GET_CORE_IF(pcd)->dev_if;
+	gintmsk_data_t intr_mask = {.d32 = 0 };
+	gintsts_data_t gintsts;
+	depctl_data_t doepctl;
+	int i;
+
+	/* Disable the Global OUT NAK Effective Interrupt */
+	intr_mask.b.goutnakeff = 1;
+	DWC_MODIFY_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintmsk,
+			 intr_mask.d32, 0);
+
+	/* If DEV OUT NAK enabled */
+	if (pcd->core_if->core_params->dev_out_nak) {
+		/* Run over all out endpoints to determine the ep number on
+		 * which the timeout has happened
+		 */
+		for (i = 0; i <= dev_if->num_out_eps; i++) {
+			if (pcd->core_if->ep_xfer_info[i].state == 2)
+				break;
+		}
+		if (i > dev_if->num_out_eps) {
+			dctl_data_t dctl;
+			dctl.d32 =
+			    DWC_READ_REG32(&dev_if->dev_global_regs->dctl);
+			dctl.b.cgoutnak = 1;
+			DWC_WRITE_REG32(&dev_if->dev_global_regs->dctl,
+					dctl.d32);
+			goto out;
+		}
+
+		/* Disable the endpoint */
+		doepctl.d32 = DWC_READ_REG32(&dev_if->out_ep_regs[i]->doepctl);
+		if (doepctl.b.epena) {
+			doepctl.b.epdis = 1;
+			doepctl.b.snak = 1;
+		}
+		DWC_WRITE_REG32(&dev_if->out_ep_regs[i]->doepctl, doepctl.d32);
+		return 1;
+	}
+	/* We come here from Incomplete ISO OUT handler */
+	if (dev_if->isoc_ep) {
+		dwc_ep_t *dwc_ep = (dwc_ep_t *) dev_if->isoc_ep;
+		uint32_t epnum = dwc_ep->num;
+		doepint_data_t doepint;
+		doepint.d32 =
+		    DWC_READ_REG32(&dev_if->out_ep_regs[dwc_ep->num]->doepint);
+		dev_if->isoc_ep = NULL;
+		doepctl.d32 =
+		    DWC_READ_REG32(&dev_if->out_ep_regs[epnum]->doepctl);
+		DWC_PRINTF("Before disable DOEPCTL = %08x\n", doepctl.d32);
+		if (doepctl.b.epena) {
+			doepctl.b.epdis = 1;
+			doepctl.b.snak = 1;
+		}
+		DWC_WRITE_REG32(&dev_if->out_ep_regs[epnum]->doepctl,
+				doepctl.d32);
+		return 1;
+	} else
+		DWC_PRINTF("INTERRUPT Handler not implemented for %s\n",
+			   "Global OUT NAK Effective\n");
+
+out:
+	/* Clear interrupt */
+	gintsts.d32 = 0;
+	gintsts.b.goutnakeff = 1;
+	DWC_WRITE_REG32(&GET_CORE_IF(pcd)->core_global_regs->gintsts,
+			gintsts.d32);
+
+	return 1;
+}
+
+/**
+ * PCD interrupt handler.
+ *
+ * The PCD handles the device interrupts.  Many conditions can cause a
+ * device interrupt. When an interrupt occurs, the device interrupt
+ * service routine determines the cause of the interrupt and
+ * dispatches handling to the appropriate function. These interrupt
+ * handling functions are described below.
+ *
+ * All interrupt registers are processed from LSB to MSB.
+ *
+ */
+int32_t dwc_otg_pcd_handle_intr(dwc_otg_pcd_t * pcd)
+{
+	dwc_otg_core_if_t *core_if = GET_CORE_IF(pcd);
+#ifdef VERBOSE
+	dwc_otg_core_global_regs_t *global_regs = core_if->core_global_regs;
+#endif
+	gintsts_data_t gintr_status;
+	int32_t retval = 0;
+
+	if (dwc_otg_check_haps_status(core_if) == -1 ) {
+		DWC_WARN("HAPS is disconnected");
+		return retval;
+	}
+
+	/* Exit from ISR if core is hibernated */
+	if (core_if->hibernation_suspend == 1) {
+		return retval;
+	}
+#ifdef VERBOSE
+	DWC_DEBUGPL(DBG_ANY, "%s() gintsts=%08x	 gintmsk=%08x\n",
+		    __func__,
+		    DWC_READ_REG32(&global_regs->gintsts),
+		    DWC_READ_REG32(&global_regs->gintmsk));
+#endif
+
+	if (dwc_otg_is_device_mode(core_if)) {
+		DWC_SPINLOCK(pcd->lock);
+#ifdef VERBOSE
+		DWC_DEBUGPL(DBG_PCDV, "%s() gintsts=%08x  gintmsk=%08x\n",
+			    __func__,
+			    DWC_READ_REG32(&global_regs->gintsts),
+			    DWC_READ_REG32(&global_regs->gintmsk));
+#endif
+
+		gintr_status.d32 = dwc_otg_read_core_intr(core_if);
+
+		DWC_DEBUGPL(DBG_PCDV, "%s: gintsts&gintmsk=%08x\n",
+			    __func__, gintr_status.d32);
+
+		if (gintr_status.b.sofintr) {
+			retval |= dwc_otg_pcd_handle_sof_intr(pcd);
+		}
+		if (gintr_status.b.rxstsqlvl) {
+			retval |=
+			    dwc_otg_pcd_handle_rx_status_q_level_intr(pcd);
+		}
+		if (gintr_status.b.nptxfempty) {
+			retval |= dwc_otg_pcd_handle_np_tx_fifo_empty_intr(pcd);
+		}
+		if (gintr_status.b.goutnakeff) {
+			retval |= dwc_otg_pcd_handle_out_nak_effective(pcd);
+		}
+		if (gintr_status.b.i2cintr) {
+			retval |= dwc_otg_pcd_handle_i2c_intr(pcd);
+		}
+		if (gintr_status.b.erlysuspend) {
+			retval |= dwc_otg_pcd_handle_early_suspend_intr(pcd);
+			hisi_switch_func(0);
+		}
+		if (gintr_status.b.usbreset) {
+			retval |= dwc_otg_pcd_handle_usb_reset_intr(pcd);
+			hisi_switch_func(0);
+		}
+		if (gintr_status.b.enumdone) {
+			retval |= dwc_otg_pcd_handle_enum_done_intr(pcd);
+		}
+		if (gintr_status.b.isooutdrop) {
+			retval |=
+			    dwc_otg_pcd_handle_isoc_out_packet_dropped_intr
+			    (pcd);
+		}
+		if (gintr_status.b.eopframe) {
+			retval |=
+			    dwc_otg_pcd_handle_end_periodic_frame_intr(pcd);
+		}
+		if (gintr_status.b.inepint) {
+			if (!core_if->multiproc_int_enable) {
+				retval |= dwc_otg_pcd_handle_in_ep_intr(pcd);
+			}
+		}
+		if (gintr_status.b.outepintr) {
+			if (!core_if->multiproc_int_enable) {
+				retval |= dwc_otg_pcd_handle_out_ep_intr(pcd);
+			}
+		}
+		if (gintr_status.b.epmismatch) {
+			retval |= dwc_otg_pcd_handle_ep_mismatch_intr(pcd);
+		}
+		if (gintr_status.b.fetsusp) {
+			retval |= dwc_otg_pcd_handle_ep_fetsusp_intr(pcd);
+		}
+		if (gintr_status.b.ginnakeff) {
+			retval |= dwc_otg_pcd_handle_in_nak_effective(pcd);
+		}
+		if (gintr_status.b.incomplisoin) {
+			retval |=
+			    dwc_otg_pcd_handle_incomplete_isoc_in_intr(pcd);
+		}
+		if (gintr_status.b.incomplisoout) {
+			retval |=
+			    dwc_otg_pcd_handle_incomplete_isoc_out_intr(pcd);
+		}
+
+		/* In MPI mode Device Endpoints interrupts are asserted
+		 * without setting outepintr and inepint bits set, so these
+		 * Interrupt handlers are called without checking these bit-fields
+		 */
+		if (core_if->multiproc_int_enable) {
+			retval |= dwc_otg_pcd_handle_in_ep_intr(pcd);
+			retval |= dwc_otg_pcd_handle_out_ep_intr(pcd);
+		}
+#ifdef VERBOSE
+		DWC_DEBUGPL(DBG_PCDV, "%s() gintsts=%0x\n", __func__,
+			    DWC_READ_REG32(&global_regs->gintsts));
+#endif
+		DWC_SPINUNLOCK(pcd->lock);
+	}
+	return retval;
+}
+
+#endif /* DWC_HOST_ONLY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd_linux.c b/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd_linux.c
new file mode 100644
index 0000000..5efda52
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_pcd_linux.c
@@ -0,0 +1,1440 @@
+ /* ==========================================================================
+  * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_pcd_linux.c $
+  * $Revision: #28 $
+  * $Date: 2013/05/07 $
+  * $Change: 2224063 $
+  *
+  * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+  * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+  * otherwise expressly agreed to in writing between Synopsys and you.
+  *
+  * The Software IS NOT an item of Licensed Software or Licensed Product under
+  * any End User Software License Agreement or Agreement for Licensed Product
+  * with Synopsys or any supplement thereto. You are permitted to use and
+  * redistribute this Software in source and binary forms, with or without
+  * modification, provided that redistributions of source code must retain this
+  * notice. You may not view, use, disclose, copy or distribute this file or
+  * any information contained herein except pursuant to this license grant from
+  * Synopsys. If you do not agree with this notice, including the disclaimer
+  * below, then you are not authorized to use the Software.
+  *
+  * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+  * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+  * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+  * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+  * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+  * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+  * DAMAGE.
+  * ========================================================================== */
+#ifndef DWC_HOST_ONLY
+
+/** @file
+ * This file implements the Peripheral Controller Driver.
+ *
+ * The Peripheral Controller Driver (PCD) is responsible for
+ * translating requests from the Function Driver into the appropriate
+ * actions on the DWC_otg controller. It isolates the Function Driver
+ * from the specifics of the controller by providing an API to the
+ * Function Driver.
+ *
+ * The Peripheral Controller Driver for Linux will implement the
+ * Gadget API, so that the existing Gadget drivers can be used.
+ * (Gadget Driver is the Linux terminology for a Function Driver.)
+ *
+ * The Linux Gadget API is defined in the header file
+ * <code><linux/usb_gadget.h></code>.  The USB EP operations API is
+ * defined in the structure <code>usb_ep_ops</code> and the USB
+ * Controller API is defined in the structure
+ * <code>usb_gadget_ops</code>.
+ *
+ */
+
+#include "dwc_otg_os_dep.h"
+#include "dwc_otg_pcd_if.h"
+#include "dwc_otg_pcd.h"
+#include "dwc_otg_driver.h"
+#include "dwc_otg_dbg.h"
+
+static struct gadget_wrapper {
+	dwc_otg_pcd_t *pcd;
+
+	struct usb_gadget gadget;
+	struct usb_gadget_driver *driver;
+
+	struct usb_ep ep0;
+	struct usb_ep in_ep[16];
+	struct usb_ep out_ep[16];
+
+} *gadget_wrapper;
+
+/* Display the contents of the buffer */
+extern void dump_msg(const u8 * buf, unsigned int length);
+
+int udc_attach_driver(const char *name, struct usb_gadget_driver *driver)
+{
+	//do nothing ,only make
+	return 0;
+}
+EXPORT_SYMBOL_GPL(udc_attach_driver);
+
+static int usb_gadget_map_req(struct usb_gadget *gadget,
+		struct usb_request *req, struct dwc_otg_pcd_ep *ep)
+{
+	if (req->length == 0)
+		return 0;
+
+	if (req->num_sgs) {
+		dev_err(&gadget->dev, "controller not support scatter/gather dma\n");
+		return -EFAULT;
+
+	} else {
+
+		if (ep == &gadget_wrapper->pcd->ep0) {
+			req->dma = dma_map_single(&gadget->dev, req->buf, req->length,
+				DMA_BIDIRECTIONAL);
+		} else {
+			req->dma = dma_map_single(&gadget->dev, req->buf, req->length,
+				ep->dwc_ep.is_in ? DMA_TO_DEVICE : DMA_FROM_DEVICE);
+		}
+
+		if (dma_mapping_error(&gadget->dev, req->dma)) {
+			dev_err(&gadget->dev, "failed to map buffer\n");
+			return -EFAULT;
+		}
+	}
+
+	return 0;
+}
+
+static void usb_gadget_unmap_req(struct usb_gadget *gadget,
+		struct usb_request *req, struct dwc_otg_pcd_ep *ep)
+{
+	if (req->length == 0)
+		return;
+
+	if (req->num_mapped_sgs) {
+		dev_err(&gadget->dev, "controller not support scatter/gather dma\n");
+	} else {
+
+		if (ep == &gadget_wrapper->pcd->ep0) {
+			dma_unmap_single(&gadget->dev, req->dma, req->length,
+				DMA_BIDIRECTIONAL);
+		} else {
+			dma_unmap_single(&gadget->dev, req->dma, req->length,
+				ep->dwc_ep.is_in ? DMA_TO_DEVICE : DMA_FROM_DEVICE);
+		}
+	}
+}
+
+/**
+ * Get the dwc_otg_pcd_ep_t* from usb_ep* pointer - NULL in case
+ * if the endpoint is not found
+ */
+static struct dwc_otg_pcd_ep *ep_from_handle(dwc_otg_pcd_t * pcd, void *handle)
+{
+	int i;
+	if (pcd->ep0.priv == handle) {
+		return &pcd->ep0;
+	}
+
+	for (i = 0; i < MAX_EPS_CHANNELS - 1; i++) {
+		if (pcd->in_ep[i].priv == handle)
+			return &pcd->in_ep[i];
+		if (pcd->out_ep[i].priv == handle)
+			return &pcd->out_ep[i];
+	}
+
+	return NULL;
+}
+
+/* USB Endpoint Operations */
+/*
+ * The following sections briefly describe the behavior of the Gadget
+ * API endpoint operations implemented in the DWC_otg driver
+ * software. Detailed descriptions of the generic behavior of each of
+ * these functions can be found in the Linux header file
+ * include/linux/usb_gadget.h.
+ *
+ * The Gadget API provides wrapper functions for each of the function
+ * pointers defined in usb_ep_ops. The Gadget Driver calls the wrapper
+ * function, which then calls the underlying PCD function. The
+ * following sections are named according to the wrapper
+ * functions. Within each section, the corresponding DWC_otg PCD
+ * function name is specified.
+ *
+ */
+
+/**
+ * This function is called by the Gadget Driver for each EP to be
+ * configured for the current configuration (SET_CONFIGURATION).
+ *
+ * This function initializes the dwc_otg_ep_t data structure, and then
+ * calls dwc_otg_ep_activate.
+ */
+static int ep_enable(struct usb_ep *usb_ep,
+		     const struct usb_endpoint_descriptor *ep_desc)
+{
+	int retval;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p,%p)\n", __func__, usb_ep, ep_desc);
+
+	if (!usb_ep || !ep_desc || ep_desc->bDescriptorType != USB_DT_ENDPOINT) {
+		DWC_WARN("%s, bad ep or descriptor\n", __func__);
+		return -EINVAL;
+	}
+	if (usb_ep == &gadget_wrapper->ep0) {
+		DWC_WARN("%s, bad ep(0)\n", __func__);
+		return -EINVAL;
+	}
+
+	/* Check FIFO size? */
+	if (!ep_desc->wMaxPacketSize) {
+		DWC_WARN("%s, bad %s maxpacket\n", __func__, usb_ep->name);
+		return -ERANGE;
+	}
+
+	if (!gadget_wrapper->driver ||
+	    gadget_wrapper->gadget.speed == USB_SPEED_UNKNOWN) {
+		DWC_WARN("%s, bogus device state\n", __func__);
+		return -ESHUTDOWN;
+	}
+
+	/* Delete after check - MAS */
+	retval = dwc_otg_pcd_ep_enable(gadget_wrapper->pcd,
+				       (const uint8_t *)ep_desc,
+				       (void *)usb_ep);
+	if (retval) {
+		DWC_WARN("dwc_otg_pcd_ep_enable failed\n");
+		return -EINVAL;
+	}
+
+	usb_ep->maxpacket = le16_to_cpu(ep_desc->wMaxPacketSize);
+
+	return 0;
+}
+
+/**
+ * This function is called when an EP is disabled due to disconnect or
+ * change in configuration. Any pending requests will terminate with a
+ * status of -ESHUTDOWN.
+ *
+ * This function modifies the dwc_otg_ep_t data structure for this EP,
+ * and then calls dwc_otg_ep_deactivate.
+ */
+static int ep_disable(struct usb_ep *usb_ep)
+{
+	int retval;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, usb_ep);
+	if (!usb_ep) {
+		DWC_DEBUGPL(DBG_PCD, "%s, %s not enabled\n", __func__,
+			    usb_ep ? usb_ep->name : NULL);
+		return -EINVAL;
+	}
+
+	retval = dwc_otg_pcd_ep_disable(gadget_wrapper->pcd, usb_ep);
+	if (retval) {
+		retval = -EINVAL;
+	}
+
+	return retval;
+}
+
+/**
+ * This function allocates a request object to use with the specified
+ * endpoint.
+ *
+ * @param ep The endpoint to be used with with the request
+ * @param gfp_flags the GFP_* flags to use.
+ */
+static struct usb_request *dwc_otg_pcd_alloc_request(struct usb_ep *ep,
+						     gfp_t gfp_flags)
+{
+	struct usb_request *usb_req;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p,%d)\n", __func__, ep, gfp_flags);
+	if (0 == ep) {
+		DWC_WARN("%s() %s\n", __func__, "Invalid EP!\n");
+		return 0;
+	}
+	usb_req = kmalloc(sizeof(*usb_req), gfp_flags);
+	if (0 == usb_req) {
+		DWC_WARN("%s() %s\n", __func__, "request allocation failed!\n");
+		return 0;
+	}
+	memset(usb_req, 0, sizeof(*usb_req));
+	usb_req->dma = DWC_DMA_ADDR_INVALID;
+
+	return usb_req;
+}
+
+/**
+ * This function frees a request object.
+ *
+ * @param ep The endpoint associated with the request
+ * @param req The request being freed
+ */
+static void dwc_otg_pcd_free_request(struct usb_ep *ep, struct usb_request *req)
+{
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p,%p)\n", __func__, ep, req);
+
+	if (0 == ep || 0 == req) {
+		DWC_WARN("%s() %s\n", __func__,
+			 "Invalid ep or req argument!\n");
+		return;
+	}
+
+	kfree(req);
+}
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,28)
+/**
+ * This function allocates an I/O buffer to be used for a transfer
+ * to/from the specified endpoint.
+ *
+ * @param usb_ep The endpoint to be used with with the request
+ * @param bytes The desired number of bytes for the buffer
+ * @param dma Pointer to the buffer's DMA address; must be valid
+ * @param gfp_flags the GFP_* flags to use.
+ * @return address of a new buffer or null is buffer could not be allocated.
+ */
+static void *dwc_otg_pcd_alloc_buffer(struct usb_ep *usb_ep, unsigned bytes,
+				      dma_addr_t * dma, gfp_t gfp_flags)
+{
+	void *buf;
+	dwc_otg_pcd_t *pcd = 0;
+
+	pcd = gadget_wrapper->pcd;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p,%d,%p,%0x)\n", __func__, usb_ep, bytes,
+		    dma, gfp_flags);
+
+	/* Check dword alignment */
+	if ((bytes & 0x3UL) != 0) {
+		DWC_WARN("%s() Buffer size is not a multiple of"
+			 "DWORD size (%d)", __func__, bytes);
+	}
+
+	buf = dma_alloc_coherent(NULL, bytes, dma, gfp_flags);
+
+	/* Check dword alignment */
+	if (((int)buf & 0x3UL) != 0) {
+		DWC_WARN("%s() Buffer is not DWORD aligned (%p)",
+			 __func__, buf);
+	}
+
+	return buf;
+}
+
+/**
+ * This function frees an I/O buffer that was allocated by alloc_buffer.
+ *
+ * @param usb_ep the endpoint associated with the buffer
+ * @param buf address of the buffer
+ * @param dma The buffer's DMA address
+ * @param bytes The number of bytes of the buffer
+ */
+static void dwc_otg_pcd_free_buffer(struct usb_ep *usb_ep, void *buf,
+				    dma_addr_t dma, unsigned bytes)
+{
+	dwc_otg_pcd_t *pcd = 0;
+
+	pcd = gadget_wrapper->pcd;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p,%0x,%d)\n", __func__, buf, dma, bytes);
+
+	dma_free_coherent(NULL, bytes, buf, dma);
+}
+#endif
+
+/**
+ * This function is used to submit an I/O Request to an EP.
+ *
+ *	- When the request completes the request's completion callback
+ *	  is called to return the request to the driver.
+ *	- An EP, except control EPs, may have multiple requests
+ *	  pending.
+ *	- Once submitted the request cannot be examined or modified.
+ *	- Each request is turned into one or more packets.
+ *	- A BULK EP can queue any amount of data; the transfer is
+ *	  packetized.
+ *	- Zero length Packets are specified with the request 'zero'
+ *	  flag.
+ */
+static int ep_queue(struct usb_ep *usb_ep, struct usb_request *usb_req,
+		    gfp_t gfp_flags)
+{
+	dwc_otg_pcd_t *pcd;
+	struct dwc_otg_pcd_ep *ep;
+	int retval, is_isoc_ep;
+	dma_addr_t dma_addr = 0;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p,%p,%d)\n",
+		    __func__, usb_ep, usb_req, gfp_flags);
+
+	if (!usb_req || !usb_req->complete || !usb_req->buf) {
+		DWC_WARN("bad params\n");
+		return -EINVAL;
+	}
+
+	if (!usb_ep) {
+		DWC_WARN("bad ep\n");
+		return -EINVAL;
+	}
+
+	pcd = gadget_wrapper->pcd;
+	if (!gadget_wrapper->driver ||
+	    gadget_wrapper->gadget.speed == USB_SPEED_UNKNOWN) {
+		DWC_DEBUGPL(DBG_PCDV, "gadget.speed=%d\n",
+			    gadget_wrapper->gadget.speed);
+		DWC_WARN("bogus device state\n");
+		return -ESHUTDOWN;
+	}
+
+	DWC_DEBUGPL(DBG_PCD, "%s queue req %p, len %d buf %p\n",
+		    usb_ep->name, usb_req, usb_req->length, usb_req->buf);
+
+	usb_req->status = -EINPROGRESS;
+	usb_req->actual = 0;
+
+	ep = ep_from_handle(pcd, usb_ep);
+	if (ep == NULL)
+		is_isoc_ep = 0;
+	else
+		is_isoc_ep = (ep->dwc_ep.type == DWC_OTG_EP_TYPE_ISOC) ? 1 : 0;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,28)
+	dma_addr = usb_req->dma;
+#else
+	if (GET_CORE_IF(pcd)->dma_enable) {
+		retval = usb_gadget_map_req(&gadget_wrapper->gadget,
+					usb_req, ep);
+		if (retval) {
+			return -EINVAL;
+		}
+		dma_addr =usb_req->dma;
+	}
+#endif
+
+#ifdef DWC_UTE_PER_IO
+	if (is_isoc_ep == 1) {
+		retval =
+		    dwc_otg_pcd_xiso_ep_queue(pcd, usb_ep, usb_req->buf,
+					      dma_addr, usb_req->length,
+					      usb_req->zero, usb_req,
+					      gfp_flags == GFP_ATOMIC ? 1 : 0,
+					      &usb_req->ext_req);
+		if (retval)
+			return -EINVAL;
+
+		return 0;
+	}
+#endif
+	retval = dwc_otg_pcd_ep_queue(pcd, usb_ep, usb_req->buf, dma_addr,
+				      usb_req->length, usb_req->zero, usb_req,
+				      gfp_flags == GFP_ATOMIC ? 1 : 0);
+	if (retval) {
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+/**
+ * This function cancels an I/O request from an EP.
+ */
+static int ep_dequeue(struct usb_ep *usb_ep, struct usb_request *usb_req)
+{
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p,%p)\n", __func__, usb_ep, usb_req);
+
+	if (!usb_ep || !usb_req) {
+		DWC_WARN("bad argument\n");
+		return -EINVAL;
+	}
+	if (!gadget_wrapper->driver ||
+	    gadget_wrapper->gadget.speed == USB_SPEED_UNKNOWN) {
+		DWC_WARN("bogus device state\n");
+		return -ESHUTDOWN;
+	}
+	if (dwc_otg_pcd_ep_dequeue(gadget_wrapper->pcd, usb_ep, usb_req)) {
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+/**
+ * usb_ep_set_halt stalls an endpoint.
+ *
+ * usb_ep_clear_halt clears an endpoint halt and resets its data
+ * toggle.
+ *
+ * Both of these functions are implemented with the same underlying
+ * function. The behavior depends on the value argument.
+ *
+ * @param[in] usb_ep the Endpoint to halt or clear halt.
+ * @param[in] value
+ *	- 0 means clear_halt.
+ *	- 1 means set_halt,
+ *	- 2 means clear stall lock flag.
+ *	- 3 means set  stall lock flag.
+ */
+static int ep_halt(struct usb_ep *usb_ep, int value)
+{
+	int retval = 0;
+
+	DWC_DEBUGPL(DBG_PCD, "HALT %s %d\n", usb_ep->name, value);
+
+	if (!usb_ep) {
+		DWC_WARN("bad ep\n");
+		return -EINVAL;
+	}
+
+	retval = dwc_otg_pcd_ep_halt(gadget_wrapper->pcd, usb_ep, value);
+	if (retval == -DWC_E_AGAIN) {
+		return -EAGAIN;
+	} else if (retval) {
+		retval = -EINVAL;
+	}
+
+	return retval;
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+static int ep_wedge(struct usb_ep *usb_ep)
+{
+	DWC_DEBUGPL(DBG_PCD, "WEDGE %s\n", usb_ep->name);
+
+	return ep_halt(usb_ep, 3);
+}
+#endif
+
+#ifdef DWC_EN_ISOC
+/**
+ * This function is used to submit an ISOC Transfer Request to an EP.
+ *
+ *	- Every time a sync period completes the request's completion callback
+ *	  is called to provide data to the gadget driver.
+ *	- Once submitted the request cannot be modified.
+ *	- Each request is turned into periodic data packets untill ISO
+ *	  Transfer is stopped..
+ */
+static int iso_ep_start(struct usb_ep *usb_ep, struct usb_iso_request *req,
+			gfp_t gfp_flags)
+{
+	int retval = 0;
+
+	if (!req || !req->process_buffer || !req->buf0 || !req->buf1) {
+		DWC_WARN("bad params\n");
+		return -EINVAL;
+	}
+
+	if (!usb_ep) {
+		DWC_PRINTF("bad params\n");
+		return -EINVAL;
+	}
+
+	req->status = -EINPROGRESS;
+
+	retval =
+	    dwc_otg_pcd_iso_ep_start(gadget_wrapper->pcd, usb_ep, req->buf0,
+				     req->buf1, req->dma0, req->dma1,
+				     req->sync_frame, req->data_pattern_frame,
+				     req->data_per_frame,
+				     req->
+				     flags & USB_REQ_ISO_ASAP ? -1 :
+				     req->start_frame, req->buf_proc_intrvl,
+				     req, gfp_flags == GFP_ATOMIC ? 1 : 0);
+
+	if (retval) {
+		return -EINVAL;
+	}
+
+	return retval;
+}
+
+/**
+ * This function stops ISO EP Periodic Data Transfer.
+ */
+static int iso_ep_stop(struct usb_ep *usb_ep, struct usb_iso_request *req)
+{
+	int retval = 0;
+	if (!usb_ep) {
+		DWC_WARN("bad ep\n");
+	}
+
+	if (!gadget_wrapper->driver ||
+	    gadget_wrapper->gadget.speed == USB_SPEED_UNKNOWN) {
+		DWC_DEBUGPL(DBG_PCDV, "gadget.speed=%d\n",
+			    gadget_wrapper->gadget.speed);
+		DWC_WARN("bogus device state\n");
+	}
+
+	dwc_otg_pcd_iso_ep_stop(gadget_wrapper->pcd, usb_ep, req);
+	if (retval) {
+		retval = -EINVAL;
+	}
+
+	return retval;
+}
+
+static struct usb_iso_request *alloc_iso_request(struct usb_ep *ep,
+						 int packets, gfp_t gfp_flags)
+{
+	struct usb_iso_request *pReq = NULL;
+	uint32_t req_size;
+
+	req_size = sizeof(struct usb_iso_request);
+	req_size +=
+	    (2 * packets * (sizeof(struct usb_gadget_iso_packet_descriptor)));
+
+	pReq = kmalloc(req_size, gfp_flags);
+	if (!pReq) {
+		DWC_WARN("Can't allocate Iso Request\n");
+		return 0;
+	}
+	pReq->iso_packet_desc0 = (void *)(pReq + 1);
+
+	pReq->iso_packet_desc1 = pReq->iso_packet_desc0 + packets;
+
+	return pReq;
+}
+
+static void free_iso_request(struct usb_ep *ep, struct usb_iso_request *req)
+{
+	kfree(req);
+}
+
+static struct usb_isoc_ep_ops dwc_otg_pcd_ep_ops = {
+	.ep_ops = {
+		   .enable = ep_enable,
+		   .disable = ep_disable,
+
+		   .alloc_request = dwc_otg_pcd_alloc_request,
+		   .free_request = dwc_otg_pcd_free_request,
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,28)
+		   .alloc_buffer = dwc_otg_pcd_alloc_buffer,
+		   .free_buffer = dwc_otg_pcd_free_buffer,
+#endif
+
+		   .queue = ep_queue,
+		   .dequeue = ep_dequeue,
+
+		   .set_halt = ep_halt,
+
+		    #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+					.set_wedge = ep_wedge,
+			#endif
+					.fifo_status = 0,
+					.fifo_flush = 0,
+			},
+
+	.iso_ep_start = iso_ep_start,
+	.iso_ep_stop = iso_ep_stop,
+	.alloc_iso_request = alloc_iso_request,
+	.free_iso_request = free_iso_request,
+};
+
+#else
+
+static struct usb_ep_ops dwc_otg_pcd_ep_ops = {
+	.enable = ep_enable,
+	.disable = ep_disable,
+
+	.alloc_request = dwc_otg_pcd_alloc_request,
+	.free_request = dwc_otg_pcd_free_request,
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,28)
+	.alloc_buffer = dwc_otg_pcd_alloc_buffer,
+	.free_buffer = dwc_otg_pcd_free_buffer,
+#endif
+
+	.queue = ep_queue,
+	.dequeue = ep_dequeue,
+
+	.set_halt = ep_halt,
+
+	#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+		.set_wedge = ep_wedge,
+    #endif
+
+	.fifo_status = 0,
+	.fifo_flush = 0,
+
+};
+
+#endif /* _EN_ISOC_ */
+/*	Gadget Operations */
+/**
+ * The following gadget operations will be implemented in the DWC_otg
+ * PCD. Functions in the API that are not described below are not
+ * implemented.
+ *
+ * The Gadget API provides wrapper functions for each of the function
+ * pointers defined in usb_gadget_ops. The Gadget Driver calls the
+ * wrapper function, which then calls the underlying PCD function. The
+ * following sections are named according to the wrapper functions
+ * (except for ioctl, which doesn't have a wrapper function). Within
+ * each section, the corresponding DWC_otg PCD function name is
+ * specified.
+ *
+ */
+
+/**
+ *Gets the USB Frame number of the last SOF.
+ */
+static int get_frame_number(struct usb_gadget *gadget)
+{
+	struct gadget_wrapper *d;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, gadget);
+
+	if (gadget == 0) {
+		return -ENODEV;
+	}
+
+	d = container_of(gadget, struct gadget_wrapper, gadget);
+	return dwc_otg_pcd_get_frame_number(d->pcd);
+}
+
+#ifdef CONFIG_USB_DWC_OTG_LPM
+static int test_lpm_enabled(struct usb_gadget *gadget)
+{
+	struct gadget_wrapper *d;
+
+	d = container_of(gadget, struct gadget_wrapper, gadget);
+
+	return dwc_otg_pcd_is_lpm_enabled(d->pcd);
+}
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
+static int test_besl_enabled(struct usb_gadget *gadget)
+{
+	struct gadget_wrapper *d;
+
+	d = container_of(gadget, struct gadget_wrapper, gadget);
+
+	return dwc_otg_pcd_is_besl_enabled(d->pcd);
+}
+static int get_param_baseline_besl(struct usb_gadget *gadget)
+{
+	struct gadget_wrapper *d;
+
+	d = container_of(gadget, struct gadget_wrapper, gadget);
+
+	return dwc_otg_pcd_get_param_baseline_besl(d->pcd);
+}
+static int get_param_deep_besl(struct usb_gadget *gadget)
+{
+	struct gadget_wrapper *d;
+
+	d = container_of(gadget, struct gadget_wrapper, gadget);
+
+	return dwc_otg_pcd_get_param_deep_besl(d->pcd);
+}
+#endif
+#endif
+
+/**
+ * Initiates Session Request Protocol (SRP) to wakeup the host if no
+ * session is in progress. If a session is already in progress, but
+ * the device is suspended, remote wakeup signaling is started.
+ *
+ */
+static int wakeup(struct usb_gadget *gadget)
+{
+	struct gadget_wrapper *d;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, gadget);
+
+	if (gadget == 0) {
+		return -ENODEV;
+	} else {
+		d = container_of(gadget, struct gadget_wrapper, gadget);
+	}
+	dwc_otg_pcd_wakeup(d->pcd);
+	return 0;
+}
+
+static int pullup(struct usb_gadget *gadget, int is_on)
+{
+        struct gadget_wrapper *d;
+
+        DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, gadget);
+
+        if (gadget == 0) {
+                return -ENODEV;
+        } else {
+                d = container_of(gadget, struct gadget_wrapper, gadget);
+        }
+
+        if (!is_on)
+                dwc_otg_pcd_pullup(d->pcd);
+
+        return 0;
+}
+
+static const struct usb_gadget_ops dwc_otg_pcd_ops = {
+	.get_frame = get_frame_number,
+	.wakeup = wakeup,
+	.pullup = pullup,
+#ifdef CONFIG_USB_DWC_OTG_LPM
+	.lpm_support = test_lpm_enabled,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,0)
+	.besl_support = test_besl_enabled,
+	.get_baseline_besl = get_param_baseline_besl,
+	.get_deep_besl = get_param_deep_besl,
+#endif
+#endif
+	// current versions must always be self-powered
+};
+
+static int _setup(dwc_otg_pcd_t * pcd, uint8_t * bytes)
+{
+	int retval = -DWC_E_NOT_SUPPORTED;
+	if (gadget_wrapper->driver && gadget_wrapper->driver->setup) {
+		retval = gadget_wrapper->driver->setup(&gadget_wrapper->gadget,
+						       (struct usb_ctrlrequest
+							*)bytes);
+	}
+
+	if (retval == -ENOTSUPP) {
+		retval = -DWC_E_NOT_SUPPORTED;
+	} else if (retval < 0) {
+		retval = -DWC_E_INVALID;
+	}
+
+	return retval;
+}
+
+#ifdef DWC_EN_ISOC
+static int _isoc_complete(dwc_otg_pcd_t * pcd, void *ep_handle,
+			  void *req_handle, int proc_buf_num)
+{
+	int i, packet_count;
+	struct usb_gadget_iso_packet_descriptor *iso_packet = 0;
+	struct usb_iso_request *iso_req = req_handle;
+
+	if (proc_buf_num) {
+		iso_packet = iso_req->iso_packet_desc1;
+	} else {
+		iso_packet = iso_req->iso_packet_desc0;
+	}
+	packet_count =
+	    dwc_otg_pcd_get_iso_packet_count(pcd, ep_handle, req_handle);
+	for (i = 0; i < packet_count; ++i) {
+		int status;
+		int actual;
+		int offset;
+		dwc_otg_pcd_get_iso_packet_params(pcd, ep_handle, req_handle,
+						  i, &status, &actual, &offset);
+		switch (status) {
+		case -DWC_E_NO_DATA:
+			status = -ENODATA;
+			break;
+		default:
+			if (status) {
+				DWC_PRINTF("unknown status in isoc packet\n");
+			}
+
+		}
+		iso_packet[i].status = status;
+		iso_packet[i].offset = offset;
+		iso_packet[i].actual_length = actual;
+	}
+
+	iso_req->status = 0;
+	iso_req->process_buffer(ep_handle, iso_req);
+
+	return 0;
+}
+#endif /* DWC_EN_ISOC */
+
+#ifdef DWC_UTE_PER_IO
+/**
+ * Copy the contents of the extended request to the Linux usb_request's
+ * extended part and call the gadget's completion.
+ *
+ * @param pcd			Pointer to the pcd structure
+ * @param ep_handle		Void pointer to the usb_ep structure
+ * @param req_handle	Void pointer to the usb_request structure
+ * @param status		Request status returned from the portable logic
+ * @param ereq_port		Void pointer to the extended request structure
+ *						created in the the portable part that contains the
+ *						results of the processed iso packets.
+ */
+static int _xisoc_complete(dwc_otg_pcd_t * pcd, void *ep_handle,
+			   void *req_handle, int32_t status, void *ereq_port)
+{
+	struct dwc_ute_iso_req_ext *ereqorg = NULL;
+	struct dwc_iso_xreq_port *ereqport = NULL;
+	struct dwc_ute_iso_packet_descriptor *desc_org = NULL;
+	int i;
+	struct usb_request *req;
+	//struct dwc_ute_iso_packet_descriptor *
+	//int status = 0;
+
+	req = (struct usb_request *)req_handle;
+	ereqorg = &req->ext_req;
+	ereqport = (struct dwc_iso_xreq_port *)ereq_port;
+	desc_org = ereqorg->per_io_frame_descs;
+
+	if (req && req->complete) {
+		/* Copy the request data from the portable logic to our request */
+		for (i = 0; i < ereqport->pio_pkt_count; i++) {
+			desc_org[i].actual_length =
+			    ereqport->per_io_frame_descs[i].actual_length;
+			desc_org[i].status =
+			    ereqport->per_io_frame_descs[i].status;
+		}
+
+		switch (status) {
+		case -DWC_E_SHUTDOWN:
+			req->status = -ESHUTDOWN;
+			break;
+		case -DWC_E_RESTART:
+			req->status = -ECONNRESET;
+			break;
+		case -DWC_E_INVALID:
+			req->status = -EINVAL;
+			break;
+		case -DWC_E_TIMEOUT:
+			req->status = -ETIMEDOUT;
+			break;
+		default:
+			req->status = status;
+		}
+
+		/* And call the gadget's completion */
+		req->complete(ep_handle, req);
+	}
+
+	return 0;
+}
+#endif /* DWC_UTE_PER_IO */
+static int _complete(dwc_otg_pcd_t * pcd, void *ep_handle,
+		     void *req_handle, int32_t status, uint32_t actual)
+{
+	struct usb_request *req = (struct usb_request *)req_handle;
+	struct dwc_otg_pcd_ep *ep = NULL;
+
+	ep = ep_from_handle(pcd, ep_handle);
+
+	if (GET_CORE_IF(pcd)->dma_enable) {
+		if (req->dma)
+			usb_gadget_unmap_req(&gadget_wrapper->gadget,
+						req, ep);
+		req->dma = (dma_addr_t)0;
+	}
+
+	if (req && req->complete) {
+		switch (status) {
+		case -DWC_E_SHUTDOWN:
+			req->status = -ESHUTDOWN;
+			break;
+		case -DWC_E_RESTART:
+			req->status = -ECONNRESET;
+			break;
+		case -DWC_E_INVALID:
+			req->status = -EINVAL;
+			break;
+		case -DWC_E_TIMEOUT:
+			req->status = -ETIMEDOUT;
+			break;
+		default:
+			req->status = status;
+
+		}
+
+		req->actual = actual;
+		DWC_SPINUNLOCK(pcd->lock);
+		req->complete(ep_handle, req);
+		DWC_SPINLOCK(pcd->lock);
+	}
+#ifdef PCI_INTERFACE
+	dev = gadget_wrapper->pcd->otg_dev->os_dep.pcidev;
+	ep = ep_from_handle(pcd, ep_handle);
+	if (GET_CORE_IF(pcd)->dma_enable) {
+		if (req->length != 0)
+			pci_unmap_single(dev, req->dma, req->length,
+					 ep->dwc_ep.is_in ? PCI_DMA_TODEVICE :
+					 PCI_DMA_FROMDEVICE);
+	}
+#endif
+
+	return 0;
+}
+
+static int _connect(dwc_otg_pcd_t * pcd, int speed)
+{
+	gadget_wrapper->gadget.speed = speed;
+	return 0;
+}
+
+static int _disconnect(dwc_otg_pcd_t * pcd)
+{
+	if (gadget_wrapper->driver && gadget_wrapper->driver->disconnect) {
+		gadget_wrapper->driver->disconnect(&gadget_wrapper->gadget);
+	}
+	return 0;
+}
+
+static int _resume(dwc_otg_pcd_t * pcd)
+{
+	if (gadget_wrapper->driver && gadget_wrapper->driver->resume) {
+		gadget_wrapper->driver->resume(&gadget_wrapper->gadget);
+	}
+
+	return 0;
+}
+
+static int _suspend(dwc_otg_pcd_t * pcd)
+{
+	if (gadget_wrapper->driver && gadget_wrapper->driver->suspend) {
+		gadget_wrapper->driver->suspend(&gadget_wrapper->gadget);
+	}
+	return 0;
+}
+
+/**
+ * This function updates the otg values in the gadget structure.
+ */
+static int _hnp_changed(dwc_otg_pcd_t * pcd)
+{
+
+	if (!gadget_wrapper->gadget.is_otg)
+		return 0;
+
+	gadget_wrapper->gadget.b_hnp_enable = get_b_hnp_enable(pcd);
+	gadget_wrapper->gadget.a_hnp_support = get_a_hnp_support(pcd);
+	gadget_wrapper->gadget.a_alt_hnp_support = get_a_alt_hnp_support(pcd);
+	return 0;
+}
+
+static int _reset(dwc_otg_pcd_t * pcd)
+{
+	return 0;
+}
+
+#ifdef DWC_UTE_CFI
+static int _cfi_setup(dwc_otg_pcd_t * pcd, void *cfi_req)
+{
+	int retval = -DWC_E_INVALID;
+	if (gadget_wrapper->driver->cfi_feature_setup) {
+		retval =
+		    gadget_wrapper->driver->
+		    cfi_feature_setup(&gadget_wrapper->gadget,
+				      (struct cfi_usb_ctrlrequest *)cfi_req);
+	}
+
+	return retval;
+}
+#endif
+
+static const struct dwc_otg_pcd_function_ops fops = {
+	.complete = _complete,
+#ifdef DWC_EN_ISOC
+	.isoc_complete = _isoc_complete,
+#endif
+	.setup = _setup,
+	.disconnect = _disconnect,
+	.connect = _connect,
+	.resume = _resume,
+	.suspend = _suspend,
+	.hnp_changed = _hnp_changed,
+	.reset = _reset,
+#ifdef DWC_UTE_CFI
+	.cfi_setup = _cfi_setup,
+#endif
+#ifdef DWC_UTE_PER_IO
+	.xisoc_complete = _xisoc_complete,
+#endif
+};
+
+/**
+ * This function is the top level PCD interrupt handler.
+ */
+static irqreturn_t dwc_otg_pcd_irq(int irq, void *dev)
+{
+	dwc_otg_pcd_t *pcd = dev;
+	int32_t retval = IRQ_NONE;
+
+	retval = dwc_otg_pcd_handle_intr(pcd);
+	if (retval != 0) {
+		S3C2410X_CLEAR_EINTPEND();
+	}
+	return IRQ_RETVAL(retval);
+}
+
+/**
+ * This function initialized the usb_ep structures to there default
+ * state.
+ *
+ * @param d Pointer on gadget_wrapper.
+ */
+void gadget_add_eps(struct gadget_wrapper *d)
+{
+	static const char *names[] = {
+
+		"ep0",
+		"ep1in",
+		"ep2in",
+		"ep3in",
+		"ep4in",
+		"ep5in",
+		"ep6in",
+		"ep7in",
+		"ep8in",
+		"ep9in",
+		"ep10in",
+		"ep11in",
+		"ep12in",
+		"ep13in",
+		"ep14in",
+		"ep15in",
+		"ep1out",
+		"ep2out",
+		"ep3out",
+		"ep4out",
+		"ep5out",
+		"ep6out",
+		"ep7out",
+		"ep8out",
+		"ep9out",
+		"ep10out",
+		"ep11out",
+		"ep12out",
+		"ep13out",
+		"ep14out",
+		"ep15out"
+	};
+
+	int i;
+	struct usb_ep *ep;
+	int8_t dev_endpoints;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s\n", __func__);
+
+	INIT_LIST_HEAD(&d->gadget.ep_list);
+	d->gadget.ep0 = &d->ep0;
+	d->gadget.speed = USB_SPEED_UNKNOWN;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0)
+	d->gadget.max_speed = USB_SPEED_HIGH;
+#endif
+
+	INIT_LIST_HEAD(&d->gadget.ep0->ep_list);
+
+	/**
+	 * Initialize the EP0 structure.
+	 */
+	ep = &d->ep0;
+
+	/* Init the usb_ep structure. */
+	ep->name = names[0];
+	ep->ops = (struct usb_ep_ops *)&dwc_otg_pcd_ep_ops;
+
+	/**
+	 * @todo NGS: What should the max packet size be set to
+	 * here?  Before EP type is set?
+	 */
+	ep->maxpacket = MAX_PACKET_SIZE;
+	dwc_otg_pcd_ep_enable(d->pcd, NULL, ep);
+
+	list_add_tail(&ep->ep_list, &d->gadget.ep_list);
+
+	/**
+	 * Initialize the EP structures.
+	 */
+	dev_endpoints = d->pcd->core_if->dev_if->num_in_eps;
+
+	for (i = 0; i < dev_endpoints; i++) {
+		ep = &d->in_ep[i];
+
+		/* Init the usb_ep structure. */
+		ep->name = names[d->pcd->in_ep[i].dwc_ep.num];
+		ep->ops = (struct usb_ep_ops *)&dwc_otg_pcd_ep_ops;
+
+		/**
+		 * @todo NGS: What should the max packet size be set to
+		 * here?  Before EP type is set?
+		 */
+		ep->maxpacket = MAX_PACKET_SIZE;
+		ep->maxpacket_limit = MAX_PACKET_SIZE;
+		list_add_tail(&ep->ep_list, &d->gadget.ep_list);
+	}
+
+	dev_endpoints = d->pcd->core_if->dev_if->num_out_eps;
+
+	for (i = 0; i < dev_endpoints; i++) {
+		ep = &d->out_ep[i];
+
+		/* Init the usb_ep structure. */
+		ep->name = names[15 + d->pcd->out_ep[i].dwc_ep.num];
+		ep->ops = (struct usb_ep_ops *)&dwc_otg_pcd_ep_ops;
+
+		/**
+		 * @todo NGS: What should the max packet size be set to
+		 * here?  Before EP type is set?
+		 */
+		ep->maxpacket = MAX_PACKET_SIZE;
+		ep->maxpacket_limit = MAX_PACKET_SIZE;
+
+		list_add_tail(&ep->ep_list, &d->gadget.ep_list);
+	}
+
+	/* remove ep0 from the list.  There is a ep0 pointer. */
+	list_del_init(&d->ep0.ep_list);
+
+	d->ep0.maxpacket = MAX_EP0_SIZE;
+}
+
+/**
+ * This function releases the Gadget device.
+ * required by device_unregister().
+ *
+ * @todo Should this do something?	Should it free the PCD?
+ */
+static void dwc_otg_pcd_gadget_release(struct device *dev)
+{
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, dev);
+}
+
+static struct gadget_wrapper *alloc_wrapper(
+	struct platform_device *_dev
+    )
+{
+	static char pcd_name[] = "dwc_otg_pcd";
+
+	dwc_otg_device_t *otg_dev =platform_get_drvdata(_dev);
+
+
+	struct gadget_wrapper *d;
+	int retval;
+
+	d = DWC_ALLOC(sizeof(*d));
+	if (d == NULL) {
+		return NULL;
+	}
+
+	memset(d, 0, sizeof(*d));
+
+	d->gadget.name = pcd_name;
+	d->pcd = otg_dev->pcd;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,30)
+	strcpy(d->gadget.dev.bus_id, "gadget");
+#else
+	dev_set_name(&d->gadget.dev, "%s", "gadget");
+#endif
+
+	d->gadget.dev.parent = &_dev->dev;
+	d->gadget.dev.release = dwc_otg_pcd_gadget_release;
+	d->gadget.ops = &dwc_otg_pcd_ops;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3,3,0)
+	d->gadget.is_dualspeed = dwc_otg_pcd_is_dualspeed(otg_dev->pcd);
+#endif
+	d->gadget.is_otg = dwc_otg_pcd_is_otg(otg_dev->pcd);
+
+	d->driver = 0;
+	/* Register the gadget device */
+	retval = device_register(&d->gadget.dev);
+	if (retval != 0) {
+		DWC_ERROR("device_register failed\n");
+		DWC_FREE(d);
+		return NULL;
+	}
+
+	return d;
+}
+
+static void free_wrapper(struct gadget_wrapper *d)
+{
+	if (d->driver) {
+		/* should have been done already by driver model core */
+		DWC_WARN("driver '%s' is still registered\n",
+			 d->driver->driver.name);
+		usb_gadget_unregister_driver(d->driver);
+	}
+
+	device_unregister(&d->gadget.dev);
+	DWC_FREE(d);
+}
+
+/**
+ * This function initialized the PCD portion of the driver.
+ *
+ */
+int pcd_init(struct platform_device *_dev, int irqnum )
+{
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(_dev);
+
+	int retval = 0;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _dev);
+
+	otg_dev->pcd = dwc_otg_pcd_init(otg_dev->core_if);
+
+	if (!otg_dev->pcd) {
+		DWC_ERROR("dwc_otg_pcd_init failed\n");
+		return -ENOMEM;
+	}
+
+	otg_dev->pcd->otg_dev = otg_dev;
+	gadget_wrapper = alloc_wrapper(_dev);
+
+	/*
+	 * Initialize EP structures
+	 */
+	gadget_add_eps(gadget_wrapper);
+	/*
+	 * Setup interupt handler
+	 */
+	DWC_DEBUGPL(DBG_ANY, "registering handler for irq%d\n", irqnum);
+	retval = request_irq(irqnum, dwc_otg_pcd_irq,
+			     IRQF_SHARED,
+			     gadget_wrapper->gadget.name, otg_dev->pcd);
+	if (retval != 0) {
+		DWC_ERROR("request of irq%d failed\n", irqnum);
+		free_wrapper(gadget_wrapper);
+		return -EBUSY;
+	}
+
+
+	dwc_otg_pcd_start(gadget_wrapper->pcd, &fops);
+
+	return retval;
+}
+
+/**
+ * Cleanup the PCD.
+ */
+void pcd_remove(	struct platform_device *_dev   )
+{
+
+	dwc_otg_device_t *otg_dev = platform_get_drvdata(_dev);
+
+	dwc_otg_pcd_t *pcd = otg_dev->pcd;
+
+	DWC_DEBUGPL(DBG_PCDV, "%s(%p)\n", __func__, _dev);
+
+	/*
+	 * Free the IRQ
+	 */
+	free_irq(_dev->resource[1].start, pcd);
+	free_wrapper(gadget_wrapper);
+	dwc_otg_pcd_remove(otg_dev->pcd);
+	otg_dev->pcd = 0;
+}
+
+/**
+ * This function registers a gadget driver with the PCD.
+ *
+ * When a driver is successfully registered, it will receive control
+ * requests including set_configuration(), which enables non-control
+ * requests.  then usb traffic follows until a disconnect is reported.
+ * then a host may connect again, or the driver might get unbound.
+ *
+ * @param driver The driver being registered
+ * @param bind The bind function of gadget driver
+ */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,37)
+int usb_gadget_register_driver(struct usb_gadget_driver *driver)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	int usb_gadget_probe_driver(struct usb_gadget_driver *driver)
+#else
+int usb_gadget_probe_driver(struct usb_gadget_driver *driver,
+		int (*bind)(struct usb_gadget *))
+#endif
+{
+	int retval;
+
+	DWC_DEBUGPL(DBG_PCD, "registering gadget driver '%s'\n",
+		    driver->driver.name);
+
+	if (!driver ||
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3,3,0)
+		driver->speed == USB_SPEED_UNKNOWN ||
+#else
+		driver->max_speed == USB_SPEED_UNKNOWN ||
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,37) || LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	    !driver->bind ||
+#else
+		!bind ||
+#endif
+	    !driver->unbind || !driver->disconnect || !driver->setup) {
+		DWC_DEBUGPL(DBG_PCDV, "EINVAL\n");
+		return -EINVAL;
+	}
+	if (gadget_wrapper == 0) {
+		DWC_DEBUGPL(DBG_PCDV, "ENODEV\n");
+		return -ENODEV;
+	}
+	if (gadget_wrapper->driver != 0) {
+		DWC_DEBUGPL(DBG_PCDV, "EBUSY (%p)\n", gadget_wrapper->driver);
+		return -EBUSY;
+	}
+
+	/* hook up the driver */
+	gadget_wrapper->driver = driver;
+	gadget_wrapper->gadget.dev.driver = &driver->driver;
+
+	DWC_DEBUGPL(DBG_PCD, "bind to driver %s\n", driver->driver.name);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,37)
+	retval = driver->bind(&gadget_wrapper->gadget);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(3,7,0)
+	retval = driver->bind(&gadget_wrapper->gadget,gadget_wrapper->driver);
+#else
+	retval = bind(&gadget_wrapper->gadget);
+#endif
+	if (retval) {
+		DWC_ERROR("bind to driver %s --> error %d\n",
+			  driver->driver.name, retval);
+		gadget_wrapper->driver = 0;
+		gadget_wrapper->gadget.dev.driver = 0;
+		return retval;
+	}
+	DWC_DEBUGPL(DBG_ANY, "registered gadget driver '%s'\n",
+		    driver->driver.name);
+	return 0;
+}
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,37)
+EXPORT_SYMBOL(usb_gadget_register_driver);
+#else
+EXPORT_SYMBOL(usb_gadget_probe_driver);
+#endif
+
+/**
+ * This function unregisters a gadget driver
+ *
+ * @param driver The driver being unregistered
+ */
+int usb_gadget_unregister_driver(struct usb_gadget_driver *driver)
+{
+	//DWC_DEBUGPL(DBG_PCDV,"%s(%p)\n", __func__, _driver);
+
+	if (gadget_wrapper == 0) {
+		DWC_DEBUGPL(DBG_ANY, "%s Return(%d): s_pcd==0\n", __func__,
+			    -ENODEV);
+		return -ENODEV;
+	}
+	if (driver == 0 || driver != gadget_wrapper->driver) {
+		DWC_DEBUGPL(DBG_ANY, "%s Return(%d): driver?\n", __func__,
+			    -EINVAL);
+		return -EINVAL;
+	}
+
+	driver->disconnect(&gadget_wrapper->gadget);
+	driver->unbind(&gadget_wrapper->gadget);
+	gadget_wrapper->driver = 0;
+
+	DWC_DEBUGPL(DBG_ANY, "unregistered driver '%s'\n", driver->driver.name);
+	return 0;
+}
+
+EXPORT_SYMBOL(usb_gadget_unregister_driver);
+
+#endif /* DWC_HOST_ONLY */
diff --git a/drivers/usb/gadget/udc/hiudc/dwc_otg_regs.h b/drivers/usb/gadget/udc/hiudc/dwc_otg_regs.h
new file mode 100644
index 0000000..b148c3d
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/dwc_otg_regs.h
@@ -0,0 +1,2557 @@
+/* ==========================================================================
+ * $File: //dwh/usb_iip/dev/software/otg/linux/drivers/dwc_otg_regs.h $
+ * $Revision: #99 $
+ * $Date: 2012/12/10 $
+ * $Change: 2123206 $
+ *
+ * Synopsys HS OTG Linux Software Driver and documentation (hereinafter,
+ * "Software") is an Unsupported proprietary work of Synopsys, Inc. unless
+ * otherwise expressly agreed to in writing between Synopsys and you.
+ *
+ * The Software IS NOT an item of Licensed Software or Licensed Product under
+ * any End User Software License Agreement or Agreement for Licensed Product
+ * with Synopsys or any supplement thereto. You are permitted to use and
+ * redistribute this Software in source and binary forms, with or without
+ * modification, provided that redistributions of source code must retain this
+ * notice. You may not view, use, disclose, copy or distribute this file or
+ * any information contained herein except pursuant to this license grant from
+ * Synopsys. If you do not agree with this notice, including the disclaimer
+ * below, then you are not authorized to use the Software.
+ *
+ * THIS SOFTWARE IS BEING DISTRIBUTED BY SYNOPSYS SOLELY ON AN "AS IS" BASIS
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE HEREBY DISCLAIMED. IN NO EVENT SHALL SYNOPSYS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
+ * DAMAGE.
+ * ========================================================================== */
+
+#ifndef __DWC_OTG_REGS_H__
+#define __DWC_OTG_REGS_H__
+
+#include "dwc_otg_core_if.h"
+
+/**
+ * @file
+ *
+ * This file contains the data structures for accessing the DWC_otg core registers.
+ *
+ * The application interfaces with the HS OTG core by reading from and
+ * writing to the Control and Status Register (CSR) space through the
+ * AHB Slave interface. These registers are 32 bits wide, and the
+ * addresses are 32-bit-block aligned.
+ * CSRs are classified as follows:
+ * - Core Global Registers
+ * - Device Mode Registers
+ * - Device Global Registers
+ * - Device Endpoint Specific Registers
+ * - Host Mode Registers
+ * - Host Global Registers
+ * - Host Port CSRs
+ * - Host Channel Specific Registers
+ *
+ * Only the Core Global registers can be accessed in both Device and
+ * Host modes. When the HS OTG core is operating in one mode, either
+ * Device or Host, the application must not access registers from the
+ * other mode. When the core switches from one mode to another, the
+ * registers in the new mode of operation must be reprogrammed as they
+ * would be after a power-on reset.
+ */
+
+/****************************************************************************/
+/** DWC_otg Core registers .
+ * The dwc_otg_core_global_regs structure defines the size
+ * and relative field offsets for the Core Global registers.
+ */
+typedef struct dwc_otg_core_global_regs {
+	/** OTG Control and Status Register.  <i>Offset: 000h</i> */
+	volatile uint32_t gotgctl;
+	/** OTG Interrupt Register.	 <i>Offset: 004h</i> */
+	volatile uint32_t gotgint;
+	/**Core AHB Configuration Register.	 <i>Offset: 008h</i> */
+	volatile uint32_t gahbcfg;
+
+#define DWC_GLBINTRMASK		0x0001
+#define DWC_DMAENABLE		0x0020
+#define DWC_NPTXEMPTYLVL_EMPTY	0x0080
+#define DWC_NPTXEMPTYLVL_HALFEMPTY	0x0000
+#define DWC_PTXEMPTYLVL_EMPTY	0x0100
+#define DWC_PTXEMPTYLVL_HALFEMPTY	0x0000
+
+	/**Core USB Configuration Register.	 <i>Offset: 00Ch</i> */
+	volatile uint32_t gusbcfg;
+	/**Core Reset Register.	 <i>Offset: 010h</i> */
+	volatile uint32_t grstctl;
+	/**Core Interrupt Register.	 <i>Offset: 014h</i> */
+	volatile uint32_t gintsts;
+	/**Core Interrupt Mask Register.  <i>Offset: 018h</i> */
+	volatile uint32_t gintmsk;
+	/**Receive Status Queue Read Register (Read Only).	<i>Offset: 01Ch</i> */
+	volatile uint32_t grxstsr;
+	/**Receive Status Queue Read & POP Register (Read Only).  <i>Offset: 020h</i>*/
+	volatile uint32_t grxstsp;
+	/**Receive FIFO Size Register.	<i>Offset: 024h</i> */
+	volatile uint32_t grxfsiz;
+	/**Non Periodic Transmit FIFO Size Register.  <i>Offset: 028h</i> */
+	volatile uint32_t gnptxfsiz;
+	/**Non Periodic Transmit FIFO/Queue Status Register (Read
+	 * Only). <i>Offset: 02Ch</i> */
+	volatile uint32_t gnptxsts;
+	/**I2C Access Register.	 <i>Offset: 030h</i> */
+	volatile uint32_t gi2cctl;
+	/**PHY Vendor Control Register.	 <i>Offset: 034h</i> */
+	volatile uint32_t gpvndctl;
+	/**General Purpose Input/Output Register.  <i>Offset: 038h</i> */
+	volatile uint32_t ggpio;
+	/**User ID Register.  <i>Offset: 03Ch</i> */
+	volatile uint32_t guid;
+	/**Synopsys ID Register (Read Only).  <i>Offset: 040h</i> */
+	volatile uint32_t gsnpsid;
+	/**User HW Config1 Register (Read Only).  <i>Offset: 044h</i> */
+	volatile uint32_t ghwcfg1;
+	/**User HW Config2 Register (Read Only).  <i>Offset: 048h</i> */
+	volatile uint32_t ghwcfg2;
+#define DWC_SLAVE_ONLY_ARCH 0
+#define DWC_EXT_DMA_ARCH 1
+#define DWC_INT_DMA_ARCH 2
+
+#define DWC_MODE_HNP_SRP_CAPABLE	0
+#define DWC_MODE_SRP_ONLY_CAPABLE	1
+#define DWC_MODE_NO_HNP_SRP_CAPABLE		2
+#define DWC_MODE_SRP_CAPABLE_DEVICE		3
+#define DWC_MODE_NO_SRP_CAPABLE_DEVICE	4
+#define DWC_MODE_SRP_CAPABLE_HOST	5
+#define DWC_MODE_NO_SRP_CAPABLE_HOST	6
+
+	/**User HW Config3 Register (Read Only).  <i>Offset: 04Ch</i> */
+	volatile uint32_t ghwcfg3;
+	/**User HW Config4 Register (Read Only).  <i>Offset: 050h</i>*/
+	volatile uint32_t ghwcfg4;
+	/** Core LPM Configuration register <i>Offset: 054h</i>*/
+	volatile uint32_t glpmcfg;
+	/** Global PowerDn Register <i>Offset: 058h</i> */
+	volatile uint32_t gpwrdn;
+	/** Global DFIFO SW Config Register  <i>Offset: 05Ch</i> */
+	volatile uint32_t gdfifocfg;
+	/** ADP Control Register  <i>Offset: 060h</i> */
+	volatile uint32_t adpctl;
+	/** Reserved  <i>Offset: 064h-0FFh</i> */
+	volatile uint32_t reserved39[39];
+	/** Host Periodic Transmit FIFO Size Register. <i>Offset: 100h</i> */
+	volatile uint32_t hptxfsiz;
+	/** Device Periodic Transmit FIFO#n Register if dedicated fifos are disabled,
+		otherwise Device Transmit FIFO#n Register.
+	 * <i>Offset: 104h + (FIFO_Number-1)*04h, 1 <= FIFO Number <= 15 (1<=n<=15).</i> */
+	volatile uint32_t dtxfsiz[15];
+} dwc_otg_core_global_regs_t;
+
+/**
+ * This union represents the bit fields of the Core OTG Control
+ * and Status Register (GOTGCTL).  Set the bits using the bit
+ * fields then write the <i>d32</i> value to the register.
+ */
+typedef union gotgctl_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned sesreqscs:1;
+		unsigned sesreq:1;
+		unsigned vbvalidoven:1;
+		unsigned vbvalidovval:1;
+		unsigned avalidoven:1;
+		unsigned avalidovval:1;
+		unsigned bvalidoven:1;
+		unsigned bvalidovval:1;
+		unsigned hstnegscs:1;
+		unsigned hnpreq:1;
+		unsigned hstsethnpen:1;
+		unsigned devhnpen:1;
+		unsigned reserved12_15:4;
+		unsigned conidsts:1;
+		unsigned dbnctime:1;
+		unsigned asesvld:1;
+		unsigned bsesvld:1;
+		unsigned otgver:1;
+		unsigned reserved1:1;
+		unsigned multvalidbc:5;
+		unsigned chirpen:1;
+		unsigned reserved28_31:4;
+	} b;
+} gotgctl_data_t;
+
+/**
+ * This union represents the bit fields of the Core OTG Interrupt Register
+ * (GOTGINT).  Set/clear the bits using the bit fields then write the <i>d32</i>
+ * value to the register.
+ */
+typedef union gotgint_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Current Mode */
+		unsigned reserved0_1:2;
+
+		/** Session End Detected */
+		unsigned sesenddet:1;
+
+		unsigned reserved3_7:5;
+
+		/** Session Request Success Status Change */
+		unsigned sesreqsucstschng:1;
+		/** Host Negotiation Success Status Change */
+		unsigned hstnegsucstschng:1;
+
+		unsigned reserved10_16:7;
+
+		/** Host Negotiation Detected */
+		unsigned hstnegdet:1;
+		/** A-Device Timeout Change */
+		unsigned adevtoutchng:1;
+		/** Debounce Done */
+		unsigned debdone:1;
+		/** Multi-Valued input changed */
+		unsigned mvic:1;
+
+		unsigned reserved31_21:11;
+
+	} b;
+} gotgint_data_t;
+
+/**
+ * This union represents the bit fields of the Core AHB Configuration
+ * Register (GAHBCFG). Set/clear the bits using the bit fields then
+ * write the <i>d32</i> value to the register.
+ */
+typedef union gahbcfg_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned glblintrmsk:1;
+#define DWC_GAHBCFG_GLBINT_ENABLE		1
+
+		unsigned hburstlen:4;
+#define DWC_GAHBCFG_INT_DMA_BURST_SINGLE	0
+#define DWC_GAHBCFG_INT_DMA_BURST_INCR		1
+#define DWC_GAHBCFG_INT_DMA_BURST_INCR4		3
+#define DWC_GAHBCFG_INT_DMA_BURST_INCR8		5
+#define DWC_GAHBCFG_INT_DMA_BURST_INCR16	7
+
+		unsigned dmaenable:1;
+#define DWC_GAHBCFG_DMAENABLE			1
+		unsigned reserved:1;
+		unsigned nptxfemplvl_txfemplvl:1;
+		unsigned ptxfemplvl:1;
+#define DWC_GAHBCFG_TXFEMPTYLVL_EMPTY		1
+#define DWC_GAHBCFG_TXFEMPTYLVL_HALFEMPTY	0
+		unsigned reserved9_20:12;
+		unsigned remmemsupp:1;
+		unsigned notialldmawrit:1;
+		unsigned ahbsingle:1;
+		unsigned reserved24_31:8;
+	} b;
+} gahbcfg_data_t;
+
+/**
+ * This union represents the bit fields of the Core USB Configuration
+ * Register (GUSBCFG). Set the bits using the bit fields then write
+ * the <i>d32</i> value to the register.
+ */
+typedef union gusbcfg_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned toutcal:3;
+		unsigned phyif:1;
+		unsigned ulpi_utmi_sel:1;
+		unsigned fsintf:1;
+		unsigned physel:1;
+		unsigned ddrsel:1;
+		unsigned srpcap:1;
+		unsigned hnpcap:1;
+		unsigned usbtrdtim:4;
+		unsigned reserved1:1;
+		unsigned phylpwrclksel:1;
+		unsigned otgutmifssel:1;
+		unsigned ulpi_fsls:1;
+		unsigned ulpi_auto_res:1;
+		unsigned ulpi_clk_sus_m:1;
+		unsigned ulpi_ext_vbus_drv:1;
+		unsigned ulpi_int_vbus_indicator:1;
+		unsigned term_sel_dl_pulse:1;
+		unsigned indicator_complement:1;
+		unsigned indicator_pass_through:1;
+		unsigned ulpi_int_prot_dis:1;
+		unsigned ic_usb_cap:1;
+		unsigned ic_traffic_pull_remove:1;
+		unsigned tx_end_delay:1;
+		unsigned force_host_mode:1;
+		unsigned force_dev_mode:1;
+		unsigned reserved31:1;
+	} b;
+} gusbcfg_data_t;
+
+/**
+ * This union represents the bit fields of the Core Reset Register
+ * (GRSTCTL).  Set/clear the bits using the bit fields then write the
+ * <i>d32</i> value to the register.
+ */
+typedef union grstctl_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Core Soft Reset (CSftRst) (Device and Host)
+		 *
+		 * The application can flush the control logic in the
+		 * entire core using this bit. This bit resets the
+		 * pipelines in the AHB Clock domain as well as the
+		 * PHY Clock domain.
+		 *
+		 * The state machines are reset to an IDLE state, the
+		 * control bits in the CSRs are cleared, all the
+		 * transmit FIFOs and the receive FIFO are flushed.
+		 *
+		 * The status mask bits that control the generation of
+		 * the interrupt, are cleared, to clear the
+		 * interrupt. The interrupt status bits are not
+		 * cleared, so the application can get the status of
+		 * any events that occurred in the core after it has
+		 * set this bit.
+		 *
+		 * Any transactions on the AHB are terminated as soon
+		 * as possible following the protocol. Any
+		 * transactions on the USB are terminated immediately.
+		 *
+		 * The configuration settings in the CSRs are
+		 * unchanged, so the software doesn't have to
+		 * reprogram these registers (Device
+		 * Configuration/Host Configuration/Core System
+		 * Configuration/Core PHY Configuration).
+		 *
+		 * The application can write to this bit, any time it
+		 * wants to reset the core. This is a self clearing
+		 * bit and the core clears this bit after all the
+		 * necessary logic is reset in the core, which may
+		 * take several clocks, depending on the current state
+		 * of the core.
+		 */
+		unsigned csftrst:1;
+		/** Hclk Soft Reset
+		 *
+		 * The application uses this bit to reset the control logic in
+		 * the AHB clock domain. Only AHB clock domain pipelines are
+		 * reset.
+		 */
+		unsigned hsftrst:1;
+		/** Host Frame Counter Reset (Host Only)<br>
+		 *
+		 * The application can reset the (micro)frame number
+		 * counter inside the core, using this bit. When the
+		 * (micro)frame counter is reset, the subsequent SOF
+		 * sent out by the core, will have a (micro)frame
+		 * number of 0.
+		 */
+		unsigned hstfrm:1;
+		/** In Token Sequence Learning Queue Flush
+		 * (INTknQFlsh) (Device Only)
+		 */
+		unsigned intknqflsh:1;
+		/** RxFIFO Flush (RxFFlsh) (Device and Host)
+		 *
+		 * The application can flush the entire Receive FIFO
+		 * using this bit. The application must first
+		 * ensure that the core is not in the middle of a
+		 * transaction. The application should write into
+		 * this bit, only after making sure that neither the
+		 * DMA engine is reading from the RxFIFO nor the MAC
+		 * is writing the data in to the FIFO. The
+		 * application should wait until the bit is cleared
+		 * before performing any other operations. This bit
+		 * will takes 8 clocks (slowest of PHY or AHB clock)
+		 * to clear.
+		 */
+		unsigned rxfflsh:1;
+		/** TxFIFO Flush (TxFFlsh) (Device and Host).
+		 *
+		 * This bit is used to selectively flush a single or
+		 * all transmit FIFOs. The application must first
+		 * ensure that the core is not in the middle of a
+		 * transaction. The application should write into
+		 * this bit, only after making sure that neither the
+		 * DMA engine is writing into the TxFIFO nor the MAC
+		 * is reading the data out of the FIFO. The
+		 * application should wait until the core clears this
+		 * bit, before performing any operations. This bit
+		 * will takes 8 clocks (slowest of PHY or AHB clock)
+		 * to clear.
+		 */
+		unsigned txfflsh:1;
+
+		/** TxFIFO Number (TxFNum) (Device and Host).
+		 *
+		 * This is the FIFO number which needs to be flushed,
+		 * using the TxFIFO Flush bit. This field should not
+		 * be changed until the TxFIFO Flush bit is cleared by
+		 * the core.
+		 *	 - 0x0 : Non Periodic TxFIFO Flush
+		 *	 - 0x1 : Periodic TxFIFO #1 Flush in device mode
+		 *	   or Periodic TxFIFO in host mode
+		 *	 - 0x2 : Periodic TxFIFO #2 Flush in device mode.
+		 *	 - ...
+		 *	 - 0xF : Periodic TxFIFO #15 Flush in device mode
+		 *	 - 0x10: Flush all the Transmit NonPeriodic and
+		 *	   Transmit Periodic FIFOs in the core
+		 */
+		unsigned txfnum:5;
+		/** Reserved */
+		unsigned reserved11_29:19;
+		/** DMA Request Signal.	 Indicated DMA request is in
+		 * probress. Used for debug purpose. */
+		unsigned dmareq:1;
+		/** AHB Master Idle.  Indicates the AHB Master State
+		 * Machine is in IDLE condition. */
+		unsigned ahbidle:1;
+	} b;
+} grstctl_t;
+
+/**
+ * This union represents the bit fields of the Core Interrupt Mask
+ * Register (GINTMSK). Set/clear the bits using the bit fields then
+ * write the <i>d32</i> value to the register.
+ */
+typedef union gintmsk_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned reserved0:1;
+		unsigned modemismatch:1;
+		unsigned otgintr:1;
+		unsigned sofintr:1;
+		unsigned rxstsqlvl:1;
+		unsigned nptxfempty:1;
+		unsigned ginnakeff:1;
+		unsigned goutnakeff:1;
+		unsigned ulpickint:1;
+		unsigned i2cintr:1;
+		unsigned erlysuspend:1;
+		unsigned usbsuspend:1;
+		unsigned usbreset:1;
+		unsigned enumdone:1;
+		unsigned isooutdrop:1;
+		unsigned eopframe:1;
+		unsigned restoredone:1;
+		unsigned epmismatch:1;
+		unsigned inepintr:1;
+		unsigned outepintr:1;
+		unsigned incomplisoin:1;
+		unsigned incomplisoout:1;
+		unsigned fetsusp:1;
+		unsigned resetdet:1;
+		unsigned portintr:1;
+		unsigned hcintr:1;
+		unsigned ptxfempty:1;
+		unsigned lpmtranrcvd:1;
+		unsigned conidstschng:1;
+		unsigned disconnect:1;
+		unsigned sessreqintr:1;
+		unsigned wkupintr:1;
+	} b;
+} gintmsk_data_t;
+/**
+ * This union represents the bit fields of the Core Interrupt Register
+ * (GINTSTS).  Set/clear the bits using the bit fields then write the
+ * <i>d32</i> value to the register.
+ */
+typedef union gintsts_data {
+	/** raw register data */
+	uint32_t d32;
+#define DWC_SOF_INTR_MASK 0x0008
+	/** register bits */
+	struct {
+#define DWC_HOST_MODE 1
+		unsigned curmode:1;
+		unsigned modemismatch:1;
+		unsigned otgintr:1;
+		unsigned sofintr:1;
+		unsigned rxstsqlvl:1;
+		unsigned nptxfempty:1;
+		unsigned ginnakeff:1;
+		unsigned goutnakeff:1;
+		unsigned ulpickint:1;
+		unsigned i2cintr:1;
+		unsigned erlysuspend:1;
+		unsigned usbsuspend:1;
+		unsigned usbreset:1;
+		unsigned enumdone:1;
+		unsigned isooutdrop:1;
+		unsigned eopframe:1;
+		unsigned restoredone:1;
+		unsigned epmismatch:1;
+		unsigned inepint:1;
+		unsigned outepintr:1;
+		unsigned incomplisoin:1;
+		unsigned incomplisoout:1;
+		unsigned fetsusp:1;
+		unsigned resetdet:1;
+		unsigned portintr:1;
+		unsigned hcintr:1;
+		unsigned ptxfempty:1;
+		unsigned lpmtranrcvd:1;
+		unsigned conidstschng:1;
+		unsigned disconnect:1;
+		unsigned sessreqintr:1;
+		unsigned wkupintr:1;
+	} b;
+} gintsts_data_t;
+
+/**
+ * This union represents the bit fields in the Device Receive Status Read and
+ * Pop Registers (GRXSTSR, GRXSTSP) Read the register into the <i>d32</i>
+ * element then read out the bits using the <i>b</i>it elements.
+ */
+typedef union device_grxsts_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned epnum:4;
+		unsigned bcnt:11;
+		unsigned dpid:2;
+
+#define DWC_STS_DATA_UPDT		0x2	// OUT Data Packet
+#define DWC_STS_XFER_COMP		0x3	// OUT Data Transfer Complete
+
+#define DWC_DSTS_GOUT_NAK		0x1	// Global OUT NAK
+#define DWC_DSTS_SETUP_COMP		0x4	// Setup Phase Complete
+#define DWC_DSTS_SETUP_UPDT 0x6	// SETUP Packet
+		unsigned pktsts:4;
+		unsigned fn:4;
+		unsigned reserved25_31:7;
+	} b;
+} device_grxsts_data_t;
+
+/**
+ * This union represents the bit fields in the Host Receive Status Read and
+ * Pop Registers (GRXSTSR, GRXSTSP) Read the register into the <i>d32</i>
+ * element then read out the bits using the <i>b</i>it elements.
+ */
+typedef union host_grxsts_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned chnum:4;
+		unsigned bcnt:11;
+		unsigned dpid:2;
+
+		unsigned pktsts:4;
+#define DWC_GRXSTS_PKTSTS_IN			  0x2
+#define DWC_GRXSTS_PKTSTS_IN_XFER_COMP	  0x3
+#define DWC_GRXSTS_PKTSTS_DATA_TOGGLE_ERR 0x5
+#define DWC_GRXSTS_PKTSTS_CH_HALTED		  0x7
+
+		unsigned reserved21_31:11;
+	} b;
+} host_grxsts_data_t;
+
+/**
+ * This union represents the bit fields in the FIFO Size Registers (HPTXFSIZ,
+ * GNPTXFSIZ, DPTXFSIZn, DIEPTXFn). Read the register into the <i>d32</i> element
+ * then read out the bits using the <i>b</i>it elements.
+ */
+typedef union fifosize_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned startaddr:16;
+		unsigned depth:16;
+	} b;
+} fifosize_data_t;
+
+/**
+ * This union represents the bit fields in the Non-Periodic Transmit
+ * FIFO/Queue Status Register (GNPTXSTS). Read the register into the
+ * <i>d32</i> element then read out the bits using the <i>b</i>it
+ * elements.
+ */
+typedef union gnptxsts_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned nptxfspcavail:16;
+		unsigned nptxqspcavail:8;
+		/** Top of the Non-Periodic Transmit Request Queue
+		 *	- bit 24 - Terminate (Last entry for the selected
+		 *	  channel/EP)
+		 *	- bits 26:25 - Token Type
+		 *	  - 2'b00 - IN/OUT
+		 *	  - 2'b01 - Zero Length OUT
+		 *	  - 2'b10 - PING/Complete Split
+		 *	  - 2'b11 - Channel Halt
+		 *	- bits 30:27 - Channel/EP Number
+		 */
+		unsigned nptxqtop_terminate:1;
+		unsigned nptxqtop_token:2;
+		unsigned nptxqtop_chnep:4;
+		unsigned reserved:1;
+	} b;
+} gnptxsts_data_t;
+
+/**
+ * This union represents the bit fields in the Transmit
+ * FIFO Status Register (DTXFSTS). Read the register into the
+ * <i>d32</i> element then read out the bits using the <i>b</i>it
+ * elements.
+ */
+typedef union dtxfsts_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned txfspcavail:16;
+		unsigned reserved:16;
+	} b;
+} dtxfsts_data_t;
+
+/**
+ * This union represents the bit fields in the I2C Control Register
+ * (I2CCTL). Read the register into the <i>d32</i> element then read out the
+ * bits using the <i>b</i>it elements.
+ */
+typedef union gi2cctl_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned rwdata:8;
+		unsigned regaddr:8;
+		unsigned addr:7;
+		unsigned i2cen:1;
+		unsigned ack:1;
+		unsigned i2csuspctl:1;
+		unsigned i2cdevaddr:2;
+		unsigned i2cdatse0:1;
+		unsigned reserved:1;
+		unsigned rw:1;
+		unsigned bsydne:1;
+	} b;
+} gi2cctl_data_t;
+
+/**
+ * This union represents the bit fields in the PHY Vendor Control Register
+ * (GPVNDCTL). Read the register into the <i>d32</i> element then read out the
+ * bits using the <i>b</i>it elements.
+ */
+typedef union gpvndctl_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned regdata:8;
+		unsigned vctrl:8;
+		unsigned regaddr16_21:6;
+		unsigned regwr:1;
+		unsigned reserved23_24:2;
+		unsigned newregreq:1;
+		unsigned vstsbsy:1;
+		unsigned vstsdone:1;
+		unsigned reserved28_30:3;
+		unsigned disulpidrvr:1;
+	} b;
+} gpvndctl_data_t;
+
+/**
+ * This union represents the bit fields in the General Purpose
+ * Input/Output Register (GGPIO).
+ * Read the register into the <i>d32</i> element then read out the
+ * bits using the <i>b</i>it elements.
+ */
+typedef union ggpio_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned gpi:16;
+		unsigned gpo:16;
+	} b;
+} ggpio_data_t;
+
+/**
+ * This union represents the bit fields in the User ID Register
+ * (GUID). Read the register into the <i>d32</i> element then read out the
+ * bits using the <i>b</i>it elements.
+ */
+typedef union guid_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned rwdata:32;
+	} b;
+} guid_data_t;
+
+/**
+ * This union represents the bit fields in the Synopsys ID Register
+ * (GSNPSID). Read the register into the <i>d32</i> element then read out the
+ * bits using the <i>b</i>it elements.
+ */
+typedef union gsnpsid_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned rwdata:32;
+	} b;
+} gsnpsid_data_t;
+
+/**
+ * This union represents the bit fields in the User HW Config1
+ * Register.  Read the register into the <i>d32</i> element then read
+ * out the bits using the <i>b</i>it elements.
+ */
+typedef union hwcfg1_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned ep_dir0:2;
+		unsigned ep_dir1:2;
+		unsigned ep_dir2:2;
+		unsigned ep_dir3:2;
+		unsigned ep_dir4:2;
+		unsigned ep_dir5:2;
+		unsigned ep_dir6:2;
+		unsigned ep_dir7:2;
+		unsigned ep_dir8:2;
+		unsigned ep_dir9:2;
+		unsigned ep_dir10:2;
+		unsigned ep_dir11:2;
+		unsigned ep_dir12:2;
+		unsigned ep_dir13:2;
+		unsigned ep_dir14:2;
+		unsigned ep_dir15:2;
+	} b;
+} hwcfg1_data_t;
+
+/**
+ * This union represents the bit fields in the User HW Config2
+ * Register.  Read the register into the <i>d32</i> element then read
+ * out the bits using the <i>b</i>it elements.
+ */
+typedef union hwcfg2_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/* GHWCFG2 */
+		unsigned op_mode:3;
+#define DWC_HWCFG2_OP_MODE_HNP_SRP_CAPABLE_OTG 0
+#define DWC_HWCFG2_OP_MODE_SRP_ONLY_CAPABLE_OTG 1
+#define DWC_HWCFG2_OP_MODE_NO_HNP_SRP_CAPABLE_OTG 2
+#define DWC_HWCFG2_OP_MODE_SRP_CAPABLE_DEVICE 3
+#define DWC_HWCFG2_OP_MODE_NO_SRP_CAPABLE_DEVICE 4
+#define DWC_HWCFG2_OP_MODE_SRP_CAPABLE_HOST 5
+#define DWC_HWCFG2_OP_MODE_NO_SRP_CAPABLE_HOST 6
+
+		unsigned architecture:2;
+		unsigned point2point:1;
+		unsigned hs_phy_type:2;
+#define DWC_HWCFG2_HS_PHY_TYPE_NOT_SUPPORTED 0
+#define DWC_HWCFG2_HS_PHY_TYPE_UTMI 1
+#define DWC_HWCFG2_HS_PHY_TYPE_ULPI 2
+#define DWC_HWCFG2_HS_PHY_TYPE_UTMI_ULPI 3
+
+		unsigned fs_phy_type:2;
+		unsigned num_dev_ep:4;
+		unsigned num_host_chan:4;
+		unsigned perio_ep_supported:1;
+		unsigned dynamic_fifo:1;
+		unsigned multi_proc_int:1;
+		unsigned reserved21:1;
+		unsigned nonperio_tx_q_depth:2;
+		unsigned host_perio_tx_q_depth:2;
+		unsigned dev_token_q_depth:5;
+		unsigned otg_enable_ic_usb:1;
+	} b;
+} hwcfg2_data_t;
+
+/**
+ * This union represents the bit fields in the User HW Config3
+ * Register.  Read the register into the <i>d32</i> element then read
+ * out the bits using the <i>b</i>it elements.
+ */
+typedef union hwcfg3_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/* GHWCFG3 */
+		unsigned xfer_size_cntr_width:4;
+		unsigned packet_size_cntr_width:3;
+		unsigned otg_func:1;
+		unsigned i2c:1;
+		unsigned vendor_ctrl_if:1;
+		unsigned optional_features:1;
+		unsigned synch_reset_type:1;
+		unsigned adp_supp:1;
+		unsigned otg_enable_hsic:1;
+		unsigned bc_support:1;
+		unsigned otg_lpm_en:1;
+		unsigned dfifo_depth:16;
+	} b;
+} hwcfg3_data_t;
+
+/**
+ * This union represents the bit fields in the User HW Config4
+ * Register.  Read the register into the <i>d32</i> element then read
+ * out the bits using the <i>b</i>it elements.
+ */
+typedef union hwcfg4_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned num_dev_perio_in_ep:4;
+		unsigned power_optimiz:1;
+		unsigned min_ahb_freq:1;
+		unsigned hiber:1;
+		unsigned xhiber:1;
+		unsigned reserved:6;
+		unsigned utmi_phy_data_width:2;
+		unsigned num_dev_mode_ctrl_ep:4;
+		unsigned iddig_filt_en:1;
+		unsigned vbus_valid_filt_en:1;
+		unsigned a_valid_filt_en:1;
+		unsigned b_valid_filt_en:1;
+		unsigned session_end_filt_en:1;
+		unsigned ded_fifo_en:1;
+		unsigned num_in_eps:4;
+		unsigned desc_dma:1;
+		unsigned desc_dma_dyn:1;
+	} b;
+} hwcfg4_data_t;
+
+/**
+ * This union represents the bit fields of the Core LPM Configuration
+ * Register (GLPMCFG). Set the bits using bit fields then write
+ * the <i>d32</i> value to the register.
+ */
+typedef union glpmctl_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** LPM-Capable (LPMCap) (Device and Host)
+		 * The application uses this bit to control
+		 * the DWC_otg core LPM capabilities.
+		 */
+		unsigned lpm_cap_en:1;
+		/** LPM response programmed by application (AppL1Res) (Device)
+		 * Handshake response to LPM token pre-programmed
+		 * by device application software.
+		 */
+		unsigned appl_resp:1;
+		/** Host Initiated Resume Duration (HIRD) (Device and Host)
+		 * In Host mode this field indicates the value of HIRD
+		 * to be sent in an LPM transaction.
+		 * In Device mode this field is updated with the
+		 * Received LPM Token HIRD bmAttribute
+		 * when an ACK/NYET/STALL response is sent
+		 * to an LPM transaction.
+		 */
+		unsigned hird:4;
+		/** RemoteWakeEnable (bRemoteWake) (Device and Host)
+		 * In Host mode this bit indicates the value of remote
+		 * wake up to be sent in wIndex field of LPM transaction.
+		 * In Device mode this field is updated with the
+		 * Received LPM Token bRemoteWake bmAttribute
+		 * when an ACK/NYET/STALL response is sent
+		 * to an LPM transaction.
+		 */
+		unsigned rem_wkup_en:1;
+		/** Enable utmi_sleep_n (EnblSlpM) (Device and Host)
+		 * The application uses this bit to control
+		 * the utmi_sleep_n assertion to the PHY when in L1 state.
+		 */
+		unsigned en_utmi_sleep:1;
+		/** HIRD Threshold (HIRD_Thres) (Device and Host)
+		 */
+		unsigned hird_thres:5;
+		/** LPM Response (CoreL1Res) (Device and Host)
+		 * In Host mode this bit contains handsake response to
+		 * LPM transaction.
+		 * In Device mode the response of the core to
+		 * LPM transaction received is reflected in these two bits.
+			- 0x0 : ERROR (No handshake response)
+			- 0x1 : STALL
+			- 0x2 : NYET
+			- 0x3 : ACK
+		 */
+		unsigned lpm_resp:2;
+		/** Port Sleep Status (SlpSts) (Device and Host)
+		 * This bit is set as long as a Sleep condition
+		 * is present on the USB bus.
+		 */
+		unsigned prt_sleep_sts:1;
+		/** Sleep State Resume OK (L1ResumeOK) (Device and Host)
+		 * Indicates that the application or host
+		 * can start resume from Sleep state.
+		 */
+		unsigned sleep_state_resumeok:1;
+		/** LPM channel Index (LPM_Chnl_Indx) (Host)
+		 * The channel number on which the LPM transaction
+		 * has to be applied while sending
+		 * an LPM transaction to the local device.
+		 */
+		unsigned lpm_chan_index:4;
+		/** LPM Retry Count (LPM_Retry_Cnt) (Host)
+		 * Number host retries that would be performed
+		 * if the device response was not valid response.
+		 */
+		unsigned retry_count:3;
+		/** Send LPM Transaction (SndLPM) (Host)
+		 * When set by application software,
+		 * an LPM transaction containing two tokens
+		 * is sent.
+		 */
+		unsigned send_lpm:1;
+		/** LPM Retry status (LPM_RetryCnt_Sts) (Host)
+		 * Number of LPM Host Retries still remaining
+		 * to be transmitted for the current LPM sequence
+		 */
+		unsigned retry_count_sts:3;
+		/** Enable Best Effort Service Latency (BESL) (Device and Host)
+		 *  This bit enables the BESL features as defined in the LPM errata
+		 */
+		unsigned en_besl:1;
+
+		unsigned reserved29:1;
+		/** In host mode once this bit is set, the host
+		 * configures to drive the HSIC Idle state on the bus.
+		 * It then waits for the  device to initiate the Connect sequence.
+		 * In device mode once this bit is set, the device waits for
+		 * the HSIC Idle line state on the bus. Upon receving the Idle
+		 * line state, it initiates the HSIC Connect sequence.
+		 */
+		unsigned hsic_connect:1;
+		/** This bit overrides and functionally inverts
+		 * the if_select_hsic input port signal.
+		 */
+		unsigned inv_sel_hsic:1;
+	} b;
+} glpmcfg_data_t;
+
+/**
+ * This union represents the bit fields of the Core ADP Timer, Control and
+ * Status Register (ADPTIMCTLSTS). Set the bits using bit fields then write
+ * the <i>d32</i> value to the register.
+ */
+typedef union adpctl_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Probe Discharge (PRB_DSCHG)
+		 *  These bits set the times for TADP_DSCHG.
+		 *  These bits are defined as follows:
+		 *  2'b00 - 4 msec
+		 *  2'b01 - 8 msec
+		 *  2'b10 - 16 msec
+		 *  2'b11 - 32 msec
+		 */
+		unsigned prb_dschg:2;
+		/** Probe Delta (PRB_DELTA)
+		 *  These bits set the resolution for RTIM   value.
+		 *  The bits are defined in units of 32 kHz clock cycles as follows:
+		 *  2'b00  -  1 cycles
+		 *  2'b01  -  2 cycles
+		 *  2'b10 -  3 cycles
+		 *  2'b11 - 4 cycles
+		 *  For example if this value is chosen to 2'b01, it means that RTIM
+		 *  increments for every 3(three) 32Khz clock cycles.
+		 */
+		unsigned prb_delta:2;
+		/** Probe Period (PRB_PER)
+		 *  These bits sets the TADP_PRD as shown in Figure 4 as follows:
+		 *  2'b00  -  0.625 to 0.925 sec (typical 0.775 sec)
+		 *  2'b01  -  1.25 to 1.85 sec (typical 1.55 sec)
+		 *  2'b10  -  1.9 to 2.6 sec (typical 2.275 sec)
+		 *  2'b11  -  Reserved
+		 */
+		unsigned prb_per:2;
+		/** These bits capture the latest time it took for VBUS to ramp from
+		 *  VADP_SINK to VADP_PRB.
+		 *  0x000  -  1 cycles
+		 *  0x001  -  2 cycles
+		 *  0x002  -  3 cycles
+		 *  etc
+		 *  0x7FF  -  2048 cycles
+		 *  A time of 1024 cycles at 32 kHz corresponds to a time of 32 msec.
+		*/
+		unsigned rtim:11;
+		/** Enable Probe (EnaPrb)
+		 *  When programmed to 1'b1, the core performs a probe operation.
+		 *  This bit is valid only if OTG_Ver = 1'b1.
+		 */
+		unsigned enaprb:1;
+		/** Enable Sense (EnaSns)
+		 *  When programmed to 1'b1, the core performs a Sense operation.
+		 *  This bit is valid only if OTG_Ver = 1'b1.
+		 */
+		unsigned enasns:1;
+		/** ADP Reset (ADPRes)
+		 *  When set, ADP controller is reset.
+		 *  This bit is valid only if OTG_Ver = 1'b1.
+		 */
+		unsigned adpres:1;
+		/** ADP Enable (ADPEn)
+		 *  When set, the core performs either ADP probing or sensing
+		 *  based on EnaPrb or EnaSns.
+		 *  This bit is valid only if OTG_Ver = 1'b1.
+		 */
+		unsigned adpen:1;
+		/** ADP Probe Interrupt (ADP_PRB_INT)
+		 *  When this bit is set, it means that the VBUS
+		 *  voltage is greater than VADP_PRB or VADP_PRB is reached.
+		 *  This bit is valid only if OTG_Ver = 1'b1.
+		 */
+		unsigned adp_prb_int:1;
+		/**
+		 *  ADP Sense Interrupt (ADP_SNS_INT)
+		 *  When this bit is set, it means that the VBUS voltage is greater than
+		 *  VADP_SNS value or VADP_SNS is reached.
+		 *  This bit is valid only if OTG_Ver = 1'b1.
+		 */
+		unsigned adp_sns_int:1;
+		/** ADP Tomeout Interrupt (ADP_TMOUT_INT)
+		 *  This bit is relevant only for an ADP probe.
+		 *  When this bit is set, it means that the ramp time has
+		 *  completed ie ADPCTL.RTIM has reached its terminal value
+		 *  of 0x7FF.  This is a debug feature that allows software
+		 *  to read the ramp time after each cycle.
+		 *  This bit is valid only if OTG_Ver = 1'b1.
+		 */
+		unsigned adp_tmout_int:1;
+		/** ADP Probe Interrupt Mask (ADP_PRB_INT_MSK)
+		 *  When this bit is set, it unmasks the interrupt due to ADP_PRB_INT.
+		 *  This bit is valid only if OTG_Ver = 1'b1.
+		 */
+		unsigned adp_prb_int_msk:1;
+		/** ADP Sense Interrupt Mask (ADP_SNS_INT_MSK)
+		 *  When this bit is set, it unmasks the interrupt due to ADP_SNS_INT.
+		 *  This bit is valid only if OTG_Ver = 1'b1.
+		 */
+		unsigned adp_sns_int_msk:1;
+		/** ADP Timoeout Interrupt Mask (ADP_TMOUT_MSK)
+		 *  When this bit is set, it unmasks the interrupt due to ADP_TMOUT_INT.
+		 *  This bit is valid only if OTG_Ver = 1'b1.
+		 */
+		unsigned adp_tmout_int_msk:1;
+		/** Access Request
+		 * 2'b00 - Read/Write Valid (updated by the core)
+		 * 2'b01 - Read
+		 * 2'b00 - Write
+		 * 2'b00 - Reserved
+		 */
+		unsigned ar:2;
+		 /** Reserved */
+		unsigned reserved29_31:3;
+	} b;
+} adpctl_data_t;
+
+////////////////////////////////////////////
+// Device Registers
+/**
+ * Device Global Registers. <i>Offsets 800h-BFFh</i>
+ *
+ * The following structures define the size and relative field offsets
+ * for the Device Mode Registers.
+ *
+ * <i>These registers are visible only in Device mode and must not be
+ * accessed in Host mode, as the results are unknown.</i>
+ */
+typedef struct dwc_otg_dev_global_regs {
+	/** Device Configuration Register. <i>Offset 800h</i> */
+	volatile uint32_t dcfg;
+	/** Device Control Register. <i>Offset: 804h</i> */
+	volatile uint32_t dctl;
+	/** Device Status Register (Read Only). <i>Offset: 808h</i> */
+	volatile uint32_t dsts;
+	/** Reserved. <i>Offset: 80Ch</i> */
+	uint32_t unused;
+	/** Device IN Endpoint Common Interrupt Mask
+	 * Register. <i>Offset: 810h</i> */
+	volatile uint32_t diepmsk;
+	/** Device OUT Endpoint Common Interrupt Mask
+	 * Register. <i>Offset: 814h</i> */
+	volatile uint32_t doepmsk;
+	/** Device All Endpoints Interrupt Register.  <i>Offset: 818h</i> */
+	volatile uint32_t daint;
+	/** Device All Endpoints Interrupt Mask Register.  <i>Offset:
+	 * 81Ch</i> */
+	volatile uint32_t daintmsk;
+	/** Device IN Token Queue Read Register-1 (Read Only).
+	 * <i>Offset: 820h</i> */
+	volatile uint32_t dtknqr1;
+	/** Device IN Token Queue Read Register-2 (Read Only).
+	 * <i>Offset: 824h</i> */
+	volatile uint32_t dtknqr2;
+	/** Device VBUS	 discharge Register.  <i>Offset: 828h</i> */
+	volatile uint32_t dvbusdis;
+	/** Device VBUS Pulse Register.	 <i>Offset: 82Ch</i> */
+	volatile uint32_t dvbuspulse;
+	/** Device IN Token Queue Read Register-3 (Read Only). /
+	 *	Device Thresholding control register (Read/Write)
+	 * <i>Offset: 830h</i> */
+	volatile uint32_t dtknqr3_dthrctl;
+	/** Device IN Token Queue Read Register-4 (Read Only). /
+	 *	Device IN EPs empty Inr. Mask Register (Read/Write)
+	 * <i>Offset: 834h</i> */
+	volatile uint32_t dtknqr4_fifoemptymsk;
+	/** Device Each Endpoint Interrupt Register (Read Only). /
+	 * <i>Offset: 838h</i> */
+	volatile uint32_t deachint;
+	/** Device Each Endpoint Interrupt mask Register (Read/Write). /
+	 * <i>Offset: 83Ch</i> */
+	volatile uint32_t deachintmsk;
+	/** Device Each In Endpoint Interrupt mask Register (Read/Write). /
+	 * <i>Offset: 840h</i> */
+	volatile uint32_t diepeachintmsk[MAX_EPS_CHANNELS];
+	/** Device Each Out Endpoint Interrupt mask Register (Read/Write). /
+	 * <i>Offset: 880h</i> */
+	volatile uint32_t doepeachintmsk[MAX_EPS_CHANNELS];
+} dwc_otg_device_global_regs_t;
+
+/**
+ * This union represents the bit fields in the Device Configuration
+ * Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.  Write the
+ * <i>d32</i> member to the dcfg register.
+ */
+typedef union dcfg_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Device Speed */
+		unsigned devspd:2;
+		/** Non Zero Length Status OUT Handshake */
+		unsigned nzstsouthshk:1;
+#define DWC_DCFG_SEND_STALL 1
+
+		unsigned ena32khzs:1;
+		/** Device Addresses */
+		unsigned devaddr:7;
+		/** Periodic Frame Interval */
+		unsigned perfrint:2;
+#define DWC_DCFG_FRAME_INTERVAL_80 0
+#define DWC_DCFG_FRAME_INTERVAL_85 1
+#define DWC_DCFG_FRAME_INTERVAL_90 2
+#define DWC_DCFG_FRAME_INTERVAL_95 3
+
+		/** Enable Device OUT NAK for bulk in DDMA mode */
+		unsigned endevoutnak:1;
+
+		unsigned reserved14_17:4;
+		/** In Endpoint Mis-match count */
+		unsigned epmscnt:5;
+		/** Enable Descriptor DMA in Device mode */
+		unsigned descdma:1;
+		unsigned perschintvl:2;
+		unsigned resvalid:6;
+	} b;
+} dcfg_data_t;
+
+/**
+ * This union represents the bit fields in the Device Control
+ * Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union dctl_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Remote Wakeup */
+		unsigned rmtwkupsig:1;
+		/** Soft Disconnect */
+		unsigned sftdiscon:1;
+		/** Global Non-Periodic IN NAK Status */
+		unsigned gnpinnaksts:1;
+		/** Global OUT NAK Status */
+		unsigned goutnaksts:1;
+		/** Test Control */
+		unsigned tstctl:3;
+		/** Set Global Non-Periodic IN NAK */
+		unsigned sgnpinnak:1;
+		/** Clear Global Non-Periodic IN NAK */
+		unsigned cgnpinnak:1;
+		/** Set Global OUT NAK */
+		unsigned sgoutnak:1;
+		/** Clear Global OUT NAK */
+		unsigned cgoutnak:1;
+		/** Power-On Programming Done */
+		unsigned pwronprgdone:1;
+		/** Reserved */
+		unsigned reserved:1;
+		/** Global Multi Count */
+		unsigned gmc:2;
+		/** Ignore Frame Number for ISOC EPs */
+		unsigned ifrmnum:1;
+		/** NAK on Babble */
+		unsigned nakonbble:1;
+		/** Enable Continue on BNA */
+		unsigned encontonbna:1;
+		/** Enable deep sleep besl reject feature*/
+		unsigned besl_reject:1;
+
+		unsigned reserved17_31:13;
+	} b;
+} dctl_data_t;
+
+/**
+ * This union represents the bit fields in the Device Status
+ * Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union dsts_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Suspend Status */
+		unsigned suspsts:1;
+		/** Enumerated Speed */
+		unsigned enumspd:2;
+#define DWC_DSTS_ENUMSPD_HS_PHY_30MHZ_OR_60MHZ 0
+#define DWC_DSTS_ENUMSPD_FS_PHY_30MHZ_OR_60MHZ 1
+#define DWC_DSTS_ENUMSPD_LS_PHY_6MHZ		   2
+#define DWC_DSTS_ENUMSPD_FS_PHY_48MHZ		   3
+		/** Erratic Error */
+		unsigned errticerr:1;
+		unsigned reserved4_7:4;
+		/** Frame or Microframe Number of the received SOF */
+		unsigned soffn:14;
+		unsigned reserved22_31:10;
+	} b;
+} dsts_data_t;
+
+/**
+ * This union represents the bit fields in the Device IN EP Interrupt
+ * Register and the Device IN EP Common Mask Register.
+ *
+ * - Read the register into the <i>d32</i> member then set/clear the
+ *	 bits using the <i>b</i>it elements.
+ */
+typedef union diepint_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Transfer complete mask */
+		unsigned xfercompl:1;
+		/** Endpoint disable mask */
+		unsigned epdisabled:1;
+		/** AHB Error mask */
+		unsigned ahberr:1;
+		/** TimeOUT Handshake mask (non-ISOC EPs) */
+		unsigned timeout:1;
+		/** IN Token received with TxF Empty mask */
+		unsigned intktxfemp:1;
+		/** IN Token Received with EP mismatch mask */
+		unsigned intknepmis:1;
+		/** IN Endpoint NAK Effective mask */
+		unsigned inepnakeff:1;
+		/** Reserved */
+		unsigned emptyintr:1;
+
+		unsigned txfifoundrn:1;
+
+		/** BNA Interrupt mask */
+		unsigned bna:1;
+
+		unsigned reserved10_12:3;
+		/** BNA Interrupt mask */
+		unsigned nak:1;
+
+		unsigned reserved14_31:18;
+	} b;
+} diepint_data_t;
+
+/**
+ * This union represents the bit fields in the Device IN EP
+ * Common/Dedicated Interrupt Mask Register.
+ */
+typedef union diepint_data diepmsk_data_t;
+
+/**
+ * This union represents the bit fields in the Device OUT EP Interrupt
+ * Registerand Device OUT EP Common Interrupt Mask Register.
+ *
+ * - Read the register into the <i>d32</i> member then set/clear the
+ *	 bits using the <i>b</i>it elements.
+ */
+typedef union doepint_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Transfer complete */
+		unsigned xfercompl:1;
+		/** Endpoint disable  */
+		unsigned epdisabled:1;
+		/** AHB Error */
+		unsigned ahberr:1;
+		/** Setup Phase Done (contorl EPs) */
+		unsigned setup:1;
+		/** OUT Token Received when Endpoint Disabled */
+		unsigned outtknepdis:1;
+
+		unsigned stsphsercvd:1;
+		/** Back-to-Back SETUP Packets Received */
+		unsigned back2backsetup:1;
+
+		unsigned reserved7:1;
+		/** OUT packet Error */
+		unsigned outpkterr:1;
+		/** BNA Interrupt */
+		unsigned bna:1;
+
+		unsigned reserved10:1;
+		/** Packet Drop Status */
+		unsigned pktdrpsts:1;
+		/** Babble Interrupt */
+		unsigned babble:1;
+		/** NAK Interrupt */
+		unsigned nak:1;
+		/** NYET Interrupt */
+		unsigned nyet:1;
+		/** Bit indicating setup packet received */
+		unsigned sr:1;
+
+		unsigned reserved16_31:16;
+	} b;
+} doepint_data_t;
+
+/**
+ * This union represents the bit fields in the Device OUT EP
+ * Common/Dedicated Interrupt Mask Register.
+ */
+typedef union doepint_data doepmsk_data_t;
+
+/**
+ * This union represents the bit fields in the Device All EP Interrupt
+ * and Mask Registers.
+ * - Read the register into the <i>d32</i> member then set/clear the
+ *	 bits using the <i>b</i>it elements.
+ */
+typedef union daint_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** IN Endpoint bits */
+		unsigned in:16;
+		/** OUT Endpoint bits */
+		unsigned out:16;
+	} ep;
+	struct {
+		/** IN Endpoint bits */
+		unsigned inep0:1;
+		unsigned inep1:1;
+		unsigned inep2:1;
+		unsigned inep3:1;
+		unsigned inep4:1;
+		unsigned inep5:1;
+		unsigned inep6:1;
+		unsigned inep7:1;
+		unsigned inep8:1;
+		unsigned inep9:1;
+		unsigned inep10:1;
+		unsigned inep11:1;
+		unsigned inep12:1;
+		unsigned inep13:1;
+		unsigned inep14:1;
+		unsigned inep15:1;
+		/** OUT Endpoint bits */
+		unsigned outep0:1;
+		unsigned outep1:1;
+		unsigned outep2:1;
+		unsigned outep3:1;
+		unsigned outep4:1;
+		unsigned outep5:1;
+		unsigned outep6:1;
+		unsigned outep7:1;
+		unsigned outep8:1;
+		unsigned outep9:1;
+		unsigned outep10:1;
+		unsigned outep11:1;
+		unsigned outep12:1;
+		unsigned outep13:1;
+		unsigned outep14:1;
+		unsigned outep15:1;
+	} b;
+} daint_data_t;
+
+/**
+ * This union represents the bit fields in the Device IN Token Queue
+ * Read Registers.
+ * - Read the register into the <i>d32</i> member.
+ * - READ-ONLY Register
+ */
+typedef union dtknq1_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** In Token Queue Write Pointer */
+		unsigned intknwptr:5;
+		/** Reserved */
+		unsigned reserved05_06:2;
+		/** write pointer has wrapped. */
+		unsigned wrap_bit:1;
+		/** EP Numbers of IN Tokens 0 ... 4 */
+		unsigned epnums0_5:24;
+	} b;
+} dtknq1_data_t;
+
+/**
+ * This union represents Threshold control Register
+ * - Read and write the register into the <i>d32</i> member.
+ * - READ-WRITABLE Register
+ */
+typedef union dthrctl_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** non ISO Tx Thr. Enable */
+		unsigned non_iso_thr_en:1;
+		/** ISO Tx Thr. Enable */
+		unsigned iso_thr_en:1;
+		/** Tx Thr. Length */
+		unsigned tx_thr_len:9;
+		/** AHB Threshold ratio */
+		unsigned ahb_thr_ratio:2;
+		/** Reserved */
+		unsigned reserved13_15:3;
+		/** Rx Thr. Enable */
+		unsigned rx_thr_en:1;
+		/** Rx Thr. Length */
+		unsigned rx_thr_len:9;
+		unsigned reserved26:1;
+		/** Arbiter Parking Enable*/
+		unsigned arbprken:1;
+		/** Reserved */
+		unsigned reserved28_31:4;
+	} b;
+} dthrctl_data_t;
+
+/**
+ * Device Logical IN Endpoint-Specific Registers. <i>Offsets
+ * 900h-AFCh</i>
+ *
+ * There will be one set of endpoint registers per logical endpoint
+ * implemented.
+ *
+ * <i>These registers are visible only in Device mode and must not be
+ * accessed in Host mode, as the results are unknown.</i>
+ */
+typedef struct dwc_otg_dev_in_ep_regs {
+	/** Device IN Endpoint Control Register. <i>Offset:900h +
+	 * (ep_num * 20h) + 00h</i> */
+	volatile uint32_t diepctl;
+	/** Reserved. <i>Offset:900h + (ep_num * 20h) + 04h</i> */
+	uint32_t reserved04;
+	/** Device IN Endpoint Interrupt Register. <i>Offset:900h +
+	 * (ep_num * 20h) + 08h</i> */
+	volatile uint32_t diepint;
+	/** Reserved. <i>Offset:900h + (ep_num * 20h) + 0Ch</i> */
+	uint32_t reserved0C;
+	/** Device IN Endpoint Transfer Size
+	 * Register. <i>Offset:900h + (ep_num * 20h) + 10h</i> */
+	volatile uint32_t dieptsiz;
+	/** Device IN Endpoint DMA Address Register. <i>Offset:900h +
+	 * (ep_num * 20h) + 14h</i> */
+	volatile uint32_t diepdma;
+	/** Device IN Endpoint Transmit FIFO Status Register. <i>Offset:900h +
+	 * (ep_num * 20h) + 18h</i> */
+	volatile uint32_t dtxfsts;
+	/** Device IN Endpoint DMA Buffer Register. <i>Offset:900h +
+	 * (ep_num * 20h) + 1Ch</i> */
+	volatile uint32_t diepdmab;
+} dwc_otg_dev_in_ep_regs_t;
+
+/**
+ * Device Logical OUT Endpoint-Specific Registers. <i>Offsets:
+ * B00h-CFCh</i>
+ *
+ * There will be one set of endpoint registers per logical endpoint
+ * implemented.
+ *
+ * <i>These registers are visible only in Device mode and must not be
+ * accessed in Host mode, as the results are unknown.</i>
+ */
+typedef struct dwc_otg_dev_out_ep_regs {
+	/** Device OUT Endpoint Control Register. <i>Offset:B00h +
+	 * (ep_num * 20h) + 00h</i> */
+	volatile uint32_t doepctl;
+	/** Reserved. <i>Offset:B00h + (ep_num * 20h) + 04h</i> */
+	uint32_t reserved04;
+	/** Device OUT Endpoint Interrupt Register. <i>Offset:B00h +
+	 * (ep_num * 20h) + 08h</i> */
+	volatile uint32_t doepint;
+	/** Reserved. <i>Offset:B00h + (ep_num * 20h) + 0Ch</i> */
+	uint32_t reserved0C;
+	/** Device OUT Endpoint Transfer Size Register. <i>Offset:
+	 * B00h + (ep_num * 20h) + 10h</i> */
+	volatile uint32_t doeptsiz;
+	/** Device OUT Endpoint DMA Address Register. <i>Offset:B00h
+	 * + (ep_num * 20h) + 14h</i> */
+	volatile uint32_t doepdma;
+	/** Reserved. <i>Offset:B00h +	 * (ep_num * 20h) + 18h</i> */
+	uint32_t unused;
+	/** Device OUT Endpoint DMA Buffer Register. <i>Offset:B00h
+	 * + (ep_num * 20h) + 1Ch</i> */
+	uint32_t doepdmab;
+} dwc_otg_dev_out_ep_regs_t;
+
+/**
+ * This union represents the bit fields in the Device EP Control
+ * Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union depctl_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Maximum Packet Size
+		 * IN/OUT EPn
+		 * IN/OUT EP0 - 2 bits
+		 *	 2'b00: 64 Bytes
+		 *	 2'b01: 32
+		 *	 2'b10: 16
+		 *	 2'b11: 8 */
+		unsigned mps:11;
+#define DWC_DEP0CTL_MPS_64	 0
+#define DWC_DEP0CTL_MPS_32	 1
+#define DWC_DEP0CTL_MPS_16	 2
+#define DWC_DEP0CTL_MPS_8	 3
+
+		/** Next Endpoint
+		 * IN EPn/IN EP0
+		 * OUT EPn/OUT EP0 - reserved */
+		unsigned nextep:4;
+
+		/** USB Active Endpoint */
+		unsigned usbactep:1;
+
+		/** Endpoint DPID (INTR/Bulk IN and OUT endpoints)
+		 * This field contains the PID of the packet going to
+		 * be received or transmitted on this endpoint. The
+		 * application should program the PID of the first
+		 * packet going to be received or transmitted on this
+		 * endpoint , after the endpoint is
+		 * activated. Application use the SetD1PID and
+		 * SetD0PID fields of this register to program either
+		 * D0 or D1 PID.
+		 *
+		 * The encoding for this field is
+		 *	 - 0: D0
+		 *	 - 1: D1
+		 */
+		unsigned dpid:1;
+
+		/** NAK Status */
+		unsigned naksts:1;
+
+		/** Endpoint Type
+		 *	2'b00: Control
+		 *	2'b01: Isochronous
+		 *	2'b10: Bulk
+		 *	2'b11: Interrupt */
+		unsigned eptype:2;
+
+		/** Snoop Mode
+		 * OUT EPn/OUT EP0
+		 * IN EPn/IN EP0 - reserved */
+		unsigned snp:1;
+
+		/** Stall Handshake */
+		unsigned stall:1;
+
+		/** Tx Fifo Number
+		 * IN EPn/IN EP0
+		 * OUT EPn/OUT EP0 - reserved */
+		unsigned txfnum:4;
+
+		/** Clear NAK */
+		unsigned cnak:1;
+		/** Set NAK */
+		unsigned snak:1;
+		/** Set DATA0 PID (INTR/Bulk IN and OUT endpoints)
+		 * Writing to this field sets the Endpoint DPID (DPID)
+		 * field in this register to DATA0. Set Even
+		 * (micro)frame (SetEvenFr) (ISO IN and OUT Endpoints)
+		 * Writing to this field sets the Even/Odd
+		 * (micro)frame (EO_FrNum) field to even (micro)
+		 * frame.
+		 */
+		unsigned setd0pid:1;
+		/** Set DATA1 PID (INTR/Bulk IN and OUT endpoints)
+		 * Writing to this field sets the Endpoint DPID (DPID)
+		 * field in this register to DATA1 Set Odd
+		 * (micro)frame (SetOddFr) (ISO IN and OUT Endpoints)
+		 * Writing to this field sets the Even/Odd
+		 * (micro)frame (EO_FrNum) field to odd (micro) frame.
+		 */
+		unsigned setd1pid:1;
+
+		/** Endpoint Disable */
+		unsigned epdis:1;
+		/** Endpoint Enable */
+		unsigned epena:1;
+	} b;
+} depctl_data_t;
+
+/**
+ * This union represents the bit fields in the Device EP Transfer
+ * Size Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union deptsiz_data {
+		/** raw register data */
+	uint32_t d32;
+		/** register bits */
+	struct {
+		/** Transfer size */
+		unsigned xfersize:19;
+/** Max packet count for EP (pow(2,10)-1) */
+#define MAX_PKT_CNT 1023
+		/** Packet Count */
+		unsigned pktcnt:10;
+		/** Multi Count - Periodic IN endpoints */
+		unsigned mc:2;
+		unsigned reserved:1;
+	} b;
+} deptsiz_data_t;
+
+/**
+ * This union represents the bit fields in the Device EP 0 Transfer
+ * Size Register.  Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union deptsiz0_data {
+		/** raw register data */
+	uint32_t d32;
+		/** register bits */
+	struct {
+		/** Transfer size */
+		unsigned xfersize:7;
+				/** Reserved */
+		unsigned reserved7_18:12;
+		/** Packet Count */
+		unsigned pktcnt:2;
+				/** Reserved */
+		unsigned reserved21_28:8;
+				/**Setup Packet Count (DOEPTSIZ0 Only) */
+		unsigned supcnt:2;
+		unsigned reserved31;
+	} b;
+} deptsiz0_data_t;
+
+/////////////////////////////////////////////////
+// DMA Descriptor Specific Structures
+//
+
+/** Buffer status definitions */
+
+#define BS_HOST_READY	0x0
+#define BS_DMA_BUSY		0x1
+#define BS_DMA_DONE		0x2
+#define BS_HOST_BUSY	0x3
+
+/** Receive/Transmit status definitions */
+
+#define RTS_SUCCESS		0x0
+#define RTS_BUFFLUSH	0x1
+#define RTS_RESERVED	0x2
+#define RTS_BUFERR		0x3
+
+/**
+ * This union represents the bit fields in the DMA Descriptor
+ * status quadlet. Read the quadlet into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it, <i>b_iso_out</i> and
+ * <i>b_iso_in</i> elements.
+ */
+typedef union dev_dma_desc_sts {
+		/** raw register data */
+	uint32_t d32;
+		/** quadlet bits */
+	struct {
+		/** Received number of bytes */
+		unsigned bytes:16;
+		/** NAK bit - only for OUT EPs */
+		unsigned nak:1;
+		unsigned reserved17_22:6;
+		/** Multiple Transfer - only for OUT EPs */
+		unsigned mtrf:1;
+		/** Setup Packet received - only for OUT EPs */
+		unsigned sr:1;
+		/** Interrupt On Complete */
+		unsigned ioc:1;
+		/** Short Packet */
+		unsigned sp:1;
+		/** Last */
+		unsigned l:1;
+		/** Receive Status */
+		unsigned sts:2;
+		/** Buffer Status */
+		unsigned bs:2;
+	} b;
+
+//#ifdef DWC_EN_ISOC
+		/** iso out quadlet bits */
+	struct {
+		/** Received number of bytes */
+		unsigned rxbytes:11;
+
+		unsigned reserved11:1;
+		/** Frame Number */
+		unsigned framenum:11;
+		/** Received ISO Data PID */
+		unsigned pid:2;
+		/** Interrupt On Complete */
+		unsigned ioc:1;
+		/** Short Packet */
+		unsigned sp:1;
+		/** Last */
+		unsigned l:1;
+		/** Receive Status */
+		unsigned rxsts:2;
+		/** Buffer Status */
+		unsigned bs:2;
+	} b_iso_out;
+
+		/** iso in quadlet bits */
+	struct {
+		/** Transmited number of bytes */
+		unsigned txbytes:12;
+		/** Frame Number */
+		unsigned framenum:11;
+		/** Transmited ISO Data PID */
+		unsigned pid:2;
+		/** Interrupt On Complete */
+		unsigned ioc:1;
+		/** Short Packet */
+		unsigned sp:1;
+		/** Last */
+		unsigned l:1;
+		/** Transmit Status */
+		unsigned txsts:2;
+		/** Buffer Status */
+		unsigned bs:2;
+	} b_iso_in;
+//#endif                                /* DWC_EN_ISOC */
+} dev_dma_desc_sts_t;
+
+/**
+ * DMA Descriptor structure
+ *
+ * DMA Descriptor structure contains two quadlets:
+ * Status quadlet and Data buffer pointer.
+ */
+typedef struct dwc_otg_dev_dma_desc {
+	/** DMA Descriptor status quadlet */
+	dev_dma_desc_sts_t status;
+	/** DMA Descriptor data buffer pointer */
+	uint32_t buf;
+} dwc_otg_dev_dma_desc_t;
+
+/**
+ * The dwc_otg_dev_if structure contains information needed to manage
+ * the DWC_otg controller acting in device mode. It represents the
+ * programming view of the device-specific aspects of the controller.
+ */
+typedef struct dwc_otg_dev_if {
+	/** Pointer to device Global registers.
+	 * Device Global Registers starting at offset 800h
+	 */
+	dwc_otg_device_global_regs_t *dev_global_regs;
+#define DWC_DEV_GLOBAL_REG_OFFSET 0x800
+
+	/**
+	 * Device Logical IN Endpoint-Specific Registers 900h-AFCh
+	 */
+	dwc_otg_dev_in_ep_regs_t *in_ep_regs[MAX_EPS_CHANNELS];
+#define DWC_DEV_IN_EP_REG_OFFSET 0x900
+#define DWC_EP_REG_OFFSET 0x20
+
+	/** Device Logical OUT Endpoint-Specific Registers B00h-CFCh */
+	dwc_otg_dev_out_ep_regs_t *out_ep_regs[MAX_EPS_CHANNELS];
+#define DWC_DEV_OUT_EP_REG_OFFSET 0xB00
+
+	/* Device configuration information */
+	uint8_t speed;				 /**< Device Speed	0: Unknown, 1: LS, 2:FS, 3: HS */
+	uint8_t num_in_eps;		 /**< Number # of Tx EP range: 0-15 exept ep0 */
+	uint8_t num_out_eps;		 /**< Number # of Rx EP range: 0-15 exept ep 0*/
+
+	/** Size of periodic FIFOs (Bytes) */
+	uint16_t perio_tx_fifo_size[MAX_PERIO_FIFOS];
+
+	/** Size of Tx FIFOs (Bytes) */
+	uint16_t tx_fifo_size[MAX_TX_FIFOS];
+
+	/** Thresholding enable flags and length varaiables **/
+	uint16_t rx_thr_en;
+	uint16_t iso_tx_thr_en;
+	uint16_t non_iso_tx_thr_en;
+
+	uint16_t rx_thr_length;
+	uint16_t tx_thr_length;
+
+	/**
+	 * Pointers to the DMA Descriptors for EP0 Control
+	 * transfers (virtual and physical)
+	 */
+
+	/** 2 descriptors for SETUP packets */
+	dwc_dma_t dma_setup_desc_addr[2];
+	dwc_otg_dev_dma_desc_t *setup_desc_addr[2];
+
+	/** Pointer to Descriptor with latest SETUP packet */
+	dwc_otg_dev_dma_desc_t *psetup;
+
+	/** Index of current SETUP handler descriptor */
+	uint32_t setup_desc_index;
+
+	/** Descriptor for Data In or Status In phases */
+	dwc_dma_t dma_in_desc_addr;
+	dwc_otg_dev_dma_desc_t *in_desc_addr;
+
+	/** Descriptor for Data Out or Status Out phases */
+	dwc_dma_t dma_out_desc_addr;
+	dwc_otg_dev_dma_desc_t *out_desc_addr;
+
+	/** Setup Packet Detected - if set clear NAK when queueing */
+	uint32_t spd;
+	/** Isoc ep pointer on which incomplete happens */
+	void *isoc_ep;
+
+} dwc_otg_dev_if_t;
+
+/////////////////////////////////////////////////
+// Host Mode Register Structures
+//
+/**
+ * The Host Global Registers structure defines the size and relative
+ * field offsets for the Host Mode Global Registers.  Host Global
+ * Registers offsets 400h-7FFh.
+*/
+typedef struct dwc_otg_host_global_regs {
+	/** Host Configuration Register.   <i>Offset: 400h</i> */
+	volatile uint32_t hcfg;
+	/** Host Frame Interval Register.	<i>Offset: 404h</i> */
+	volatile uint32_t hfir;
+	/** Host Frame Number / Frame Remaining Register. <i>Offset: 408h</i> */
+	volatile uint32_t hfnum;
+	/** Reserved.	<i>Offset: 40Ch</i> */
+	uint32_t reserved40C;
+	/** Host Periodic Transmit FIFO/ Queue Status Register. <i>Offset: 410h</i> */
+	volatile uint32_t hptxsts;
+	/** Host All Channels Interrupt Register. <i>Offset: 414h</i> */
+	volatile uint32_t haint;
+	/** Host All Channels Interrupt Mask Register. <i>Offset: 418h</i> */
+	volatile uint32_t haintmsk;
+	/** Host Frame List Base Address Register . <i>Offset: 41Ch</i> */
+	volatile uint32_t hflbaddr;
+} dwc_otg_host_global_regs_t;
+
+/**
+ * This union represents the bit fields in the Host Configuration Register.
+ * Read the register into the <i>d32</i> member then set/clear the bits using
+ * the <i>b</i>it elements. Write the <i>d32</i> member to the hcfg register.
+ */
+typedef union hcfg_data {
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		/** FS/LS Phy Clock Select */
+		unsigned fslspclksel:2;
+#define DWC_HCFG_30_60_MHZ 0
+#define DWC_HCFG_48_MHZ	   1
+#define DWC_HCFG_6_MHZ	   2
+
+		/** FS/LS Only Support */
+		unsigned fslssupp:1;
+		unsigned reserved3_6:4;
+		/** Enable 32-KHz Suspend Mode */
+		unsigned ena32khzs:1;
+		/** Resume Validation Periiod */
+		unsigned resvalid:8;
+		unsigned reserved16_22:7;
+		/** Enable Scatter/gather DMA in Host mode */
+		unsigned descdma:1;
+		/** Frame List Entries */
+		unsigned frlisten:2;
+		/** Enable Periodic Scheduling */
+		unsigned perschedena:1;
+		unsigned reserved27_30:4;
+		unsigned modechtimen:1;
+	} b;
+} hcfg_data_t;
+
+/**
+ * This union represents the bit fields in the Host Frame Remaing/Number
+ * Register.
+ */
+typedef union hfir_data {
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		unsigned frint:16;
+		unsigned hfirrldctrl:1;
+		unsigned reserved:15;
+	} b;
+} hfir_data_t;
+
+/**
+ * This union represents the bit fields in the Host Frame Remaing/Number
+ * Register.
+ */
+typedef union hfnum_data {
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		unsigned frnum:16;
+#define DWC_HFNUM_MAX_FRNUM 0x3FFF
+		unsigned frrem:16;
+	} b;
+} hfnum_data_t;
+
+typedef union hptxsts_data {
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		unsigned ptxfspcavail:16;
+		unsigned ptxqspcavail:8;
+		/** Top of the Periodic Transmit Request Queue
+		 *	- bit 24 - Terminate (last entry for the selected channel)
+		 *	- bits 26:25 - Token Type
+		 *	  - 2'b00 - Zero length
+		 *	  - 2'b01 - Ping
+		 *	  - 2'b10 - Disable
+		 *	- bits 30:27 - Channel Number
+		 *	- bit 31 - Odd/even microframe
+		 */
+		unsigned ptxqtop_terminate:1;
+		unsigned ptxqtop_token:2;
+		unsigned ptxqtop_chnum:4;
+		unsigned ptxqtop_odd:1;
+	} b;
+} hptxsts_data_t;
+
+/**
+ * This union represents the bit fields in the Host Port Control and Status
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements. Write the <i>d32</i> member to the
+ * hprt0 register.
+ */
+typedef union hprt0_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned prtconnsts:1;
+		unsigned prtconndet:1;
+		unsigned prtena:1;
+		unsigned prtenchng:1;
+		unsigned prtovrcurract:1;
+		unsigned prtovrcurrchng:1;
+		unsigned prtres:1;
+		unsigned prtsusp:1;
+		unsigned prtrst:1;
+		unsigned reserved9:1;
+		unsigned prtlnsts:2;
+		unsigned prtpwr:1;
+		unsigned prttstctl:4;
+		unsigned prtspd:2;
+#define DWC_HPRT0_PRTSPD_HIGH_SPEED 0
+#define DWC_HPRT0_PRTSPD_FULL_SPEED 1
+#define DWC_HPRT0_PRTSPD_LOW_SPEED	2
+		unsigned reserved19_31:13;
+	} b;
+} hprt0_data_t;
+
+/**
+ * This union represents the bit fields in the Host All Interrupt
+ * Register.
+ */
+typedef union haint_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned ch0:1;
+		unsigned ch1:1;
+		unsigned ch2:1;
+		unsigned ch3:1;
+		unsigned ch4:1;
+		unsigned ch5:1;
+		unsigned ch6:1;
+		unsigned ch7:1;
+		unsigned ch8:1;
+		unsigned ch9:1;
+		unsigned ch10:1;
+		unsigned ch11:1;
+		unsigned ch12:1;
+		unsigned ch13:1;
+		unsigned ch14:1;
+		unsigned ch15:1;
+		unsigned reserved:16;
+	} b;
+
+	struct {
+		unsigned chint:16;
+		unsigned reserved:16;
+	} b2;
+} haint_data_t;
+
+/**
+ * This union represents the bit fields in the Host All Interrupt
+ * Register.
+ */
+typedef union haintmsk_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned ch0:1;
+		unsigned ch1:1;
+		unsigned ch2:1;
+		unsigned ch3:1;
+		unsigned ch4:1;
+		unsigned ch5:1;
+		unsigned ch6:1;
+		unsigned ch7:1;
+		unsigned ch8:1;
+		unsigned ch9:1;
+		unsigned ch10:1;
+		unsigned ch11:1;
+		unsigned ch12:1;
+		unsigned ch13:1;
+		unsigned ch14:1;
+		unsigned ch15:1;
+		unsigned reserved:16;
+	} b;
+
+	struct {
+		unsigned chint:16;
+		unsigned reserved:16;
+	} b2;
+} haintmsk_data_t;
+
+/**
+ * Host Channel Specific Registers. <i>500h-5FCh</i>
+ */
+typedef struct dwc_otg_hc_regs {
+	/** Host Channel 0 Characteristic Register. <i>Offset: 500h + (chan_num * 20h) + 00h</i> */
+	volatile uint32_t hcchar;
+	/** Host Channel 0 Split Control Register. <i>Offset: 500h + (chan_num * 20h) + 04h</i> */
+	volatile uint32_t hcsplt;
+	/** Host Channel 0 Interrupt Register. <i>Offset: 500h + (chan_num * 20h) + 08h</i> */
+	volatile uint32_t hcint;
+	/** Host Channel 0 Interrupt Mask Register. <i>Offset: 500h + (chan_num * 20h) + 0Ch</i> */
+	volatile uint32_t hcintmsk;
+	/** Host Channel 0 Transfer Size Register. <i>Offset: 500h + (chan_num * 20h) + 10h</i> */
+	volatile uint32_t hctsiz;
+	/** Host Channel 0 DMA Address Register. <i>Offset: 500h + (chan_num * 20h) + 14h</i> */
+	volatile uint32_t hcdma;
+	volatile uint32_t reserved;
+	/** Host Channel 0 DMA Buffer Address Register. <i>Offset: 500h + (chan_num * 20h) + 1Ch</i> */
+	volatile uint32_t hcdmab;
+} dwc_otg_hc_regs_t;
+
+/**
+ * This union represents the bit fields in the Host Channel Characteristics
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements. Write the <i>d32</i> member to the
+ * hcchar register.
+ */
+typedef union hcchar_data {
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		/** Maximum packet size in bytes */
+		unsigned mps:11;
+
+		/** Endpoint number */
+		unsigned epnum:4;
+
+		/** 0: OUT, 1: IN */
+		unsigned epdir:1;
+
+		unsigned reserved:1;
+
+		/** 0: Full/high speed device, 1: Low speed device */
+		unsigned lspddev:1;
+
+		/** 0: Control, 1: Isoc, 2: Bulk, 3: Intr */
+		unsigned eptype:2;
+
+		/** Packets per frame for periodic transfers. 0 is reserved. */
+		unsigned multicnt:2;
+
+		/** Device address */
+		unsigned devaddr:7;
+
+		/**
+		 * Frame to transmit periodic transaction.
+		 * 0: even, 1: odd
+		 */
+		unsigned oddfrm:1;
+
+		/** Channel disable */
+		unsigned chdis:1;
+
+		/** Channel enable */
+		unsigned chen:1;
+	} b;
+} hcchar_data_t;
+
+typedef union hcsplt_data {
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		/** Port Address */
+		unsigned prtaddr:7;
+
+		/** Hub Address */
+		unsigned hubaddr:7;
+
+		/** Transaction Position */
+		unsigned xactpos:2;
+#define DWC_HCSPLIT_XACTPOS_MID 0
+#define DWC_HCSPLIT_XACTPOS_END 1
+#define DWC_HCSPLIT_XACTPOS_BEGIN 2
+#define DWC_HCSPLIT_XACTPOS_ALL 3
+
+		/** Do Complete Split */
+		unsigned compsplt:1;
+
+		/** Reserved */
+		unsigned reserved:14;
+
+		/** Split Enble */
+		unsigned spltena:1;
+	} b;
+} hcsplt_data_t;
+
+/**
+ * This union represents the bit fields in the Host All Interrupt
+ * Register.
+ */
+typedef union hcint_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** Transfer Complete */
+		unsigned xfercomp:1;
+		/** Channel Halted */
+		unsigned chhltd:1;
+		/** AHB Error */
+		unsigned ahberr:1;
+		/** STALL Response Received */
+		unsigned stall:1;
+		/** NAK Response Received */
+		unsigned nak:1;
+		/** ACK Response Received */
+		unsigned ack:1;
+		/** NYET Response Received */
+		unsigned nyet:1;
+		/** Transaction Err */
+		unsigned xacterr:1;
+		/** Babble Error */
+		unsigned bblerr:1;
+		/** Frame Overrun */
+		unsigned frmovrun:1;
+		/** Data Toggle Error */
+		unsigned datatglerr:1;
+		/** Buffer Not Available (only for DDMA mode) */
+		unsigned bna:1;
+		/** Exessive transaction error (only for DDMA mode) */
+		unsigned xcs_xact:1;
+		/** Frame List Rollover interrupt */
+		unsigned frm_list_roll:1;
+		/** Reserved */
+		unsigned reserved14_31:18;
+	} b;
+} hcint_data_t;
+
+/**
+ * This union represents the bit fields in the Host Channel Interrupt Mask
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements. Write the <i>d32</i> member to the
+ * hcintmsk register.
+ */
+typedef union hcintmsk_data {
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		unsigned xfercompl:1;
+		unsigned chhltd:1;
+		unsigned ahberr:1;
+		unsigned stall:1;
+		unsigned nak:1;
+		unsigned ack:1;
+		unsigned nyet:1;
+		unsigned xacterr:1;
+		unsigned bblerr:1;
+		unsigned frmovrun:1;
+		unsigned datatglerr:1;
+		unsigned bna:1;
+		unsigned xcs_xact:1;
+		unsigned frm_list_roll:1;
+		unsigned reserved14_31:18;
+	} b;
+} hcintmsk_data_t;
+
+/**
+ * This union represents the bit fields in the Host Channel Transfer Size
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements. Write the <i>d32</i> member to the
+ * hcchar register.
+ */
+
+typedef union hctsiz_data {
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		/** Total transfer size in bytes */
+		unsigned xfersize:19;
+
+		/** Data packets to transfer */
+		unsigned pktcnt:10;
+
+		/**
+		 * Packet ID for next data packet
+		 * 0: DATA0
+		 * 1: DATA2
+		 * 2: DATA1
+		 * 3: MDATA (non-Control), SETUP (Control)
+		 */
+		unsigned pid:2;
+#define DWC_HCTSIZ_DATA0 0
+#define DWC_HCTSIZ_DATA1 2
+#define DWC_HCTSIZ_DATA2 1
+#define DWC_HCTSIZ_MDATA 3
+#define DWC_HCTSIZ_SETUP 3
+
+		/** Do PING protocol when 1 */
+		unsigned dopng:1;
+	} b;
+
+	/** register bits */
+	struct {
+		/** Scheduling information */
+		unsigned schinfo:8;
+
+		/** Number of transfer descriptors.
+		 * Max value:
+		 * 64 in general,
+		 * 256 only for HS isochronous endpoint.
+		 */
+		unsigned ntd:8;
+
+		/** Data packets to transfer */
+		unsigned reserved16_28:13;
+
+		/**
+		 * Packet ID for next data packet
+		 * 0: DATA0
+		 * 1: DATA2
+		 * 2: DATA1
+		 * 3: MDATA (non-Control)
+		 */
+		unsigned pid:2;
+
+		/** Do PING protocol when 1 */
+		unsigned dopng:1;
+	} b_ddma;
+} hctsiz_data_t;
+
+/**
+ * This union represents the bit fields in the Host DMA Address
+ * Register used in Descriptor DMA mode.
+ */
+typedef union hcdma_data {
+	/** raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		unsigned reserved0_2:3;
+		/** Current Transfer Descriptor. Not used for ISOC */
+		unsigned ctd:8;
+		/** Start Address of Descriptor List */
+		unsigned dma_addr:21;
+	} b;
+} hcdma_data_t;
+
+/**
+ * This union represents the bit fields in the DMA Descriptor
+ * status quadlet for host mode. Read the quadlet into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union host_dma_desc_sts {
+	/** raw register data */
+	uint32_t d32;
+	/** quadlet bits */
+
+	/* for non-isochronous  */
+	struct {
+		/** Number of bytes */
+		unsigned n_bytes:17;
+		/** QTD offset to jump when Short Packet received - only for IN EPs */
+		unsigned qtd_offset:6;
+		/**
+		 * Set to request the core to jump to alternate QTD if
+		 * Short Packet received - only for IN EPs
+		 */
+		unsigned a_qtd:1;
+		 /**
+		  * Setup Packet bit. When set indicates that buffer contains
+		  * setup packet.
+		  */
+		unsigned sup:1;
+		/** Interrupt On Complete */
+		unsigned ioc:1;
+		/** End of List */
+		unsigned eol:1;
+		unsigned reserved27:1;
+		/** Rx/Tx Status */
+		unsigned sts:2;
+#define DMA_DESC_STS_PKTERR	1
+		unsigned reserved30:1;
+		/** Active Bit */
+		unsigned a:1;
+	} b;
+	/* for isochronous */
+	struct {
+		/** Number of bytes */
+		unsigned n_bytes:12;
+		unsigned reserved12_24:13;
+		/** Interrupt On Complete */
+		unsigned ioc:1;
+		unsigned reserved26_27:2;
+		/** Rx/Tx Status */
+		unsigned sts:2;
+		unsigned reserved30:1;
+		/** Active Bit */
+		unsigned a:1;
+	} b_isoc;
+} host_dma_desc_sts_t;
+
+#define	MAX_DMA_DESC_SIZE		131071
+#define MAX_DMA_DESC_NUM_GENERIC	64
+#define MAX_DMA_DESC_NUM_HS_ISOC	256
+#define MAX_FRLIST_EN_NUM		64
+/**
+ * Host-mode DMA Descriptor structure
+ *
+ * DMA Descriptor structure contains two quadlets:
+ * Status quadlet and Data buffer pointer.
+ */
+typedef struct dwc_otg_host_dma_desc {
+	/** DMA Descriptor status quadlet */
+	host_dma_desc_sts_t status;
+	/** DMA Descriptor data buffer pointer */
+	uint32_t buf;
+} dwc_otg_host_dma_desc_t;
+
+/** OTG Host Interface Structure.
+ *
+ * The OTG Host Interface Structure structure contains information
+ * needed to manage the DWC_otg controller acting in host mode. It
+ * represents the programming view of the host-specific aspects of the
+ * controller.
+ */
+typedef struct dwc_otg_host_if {
+	/** Host Global Registers starting at offset 400h.*/
+	dwc_otg_host_global_regs_t *host_global_regs;
+#define DWC_OTG_HOST_GLOBAL_REG_OFFSET 0x400
+
+	/** Host Port 0 Control and Status Register */
+	volatile uint32_t *hprt0;
+#define DWC_OTG_HOST_PORT_REGS_OFFSET 0x440
+
+	/** Host Channel Specific Registers at offsets 500h-5FCh. */
+	dwc_otg_hc_regs_t *hc_regs[MAX_EPS_CHANNELS];
+#define DWC_OTG_HOST_CHAN_REGS_OFFSET 0x500
+#define DWC_OTG_CHAN_REGS_OFFSET 0x20
+
+	/* Host configuration information */
+	/** Number of Host Channels (range: 1-16) */
+	uint8_t num_host_channels;
+	/** Periodic EPs supported (0: no, 1: yes) */
+	uint8_t perio_eps_supported;
+	/** Periodic Tx FIFO Size (Only 1 host periodic Tx FIFO) */
+	uint16_t perio_tx_fifo_size;
+
+} dwc_otg_host_if_t;
+
+/**
+ * This union represents the bit fields in the Power and Clock Gating Control
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements.
+ */
+typedef union pcgcctl_data {
+	/** raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		/** Stop Pclk */
+		unsigned stoppclk:1;
+		/** Gate Hclk */
+		unsigned gatehclk:1;
+		/** Power Clamp */
+		unsigned pwrclmp:1;
+		/** Reset Power Down Modules */
+		unsigned rstpdwnmodule:1;
+		/** Reserved */
+		unsigned reserved:1;
+		/** Enable Sleep Clock Gating (Enbl_L1Gating) */
+		unsigned enbl_sleep_gating:1;
+		/** PHY In Sleep (PhySleep) */
+		unsigned phy_in_sleep:1;
+		/** Deep Sleep*/
+		unsigned deep_sleep:1;
+		unsigned resetaftsusp:1;
+		unsigned restoremode:1;
+		unsigned enbl_extnd_hiber:1;
+		unsigned extnd_hiber_pwrclmp:1;
+		unsigned extnd_hiber_switch:1;
+		unsigned ess_reg_restored:1;
+		unsigned prt_clk_sel:2;
+		unsigned port_power:1;
+		unsigned max_xcvrselect:2;
+		unsigned max_termsel:1;
+		unsigned mac_dev_addr:7;
+		unsigned p2hd_dev_enum_spd:2;
+		unsigned p2hd_prt_spd:2;
+		unsigned if_dev_mode:1;
+	} b;
+} pcgcctl_data_t;
+
+/**
+ * This union represents the bit fields in the Global Data FIFO Software
+ * Configuration Register. Read the register into the <i>d32</i> member then
+ * set/clear the bits using the <i>b</i>it elements.
+ */
+typedef union gdfifocfg_data {
+	/* raw register data */
+	uint32_t d32;
+	/** register bits */
+	struct {
+		/** OTG Data FIFO depth */
+		unsigned gdfifocfg:16;
+		/** Start address of EP info controller */
+		unsigned epinfobase:16;
+	} b;
+} gdfifocfg_data_t;
+
+/**
+ * This union represents the bit fields in the Global Power Down Register
+ * Register. Read the register into the <i>d32</i> member then set/clear the
+ * bits using the <i>b</i>it elements.
+ */
+typedef union gpwrdn_data {
+	/* raw register data */
+	uint32_t d32;
+
+	/** register bits */
+	struct {
+		/** PMU Interrupt Select */
+		unsigned pmuintsel:1;
+		/** PMU Active */
+		unsigned pmuactv:1;
+		/** Restore */
+		unsigned restore:1;
+		/** Power Down Clamp */
+		unsigned pwrdnclmp:1;
+		/** Power Down Reset */
+		unsigned pwrdnrstn:1;
+		/** Power Down Switch */
+		unsigned pwrdnswtch:1;
+		/** Disable VBUS */
+		unsigned dis_vbus:1;
+		/** Line State Change */
+		unsigned lnstschng:1;
+		/** Line state change mask */
+		unsigned lnstchng_msk:1;
+		/** Reset Detected */
+		unsigned rst_det:1;
+		/** Reset Detect mask */
+		unsigned rst_det_msk:1;
+		/** Disconnect Detected */
+		unsigned disconn_det:1;
+		/** Disconnect Detect mask */
+		unsigned disconn_det_msk:1;
+		/** Connect Detected*/
+		unsigned connect_det:1;
+		/** Connect Detected Mask*/
+		unsigned connect_det_msk:1;
+		/** SRP Detected */
+		unsigned srp_det:1;
+		/** SRP Detect mask */
+		unsigned srp_det_msk:1;
+		/** Status Change Interrupt */
+		unsigned sts_chngint:1;
+		/** Status Change Interrupt Mask */
+		unsigned sts_chngint_msk:1;
+		/** Line State */
+		unsigned linestate:2;
+		/** Indicates current mode(status of IDDIG signal) */
+		unsigned idsts:1;
+		/** B Session Valid signal status*/
+		unsigned bsessvld:1;
+		/** ADP Event Detected */
+		unsigned adp_int:1;
+		/** Multi Valued ID pin */
+		unsigned mult_val_id_bc:5;
+		/** Reserved 24_31 */
+		unsigned reserved29_31:3;
+	} b;
+} gpwrdn_data_t;
+
+#endif
diff --git a/drivers/usb/gadget/udc/hiudc/usb.h b/drivers/usb/gadget/udc/hiudc/usb.h
new file mode 100644
index 0000000..357d6c7
--- /dev/null
+++ b/drivers/usb/gadget/udc/hiudc/usb.h
@@ -0,0 +1,933 @@
+/*
+ * Copyright (c) 1998 The NetBSD Foundation, Inc.
+ * All rights reserved.
+ *
+ * This code is derived from software contributed to The NetBSD Foundation
+ * by Lennart Augustsson (lennart@augustsson.net) at
+ * Carlstedt Research & Technology.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. All advertising materials mentioning features or use of this software
+ *    must display the following acknowledgement:
+ *        This product includes software developed by the NetBSD
+ *        Foundation, Inc. and its contributors.
+ * 4. Neither the name of The NetBSD Foundation nor the names of its
+ *    contributors may be used to endorse or promote products derived
+ *    from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
+ * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
+ * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/* Modified by Synopsys, Inc, 12/12/2007 */
+
+
+#ifndef _USB_H_
+#define _USB_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/*
+ * The USB records contain some unaligned little-endian word
+ * components.  The U[SG]ETW macros take care of both the alignment
+ * and endian problem and should always be used to access non-byte
+ * values.
+ */
+typedef u_int8_t uByte;
+typedef u_int8_t uWord[2];
+typedef u_int8_t uDWord[4];
+
+#define USETW2(w,h,l) ((w)[0] = (u_int8_t)(l), (w)[1] = (u_int8_t)(h))
+#define UCONSTW(x)	{ (x) & 0xff, ((x) >> 8) & 0xff }
+#define UCONSTDW(x)	{ (x) & 0xff, ((x) >> 8) & 0xff, \
+			  ((x) >> 16) & 0xff, ((x) >> 24) & 0xff }
+
+#if 1
+#define UGETW(w) ((w)[0] | ((w)[1] << 8))
+#define USETW(w,v) ((w)[0] = (u_int8_t)(v), (w)[1] = (u_int8_t)((v) >> 8))
+#define UGETDW(w) ((w)[0] | ((w)[1] << 8) | ((w)[2] << 16) | ((w)[3] << 24))
+#define USETDW(w,v) ((w)[0] = (u_int8_t)(v), \
+		     (w)[1] = (u_int8_t)((v) >> 8), \
+		     (w)[2] = (u_int8_t)((v) >> 16), \
+		     (w)[3] = (u_int8_t)((v) >> 24))
+#else
+/*
+ * On little-endian machines that can handle unanliged accesses
+ * (e.g. i386) these macros can be replaced by the following.
+ */
+#define UGETW(w) (*(u_int16_t *)(w))
+#define USETW(w,v) (*(u_int16_t *)(w) = (v))
+#define UGETDW(w) (*(u_int32_t *)(w))
+#define USETDW(w,v) (*(u_int32_t *)(w) = (v))
+#endif
+
+/*
+ * Macros for accessing UAS IU fields, which are big-endian
+ */
+#define IUSETW2(w,h,l) ((w)[0] = (u_int8_t)(h), (w)[1] = (u_int8_t)(l))
+#define IUCONSTW(x)	{ ((x) >> 8) & 0xff, (x) & 0xff }
+#define IUCONSTDW(x)	{ ((x) >> 24) & 0xff, ((x) >> 16) & 0xff, \
+			((x) >> 8) & 0xff, (x) & 0xff }
+#define IUGETW(w) (((w)[0] << 8) | (w)[1])
+#define IUSETW(w,v) ((w)[0] = (u_int8_t)((v) >> 8), (w)[1] = (u_int8_t)(v))
+#define IUGETDW(w) (((w)[0] << 24) | ((w)[1] << 16) | ((w)[2] << 8) | (w)[3])
+#define IUSETDW(w,v) ((w)[0] = (u_int8_t)((v) >> 24), \
+		      (w)[1] = (u_int8_t)((v) >> 16), \
+		      (w)[2] = (u_int8_t)((v) >> 8), \
+		      (w)[3] = (u_int8_t)(v))
+
+#define UPACKED __attribute__((__packed__))
+
+typedef struct {
+	uByte		bmRequestType;
+	uByte		bRequest;
+	uWord		wValue;
+	uWord		wIndex;
+	uWord		wLength;
+} UPACKED usb_device_request_t;
+
+#define UT_GET_DIR(a) ((a) & 0x80)
+#define UT_WRITE		0x00
+#define UT_READ			0x80
+
+#define UT_GET_TYPE(a) ((a) & 0x60)
+#define UT_STANDARD		0x00
+#define UT_CLASS		0x20
+#define UT_VENDOR		0x40
+
+#define UT_GET_RECIPIENT(a) ((a) & 0x1f)
+#define UT_DEVICE		0x00
+#define UT_INTERFACE		0x01
+#define UT_ENDPOINT		0x02
+#define UT_OTHER		0x03
+
+#define UT_READ_DEVICE		(UT_READ  | UT_STANDARD | UT_DEVICE)
+#define UT_READ_INTERFACE	(UT_READ  | UT_STANDARD | UT_INTERFACE)
+#define UT_READ_ENDPOINT	(UT_READ  | UT_STANDARD | UT_ENDPOINT)
+#define UT_WRITE_DEVICE		(UT_WRITE | UT_STANDARD | UT_DEVICE)
+#define UT_WRITE_INTERFACE	(UT_WRITE | UT_STANDARD | UT_INTERFACE)
+#define UT_WRITE_ENDPOINT	(UT_WRITE | UT_STANDARD | UT_ENDPOINT)
+#define UT_READ_CLASS_DEVICE	(UT_READ  | UT_CLASS | UT_DEVICE)
+#define UT_READ_CLASS_INTERFACE	(UT_READ  | UT_CLASS | UT_INTERFACE)
+#define UT_READ_CLASS_OTHER	(UT_READ  | UT_CLASS | UT_OTHER)
+#define UT_READ_CLASS_ENDPOINT	(UT_READ  | UT_CLASS | UT_ENDPOINT)
+#define UT_WRITE_CLASS_DEVICE	(UT_WRITE | UT_CLASS | UT_DEVICE)
+#define UT_WRITE_CLASS_INTERFACE (UT_WRITE | UT_CLASS | UT_INTERFACE)
+#define UT_WRITE_CLASS_OTHER	(UT_WRITE | UT_CLASS | UT_OTHER)
+#define UT_WRITE_CLASS_ENDPOINT	(UT_WRITE | UT_CLASS | UT_ENDPOINT)
+#define UT_READ_VENDOR_DEVICE	(UT_READ  | UT_VENDOR | UT_DEVICE)
+#define UT_READ_VENDOR_INTERFACE (UT_READ  | UT_VENDOR | UT_INTERFACE)
+#define UT_READ_VENDOR_OTHER	(UT_READ  | UT_VENDOR | UT_OTHER)
+#define UT_READ_VENDOR_ENDPOINT	(UT_READ  | UT_VENDOR | UT_ENDPOINT)
+#define UT_WRITE_VENDOR_DEVICE	(UT_WRITE | UT_VENDOR | UT_DEVICE)
+#define UT_WRITE_VENDOR_INTERFACE (UT_WRITE | UT_VENDOR | UT_INTERFACE)
+#define UT_WRITE_VENDOR_OTHER	(UT_WRITE | UT_VENDOR | UT_OTHER)
+#define UT_WRITE_VENDOR_ENDPOINT (UT_WRITE | UT_VENDOR | UT_ENDPOINT)
+
+/* Requests */
+#define UR_GET_STATUS		0x00
+#define  USTAT_STANDARD_STATUS  0x00
+#define  WUSTAT_WUSB_FEATURE    0x01
+#define  WUSTAT_CHANNEL_INFO    0x02
+#define  WUSTAT_RECEIVED_DATA   0x03
+#define  WUSTAT_MAS_AVAILABILITY 0x04
+#define  WUSTAT_CURRENT_TRANSMIT_POWER 0x05
+#define UR_CLEAR_FEATURE	0x01
+#define UR_SET_FEATURE		0x03
+#define UR_SET_AND_TEST_FEATURE 0x0c
+#define UR_SET_ADDRESS		0x05
+#define UR_GET_DESCRIPTOR	0x06
+#define  UDESC_DEVICE		0x01
+#define  UDESC_CONFIG		0x02
+#define  UDESC_STRING		0x03
+#define  UDESC_INTERFACE	0x04
+#define  UDESC_ENDPOINT		0x05
+#define  UDESC_SS_USB_COMPANION	0x30
+#define  UDESC_DEVICE_QUALIFIER	0x06
+#define  UDESC_OTHER_SPEED_CONFIGURATION 0x07
+#define  UDESC_INTERFACE_POWER	0x08
+#define  UDESC_OTG		0x09
+#define  WUDESC_SECURITY	0x0c
+#define  WUDESC_KEY		0x0d
+#define   WUD_GET_KEY_INDEX(_wValue_) ((_wValue_) & 0xf)
+#define   WUD_GET_KEY_TYPE(_wValue_) (((_wValue_) & 0x30) >> 4)
+#define    WUD_KEY_TYPE_ASSOC    0x01
+#define    WUD_KEY_TYPE_GTK      0x02
+#define   WUD_GET_KEY_ORIGIN(_wValue_) (((_wValue_) & 0x40) >> 6)
+#define    WUD_KEY_ORIGIN_HOST   0x00
+#define    WUD_KEY_ORIGIN_DEVICE 0x01
+#define  WUDESC_ENCRYPTION_TYPE	0x0e
+#define  WUDESC_BOS		0x0f
+#define  WUDESC_DEVICE_CAPABILITY 0x10
+#define  WUDESC_WIRELESS_ENDPOINT_COMPANION 0x11
+#define  UDESC_BOS		0x0f
+#define  UDESC_DEVICE_CAPABILITY 0x10
+#define  UDESC_CS_DEVICE	0x21	/* class specific */
+#define  UDESC_CS_CONFIG	0x22
+#define  UDESC_CS_STRING	0x23
+#define  UDESC_CS_INTERFACE	0x24
+#define  UDESC_CS_ENDPOINT	0x25
+#define  UDESC_HUB		0x29
+#define UR_SET_DESCRIPTOR	0x07
+#define UR_GET_CONFIG		0x08
+#define UR_SET_CONFIG		0x09
+#define UR_GET_INTERFACE	0x0a
+#define UR_SET_INTERFACE	0x0b
+#define UR_SYNCH_FRAME		0x0c
+#define WUR_SET_ENCRYPTION      0x0d
+#define WUR_GET_ENCRYPTION	0x0e
+#define WUR_SET_HANDSHAKE	0x0f
+#define WUR_GET_HANDSHAKE	0x10
+#define WUR_SET_CONNECTION	0x11
+#define WUR_SET_SECURITY_DATA	0x12
+#define WUR_GET_SECURITY_DATA	0x13
+#define WUR_SET_WUSB_DATA	0x14
+#define  WUDATA_DRPIE_INFO	0x01
+#define  WUDATA_TRANSMIT_DATA	0x02
+#define  WUDATA_TRANSMIT_PARAMS	0x03
+#define  WUDATA_RECEIVE_PARAMS	0x04
+#define  WUDATA_TRANSMIT_POWER	0x05
+#define WUR_LOOPBACK_DATA_WRITE	0x15
+#define WUR_LOOPBACK_DATA_READ	0x16
+#define WUR_SET_INTERFACE_DS	0x17
+
+/* Feature numbers */
+#define UF_ENDPOINT_HALT	0
+#define UF_DEVICE_REMOTE_WAKEUP	1
+#define UF_TEST_MODE		2
+#define UF_DEVICE_B_HNP_ENABLE	3
+#define UF_DEVICE_A_HNP_SUPPORT	4
+#define UF_DEVICE_A_ALT_HNP_SUPPORT 5
+#define WUF_WUSB		3
+#define  WUF_TX_DRPIE		0x0
+#define  WUF_DEV_XMIT_PACKET	0x1
+#define  WUF_COUNT_PACKETS	0x2
+#define  WUF_CAPTURE_PACKETS	0x3
+#define UF_FUNCTION_SUSPEND	0
+#define UF_U1_ENABLE		48
+#define UF_U2_ENABLE		49
+#define UF_LTM_ENABLE		50
+
+/* Class requests from the USB 2.0 hub spec, table 11-15 */
+#define UCR_CLEAR_HUB_FEATURE		(0x2000 | UR_CLEAR_FEATURE)
+#define UCR_CLEAR_PORT_FEATURE		(0x2300 | UR_CLEAR_FEATURE)
+#define UCR_GET_HUB_DESCRIPTOR		(0xa000 | UR_GET_DESCRIPTOR)
+#define UCR_GET_HUB_STATUS		(0xa000 | UR_GET_STATUS)
+#define UCR_GET_PORT_STATUS		(0xa300 | UR_GET_STATUS)
+#define UCR_SET_HUB_FEATURE		(0x2000 | UR_SET_FEATURE)
+#define UCR_SET_PORT_FEATURE		(0x2300 | UR_SET_FEATURE)
+#define UCR_SET_AND_TEST_PORT_FEATURE	(0xa300 | UR_SET_AND_TEST_FEATURE)
+
+#ifdef _MSC_VER
+#include <pshpack1.h>
+#endif
+
+typedef struct {
+	uByte		bLength;
+	uByte		bDescriptorType;
+	uByte		bDescriptorSubtype;
+} UPACKED usb_descriptor_t;
+
+typedef struct {
+	uByte		bLength;
+	uByte		bDescriptorType;
+} UPACKED usb_descriptor_header_t;
+
+typedef struct {
+	uByte		bLength;
+	uByte		bDescriptorType;
+	uWord		bcdUSB;
+#define UD_USB_2_0		0x0200
+#define UD_IS_USB2(d) (UGETW((d)->bcdUSB) >= UD_USB_2_0)
+	uByte		bDeviceClass;
+	uByte		bDeviceSubClass;
+	uByte		bDeviceProtocol;
+	uByte		bMaxPacketSize;
+	/* The fields below are not part of the initial descriptor. */
+	uWord		idVendor;
+	uWord		idProduct;
+	uWord		bcdDevice;
+	uByte		iManufacturer;
+	uByte		iProduct;
+	uByte		iSerialNumber;
+	uByte		bNumConfigurations;
+} UPACKED usb_device_descriptor_t;
+#define USB_DEVICE_DESCRIPTOR_SIZE 18
+
+typedef struct {
+	uByte		bLength;
+	uByte		bDescriptorType;
+	uWord		wTotalLength;
+	uByte		bNumInterface;
+	uByte		bConfigurationValue;
+	uByte		iConfiguration;
+#define UC_ATT_ONE		(1 << 7)	/* must be set */
+#define UC_ATT_SELFPOWER	(1 << 6)	/* self powered */
+#define UC_ATT_WAKEUP		(1 << 5)	/* can wakeup */
+#define UC_ATT_BATTERY		(1 << 4)	/* battery powered */
+	uByte		bmAttributes;
+#define UC_BUS_POWERED		0x80
+#define UC_SELF_POWERED		0x40
+#define UC_REMOTE_WAKEUP	0x20
+	uByte		bMaxPower; /* max current in 2 mA units */
+#define UC_POWER_FACTOR 2
+} UPACKED usb_config_descriptor_t;
+#define USB_CONFIG_DESCRIPTOR_SIZE 9
+
+typedef struct {
+	uByte		bLength;
+	uByte		bDescriptorType;
+	uByte		bInterfaceNumber;
+	uByte		bAlternateSetting;
+	uByte		bNumEndpoints;
+	uByte		bInterfaceClass;
+	uByte		bInterfaceSubClass;
+	uByte		bInterfaceProtocol;
+	uByte		iInterface;
+} UPACKED usb_interface_descriptor_t;
+#define USB_INTERFACE_DESCRIPTOR_SIZE 9
+
+typedef struct {
+	uByte		bLength;
+	uByte		bDescriptorType;
+	uByte		bEndpointAddress;
+#define UE_GET_DIR(a)	((a) & 0x80)
+#define UE_SET_DIR(a,d)	((a) | (((d)&1) << 7))
+#define UE_DIR_IN	0x80
+#define UE_DIR_OUT	0x00
+#define UE_ADDR		0x0f
+#define UE_GET_ADDR(a)	((a) & UE_ADDR)
+	uByte		bmAttributes;
+#define UE_XFERTYPE	0x03
+#define  UE_CONTROL	0x00
+#define  UE_ISOCHRONOUS	0x01
+#define  UE_BULK	0x02
+#define  UE_INTERRUPT	0x03
+#define UE_GET_XFERTYPE(a)	((a) & UE_XFERTYPE)
+#define UE_ISO_TYPE	0x0c
+#define  UE_ISO_ASYNC	0x04
+#define  UE_ISO_ADAPT	0x08
+#define  UE_ISO_SYNC	0x0c
+#define UE_GET_ISO_TYPE(a)	((a) & UE_ISO_TYPE)
+	uWord		wMaxPacketSize;
+	uByte		bInterval;
+} UPACKED usb_endpoint_descriptor_t;
+#define USB_ENDPOINT_DESCRIPTOR_SIZE 7
+
+typedef struct ss_endpoint_companion_descriptor {
+	uByte bLength;
+	uByte bDescriptorType;
+	uByte bMaxBurst;
+#define USSE_GET_MAX_STREAMS(a)		((a) & 0x1f)
+#define USSE_SET_MAX_STREAMS(a, b)	((a) | ((b) & 0x1f))
+#define USSE_GET_MAX_PACKET_NUM(a)	((a) & 0x03)
+#define USSE_SET_MAX_PACKET_NUM(a, b)	((a) | ((b) & 0x03))
+	uByte bmAttributes;
+	uWord wBytesPerInterval;
+} UPACKED ss_endpoint_companion_descriptor_t;
+#define USB_SS_ENDPOINT_COMPANION_DESCRIPTOR_SIZE 6
+
+typedef struct {
+	uByte		bLength;
+	uByte		bDescriptorType;
+	uWord		bString[127];
+} UPACKED usb_string_descriptor_t;
+#define USB_MAX_STRING_LEN 128
+#define USB_LANGUAGE_TABLE 0	/* # of the string language id table */
+
+/* Hub specific request */
+#define UR_GET_BUS_STATE	0x02
+#define UR_CLEAR_TT_BUFFER	0x08
+#define UR_RESET_TT		0x09
+#define UR_GET_TT_STATE		0x0a
+#define UR_STOP_TT		0x0b
+
+/* Hub features */
+#define UHF_C_HUB_LOCAL_POWER	0
+#define UHF_C_HUB_OVER_CURRENT	1
+#define UHF_PORT_CONNECTION	0
+#define UHF_PORT_ENABLE		1
+#define UHF_PORT_SUSPEND	2
+#define UHF_PORT_OVER_CURRENT	3
+#define UHF_PORT_RESET		4
+#define UHF_PORT_L1		5
+#define UHF_PORT_POWER		8
+#define UHF_PORT_LOW_SPEED	9
+#define UHF_PORT_HIGH_SPEED	10
+#define UHF_C_PORT_CONNECTION	16
+#define UHF_C_PORT_ENABLE	17
+#define UHF_C_PORT_SUSPEND	18
+#define UHF_C_PORT_OVER_CURRENT	19
+#define UHF_C_PORT_RESET	20
+#define UHF_C_PORT_L1		23
+#define UHF_PORT_TEST		21
+#define UHF_PORT_INDICATOR	22
+
+typedef struct {
+	uByte		bDescLength;
+	uByte		bDescriptorType;
+	uByte		bNbrPorts;
+	uWord		wHubCharacteristics;
+#define UHD_PWR			0x0003
+#define  UHD_PWR_GANGED		0x0000
+#define  UHD_PWR_INDIVIDUAL	0x0001
+#define  UHD_PWR_NO_SWITCH	0x0002
+#define UHD_COMPOUND		0x0004
+#define UHD_OC			0x0018
+#define  UHD_OC_GLOBAL		0x0000
+#define  UHD_OC_INDIVIDUAL	0x0008
+#define  UHD_OC_NONE		0x0010
+#define UHD_TT_THINK		0x0060
+#define  UHD_TT_THINK_8		0x0000
+#define  UHD_TT_THINK_16	0x0020
+#define  UHD_TT_THINK_24	0x0040
+#define  UHD_TT_THINK_32	0x0060
+#define UHD_PORT_IND		0x0080
+	uByte		bPwrOn2PwrGood;	/* delay in 2 ms units */
+#define UHD_PWRON_FACTOR 2
+	uByte		bHubContrCurrent;
+	uByte		DeviceRemovable[32]; /* max 255 ports */
+#define UHD_NOT_REMOV(desc, i) \
+    (((desc)->DeviceRemovable[(i)/8] >> ((i) % 8)) & 1)
+	/* deprecated */ uByte		PortPowerCtrlMask[1];
+} UPACKED usb_hub_descriptor_t;
+#define USB_HUB_DESCRIPTOR_SIZE 9 /* includes deprecated PortPowerCtrlMask */
+
+typedef struct {
+	uByte		bLength;
+	uByte		bDescriptorType;
+	uWord		bcdUSB;
+	uByte		bDeviceClass;
+	uByte		bDeviceSubClass;
+	uByte		bDeviceProtocol;
+	uByte		bMaxPacketSize0;
+	uByte		bNumConfigurations;
+	uByte		bReserved;
+} UPACKED usb_device_qualifier_t;
+#define USB_DEVICE_QUALIFIER_SIZE 10
+
+typedef struct {
+	uByte		bLength;
+	uByte		bDescriptorType;
+	uByte		bmAttributes;
+#define UOTG_SRP	0x01
+#define UOTG_HNP	0x02
+} UPACKED usb_otg_descriptor_t;
+
+/* OTG feature selectors */
+#define UOTG_B_HNP_ENABLE	3
+#define UOTG_A_HNP_SUPPORT	4
+#define UOTG_A_ALT_HNP_SUPPORT	5
+
+typedef struct {
+	uWord		wStatus;
+/* Device status flags */
+#define UDS_SELF_POWERED		0x0001
+#define UDS_REMOTE_WAKEUP		0x0002
+/* Endpoint status flags */
+#define UES_HALT			0x0001
+} UPACKED usb_status_t;
+
+typedef struct {
+	uWord		wHubStatus;
+#define UHS_LOCAL_POWER			0x0001
+#define UHS_OVER_CURRENT		0x0002
+	uWord		wHubChange;
+} UPACKED usb_hub_status_t;
+
+typedef struct {
+	uWord		wPortStatus;
+#define UPS_CURRENT_CONNECT_STATUS	0x0001
+#define UPS_PORT_ENABLED		0x0002
+#define UPS_SUSPEND			0x0004
+#define UPS_OVERCURRENT_INDICATOR	0x0008
+#define UPS_RESET			0x0010
+#define UPS_PORT_POWER			0x0100
+#define UPS_LOW_SPEED			0x0200
+#define UPS_HIGH_SPEED			0x0400
+#define UPS_PORT_TEST			0x0800
+#define UPS_PORT_INDICATOR		0x1000
+	uWord		wPortChange;
+#define UPS_C_CONNECT_STATUS		0x0001
+#define UPS_C_PORT_ENABLED		0x0002
+#define UPS_C_SUSPEND			0x0004
+#define UPS_C_OVERCURRENT_INDICATOR	0x0008
+#define UPS_C_PORT_RESET		0x0010
+} UPACKED usb_port_status_t;
+
+#ifdef _MSC_VER
+#include <poppack.h>
+#endif
+
+/* Device class codes */
+#define UDCLASS_IN_INTERFACE	0x00
+#define UDCLASS_COMM		0x02
+#define UDCLASS_HUB		0x09
+#define  UDSUBCLASS_HUB		0x00
+#define  UDPROTO_FSHUB		0x00
+#define  UDPROTO_HSHUBSTT	0x01
+#define  UDPROTO_HSHUBMTT	0x02
+#define UDCLASS_DIAGNOSTIC	0xdc
+#define UDCLASS_WIRELESS	0xe0
+#define  UDSUBCLASS_RF		0x01
+#define   UDPROTO_BLUETOOTH	0x01
+#define UDCLASS_VENDOR		0xff
+
+/* Interface class codes */
+#define UICLASS_UNSPEC		0x00
+
+#define UICLASS_AUDIO		0x01
+#define  UISUBCLASS_AUDIOCONTROL	1
+#define  UISUBCLASS_AUDIOSTREAM		2
+#define  UISUBCLASS_MIDISTREAM		3
+
+#define UICLASS_CDC		0x02 /* communication */
+#define  UISUBCLASS_DIRECT_LINE_CONTROL_MODEL	1
+#define  UISUBCLASS_ABSTRACT_CONTROL_MODEL	2
+#define  UISUBCLASS_TELEPHONE_CONTROL_MODEL	3
+#define  UISUBCLASS_MULTICHANNEL_CONTROL_MODEL	4
+#define  UISUBCLASS_CAPI_CONTROLMODEL		5
+#define  UISUBCLASS_ETHERNET_NETWORKING_CONTROL_MODEL 6
+#define  UISUBCLASS_ATM_NETWORKING_CONTROL_MODEL 7
+#define   UIPROTO_CDC_AT			1
+
+#define UICLASS_HID		0x03
+#define  UISUBCLASS_BOOT	1
+#define  UIPROTO_BOOT_KEYBOARD	1
+
+#define UICLASS_PHYSICAL	0x05
+
+#define UICLASS_IMAGE		0x06
+
+#define UICLASS_PRINTER		0x07
+#define  UISUBCLASS_PRINTER	1
+#define  UIPROTO_PRINTER_UNI	1
+#define  UIPROTO_PRINTER_BI	2
+#define  UIPROTO_PRINTER_1284	3
+
+#define UICLASS_MASS		0x08
+#define  UISUBCLASS_RBC		1
+#define  UISUBCLASS_SFF8020I	2
+#define  UISUBCLASS_QIC157	3
+#define  UISUBCLASS_UFI		4
+#define  UISUBCLASS_SFF8070I	5
+#define  UISUBCLASS_SCSI	6
+#define  UIPROTO_MASS_CBI_I	0
+#define  UIPROTO_MASS_CBI	1
+#define  UIPROTO_MASS_BBB_OLD	2	/* Not in the spec anymore */
+#define  UIPROTO_MASS_BBB	80	/* 'P' for the Iomega Zip drive */
+
+#define UICLASS_HUB		0x09
+#define  UISUBCLASS_HUB		0
+#define  UIPROTO_FSHUB		0
+#define  UIPROTO_HSHUBSTT	0 /* Yes, same as previous */
+#define  UIPROTO_HSHUBMTT	1
+
+#define UICLASS_CDC_DATA	0x0a
+#define  UISUBCLASS_DATA		0
+#define   UIPROTO_DATA_ISDNBRI		0x30    /* Physical iface */
+#define   UIPROTO_DATA_HDLC		0x31    /* HDLC */
+#define   UIPROTO_DATA_TRANSPARENT	0x32    /* Transparent */
+#define   UIPROTO_DATA_Q921M		0x50    /* Management for Q921 */
+#define   UIPROTO_DATA_Q921		0x51    /* Data for Q921 */
+#define   UIPROTO_DATA_Q921TM		0x52    /* TEI multiplexer for Q921 */
+#define   UIPROTO_DATA_V42BIS		0x90    /* Data compression */
+#define   UIPROTO_DATA_Q931		0x91    /* Euro-ISDN */
+#define   UIPROTO_DATA_V120		0x92    /* V.24 rate adaption */
+#define   UIPROTO_DATA_CAPI		0x93    /* CAPI 2.0 commands */
+#define   UIPROTO_DATA_HOST_BASED	0xfd    /* Host based driver */
+#define   UIPROTO_DATA_PUF		0xfe    /* see Prot. Unit Func. Desc.*/
+#define   UIPROTO_DATA_VENDOR		0xff    /* Vendor specific */
+
+#define UICLASS_SMARTCARD	0x0b
+
+/*#define UICLASS_FIRM_UPD	0x0c*/
+
+#define UICLASS_SECURITY	0x0d
+
+#define UICLASS_DIAGNOSTIC	0xdc
+
+#define UICLASS_WIRELESS	0xe0
+#define  UISUBCLASS_RF			0x01
+#define   UIPROTO_BLUETOOTH		0x01
+
+#define UICLASS_APPL_SPEC	0xfe
+#define  UISUBCLASS_FIRMWARE_DOWNLOAD	1
+#define  UISUBCLASS_IRDA		2
+#define  UIPROTO_IRDA			0
+
+#define UICLASS_VENDOR		0xff
+
+#define USB_HUB_MAX_DEPTH 5
+
+/*
+ * Minimum time a device needs to be powered down to go through
+ * a power cycle.  XXX Are these time in the spec?
+ */
+#define USB_POWER_DOWN_TIME	200 /* ms */
+#define USB_PORT_POWER_DOWN_TIME	100 /* ms */
+
+/* Allow for marginal (i.e. non-conforming) devices. */
+#define USB_PORT_RESET_DELAY	50  /* ms */
+#define USB_PORT_ROOT_RESET_DELAY 250  /* ms */
+#define USB_PORT_RESET_RECOVERY	250  /* ms */
+#define USB_PORT_POWERUP_DELAY	300 /* ms */
+#define USB_SET_ADDRESS_SETTLE	10  /* ms */
+#define USB_RESUME_DELAY	(50*5)  /* ms */
+#define USB_RESUME_WAIT		50  /* ms */
+#define USB_RESUME_RECOVERY	50  /* ms */
+#define USB_EXTRA_POWER_UP_TIME	20  /* ms */
+
+#define USB_MIN_POWER		100 /* mA */
+#define USB_MAX_POWER		500 /* mA */
+
+#define USB_BUS_RESET_DELAY	100 /* ms XXX?*/
+
+#define USB_UNCONFIG_NO 0
+#define USB_UNCONFIG_INDEX (-1)
+
+/*** ioctl() related stuff ***/
+
+struct usb_ctl_request {
+	int	ucr_addr;
+	usb_device_request_t ucr_request;
+	void	*ucr_data;
+	int	ucr_flags;
+#define USBD_SHORT_XFER_OK	0x04	/* allow short reads */
+	int	ucr_actlen;		/* actual length transferred */
+};
+
+struct usb_alt_interface {
+	int	uai_config_index;
+	int	uai_interface_index;
+	int	uai_alt_no;
+};
+
+#define USB_CURRENT_CONFIG_INDEX (-1)
+#define USB_CURRENT_ALT_INDEX (-1)
+
+struct usb_config_desc {
+	int	ucd_config_index;
+	usb_config_descriptor_t ucd_desc;
+};
+
+struct usb_interface_desc {
+	int	uid_config_index;
+	int	uid_interface_index;
+	int	uid_alt_index;
+	usb_interface_descriptor_t uid_desc;
+};
+
+struct usb_endpoint_desc {
+	int	ued_config_index;
+	int	ued_interface_index;
+	int	ued_alt_index;
+	int	ued_endpoint_index;
+	usb_endpoint_descriptor_t ued_desc;
+};
+
+struct usb_full_desc {
+	int	ufd_config_index;
+	u_int	ufd_size;
+	u_char	*ufd_data;
+};
+
+struct usb_string_desc {
+	int	usd_string_index;
+	int	usd_language_id;
+	usb_string_descriptor_t usd_desc;
+};
+
+struct usb_ctl_report_desc {
+	int	ucrd_size;
+	u_char	ucrd_data[1024];	/* filled data size will vary */
+};
+
+typedef struct { u_int32_t cookie; } usb_event_cookie_t;
+
+#define USB_MAX_DEVNAMES 4
+#define USB_MAX_DEVNAMELEN 16
+struct usb_device_info {
+	u_int8_t	udi_bus;
+	u_int8_t	udi_addr;	/* device address */
+	usb_event_cookie_t udi_cookie;
+	char		udi_product[USB_MAX_STRING_LEN];
+	char		udi_vendor[USB_MAX_STRING_LEN];
+	char		udi_release[8];
+	u_int16_t	udi_productNo;
+	u_int16_t	udi_vendorNo;
+	u_int16_t	udi_releaseNo;
+	u_int8_t	udi_class;
+	u_int8_t	udi_subclass;
+	u_int8_t	udi_protocol;
+	u_int8_t	udi_config;
+	u_int8_t	udi_speed;
+#define USB_SPEED_UNKNOWN	0
+#define USB_SPEED_LOW		1
+#define USB_SPEED_FULL		2
+#define USB_SPEED_HIGH		3
+#define USB_SPEED_VARIABLE	4
+#define USB_SPEED_SUPER		5
+	int		udi_power;	/* power consumption in mA, 0 if selfpowered */
+	int		udi_nports;
+	char		udi_devnames[USB_MAX_DEVNAMES][USB_MAX_DEVNAMELEN];
+	u_int8_t	udi_ports[16];/* hub only: addresses of devices on ports */
+#define USB_PORT_ENABLED 0xff
+#define USB_PORT_SUSPENDED 0xfe
+#define USB_PORT_POWERED 0xfd
+#define USB_PORT_DISABLED 0xfc
+};
+
+struct usb_ctl_report {
+	int	ucr_report;
+	u_char	ucr_data[1024];	/* filled data size will vary */
+};
+
+struct usb_device_stats {
+	u_long	uds_requests[4];	/* indexed by transfer type UE_* */
+};
+
+#define WUSB_MIN_IE			0x80
+#define WUSB_WCTA_IE			0x80
+#define WUSB_WCONNECTACK_IE		0x81
+#define WUSB_WHOSTINFO_IE		0x82
+#define  WUHI_GET_CA(_bmAttributes_) ((_bmAttributes_) & 0x3)
+#define   WUHI_CA_RECONN		0x00
+#define   WUHI_CA_LIMITED		0x01
+#define   WUHI_CA_ALL			0x03
+#define  WUHI_GET_MLSI(_bmAttributes_) (((_bmAttributes_) & 0x38) >> 3)
+#define WUSB_WCHCHANGEANNOUNCE_IE	0x83
+#define WUSB_WDEV_DISCONNECT_IE		0x84
+#define WUSB_WHOST_DISCONNECT_IE	0x85
+#define WUSB_WRELEASE_CHANNEL_IE	0x86
+#define WUSB_WWORK_IE			0x87
+#define WUSB_WCHANNEL_STOP_IE		0x88
+#define WUSB_WDEV_KEEPALIVE_IE		0x89
+#define WUSB_WISOCH_DISCARD_IE		0x8A
+#define WUSB_WRESETDEVICE_IE		0x8B
+#define WUSB_WXMIT_PACKET_ADJUST_IE	0x8C
+#define WUSB_MAX_IE			0x8C
+
+/* Device Notification Types */
+
+#define WUSB_DN_MIN			0x01
+#define WUSB_DN_CONNECT			0x01
+# define WUSB_DA_OLDCONN	0x00
+# define WUSB_DA_NEWCONN	0x01
+# define WUSB_DA_SELF_BEACON	0x02
+# define WUSB_DA_DIR_BEACON	0x04
+# define WUSB_DA_NO_BEACON	0x06
+#define WUSB_DN_DISCONNECT		0x02
+#define WUSB_DN_EPRDY			0x03
+#define WUSB_DN_MASAVAILCHANGED		0x04
+#define WUSB_DN_REMOTEWAKEUP		0x05
+#define WUSB_DN_SLEEP			0x06
+#define WUSB_DN_ALIVE			0x07
+#define WUSB_DN_MAX			0x07
+
+#ifdef _MSC_VER
+#include <pshpack1.h>
+#endif
+
+/* WUSB Handshake Data.  Used during the SET/GET HANDSHAKE requests */
+typedef struct wusb_hndshk_data {
+	uByte bMessageNumber;
+	uByte bStatus;
+	uByte tTKID[3];
+	uByte bReserved;
+	uByte CDID[16];
+	uByte Nonce[16];
+	uByte MIC[8];
+} UPACKED wusb_hndshk_data_t;
+#define WUSB_HANDSHAKE_LEN_FOR_MIC	38
+
+/* WUSB Connection Context */
+typedef struct wusb_conn_context {
+	uByte CHID [16];
+	uByte CDID [16];
+	uByte CK [16];
+} UPACKED wusb_conn_context_t;
+
+/* WUSB Security Descriptor */
+typedef struct wusb_security_desc {
+	uByte bLength;
+	uByte bDescriptorType;
+	uWord wTotalLength;
+	uByte bNumEncryptionTypes;
+} UPACKED wusb_security_desc_t;
+
+/* WUSB Encryption Type Descriptor */
+typedef struct wusb_encrypt_type_desc {
+	uByte bLength;
+	uByte bDescriptorType;
+
+	uByte bEncryptionType;
+#define WUETD_UNSECURE		0
+#define WUETD_WIRED		1
+#define WUETD_CCM_1		2
+#define WUETD_RSA_1		3
+
+	uByte bEncryptionValue;
+	uByte bAuthKeyIndex;
+} UPACKED wusb_encrypt_type_desc_t;
+
+/* WUSB Key Descriptor */
+typedef struct wusb_key_desc {
+	uByte bLength;
+	uByte bDescriptorType;
+	uByte tTKID[3];
+	uByte bReserved;
+	uByte KeyData[1];	/* variable length */
+} UPACKED wusb_key_desc_t;
+
+/* WUSB BOS Descriptor (Binary device Object Store) */
+typedef struct wusb_bos_desc {
+	uByte bLength;
+	uByte bDescriptorType;
+	uWord wTotalLength;
+	uByte bNumDeviceCaps;
+} UPACKED wusb_bos_desc_t;
+
+#define USB_DEVICE_CAPABILITY_20_EXTENSION	0x02
+typedef struct usb_dev_cap_20_ext_desc {
+	uByte bLength;
+	uByte bDescriptorType;
+	uByte bDevCapabilityType;
+#define USB_20_EXT_LPM				0x02
+	uDWord bmAttributes;
+} UPACKED usb_dev_cap_20_ext_desc_t;
+
+#define USB_DEVICE_CAPABILITY_SS_USB		0x03
+typedef struct usb_dev_cap_ss_usb {
+	uByte bLength;
+	uByte bDescriptorType;
+	uByte bDevCapabilityType;
+#define USB_DC_SS_USB_LTM_CAPABLE		0x02
+	uByte bmAttributes;
+#define USB_DC_SS_USB_SPEED_SUPPORT_LOW		0x01
+#define USB_DC_SS_USB_SPEED_SUPPORT_FULL	0x02
+#define USB_DC_SS_USB_SPEED_SUPPORT_HIGH	0x04
+#define USB_DC_SS_USB_SPEED_SUPPORT_SS		0x08
+	uWord wSpeedsSupported;
+	uByte bFunctionalitySupport;
+	uByte bU1DevExitLat;
+	uWord wU2DevExitLat;
+} UPACKED usb_dev_cap_ss_usb_t;
+
+#define USB_DEVICE_CAPABILITY_CONTAINER_ID	0x04
+typedef struct usb_dev_cap_container_id {
+	uByte bLength;
+	uByte bDescriptorType;
+	uByte bDevCapabilityType;
+	uByte bReserved;
+	uByte containerID[16];
+} UPACKED usb_dev_cap_container_id_t;
+
+/* Device Capability Type Codes */
+#define WUSB_DEVICE_CAPABILITY_WIRELESS_USB 0x01
+
+/* Device Capability Descriptor */
+typedef struct wusb_dev_cap_desc {
+	uByte bLength;
+	uByte bDescriptorType;
+	uByte bDevCapabilityType;
+	uByte caps[1];	/* Variable length */
+} UPACKED wusb_dev_cap_desc_t;
+
+/* Device Capability Descriptor */
+typedef struct wusb_dev_cap_uwb_desc {
+	uByte bLength;
+	uByte bDescriptorType;
+	uByte bDevCapabilityType;
+	uByte bmAttributes;
+	uWord wPHYRates;	/* Bitmap */
+	uByte bmTFITXPowerInfo;
+	uByte bmFFITXPowerInfo;
+	uWord bmBandGroup;
+	uByte bReserved;
+} UPACKED wusb_dev_cap_uwb_desc_t;
+
+/* Wireless USB Endpoint Companion Descriptor */
+typedef struct wusb_endpoint_companion_desc {
+	uByte bLength;
+	uByte bDescriptorType;
+	uByte bMaxBurst;
+	uByte bMaxSequence;
+	uWord wMaxStreamDelay;
+	uWord wOverTheAirPacketSize;
+	uByte bOverTheAirInterval;
+	uByte bmCompAttributes;
+} UPACKED wusb_endpoint_companion_desc_t;
+
+/* Wireless USB Numeric Association M1 Data Structure */
+typedef struct wusb_m1_data {
+	uByte version;
+	uWord langId;
+	uByte deviceFriendlyNameLength;
+	uByte sha_256_m3[32];
+	uByte deviceFriendlyName[256];
+} UPACKED wusb_m1_data_t;
+
+typedef struct wusb_m2_data {
+	uByte version;
+	uWord langId;
+	uByte hostFriendlyNameLength;
+	uByte pkh[384];
+	uByte hostFriendlyName[256];
+} UPACKED wusb_m2_data_t;
+
+typedef struct wusb_m3_data {
+	uByte pkd[384];
+	uByte nd;
+} UPACKED wusb_m3_data_t;
+
+typedef struct wusb_m4_data {
+	uDWord _attributeTypeIdAndLength_1;
+	uWord  associationTypeId;
+
+	uDWord _attributeTypeIdAndLength_2;
+	uWord  associationSubTypeId;
+
+	uDWord _attributeTypeIdAndLength_3;
+	uDWord length;
+
+	uDWord _attributeTypeIdAndLength_4;
+	uDWord associationStatus;
+
+	uDWord _attributeTypeIdAndLength_5;
+	uByte  chid[16];
+
+	uDWord _attributeTypeIdAndLength_6;
+	uByte  cdid[16];
+
+	uDWord _attributeTypeIdAndLength_7;
+	uByte  bandGroups[2];
+} UPACKED wusb_m4_data_t;
+
+#ifdef _MSC_VER
+#include <poppack.h>
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _USB_H_ */
diff --git a/fs/Kconfig b/fs/Kconfig
index 4bd03a2..9b0955c 100644
--- a/fs/Kconfig
+++ b/fs/Kconfig
@@ -232,6 +232,7 @@ source "fs/hfsplus/Kconfig"
 source "fs/befs/Kconfig"
 source "fs/bfs/Kconfig"
 source "fs/efs/Kconfig"
+source "fs/yaffs2/Kconfig"
 source "fs/jffs2/Kconfig"
 # UBIFS File system configuration
 source "fs/ubifs/Kconfig"
diff --git a/fs/Makefile b/fs/Makefile
index ed2b632..c255772 100644
--- a/fs/Makefile
+++ b/fs/Makefile
@@ -129,3 +129,4 @@ obj-y				+= exofs/ # Multiple modules
 obj-$(CONFIG_CEPH_FS)		+= ceph/
 obj-$(CONFIG_PSTORE)		+= pstore/
 obj-$(CONFIG_EFIVAR_FS)		+= efivarfs/
+obj-$(CONFIG_YAFFS_FS)		+= yaffs2/
diff --git a/fs/xfs/xfs_buf.c b/fs/xfs/xfs_buf.c
index 1626927..24940dd 100644
--- a/fs/xfs/xfs_buf.c
+++ b/fs/xfs/xfs_buf.c
@@ -116,7 +116,7 @@ static inline void
 __xfs_buf_ioacct_dec(
 	struct xfs_buf	*bp)
 {
-	ASSERT(spin_is_locked(&bp->b_lock));
+	lockdep_assert_held(&bp->b_lock);
 
 	if (bp->b_state & XFS_BSTATE_IN_FLIGHT) {
 		bp->b_state &= ~XFS_BSTATE_IN_FLIGHT;
diff --git a/fs/xfs/xfs_icache.c b/fs/xfs/xfs_icache.c
index 74304b6..e279882 100644
--- a/fs/xfs/xfs_icache.c
+++ b/fs/xfs/xfs_icache.c
@@ -66,7 +66,6 @@ xfs_inode_alloc(
 
 	XFS_STATS_INC(mp, vn_active);
 	ASSERT(atomic_read(&ip->i_pincount) == 0);
-	ASSERT(!spin_is_locked(&ip->i_flags_lock));
 	ASSERT(!xfs_isiflocked(ip));
 	ASSERT(ip->i_ino == 0);
 
@@ -192,7 +191,7 @@ xfs_perag_set_reclaim_tag(
 {
 	struct xfs_mount	*mp = pag->pag_mount;
 
-	ASSERT(spin_is_locked(&pag->pag_ici_lock));
+	lockdep_assert_held(&pag->pag_ici_lock);
 	if (pag->pag_ici_reclaimable++)
 		return;
 
@@ -214,7 +213,7 @@ xfs_perag_clear_reclaim_tag(
 {
 	struct xfs_mount	*mp = pag->pag_mount;
 
-	ASSERT(spin_is_locked(&pag->pag_ici_lock));
+	lockdep_assert_held(&pag->pag_ici_lock);
 	if (--pag->pag_ici_reclaimable)
 		return;
 
diff --git a/fs/yaffs2/Kconfig b/fs/yaffs2/Kconfig
new file mode 100644
index 0000000..408570f
--- /dev/null
+++ b/fs/yaffs2/Kconfig
@@ -0,0 +1,171 @@
+#
+# yaffs file system configurations
+#
+
+config YAFFS_FS
+	tristate "yaffs2 file system support"
+	default n
+	depends on MTD_BLOCK
+	select YAFFS_YAFFS1
+	select YAFFS_YAFFS2
+	help
+	  yaffs2, or Yet Another Flash File System, is a file system
+	  optimised for NAND Flash chips.
+
+	  To compile the yaffs2 file system support as a module, choose M
+	  here: the module will be called yaffs2.
+
+	  If unsure, say N.
+
+	  Further information on yaffs2 is available at
+	  <http://www.aleph1.co.uk/yaffs/>.
+
+config YAFFS_YAFFS1
+	bool "512 byte / page devices"
+	depends on YAFFS_FS
+	default y
+	help
+	  Enable yaffs1 support -- yaffs for 512 byte / page devices
+
+	  Not needed for 2K-page devices.
+
+	  If unsure, say Y.
+
+config YAFFS_9BYTE_TAGS
+	bool "Use older-style on-NAND data format with pageStatus byte"
+	depends on YAFFS_YAFFS1
+	default n
+	help
+
+	  Older-style on-NAND data format has a "pageStatus" byte to record
+	  chunk/page state.  This byte is zero when the page is discarded.
+	  Choose this option if you have existing on-NAND data using this
+	  format that you need to continue to support.  New data written
+	  also uses the older-style format.  Note: Use of this option
+	  generally requires that MTD's oob layout be adjusted to use the
+	  older-style format.  See notes on tags formats and MTD versions
+	  in yaffs_mtdif1.c.
+
+	  If unsure, say N.
+
+config YAFFS_DOES_ECC
+	bool "Lets yaffs do its own ECC"
+	depends on YAFFS_FS && YAFFS_YAFFS1 && !YAFFS_9BYTE_TAGS
+	default n
+	help
+	  This enables yaffs to use its own ECC functions instead of using
+	  the ones from the generic MTD-NAND driver.
+
+	  If unsure, say N.
+
+config YAFFS_ECC_WRONG_ORDER
+	bool "Use the same ecc byte order as Steven Hill's nand_ecc.c"
+	depends on YAFFS_FS && YAFFS_DOES_ECC && !YAFFS_9BYTE_TAGS
+	default n
+	help
+	  This makes yaffs_ecc.c use the same ecc byte order as Steven
+	  Hill's nand_ecc.c. If not set, then you get the same ecc byte
+	  order as SmartMedia.
+
+	  If unsure, say N.
+
+config YAFFS_YAFFS2
+	bool "2048 byte (or larger) / page devices"
+	depends on YAFFS_FS
+	default y
+	help
+	  Enable yaffs2 support -- yaffs for >= 2K bytes per page devices
+
+	  If unsure, say Y.
+
+config YAFFS_AUTO_YAFFS2
+	bool "Autoselect yaffs2 format"
+	depends on YAFFS_YAFFS2
+	default y
+	help
+	  Without this, you need to explicitely use yaffs2 as the file
+	  system type. With this, you can say "yaffs" and yaffs or yaffs2
+	  will be used depending on the device page size (yaffs on
+	  512-byte page devices, yaffs2 on 2K page devices).
+
+	  If unsure, say Y.
+
+config YAFFS_DISABLE_TAGS_ECC
+	bool "Disable yaffs from doing ECC on tags by default"
+	depends on YAFFS_FS && YAFFS_YAFFS2
+	default n
+	help
+	  This defaults yaffs to using its own ECC calculations on tags instead of
+	  just relying on the MTD.
+	  This behavior can also be overridden with tags_ecc_on and
+	  tags_ecc_off mount options.
+
+	  If unsure, say N.
+
+config YAFFS_ALWAYS_CHECK_CHUNK_ERASED
+	bool "Force chunk erase check"
+	depends on YAFFS_FS
+	default n
+	help
+          Normally yaffs only checks chunks before writing until an erased
+	  chunk is found. This helps to detect any partially written
+	  chunks that might have happened due to power loss.
+
+	  Enabling this forces on the test that chunks are erased in flash
+	  before writing to them. This takes more time but is potentially
+	  a bit more secure.
+
+	  Suggest setting Y during development and ironing out driver
+	  issues etc. Suggest setting to N if you want faster writing.
+
+	  If unsure, say Y.
+
+config YAFFS_EMPTY_LOST_AND_FOUND
+	bool "Empty lost and found on boot"
+	depends on YAFFS_FS
+	default n
+	help
+	  If this is enabled then the contents of lost and found is
+	  automatically dumped at mount.
+
+	  If unsure, say N.
+
+config YAFFS_DISABLE_BLOCK_REFRESHING
+	bool "Disable yaffs2 block refreshing"
+	depends on YAFFS_FS
+	default n
+	help
+	 If this is set, then block refreshing is disabled.
+	 Block refreshing infrequently refreshes the oldest block in
+	 a yaffs2 file system. This mechanism helps to refresh flash to
+	 mitigate against data loss. This is particularly useful for MLC.
+
+	  If unsure, say N.
+
+config YAFFS_DISABLE_BACKGROUND
+	bool "Disable yaffs2 background processing"
+	depends on YAFFS_FS
+	default n
+	help
+	 If this is set, then background processing is disabled.
+	 Background processing makes many foreground activities faster.
+
+	 If unsure, say N.
+
+config YAFFS_DISABLE_BAD_BLOCK_MARKING
+	bool "Disable yaffs2 bad block marking"
+	depends on YAFFS_FS
+	default n
+	help
+	 Useful during early flash bring up to prevent problems causing
+	 lots of bad block marking.
+
+	 If unsure, say N.
+
+config YAFFS_XATTR
+	bool "Enable yaffs2 xattr support"
+	depends on YAFFS_FS
+	default y
+	help
+	 If this is set then yaffs2 will provide xattr support.
+	 If unsure, say Y.
diff --git a/fs/yaffs2/Makefile b/fs/yaffs2/Makefile
new file mode 100644
index 0000000..c052395
--- /dev/null
+++ b/fs/yaffs2/Makefile
@@ -0,0 +1,19 @@
+#
+# Makefile for the linux YAFFS filesystem routines.
+#
+
+obj-$(CONFIG_YAFFS_FS) += yaffs.o
+
+yaffs-y := yaffs_ecc.o yaffs_vfs.o yaffs_guts.o yaffs_checkptrw.o
+yaffs-y += yaffs_packedtags1.o yaffs_packedtags2.o yaffs_nand.o
+yaffs-y += yaffs_tagscompat.o yaffs_tagsmarshall.o
+yaffs-y += yaffs_endian.o
+yaffs-y += yaffs_mtdif.o
+yaffs-y += yaffs_nameval.o yaffs_attribs.o
+yaffs-y += yaffs_allocator.o
+yaffs-y += yaffs_yaffs1.o
+yaffs-y += yaffs_yaffs2.o
+yaffs-y += yaffs_bitmap.o
+yaffs-y += yaffs_summary.o
+yaffs-y += yaffs_verify.o
+
diff --git a/fs/yaffs2/yaffs_allocator.c b/fs/yaffs2/yaffs_allocator.c
new file mode 100644
index 0000000..c8f2861
--- /dev/null
+++ b/fs/yaffs2/yaffs_allocator.c
@@ -0,0 +1,357 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include "yaffs_allocator.h"
+#include "yaffs_guts.h"
+#include "yaffs_trace.h"
+#include "yportenv.h"
+
+/*
+ * Each entry in yaffs_tnode_list and yaffs_obj_list hold blocks
+ * of approx 100 objects that are themn allocated singly.
+ * This is basically a simplified slab allocator.
+ *
+ * We don't use the Linux slab allocator because slab does not allow
+ * us to dump all the objects in one hit when we do a umount and tear
+ * down  all the tnodes and objects. slab requires that we first free
+ * the individual objects.
+ *
+ * Once yaffs has been mainlined I shall try to motivate for a change
+ * to slab to provide the extra features we need here.
+ */
+
+struct yaffs_tnode_list {
+	struct yaffs_tnode_list *next;
+	struct yaffs_tnode *tnodes;
+};
+
+struct yaffs_obj_list {
+	struct yaffs_obj_list *next;
+	struct yaffs_obj *objects;
+};
+
+struct yaffs_allocator {
+	int n_tnodes_created;
+	struct yaffs_tnode *free_tnodes;
+	int n_free_tnodes;
+	struct yaffs_tnode_list *alloc_tnode_list;
+
+	int n_obj_created;
+	struct list_head free_objs;
+	int n_free_objects;
+
+	struct yaffs_obj_list *allocated_obj_list;
+};
+
+static void yaffs_deinit_raw_tnodes(struct yaffs_dev *dev)
+{
+	struct yaffs_allocator *allocator =
+	    (struct yaffs_allocator *)dev->allocator;
+	struct yaffs_tnode_list *tmp;
+
+	if (!allocator) {
+		BUG();
+		return;
+	}
+
+	while (allocator->alloc_tnode_list) {
+		tmp = allocator->alloc_tnode_list->next;
+
+		kfree(allocator->alloc_tnode_list->tnodes);
+		kfree(allocator->alloc_tnode_list);
+		allocator->alloc_tnode_list = tmp;
+	}
+
+	allocator->free_tnodes = NULL;
+	allocator->n_free_tnodes = 0;
+	allocator->n_tnodes_created = 0;
+}
+
+static void yaffs_init_raw_tnodes(struct yaffs_dev *dev)
+{
+	struct yaffs_allocator *allocator = dev->allocator;
+
+	if (!allocator) {
+		BUG();
+		return;
+	}
+
+	allocator->alloc_tnode_list = NULL;
+	allocator->free_tnodes = NULL;
+	allocator->n_free_tnodes = 0;
+	allocator->n_tnodes_created = 0;
+}
+
+static int yaffs_create_tnodes(struct yaffs_dev *dev, int n_tnodes)
+{
+	struct yaffs_allocator *allocator =
+	    (struct yaffs_allocator *)dev->allocator;
+	int i;
+	struct yaffs_tnode *new_tnodes;
+	u8 *mem;
+	struct yaffs_tnode *curr;
+	struct yaffs_tnode *next;
+	struct yaffs_tnode_list *tnl;
+
+	if (!allocator) {
+		BUG();
+		return YAFFS_FAIL;
+	}
+
+	if (n_tnodes < 1)
+		return YAFFS_OK;
+
+	/* make these things */
+	new_tnodes = kmalloc(n_tnodes * dev->tnode_size, GFP_NOFS);
+	mem = (u8 *) new_tnodes;
+
+	if (!new_tnodes) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"yaffs: Could not allocate Tnodes");
+		return YAFFS_FAIL;
+	}
+
+	/* New hookup for wide tnodes */
+	for (i = 0; i < n_tnodes - 1; i++) {
+		curr = (struct yaffs_tnode *)&mem[i * dev->tnode_size];
+		next = (struct yaffs_tnode *)&mem[(i + 1) * dev->tnode_size];
+		curr->internal[0] = next;
+	}
+
+	curr = (struct yaffs_tnode *)&mem[(n_tnodes - 1) * dev->tnode_size];
+	curr->internal[0] = allocator->free_tnodes;
+	allocator->free_tnodes = (struct yaffs_tnode *)mem;
+
+	allocator->n_free_tnodes += n_tnodes;
+	allocator->n_tnodes_created += n_tnodes;
+
+	/* Now add this bunch of tnodes to a list for freeing up.
+	 * NB If we can't add this to the management list it isn't fatal
+	 * but it just means we can't free this bunch of tnodes later.
+	 */
+	tnl = kmalloc(sizeof(struct yaffs_tnode_list), GFP_NOFS);
+	if (!tnl) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"Could not add tnodes to management list");
+		return YAFFS_FAIL;
+	} else {
+		tnl->tnodes = new_tnodes;
+		tnl->next = allocator->alloc_tnode_list;
+		allocator->alloc_tnode_list = tnl;
+	}
+
+	yaffs_trace(YAFFS_TRACE_ALLOCATE, "Tnodes added");
+
+	return YAFFS_OK;
+}
+
+struct yaffs_tnode *yaffs_alloc_raw_tnode(struct yaffs_dev *dev)
+{
+	struct yaffs_allocator *allocator =
+	    (struct yaffs_allocator *)dev->allocator;
+	struct yaffs_tnode *tn = NULL;
+
+	if (!allocator) {
+		BUG();
+		return NULL;
+	}
+
+	/* If there are none left make more */
+	if (!allocator->free_tnodes)
+		yaffs_create_tnodes(dev, YAFFS_ALLOCATION_NTNODES);
+
+	if (allocator->free_tnodes) {
+		tn = allocator->free_tnodes;
+		allocator->free_tnodes = allocator->free_tnodes->internal[0];
+		allocator->n_free_tnodes--;
+	}
+
+	return tn;
+}
+
+/* FreeTnode frees up a tnode and puts it back on the free list */
+void yaffs_free_raw_tnode(struct yaffs_dev *dev, struct yaffs_tnode *tn)
+{
+	struct yaffs_allocator *allocator = dev->allocator;
+
+	if (!allocator) {
+		BUG();
+		return;
+	}
+
+	if (tn) {
+		tn->internal[0] = allocator->free_tnodes;
+		allocator->free_tnodes = tn;
+		allocator->n_free_tnodes++;
+	}
+	dev->checkpoint_blocks_required = 0;	/* force recalculation */
+}
+
+/*--------------- yaffs_obj alloaction ------------------------
+ *
+ * Free yaffs_objs are stored in a list using obj->siblings.
+ * The blocks of allocated objects are stored in a linked list.
+ */
+
+static void yaffs_init_raw_objs(struct yaffs_dev *dev)
+{
+	struct yaffs_allocator *allocator = dev->allocator;
+
+	if (!allocator) {
+		BUG();
+		return;
+	}
+
+	allocator->allocated_obj_list = NULL;
+	INIT_LIST_HEAD(&allocator->free_objs);
+	allocator->n_free_objects = 0;
+}
+
+static void yaffs_deinit_raw_objs(struct yaffs_dev *dev)
+{
+	struct yaffs_allocator *allocator = dev->allocator;
+	struct yaffs_obj_list *tmp;
+
+	if (!allocator) {
+		BUG();
+		return;
+	}
+
+	while (allocator->allocated_obj_list) {
+		tmp = allocator->allocated_obj_list->next;
+		kfree(allocator->allocated_obj_list->objects);
+		kfree(allocator->allocated_obj_list);
+		allocator->allocated_obj_list = tmp;
+	}
+
+	INIT_LIST_HEAD(&allocator->free_objs);
+	allocator->n_free_objects = 0;
+	allocator->n_obj_created = 0;
+}
+
+static int yaffs_create_free_objs(struct yaffs_dev *dev, int n_obj)
+{
+	struct yaffs_allocator *allocator = dev->allocator;
+	int i;
+	struct yaffs_obj *new_objs;
+	struct yaffs_obj_list *list;
+
+	if (!allocator) {
+		BUG();
+		return YAFFS_FAIL;
+	}
+
+	if (n_obj < 1)
+		return YAFFS_OK;
+
+	/* make these things */
+	new_objs = kmalloc(n_obj * sizeof(struct yaffs_obj), GFP_NOFS);
+	list = kmalloc(sizeof(struct yaffs_obj_list), GFP_NOFS);
+
+	if (!new_objs || !list) {
+		kfree(new_objs);
+		new_objs = NULL;
+		kfree(list);
+		list = NULL;
+		yaffs_trace(YAFFS_TRACE_ALLOCATE,
+			"Could not allocate more objects");
+		return YAFFS_FAIL;
+	}
+
+	/* Hook them into the free list */
+	for (i = 0; i < n_obj; i++)
+		list_add(&new_objs[i].siblings, &allocator->free_objs);
+
+	allocator->n_free_objects += n_obj;
+	allocator->n_obj_created += n_obj;
+
+	/* Now add this bunch of Objects to a list for freeing up. */
+
+	list->objects = new_objs;
+	list->next = allocator->allocated_obj_list;
+	allocator->allocated_obj_list = list;
+
+	return YAFFS_OK;
+}
+
+struct yaffs_obj *yaffs_alloc_raw_obj(struct yaffs_dev *dev)
+{
+	struct yaffs_obj *obj = NULL;
+	struct list_head *lh;
+	struct yaffs_allocator *allocator = dev->allocator;
+
+	if (!allocator) {
+		BUG();
+		return obj;
+	}
+
+	/* If there are none left make more */
+	if (list_empty(&allocator->free_objs))
+		yaffs_create_free_objs(dev, YAFFS_ALLOCATION_NOBJECTS);
+
+	if (!list_empty(&allocator->free_objs)) {
+		lh = allocator->free_objs.next;
+		obj = list_entry(lh, struct yaffs_obj, siblings);
+		list_del_init(lh);
+		allocator->n_free_objects--;
+	}
+
+	return obj;
+}
+
+void yaffs_free_raw_obj(struct yaffs_dev *dev, struct yaffs_obj *obj)
+{
+
+	struct yaffs_allocator *allocator = dev->allocator;
+
+	if (!allocator) {
+		BUG();
+		return;
+	}
+
+	/* Link into the free list. */
+	list_add(&obj->siblings, &allocator->free_objs);
+	allocator->n_free_objects++;
+}
+
+void yaffs_deinit_raw_tnodes_and_objs(struct yaffs_dev *dev)
+{
+
+	if (!dev->allocator) {
+		BUG();
+		return;
+	}
+
+	yaffs_deinit_raw_tnodes(dev);
+	yaffs_deinit_raw_objs(dev);
+	kfree(dev->allocator);
+	dev->allocator = NULL;
+}
+
+void yaffs_init_raw_tnodes_and_objs(struct yaffs_dev *dev)
+{
+	struct yaffs_allocator *allocator;
+
+	if (dev->allocator) {
+		BUG();
+		return;
+	}
+
+	allocator = kmalloc(sizeof(struct yaffs_allocator), GFP_NOFS);
+	if (allocator) {
+		dev->allocator = allocator;
+		yaffs_init_raw_tnodes(dev);
+		yaffs_init_raw_objs(dev);
+	}
+}
+
diff --git a/fs/yaffs2/yaffs_allocator.h b/fs/yaffs2/yaffs_allocator.h
new file mode 100644
index 0000000..a8cc322
--- /dev/null
+++ b/fs/yaffs2/yaffs_allocator.h
@@ -0,0 +1,30 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_ALLOCATOR_H__
+#define __YAFFS_ALLOCATOR_H__
+
+#include "yaffs_guts.h"
+
+void yaffs_init_raw_tnodes_and_objs(struct yaffs_dev *dev);
+void yaffs_deinit_raw_tnodes_and_objs(struct yaffs_dev *dev);
+
+struct yaffs_tnode *yaffs_alloc_raw_tnode(struct yaffs_dev *dev);
+void yaffs_free_raw_tnode(struct yaffs_dev *dev, struct yaffs_tnode *tn);
+
+struct yaffs_obj *yaffs_alloc_raw_obj(struct yaffs_dev *dev);
+void yaffs_free_raw_obj(struct yaffs_dev *dev, struct yaffs_obj *obj);
+
+#endif
diff --git a/fs/yaffs2/yaffs_attribs.c b/fs/yaffs2/yaffs_attribs.c
new file mode 100644
index 0000000..5eb7c5a
--- /dev/null
+++ b/fs/yaffs2/yaffs_attribs.c
@@ -0,0 +1,136 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include "yaffs_guts.h"
+#include "yaffs_attribs.h"
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 14, 0))
+#define IATTR_UID ia_uid
+#define IATTR_GID ia_gid
+#else
+#define IATTR_UID ia_uid.val
+#define IATTR_GID ia_gid.val
+#endif
+
+/*
+ * Loading attibs from/to object header assumes the object header
+ * is in cpu endian.
+ */
+void yaffs_load_attribs(struct yaffs_obj *obj, struct yaffs_obj_hdr *oh)
+{
+	obj->yst_uid = oh->yst_uid;
+	obj->yst_gid = oh->yst_gid;
+	obj->yst_atime = oh->yst_atime;
+	obj->yst_mtime = oh->yst_mtime;
+	obj->yst_ctime = oh->yst_ctime;
+	obj->yst_rdev = oh->yst_rdev;
+}
+
+void yaffs_load_attribs_oh(struct yaffs_obj_hdr *oh, struct yaffs_obj *obj)
+{
+	oh->yst_uid = obj->yst_uid;
+	oh->yst_gid = obj->yst_gid;
+	oh->yst_atime = obj->yst_atime;
+	oh->yst_mtime = obj->yst_mtime;
+	oh->yst_ctime = obj->yst_ctime;
+	oh->yst_rdev = obj->yst_rdev;
+
+}
+
+void yaffs_load_current_time(struct yaffs_obj *obj, int do_a, int do_c)
+{
+	obj->yst_mtime = Y_CURRENT_TIME;
+	if (do_a)
+		obj->yst_atime = obj->yst_mtime;
+	if (do_c)
+		obj->yst_ctime = obj->yst_mtime;
+}
+
+void yaffs_attribs_init(struct yaffs_obj *obj, u32 gid, u32 uid, u32 rdev)
+{
+	yaffs_load_current_time(obj, 1, 1);
+	obj->yst_rdev = rdev;
+	obj->yst_uid = uid;
+	obj->yst_gid = gid;
+}
+
+static loff_t yaffs_get_file_size(struct yaffs_obj *obj)
+{
+	YCHAR *alias = NULL;
+	obj = yaffs_get_equivalent_obj(obj);
+
+	switch (obj->variant_type) {
+	case YAFFS_OBJECT_TYPE_FILE:
+		return obj->variant.file_variant.file_size;
+	case YAFFS_OBJECT_TYPE_SYMLINK:
+		alias = obj->variant.symlink_variant.alias;
+		if (!alias)
+			return 0;
+		return strnlen(alias, YAFFS_MAX_ALIAS_LENGTH);
+	default:
+		return 0;
+	}
+}
+
+int yaffs_set_attribs(struct yaffs_obj *obj, struct iattr *attr)
+{
+	unsigned int valid = attr->ia_valid;
+
+	if (valid & ATTR_MODE)
+		obj->yst_mode = attr->ia_mode;
+	if (valid & ATTR_UID)
+		obj->yst_uid = attr->IATTR_UID;
+	if (valid & ATTR_GID)
+		obj->yst_gid = attr->IATTR_GID;
+
+	if (valid & ATTR_ATIME)
+		obj->yst_atime = Y_TIME_CONVERT(attr->ia_atime);
+	if (valid & ATTR_CTIME)
+		obj->yst_ctime = Y_TIME_CONVERT(attr->ia_ctime);
+	if (valid & ATTR_MTIME)
+		obj->yst_mtime = Y_TIME_CONVERT(attr->ia_mtime);
+
+	if (valid & ATTR_SIZE)
+		yaffs_resize_file(obj, attr->ia_size);
+
+	yaffs_update_oh(obj, NULL, 1, 0, 0, NULL);
+
+	return YAFFS_OK;
+
+}
+
+int yaffs_get_attribs(struct yaffs_obj *obj, struct iattr *attr)
+{
+	unsigned int valid = 0;
+
+	attr->ia_mode = obj->yst_mode;
+	valid |= ATTR_MODE;
+	attr->IATTR_UID = obj->yst_uid;
+	valid |= ATTR_UID;
+	attr->IATTR_GID = obj->yst_gid;
+	valid |= ATTR_GID;
+
+	Y_TIME_CONVERT(attr->ia_atime) = obj->yst_atime;
+	valid |= ATTR_ATIME;
+	Y_TIME_CONVERT(attr->ia_ctime) = obj->yst_ctime;
+	valid |= ATTR_CTIME;
+	Y_TIME_CONVERT(attr->ia_mtime) = obj->yst_mtime;
+	valid |= ATTR_MTIME;
+
+	attr->ia_size = yaffs_get_file_size(obj);
+	valid |= ATTR_SIZE;
+
+	attr->ia_valid = valid;
+
+	return YAFFS_OK;
+}
diff --git a/fs/yaffs2/yaffs_attribs.h b/fs/yaffs2/yaffs_attribs.h
new file mode 100644
index 0000000..5b21b08
--- /dev/null
+++ b/fs/yaffs2/yaffs_attribs.h
@@ -0,0 +1,28 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_ATTRIBS_H__
+#define __YAFFS_ATTRIBS_H__
+
+#include "yaffs_guts.h"
+
+void yaffs_load_attribs(struct yaffs_obj *obj, struct yaffs_obj_hdr *oh);
+void yaffs_load_attribs_oh(struct yaffs_obj_hdr *oh, struct yaffs_obj *obj);
+void yaffs_attribs_init(struct yaffs_obj *obj, u32 gid, u32 uid, u32 rdev);
+void yaffs_load_current_time(struct yaffs_obj *obj, int do_a, int do_c);
+int yaffs_set_attribs(struct yaffs_obj *obj, struct iattr *attr);
+int yaffs_get_attribs(struct yaffs_obj *obj, struct iattr *attr);
+
+#endif
diff --git a/fs/yaffs2/yaffs_bitmap.c b/fs/yaffs2/yaffs_bitmap.c
new file mode 100644
index 0000000..bf8cbb3
--- /dev/null
+++ b/fs/yaffs2/yaffs_bitmap.c
@@ -0,0 +1,99 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include "yaffs_bitmap.h"
+#include "yaffs_trace.h"
+/*
+ * Chunk bitmap manipulations
+ */
+
+static inline u8 *yaffs_block_bits(struct yaffs_dev *dev, int blk)
+{
+	if (blk < (int)dev->internal_start_block ||
+	    blk > (int)dev->internal_end_block) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"BlockBits block %d is not valid",
+			blk);
+		BUG();
+	}
+	return dev->chunk_bits +
+	    (dev->chunk_bit_stride * (blk - dev->internal_start_block));
+}
+
+void yaffs_verify_chunk_bit_id(struct yaffs_dev *dev, int blk, int chunk)
+{
+	if (blk < (int)dev->internal_start_block ||
+	    blk > (int)dev->internal_end_block ||
+	    chunk < 0 || chunk >= (int)dev->param.chunks_per_block) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"Chunk Id (%d:%d) invalid",
+			blk, chunk);
+		BUG();
+	}
+}
+
+void yaffs_clear_chunk_bits(struct yaffs_dev *dev, int blk)
+{
+	u8 *blk_bits = yaffs_block_bits(dev, blk);
+
+	memset(blk_bits, 0, dev->chunk_bit_stride);
+}
+
+void yaffs_clear_chunk_bit(struct yaffs_dev *dev, int blk, int chunk)
+{
+	u8 *blk_bits = yaffs_block_bits(dev, blk);
+
+	yaffs_verify_chunk_bit_id(dev, blk, chunk);
+	blk_bits[chunk / 8] &= ~(1 << (chunk & 7));
+}
+
+void yaffs_set_chunk_bit(struct yaffs_dev *dev, int blk, int chunk)
+{
+	u8 *blk_bits = yaffs_block_bits(dev, blk);
+
+	yaffs_verify_chunk_bit_id(dev, blk, chunk);
+	blk_bits[chunk / 8] |= (1 << (chunk & 7));
+}
+
+int yaffs_check_chunk_bit(struct yaffs_dev *dev, int blk, int chunk)
+{
+	u8 *blk_bits = yaffs_block_bits(dev, blk);
+
+	yaffs_verify_chunk_bit_id(dev, blk, chunk);
+	return (blk_bits[chunk / 8] & (1 << (chunk & 7))) ? 1 : 0;
+}
+
+int yaffs_still_some_chunks(struct yaffs_dev *dev, int blk)
+{
+	u8 *blk_bits = yaffs_block_bits(dev, blk);
+	int i;
+
+	for (i = 0; i < dev->chunk_bit_stride; i++) {
+		if (*blk_bits)
+			return 1;
+		blk_bits++;
+	}
+	return 0;
+}
+
+int yaffs_count_chunk_bits(struct yaffs_dev *dev, int blk)
+{
+	u8 *blk_bits = yaffs_block_bits(dev, blk);
+	int i;
+	int n = 0;
+
+	for (i = 0; i < dev->chunk_bit_stride; i++, blk_bits++)
+		n += hweight8(*blk_bits);
+
+	return n;
+}
diff --git a/fs/yaffs2/yaffs_bitmap.h b/fs/yaffs2/yaffs_bitmap.h
new file mode 100644
index 0000000..e26b37d
--- /dev/null
+++ b/fs/yaffs2/yaffs_bitmap.h
@@ -0,0 +1,33 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+/*
+ * Chunk bitmap manipulations
+ */
+
+#ifndef __YAFFS_BITMAP_H__
+#define __YAFFS_BITMAP_H__
+
+#include "yaffs_guts.h"
+
+void yaffs_verify_chunk_bit_id(struct yaffs_dev *dev, int blk, int chunk);
+void yaffs_clear_chunk_bits(struct yaffs_dev *dev, int blk);
+void yaffs_clear_chunk_bit(struct yaffs_dev *dev, int blk, int chunk);
+void yaffs_set_chunk_bit(struct yaffs_dev *dev, int blk, int chunk);
+int yaffs_check_chunk_bit(struct yaffs_dev *dev, int blk, int chunk);
+int yaffs_still_some_chunks(struct yaffs_dev *dev, int blk);
+int yaffs_count_chunk_bits(struct yaffs_dev *dev, int blk);
+
+#endif
diff --git a/fs/yaffs2/yaffs_checkptrw.c b/fs/yaffs2/yaffs_checkptrw.c
new file mode 100644
index 0000000..c7cbda3
--- /dev/null
+++ b/fs/yaffs2/yaffs_checkptrw.c
@@ -0,0 +1,481 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include "yaffs_checkptrw.h"
+#include "yaffs_getblockinfo.h"
+#include "yaffs_endian.h"
+
+struct yaffs_checkpt_chunk_hdr {
+	int version;
+	int seq;
+	u32 sum;
+	u32 xor;
+} ;
+
+
+static int apply_chunk_offset(struct yaffs_dev *dev, int chunk)
+{
+	return chunk - dev->chunk_offset;
+}
+
+static int apply_block_offset(struct yaffs_dev *dev, int block)
+{
+	return block - dev->block_offset;
+}
+
+
+static void yaffs2_do_endian_hdr(struct yaffs_dev *dev,
+				 struct yaffs_checkpt_chunk_hdr *hdr)
+{
+	if (!dev->swap_endian)
+		return;
+	hdr->version = swap_s32(hdr->version);
+	hdr->seq     = swap_s32(hdr->seq);
+	hdr->sum     = swap_u32(hdr->sum);
+	hdr->xor     = swap_u32(hdr->xor);
+}
+
+static void yaffs2_checkpt_init_chunk_hdr(struct yaffs_dev *dev)
+{
+	struct yaffs_checkpt_chunk_hdr hdr;
+
+	hdr.version = YAFFS_CHECKPOINT_VERSION;
+	hdr.seq = dev->checkpt_page_seq;
+	hdr.sum = dev->checkpt_sum;
+	hdr.xor = dev->checkpt_xor;
+
+	dev->checkpt_byte_offs = sizeof(hdr);
+
+	yaffs2_do_endian_hdr(dev, &hdr);
+	memcpy(dev->checkpt_buffer, &hdr, sizeof(hdr));
+}
+
+static int yaffs2_checkpt_check_chunk_hdr(struct yaffs_dev *dev)
+{
+	struct yaffs_checkpt_chunk_hdr hdr;
+
+	memcpy(&hdr, dev->checkpt_buffer, sizeof(hdr));
+	yaffs2_do_endian_hdr(dev, &hdr);
+
+	dev->checkpt_byte_offs = sizeof(hdr);
+
+	return hdr.version == YAFFS_CHECKPOINT_VERSION &&
+		hdr.seq == dev->checkpt_page_seq &&
+		hdr.sum == dev->checkpt_sum &&
+		hdr.xor == dev->checkpt_xor;
+}
+
+static int yaffs2_checkpt_space_ok(struct yaffs_dev *dev)
+{
+	int blocks_avail = dev->n_erased_blocks - dev->param.n_reserved_blocks;
+
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+		"checkpt blocks_avail = %d", blocks_avail);
+
+	return (blocks_avail <= 0) ? 0 : 1;
+}
+
+static int yaffs_checkpt_erase(struct yaffs_dev *dev)
+{
+	u32 i;
+
+	if (!dev->drv.drv_erase_fn)
+		return 0;
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+		"checking blocks %d to %d",
+		dev->internal_start_block, dev->internal_end_block);
+
+	for (i = dev->internal_start_block; i <= dev->internal_end_block; i++) {
+		struct yaffs_block_info *bi = yaffs_get_block_info(dev, i);
+		int offset_i = apply_block_offset(dev, i);
+		int result;
+
+		if (bi->block_state == YAFFS_BLOCK_STATE_CHECKPOINT) {
+			yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"erasing checkpt block %d", i);
+
+			dev->n_erasures++;
+
+			result = dev->drv.drv_erase_fn(dev, offset_i);
+			if(result) {
+				bi->block_state = YAFFS_BLOCK_STATE_EMPTY;
+				dev->n_erased_blocks++;
+				dev->n_free_chunks +=
+				    dev->param.chunks_per_block;
+			} else {
+				dev->drv.drv_mark_bad_fn(dev, offset_i);
+				bi->block_state = YAFFS_BLOCK_STATE_DEAD;
+			}
+		}
+	}
+
+	dev->blocks_in_checkpt = 0;
+
+	return 1;
+}
+
+static void yaffs2_checkpt_find_erased_block(struct yaffs_dev *dev)
+{
+	u32 i;
+	int blocks_avail = dev->n_erased_blocks - dev->param.n_reserved_blocks;
+
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+		"allocating checkpt block: erased %d reserved %d avail %d next %d ",
+		dev->n_erased_blocks, dev->param.n_reserved_blocks,
+		blocks_avail, dev->checkpt_next_block);
+
+	if (dev->checkpt_next_block >= 0 &&
+	    dev->checkpt_next_block <= (int)dev->internal_end_block &&
+	    blocks_avail > 0) {
+
+		for (i = dev->checkpt_next_block; i <= dev->internal_end_block;
+		     i++) {
+			struct yaffs_block_info *bi;
+
+			bi = yaffs_get_block_info(dev, i);
+			if (bi->block_state == YAFFS_BLOCK_STATE_EMPTY) {
+				dev->checkpt_next_block = i + 1;
+				dev->checkpt_cur_block = i;
+				yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+					"allocating checkpt block %d", i);
+				return;
+			}
+		}
+	}
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT, "out of checkpt blocks");
+
+	dev->checkpt_next_block = -1;
+	dev->checkpt_cur_block = -1;
+}
+
+static void yaffs2_checkpt_find_block(struct yaffs_dev *dev)
+{
+	u32 i;
+	struct yaffs_ext_tags tags;
+
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+		"find next checkpt block: start:  blocks %d next %d",
+		dev->blocks_in_checkpt, dev->checkpt_next_block);
+
+	if (dev->blocks_in_checkpt < dev->checkpt_max_blocks)
+		for (i = dev->checkpt_next_block; i <= dev->internal_end_block;
+		     i++) {
+			int chunk = i * dev->param.chunks_per_block;
+			enum yaffs_block_state state;
+			u32 seq;
+
+			dev->tagger.read_chunk_tags_fn(dev,
+					apply_chunk_offset(dev, chunk),
+					NULL, &tags);
+			yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+				"find next checkpt block: search: block %d state %d oid %d seq %d eccr %d",
+				i, (int) state,
+				tags.obj_id, tags.seq_number,
+				tags.ecc_result);
+
+			if (tags.seq_number != YAFFS_SEQUENCE_CHECKPOINT_DATA)
+				continue;
+
+			dev->tagger.query_block_fn(dev,
+						apply_block_offset(dev, i),
+						&state, &seq);
+			if (state == YAFFS_BLOCK_STATE_DEAD)
+				continue;
+
+			/* Right kind of block */
+			dev->checkpt_next_block = tags.obj_id;
+			dev->checkpt_cur_block = i;
+			dev->checkpt_block_list[dev->blocks_in_checkpt] = i;
+			dev->blocks_in_checkpt++;
+			yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+				"found checkpt block %d", i);
+			return;
+		}
+
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT, "found no more checkpt blocks");
+
+	dev->checkpt_next_block = -1;
+	dev->checkpt_cur_block = -1;
+}
+
+int yaffs2_checkpt_open(struct yaffs_dev *dev, int writing)
+{
+	u32 i;
+
+	dev->checkpt_open_write = writing;
+
+	/* Got the functions we need? */
+	if (!dev->tagger.write_chunk_tags_fn ||
+	    !dev->tagger.read_chunk_tags_fn ||
+	    !dev->drv.drv_erase_fn ||
+	    !dev->drv.drv_mark_bad_fn)
+		return 0;
+
+	if (writing && !yaffs2_checkpt_space_ok(dev))
+		return 0;
+
+	if (!dev->checkpt_buffer)
+		dev->checkpt_buffer =
+		    kmalloc(dev->param.total_bytes_per_chunk, GFP_NOFS);
+	if (!dev->checkpt_buffer)
+		return 0;
+
+	dev->checkpt_page_seq = 0;
+	dev->checkpt_byte_count = 0;
+	dev->checkpt_sum = 0;
+	dev->checkpt_xor = 0;
+	dev->checkpt_cur_block = -1;
+	dev->checkpt_cur_chunk = -1;
+	dev->checkpt_next_block = dev->internal_start_block;
+
+	if (writing) {
+		memset(dev->checkpt_buffer, 0, dev->data_bytes_per_chunk);
+		yaffs2_checkpt_init_chunk_hdr(dev);
+		return yaffs_checkpt_erase(dev);
+	}
+
+	/* Opening for a read */
+	/* Set to a value that will kick off a read */
+	dev->checkpt_byte_offs = dev->data_bytes_per_chunk;
+	/* A checkpoint block list of 1 checkpoint block per 16 block is
+	 * (hopefully) going to be way more than we need */
+	dev->blocks_in_checkpt = 0;
+	dev->checkpt_max_blocks =
+	    (dev->internal_end_block - dev->internal_start_block) / 16 + 2;
+	if (!dev->checkpt_block_list)
+		dev->checkpt_block_list =
+		      kmalloc(sizeof(int) * dev->checkpt_max_blocks, GFP_NOFS);
+
+	if (!dev->checkpt_block_list)
+		return 0;
+
+	for (i = 0; i < dev->checkpt_max_blocks; i++)
+		dev->checkpt_block_list[i] = -1;
+
+	return 1;
+}
+
+int yaffs2_get_checkpt_sum(struct yaffs_dev *dev, u32 * sum)
+{
+	u32 composite_sum;
+
+	composite_sum = (dev->checkpt_sum << 8) | (dev->checkpt_xor & 0xff);
+	*sum = composite_sum;
+	return 1;
+}
+
+static int yaffs2_checkpt_flush_buffer(struct yaffs_dev *dev)
+{
+	int chunk;
+	int offset_chunk;
+	struct yaffs_ext_tags tags;
+
+	if (dev->checkpt_cur_block < 0) {
+		yaffs2_checkpt_find_erased_block(dev);
+		dev->checkpt_cur_chunk = 0;
+	}
+
+	if (dev->checkpt_cur_block < 0)
+		return 0;
+
+	tags.is_deleted = 0;
+	tags.obj_id = dev->checkpt_next_block;	/* Hint to next place to look */
+	tags.chunk_id = dev->checkpt_page_seq + 1;
+	tags.seq_number = YAFFS_SEQUENCE_CHECKPOINT_DATA;
+	tags.n_bytes = dev->data_bytes_per_chunk;
+	if (dev->checkpt_cur_chunk == 0) {
+		/* First chunk we write for the block? Set block state to
+		   checkpoint */
+		struct yaffs_block_info *bi =
+		    yaffs_get_block_info(dev, dev->checkpt_cur_block);
+		bi->block_state = YAFFS_BLOCK_STATE_CHECKPOINT;
+		dev->blocks_in_checkpt++;
+	}
+
+	chunk =
+	    dev->checkpt_cur_block * dev->param.chunks_per_block +
+	    dev->checkpt_cur_chunk;
+
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+		"checkpoint wite buffer nand %d(%d:%d) objid %d chId %d",
+		chunk, dev->checkpt_cur_block, dev->checkpt_cur_chunk,
+		tags.obj_id, tags.chunk_id);
+
+	offset_chunk = apply_chunk_offset(dev, chunk);
+
+	dev->n_page_writes++;
+
+	dev->tagger.write_chunk_tags_fn(dev, offset_chunk,
+				       dev->checkpt_buffer, &tags);
+	dev->checkpt_page_seq++;
+	dev->checkpt_cur_chunk++;
+	if (dev->checkpt_cur_chunk >= (int)dev->param.chunks_per_block) {
+		dev->checkpt_cur_chunk = 0;
+		dev->checkpt_cur_block = -1;
+	}
+	memset(dev->checkpt_buffer, 0, dev->data_bytes_per_chunk);
+
+	yaffs2_checkpt_init_chunk_hdr(dev);
+
+
+	return 1;
+}
+
+int yaffs2_checkpt_wr(struct yaffs_dev *dev, const void *data, int n_bytes)
+{
+	int i = 0;
+	int ok = 1;
+	u8 *data_bytes = (u8 *) data;
+
+	if (!dev->checkpt_buffer)
+		return 0;
+
+	if (!dev->checkpt_open_write)
+		return -1;
+
+	while (i < n_bytes && ok) {
+		dev->checkpt_buffer[dev->checkpt_byte_offs] = *data_bytes;
+		dev->checkpt_sum += *data_bytes;
+		dev->checkpt_xor ^= *data_bytes;
+
+		dev->checkpt_byte_offs++;
+		i++;
+		data_bytes++;
+		dev->checkpt_byte_count++;
+
+		if (dev->checkpt_byte_offs < 0 ||
+		    dev->checkpt_byte_offs >= (int)dev->data_bytes_per_chunk)
+			ok = yaffs2_checkpt_flush_buffer(dev);
+	}
+
+	return i;
+}
+
+int yaffs2_checkpt_rd(struct yaffs_dev *dev, void *data, int n_bytes)
+{
+	int i = 0;
+	struct yaffs_ext_tags tags;
+	int chunk;
+	int offset_chunk;
+	u8 *data_bytes = (u8 *) data;
+
+	if (!dev->checkpt_buffer)
+		return 0;
+
+	if (dev->checkpt_open_write)
+		return -1;
+
+	while (i < n_bytes) {
+
+		if (dev->checkpt_byte_offs < 0 ||
+		    dev->checkpt_byte_offs >= (int)dev->data_bytes_per_chunk) {
+
+			if (dev->checkpt_cur_block < 0) {
+				yaffs2_checkpt_find_block(dev);
+				dev->checkpt_cur_chunk = 0;
+			}
+
+			/* Bail out if we can't find a checpoint block */
+			if (dev->checkpt_cur_block < 0)
+				break;
+
+			chunk = dev->checkpt_cur_block *
+			    dev->param.chunks_per_block +
+			    dev->checkpt_cur_chunk;
+
+			offset_chunk = apply_chunk_offset(dev, chunk);
+			dev->n_page_reads++;
+
+			/* Read in the next chunk */
+			dev->tagger.read_chunk_tags_fn(dev,
+						offset_chunk,
+						dev->checkpt_buffer,
+						&tags);
+
+			/* Bail out if the chunk is corrupted. */
+			if (tags.chunk_id != (u32)(dev->checkpt_page_seq + 1) ||
+			    tags.ecc_result > YAFFS_ECC_RESULT_FIXED ||
+			    tags.seq_number != YAFFS_SEQUENCE_CHECKPOINT_DATA)
+				break;
+
+			/* Bail out if it is not a checkpoint chunk. */
+			if(!yaffs2_checkpt_check_chunk_hdr(dev))
+				break;
+
+			dev->checkpt_page_seq++;
+			dev->checkpt_cur_chunk++;
+
+			if (dev->checkpt_cur_chunk >=
+					(int)dev->param.chunks_per_block)
+				dev->checkpt_cur_block = -1;
+
+		}
+
+		*data_bytes = dev->checkpt_buffer[dev->checkpt_byte_offs];
+		dev->checkpt_sum += *data_bytes;
+		dev->checkpt_xor ^= *data_bytes;
+		dev->checkpt_byte_offs++;
+		i++;
+		data_bytes++;
+		dev->checkpt_byte_count++;
+	}
+
+	return i; /* Number of bytes read */
+}
+
+int yaffs_checkpt_close(struct yaffs_dev *dev)
+{
+	u32 i;
+
+	if (dev->checkpt_open_write) {
+		if (dev->checkpt_byte_offs !=
+			sizeof(sizeof(struct yaffs_checkpt_chunk_hdr)))
+			yaffs2_checkpt_flush_buffer(dev);
+	} else if (dev->checkpt_block_list) {
+		for (i = 0;
+		     i < dev->blocks_in_checkpt &&
+		     dev->checkpt_block_list[i] >= 0; i++) {
+			int blk = dev->checkpt_block_list[i];
+			struct yaffs_block_info *bi = NULL;
+
+			if ((int)dev->internal_start_block <= blk &&
+			    blk <= (int)dev->internal_end_block)
+				bi = yaffs_get_block_info(dev, blk);
+			if (bi && bi->block_state == YAFFS_BLOCK_STATE_EMPTY)
+				bi->block_state = YAFFS_BLOCK_STATE_CHECKPOINT;
+		}
+	}
+
+	dev->n_free_chunks -=
+		dev->blocks_in_checkpt * dev->param.chunks_per_block;
+	dev->n_erased_blocks -= dev->blocks_in_checkpt;
+
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT, "checkpoint byte count %d",
+		dev->checkpt_byte_count);
+
+	if (dev->checkpt_buffer)
+		return 1;
+	else
+		return 0;
+}
+
+int yaffs2_checkpt_invalidate_stream(struct yaffs_dev *dev)
+{
+	/* Erase the checkpoint data */
+
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+		"checkpoint invalidate of %d blocks",
+		dev->blocks_in_checkpt);
+
+	return yaffs_checkpt_erase(dev);
+}
diff --git a/fs/yaffs2/yaffs_checkptrw.h b/fs/yaffs2/yaffs_checkptrw.h
new file mode 100644
index 0000000..cdbaba7
--- /dev/null
+++ b/fs/yaffs2/yaffs_checkptrw.h
@@ -0,0 +1,33 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_CHECKPTRW_H__
+#define __YAFFS_CHECKPTRW_H__
+
+#include "yaffs_guts.h"
+
+int yaffs2_checkpt_open(struct yaffs_dev *dev, int writing);
+
+int yaffs2_checkpt_wr(struct yaffs_dev *dev, const void *data, int n_bytes);
+
+int yaffs2_checkpt_rd(struct yaffs_dev *dev, void *data, int n_bytes);
+
+int yaffs2_get_checkpt_sum(struct yaffs_dev *dev, u32 * sum);
+
+int yaffs_checkpt_close(struct yaffs_dev *dev);
+
+int yaffs2_checkpt_invalidate_stream(struct yaffs_dev *dev);
+
+#endif
diff --git a/fs/yaffs2/yaffs_ecc.c b/fs/yaffs2/yaffs_ecc.c
new file mode 100644
index 0000000..9294107
--- /dev/null
+++ b/fs/yaffs2/yaffs_ecc.c
@@ -0,0 +1,281 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+/*
+ * This code implements the ECC algorithm used in SmartMedia.
+ *
+ * The ECC comprises 22 bits of parity information and is stuffed into 3 bytes.
+ * The two unused bit are set to 1.
+ * The ECC can correct single bit errors in a 256-byte page of data. Thus, two
+ * such ECC blocks are used on a 512-byte NAND page.
+ *
+ */
+
+#include "yportenv.h"
+
+#include "yaffs_ecc.h"
+
+/* Table generated by gen-ecc.c
+ * Using a table means we do not have to calculate p1..p4 and p1'..p4'
+ * for each byte of data. These are instead provided in a table in bits7..2.
+ * Bit 0 of each entry indicates whether the entry has an odd or even parity,
+ * and therefore this bytes influence on the line parity.
+ */
+
+static const unsigned char column_parity_table[] = {
+	0x00, 0x55, 0x59, 0x0c, 0x65, 0x30, 0x3c, 0x69,
+	0x69, 0x3c, 0x30, 0x65, 0x0c, 0x59, 0x55, 0x00,
+	0x95, 0xc0, 0xcc, 0x99, 0xf0, 0xa5, 0xa9, 0xfc,
+	0xfc, 0xa9, 0xa5, 0xf0, 0x99, 0xcc, 0xc0, 0x95,
+	0x99, 0xcc, 0xc0, 0x95, 0xfc, 0xa9, 0xa5, 0xf0,
+	0xf0, 0xa5, 0xa9, 0xfc, 0x95, 0xc0, 0xcc, 0x99,
+	0x0c, 0x59, 0x55, 0x00, 0x69, 0x3c, 0x30, 0x65,
+	0x65, 0x30, 0x3c, 0x69, 0x00, 0x55, 0x59, 0x0c,
+	0xa5, 0xf0, 0xfc, 0xa9, 0xc0, 0x95, 0x99, 0xcc,
+	0xcc, 0x99, 0x95, 0xc0, 0xa9, 0xfc, 0xf0, 0xa5,
+	0x30, 0x65, 0x69, 0x3c, 0x55, 0x00, 0x0c, 0x59,
+	0x59, 0x0c, 0x00, 0x55, 0x3c, 0x69, 0x65, 0x30,
+	0x3c, 0x69, 0x65, 0x30, 0x59, 0x0c, 0x00, 0x55,
+	0x55, 0x00, 0x0c, 0x59, 0x30, 0x65, 0x69, 0x3c,
+	0xa9, 0xfc, 0xf0, 0xa5, 0xcc, 0x99, 0x95, 0xc0,
+	0xc0, 0x95, 0x99, 0xcc, 0xa5, 0xf0, 0xfc, 0xa9,
+	0xa9, 0xfc, 0xf0, 0xa5, 0xcc, 0x99, 0x95, 0xc0,
+	0xc0, 0x95, 0x99, 0xcc, 0xa5, 0xf0, 0xfc, 0xa9,
+	0x3c, 0x69, 0x65, 0x30, 0x59, 0x0c, 0x00, 0x55,
+	0x55, 0x00, 0x0c, 0x59, 0x30, 0x65, 0x69, 0x3c,
+	0x30, 0x65, 0x69, 0x3c, 0x55, 0x00, 0x0c, 0x59,
+	0x59, 0x0c, 0x00, 0x55, 0x3c, 0x69, 0x65, 0x30,
+	0xa5, 0xf0, 0xfc, 0xa9, 0xc0, 0x95, 0x99, 0xcc,
+	0xcc, 0x99, 0x95, 0xc0, 0xa9, 0xfc, 0xf0, 0xa5,
+	0x0c, 0x59, 0x55, 0x00, 0x69, 0x3c, 0x30, 0x65,
+	0x65, 0x30, 0x3c, 0x69, 0x00, 0x55, 0x59, 0x0c,
+	0x99, 0xcc, 0xc0, 0x95, 0xfc, 0xa9, 0xa5, 0xf0,
+	0xf0, 0xa5, 0xa9, 0xfc, 0x95, 0xc0, 0xcc, 0x99,
+	0x95, 0xc0, 0xcc, 0x99, 0xf0, 0xa5, 0xa9, 0xfc,
+	0xfc, 0xa9, 0xa5, 0xf0, 0x99, 0xcc, 0xc0, 0x95,
+	0x00, 0x55, 0x59, 0x0c, 0x65, 0x30, 0x3c, 0x69,
+	0x69, 0x3c, 0x30, 0x65, 0x0c, 0x59, 0x55, 0x00,
+};
+
+
+/* Calculate the ECC for a 256-byte block of data */
+void yaffs_ecc_calc(const unsigned char *data, unsigned char *ecc)
+{
+	unsigned int i;
+	unsigned char col_parity = 0;
+	unsigned char line_parity = 0;
+	unsigned char line_parity_prime = 0;
+	unsigned char t;
+	unsigned char b;
+
+	for (i = 0; i < 256; i++) {
+		b = column_parity_table[*data++];
+		col_parity ^= b;
+
+		if (b & 0x01) {	/* odd number of bits in the byte */
+			line_parity ^= i;
+			line_parity_prime ^= ~i;
+		}
+	}
+
+	ecc[2] = (~col_parity) | 0x03;
+
+	t = 0;
+	if (line_parity & 0x80)
+		t |= 0x80;
+	if (line_parity_prime & 0x80)
+		t |= 0x40;
+	if (line_parity & 0x40)
+		t |= 0x20;
+	if (line_parity_prime & 0x40)
+		t |= 0x10;
+	if (line_parity & 0x20)
+		t |= 0x08;
+	if (line_parity_prime & 0x20)
+		t |= 0x04;
+	if (line_parity & 0x10)
+		t |= 0x02;
+	if (line_parity_prime & 0x10)
+		t |= 0x01;
+	ecc[1] = ~t;
+
+	t = 0;
+	if (line_parity & 0x08)
+		t |= 0x80;
+	if (line_parity_prime & 0x08)
+		t |= 0x40;
+	if (line_parity & 0x04)
+		t |= 0x20;
+	if (line_parity_prime & 0x04)
+		t |= 0x10;
+	if (line_parity & 0x02)
+		t |= 0x08;
+	if (line_parity_prime & 0x02)
+		t |= 0x04;
+	if (line_parity & 0x01)
+		t |= 0x02;
+	if (line_parity_prime & 0x01)
+		t |= 0x01;
+	ecc[0] = ~t;
+
+}
+
+/* Correct the ECC on a 256 byte block of data */
+
+int yaffs_ecc_correct(unsigned char *data, unsigned char *read_ecc,
+		      const unsigned char *test_ecc)
+{
+	unsigned char d0, d1, d2;	/* deltas */
+
+	d0 = read_ecc[0] ^ test_ecc[0];
+	d1 = read_ecc[1] ^ test_ecc[1];
+	d2 = read_ecc[2] ^ test_ecc[2];
+
+	if ((d0 | d1 | d2) == 0)
+		return 0;	/* no error */
+
+	if (((d0 ^ (d0 >> 1)) & 0x55) == 0x55 &&
+	    ((d1 ^ (d1 >> 1)) & 0x55) == 0x55 &&
+	    ((d2 ^ (d2 >> 1)) & 0x54) == 0x54) {
+		/* Single bit (recoverable) error in data */
+
+		unsigned byte;
+		unsigned bit;
+
+		bit = byte = 0;
+
+		if (d1 & 0x80)
+			byte |= 0x80;
+		if (d1 & 0x20)
+			byte |= 0x40;
+		if (d1 & 0x08)
+			byte |= 0x20;
+		if (d1 & 0x02)
+			byte |= 0x10;
+		if (d0 & 0x80)
+			byte |= 0x08;
+		if (d0 & 0x20)
+			byte |= 0x04;
+		if (d0 & 0x08)
+			byte |= 0x02;
+		if (d0 & 0x02)
+			byte |= 0x01;
+
+		if (d2 & 0x80)
+			bit |= 0x04;
+		if (d2 & 0x20)
+			bit |= 0x02;
+		if (d2 & 0x08)
+			bit |= 0x01;
+
+		data[byte] ^= (1 << bit);
+
+		return 1;	/* Corrected the error */
+	}
+
+	if ((hweight8(d0) + hweight8(d1) + hweight8(d2)) == 1) {
+		/* Reccoverable error in ecc */
+
+		read_ecc[0] = test_ecc[0];
+		read_ecc[1] = test_ecc[1];
+		read_ecc[2] = test_ecc[2];
+
+		return 1;	/* Corrected the error */
+	}
+
+	/* Unrecoverable error */
+
+	return -1;
+
+}
+
+/*
+ * ECCxxxOther does ECC calcs on arbitrary n bytes of data
+ */
+void yaffs_ecc_calc_other(const unsigned char *data, unsigned n_bytes,
+			  struct yaffs_ecc_other *ecc_other)
+{
+	unsigned int i;
+	unsigned char col_parity = 0;
+	unsigned line_parity = 0;
+	unsigned line_parity_prime = 0;
+	unsigned char b;
+
+	for (i = 0; i < n_bytes; i++) {
+		b = column_parity_table[*data++];
+		col_parity ^= b;
+
+		if (b & 0x01) {
+			/* odd number of bits in the byte */
+			line_parity ^= i;
+			line_parity_prime ^= ~i;
+		}
+
+	}
+
+	ecc_other->col_parity = (col_parity >> 2) & 0x3f;
+	ecc_other->line_parity = line_parity;
+	ecc_other->line_parity_prime = line_parity_prime;
+}
+
+int yaffs_ecc_correct_other(unsigned char *data, unsigned n_bytes,
+			    struct yaffs_ecc_other *read_ecc,
+			    const struct yaffs_ecc_other *test_ecc)
+{
+	unsigned char delta_col;	/* column parity delta */
+	unsigned delta_line;	/* line parity delta */
+	unsigned delta_line_prime;	/* line parity delta */
+	unsigned bit;
+
+	delta_col = read_ecc->col_parity ^ test_ecc->col_parity;
+	delta_line = read_ecc->line_parity ^ test_ecc->line_parity;
+	delta_line_prime =
+	    read_ecc->line_parity_prime ^ test_ecc->line_parity_prime;
+
+	if ((delta_col | delta_line | delta_line_prime) == 0)
+		return 0;	/* no error */
+
+	if (delta_line == ~delta_line_prime &&
+	    (((delta_col ^ (delta_col >> 1)) & 0x15) == 0x15)) {
+		/* Single bit (recoverable) error in data */
+
+		bit = 0;
+
+		if (delta_col & 0x20)
+			bit |= 0x04;
+		if (delta_col & 0x08)
+			bit |= 0x02;
+		if (delta_col & 0x02)
+			bit |= 0x01;
+
+		if (delta_line >= n_bytes)
+			return -1;
+
+		data[delta_line] ^= (1 << bit);
+
+		return 1;	/* corrected */
+	}
+
+	if ((hweight32(delta_line) +
+	     hweight32(delta_line_prime) +
+	     hweight8(delta_col)) == 1) {
+		/* Reccoverable error in ecc */
+
+		*read_ecc = *test_ecc;
+		return 1;	/* corrected */
+	}
+
+	/* Unrecoverable error */
+
+	return -1;
+}
diff --git a/fs/yaffs2/yaffs_ecc.h b/fs/yaffs2/yaffs_ecc.h
new file mode 100644
index 0000000..17d47bd
--- /dev/null
+++ b/fs/yaffs2/yaffs_ecc.h
@@ -0,0 +1,44 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+/*
+ * This code implements the ECC algorithm used in SmartMedia.
+ *
+ * The ECC comprises 22 bits of parity information and is stuffed into 3 bytes.
+ * The two unused bit are set to 1.
+ * The ECC can correct single bit errors in a 256-byte page of data.
+ * Thus, two such ECC blocks are used on a 512-byte NAND page.
+ *
+ */
+
+#ifndef __YAFFS_ECC_H__
+#define __YAFFS_ECC_H__
+
+struct yaffs_ecc_other {
+	unsigned char col_parity;
+	unsigned line_parity;
+	unsigned line_parity_prime;
+};
+
+void yaffs_ecc_calc(const unsigned char *data, unsigned char *ecc);
+int yaffs_ecc_correct(unsigned char *data, unsigned char *read_ecc,
+		      const unsigned char *test_ecc);
+
+void yaffs_ecc_calc_other(const unsigned char *data, unsigned n_bytes,
+			  struct yaffs_ecc_other *ecc);
+int yaffs_ecc_correct_other(unsigned char *data, unsigned n_bytes,
+			    struct yaffs_ecc_other *read_ecc,
+			    const struct yaffs_ecc_other *test_ecc);
+#endif
diff --git a/fs/yaffs2/yaffs_endian.c b/fs/yaffs2/yaffs_endian.c
new file mode 100644
index 0000000..8c291ad
--- /dev/null
+++ b/fs/yaffs2/yaffs_endian.c
@@ -0,0 +1,106 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * Endian processing functions.
+ */
+
+#include "yaffs_endian.h"
+#include "yaffs_guts.h"
+
+
+void yaffs_do_endian_u32(struct yaffs_dev *dev, u32 *val)
+{
+	if (!dev->swap_endian)
+		return;
+	*val = swap_u32(*val);
+}
+
+void yaffs_do_endian_s32(struct yaffs_dev *dev, s32 *val)
+{
+	if (!dev->swap_endian)
+		return;
+	*val = swap_s32(*val);
+}
+
+void yaffs_do_endian_oh(struct yaffs_dev *dev, struct yaffs_obj_hdr *oh)
+{
+	if (!dev->swap_endian)
+		return;
+	/* Change every field */
+	oh->type = swap_u32(oh->type);
+	oh->parent_obj_id = swap_u32(oh->parent_obj_id);
+
+	oh->yst_mode = swap_u32(oh->yst_mode);
+
+	oh->yst_uid = swap_u32(oh->yst_uid);
+	oh->yst_gid = swap_u32(oh->yst_gid);
+	oh->yst_atime = swap_u32(oh->yst_atime);
+	oh->yst_mtime = swap_u32(oh->yst_mtime);
+	oh->yst_ctime = swap_u32(oh->yst_ctime);
+
+	oh->file_size_low = swap_u32(oh->file_size_low);
+
+	oh->equiv_id = swap_u32(oh->equiv_id);
+
+	oh->yst_rdev = swap_u32(oh->yst_rdev);
+
+	oh->win_ctime[0] = swap_u32(oh->win_ctime[0]);
+	oh->win_ctime[1] = swap_u32(oh->win_ctime[1]);
+	oh->win_atime[0] = swap_u32(oh->win_atime[0]);
+	oh->win_atime[1] = swap_u32(oh->win_atime[1]);
+	oh->win_mtime[0] = swap_u32(oh->win_mtime[0]);
+	oh->win_mtime[1] = swap_u32(oh->win_mtime[1]);
+
+	oh->inband_shadowed_obj_id = swap_u32(oh->inband_shadowed_obj_id);
+	oh->inband_is_shrink = swap_u32(oh->inband_is_shrink);
+
+	oh->file_size_high = swap_u32(oh->file_size_high);
+	oh->reserved[0] = swap_u32(oh->reserved[0]);
+	oh->shadows_obj = swap_s32(oh->shadows_obj);
+
+	oh->is_shrink = swap_u32(oh->is_shrink);
+}
+
+
+void yaffs_do_endian_packed_tags2(struct yaffs_dev *dev,
+				struct yaffs_packed_tags2_tags_only *ptt)
+{
+	if (!dev->swap_endian)
+		return;
+	ptt->seq_number = swap_u32(ptt->seq_number);
+	ptt->obj_id = swap_u32(ptt->obj_id);
+	ptt->chunk_id = swap_u32(ptt->chunk_id);
+	ptt->n_bytes = swap_u32(ptt->n_bytes);
+}
+
+void yaffs_endian_config(struct yaffs_dev *dev)
+{
+	u32 x = 1;
+
+	if (dev->tnode_size < 1)
+		BUG();
+
+	dev->swap_endian = 0;
+
+	if (((char *)&x)[0] == 1) {
+		/* Little Endian. */
+		if (dev->param.stored_endian == 2 /* big endian */)
+			dev->swap_endian = 1;
+	} else  {
+		/* Big Endian. */
+		if (dev->param.stored_endian == 1 /* little endian */)
+			dev->swap_endian = 1;
+	}
+
+	if (dev->swap_endian)
+		dev->tn_swap_buffer = kmalloc(dev->tnode_size, GFP_NOFS);
+}
diff --git a/fs/yaffs2/yaffs_endian.h b/fs/yaffs2/yaffs_endian.h
new file mode 100644
index 0000000..e2fc602
--- /dev/null
+++ b/fs/yaffs2/yaffs_endian.h
@@ -0,0 +1,55 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_ENDIAN_H__
+#define __YAFFS_ENDIAN_H__
+#include "yaffs_guts.h"
+#include "yaffs_packedtags2.h"
+
+static inline u32 swap_u32(u32 val)
+{
+	return ((val >>24) & 0x000000ff) |
+	       ((val >> 8) & 0x0000ff00) |
+	       ((val << 8) & 0x00ff0000) |
+	       ((val <<24) & 0xff000000);
+}
+
+#define swap_s32(val) \
+	(s32)(swap_u32((u32)(val)))
+
+static inline loff_t swap_loff_t(loff_t lval)
+{
+	u32 vall = swap_u32(FSIZE_LOW(lval));
+	u32 valh;
+
+	if (sizeof(loff_t) == sizeof(u32))
+		return (loff_t) vall;
+
+	valh = swap_u32(FSIZE_HIGH(lval));
+
+	return FSIZE_COMBINE(vall, valh); /*NB: h and l are swapped. */
+}
+
+
+
+struct yaffs_dev;
+void yaffs_do_endian_s32(struct yaffs_dev *dev, s32 *val);
+void yaffs_do_endian_u32(struct yaffs_dev *dev, u32 *val);
+void yaffs_do_endian_oh(struct yaffs_dev *dev, struct yaffs_obj_hdr *oh);
+void yaffs_do_endian_packed_tags2(struct yaffs_dev *dev,
+				struct yaffs_packed_tags2_tags_only *ptt);
+void yaffs_endian_config(struct yaffs_dev *dev);
+
+#endif
diff --git a/fs/yaffs2/yaffs_getblockinfo.h b/fs/yaffs2/yaffs_getblockinfo.h
new file mode 100644
index 0000000..09b5a16
--- /dev/null
+++ b/fs/yaffs2/yaffs_getblockinfo.h
@@ -0,0 +1,36 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_GETBLOCKINFO_H__
+#define __YAFFS_GETBLOCKINFO_H__
+
+#include "yaffs_guts.h"
+#include "yaffs_trace.h"
+
+/* Function to manipulate block info */
+static inline struct yaffs_block_info *yaffs_get_block_info(struct yaffs_dev
+							      *dev, int blk)
+{
+	if (blk < (int)dev->internal_start_block ||
+	    blk > (int)dev->internal_end_block) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"**>> yaffs: get_block_info block %d is not valid",
+			blk);
+		BUG();
+	}
+	return &dev->block_info[blk - dev->internal_start_block];
+}
+
+#endif
diff --git a/fs/yaffs2/yaffs_guts.c b/fs/yaffs2/yaffs_guts.c
new file mode 100644
index 0000000..ef2deb6
--- /dev/null
+++ b/fs/yaffs2/yaffs_guts.c
@@ -0,0 +1,5215 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include "yportenv.h"
+#include "yaffs_trace.h"
+
+#include "yaffs_guts.h"
+#include "yaffs_endian.h"
+#include "yaffs_getblockinfo.h"
+#include "yaffs_tagscompat.h"
+#include "yaffs_tagsmarshall.h"
+#include "yaffs_nand.h"
+#include "yaffs_yaffs1.h"
+#include "yaffs_yaffs2.h"
+#include "yaffs_bitmap.h"
+#include "yaffs_verify.h"
+#include "yaffs_nand.h"
+#include "yaffs_packedtags2.h"
+#include "yaffs_nameval.h"
+#include "yaffs_allocator.h"
+#include "yaffs_attribs.h"
+#include "yaffs_summary.h"
+
+/* Note YAFFS_GC_GOOD_ENOUGH must be <= YAFFS_GC_PASSIVE_THRESHOLD */
+#define YAFFS_GC_GOOD_ENOUGH 2
+#define YAFFS_GC_PASSIVE_THRESHOLD 4
+
+#include "yaffs_ecc.h"
+
+/* Forward declarations */
+
+static int yaffs_wr_data_obj(struct yaffs_obj *in, int inode_chunk,
+			     const u8 *buffer, int n_bytes, int use_reserve);
+
+static void yaffs_fix_null_name(struct yaffs_obj *obj, YCHAR *name,
+				int buffer_size);
+
+/* Function to calculate chunk and offset */
+
+void yaffs_addr_to_chunk(struct yaffs_dev *dev, loff_t addr,
+				int *chunk_out, u32 *offset_out)
+{
+	int chunk;
+	u32 offset;
+
+	chunk = (u32) (addr >> dev->chunk_shift);
+
+	if (dev->chunk_div == 1) {
+		/* easy power of 2 case */
+		offset = (u32) (addr & dev->chunk_mask);
+	} else {
+		/* Non power-of-2 case */
+
+		loff_t chunk_base;
+
+		chunk /= dev->chunk_div;
+
+		chunk_base = ((loff_t) chunk) * dev->data_bytes_per_chunk;
+		offset = (u32) (addr - chunk_base);
+	}
+
+	*chunk_out = chunk;
+	*offset_out = offset;
+}
+
+/* Function to return the number of shifts for a power of 2 greater than or
+ * equal to the given number
+ * Note we don't try to cater for all possible numbers and this does not have to
+ * be hellishly efficient.
+ */
+
+static inline u32 calc_shifts_ceiling(u32 x)
+{
+	int extra_bits;
+	int shifts;
+
+	shifts = extra_bits = 0;
+
+	while (x > 1) {
+		if (x & 1)
+			extra_bits++;
+		x >>= 1;
+		shifts++;
+	}
+
+	if (extra_bits)
+		shifts++;
+
+	return shifts;
+}
+
+/* Function to return the number of shifts to get a 1 in bit 0
+ */
+
+static inline u32 calc_shifts(u32 x)
+{
+	u32 shifts;
+
+	shifts = 0;
+
+	if (!x)
+		return 0;
+
+	while (!(x & 1)) {
+		x >>= 1;
+		shifts++;
+	}
+
+	return shifts;
+}
+
+/*
+ * Temporary buffer manipulations.
+ */
+
+static int yaffs_init_tmp_buffers(struct yaffs_dev *dev)
+{
+	int i;
+	u8 *buf = (u8 *) 1;
+
+	memset(dev->temp_buffer, 0, sizeof(dev->temp_buffer));
+
+	for (i = 0; buf && i < YAFFS_N_TEMP_BUFFERS; i++) {
+		dev->temp_buffer[i].in_use = 0;
+		buf = kmalloc(dev->param.total_bytes_per_chunk, GFP_NOFS);
+		dev->temp_buffer[i].buffer = buf;
+	}
+
+	return buf ? YAFFS_OK : YAFFS_FAIL;
+}
+
+u8 *yaffs_get_temp_buffer(struct yaffs_dev * dev)
+{
+	int i;
+
+	dev->temp_in_use++;
+	if (dev->temp_in_use > dev->max_temp)
+		dev->max_temp = dev->temp_in_use;
+
+	for (i = 0; i < YAFFS_N_TEMP_BUFFERS; i++) {
+		if (dev->temp_buffer[i].in_use == 0) {
+			dev->temp_buffer[i].in_use = 1;
+			return dev->temp_buffer[i].buffer;
+		}
+	}
+
+	yaffs_trace(YAFFS_TRACE_BUFFERS, "Out of temp buffers");
+	/*
+	 * If we got here then we have to allocate an unmanaged one
+	 * This is not good.
+	 */
+
+	dev->unmanaged_buffer_allocs++;
+	return kmalloc(dev->data_bytes_per_chunk, GFP_NOFS);
+
+}
+
+void yaffs_release_temp_buffer(struct yaffs_dev *dev, u8 *buffer)
+{
+	int i;
+
+	dev->temp_in_use--;
+
+	for (i = 0; i < YAFFS_N_TEMP_BUFFERS; i++) {
+		if (dev->temp_buffer[i].buffer == buffer) {
+			dev->temp_buffer[i].in_use = 0;
+			return;
+		}
+	}
+
+	if (buffer) {
+		/* assume it is an unmanaged one. */
+		yaffs_trace(YAFFS_TRACE_BUFFERS,
+			"Releasing unmanaged temp buffer");
+		kfree(buffer);
+		dev->unmanaged_buffer_deallocs++;
+	}
+
+}
+
+/*
+ * Functions for robustisizing TODO
+ *
+ */
+
+static void yaffs_handle_chunk_wr_ok(struct yaffs_dev *dev, int nand_chunk,
+				     const u8 *data,
+				     const struct yaffs_ext_tags *tags)
+{
+	(void) dev;
+	(void) nand_chunk;
+	(void) data;
+	(void) tags;
+}
+
+static void yaffs_handle_chunk_update(struct yaffs_dev *dev, int nand_chunk,
+				      const struct yaffs_ext_tags *tags)
+{
+	(void) dev;
+	(void) nand_chunk;
+	(void) tags;
+}
+
+void yaffs_handle_chunk_error(struct yaffs_dev *dev,
+			      struct yaffs_block_info *bi)
+{
+	if (!bi->gc_prioritise) {
+		bi->gc_prioritise = 1;
+		dev->has_pending_prioritised_gc = 1;
+		bi->chunk_error_strikes++;
+
+		if (bi->chunk_error_strikes > 3) {
+			bi->needs_retiring = 1;	/* Too many stikes, so retire */
+			yaffs_trace(YAFFS_TRACE_ALWAYS,
+				"yaffs: Block struck out");
+
+		}
+	}
+}
+
+static void yaffs_handle_chunk_wr_error(struct yaffs_dev *dev, int nand_chunk,
+					int erased_ok)
+{
+	int flash_block = nand_chunk / dev->param.chunks_per_block;
+	struct yaffs_block_info *bi = yaffs_get_block_info(dev, flash_block);
+
+	yaffs_handle_chunk_error(dev, bi);
+
+	if (erased_ok) {
+		/* Was an actual write failure,
+		 * so mark the block for retirement.*/
+		bi->needs_retiring = 1;
+		yaffs_trace(YAFFS_TRACE_ERROR | YAFFS_TRACE_BAD_BLOCKS,
+		  "**>> Block %d needs retiring", flash_block);
+	}
+
+	/* Delete the chunk */
+	yaffs_chunk_del(dev, nand_chunk, 1, __LINE__);
+	yaffs_skip_rest_of_block(dev);
+}
+
+/*
+ * Verification code
+ */
+
+/*
+ *  Simple hash function. Needs to have a reasonable spread
+ */
+
+static inline int yaffs_hash_fn(int n)
+{
+	if (n < 0)
+		n = -n;
+	return n % YAFFS_NOBJECT_BUCKETS;
+}
+
+/*
+ * Access functions to useful fake objects.
+ * Note that root might have a presence in NAND if permissions are set.
+ */
+
+struct yaffs_obj *yaffs_root(struct yaffs_dev *dev)
+{
+	return dev->root_dir;
+}
+
+struct yaffs_obj *yaffs_lost_n_found(struct yaffs_dev *dev)
+{
+	return dev->lost_n_found;
+}
+
+/*
+ *  Erased NAND checking functions
+ */
+
+int yaffs_check_ff(u8 *buffer, int n_bytes)
+{
+	/* Horrible, slow implementation */
+	while (n_bytes--) {
+		if (*buffer != 0xff)
+			return 0;
+		buffer++;
+	}
+	return 1;
+}
+
+static int yaffs_check_chunk_erased(struct yaffs_dev *dev, int nand_chunk)
+{
+	int retval = YAFFS_OK;
+	u8 *data = yaffs_get_temp_buffer(dev);
+	struct yaffs_ext_tags tags;
+	int result;
+
+	result = yaffs_rd_chunk_tags_nand(dev, nand_chunk, data, &tags);
+
+	if (result == YAFFS_FAIL ||
+	    tags.ecc_result > YAFFS_ECC_RESULT_NO_ERROR)
+		retval = YAFFS_FAIL;
+
+	if (!yaffs_check_ff(data, dev->data_bytes_per_chunk) ||
+		tags.chunk_used) {
+		yaffs_trace(YAFFS_TRACE_NANDACCESS,
+			"Chunk %d not erased", nand_chunk);
+		retval = YAFFS_FAIL;
+	}
+
+	yaffs_release_temp_buffer(dev, data);
+
+	return retval;
+
+}
+
+static int yaffs_verify_chunk_written(struct yaffs_dev *dev,
+				      int nand_chunk,
+				      const u8 *data,
+				      struct yaffs_ext_tags *tags)
+{
+	int retval = YAFFS_OK;
+	struct yaffs_ext_tags temp_tags;
+	u8 *buffer = yaffs_get_temp_buffer(dev);
+	int result;
+
+	result = yaffs_rd_chunk_tags_nand(dev, nand_chunk, buffer, &temp_tags);
+	if (result == YAFFS_FAIL ||
+	    memcmp(buffer, data, dev->data_bytes_per_chunk) ||
+	    temp_tags.obj_id != tags->obj_id ||
+	    temp_tags.chunk_id != tags->chunk_id ||
+	    temp_tags.n_bytes != tags->n_bytes)
+		retval = YAFFS_FAIL;
+
+	yaffs_release_temp_buffer(dev, buffer);
+
+	return retval;
+}
+
+
+int yaffs_check_alloc_available(struct yaffs_dev *dev, int n_chunks)
+{
+	int reserved_chunks;
+	int reserved_blocks = dev->param.n_reserved_blocks;
+	int checkpt_blocks;
+
+	checkpt_blocks = yaffs_calc_checkpt_blocks_required(dev);
+
+	reserved_chunks =
+	    (reserved_blocks + checkpt_blocks) * dev->param.chunks_per_block;
+
+	return (dev->n_free_chunks > (reserved_chunks + n_chunks));
+}
+
+static int yaffs_find_alloc_block(struct yaffs_dev *dev)
+{
+	u32 i;
+	struct yaffs_block_info *bi;
+
+	if (dev->n_erased_blocks < 1) {
+		/* Hoosterman we've got a problem.
+		 * Can't get space to gc
+		 */
+		yaffs_trace(YAFFS_TRACE_ERROR,
+		  "yaffs tragedy: no more erased blocks");
+
+		return -1;
+	}
+
+	/* Find an empty block. */
+
+	for (i = dev->internal_start_block; i <= dev->internal_end_block; i++) {
+		dev->alloc_block_finder++;
+		if (dev->alloc_block_finder < (int)dev->internal_start_block
+		    || dev->alloc_block_finder > (int)dev->internal_end_block) {
+			dev->alloc_block_finder = dev->internal_start_block;
+		}
+
+		bi = yaffs_get_block_info(dev, dev->alloc_block_finder);
+
+		if (bi->block_state == YAFFS_BLOCK_STATE_EMPTY) {
+			bi->block_state = YAFFS_BLOCK_STATE_ALLOCATING;
+			dev->seq_number++;
+			bi->seq_number = dev->seq_number;
+			dev->n_erased_blocks--;
+			yaffs_trace(YAFFS_TRACE_ALLOCATE,
+			  "Allocated block %d, seq  %d, %d left" ,
+			   dev->alloc_block_finder, dev->seq_number,
+			   dev->n_erased_blocks);
+			return dev->alloc_block_finder;
+		}
+	}
+
+	yaffs_trace(YAFFS_TRACE_ALWAYS,
+		"yaffs tragedy: no more erased blocks, but there should have been %d",
+		dev->n_erased_blocks);
+
+	return -1;
+}
+
+static int yaffs_alloc_chunk(struct yaffs_dev *dev, int use_reserver,
+			     struct yaffs_block_info **block_ptr)
+{
+	int ret_val;
+	struct yaffs_block_info *bi;
+
+	if (dev->alloc_block < 0) {
+		/* Get next block to allocate off */
+		dev->alloc_block = yaffs_find_alloc_block(dev);
+		dev->alloc_page = 0;
+	}
+
+	if (!use_reserver && !yaffs_check_alloc_available(dev, 1)) {
+		/* No space unless we're allowed to use the reserve. */
+		return -1;
+	}
+
+	if (dev->n_erased_blocks < (int)dev->param.n_reserved_blocks
+	    && dev->alloc_page == 0)
+		yaffs_trace(YAFFS_TRACE_ALLOCATE, "Allocating reserve");
+
+	/* Next page please.... */
+	if (dev->alloc_block >= 0) {
+		bi = yaffs_get_block_info(dev, dev->alloc_block);
+
+		ret_val = (dev->alloc_block * dev->param.chunks_per_block) +
+		    dev->alloc_page;
+		bi->pages_in_use++;
+		yaffs_set_chunk_bit(dev, dev->alloc_block, dev->alloc_page);
+
+		dev->alloc_page++;
+
+		dev->n_free_chunks--;
+
+		/* If the block is full set the state to full */
+		if (dev->alloc_page >= dev->param.chunks_per_block) {
+			bi->block_state = YAFFS_BLOCK_STATE_FULL;
+			dev->alloc_block = -1;
+		}
+
+		if (block_ptr)
+			*block_ptr = bi;
+
+		return ret_val;
+	}
+
+	yaffs_trace(YAFFS_TRACE_ERROR,
+		"!!!!!!!!! Allocator out !!!!!!!!!!!!!!!!!");
+
+	return -1;
+}
+
+static int yaffs_get_erased_chunks(struct yaffs_dev *dev)
+{
+	int n;
+
+	n = dev->n_erased_blocks * dev->param.chunks_per_block;
+
+	if (dev->alloc_block > 0)
+		n += (dev->param.chunks_per_block - dev->alloc_page);
+
+	return n;
+
+}
+
+/*
+ * yaffs_skip_rest_of_block() skips over the rest of the allocation block
+ * if we don't want to write to it.
+ */
+void yaffs_skip_rest_of_block(struct yaffs_dev *dev)
+{
+	struct yaffs_block_info *bi;
+
+	if (dev->alloc_block > 0) {
+		bi = yaffs_get_block_info(dev, dev->alloc_block);
+		if (bi->block_state == YAFFS_BLOCK_STATE_ALLOCATING) {
+			bi->block_state = YAFFS_BLOCK_STATE_FULL;
+			dev->alloc_block = -1;
+		}
+	}
+}
+
+static int yaffs_write_new_chunk(struct yaffs_dev *dev,
+				 const u8 *data,
+				 struct yaffs_ext_tags *tags, int use_reserver)
+{
+	u32 attempts = 0;
+	int write_ok = 0;
+	int chunk;
+
+	yaffs2_checkpt_invalidate(dev);
+
+	do {
+		struct yaffs_block_info *bi = 0;
+		int erased_ok = 0;
+
+		chunk = yaffs_alloc_chunk(dev, use_reserver, &bi);
+		if (chunk < 0) {
+			/* no space */
+			break;
+		}
+
+		/* First check this chunk is erased, if it needs
+		 * checking.  The checking policy (unless forced
+		 * always on) is as follows:
+		 *
+		 * Check the first page we try to write in a block.
+		 * If the check passes then we don't need to check any
+		 * more.        If the check fails, we check again...
+		 * If the block has been erased, we don't need to check.
+		 *
+		 * However, if the block has been prioritised for gc,
+		 * then we think there might be something odd about
+		 * this block and stop using it.
+		 *
+		 * Rationale: We should only ever see chunks that have
+		 * not been erased if there was a partially written
+		 * chunk due to power loss.  This checking policy should
+		 * catch that case with very few checks and thus save a
+		 * lot of checks that are most likely not needed.
+		 *
+		 * Mods to the above
+		 * If an erase check fails or the write fails we skip the
+		 * rest of the block.
+		 */
+
+		/* let's give it a try */
+		attempts++;
+
+		if (dev->param.always_check_erased)
+			bi->skip_erased_check = 0;
+
+		if (!bi->skip_erased_check) {
+			erased_ok = yaffs_check_chunk_erased(dev, chunk);
+			if (erased_ok != YAFFS_OK) {
+				yaffs_trace(YAFFS_TRACE_ERROR,
+				  "**>> yaffs chunk %d was not erased",
+				  chunk);
+
+				/* If not erased, delete this one,
+				 * skip rest of block and
+				 * try another chunk */
+				yaffs_chunk_del(dev, chunk, 1, __LINE__);
+				yaffs_skip_rest_of_block(dev);
+				continue;
+			}
+		}
+
+		write_ok = yaffs_wr_chunk_tags_nand(dev, chunk, data, tags);
+
+		if (!bi->skip_erased_check)
+			write_ok =
+			    yaffs_verify_chunk_written(dev, chunk, data, tags);
+
+		if (write_ok != YAFFS_OK) {
+			/* Clean up aborted write, skip to next block and
+			 * try another chunk */
+			yaffs_handle_chunk_wr_error(dev, chunk, erased_ok);
+			continue;
+		}
+
+		bi->skip_erased_check = 1;
+
+		/* Copy the data into the robustification buffer */
+		yaffs_handle_chunk_wr_ok(dev, chunk, data, tags);
+
+	} while (write_ok != YAFFS_OK &&
+		 (yaffs_wr_attempts == 0 || attempts <= yaffs_wr_attempts));
+
+	if (!write_ok)
+		chunk = -1;
+
+	if (attempts > 1) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"**>> yaffs write required %d attempts",
+			attempts);
+		dev->n_retried_writes += (attempts - 1);
+	}
+
+	return chunk;
+}
+
+/*
+ * Block retiring for handling a broken block.
+ */
+
+static void yaffs_retire_block(struct yaffs_dev *dev, int flash_block)
+{
+	struct yaffs_block_info *bi = yaffs_get_block_info(dev, flash_block);
+
+	yaffs2_checkpt_invalidate(dev);
+
+	yaffs2_clear_oldest_dirty_seq(dev, bi);
+
+	if (yaffs_mark_bad(dev, flash_block) != YAFFS_OK) {
+		if (yaffs_erase_block(dev, flash_block) != YAFFS_OK) {
+			yaffs_trace(YAFFS_TRACE_ALWAYS,
+				"yaffs: Failed to mark bad and erase block %d",
+				flash_block);
+		} else {
+			struct yaffs_ext_tags tags;
+			int chunk_id =
+			    flash_block * dev->param.chunks_per_block;
+
+			u8 *buffer = yaffs_get_temp_buffer(dev);
+
+			memset(buffer, 0xff, dev->data_bytes_per_chunk);
+			memset(&tags, 0, sizeof(tags));
+			tags.seq_number = YAFFS_SEQUENCE_BAD_BLOCK;
+			if (dev->tagger.write_chunk_tags_fn(dev, chunk_id -
+							dev->chunk_offset,
+							buffer,
+							&tags) != YAFFS_OK)
+				yaffs_trace(YAFFS_TRACE_ALWAYS,
+					"yaffs: Failed to write bad block marker to block %d",
+					flash_block);
+
+			yaffs_release_temp_buffer(dev, buffer);
+		}
+	}
+
+	bi->block_state = YAFFS_BLOCK_STATE_DEAD;
+	bi->gc_prioritise = 0;
+	bi->needs_retiring = 0;
+
+	dev->n_retired_blocks++;
+}
+
+/*---------------- Name handling functions ------------*/
+
+static void yaffs_load_name_from_oh(struct yaffs_dev *dev, YCHAR *name,
+				    const YCHAR *oh_name, int buff_size)
+{
+#ifdef CONFIG_YAFFS_AUTO_UNICODE
+	if (dev->param.auto_unicode) {
+		if (*oh_name) {
+			/* It is an ASCII name, do an ASCII to
+			 * unicode conversion */
+			const char *ascii_oh_name = (const char *)oh_name;
+			int n = buff_size - 1;
+			while (n > 0 && *ascii_oh_name) {
+				*name = *ascii_oh_name;
+				name++;
+				ascii_oh_name++;
+				n--;
+			}
+		} else {
+			strncpy(name, oh_name + 1, buff_size - 1);
+		}
+	} else {
+#else
+	(void) dev;
+	{
+#endif
+		strncpy(name, oh_name, buff_size - 1);
+	}
+}
+
+static void yaffs_load_oh_from_name(struct yaffs_dev *dev, YCHAR *oh_name,
+				    const YCHAR *name)
+{
+#ifdef CONFIG_YAFFS_AUTO_UNICODE
+
+	int is_ascii;
+	const YCHAR *w;
+
+	if (dev->param.auto_unicode) {
+
+		is_ascii = 1;
+		w = name;
+
+		/* Figure out if the name will fit in ascii character set */
+		while (is_ascii && *w) {
+			if ((*w) & 0xff00)
+				is_ascii = 0;
+			w++;
+		}
+
+		if (is_ascii) {
+			/* It is an ASCII name, so convert unicode to ascii */
+			char *ascii_oh_name = (char *)oh_name;
+			int n = YAFFS_MAX_NAME_LENGTH - 1;
+			while (n > 0 && *name) {
+				*ascii_oh_name = *name;
+				name++;
+				ascii_oh_name++;
+				n--;
+			}
+		} else {
+			/* Unicode name, so save starting at the second YCHAR */
+			*oh_name = 0;
+			strncpy(oh_name + 1, name, YAFFS_MAX_NAME_LENGTH - 2);
+		}
+	} else {
+#else
+	dev = dev;
+	{
+#endif
+		strncpy(oh_name, name, YAFFS_MAX_NAME_LENGTH - 1);
+	}
+}
+
+static u16 yaffs_calc_name_sum(const YCHAR *name)
+{
+	u16 sum = 0;
+	u16 i = 1;
+
+	if (!name)
+		return 0;
+
+	while ((*name) && i < (YAFFS_MAX_NAME_LENGTH / 2)) {
+
+		/* 0x1f mask is case insensitive */
+		sum += ((*name) & 0x1f) * i;
+		i++;
+		name++;
+	}
+	return sum;
+}
+
+
+void yaffs_set_obj_name(struct yaffs_obj *obj, const YCHAR * name)
+{
+	memset(obj->short_name, 0, sizeof(obj->short_name));
+
+	if (name && !name[0]) {
+		yaffs_fix_null_name(obj, obj->short_name,
+				YAFFS_SHORT_NAME_LENGTH);
+		name = obj->short_name;
+	} else if (name &&
+		strnlen(name, YAFFS_SHORT_NAME_LENGTH + 1) <=
+		YAFFS_SHORT_NAME_LENGTH)  {
+		strcpy(obj->short_name, name);
+	}
+
+	obj->sum = yaffs_calc_name_sum(name);
+}
+
+void yaffs_set_obj_name_from_oh(struct yaffs_obj *obj,
+				const struct yaffs_obj_hdr *oh)
+{
+#ifdef CONFIG_YAFFS_AUTO_UNICODE
+	YCHAR tmp_name[YAFFS_MAX_NAME_LENGTH + 1];
+	memset(tmp_name, 0, sizeof(tmp_name));
+	yaffs_load_name_from_oh(obj->my_dev, tmp_name, oh->name,
+				YAFFS_MAX_NAME_LENGTH + 1);
+	yaffs_set_obj_name(obj, tmp_name);
+#else
+	yaffs_set_obj_name(obj, oh->name);
+#endif
+}
+
+loff_t yaffs_max_file_size(struct yaffs_dev *dev)
+{
+	if (sizeof(loff_t) < 8)
+		return YAFFS_MAX_FILE_SIZE_32;
+	else
+		return ((loff_t) YAFFS_MAX_CHUNK_ID) * dev->data_bytes_per_chunk;
+}
+
+/*-------------------- TNODES -------------------
+
+ * List of spare tnodes
+ * The list is hooked together using the first pointer
+ * in the tnode.
+ */
+
+struct yaffs_tnode *yaffs_get_tnode(struct yaffs_dev *dev)
+{
+	struct yaffs_tnode *tn = yaffs_alloc_raw_tnode(dev);
+
+	if (tn) {
+		memset(tn, 0, dev->tnode_size);
+		dev->n_tnodes++;
+	}
+
+	dev->checkpoint_blocks_required = 0;	/* force recalculation */
+
+	return tn;
+}
+
+/* FreeTnode frees up a tnode and puts it back on the free list */
+static void yaffs_free_tnode(struct yaffs_dev *dev, struct yaffs_tnode *tn)
+{
+	yaffs_free_raw_tnode(dev, tn);
+	dev->n_tnodes--;
+	dev->checkpoint_blocks_required = 0;	/* force recalculation */
+}
+
+static void yaffs_deinit_tnodes_and_objs(struct yaffs_dev *dev)
+{
+	yaffs_deinit_raw_tnodes_and_objs(dev);
+	dev->n_obj = 0;
+	dev->n_tnodes = 0;
+}
+
+static void yaffs_load_tnode_0(struct yaffs_dev *dev, struct yaffs_tnode *tn,
+			unsigned pos, unsigned val)
+{
+	u32 *map = (u32 *) tn;
+	u32 bit_in_map;
+	u32 bit_in_word;
+	u32 word_in_map;
+	u32 mask;
+
+	pos &= YAFFS_TNODES_LEVEL0_MASK;
+	val >>= dev->chunk_grp_bits;
+
+	bit_in_map = pos * dev->tnode_width;
+	word_in_map = bit_in_map / 32;
+	bit_in_word = bit_in_map & (32 - 1);
+
+	mask = dev->tnode_mask << bit_in_word;
+
+	map[word_in_map] &= ~mask;
+	map[word_in_map] |= (mask & (val << bit_in_word));
+
+	if (dev->tnode_width > (32 - bit_in_word)) {
+		bit_in_word = (32 - bit_in_word);
+		word_in_map++;
+		mask =
+		    dev->tnode_mask >> bit_in_word;
+		map[word_in_map] &= ~mask;
+		map[word_in_map] |= (mask & (val >> bit_in_word));
+	}
+}
+
+u32 yaffs_get_group_base(struct yaffs_dev *dev, struct yaffs_tnode *tn,
+			 unsigned pos)
+{
+	u32 *map = (u32 *) tn;
+	u32 bit_in_map;
+	u32 bit_in_word;
+	u32 word_in_map;
+	u32 val;
+
+	pos &= YAFFS_TNODES_LEVEL0_MASK;
+
+	bit_in_map = pos * dev->tnode_width;
+	word_in_map = bit_in_map / 32;
+	bit_in_word = bit_in_map & (32 - 1);
+
+	val = map[word_in_map] >> bit_in_word;
+
+	if (dev->tnode_width > (32 - bit_in_word)) {
+		bit_in_word = (32 - bit_in_word);
+		word_in_map++;
+		val |= (map[word_in_map] << bit_in_word);
+	}
+
+	val &= dev->tnode_mask;
+	val <<= dev->chunk_grp_bits;
+
+	return val;
+}
+
+/* ------------------- End of individual tnode manipulation -----------------*/
+
+/* ---------Functions to manipulate the look-up tree (made up of tnodes) ------
+ * The look up tree is represented by the top tnode and the number of top_level
+ * in the tree. 0 means only the level 0 tnode is in the tree.
+ */
+
+/* FindLevel0Tnode finds the level 0 tnode, if one exists. */
+struct yaffs_tnode *yaffs_find_tnode_0(struct yaffs_dev *dev,
+				       struct yaffs_file_var *file_struct,
+				       u32 chunk_id)
+{
+	struct yaffs_tnode *tn = file_struct->top;
+	u32 i;
+	int required_depth;
+	int level = file_struct->top_level;
+
+	(void) dev;
+
+	/* Check sane level and chunk Id */
+	if (level < 0 || level > YAFFS_TNODES_MAX_LEVEL)
+		return NULL;
+
+	if (chunk_id > YAFFS_MAX_CHUNK_ID)
+		return NULL;
+
+	/* First check we're tall enough (ie enough top_level) */
+
+	i = chunk_id >> YAFFS_TNODES_LEVEL0_BITS;
+	required_depth = 0;
+	while (i) {
+		i >>= YAFFS_TNODES_INTERNAL_BITS;
+		required_depth++;
+	}
+
+	if (required_depth > file_struct->top_level)
+		return NULL;	/* Not tall enough, so we can't find it */
+
+	/* Traverse down to level 0 */
+	while (level > 0 && tn) {
+		tn = tn->internal[(chunk_id >>
+				   (YAFFS_TNODES_LEVEL0_BITS +
+				    (level - 1) *
+				    YAFFS_TNODES_INTERNAL_BITS)) &
+				  YAFFS_TNODES_INTERNAL_MASK];
+		level--;
+	}
+
+	return tn;
+}
+
+/* add_find_tnode_0 finds the level 0 tnode if it exists,
+ * otherwise first expands the tree.
+ * This happens in two steps:
+ *  1. If the tree isn't tall enough, then make it taller.
+ *  2. Scan down the tree towards the level 0 tnode adding tnodes if required.
+ *
+ * Used when modifying the tree.
+ *
+ *  If the tn argument is NULL, then a fresh tnode will be added otherwise the
+ *  specified tn will be plugged into the ttree.
+ */
+
+struct yaffs_tnode *yaffs_add_find_tnode_0(struct yaffs_dev *dev,
+					   struct yaffs_file_var *file_struct,
+					   u32 chunk_id,
+					   struct yaffs_tnode *passed_tn)
+{
+	int required_depth;
+	int i;
+	int l;
+	struct yaffs_tnode *tn;
+	u32 x;
+
+	/* Check sane level and page Id */
+	if (file_struct->top_level < 0 ||
+	    file_struct->top_level > YAFFS_TNODES_MAX_LEVEL)
+		return NULL;
+
+	if (chunk_id > YAFFS_MAX_CHUNK_ID)
+		return NULL;
+
+	/* First check we're tall enough (ie enough top_level) */
+
+	x = chunk_id >> YAFFS_TNODES_LEVEL0_BITS;
+	required_depth = 0;
+	while (x) {
+		x >>= YAFFS_TNODES_INTERNAL_BITS;
+		required_depth++;
+	}
+
+	if (required_depth > file_struct->top_level) {
+		/* Not tall enough, gotta make the tree taller */
+		for (i = file_struct->top_level; i < required_depth; i++) {
+
+			tn = yaffs_get_tnode(dev);
+
+			if (tn) {
+				tn->internal[0] = file_struct->top;
+				file_struct->top = tn;
+				file_struct->top_level++;
+			} else {
+				yaffs_trace(YAFFS_TRACE_ERROR,
+					"yaffs: no more tnodes");
+				return NULL;
+			}
+		}
+	}
+
+	/* Traverse down to level 0, adding anything we need */
+
+	l = file_struct->top_level;
+	tn = file_struct->top;
+
+	if (l > 0) {
+		while (l > 0 && tn) {
+			x = (chunk_id >>
+			     (YAFFS_TNODES_LEVEL0_BITS +
+			      (l - 1) * YAFFS_TNODES_INTERNAL_BITS)) &
+			    YAFFS_TNODES_INTERNAL_MASK;
+
+			if ((l > 1) && !tn->internal[x]) {
+				/* Add missing non-level-zero tnode */
+				tn->internal[x] = yaffs_get_tnode(dev);
+				if (!tn->internal[x])
+					return NULL;
+			} else if (l == 1) {
+				/* Looking from level 1 at level 0 */
+				if (passed_tn) {
+					/* If we already have one, release it */
+					if (tn->internal[x])
+						yaffs_free_tnode(dev,
+							tn->internal[x]);
+					tn->internal[x] = passed_tn;
+
+				} else if (!tn->internal[x]) {
+					/* Don't have one, none passed in */
+					tn->internal[x] = yaffs_get_tnode(dev);
+					if (!tn->internal[x])
+						return NULL;
+				}
+			}
+
+			tn = tn->internal[x];
+			l--;
+		}
+	} else {
+		/* top is level 0 */
+		if (passed_tn) {
+			memcpy(tn, passed_tn,
+			       (dev->tnode_width * YAFFS_NTNODES_LEVEL0) / 8);
+			yaffs_free_tnode(dev, passed_tn);
+		}
+	}
+
+	return tn;
+}
+
+static int yaffs_tags_match(const struct yaffs_ext_tags *tags, int obj_id,
+			    int chunk_obj)
+{
+	return (tags->chunk_id == (u32)chunk_obj &&
+		tags->obj_id == (u32)obj_id &&
+		!tags->is_deleted) ? 1 : 0;
+
+}
+
+static int yaffs_find_chunk_in_group(struct yaffs_dev *dev, int the_chunk,
+					struct yaffs_ext_tags *tags, int obj_id,
+					int inode_chunk)
+{
+	int j;
+
+	for (j = 0; the_chunk && j < dev->chunk_grp_size; j++) {
+		if (yaffs_check_chunk_bit
+		    (dev, the_chunk / dev->param.chunks_per_block,
+		     the_chunk % dev->param.chunks_per_block)) {
+
+			if (dev->chunk_grp_size == 1)
+				return the_chunk;
+			else {
+				yaffs_rd_chunk_tags_nand(dev, the_chunk, NULL,
+							 tags);
+				if (yaffs_tags_match(tags,
+							obj_id, inode_chunk)) {
+					/* found it; */
+					return the_chunk;
+				}
+			}
+		}
+		the_chunk++;
+	}
+	return -1;
+}
+
+int yaffs_find_chunk_in_file(struct yaffs_obj *in, int inode_chunk,
+				    struct yaffs_ext_tags *tags)
+{
+	/*Get the Tnode, then get the level 0 offset chunk offset */
+	struct yaffs_tnode *tn;
+	int the_chunk = -1;
+	struct yaffs_ext_tags local_tags;
+	int ret_val = -1;
+	struct yaffs_dev *dev = in->my_dev;
+
+	if (!tags) {
+		/* Passed a NULL, so use our own tags space */
+		tags = &local_tags;
+	}
+
+	tn = yaffs_find_tnode_0(dev, &in->variant.file_variant, inode_chunk);
+
+	if (!tn)
+		return ret_val;
+
+	the_chunk = yaffs_get_group_base(dev, tn, inode_chunk);
+
+	ret_val = yaffs_find_chunk_in_group(dev, the_chunk, tags, in->obj_id,
+					      inode_chunk);
+	return ret_val;
+}
+
+static int yaffs_find_del_file_chunk(struct yaffs_obj *in, int inode_chunk,
+				     struct yaffs_ext_tags *tags)
+{
+	/* Get the Tnode, then get the level 0 offset chunk offset */
+	struct yaffs_tnode *tn;
+	int the_chunk = -1;
+	struct yaffs_ext_tags local_tags;
+	struct yaffs_dev *dev = in->my_dev;
+	int ret_val = -1;
+
+	if (!tags) {
+		/* Passed a NULL, so use our own tags space */
+		tags = &local_tags;
+	}
+
+	tn = yaffs_find_tnode_0(dev, &in->variant.file_variant, inode_chunk);
+
+	if (!tn)
+		return ret_val;
+
+	the_chunk = yaffs_get_group_base(dev, tn, inode_chunk);
+
+	ret_val = yaffs_find_chunk_in_group(dev, the_chunk, tags, in->obj_id,
+					      inode_chunk);
+
+	/* Delete the entry in the filestructure (if found) */
+	if (ret_val != -1)
+		yaffs_load_tnode_0(dev, tn, inode_chunk, 0);
+
+	return ret_val;
+}
+
+int yaffs_put_chunk_in_file(struct yaffs_obj *in, int inode_chunk,
+			    int nand_chunk, int in_scan)
+{
+	/* NB in_scan is zero unless scanning.
+	 * For forward scanning, in_scan is > 0;
+	 * for backward scanning in_scan is < 0
+	 *
+	 * nand_chunk = 0 is a dummy insert to make sure the tnodes are there.
+	 */
+
+	struct yaffs_tnode *tn;
+	struct yaffs_dev *dev = in->my_dev;
+	int existing_cunk;
+	struct yaffs_ext_tags existing_tags;
+	struct yaffs_ext_tags new_tags;
+	unsigned existing_serial, new_serial;
+
+	if (in->variant_type != YAFFS_OBJECT_TYPE_FILE) {
+		/* Just ignore an attempt at putting a chunk into a non-file
+		 * during scanning.
+		 * If it is not during Scanning then something went wrong!
+		 */
+		if (!in_scan) {
+			yaffs_trace(YAFFS_TRACE_ERROR,
+				"yaffs tragedy:attempt to put data chunk into a non-file"
+				);
+			BUG();
+		}
+
+		yaffs_chunk_del(dev, nand_chunk, 1, __LINE__);
+		return YAFFS_OK;
+	}
+
+	tn = yaffs_add_find_tnode_0(dev,
+				    &in->variant.file_variant,
+				    inode_chunk, NULL);
+	if (!tn)
+		return YAFFS_FAIL;
+
+	if (!nand_chunk)
+		/* Dummy insert, bail now */
+		return YAFFS_OK;
+
+	existing_cunk = yaffs_get_group_base(dev, tn, inode_chunk);
+
+	if (in_scan != 0) {
+		/* If we're scanning then we need to test for duplicates
+		 * NB This does not need to be efficient since it should only
+		 * happen when the power fails during a write, then only one
+		 * chunk should ever be affected.
+		 *
+		 * Correction for YAFFS2: This could happen quite a lot and we
+		 * need to think about efficiency! TODO
+		 * Update: For backward scanning we don't need to re-read tags
+		 * so this is quite cheap.
+		 */
+
+		if (existing_cunk > 0) {
+			/* NB Right now existing chunk will not be real
+			 * chunk_id if the chunk group size > 1
+			 * thus we have to do a FindChunkInFile to get the
+			 * real chunk id.
+			 *
+			 * We have a duplicate now we need to decide which
+			 * one to use:
+			 *
+			 * Backwards scanning YAFFS2: The old one is what
+			 * we use, dump the new one.
+			 * YAFFS1: Get both sets of tags and compare serial
+			 * numbers.
+			 */
+
+			if (in_scan > 0) {
+				/* Only do this for forward scanning */
+				yaffs_rd_chunk_tags_nand(dev,
+							 nand_chunk,
+							 NULL, &new_tags);
+
+				/* Do a proper find */
+				existing_cunk =
+				    yaffs_find_chunk_in_file(in, inode_chunk,
+							     &existing_tags);
+			}
+
+			if (existing_cunk <= 0) {
+				/*Hoosterman - how did this happen? */
+
+				yaffs_trace(YAFFS_TRACE_ERROR,
+					"yaffs tragedy: existing chunk < 0 in scan"
+					);
+
+			}
+
+			/* NB The deleted flags should be false, otherwise
+			 * the chunks will not be loaded during a scan
+			 */
+
+			if (in_scan > 0) {
+				new_serial = new_tags.serial_number;
+				existing_serial = existing_tags.serial_number;
+			}
+
+			if ((in_scan > 0) &&
+			    (existing_cunk <= 0 ||
+			     ((existing_serial + 1) & 3) == new_serial)) {
+				/* Forward scanning.
+				 * Use new
+				 * Delete the old one and drop through to
+				 * update the tnode
+				 */
+				yaffs_chunk_del(dev, existing_cunk, 1,
+						__LINE__);
+			} else {
+				/* Backward scanning or we want to use the
+				 * existing one
+				 * Delete the new one and return early so that
+				 * the tnode isn't changed
+				 */
+				yaffs_chunk_del(dev, nand_chunk, 1, __LINE__);
+				return YAFFS_OK;
+			}
+		}
+
+	}
+
+	if (existing_cunk == 0)
+		in->n_data_chunks++;
+
+	yaffs_load_tnode_0(dev, tn, inode_chunk, nand_chunk);
+
+	return YAFFS_OK;
+}
+
+static void yaffs_soft_del_chunk(struct yaffs_dev *dev, int chunk)
+{
+	struct yaffs_block_info *the_block;
+	unsigned block_no;
+
+	yaffs_trace(YAFFS_TRACE_DELETION, "soft delete chunk %d", chunk);
+
+	block_no = chunk / dev->param.chunks_per_block;
+	the_block = yaffs_get_block_info(dev, block_no);
+	if (the_block) {
+		the_block->soft_del_pages++;
+		dev->n_free_chunks++;
+		yaffs2_update_oldest_dirty_seq(dev, block_no, the_block);
+	}
+}
+
+/* SoftDeleteWorker scans backwards through the tnode tree and soft deletes all
+ * the chunks in the file.
+ * All soft deleting does is increment the block's softdelete count and pulls
+ * the chunk out of the tnode.
+ * Thus, essentially this is the same as DeleteWorker except that the chunks
+ * are soft deleted.
+ */
+
+static int yaffs_soft_del_worker(struct yaffs_obj *in, struct yaffs_tnode *tn,
+				 u32 level, int chunk_offset)
+{
+	int i;
+	int the_chunk;
+	int all_done = 1;
+	struct yaffs_dev *dev = in->my_dev;
+
+	if (!tn)
+		return 1;
+
+	if (level > 0) {
+		for (i = YAFFS_NTNODES_INTERNAL - 1;
+			all_done && i >= 0;
+			i--) {
+			if (tn->internal[i]) {
+				all_done =
+				    yaffs_soft_del_worker(in,
+					tn->internal[i],
+					level - 1,
+					(chunk_offset <<
+					YAFFS_TNODES_INTERNAL_BITS)
+					+ i);
+				if (all_done) {
+					yaffs_free_tnode(dev,
+						tn->internal[i]);
+					tn->internal[i] = NULL;
+				} else {
+					/* Can this happen? */
+				}
+			}
+		}
+		return (all_done) ? 1 : 0;
+	}
+
+	/* level 0 */
+	 for (i = YAFFS_NTNODES_LEVEL0 - 1; i >= 0; i--) {
+		the_chunk = yaffs_get_group_base(dev, tn, i);
+		if (the_chunk) {
+			yaffs_soft_del_chunk(dev, the_chunk);
+			yaffs_load_tnode_0(dev, tn, i, 0);
+		}
+	}
+	return 1;
+}
+
+static void yaffs_remove_obj_from_dir(struct yaffs_obj *obj)
+{
+	struct yaffs_dev *dev = obj->my_dev;
+	struct yaffs_obj *parent;
+
+	yaffs_verify_obj_in_dir(obj);
+	parent = obj->parent;
+
+	yaffs_verify_dir(parent);
+
+	if (dev && dev->param.remove_obj_fn)
+		dev->param.remove_obj_fn(obj);
+
+	list_del_init(&obj->siblings);
+	obj->parent = NULL;
+
+	yaffs_verify_dir(parent);
+}
+
+void yaffs_add_obj_to_dir(struct yaffs_obj *directory, struct yaffs_obj *obj)
+{
+	if (!directory) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"tragedy: Trying to add an object to a null pointer directory"
+			);
+		BUG();
+		return;
+	}
+	if (directory->variant_type != YAFFS_OBJECT_TYPE_DIRECTORY) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"tragedy: Trying to add an object to a non-directory"
+			);
+		BUG();
+	}
+
+	if (obj->siblings.prev == NULL) {
+		/* Not initialised */
+		BUG();
+	}
+
+	yaffs_verify_dir(directory);
+
+	yaffs_remove_obj_from_dir(obj);
+
+	/* Now add it */
+	list_add(&obj->siblings, &directory->variant.dir_variant.children);
+	obj->parent = directory;
+
+	if (directory == obj->my_dev->unlinked_dir
+	    || directory == obj->my_dev->del_dir) {
+		obj->unlinked = 1;
+		obj->my_dev->n_unlinked_files++;
+		obj->rename_allowed = 0;
+	}
+
+	yaffs_verify_dir(directory);
+	yaffs_verify_obj_in_dir(obj);
+}
+
+static int yaffs_change_obj_name(struct yaffs_obj *obj,
+				 struct yaffs_obj *new_dir,
+				 const YCHAR *new_name, int force, int shadows)
+{
+	int unlink_op;
+	int del_op;
+	struct yaffs_obj *existing_target;
+
+	if (new_dir == NULL)
+		new_dir = obj->parent;	/* use the old directory */
+
+	if (new_dir->variant_type != YAFFS_OBJECT_TYPE_DIRECTORY) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"tragedy: yaffs_change_obj_name: new_dir is not a directory"
+			);
+		BUG();
+	}
+
+	unlink_op = (new_dir == obj->my_dev->unlinked_dir);
+	del_op = (new_dir == obj->my_dev->del_dir);
+
+	existing_target = yaffs_find_by_name(new_dir, new_name);
+
+	/* If the object is a file going into the unlinked directory,
+	 *   then it is OK to just stuff it in since duplicate names are OK.
+	 *   else only proceed if the new name does not exist and we're putting
+	 *   it into a directory.
+	 */
+	if (!(unlink_op || del_op || force ||
+	      shadows > 0 || !existing_target) ||
+	      new_dir->variant_type != YAFFS_OBJECT_TYPE_DIRECTORY)
+		return YAFFS_FAIL;
+
+	yaffs_set_obj_name(obj, new_name);
+	obj->dirty = 1;
+	yaffs_add_obj_to_dir(new_dir, obj);
+
+	if (unlink_op)
+		obj->unlinked = 1;
+
+	/* If it is a deletion then we mark it as a shrink for gc  */
+	if (yaffs_update_oh(obj, new_name, 0, del_op, shadows, NULL) >= 0)
+		return YAFFS_OK;
+
+	return YAFFS_FAIL;
+}
+
+/*------------------------ Short Operations Cache ------------------------------
+ *   In many situations where there is no high level buffering  a lot of
+ *   reads might be short sequential reads, and a lot of writes may be short
+ *   sequential writes. eg. scanning/writing a jpeg file.
+ *   In these cases, a short read/write cache can provide a huge perfomance
+ *   benefit with dumb-as-a-rock code.
+ *   In Linux, the page cache provides read buffering and the short op cache
+ *   provides write buffering.
+ *
+ *   There are a small number (~10) of cache chunks per device so that we don't
+ *   need a very intelligent search.
+ */
+
+static int yaffs_obj_cache_dirty(struct yaffs_obj *obj)
+{
+	struct yaffs_dev *dev = obj->my_dev;
+	int i;
+	struct yaffs_cache *cache;
+	int n_caches = obj->my_dev->param.n_caches;
+
+	for (i = 0; i < n_caches; i++) {
+		cache = &dev->cache[i];
+		if (cache->object == obj && cache->dirty)
+			return 1;
+	}
+
+	return 0;
+}
+
+static void yaffs_flush_single_cache(struct yaffs_cache *cache, int discard)
+{
+
+	if (!cache || cache->locked)
+		return;
+
+	/* Write it out and free it up  if need be.*/
+	if (cache->dirty) {
+		yaffs_wr_data_obj(cache->object,
+				  cache->chunk_id,
+				  cache->data,
+				  cache->n_bytes,
+				  1);
+
+		cache->dirty = 0;
+	}
+
+	if (discard)
+		cache->object = NULL;
+}
+
+static void yaffs_flush_file_cache(struct yaffs_obj *obj, int discard)
+{
+	struct yaffs_dev *dev = obj->my_dev;
+	int i;
+	struct yaffs_cache *cache;
+	int n_caches = obj->my_dev->param.n_caches;
+
+	if (n_caches < 1)
+		return;
+
+
+	/* Find the chunks for this object and flush them. */
+	for (i = 0; i < n_caches; i++) {
+		cache = &dev->cache[i];
+		if (cache->object == obj)
+			yaffs_flush_single_cache(cache, discard);
+	}
+
+}
+
+
+void yaffs_flush_whole_cache(struct yaffs_dev *dev, int discard)
+{
+	struct yaffs_obj *obj;
+	int n_caches = dev->param.n_caches;
+	int i;
+
+	/* Find a dirty object in the cache and flush it...
+	 * until there are no further dirty objects.
+	 */
+	do {
+		obj = NULL;
+		for (i = 0; i < n_caches && !obj; i++) {
+			if (dev->cache[i].object && dev->cache[i].dirty)
+				obj = dev->cache[i].object;
+		}
+		if (obj)
+			yaffs_flush_file_cache(obj, discard);
+	} while (obj);
+
+}
+
+/* Grab us an unused cache chunk for use.
+ * First look for an empty one.
+ * Then look for the least recently used non-dirty one.
+ * Then look for the least recently used dirty one...., flush and look again.
+ */
+static struct yaffs_cache *yaffs_grab_chunk_worker(struct yaffs_dev *dev)
+{
+	u32 i;
+
+	if (dev->param.n_caches > 0) {
+		for (i = 0; i < dev->param.n_caches; i++) {
+			if (!dev->cache[i].object)
+				return &dev->cache[i];
+		}
+	}
+
+	return NULL;
+}
+
+static struct yaffs_cache *yaffs_grab_chunk_cache(struct yaffs_dev *dev)
+{
+	struct yaffs_cache *cache;
+	int usage;
+	u32 i;
+
+	if (dev->param.n_caches < 1)
+		return NULL;
+
+	/* First look for an unused cache */
+
+	cache = yaffs_grab_chunk_worker(dev);
+
+	if (cache)
+		return cache;
+
+	/*
+	 * Thery were all in use.
+	 * Find the LRU cache and flush it if it is dirty.
+	 */
+
+	usage = -1;
+	cache = NULL;
+
+	for (i = 0; i < dev->param.n_caches; i++) {
+		if (dev->cache[i].object &&
+		    !dev->cache[i].locked &&
+		    (dev->cache[i].last_use < usage || !cache)) {
+				usage = dev->cache[i].last_use;
+				cache = &dev->cache[i];
+		}
+	}
+
+#if 1
+	yaffs_flush_single_cache(cache, 1);
+#else
+	yaffs_flush_file_cache(cache->object, 1);
+	cache = yaffs_grab_chunk_worker(dev);
+#endif
+
+	return cache;
+}
+
+/* Find a cached chunk */
+static struct yaffs_cache *yaffs_find_chunk_cache(const struct yaffs_obj *obj,
+						  int chunk_id)
+{
+	struct yaffs_dev *dev = obj->my_dev;
+	u32 i;
+
+	if (dev->param.n_caches < 1)
+		return NULL;
+
+	for (i = 0; i < dev->param.n_caches; i++) {
+		if (dev->cache[i].object == obj &&
+		    dev->cache[i].chunk_id == chunk_id) {
+			dev->cache_hits++;
+
+			return &dev->cache[i];
+		}
+	}
+	return NULL;
+}
+
+/* Mark the chunk for the least recently used algorithym */
+static void yaffs_use_cache(struct yaffs_dev *dev, struct yaffs_cache *cache,
+			    int is_write)
+{
+	u32 i;
+
+	if (dev->param.n_caches < 1)
+		return;
+
+	if (dev->cache_last_use < 0 ||
+		dev->cache_last_use > 100000000) {
+		/* Reset the cache usages */
+		for (i = 1; i < dev->param.n_caches; i++)
+			dev->cache[i].last_use = 0;
+
+		dev->cache_last_use = 0;
+	}
+	dev->cache_last_use++;
+	cache->last_use = dev->cache_last_use;
+
+	if (is_write)
+		cache->dirty = 1;
+}
+
+/* Invalidate a single cache page.
+ * Do this when a whole page gets written,
+ * ie the short cache for this page is no longer valid.
+ */
+static void yaffs_invalidate_chunk_cache(struct yaffs_obj *object, int chunk_id)
+{
+	struct yaffs_cache *cache;
+
+	if (object->my_dev->param.n_caches > 0) {
+		cache = yaffs_find_chunk_cache(object, chunk_id);
+
+		if (cache)
+			cache->object = NULL;
+	}
+}
+
+/* Invalidate all the cache pages associated with this object
+ * Do this whenever ther file is deleted or resized.
+ */
+static void yaffs_invalidate_whole_cache(struct yaffs_obj *in)
+{
+	u32 i;
+	struct yaffs_dev *dev = in->my_dev;
+
+	if (dev->param.n_caches > 0) {
+		/* Invalidate it. */
+		for (i = 0; i < dev->param.n_caches; i++) {
+			if (dev->cache[i].object == in)
+				dev->cache[i].object = NULL;
+		}
+	}
+}
+
+static void yaffs_unhash_obj(struct yaffs_obj *obj)
+{
+	int bucket;
+	struct yaffs_dev *dev = obj->my_dev;
+
+	/* If it is still linked into the bucket list, free from the list */
+	if (!list_empty(&obj->hash_link)) {
+		list_del_init(&obj->hash_link);
+		bucket = yaffs_hash_fn(obj->obj_id);
+		dev->obj_bucket[bucket].count--;
+	}
+}
+
+/*  FreeObject frees up a Object and puts it back on the free list */
+static void yaffs_free_obj(struct yaffs_obj *obj)
+{
+	struct yaffs_dev *dev;
+
+	if (!obj) {
+		BUG();
+		return;
+	}
+	dev = obj->my_dev;
+	yaffs_trace(YAFFS_TRACE_OS, "FreeObject %p inode %p",
+		obj, obj->my_inode);
+	if (obj->parent)
+		BUG();
+	if (!list_empty(&obj->siblings))
+		BUG();
+
+	if (obj->my_inode) {
+		/* We're still hooked up to a cached inode.
+		 * Don't delete now, but mark for later deletion
+		 */
+		obj->defered_free = 1;
+		return;
+	}
+
+	yaffs_unhash_obj(obj);
+
+	yaffs_free_raw_obj(dev, obj);
+	dev->n_obj--;
+	dev->checkpoint_blocks_required = 0;	/* force recalculation */
+}
+
+void yaffs_handle_defered_free(struct yaffs_obj *obj)
+{
+	if (obj->defered_free)
+		yaffs_free_obj(obj);
+}
+
+static int yaffs_generic_obj_del(struct yaffs_obj *in)
+{
+	/* Iinvalidate the file's data in the cache, without flushing. */
+	yaffs_invalidate_whole_cache(in);
+
+	if (in->my_dev->param.is_yaffs2 && in->parent != in->my_dev->del_dir) {
+		/* Move to unlinked directory so we have a deletion record */
+		yaffs_change_obj_name(in, in->my_dev->del_dir, _Y("deleted"), 0,
+				      0);
+	}
+
+	yaffs_remove_obj_from_dir(in);
+	yaffs_chunk_del(in->my_dev, in->hdr_chunk, 1, __LINE__);
+	in->hdr_chunk = 0;
+
+	yaffs_free_obj(in);
+	return YAFFS_OK;
+
+}
+
+static void yaffs_soft_del_file(struct yaffs_obj *obj)
+{
+	if (!obj->deleted ||
+	    obj->variant_type != YAFFS_OBJECT_TYPE_FILE ||
+	    obj->soft_del)
+		return;
+
+	if (obj->n_data_chunks <= 0) {
+		/* Empty file with no duplicate object headers,
+		 * just delete it immediately */
+		yaffs_free_tnode(obj->my_dev, obj->variant.file_variant.top);
+		obj->variant.file_variant.top = NULL;
+		yaffs_trace(YAFFS_TRACE_TRACING,
+			"yaffs: Deleting empty file %d",
+			obj->obj_id);
+		yaffs_generic_obj_del(obj);
+	} else {
+		yaffs_soft_del_worker(obj,
+				      obj->variant.file_variant.top,
+				      obj->variant.
+				      file_variant.top_level, 0);
+		obj->soft_del = 1;
+	}
+}
+
+/* Pruning removes any part of the file structure tree that is beyond the
+ * bounds of the file (ie that does not point to chunks).
+ *
+ * A file should only get pruned when its size is reduced.
+ *
+ * Before pruning, the chunks must be pulled from the tree and the
+ * level 0 tnode entries must be zeroed out.
+ * Could also use this for file deletion, but that's probably better handled
+ * by a special case.
+ *
+ * This function is recursive. For levels > 0 the function is called again on
+ * any sub-tree. For level == 0 we just check if the sub-tree has data.
+ * If there is no data in a subtree then it is pruned.
+ */
+
+static struct yaffs_tnode *yaffs_prune_worker(struct yaffs_dev *dev,
+					      struct yaffs_tnode *tn, u32 level,
+					      int del0)
+{
+	int i;
+	int has_data;
+
+	if (!tn)
+		return tn;
+
+	has_data = 0;
+
+	if (level > 0) {
+		for (i = 0; i < YAFFS_NTNODES_INTERNAL; i++) {
+			if (tn->internal[i]) {
+				tn->internal[i] =
+				    yaffs_prune_worker(dev,
+						tn->internal[i],
+						level - 1,
+						(i == 0) ? del0 : 1);
+			}
+
+			if (tn->internal[i])
+				has_data++;
+		}
+	} else {
+		int tnode_size_u32 = dev->tnode_size / sizeof(u32);
+		u32 *map = (u32 *) tn;
+
+		for (i = 0; !has_data && i < tnode_size_u32; i++) {
+			if (map[i])
+				has_data++;
+		}
+	}
+
+	if (has_data == 0 && del0) {
+		/* Free and return NULL */
+		yaffs_free_tnode(dev, tn);
+		tn = NULL;
+	}
+	return tn;
+}
+
+static int yaffs_prune_tree(struct yaffs_dev *dev,
+			    struct yaffs_file_var *file_struct)
+{
+	int i;
+	int has_data;
+	int done = 0;
+	struct yaffs_tnode *tn;
+
+	if (file_struct->top_level < 1)
+		return YAFFS_OK;
+
+	file_struct->top =
+	   yaffs_prune_worker(dev, file_struct->top, file_struct->top_level, 0);
+
+	/* Now we have a tree with all the non-zero branches NULL but
+	 * the height is the same as it was.
+	 * Let's see if we can trim internal tnodes to shorten the tree.
+	 * We can do this if only the 0th element in the tnode is in use
+	 * (ie all the non-zero are NULL)
+	 */
+
+	while (file_struct->top_level && !done) {
+		tn = file_struct->top;
+
+		has_data = 0;
+		for (i = 1; i < YAFFS_NTNODES_INTERNAL; i++) {
+			if (tn->internal[i])
+				has_data++;
+		}
+
+		if (!has_data) {
+			file_struct->top = tn->internal[0];
+			file_struct->top_level--;
+			yaffs_free_tnode(dev, tn);
+		} else {
+			done = 1;
+		}
+	}
+
+	return YAFFS_OK;
+}
+
+/*-------------------- End of File Structure functions.-------------------*/
+
+/* alloc_empty_obj gets us a clean Object.*/
+static struct yaffs_obj *yaffs_alloc_empty_obj(struct yaffs_dev *dev)
+{
+	struct yaffs_obj *obj = yaffs_alloc_raw_obj(dev);
+
+	if (!obj)
+		return obj;
+
+	dev->n_obj++;
+
+	/* Now sweeten it up... */
+
+	memset(obj, 0, sizeof(struct yaffs_obj));
+	obj->being_created = 1;
+
+	obj->my_dev = dev;
+	obj->hdr_chunk = 0;
+	obj->variant_type = YAFFS_OBJECT_TYPE_UNKNOWN;
+	INIT_LIST_HEAD(&(obj->hard_links));
+	INIT_LIST_HEAD(&(obj->hash_link));
+	INIT_LIST_HEAD(&obj->siblings);
+
+	/* Now make the directory sane */
+	if (dev->root_dir) {
+		obj->parent = dev->root_dir;
+		list_add(&(obj->siblings),
+			 &dev->root_dir->variant.dir_variant.children);
+	}
+
+	/* Add it to the lost and found directory.
+	 * NB Can't put root or lost-n-found in lost-n-found so
+	 * check if lost-n-found exists first
+	 */
+	if (dev->lost_n_found)
+		yaffs_add_obj_to_dir(dev->lost_n_found, obj);
+
+	obj->being_created = 0;
+
+	dev->checkpoint_blocks_required = 0;	/* force recalculation */
+
+	return obj;
+}
+
+static int yaffs_find_nice_bucket(struct yaffs_dev *dev)
+{
+	int i;
+	int l = 999;
+	int lowest = 999999;
+
+	/* Search for the shortest list or one that
+	 * isn't too long.
+	 */
+
+	for (i = 0; i < 10 && lowest > 4; i++) {
+		dev->bucket_finder++;
+		dev->bucket_finder %= YAFFS_NOBJECT_BUCKETS;
+		if (dev->obj_bucket[dev->bucket_finder].count < lowest) {
+			lowest = dev->obj_bucket[dev->bucket_finder].count;
+			l = dev->bucket_finder;
+		}
+	}
+
+	return l;
+}
+
+static int yaffs_new_obj_id(struct yaffs_dev *dev)
+{
+	int bucket = yaffs_find_nice_bucket(dev);
+	int found = 0;
+	struct list_head *i;
+	u32 n = (u32) bucket;
+
+	/*
+	 * Now find an object value that has not already been taken
+	 * by scanning the list, incrementing each time by number of buckets.
+	 */
+	while (!found) {
+		found = 1;
+		n += YAFFS_NOBJECT_BUCKETS;
+		list_for_each(i, &dev->obj_bucket[bucket].list) {
+			/* Check if this value is already taken. */
+			if (i && list_entry(i, struct yaffs_obj,
+					    hash_link)->obj_id == n)
+				found = 0;
+		}
+	}
+	return n;
+}
+
+static void yaffs_hash_obj(struct yaffs_obj *in)
+{
+	int bucket = yaffs_hash_fn(in->obj_id);
+	struct yaffs_dev *dev = in->my_dev;
+
+	list_add(&in->hash_link, &dev->obj_bucket[bucket].list);
+	dev->obj_bucket[bucket].count++;
+}
+
+struct yaffs_obj *yaffs_find_by_number(struct yaffs_dev *dev, u32 number)
+{
+	int bucket = yaffs_hash_fn(number);
+	struct list_head *i;
+	struct yaffs_obj *in;
+
+	list_for_each(i, &dev->obj_bucket[bucket].list) {
+		/* Look if it is in the list */
+		in = list_entry(i, struct yaffs_obj, hash_link);
+		if (in->obj_id == number) {
+			/* Don't show if it is defered free */
+			if (in->defered_free)
+				return NULL;
+			return in;
+		}
+	}
+
+	return NULL;
+}
+
+static struct yaffs_obj *yaffs_new_obj(struct yaffs_dev *dev, int number,
+				enum yaffs_obj_type type)
+{
+	struct yaffs_obj *the_obj = NULL;
+	struct yaffs_tnode *tn = NULL;
+
+	if (number < 0)
+		number = yaffs_new_obj_id(dev);
+
+	if (type == YAFFS_OBJECT_TYPE_FILE) {
+		tn = yaffs_get_tnode(dev);
+		if (!tn)
+			return NULL;
+	}
+
+	the_obj = yaffs_alloc_empty_obj(dev);
+	if (!the_obj) {
+		if (tn)
+			yaffs_free_tnode(dev, tn);
+		return NULL;
+	}
+
+	the_obj->fake = 0;
+	the_obj->rename_allowed = 1;
+	the_obj->unlink_allowed = 1;
+	the_obj->obj_id = number;
+	yaffs_hash_obj(the_obj);
+	the_obj->variant_type = type;
+	yaffs_load_current_time(the_obj, 1, 1);
+
+	switch (type) {
+	case YAFFS_OBJECT_TYPE_FILE:
+		the_obj->variant.file_variant.file_size = 0;
+		the_obj->variant.file_variant.stored_size = 0;
+		the_obj->variant.file_variant.shrink_size =
+						yaffs_max_file_size(dev);
+		the_obj->variant.file_variant.top_level = 0;
+		the_obj->variant.file_variant.top = tn;
+		break;
+	case YAFFS_OBJECT_TYPE_DIRECTORY:
+		INIT_LIST_HEAD(&the_obj->variant.dir_variant.children);
+		INIT_LIST_HEAD(&the_obj->variant.dir_variant.dirty);
+		break;
+	case YAFFS_OBJECT_TYPE_SYMLINK:
+	case YAFFS_OBJECT_TYPE_HARDLINK:
+	case YAFFS_OBJECT_TYPE_SPECIAL:
+		/* No action required */
+		break;
+	case YAFFS_OBJECT_TYPE_UNKNOWN:
+		/* todo this should not happen */
+		break;
+	}
+	return the_obj;
+}
+
+static struct yaffs_obj *yaffs_create_fake_dir(struct yaffs_dev *dev,
+					       int number, u32 mode)
+{
+
+	struct yaffs_obj *obj =
+	    yaffs_new_obj(dev, number, YAFFS_OBJECT_TYPE_DIRECTORY);
+
+	if (!obj)
+		return NULL;
+
+	obj->fake = 1;	/* it is fake so it might not use NAND */
+	obj->rename_allowed = 0;
+	obj->unlink_allowed = 0;
+	obj->deleted = 0;
+	obj->unlinked = 0;
+	obj->yst_mode = mode;
+	obj->my_dev = dev;
+	obj->hdr_chunk = 0;	/* Not a valid chunk. */
+	return obj;
+
+}
+
+
+static void yaffs_init_tnodes_and_objs(struct yaffs_dev *dev)
+{
+	int i;
+
+	dev->n_obj = 0;
+	dev->n_tnodes = 0;
+	yaffs_init_raw_tnodes_and_objs(dev);
+
+	for (i = 0; i < YAFFS_NOBJECT_BUCKETS; i++) {
+		INIT_LIST_HEAD(&dev->obj_bucket[i].list);
+		dev->obj_bucket[i].count = 0;
+	}
+}
+
+struct yaffs_obj *yaffs_find_or_create_by_number(struct yaffs_dev *dev,
+						 int number,
+						 enum yaffs_obj_type type)
+{
+	struct yaffs_obj *the_obj = NULL;
+
+	if (number > 0)
+		the_obj = yaffs_find_by_number(dev, number);
+
+	if (!the_obj)
+		the_obj = yaffs_new_obj(dev, number, type);
+
+	return the_obj;
+
+}
+
+YCHAR *yaffs_clone_str(const YCHAR *str)
+{
+	YCHAR *new_str = NULL;
+	int len;
+
+	if (!str)
+		str = _Y("");
+
+	len = strnlen(str, YAFFS_MAX_ALIAS_LENGTH);
+	new_str = kmalloc((len + 1) * sizeof(YCHAR), GFP_NOFS);
+	if (new_str) {
+		strncpy(new_str, str, len);
+		new_str[len] = 0;
+	}
+	return new_str;
+
+}
+/*
+ *yaffs_update_parent() handles fixing a directories mtime and ctime when a new
+ * link (ie. name) is created or deleted in the directory.
+ *
+ * ie.
+ *   create dir/a : update dir's mtime/ctime
+ *   rm dir/a:   update dir's mtime/ctime
+ *   modify dir/a: don't update dir's mtimme/ctime
+ *
+ * This can be handled immediately or defered. Defering helps reduce the number
+ * of updates when many files in a directory are changed within a brief period.
+ *
+ * If the directory updating is defered then yaffs_update_dirty_dirs must be
+ * called periodically.
+ */
+
+static void yaffs_update_parent(struct yaffs_obj *obj)
+{
+	struct yaffs_dev *dev;
+
+	if (!obj)
+		return;
+	dev = obj->my_dev;
+	obj->dirty = 1;
+	yaffs_load_current_time(obj, 0, 1);
+	if (dev->param.defered_dir_update) {
+		struct list_head *link = &obj->variant.dir_variant.dirty;
+
+		if (list_empty(link)) {
+			list_add(link, &dev->dirty_dirs);
+			yaffs_trace(YAFFS_TRACE_BACKGROUND,
+			  "Added object %d to dirty directories",
+			   obj->obj_id);
+		}
+
+	} else {
+		yaffs_update_oh(obj, NULL, 0, 0, 0, NULL);
+	}
+}
+
+void yaffs_update_dirty_dirs(struct yaffs_dev *dev)
+{
+	struct list_head *link;
+	struct yaffs_obj *obj;
+	struct yaffs_dir_var *d_s;
+	union yaffs_obj_var *o_v;
+
+	yaffs_trace(YAFFS_TRACE_BACKGROUND, "Update dirty directories");
+
+	while (!list_empty(&dev->dirty_dirs)) {
+		link = dev->dirty_dirs.next;
+		list_del_init(link);
+
+		d_s = list_entry(link, struct yaffs_dir_var, dirty);
+		o_v = list_entry(d_s, union yaffs_obj_var, dir_variant);
+		obj = list_entry(o_v, struct yaffs_obj, variant);
+
+		yaffs_trace(YAFFS_TRACE_BACKGROUND, "Update directory %d",
+			obj->obj_id);
+
+		if (obj->dirty)
+			yaffs_update_oh(obj, NULL, 0, 0, 0, NULL);
+	}
+}
+
+/*
+ * Mknod (create) a new object.
+ * equiv_obj only has meaning for a hard link;
+ * alias_str only has meaning for a symlink.
+ * rdev only has meaning for devices (a subset of special objects)
+ */
+
+static struct yaffs_obj *yaffs_create_obj(enum yaffs_obj_type type,
+					  struct yaffs_obj *parent,
+					  const YCHAR *name,
+					  u32 mode,
+					  u32 uid,
+					  u32 gid,
+					  struct yaffs_obj *equiv_obj,
+					  const YCHAR *alias_str, u32 rdev)
+{
+	struct yaffs_obj *in;
+	YCHAR *str = NULL;
+	struct yaffs_dev *dev = parent->my_dev;
+
+	/* Check if the entry exists.
+	 * If it does then fail the call since we don't want a dup. */
+	if (yaffs_find_by_name(parent, name))
+		return NULL;
+
+	if (type == YAFFS_OBJECT_TYPE_SYMLINK) {
+		str = yaffs_clone_str(alias_str);
+		if (!str)
+			return NULL;
+	}
+
+	in = yaffs_new_obj(dev, -1, type);
+
+	if (!in) {
+		kfree(str);
+		return NULL;
+	}
+
+	in->hdr_chunk = 0;
+	in->valid = 1;
+	in->variant_type = type;
+
+	in->yst_mode = mode;
+
+	yaffs_attribs_init(in, gid, uid, rdev);
+
+	in->n_data_chunks = 0;
+
+	yaffs_set_obj_name(in, name);
+	in->dirty = 1;
+
+	yaffs_add_obj_to_dir(parent, in);
+
+	in->my_dev = parent->my_dev;
+
+	switch (type) {
+	case YAFFS_OBJECT_TYPE_SYMLINK:
+		in->variant.symlink_variant.alias = str;
+		break;
+	case YAFFS_OBJECT_TYPE_HARDLINK:
+		in->variant.hardlink_variant.equiv_obj = equiv_obj;
+		in->variant.hardlink_variant.equiv_id = equiv_obj->obj_id;
+		list_add(&in->hard_links, &equiv_obj->hard_links);
+		break;
+	case YAFFS_OBJECT_TYPE_FILE:
+	case YAFFS_OBJECT_TYPE_DIRECTORY:
+	case YAFFS_OBJECT_TYPE_SPECIAL:
+	case YAFFS_OBJECT_TYPE_UNKNOWN:
+		/* do nothing */
+		break;
+	}
+
+	if (yaffs_update_oh(in, name, 0, 0, 0, NULL) < 0) {
+		/* Could not create the object header, fail */
+		yaffs_del_obj(in);
+		in = NULL;
+	}
+
+	if (in)
+		yaffs_update_parent(parent);
+
+	return in;
+}
+
+struct yaffs_obj *yaffs_create_file(struct yaffs_obj *parent,
+				    const YCHAR *name, u32 mode, u32 uid,
+				    u32 gid)
+{
+	return yaffs_create_obj(YAFFS_OBJECT_TYPE_FILE, parent, name, mode,
+				uid, gid, NULL, NULL, 0);
+}
+
+struct yaffs_obj *yaffs_create_dir(struct yaffs_obj *parent, const YCHAR *name,
+				   u32 mode, u32 uid, u32 gid)
+{
+	return yaffs_create_obj(YAFFS_OBJECT_TYPE_DIRECTORY, parent, name,
+				mode, uid, gid, NULL, NULL, 0);
+}
+
+struct yaffs_obj *yaffs_create_special(struct yaffs_obj *parent,
+				       const YCHAR *name, u32 mode, u32 uid,
+				       u32 gid, u32 rdev)
+{
+	return yaffs_create_obj(YAFFS_OBJECT_TYPE_SPECIAL, parent, name, mode,
+				uid, gid, NULL, NULL, rdev);
+}
+
+struct yaffs_obj *yaffs_create_symlink(struct yaffs_obj *parent,
+				       const YCHAR *name, u32 mode, u32 uid,
+				       u32 gid, const YCHAR *alias)
+{
+	return yaffs_create_obj(YAFFS_OBJECT_TYPE_SYMLINK, parent, name, mode,
+				uid, gid, NULL, alias, 0);
+}
+
+/* yaffs_link_obj returns the object id of the equivalent object.*/
+struct yaffs_obj *yaffs_link_obj(struct yaffs_obj *parent, const YCHAR * name,
+				 struct yaffs_obj *equiv_obj)
+{
+	/* Get the real object in case we were fed a hard link obj */
+	equiv_obj = yaffs_get_equivalent_obj(equiv_obj);
+
+	if (yaffs_create_obj(YAFFS_OBJECT_TYPE_HARDLINK,
+			parent, name, 0, 0, 0,
+			equiv_obj, NULL, 0))
+		return equiv_obj;
+
+	return NULL;
+
+}
+
+
+
+/*---------------------- Block Management and Page Allocation -------------*/
+
+static void yaffs_deinit_blocks(struct yaffs_dev *dev)
+{
+	if (dev->block_info_alt && dev->block_info)
+		vfree(dev->block_info);
+	else
+		kfree(dev->block_info);
+
+	dev->block_info_alt = 0;
+
+	dev->block_info = NULL;
+
+	if (dev->chunk_bits_alt && dev->chunk_bits)
+		vfree(dev->chunk_bits);
+	else
+		kfree(dev->chunk_bits);
+	dev->chunk_bits_alt = 0;
+	dev->chunk_bits = NULL;
+}
+
+static int yaffs_init_blocks(struct yaffs_dev *dev)
+{
+	int n_blocks = dev->internal_end_block - dev->internal_start_block + 1;
+
+	dev->block_info = NULL;
+	dev->chunk_bits = NULL;
+	dev->alloc_block = -1;	/* force it to get a new one */
+
+	/* If the first allocation strategy fails, thry the alternate one */
+	dev->block_info =
+		kmalloc(n_blocks * sizeof(struct yaffs_block_info), GFP_NOFS);
+	if (!dev->block_info) {
+		dev->block_info =
+		    vmalloc(n_blocks * sizeof(struct yaffs_block_info));
+		dev->block_info_alt = 1;
+	} else {
+		dev->block_info_alt = 0;
+	}
+
+	if (!dev->block_info)
+		goto alloc_error;
+
+	/* Set up dynamic blockinfo stuff. Round up bytes. */
+	dev->chunk_bit_stride = (dev->param.chunks_per_block + 7) / 8;
+	dev->chunk_bits =
+		kmalloc(dev->chunk_bit_stride * n_blocks, GFP_NOFS);
+	if (!dev->chunk_bits) {
+		dev->chunk_bits =
+		    vmalloc(dev->chunk_bit_stride * n_blocks);
+		dev->chunk_bits_alt = 1;
+	} else {
+		dev->chunk_bits_alt = 0;
+	}
+	if (!dev->chunk_bits)
+		goto alloc_error;
+
+
+	memset(dev->block_info, 0, n_blocks * sizeof(struct yaffs_block_info));
+	memset(dev->chunk_bits, 0, dev->chunk_bit_stride * n_blocks);
+	return YAFFS_OK;
+
+alloc_error:
+	yaffs_deinit_blocks(dev);
+	return YAFFS_FAIL;
+}
+
+
+void yaffs_block_became_dirty(struct yaffs_dev *dev, int block_no)
+{
+	struct yaffs_block_info *bi = yaffs_get_block_info(dev, block_no);
+	int erased_ok = 0;
+	u32 i;
+
+	/* If the block is still healthy erase it and mark as clean.
+	 * If the block has had a data failure, then retire it.
+	 */
+
+	yaffs_trace(YAFFS_TRACE_GC | YAFFS_TRACE_ERASE,
+		"yaffs_block_became_dirty block %d state %d %s",
+		block_no, bi->block_state,
+		(bi->needs_retiring) ? "needs retiring" : "");
+
+	yaffs2_clear_oldest_dirty_seq(dev, bi);
+
+	bi->block_state = YAFFS_BLOCK_STATE_DIRTY;
+
+	/* If this is the block being garbage collected then stop gc'ing */
+	if (block_no == (int)dev->gc_block)
+		dev->gc_block = 0;
+
+	/* If this block is currently the best candidate for gc
+	 * then drop as a candidate */
+	if (block_no == (int)dev->gc_dirtiest) {
+		dev->gc_dirtiest = 0;
+		dev->gc_pages_in_use = 0;
+	}
+
+	if (!bi->needs_retiring) {
+		yaffs2_checkpt_invalidate(dev);
+		erased_ok = yaffs_erase_block(dev, block_no);
+		if (!erased_ok) {
+			dev->n_erase_failures++;
+			yaffs_trace(YAFFS_TRACE_ERROR | YAFFS_TRACE_BAD_BLOCKS,
+			  "**>> Erasure failed %d", block_no);
+		}
+	}
+
+	/* Verify erasure if needed */
+	if (erased_ok &&
+	    ((yaffs_trace_mask & YAFFS_TRACE_ERASE) ||
+	     !yaffs_skip_verification(dev))) {
+		for (i = 0; i < dev->param.chunks_per_block; i++) {
+			if (!yaffs_check_chunk_erased(dev,
+				block_no * dev->param.chunks_per_block + i)) {
+				yaffs_trace(YAFFS_TRACE_ERROR,
+					">>Block %d erasure supposedly OK, but chunk %d not erased",
+					block_no, i);
+			}
+		}
+	}
+
+	if (!erased_ok) {
+		/* We lost a block of free space */
+		dev->n_free_chunks -= dev->param.chunks_per_block;
+		yaffs_retire_block(dev, block_no);
+		yaffs_trace(YAFFS_TRACE_ERROR | YAFFS_TRACE_BAD_BLOCKS,
+			"**>> Block %d retired", block_no);
+		return;
+	}
+
+	/* Clean it up... */
+	bi->block_state = YAFFS_BLOCK_STATE_EMPTY;
+	bi->seq_number = 0;
+	dev->n_erased_blocks++;
+	bi->pages_in_use = 0;
+	bi->soft_del_pages = 0;
+	bi->has_shrink_hdr = 0;
+	bi->skip_erased_check = 1;	/* Clean, so no need to check */
+	bi->gc_prioritise = 0;
+	bi->has_summary = 0;
+
+	yaffs_clear_chunk_bits(dev, block_no);
+
+	yaffs_trace(YAFFS_TRACE_ERASE, "Erased block %d", block_no);
+}
+
+static inline int yaffs_gc_process_chunk(struct yaffs_dev *dev,
+					struct yaffs_block_info *bi,
+					int old_chunk, u8 *buffer)
+{
+	int new_chunk;
+	int mark_flash = 1;
+	struct yaffs_ext_tags tags;
+	struct yaffs_obj *object;
+	int matching_chunk;
+	int ret_val = YAFFS_OK;
+
+	memset(&tags, 0, sizeof(tags));
+	yaffs_rd_chunk_tags_nand(dev, old_chunk,
+				 buffer, &tags);
+	object = yaffs_find_by_number(dev, tags.obj_id);
+
+	yaffs_trace(YAFFS_TRACE_GC_DETAIL,
+		"Collecting chunk in block %d, %d %d %d ",
+		dev->gc_chunk, tags.obj_id,
+		tags.chunk_id, tags.n_bytes);
+
+	if (object && !yaffs_skip_verification(dev)) {
+		if (tags.chunk_id == 0)
+			matching_chunk =
+			    object->hdr_chunk;
+		else if (object->soft_del)
+			/* Defeat the test */
+			matching_chunk = old_chunk;
+		else
+			matching_chunk =
+			    yaffs_find_chunk_in_file
+			    (object, tags.chunk_id,
+			     NULL);
+
+		if (old_chunk != matching_chunk)
+			yaffs_trace(YAFFS_TRACE_ERROR,
+				"gc: page in gc mismatch: %d %d %d %d",
+				old_chunk,
+				matching_chunk,
+				tags.obj_id,
+				tags.chunk_id);
+	}
+
+	if (!object) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"page %d in gc has no object: %d %d %d ",
+			old_chunk,
+			tags.obj_id, tags.chunk_id,
+			tags.n_bytes);
+	}
+
+	if (object &&
+	    object->deleted &&
+	    object->soft_del && tags.chunk_id != 0) {
+		/* Data chunk in a soft deleted file,
+		 * throw it away.
+		 * It's a soft deleted data chunk,
+		 * No need to copy this, just forget
+		 * about it and fix up the object.
+		 */
+
+		/* Free chunks already includes
+		 * softdeleted chunks, how ever this
+		 * chunk is going to soon be really
+		 * deleted which will increment free
+		 * chunks. We have to decrement free
+		 * chunks so this works out properly.
+		 */
+		dev->n_free_chunks--;
+		bi->soft_del_pages--;
+
+		object->n_data_chunks--;
+		if (object->n_data_chunks <= 0) {
+			/* remeber to clean up obj */
+			dev->gc_cleanup_list[dev->n_clean_ups] = tags.obj_id;
+			dev->n_clean_ups++;
+		}
+		mark_flash = 0;
+	} else if (object) {
+		/* It's either a data chunk in a live
+		 * file or an ObjectHeader, so we're
+		 * interested in it.
+		 * NB Need to keep the ObjectHeaders of
+		 * deleted files until the whole file
+		 * has been deleted off
+		 */
+		tags.serial_number++;
+		dev->n_gc_copies++;
+
+		if (tags.chunk_id == 0) {
+			/* It is an object Id,
+			 * We need to nuke the shrinkheader flags since its
+			 * work is done.
+			 * Also need to clean up shadowing.
+			 * NB We don't want to do all the work of translating
+			 * object header endianism back and forth so we leave
+			 * the oh endian in its stored order.
+			 */
+
+			struct yaffs_obj_hdr *oh;
+			oh = (struct yaffs_obj_hdr *) buffer;
+
+			oh->is_shrink = 0;
+			tags.extra_is_shrink = 0;
+			oh->shadows_obj = 0;
+			oh->inband_shadowed_obj_id = 0;
+			tags.extra_shadows = 0;
+
+			/* Update file size */
+			if (object->variant_type == YAFFS_OBJECT_TYPE_FILE) {
+				yaffs_oh_size_load(dev, oh,
+				    object->variant.file_variant.stored_size, 1);
+				tags.extra_file_size =
+				    object->variant.file_variant.stored_size;
+			}
+
+			yaffs_verify_oh(object, oh, &tags, 1);
+			new_chunk =
+			    yaffs_write_new_chunk(dev, (u8 *) oh, &tags, 1);
+		} else {
+			new_chunk =
+			    yaffs_write_new_chunk(dev, buffer, &tags, 1);
+		}
+
+		if (new_chunk < 0) {
+			ret_val = YAFFS_FAIL;
+		} else {
+
+			/* Now fix up the Tnodes etc. */
+
+			if (tags.chunk_id == 0) {
+				/* It's a header */
+				object->hdr_chunk = new_chunk;
+				object->serial = tags.serial_number;
+			} else {
+				/* It's a data chunk */
+				yaffs_put_chunk_in_file(object, tags.chunk_id,
+							new_chunk, 0);
+			}
+		}
+	}
+	if (ret_val == YAFFS_OK)
+		yaffs_chunk_del(dev, old_chunk, mark_flash, __LINE__);
+	return ret_val;
+}
+
+static int yaffs_gc_block(struct yaffs_dev *dev, int block, int whole_block)
+{
+	int old_chunk;
+	int ret_val = YAFFS_OK;
+	u32 i;
+	int is_checkpt_block;
+	int max_copies;
+	int chunks_before = yaffs_get_erased_chunks(dev);
+	int chunks_after;
+	struct yaffs_block_info *bi = yaffs_get_block_info(dev, block);
+
+	is_checkpt_block = (bi->block_state == YAFFS_BLOCK_STATE_CHECKPOINT);
+
+	yaffs_trace(YAFFS_TRACE_TRACING,
+		"Collecting block %d, in use %d, shrink %d, whole_block %d",
+		block, bi->pages_in_use, bi->has_shrink_hdr,
+		whole_block);
+
+	/*yaffs_verify_free_chunks(dev); */
+
+	if (bi->block_state == YAFFS_BLOCK_STATE_FULL)
+		bi->block_state = YAFFS_BLOCK_STATE_COLLECTING;
+
+	bi->has_shrink_hdr = 0;	/* clear the flag so that the block can erase */
+
+	dev->gc_disable = 1;
+
+	yaffs_summary_gc(dev, block);
+
+	if (is_checkpt_block || !yaffs_still_some_chunks(dev, block)) {
+		yaffs_trace(YAFFS_TRACE_TRACING,
+			"Collecting block %d that has no chunks in use",
+			block);
+		yaffs_block_became_dirty(dev, block);
+	} else {
+
+		u8 *buffer = yaffs_get_temp_buffer(dev);
+
+		yaffs_verify_blk(dev, bi, block);
+
+		max_copies = (whole_block) ? dev->param.chunks_per_block : 5;
+		old_chunk = block * dev->param.chunks_per_block + dev->gc_chunk;
+
+		for (/* init already done */ ;
+		     ret_val == YAFFS_OK &&
+		     dev->gc_chunk < dev->param.chunks_per_block &&
+		     (bi->block_state == YAFFS_BLOCK_STATE_COLLECTING) &&
+		     max_copies > 0;
+		     dev->gc_chunk++, old_chunk++) {
+			if (yaffs_check_chunk_bit(dev, block, dev->gc_chunk)) {
+				/* Page is in use and might need to be copied */
+				max_copies--;
+				ret_val = yaffs_gc_process_chunk(dev, bi,
+							old_chunk, buffer);
+			}
+		}
+		yaffs_release_temp_buffer(dev, buffer);
+	}
+
+	yaffs_verify_collected_blk(dev, bi, block);
+
+	if (bi->block_state == YAFFS_BLOCK_STATE_COLLECTING) {
+		/*
+		 * The gc did not complete. Set block state back to FULL
+		 * because checkpointing does not restore gc.
+		 */
+		bi->block_state = YAFFS_BLOCK_STATE_FULL;
+	} else {
+		/* The gc completed. */
+		/* Do any required cleanups */
+		for (i = 0; i < dev->n_clean_ups; i++) {
+			/* Time to delete the file too */
+			struct yaffs_obj *object =
+			    yaffs_find_by_number(dev, dev->gc_cleanup_list[i]);
+			if (object) {
+				yaffs_free_tnode(dev,
+					  object->variant.file_variant.top);
+				object->variant.file_variant.top = NULL;
+				yaffs_trace(YAFFS_TRACE_GC,
+					"yaffs: About to finally delete object %d",
+					object->obj_id);
+				yaffs_generic_obj_del(object);
+				object->my_dev->n_deleted_files--;
+			}
+
+		}
+		chunks_after = yaffs_get_erased_chunks(dev);
+		if (chunks_before >= chunks_after)
+			yaffs_trace(YAFFS_TRACE_GC,
+				"gc did not increase free chunks before %d after %d",
+				chunks_before, chunks_after);
+		dev->gc_block = 0;
+		dev->gc_chunk = 0;
+		dev->n_clean_ups = 0;
+	}
+
+	dev->gc_disable = 0;
+
+	return ret_val;
+}
+
+/*
+ * find_gc_block() selects the dirtiest block (or close enough)
+ * for garbage collection.
+ */
+
+static unsigned yaffs_find_gc_block(struct yaffs_dev *dev,
+				    int aggressive, int background)
+{
+	u32 i;
+	u32 iterations;
+	u32 selected = 0;
+	int prioritised = 0;
+	int prioritised_exist = 0;
+	struct yaffs_block_info *bi;
+	u32 threshold;
+
+	/* First let's see if we need to grab a prioritised block */
+	if (dev->has_pending_prioritised_gc && !aggressive) {
+		dev->gc_dirtiest = 0;
+		bi = dev->block_info;
+		for (i = dev->internal_start_block;
+		     i <= dev->internal_end_block && !selected; i++) {
+
+			if (bi->gc_prioritise) {
+				prioritised_exist = 1;
+				if (bi->block_state == YAFFS_BLOCK_STATE_FULL &&
+				    yaffs_block_ok_for_gc(dev, bi)) {
+					selected = i;
+					prioritised = 1;
+				}
+			}
+			bi++;
+		}
+
+		/*
+		 * If there is a prioritised block and none was selected then
+		 * this happened because there is at least one old dirty block
+		 * gumming up the works. Let's gc the oldest dirty block.
+		 */
+
+		if (prioritised_exist &&
+		    !selected && dev->oldest_dirty_block > 0)
+			selected = dev->oldest_dirty_block;
+
+		if (!prioritised_exist)	/* None found, so we can clear this */
+			dev->has_pending_prioritised_gc = 0;
+	}
+
+	/* If we're doing aggressive GC then we are happy to take a less-dirty
+	 * block, and search harder.
+	 * else (leasurely gc), then we only bother to do this if the
+	 * block has only a few pages in use.
+	 */
+
+	if (!selected) {
+		u32 pages_used;
+		int n_blocks =
+		    dev->internal_end_block - dev->internal_start_block + 1;
+		if (aggressive) {
+			threshold = dev->param.chunks_per_block;
+			iterations = n_blocks;
+		} else {
+			u32 max_threshold;
+
+			if (background)
+				max_threshold = dev->param.chunks_per_block / 2;
+			else
+				max_threshold = dev->param.chunks_per_block / 8;
+
+			if (max_threshold < YAFFS_GC_PASSIVE_THRESHOLD)
+				max_threshold = YAFFS_GC_PASSIVE_THRESHOLD;
+
+			threshold = background ? (dev->gc_not_done + 2) * 2 : 0;
+			if (threshold < YAFFS_GC_PASSIVE_THRESHOLD)
+				threshold = YAFFS_GC_PASSIVE_THRESHOLD;
+			if (threshold > max_threshold)
+				threshold = max_threshold;
+
+			iterations = n_blocks / 16 + 1;
+			if (iterations > 100)
+				iterations = 100;
+		}
+
+		for (i = 0;
+		     i < iterations &&
+		     (dev->gc_dirtiest < 1 ||
+		      dev->gc_pages_in_use > YAFFS_GC_GOOD_ENOUGH);
+		     i++) {
+			dev->gc_block_finder++;
+			if (dev->gc_block_finder < dev->internal_start_block ||
+			    dev->gc_block_finder > dev->internal_end_block)
+				dev->gc_block_finder =
+				    dev->internal_start_block;
+
+			bi = yaffs_get_block_info(dev, dev->gc_block_finder);
+
+			pages_used = bi->pages_in_use - bi->soft_del_pages;
+
+			if (bi->block_state == YAFFS_BLOCK_STATE_FULL &&
+			    pages_used < dev->param.chunks_per_block &&
+			    (dev->gc_dirtiest < 1 ||
+			     pages_used < dev->gc_pages_in_use) &&
+			    yaffs_block_ok_for_gc(dev, bi)) {
+				dev->gc_dirtiest = dev->gc_block_finder;
+				dev->gc_pages_in_use = pages_used;
+			}
+		}
+
+		if (dev->gc_dirtiest > 0 && dev->gc_pages_in_use <= threshold)
+			selected = dev->gc_dirtiest;
+	}
+
+	/*
+	 * If nothing has been selected for a while, try the oldest dirty
+	 * because that's gumming up the works.
+	 */
+
+	if (!selected && dev->param.is_yaffs2 &&
+	    dev->gc_not_done >= (background ? 10 : 20)) {
+		yaffs2_find_oldest_dirty_seq(dev);
+		if (dev->oldest_dirty_block > 0) {
+			selected = dev->oldest_dirty_block;
+			dev->gc_dirtiest = selected;
+			dev->oldest_dirty_gc_count++;
+			bi = yaffs_get_block_info(dev, selected);
+			dev->gc_pages_in_use =
+			    bi->pages_in_use - bi->soft_del_pages;
+		} else {
+			dev->gc_not_done = 0;
+		}
+	}
+
+	if (selected) {
+		yaffs_trace(YAFFS_TRACE_GC,
+			"GC Selected block %d with %d free, prioritised:%d",
+			selected,
+			dev->param.chunks_per_block - dev->gc_pages_in_use,
+			prioritised);
+
+		dev->n_gc_blocks++;
+		if (background)
+			dev->bg_gcs++;
+
+		dev->gc_dirtiest = 0;
+		dev->gc_pages_in_use = 0;
+		dev->gc_not_done = 0;
+		if (dev->refresh_skip > 0)
+			dev->refresh_skip--;
+	} else {
+		dev->gc_not_done++;
+		yaffs_trace(YAFFS_TRACE_GC,
+			"GC none: finder %d skip %d threshold %d dirtiest %d using %d oldest %d%s",
+			dev->gc_block_finder, dev->gc_not_done, threshold,
+			dev->gc_dirtiest, dev->gc_pages_in_use,
+			dev->oldest_dirty_block, background ? " bg" : "");
+	}
+
+	return selected;
+}
+
+/* New garbage collector
+ * If we're very low on erased blocks then we do aggressive garbage collection
+ * otherwise we do "leasurely" garbage collection.
+ * Aggressive gc looks further (whole array) and will accept less dirty blocks.
+ * Passive gc only inspects smaller areas and only accepts more dirty blocks.
+ *
+ * The idea is to help clear out space in a more spread-out manner.
+ * Dunno if it really does anything useful.
+ */
+static int yaffs_check_gc(struct yaffs_dev *dev, int background)
+{
+	int aggressive = 0;
+	int gc_ok = YAFFS_OK;
+	int max_tries = 0;
+	int min_erased;
+	int erased_chunks;
+	int checkpt_block_adjust;
+
+	if (dev->param.gc_control_fn &&
+		(dev->param.gc_control_fn(dev) & 1) == 0)
+		return YAFFS_OK;
+
+	if (dev->gc_disable)
+		/* Bail out so we don't get recursive gc */
+		return YAFFS_OK;
+
+	/* This loop should pass the first time.
+	 * Only loops here if the collection does not increase space.
+	 */
+
+	do {
+		max_tries++;
+
+		checkpt_block_adjust = yaffs_calc_checkpt_blocks_required(dev);
+
+		min_erased =
+		    dev->param.n_reserved_blocks + checkpt_block_adjust + 1;
+		erased_chunks =
+		    dev->n_erased_blocks * dev->param.chunks_per_block;
+
+		/* If we need a block soon then do aggressive gc. */
+		if (dev->n_erased_blocks < min_erased)
+			aggressive = 1;
+		else {
+			if (!background
+			    && erased_chunks > (dev->n_free_chunks / 4))
+				break;
+
+			if (dev->gc_skip > 20)
+				dev->gc_skip = 20;
+			if (erased_chunks < dev->n_free_chunks / 2 ||
+			    dev->gc_skip < 1 || background)
+				aggressive = 0;
+			else {
+				dev->gc_skip--;
+				break;
+			}
+		}
+
+		dev->gc_skip = 5;
+
+		/* If we don't already have a block being gc'd then see if we
+		 * should start another */
+
+		if (dev->gc_block < 1 && !aggressive) {
+			dev->gc_block = yaffs2_find_refresh_block(dev);
+			dev->gc_chunk = 0;
+			dev->n_clean_ups = 0;
+		}
+		if (dev->gc_block < 1) {
+			dev->gc_block =
+			    yaffs_find_gc_block(dev, aggressive, background);
+			dev->gc_chunk = 0;
+			dev->n_clean_ups = 0;
+		}
+
+		if (dev->gc_block > 0) {
+			dev->all_gcs++;
+			if (!aggressive)
+				dev->passive_gc_count++;
+
+			yaffs_trace(YAFFS_TRACE_GC,
+				"yaffs: GC n_erased_blocks %d aggressive %d",
+				dev->n_erased_blocks, aggressive);
+
+			gc_ok = yaffs_gc_block(dev, dev->gc_block, aggressive);
+		}
+
+		if (dev->n_erased_blocks < (int)dev->param.n_reserved_blocks &&
+		    dev->gc_block > 0) {
+			yaffs_trace(YAFFS_TRACE_GC,
+				"yaffs: GC !!!no reclaim!!! n_erased_blocks %d after try %d block %d",
+				dev->n_erased_blocks, max_tries,
+				dev->gc_block);
+		}
+	} while ((dev->n_erased_blocks < (int)dev->param.n_reserved_blocks) &&
+		 (dev->gc_block > 0) && (max_tries < 2));
+
+	return aggressive ? gc_ok : YAFFS_OK;
+}
+
+/*
+ * yaffs_bg_gc()
+ * Garbage collects. Intended to be called from a background thread.
+ * Returns non-zero if at least half the free chunks are erased.
+ */
+int yaffs_bg_gc(struct yaffs_dev *dev, unsigned urgency)
+{
+	int erased_chunks = dev->n_erased_blocks * dev->param.chunks_per_block;
+
+	yaffs_trace(YAFFS_TRACE_BACKGROUND, "Background gc %u", urgency);
+
+	yaffs_check_gc(dev, 1);
+	return erased_chunks > dev->n_free_chunks / 2;
+}
+
+/*-------------------- Data file manipulation -----------------*/
+
+static int yaffs_rd_data_obj(struct yaffs_obj *in, int inode_chunk, u8 * buffer)
+{
+	int nand_chunk = yaffs_find_chunk_in_file(in, inode_chunk, NULL);
+
+	if (nand_chunk >= 0)
+		return yaffs_rd_chunk_tags_nand(in->my_dev, nand_chunk,
+						buffer, NULL);
+	else {
+		yaffs_trace(YAFFS_TRACE_NANDACCESS,
+			"Chunk %d not found zero instead",
+			nand_chunk);
+		/* get sane (zero) data if you read a hole */
+		memset(buffer, 0, in->my_dev->data_bytes_per_chunk);
+		return 0;
+	}
+
+}
+
+void yaffs_chunk_del(struct yaffs_dev *dev, int chunk_id, int mark_flash,
+		     int lyn)
+{
+	int block;
+	int page;
+	struct yaffs_ext_tags tags;
+	struct yaffs_block_info *bi;
+
+	if (chunk_id <= 0)
+		return;
+
+	dev->n_deletions++;
+	block = chunk_id / dev->param.chunks_per_block;
+	page = chunk_id % dev->param.chunks_per_block;
+
+	if (!yaffs_check_chunk_bit(dev, block, page))
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Deleting invalid chunk %d", chunk_id);
+
+	bi = yaffs_get_block_info(dev, block);
+
+	yaffs2_update_oldest_dirty_seq(dev, block, bi);
+
+	yaffs_trace(YAFFS_TRACE_DELETION,
+		"line %d delete of chunk %d",
+		lyn, chunk_id);
+
+	if (!dev->param.is_yaffs2 && mark_flash &&
+	    bi->block_state != YAFFS_BLOCK_STATE_COLLECTING) {
+
+		memset(&tags, 0, sizeof(tags));
+		tags.is_deleted = 1;
+		yaffs_wr_chunk_tags_nand(dev, chunk_id, NULL, &tags);
+		yaffs_handle_chunk_update(dev, chunk_id, &tags);
+	} else {
+		dev->n_unmarked_deletions++;
+	}
+
+	/* Pull out of the management area.
+	 * If the whole block became dirty, this will kick off an erasure.
+	 */
+	if (bi->block_state == YAFFS_BLOCK_STATE_ALLOCATING ||
+	    bi->block_state == YAFFS_BLOCK_STATE_FULL ||
+	    bi->block_state == YAFFS_BLOCK_STATE_NEEDS_SCAN ||
+	    bi->block_state == YAFFS_BLOCK_STATE_COLLECTING) {
+		dev->n_free_chunks++;
+		yaffs_clear_chunk_bit(dev, block, page);
+		bi->pages_in_use--;
+
+		if (bi->pages_in_use == 0 &&
+		    !bi->has_shrink_hdr &&
+		    bi->block_state != YAFFS_BLOCK_STATE_ALLOCATING &&
+		    bi->block_state != YAFFS_BLOCK_STATE_NEEDS_SCAN) {
+			yaffs_block_became_dirty(dev, block);
+		}
+	}
+}
+
+static int yaffs_wr_data_obj(struct yaffs_obj *in, int inode_chunk,
+			     const u8 *buffer, int n_bytes, int use_reserve)
+{
+	/* Find old chunk Need to do this to get serial number
+	 * Write new one and patch into tree.
+	 * Invalidate old tags.
+	 */
+
+	int prev_chunk_id;
+	struct yaffs_ext_tags prev_tags;
+	int new_chunk_id;
+	struct yaffs_ext_tags new_tags;
+	struct yaffs_dev *dev = in->my_dev;
+	loff_t endpos;
+
+	yaffs_check_gc(dev, 0);
+
+	/* Get the previous chunk at this location in the file if it exists.
+	 * If it does not exist then put a zero into the tree. This creates
+	 * the tnode now, rather than later when it is harder to clean up.
+	 */
+	prev_chunk_id = yaffs_find_chunk_in_file(in, inode_chunk, &prev_tags);
+	if (prev_chunk_id < 1 &&
+	    !yaffs_put_chunk_in_file(in, inode_chunk, 0, 0))
+		return 0;
+
+	/* Set up new tags */
+	memset(&new_tags, 0, sizeof(new_tags));
+
+	new_tags.chunk_id = inode_chunk;
+	new_tags.obj_id = in->obj_id;
+	new_tags.serial_number =
+	    (prev_chunk_id > 0) ? prev_tags.serial_number + 1 : 1;
+	new_tags.n_bytes = n_bytes;
+
+	if (n_bytes < 1 || n_bytes > (int)dev->data_bytes_per_chunk) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+		  "Writing %d bytes to chunk!!!!!!!!!",
+		   n_bytes);
+		BUG();
+	}
+
+	/*
+	 * If this is a data chunk and the write goes past the end of the stored
+	 * size then update the stored_size.
+	 */
+	if (inode_chunk > 0) {
+		endpos =  (inode_chunk - 1) * dev->data_bytes_per_chunk +
+				n_bytes;
+		if (in->variant.file_variant.stored_size < endpos)
+			in->variant.file_variant.stored_size = endpos;
+	}
+
+	new_chunk_id =
+	    yaffs_write_new_chunk(dev, buffer, &new_tags, use_reserve);
+
+	if (new_chunk_id > 0) {
+		yaffs_put_chunk_in_file(in, inode_chunk, new_chunk_id, 0);
+
+		if (prev_chunk_id > 0)
+			yaffs_chunk_del(dev, prev_chunk_id, 1, __LINE__);
+
+		yaffs_verify_file_sane(in);
+	}
+	return new_chunk_id;
+}
+
+
+
+static int yaffs_do_xattrib_mod(struct yaffs_obj *obj, int set,
+				const YCHAR *name, const void *value, int size,
+				int flags)
+{
+	struct yaffs_xattr_mod xmod;
+	int result;
+
+	xmod.set = set;
+	xmod.name = name;
+	xmod.data = value;
+	xmod.size = size;
+	xmod.flags = flags;
+	xmod.result = -ENOSPC;
+
+	result = yaffs_update_oh(obj, NULL, 0, 0, 0, &xmod);
+
+	if (result > 0)
+		return xmod.result;
+	else
+		return -ENOSPC;
+}
+
+static int yaffs_apply_xattrib_mod(struct yaffs_obj *obj, char *buffer,
+				   struct yaffs_xattr_mod *xmod)
+{
+	int retval = 0;
+	int x_offs = sizeof(struct yaffs_obj_hdr);
+	struct yaffs_dev *dev = obj->my_dev;
+	int x_size = dev->data_bytes_per_chunk - sizeof(struct yaffs_obj_hdr);
+	char *x_buffer = buffer + x_offs;
+
+	if (xmod->set)
+		retval =
+		    nval_set(dev, x_buffer, x_size, xmod->name, xmod->data,
+			     xmod->size, xmod->flags);
+	else
+		retval = nval_del(dev, x_buffer, x_size, xmod->name);
+
+	obj->has_xattr = nval_hasvalues(dev, x_buffer, x_size);
+	obj->xattr_known = 1;
+	xmod->result = retval;
+
+	return retval;
+}
+
+static int yaffs_do_xattrib_fetch(struct yaffs_obj *obj, const YCHAR *name,
+				  void *value, int size)
+{
+	char *buffer = NULL;
+	int result;
+	struct yaffs_ext_tags tags;
+	struct yaffs_dev *dev = obj->my_dev;
+	int x_offs = sizeof(struct yaffs_obj_hdr);
+	int x_size = dev->data_bytes_per_chunk - sizeof(struct yaffs_obj_hdr);
+	char *x_buffer;
+	int retval = 0;
+
+	if (obj->hdr_chunk < 1)
+		return -ENODATA;
+
+	/* If we know that the object has no xattribs then don't do all the
+	 * reading and parsing.
+	 */
+	if (obj->xattr_known && !obj->has_xattr) {
+		if (name)
+			return -ENODATA;
+		else
+			return 0;
+	}
+
+	buffer = (char *)yaffs_get_temp_buffer(dev);
+	if (!buffer)
+		return -ENOMEM;
+
+	result =
+	    yaffs_rd_chunk_tags_nand(dev, obj->hdr_chunk, (u8 *) buffer, &tags);
+
+	if (result != YAFFS_OK)
+		retval = -ENOENT;
+	else {
+		x_buffer = buffer + x_offs;
+
+		if (!obj->xattr_known) {
+			obj->has_xattr = nval_hasvalues(dev, x_buffer, x_size);
+			obj->xattr_known = 1;
+		}
+
+		if (name)
+			retval = nval_get(dev, x_buffer, x_size,
+						name, value, size);
+		else
+			retval = nval_list(dev, x_buffer, x_size, value, size);
+	}
+	yaffs_release_temp_buffer(dev, (u8 *) buffer);
+	return retval;
+}
+
+int yaffs_set_xattrib(struct yaffs_obj *obj, const YCHAR * name,
+		      const void *value, int size, int flags)
+{
+	return yaffs_do_xattrib_mod(obj, 1, name, value, size, flags);
+}
+
+int yaffs_remove_xattrib(struct yaffs_obj *obj, const YCHAR * name)
+{
+	return yaffs_do_xattrib_mod(obj, 0, name, NULL, 0, 0);
+}
+
+int yaffs_get_xattrib(struct yaffs_obj *obj, const YCHAR * name, void *value,
+		      int size)
+{
+	return yaffs_do_xattrib_fetch(obj, name, value, size);
+}
+
+int yaffs_list_xattrib(struct yaffs_obj *obj, char *buffer, int size)
+{
+	return yaffs_do_xattrib_fetch(obj, NULL, buffer, size);
+}
+
+static void yaffs_check_obj_details_loaded(struct yaffs_obj *in)
+{
+	u8 *buf;
+	struct yaffs_obj_hdr *oh;
+	struct yaffs_dev *dev;
+	struct yaffs_ext_tags tags;
+	int result;
+
+	if (!in || !in->lazy_loaded || in->hdr_chunk < 1)
+		return;
+
+	dev = in->my_dev;
+	buf = yaffs_get_temp_buffer(dev);
+
+	result = yaffs_rd_chunk_tags_nand(dev, in->hdr_chunk, buf, &tags);
+
+	if (result == YAFFS_FAIL)
+		return;
+
+	oh = (struct yaffs_obj_hdr *)buf;
+
+	yaffs_do_endian_oh(dev, oh);
+
+	in->lazy_loaded = 0;
+	in->yst_mode = oh->yst_mode;
+	yaffs_load_attribs(in, oh);
+	yaffs_set_obj_name_from_oh(in, oh);
+
+	if (in->variant_type == YAFFS_OBJECT_TYPE_SYMLINK)
+		in->variant.symlink_variant.alias =
+		    yaffs_clone_str(oh->alias);
+	yaffs_release_temp_buffer(dev, buf);
+}
+
+/* UpdateObjectHeader updates the header on NAND for an object.
+ * If name is not NULL, then that new name is used.
+ *
+ * We're always creating the obj header from scratch (except reading
+ * the old name) so first set up in cpu endianness then run it through
+ * endian fixing at the end.
+ *
+ * However, a twist: If there are xattribs we leave them as they were.
+ *
+ * Careful! The buffer holds the whole chunk. Part of the chunk holds the
+ * object header and the rest holds the xattribs, therefore we use a buffer
+ * pointer and an oh pointer to point to the same memory.
+ */
+
+int yaffs_update_oh(struct yaffs_obj *in, const YCHAR *name, int force,
+		    int is_shrink, int shadows, struct yaffs_xattr_mod *xmod)
+{
+
+	struct yaffs_block_info *bi;
+	struct yaffs_dev *dev = in->my_dev;
+	int prev_chunk_id;
+	int ret_val = 0;
+	int result = 0;
+	int new_chunk_id;
+	struct yaffs_ext_tags new_tags;
+	struct yaffs_ext_tags old_tags;
+	const YCHAR *alias = NULL;
+	u8 *buffer = NULL;
+	YCHAR old_name[YAFFS_MAX_NAME_LENGTH + 1];
+	struct yaffs_obj_hdr *oh = NULL;
+	loff_t file_size = 0;
+
+	strcpy(old_name, _Y("silly old name"));
+
+	if (in->fake && in != dev->root_dir && !force && !xmod)
+		return ret_val;
+
+	yaffs_check_gc(dev, 0);
+	yaffs_check_obj_details_loaded(in);
+
+	buffer = yaffs_get_temp_buffer(in->my_dev);
+	oh = (struct yaffs_obj_hdr *)buffer;
+
+	prev_chunk_id = in->hdr_chunk;
+
+	if (prev_chunk_id > 0) {
+		/* Access the old obj header just to read the name. */
+		result = yaffs_rd_chunk_tags_nand(dev, prev_chunk_id,
+						  buffer, &old_tags);
+		if (result == YAFFS_OK) {
+			yaffs_verify_oh(in, oh, &old_tags, 0);
+			memcpy(old_name, oh->name, sizeof(oh->name));
+
+			/*
+			* NB We only wipe the object header area because the rest of
+			* the buffer might contain xattribs.
+			*/
+			memset(oh, 0xff, sizeof(*oh));
+		}
+	} else {
+		memset(buffer, 0xff, dev->data_bytes_per_chunk);
+	}
+
+	oh->type = in->variant_type;
+	oh->yst_mode = in->yst_mode;
+	oh->shadows_obj = oh->inband_shadowed_obj_id = shadows;
+
+	yaffs_load_attribs_oh(oh, in);
+
+	if (in->parent)
+		oh->parent_obj_id = in->parent->obj_id;
+	else
+		oh->parent_obj_id = 0;
+
+	if (name && *name) {
+		memset(oh->name, 0, sizeof(oh->name));
+		yaffs_load_oh_from_name(dev, oh->name, name);
+	} else if (prev_chunk_id > 0) {
+		memcpy(oh->name, old_name, sizeof(oh->name));
+	} else {
+		memset(oh->name, 0, sizeof(oh->name));
+	}
+
+	oh->is_shrink = is_shrink;
+
+	switch (in->variant_type) {
+	case YAFFS_OBJECT_TYPE_UNKNOWN:
+		/* Should not happen */
+		break;
+	case YAFFS_OBJECT_TYPE_FILE:
+		if (oh->parent_obj_id != YAFFS_OBJECTID_DELETED &&
+		    oh->parent_obj_id != YAFFS_OBJECTID_UNLINKED)
+			file_size = in->variant.file_variant.stored_size;
+		yaffs_oh_size_load(dev, oh, file_size, 0);
+		break;
+	case YAFFS_OBJECT_TYPE_HARDLINK:
+		oh->equiv_id = in->variant.hardlink_variant.equiv_id;
+		break;
+	case YAFFS_OBJECT_TYPE_SPECIAL:
+		/* Do nothing */
+		break;
+	case YAFFS_OBJECT_TYPE_DIRECTORY:
+		/* Do nothing */
+		break;
+	case YAFFS_OBJECT_TYPE_SYMLINK:
+		alias = in->variant.symlink_variant.alias;
+		if (!alias)
+			alias = _Y("no alias");
+		strncpy(oh->alias, alias, YAFFS_MAX_ALIAS_LENGTH);
+		oh->alias[YAFFS_MAX_ALIAS_LENGTH] = 0;
+		break;
+	}
+
+	/* process any xattrib modifications */
+	if (xmod)
+		yaffs_apply_xattrib_mod(in, (char *)buffer, xmod);
+
+	/* Tags */
+	memset(&new_tags, 0, sizeof(new_tags));
+	in->serial++;
+	new_tags.chunk_id = 0;
+	new_tags.obj_id = in->obj_id;
+	new_tags.serial_number = in->serial;
+
+	/* Add extra info for file header */
+	new_tags.extra_available = 1;
+	new_tags.extra_parent_id = oh->parent_obj_id;
+	new_tags.extra_file_size = file_size;
+	new_tags.extra_is_shrink = oh->is_shrink;
+	new_tags.extra_equiv_id = oh->equiv_id;
+	new_tags.extra_shadows = (oh->shadows_obj > 0) ? 1 : 0;
+	new_tags.extra_obj_type = in->variant_type;
+
+	/* Now endian swizzle the oh if needed. */
+	yaffs_do_endian_oh(dev, oh);
+
+	yaffs_verify_oh(in, oh, &new_tags, 1);
+
+	/* Create new chunk in NAND */
+	new_chunk_id =
+	    yaffs_write_new_chunk(dev, buffer, &new_tags,
+				  (prev_chunk_id > 0) ? 1 : 0);
+
+	if (buffer)
+		yaffs_release_temp_buffer(dev, buffer);
+
+	if (new_chunk_id < 0)
+		return new_chunk_id;
+
+	in->hdr_chunk = new_chunk_id;
+
+	if (prev_chunk_id > 0)
+		yaffs_chunk_del(dev, prev_chunk_id, 1, __LINE__);
+
+	if (!yaffs_obj_cache_dirty(in))
+		in->dirty = 0;
+
+	/* If this was a shrink, then mark the block
+	 * that the chunk lives on */
+	if (is_shrink) {
+		bi = yaffs_get_block_info(in->my_dev,
+					  new_chunk_id /
+					  in->my_dev->param.chunks_per_block);
+		bi->has_shrink_hdr = 1;
+	}
+
+
+	return new_chunk_id;
+}
+
+/*--------------------- File read/write ------------------------
+ * Read and write have very similar structures.
+ * In general the read/write has three parts to it
+ * An incomplete chunk to start with (if the read/write is not chunk-aligned)
+ * Some complete chunks
+ * An incomplete chunk to end off with
+ *
+ * Curve-balls: the first chunk might also be the last chunk.
+ */
+
+int yaffs_file_rd(struct yaffs_obj *in, u8 * buffer, loff_t offset, int n_bytes)
+{
+	int chunk;
+	u32 start;
+	int n_copy;
+	int n = n_bytes;
+	int n_done = 0;
+	struct yaffs_cache *cache;
+	struct yaffs_dev *dev;
+
+	dev = in->my_dev;
+
+	while (n > 0) {
+		yaffs_addr_to_chunk(dev, offset, &chunk, &start);
+		chunk++;
+
+		/* OK now check for the curveball where the start and end are in
+		 * the same chunk.
+		 */
+		if ((start + n) < dev->data_bytes_per_chunk)
+			n_copy = n;
+		else
+			n_copy = dev->data_bytes_per_chunk - start;
+
+		cache = yaffs_find_chunk_cache(in, chunk);
+
+		/* If the chunk is already in the cache or it is less than
+		 * a whole chunk or we're using inband tags then use the cache
+		 * (if there is caching) else bypass the cache.
+		 */
+		if (cache || n_copy != (int)dev->data_bytes_per_chunk ||
+		    dev->param.inband_tags) {
+			if (dev->param.n_caches > 0) {
+
+				/* If we can't find the data in the cache,
+				 * then load it up. */
+
+				if (!cache) {
+					cache =
+					    yaffs_grab_chunk_cache(in->my_dev);
+					cache->object = in;
+					cache->chunk_id = chunk;
+					cache->dirty = 0;
+					cache->locked = 0;
+					yaffs_rd_data_obj(in, chunk,
+							  cache->data);
+					cache->n_bytes = 0;
+				}
+
+				yaffs_use_cache(dev, cache, 0);
+
+				cache->locked = 1;
+
+				memcpy(buffer, &cache->data[start], n_copy);
+
+				cache->locked = 0;
+			} else {
+				/* Read into the local buffer then copy.. */
+
+				u8 *local_buffer =
+				    yaffs_get_temp_buffer(dev);
+				yaffs_rd_data_obj(in, chunk, local_buffer);
+
+				memcpy(buffer, &local_buffer[start], n_copy);
+
+				yaffs_release_temp_buffer(dev, local_buffer);
+			}
+		} else {
+			/* A full chunk. Read directly into the buffer. */
+			yaffs_rd_data_obj(in, chunk, buffer);
+		}
+		n -= n_copy;
+		offset += n_copy;
+		buffer += n_copy;
+		n_done += n_copy;
+	}
+	return n_done;
+}
+
+int yaffs_do_file_wr(struct yaffs_obj *in, const u8 *buffer, loff_t offset,
+		     int n_bytes, int write_through)
+{
+
+	int chunk;
+	u32 start;
+	int n_copy;
+	int n = n_bytes;
+	int n_done = 0;
+	int n_writeback;
+	loff_t start_write = offset;
+	int chunk_written = 0;
+	u32 n_bytes_read;
+	loff_t chunk_start;
+	struct yaffs_dev *dev;
+
+	dev = in->my_dev;
+
+	while (n > 0 && chunk_written >= 0) {
+		yaffs_addr_to_chunk(dev, offset, &chunk, &start);
+
+		if (((loff_t)chunk) *
+		    dev->data_bytes_per_chunk + start != offset ||
+		    start >= dev->data_bytes_per_chunk) {
+			yaffs_trace(YAFFS_TRACE_ERROR,
+				"AddrToChunk of offset %lld gives chunk %d start %d",
+				(long  long)offset, chunk, start);
+		}
+		chunk++;	/* File pos to chunk in file offset */
+
+		/* OK now check for the curveball where the start and end are in
+		 * the same chunk.
+		 */
+
+		if ((start + n) < dev->data_bytes_per_chunk) {
+			n_copy = n;
+
+			/* Now calculate how many bytes to write back....
+			 * If we're overwriting and not writing to then end of
+			 * file then we need to write back as much as was there
+			 * before.
+			 */
+
+			chunk_start = (((loff_t)(chunk - 1)) *
+					dev->data_bytes_per_chunk);
+
+			if (chunk_start > in->variant.file_variant.file_size)
+				n_bytes_read = 0;	/* Past end of file */
+			else
+				n_bytes_read =
+				    in->variant.file_variant.file_size -
+				    chunk_start;
+
+			if (n_bytes_read > dev->data_bytes_per_chunk)
+				n_bytes_read = dev->data_bytes_per_chunk;
+
+			n_writeback =
+			    (n_bytes_read >
+			     (start + n)) ? n_bytes_read : (start + n);
+
+			if (n_writeback < 0 ||
+			    n_writeback > (int)dev->data_bytes_per_chunk)
+				BUG();
+
+		} else {
+			n_copy = dev->data_bytes_per_chunk - start;
+			n_writeback = dev->data_bytes_per_chunk;
+		}
+
+		if (n_copy != (int)dev->data_bytes_per_chunk ||
+		    !dev->param.cache_bypass_aligned ||
+		    dev->param.inband_tags) {
+			/* An incomplete start or end chunk (or maybe both
+			 * start and end chunk), or we're using inband tags,
+			 * or we're forcing writes through the cache,
+			 * so we want to use the cache buffers.
+			 */
+			if (dev->param.n_caches > 0) {
+				struct yaffs_cache *cache;
+
+				/* If we can't find the data in the cache, then
+				 * load the cache */
+				cache = yaffs_find_chunk_cache(in, chunk);
+
+				if (!cache &&
+				    yaffs_check_alloc_available(dev, 1)) {
+					cache = yaffs_grab_chunk_cache(dev);
+					cache->object = in;
+					cache->chunk_id = chunk;
+					cache->dirty = 0;
+					cache->locked = 0;
+					yaffs_rd_data_obj(in, chunk,
+							  cache->data);
+				} else if (cache &&
+					   !cache->dirty &&
+					   !yaffs_check_alloc_available(dev,
+									1)) {
+					/* Drop the cache if it was a read cache
+					 * item and no space check has been made
+					 * for it.
+					 */
+					cache = NULL;
+				}
+
+				if (cache) {
+					yaffs_use_cache(dev, cache, 1);
+					cache->locked = 1;
+
+					memcpy(&cache->data[start], buffer,
+					       n_copy);
+
+					cache->locked = 0;
+					cache->n_bytes = n_writeback;
+
+					if (write_through) {
+						chunk_written =
+						    yaffs_wr_data_obj
+						    (cache->object,
+						     cache->chunk_id,
+						     cache->data,
+						     cache->n_bytes, 1);
+						cache->dirty = 0;
+					}
+				} else {
+					chunk_written = -1;	/* fail write */
+				}
+			} else {
+				/* An incomplete start or end chunk (or maybe
+				 * both start and end chunk). Read into the
+				 * local buffer then copy over and write back.
+				 */
+
+				u8 *local_buffer = yaffs_get_temp_buffer(dev);
+
+				yaffs_rd_data_obj(in, chunk, local_buffer);
+				memcpy(&local_buffer[start], buffer, n_copy);
+
+				chunk_written =
+				    yaffs_wr_data_obj(in, chunk,
+						      local_buffer,
+						      n_writeback, 0);
+
+				yaffs_release_temp_buffer(dev, local_buffer);
+			}
+		} else {
+			/* A full chunk. Write directly from the buffer. */
+
+			chunk_written =
+			    yaffs_wr_data_obj(in, chunk, buffer,
+					      dev->data_bytes_per_chunk, 0);
+
+			/* Since we've overwritten the cached data,
+			 * we better invalidate it. */
+			yaffs_invalidate_chunk_cache(in, chunk);
+		}
+
+		if (chunk_written >= 0) {
+			n -= n_copy;
+			offset += n_copy;
+			buffer += n_copy;
+			n_done += n_copy;
+		}
+	}
+
+	/* Update file object */
+
+	if ((start_write + n_done) > in->variant.file_variant.file_size)
+		in->variant.file_variant.file_size = (start_write + n_done);
+
+	in->dirty = 1;
+	return n_done;
+}
+
+int yaffs_wr_file(struct yaffs_obj *in, const u8 *buffer, loff_t offset,
+		  int n_bytes, int write_through)
+{
+	yaffs2_handle_hole(in, offset);
+	return yaffs_do_file_wr(in, buffer, offset, n_bytes, write_through);
+}
+
+/* ---------------------- File resizing stuff ------------------ */
+
+static void yaffs_prune_chunks(struct yaffs_obj *in, loff_t new_size)
+{
+
+	struct yaffs_dev *dev = in->my_dev;
+	loff_t old_size = in->variant.file_variant.file_size;
+	int i;
+	int chunk_id;
+	u32 dummy;
+	int last_del;
+	int start_del;
+
+	if (old_size > 0)
+		yaffs_addr_to_chunk(dev, old_size - 1, &last_del, &dummy);
+	else
+		last_del = 0;
+
+	yaffs_addr_to_chunk(dev, new_size + dev->data_bytes_per_chunk - 1,
+				&start_del, &dummy);
+	last_del++;
+	start_del++;
+
+	/* Delete backwards so that we don't end up with holes if
+	 * power is lost part-way through the operation.
+	 */
+	for (i = last_del; i >= start_del; i--) {
+		/* NB this could be optimised somewhat,
+		 * eg. could retrieve the tags and write them without
+		 * using yaffs_chunk_del
+		 */
+
+		chunk_id = yaffs_find_del_file_chunk(in, i, NULL);
+
+		if (chunk_id < 1)
+			continue;
+
+		if ((u32)chunk_id <
+		    (dev->internal_start_block * dev->param.chunks_per_block) ||
+		    (u32)chunk_id >=
+		    ((dev->internal_end_block + 1) *
+		      dev->param.chunks_per_block)) {
+			yaffs_trace(YAFFS_TRACE_ALWAYS,
+				"Found daft chunk_id %d for %d",
+				chunk_id, i);
+		} else {
+			in->n_data_chunks--;
+			yaffs_chunk_del(dev, chunk_id, 1, __LINE__);
+		}
+	}
+}
+
+void yaffs_resize_file_down(struct yaffs_obj *obj, loff_t new_size)
+{
+	int new_full;
+	u32 new_partial;
+	struct yaffs_dev *dev = obj->my_dev;
+
+	yaffs_addr_to_chunk(dev, new_size, &new_full, &new_partial);
+
+	yaffs_prune_chunks(obj, new_size);
+
+	if (new_partial != 0) {
+		int last_chunk = 1 + new_full;
+		u8 *local_buffer = yaffs_get_temp_buffer(dev);
+
+		/* Rewrite the last chunk with its new size and zero pad */
+		yaffs_rd_data_obj(obj, last_chunk, local_buffer);
+		memset(local_buffer + new_partial, 0,
+		       dev->data_bytes_per_chunk - new_partial);
+
+		yaffs_wr_data_obj(obj, last_chunk, local_buffer,
+				  new_partial, 1);
+
+		yaffs_release_temp_buffer(dev, local_buffer);
+	}
+
+	obj->variant.file_variant.file_size = new_size;
+	obj->variant.file_variant.stored_size = new_size;
+
+	yaffs_prune_tree(dev, &obj->variant.file_variant);
+}
+
+int yaffs_resize_file(struct yaffs_obj *in, loff_t new_size)
+{
+	struct yaffs_dev *dev = in->my_dev;
+	loff_t old_size = in->variant.file_variant.file_size;
+
+	yaffs_flush_file_cache(in, 1);
+	yaffs_invalidate_whole_cache(in);
+
+	yaffs_check_gc(dev, 0);
+
+	if (in->variant_type != YAFFS_OBJECT_TYPE_FILE)
+		return YAFFS_FAIL;
+
+	if (new_size == old_size)
+		return YAFFS_OK;
+
+	if (new_size > old_size) {
+		yaffs2_handle_hole(in, new_size);
+		in->variant.file_variant.file_size = new_size;
+	} else {
+		/* new_size < old_size */
+		yaffs_resize_file_down(in, new_size);
+	}
+
+	/* Write a new object header to reflect the resize.
+	 * show we've shrunk the file, if need be
+	 * Do this only if the file is not in the deleted directories
+	 * and is not shadowed.
+	 */
+	if (in->parent &&
+	    !in->is_shadowed &&
+	    in->parent->obj_id != YAFFS_OBJECTID_UNLINKED &&
+	    in->parent->obj_id != YAFFS_OBJECTID_DELETED)
+		yaffs_update_oh(in, NULL, 0, 0, 0, NULL);
+
+	return YAFFS_OK;
+}
+
+int yaffs_flush_file(struct yaffs_obj *in,
+		     int update_time,
+		     int data_sync,
+		     int discard_cache)
+{
+	if (!in->dirty)
+		return YAFFS_OK;
+
+	yaffs_flush_file_cache(in, discard_cache);
+
+	if (data_sync)
+		return YAFFS_OK;
+
+	if (update_time)
+		yaffs_load_current_time(in, 0, 0);
+
+	return (yaffs_update_oh(in, NULL, 0, 0, 0, NULL) >= 0) ?
+				YAFFS_OK : YAFFS_FAIL;
+}
+
+
+/* yaffs_del_file deletes the whole file data
+ * and the inode associated with the file.
+ * It does not delete the links associated with the file.
+ */
+static int yaffs_unlink_file_if_needed(struct yaffs_obj *in)
+{
+	int ret_val;
+	int del_now = 0;
+	struct yaffs_dev *dev = in->my_dev;
+
+	if (!in->my_inode)
+		del_now = 1;
+
+	if (del_now) {
+		ret_val =
+		    yaffs_change_obj_name(in, in->my_dev->del_dir,
+					  _Y("deleted"), 0, 0);
+		yaffs_trace(YAFFS_TRACE_TRACING,
+			"yaffs: immediate deletion of file %d",
+			in->obj_id);
+		in->deleted = 1;
+		in->my_dev->n_deleted_files++;
+		if (dev->param.disable_soft_del || dev->param.is_yaffs2)
+			yaffs_resize_file(in, 0);
+		yaffs_soft_del_file(in);
+	} else {
+		ret_val =
+		    yaffs_change_obj_name(in, in->my_dev->unlinked_dir,
+					  _Y("unlinked"), 0, 0);
+	}
+	return ret_val;
+}
+
+static int yaffs_del_file(struct yaffs_obj *in)
+{
+	int ret_val = YAFFS_OK;
+	int deleted;	/* Need to cache value on stack if in is freed */
+	struct yaffs_dev *dev = in->my_dev;
+
+	if (dev->param.disable_soft_del || dev->param.is_yaffs2)
+		yaffs_resize_file(in, 0);
+
+	if (in->n_data_chunks > 0) {
+		/* Use soft deletion if there is data in the file.
+		 * That won't be the case if it has been resized to zero.
+		 */
+		if (!in->unlinked)
+			ret_val = yaffs_unlink_file_if_needed(in);
+
+		deleted = in->deleted;
+
+		if (ret_val == YAFFS_OK && in->unlinked && !in->deleted) {
+			in->deleted = 1;
+			deleted = 1;
+			in->my_dev->n_deleted_files++;
+			yaffs_soft_del_file(in);
+		}
+		return deleted ? YAFFS_OK : YAFFS_FAIL;
+	} else {
+		/* The file has no data chunks so we toss it immediately */
+		yaffs_free_tnode(in->my_dev, in->variant.file_variant.top);
+		in->variant.file_variant.top = NULL;
+		yaffs_generic_obj_del(in);
+
+		return YAFFS_OK;
+	}
+}
+
+int yaffs_is_non_empty_dir(struct yaffs_obj *obj)
+{
+	return (obj &&
+		obj->variant_type == YAFFS_OBJECT_TYPE_DIRECTORY) &&
+		!(list_empty(&obj->variant.dir_variant.children));
+}
+
+static int yaffs_del_dir(struct yaffs_obj *obj)
+{
+	/* First check that the directory is empty. */
+	if (yaffs_is_non_empty_dir(obj))
+		return YAFFS_FAIL;
+
+	return yaffs_generic_obj_del(obj);
+}
+
+static int yaffs_del_symlink(struct yaffs_obj *in)
+{
+	kfree(in->variant.symlink_variant.alias);
+	in->variant.symlink_variant.alias = NULL;
+
+	return yaffs_generic_obj_del(in);
+}
+
+static int yaffs_del_link(struct yaffs_obj *in)
+{
+	/* remove this hardlink from the list associated with the equivalent
+	 * object
+	 */
+	list_del_init(&in->hard_links);
+	return yaffs_generic_obj_del(in);
+}
+
+int yaffs_del_obj(struct yaffs_obj *obj)
+{
+	int ret_val = -1;
+
+	switch (obj->variant_type) {
+	case YAFFS_OBJECT_TYPE_FILE:
+		ret_val = yaffs_del_file(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_DIRECTORY:
+		if (!list_empty(&obj->variant.dir_variant.dirty)) {
+			yaffs_trace(YAFFS_TRACE_BACKGROUND,
+				"Remove object %d from dirty directories",
+				obj->obj_id);
+			list_del_init(&obj->variant.dir_variant.dirty);
+		}
+		return yaffs_del_dir(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_SYMLINK:
+		ret_val = yaffs_del_symlink(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_HARDLINK:
+		ret_val = yaffs_del_link(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_SPECIAL:
+		ret_val = yaffs_generic_obj_del(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_UNKNOWN:
+		ret_val = 0;
+		break;		/* should not happen. */
+	}
+	return ret_val;
+}
+
+
+static void yaffs_empty_dir_to_dir(struct yaffs_obj *from_dir,
+				   struct yaffs_obj *to_dir)
+{
+	struct yaffs_obj *obj;
+	struct list_head *lh;
+	struct list_head *n;
+
+	list_for_each_safe(lh, n, &from_dir->variant.dir_variant.children) {
+		obj = list_entry(lh, struct yaffs_obj, siblings);
+		yaffs_add_obj_to_dir(to_dir, obj);
+	}
+}
+
+struct yaffs_obj *yaffs_retype_obj(struct yaffs_obj *obj,
+				   enum yaffs_obj_type type)
+{
+	/* Tear down the old variant */
+	switch (obj->variant_type) {
+	case YAFFS_OBJECT_TYPE_FILE:
+		/* Nuke file data */
+		yaffs_resize_file(obj, 0);
+		yaffs_free_tnode(obj->my_dev, obj->variant.file_variant.top);
+		obj->variant.file_variant.top = NULL;
+		break;
+	case YAFFS_OBJECT_TYPE_DIRECTORY:
+		/* Put the children in lost and found. */
+		yaffs_empty_dir_to_dir(obj, obj->my_dev->lost_n_found);
+		if (!list_empty(&obj->variant.dir_variant.dirty))
+			list_del_init(&obj->variant.dir_variant.dirty);
+		break;
+	case YAFFS_OBJECT_TYPE_SYMLINK:
+		/* Nuke symplink data */
+		kfree(obj->variant.symlink_variant.alias);
+		obj->variant.symlink_variant.alias = NULL;
+		break;
+	case YAFFS_OBJECT_TYPE_HARDLINK:
+		list_del_init(&obj->hard_links);
+		break;
+	default:
+		break;
+	}
+
+	memset(&obj->variant, 0, sizeof(obj->variant));
+
+	/*Set up new variant if the memset is not enough. */
+	switch (type) {
+	case YAFFS_OBJECT_TYPE_DIRECTORY:
+		INIT_LIST_HEAD(&obj->variant.dir_variant.children);
+		INIT_LIST_HEAD(&obj->variant.dir_variant.dirty);
+		break;
+	case YAFFS_OBJECT_TYPE_FILE:
+	case YAFFS_OBJECT_TYPE_SYMLINK:
+	case YAFFS_OBJECT_TYPE_HARDLINK:
+	default:
+		break;
+	}
+
+	obj->variant_type = type;
+
+	return obj;
+
+}
+
+static int yaffs_unlink_worker(struct yaffs_obj *obj)
+{
+	int del_now = 0;
+
+	if (!obj)
+		return YAFFS_FAIL;
+
+	if (!obj->my_inode)
+		del_now = 1;
+
+	yaffs_update_parent(obj->parent);
+
+	if (obj->variant_type == YAFFS_OBJECT_TYPE_HARDLINK) {
+		return yaffs_del_link(obj);
+	} else if (!list_empty(&obj->hard_links)) {
+		/* Curve ball: We're unlinking an object that has a hardlink.
+		 *
+		 * This problem arises because we are not strictly following
+		 * The Linux link/inode model.
+		 *
+		 * We can't really delete the object.
+		 * Instead, we do the following:
+		 * - Select a hardlink.
+		 * - Unhook it from the hard links
+		 * - Move it from its parent directory so that the rename works.
+		 * - Rename the object to the hardlink's name.
+		 * - Delete the hardlink
+		 */
+
+		struct yaffs_obj *hl;
+		struct yaffs_obj *parent;
+		int ret_val;
+		YCHAR name[YAFFS_MAX_NAME_LENGTH + 1];
+
+		hl = list_entry(obj->hard_links.next, struct yaffs_obj,
+				hard_links);
+
+		yaffs_get_obj_name(hl, name, YAFFS_MAX_NAME_LENGTH + 1);
+		parent = hl->parent;
+
+		list_del_init(&hl->hard_links);
+
+		yaffs_add_obj_to_dir(obj->my_dev->unlinked_dir, hl);
+
+		ret_val = yaffs_change_obj_name(obj, parent, name, 0, 0);
+
+		if (ret_val == YAFFS_OK)
+			ret_val = yaffs_generic_obj_del(hl);
+
+		return ret_val;
+
+	} else if (del_now) {
+		switch (obj->variant_type) {
+		case YAFFS_OBJECT_TYPE_FILE:
+			return yaffs_del_file(obj);
+			break;
+		case YAFFS_OBJECT_TYPE_DIRECTORY:
+			list_del_init(&obj->variant.dir_variant.dirty);
+			return yaffs_del_dir(obj);
+			break;
+		case YAFFS_OBJECT_TYPE_SYMLINK:
+			return yaffs_del_symlink(obj);
+			break;
+		case YAFFS_OBJECT_TYPE_SPECIAL:
+			return yaffs_generic_obj_del(obj);
+			break;
+		case YAFFS_OBJECT_TYPE_HARDLINK:
+		case YAFFS_OBJECT_TYPE_UNKNOWN:
+		default:
+			return YAFFS_FAIL;
+		}
+	} else if (yaffs_is_non_empty_dir(obj)) {
+		return YAFFS_FAIL;
+	} else {
+		return yaffs_change_obj_name(obj, obj->my_dev->unlinked_dir,
+						_Y("unlinked"), 0, 0);
+	}
+}
+
+int yaffs_unlink_obj(struct yaffs_obj *obj)
+{
+	if (obj && obj->unlink_allowed)
+		return yaffs_unlink_worker(obj);
+
+	return YAFFS_FAIL;
+}
+
+int yaffs_unlinker(struct yaffs_obj *dir, const YCHAR *name)
+{
+	struct yaffs_obj *obj;
+
+	obj = yaffs_find_by_name(dir, name);
+	return yaffs_unlink_obj(obj);
+}
+
+/* Note:
+ * If old_name is NULL then we take old_dir as the object to be renamed.
+ */
+int yaffs_rename_obj(struct yaffs_obj *old_dir, const YCHAR *old_name,
+		     struct yaffs_obj *new_dir, const YCHAR *new_name)
+{
+	struct yaffs_obj *obj = NULL;
+	struct yaffs_obj *existing_target = NULL;
+	int force = 0;
+	int result;
+	struct yaffs_dev *dev;
+
+	if (!old_dir || old_dir->variant_type != YAFFS_OBJECT_TYPE_DIRECTORY) {
+		BUG();
+		return YAFFS_FAIL;
+	}
+	if (!new_dir || new_dir->variant_type != YAFFS_OBJECT_TYPE_DIRECTORY) {
+		BUG();
+		return YAFFS_FAIL;
+	}
+
+	dev = old_dir->my_dev;
+
+#ifdef CONFIG_YAFFS_CASE_INSENSITIVE
+	/* Special case for case insemsitive systems.
+	 * While look-up is case insensitive, the name isn't.
+	 * Therefore we might want to change x.txt to X.txt
+	 */
+	if (old_dir == new_dir &&
+		old_name && new_name &&
+		strcmp(old_name, new_name) == 0)
+		force = 1;
+#endif
+
+	if (strnlen(new_name, YAFFS_MAX_NAME_LENGTH + 1) >
+	    YAFFS_MAX_NAME_LENGTH)
+		/* ENAMETOOLONG */
+		return YAFFS_FAIL;
+
+	if (old_name)
+		obj = yaffs_find_by_name(old_dir, old_name);
+	else{
+		obj = old_dir;
+		old_dir = obj->parent;
+	}
+
+	if (obj && obj->rename_allowed) {
+		/* Now handle an existing target, if there is one */
+		existing_target = yaffs_find_by_name(new_dir, new_name);
+		if (yaffs_is_non_empty_dir(existing_target)) {
+			return YAFFS_FAIL;	/* ENOTEMPTY */
+		} else if (existing_target && existing_target != obj) {
+			/* Nuke the target first, using shadowing,
+			 * but only if it isn't the same object.
+			 *
+			 * Note we must disable gc here otherwise it can mess
+			 * up the shadowing.
+			 *
+			 */
+			dev->gc_disable = 1;
+			yaffs_change_obj_name(obj, new_dir, new_name, force,
+					      existing_target->obj_id);
+			existing_target->is_shadowed = 1;
+			yaffs_unlink_obj(existing_target);
+			dev->gc_disable = 0;
+		}
+
+		result = yaffs_change_obj_name(obj, new_dir, new_name, 1, 0);
+
+		yaffs_update_parent(old_dir);
+		if (new_dir != old_dir)
+			yaffs_update_parent(new_dir);
+
+		return result;
+	}
+	return YAFFS_FAIL;
+}
+
+/*----------------------- Initialisation Scanning ---------------------- */
+
+void yaffs_handle_shadowed_obj(struct yaffs_dev *dev, int obj_id,
+			       int backward_scanning)
+{
+	struct yaffs_obj *obj;
+
+	if (backward_scanning) {
+		/* Handle YAFFS2 case (backward scanning)
+		 * If the shadowed object exists then ignore.
+		 */
+		obj = yaffs_find_by_number(dev, obj_id);
+		if (obj)
+			return;
+	}
+
+	/* Let's create it (if it does not exist) assuming it is a file so that
+	 * it can do shrinking etc.
+	 * We put it in unlinked dir to be cleaned up after the scanning
+	 */
+	obj =
+	    yaffs_find_or_create_by_number(dev, obj_id, YAFFS_OBJECT_TYPE_FILE);
+	if (!obj)
+		return;
+	obj->is_shadowed = 1;
+	yaffs_add_obj_to_dir(dev->unlinked_dir, obj);
+	obj->variant.file_variant.shrink_size = 0;
+	obj->valid = 1;		/* So that we don't read any other info. */
+}
+
+void yaffs_link_fixup(struct yaffs_dev *dev, struct list_head *hard_list)
+{
+	struct list_head *lh;
+	struct list_head *save;
+	struct yaffs_obj *hl;
+	struct yaffs_obj *in;
+
+	list_for_each_safe(lh, save, hard_list) {
+		hl = list_entry(lh, struct yaffs_obj, hard_links);
+		in = yaffs_find_by_number(dev,
+					hl->variant.hardlink_variant.equiv_id);
+
+		if (in) {
+			/* Add the hardlink pointers */
+			hl->variant.hardlink_variant.equiv_obj = in;
+			list_add(&hl->hard_links, &in->hard_links);
+		} else {
+			/* Todo Need to report/handle this better.
+			 * Got a problem... hardlink to a non-existant object
+			 */
+			hl->variant.hardlink_variant.equiv_obj = NULL;
+			INIT_LIST_HEAD(&hl->hard_links);
+		}
+	}
+}
+
+static void yaffs_strip_deleted_objs(struct yaffs_dev *dev)
+{
+	/*
+	 *  Sort out state of unlinked and deleted objects after scanning.
+	 */
+	struct list_head *i;
+	struct list_head *n;
+	struct yaffs_obj *l;
+
+	if (dev->read_only)
+		return;
+
+	/* Soft delete all the unlinked files */
+	list_for_each_safe(i, n,
+			   &dev->unlinked_dir->variant.dir_variant.children) {
+		l = list_entry(i, struct yaffs_obj, siblings);
+		yaffs_del_obj(l);
+	}
+
+	list_for_each_safe(i, n, &dev->del_dir->variant.dir_variant.children) {
+		l = list_entry(i, struct yaffs_obj, siblings);
+		yaffs_del_obj(l);
+	}
+}
+
+/*
+ * This code iterates through all the objects making sure that they are rooted.
+ * Any unrooted objects are re-rooted in lost+found.
+ * An object needs to be in one of:
+ * - Directly under deleted, unlinked
+ * - Directly or indirectly under root.
+ *
+ * Note:
+ *  This code assumes that we don't ever change the current relationships
+ *  between directories:
+ *   root_dir->parent == unlinked_dir->parent == del_dir->parent == NULL
+ *   lost-n-found->parent == root_dir
+ *
+ * This fixes the problem where directories might have inadvertently been
+ * deleted leaving the object "hanging" without being rooted in the
+ * directory tree.
+ */
+
+static int yaffs_has_null_parent(struct yaffs_dev *dev, struct yaffs_obj *obj)
+{
+	return (obj == dev->del_dir ||
+		obj == dev->unlinked_dir || obj == dev->root_dir);
+}
+
+static void yaffs_fix_hanging_objs(struct yaffs_dev *dev)
+{
+	struct yaffs_obj *obj;
+	struct yaffs_obj *parent;
+	int i;
+	struct list_head *lh;
+	struct list_head *n;
+	int depth_limit;
+	int hanging;
+
+	if (dev->read_only)
+		return;
+
+	/* Iterate through the objects in each hash entry,
+	 * looking at each object.
+	 * Make sure it is rooted.
+	 */
+
+	for (i = 0; i < YAFFS_NOBJECT_BUCKETS; i++) {
+		list_for_each_safe(lh, n, &dev->obj_bucket[i].list) {
+			obj = list_entry(lh, struct yaffs_obj, hash_link);
+			parent = obj->parent;
+
+			if (yaffs_has_null_parent(dev, obj)) {
+				/* These directories are not hanging */
+				hanging = 0;
+			} else if (!parent ||
+				   parent->variant_type !=
+				   YAFFS_OBJECT_TYPE_DIRECTORY) {
+				hanging = 1;
+			} else if (yaffs_has_null_parent(dev, parent)) {
+				hanging = 0;
+			} else {
+				/*
+				 * Need to follow the parent chain to
+				 * see if it is hanging.
+				 */
+				hanging = 0;
+				depth_limit = 100;
+
+				while (parent != dev->root_dir &&
+				       parent->parent &&
+				       parent->parent->variant_type ==
+				       YAFFS_OBJECT_TYPE_DIRECTORY &&
+				       depth_limit > 0) {
+					parent = parent->parent;
+					depth_limit--;
+				}
+				if (parent != dev->root_dir)
+					hanging = 1;
+			}
+			if (hanging) {
+				yaffs_trace(YAFFS_TRACE_SCAN,
+					"Hanging object %d moved to lost and found",
+					obj->obj_id);
+				yaffs_add_obj_to_dir(dev->lost_n_found, obj);
+			}
+		}
+	}
+}
+
+/*
+ * Delete directory contents for cleaning up lost and found.
+ */
+static void yaffs_del_dir_contents(struct yaffs_obj *dir)
+{
+	struct yaffs_obj *obj;
+	struct list_head *lh;
+	struct list_head *n;
+
+	if (dir->variant_type != YAFFS_OBJECT_TYPE_DIRECTORY)
+		BUG();
+
+	list_for_each_safe(lh, n, &dir->variant.dir_variant.children) {
+		obj = list_entry(lh, struct yaffs_obj, siblings);
+		if (obj->variant_type == YAFFS_OBJECT_TYPE_DIRECTORY)
+			yaffs_del_dir_contents(obj);
+		yaffs_trace(YAFFS_TRACE_SCAN,
+			"Deleting lost_found object %d",
+			obj->obj_id);
+		yaffs_unlink_obj(obj);
+	}
+}
+
+static void yaffs_empty_l_n_f(struct yaffs_dev *dev)
+{
+	yaffs_del_dir_contents(dev->lost_n_found);
+}
+
+
+struct yaffs_obj *yaffs_find_by_name(struct yaffs_obj *directory,
+				     const YCHAR *name)
+{
+	int sum;
+	struct list_head *i;
+	YCHAR buffer[YAFFS_MAX_NAME_LENGTH + 1];
+	struct yaffs_obj *l;
+
+	if (!name)
+		return NULL;
+
+	if (!directory) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"tragedy: yaffs_find_by_name: null pointer directory"
+			);
+		BUG();
+		return NULL;
+	}
+	if (directory->variant_type != YAFFS_OBJECT_TYPE_DIRECTORY) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"tragedy: yaffs_find_by_name: non-directory"
+			);
+		BUG();
+	}
+
+	sum = yaffs_calc_name_sum(name);
+
+	list_for_each(i, &directory->variant.dir_variant.children) {
+		l = list_entry(i, struct yaffs_obj, siblings);
+
+		if (l->parent != directory)
+			BUG();
+
+		yaffs_check_obj_details_loaded(l);
+
+		/* Special case for lost-n-found */
+		if (l->obj_id == YAFFS_OBJECTID_LOSTNFOUND) {
+			if (!strcmp(name, YAFFS_LOSTNFOUND_NAME))
+				return l;
+		} else if (l->sum == sum || l->hdr_chunk <= 0) {
+			/* LostnFound chunk called Objxxx
+			 * Do a real check
+			 */
+			yaffs_get_obj_name(l, buffer,
+				YAFFS_MAX_NAME_LENGTH + 1);
+			if (!strncmp(name, buffer, YAFFS_MAX_NAME_LENGTH))
+				return l;
+		}
+	}
+	return NULL;
+}
+
+/* GetEquivalentObject dereferences any hard links to get to the
+ * actual object.
+ */
+
+struct yaffs_obj *yaffs_get_equivalent_obj(struct yaffs_obj *obj)
+{
+	if (obj && obj->variant_type == YAFFS_OBJECT_TYPE_HARDLINK) {
+		obj = obj->variant.hardlink_variant.equiv_obj;
+		yaffs_check_obj_details_loaded(obj);
+	}
+	return obj;
+}
+
+/*
+ *  A note or two on object names.
+ *  * If the object name is missing, we then make one up in the form objnnn
+ *
+ *  * ASCII names are stored in the object header's name field from byte zero
+ *  * Unicode names are historically stored starting from byte zero.
+ *
+ * Then there are automatic Unicode names...
+ * The purpose of these is to save names in a way that can be read as
+ * ASCII or Unicode names as appropriate, thus allowing a Unicode and ASCII
+ * system to share files.
+ *
+ * These automatic unicode are stored slightly differently...
+ *  - If the name can fit in the ASCII character space then they are saved as
+ *    ascii names as per above.
+ *  - If the name needs Unicode then the name is saved in Unicode
+ *    starting at oh->name[1].
+
+ */
+static void yaffs_fix_null_name(struct yaffs_obj *obj, YCHAR *name,
+				int buffer_size)
+{
+	/* Create an object name if we could not find one. */
+	if (strnlen(name, YAFFS_MAX_NAME_LENGTH) == 0) {
+		YCHAR local_name[20];
+		YCHAR num_string[20];
+		YCHAR *x = &num_string[19];
+		unsigned v = obj->obj_id;
+		num_string[19] = 0;
+		while (v > 0) {
+			x--;
+			*x = '0' + (v % 10);
+			v /= 10;
+		}
+		/* make up a name */
+		strcpy(local_name, YAFFS_LOSTNFOUND_PREFIX);
+		strcat(local_name, x);
+		strncpy(name, local_name, buffer_size - 1);
+	}
+}
+
+int yaffs_get_obj_name(struct yaffs_obj *obj, YCHAR *name, int buffer_size)
+{
+	memset(name, 0, buffer_size * sizeof(YCHAR));
+	yaffs_check_obj_details_loaded(obj);
+	if (obj->obj_id == YAFFS_OBJECTID_LOSTNFOUND) {
+		strncpy(name, YAFFS_LOSTNFOUND_NAME, buffer_size - 1);
+	} else if (obj->short_name[0]) {
+		strcpy(name, obj->short_name);
+	} else if (obj->hdr_chunk > 0) {
+		int result = 0;
+		u8 *buffer = yaffs_get_temp_buffer(obj->my_dev);
+
+		struct yaffs_obj_hdr *oh = (struct yaffs_obj_hdr *)buffer;
+
+		memset(buffer, 0, obj->my_dev->data_bytes_per_chunk);
+
+		if (obj->hdr_chunk > 0) {
+			result = yaffs_rd_chunk_tags_nand(obj->my_dev,
+							  obj->hdr_chunk,
+							  buffer, NULL);
+		}
+		if (result == YAFFS_OK)
+			yaffs_load_name_from_oh(obj->my_dev, name, oh->name,
+					buffer_size);
+
+		yaffs_release_temp_buffer(obj->my_dev, buffer);
+	}
+
+	yaffs_fix_null_name(obj, name, buffer_size);
+
+	return strnlen(name, YAFFS_MAX_NAME_LENGTH);
+}
+
+loff_t yaffs_get_obj_length(struct yaffs_obj *obj)
+{
+	/* Dereference any hard linking */
+	obj = yaffs_get_equivalent_obj(obj);
+
+	if (obj->variant_type == YAFFS_OBJECT_TYPE_FILE)
+		return obj->variant.file_variant.file_size;
+	if (obj->variant_type == YAFFS_OBJECT_TYPE_SYMLINK) {
+		if (!obj->variant.symlink_variant.alias)
+			return 0;
+		return strnlen(obj->variant.symlink_variant.alias,
+				     YAFFS_MAX_ALIAS_LENGTH);
+	} else {
+		/* Only a directory should drop through to here */
+		return obj->my_dev->data_bytes_per_chunk;
+	}
+}
+
+int yaffs_get_obj_link_count(struct yaffs_obj *obj)
+{
+	int count = 0;
+	struct list_head *i;
+
+	if (!obj->unlinked)
+		count++;	/* the object itself */
+
+	list_for_each(i, &obj->hard_links)
+	    count++;		/* add the hard links; */
+
+	return count;
+}
+
+int yaffs_get_obj_inode(struct yaffs_obj *obj)
+{
+	obj = yaffs_get_equivalent_obj(obj);
+
+	return obj->obj_id;
+}
+
+unsigned yaffs_get_obj_type(struct yaffs_obj *obj)
+{
+	obj = yaffs_get_equivalent_obj(obj);
+
+	switch (obj->variant_type) {
+	case YAFFS_OBJECT_TYPE_FILE:
+		return DT_REG;
+		break;
+	case YAFFS_OBJECT_TYPE_DIRECTORY:
+		return DT_DIR;
+		break;
+	case YAFFS_OBJECT_TYPE_SYMLINK:
+		return DT_LNK;
+		break;
+	case YAFFS_OBJECT_TYPE_HARDLINK:
+		return DT_REG;
+		break;
+	case YAFFS_OBJECT_TYPE_SPECIAL:
+		if (S_ISFIFO(obj->yst_mode))
+			return DT_FIFO;
+		if (S_ISCHR(obj->yst_mode))
+			return DT_CHR;
+		if (S_ISBLK(obj->yst_mode))
+			return DT_BLK;
+		if (S_ISSOCK(obj->yst_mode))
+			return DT_SOCK;
+		return DT_REG;
+		break;
+	default:
+		return DT_REG;
+		break;
+	}
+}
+
+YCHAR *yaffs_get_symlink_alias(struct yaffs_obj *obj)
+{
+	obj = yaffs_get_equivalent_obj(obj);
+	if (obj->variant_type == YAFFS_OBJECT_TYPE_SYMLINK)
+		return yaffs_clone_str(obj->variant.symlink_variant.alias);
+	else
+		return yaffs_clone_str(_Y(""));
+}
+
+/*--------------------------- Initialisation code -------------------------- */
+
+static int yaffs_check_dev_fns(struct yaffs_dev *dev)
+{
+	struct yaffs_driver *drv = &dev->drv;
+	struct yaffs_tags_handler *tagger = &dev->tagger;
+
+	/* Common functions, gotta have */
+	if (!drv->drv_read_chunk_fn ||
+	    !drv->drv_write_chunk_fn ||
+	    !drv->drv_erase_fn)
+		return 0;
+
+	if (dev->param.is_yaffs2 &&
+	     (!drv->drv_mark_bad_fn  || !drv->drv_check_bad_fn))
+		return 0;
+
+	/* Install the default tags marshalling functions if needed. */
+	yaffs_tags_compat_install(dev);
+	yaffs_tags_marshall_install(dev);
+
+	/* Check we now have the marshalling functions required. */
+	if (!tagger->write_chunk_tags_fn ||
+	    !tagger->read_chunk_tags_fn ||
+	    !tagger->query_block_fn ||
+	    !tagger->mark_bad_fn)
+		return 0;
+
+	return 1;
+}
+
+static int yaffs_create_initial_dir(struct yaffs_dev *dev)
+{
+	/* Initialise the unlinked, deleted, root and lost+found directories */
+	dev->lost_n_found = NULL;
+	dev->root_dir = NULL;
+	dev->unlinked_dir = NULL;
+	dev->del_dir = NULL;
+
+	dev->unlinked_dir =
+	    yaffs_create_fake_dir(dev, YAFFS_OBJECTID_UNLINKED, S_IFDIR);
+	dev->del_dir =
+	    yaffs_create_fake_dir(dev, YAFFS_OBJECTID_DELETED, S_IFDIR);
+	dev->root_dir =
+	    yaffs_create_fake_dir(dev, YAFFS_OBJECTID_ROOT,
+				  YAFFS_ROOT_MODE | S_IFDIR);
+	dev->lost_n_found =
+	    yaffs_create_fake_dir(dev, YAFFS_OBJECTID_LOSTNFOUND,
+				  YAFFS_LOSTNFOUND_MODE | S_IFDIR);
+
+	if (dev->lost_n_found &&
+		dev->root_dir &&
+		dev->unlinked_dir &&
+		dev->del_dir) {
+			/* If lost-n-found is hidden then yank it out of the directory tree. */
+			if (dev->param.hide_lost_n_found)
+				list_del_init(&dev->lost_n_found->siblings);
+			else
+				yaffs_add_obj_to_dir(dev->root_dir, dev->lost_n_found);
+		return YAFFS_OK;
+	}
+	return YAFFS_FAIL;
+}
+
+/* Low level init.
+ * Typically only used by yaffs_guts_initialise, but also used by the
+ * Low level yaffs driver tests.
+ */
+
+int yaffs_guts_ll_init(struct yaffs_dev *dev)
+{
+
+
+	yaffs_trace(YAFFS_TRACE_TRACING, "yaffs: yaffs_ll_init()");
+
+	if (!dev) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"yaffs: Need a device"
+			);
+		return YAFFS_FAIL;
+	}
+
+	if (dev->ll_init)
+		return YAFFS_OK;
+
+	dev->internal_start_block = dev->param.start_block;
+	dev->internal_end_block = dev->param.end_block;
+	dev->block_offset = 0;
+	dev->chunk_offset = 0;
+	dev->n_free_chunks = 0;
+
+	dev->gc_block = 0;
+
+	if (dev->param.start_block == 0) {
+		dev->internal_start_block = dev->param.start_block + 1;
+		dev->internal_end_block = dev->param.end_block + 1;
+		dev->block_offset = 1;
+		dev->chunk_offset = dev->param.chunks_per_block;
+	}
+
+	/* Check geometry parameters. */
+
+	if ((!dev->param.inband_tags && dev->param.is_yaffs2 &&
+		dev->param.total_bytes_per_chunk < 1024) ||
+		(!dev->param.is_yaffs2 &&
+			dev->param.total_bytes_per_chunk < 512) ||
+		(dev->param.inband_tags && !dev->param.is_yaffs2) ||
+		 dev->param.chunks_per_block < 2 ||
+		 dev->param.n_reserved_blocks < 2 ||
+		dev->internal_start_block <= 0 ||
+		dev->internal_end_block <= 0 ||
+		dev->internal_end_block <=
+		(dev->internal_start_block + dev->param.n_reserved_blocks + 2)
+		) {
+		/* otherwise it is too small */
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"NAND geometry problems: chunk size %d, type is yaffs%s, inband_tags %d ",
+			dev->param.total_bytes_per_chunk,
+			dev->param.is_yaffs2 ? "2" : "",
+			dev->param.inband_tags);
+		return YAFFS_FAIL;
+	}
+
+	/* Sort out space for inband tags, if required */
+	if (dev->param.inband_tags)
+		dev->data_bytes_per_chunk =
+		    dev->param.total_bytes_per_chunk -
+		    sizeof(struct yaffs_packed_tags2_tags_only);
+	else
+		dev->data_bytes_per_chunk = dev->param.total_bytes_per_chunk;
+
+	/* Got the right mix of functions? */
+	if (!yaffs_check_dev_fns(dev)) {
+		/* Function missing */
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"device function(s) missing or wrong");
+
+		return YAFFS_FAIL;
+	}
+
+	if (yaffs_init_nand(dev) != YAFFS_OK) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS, "InitialiseNAND failed");
+		return YAFFS_FAIL;
+	}
+
+	return YAFFS_OK;
+}
+
+
+int yaffs_guts_format_dev(struct yaffs_dev *dev)
+{
+	u32 i;
+	enum yaffs_block_state state;
+	u32 dummy;
+
+	if(yaffs_guts_ll_init(dev) != YAFFS_OK)
+		return YAFFS_FAIL;
+
+	if(dev->is_mounted)
+		return YAFFS_FAIL;
+
+	for (i = dev->internal_start_block; i <= dev->internal_end_block; i++) {
+		yaffs_query_init_block_state(dev, i, &state, &dummy);
+		if (state != YAFFS_BLOCK_STATE_DEAD)
+			yaffs_erase_block(dev, i);
+	}
+
+	return YAFFS_OK;
+}
+
+
+int yaffs_guts_initialise(struct yaffs_dev *dev)
+{
+	int init_failed = 0;
+	u32 x;
+	u32 bits;
+
+	if(yaffs_guts_ll_init(dev) != YAFFS_OK)
+		return YAFFS_FAIL;
+
+	if (dev->is_mounted) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS, "device already mounted");
+		return YAFFS_FAIL;
+	}
+
+	dev->is_mounted = 1;
+
+	/* OK now calculate a few things for the device */
+
+	/*
+	 *  Calculate all the chunk size manipulation numbers:
+	 */
+	x = dev->data_bytes_per_chunk;
+	/* We always use dev->chunk_shift and dev->chunk_div */
+	dev->chunk_shift = calc_shifts(x);
+	x >>= dev->chunk_shift;
+	dev->chunk_div = x;
+	/* We only use chunk mask if chunk_div is 1 */
+	dev->chunk_mask = (1 << dev->chunk_shift) - 1;
+
+	/*
+	 * Calculate chunk_grp_bits.
+	 * We need to find the next power of 2 > than internal_end_block
+	 */
+
+	x = dev->param.chunks_per_block * (dev->internal_end_block + 1);
+
+	bits = calc_shifts_ceiling(x);
+
+	/* Set up tnode width if wide tnodes are enabled. */
+	if (!dev->param.wide_tnodes_disabled) {
+		/* bits must be even so that we end up with 32-bit words */
+		if (bits & 1)
+			bits++;
+		if (bits < 16)
+			dev->tnode_width = 16;
+		else
+			dev->tnode_width = bits;
+	} else {
+		dev->tnode_width = 16;
+	}
+
+	dev->tnode_mask = (1 << dev->tnode_width) - 1;
+
+	/* Level0 Tnodes are 16 bits or wider (if wide tnodes are enabled),
+	 * so if the bitwidth of the
+	 * chunk range we're using is greater than 16 we need
+	 * to figure out chunk shift and chunk_grp_size
+	 */
+
+	if (bits <= dev->tnode_width)
+		dev->chunk_grp_bits = 0;
+	else
+		dev->chunk_grp_bits = bits - dev->tnode_width;
+
+	dev->tnode_size = (dev->tnode_width * YAFFS_NTNODES_LEVEL0) / 8;
+	if (dev->tnode_size < sizeof(struct yaffs_tnode))
+		dev->tnode_size = sizeof(struct yaffs_tnode);
+
+	dev->chunk_grp_size = 1 << dev->chunk_grp_bits;
+
+	if (dev->param.chunks_per_block < dev->chunk_grp_size) {
+		/* We have a problem because the soft delete won't work if
+		 * the chunk group size > chunks per block.
+		 * This can be remedied by using larger "virtual blocks".
+		 */
+		yaffs_trace(YAFFS_TRACE_ALWAYS, "chunk group too large");
+
+		return YAFFS_FAIL;
+	}
+
+	/* Finished verifying the device, continue with initialisation */
+
+	/* More device initialisation */
+	dev->all_gcs = 0;
+	dev->passive_gc_count = 0;
+	dev->oldest_dirty_gc_count = 0;
+	dev->bg_gcs = 0;
+	dev->gc_block_finder = 0;
+	dev->buffered_block = -1;
+	dev->doing_buffered_block_rewrite = 0;
+	dev->n_deleted_files = 0;
+	dev->n_bg_deletions = 0;
+	dev->n_unlinked_files = 0;
+	dev->n_ecc_fixed = 0;
+	dev->n_ecc_unfixed = 0;
+	dev->n_tags_ecc_fixed = 0;
+	dev->n_tags_ecc_unfixed = 0;
+	dev->n_erase_failures = 0;
+	dev->n_erased_blocks = 0;
+	dev->gc_disable = 0;
+	dev->has_pending_prioritised_gc = 1; /* Assume the worst for now,
+					      * will get fixed on first GC */
+	INIT_LIST_HEAD(&dev->dirty_dirs);
+	dev->oldest_dirty_seq = 0;
+	dev->oldest_dirty_block = 0;
+
+	yaffs_endian_config(dev);
+
+	/* Initialise temporary buffers and caches. */
+	if (!yaffs_init_tmp_buffers(dev))
+		init_failed = 1;
+
+	dev->cache = NULL;
+	dev->gc_cleanup_list = NULL;
+
+	if (!init_failed && dev->param.n_caches > 0) {
+		u32 i;
+		void *buf;
+		u32 cache_bytes =
+		    dev->param.n_caches * sizeof(struct yaffs_cache);
+
+		if (dev->param.n_caches > YAFFS_MAX_SHORT_OP_CACHES)
+			dev->param.n_caches = YAFFS_MAX_SHORT_OP_CACHES;
+
+		dev->cache = kmalloc(cache_bytes, GFP_NOFS);
+
+		buf = (u8 *) dev->cache;
+
+		if (dev->cache)
+			memset(dev->cache, 0, cache_bytes);
+
+		for (i = 0; i < dev->param.n_caches && buf; i++) {
+			dev->cache[i].object = NULL;
+			dev->cache[i].last_use = 0;
+			dev->cache[i].dirty = 0;
+			dev->cache[i].data = buf =
+			    kmalloc(dev->param.total_bytes_per_chunk, GFP_NOFS);
+		}
+		if (!buf)
+			init_failed = 1;
+
+		dev->cache_last_use = 0;
+	}
+
+	dev->cache_hits = 0;
+
+	if (!init_failed) {
+		dev->gc_cleanup_list =
+		    kmalloc(dev->param.chunks_per_block * sizeof(u32),
+					GFP_NOFS);
+		if (!dev->gc_cleanup_list)
+			init_failed = 1;
+	}
+
+	if (dev->param.is_yaffs2)
+		dev->param.use_header_file_size = 1;
+
+	if (!init_failed && !yaffs_init_blocks(dev))
+		init_failed = 1;
+
+	yaffs_init_tnodes_and_objs(dev);
+
+	if (!init_failed && !yaffs_create_initial_dir(dev))
+		init_failed = 1;
+
+	if (!init_failed && dev->param.is_yaffs2 &&
+		!dev->param.disable_summary &&
+		!yaffs_summary_init(dev))
+		init_failed = 1;
+
+	if (!init_failed) {
+		/* Now scan the flash. */
+		if (dev->param.is_yaffs2) {
+			if (yaffs2_checkpt_restore(dev)) {
+				yaffs_check_obj_details_loaded(dev->root_dir);
+				yaffs_trace(YAFFS_TRACE_CHECKPOINT |
+					YAFFS_TRACE_MOUNT,
+					"yaffs: restored from checkpoint"
+					);
+			} else {
+
+				/* Clean up the mess caused by an aborted
+				 * checkpoint load then scan backwards.
+				 */
+				yaffs_deinit_blocks(dev);
+
+				yaffs_deinit_tnodes_and_objs(dev);
+
+				dev->n_erased_blocks = 0;
+				dev->n_free_chunks = 0;
+				dev->alloc_block = -1;
+				dev->alloc_page = -1;
+				dev->n_deleted_files = 0;
+				dev->n_unlinked_files = 0;
+				dev->n_bg_deletions = 0;
+
+				if (!init_failed && !yaffs_init_blocks(dev))
+					init_failed = 1;
+
+				yaffs_init_tnodes_and_objs(dev);
+
+				if (!init_failed
+				    && !yaffs_create_initial_dir(dev))
+					init_failed = 1;
+
+				if (!init_failed && !yaffs2_scan_backwards(dev))
+					init_failed = 1;
+			}
+		} else if (!yaffs1_scan(dev)) {
+			init_failed = 1;
+		}
+
+		yaffs_strip_deleted_objs(dev);
+		yaffs_fix_hanging_objs(dev);
+		if (dev->param.empty_lost_n_found)
+			yaffs_empty_l_n_f(dev);
+	}
+
+	if (init_failed) {
+		/* Clean up the mess */
+		yaffs_trace(YAFFS_TRACE_TRACING,
+		  "yaffs: yaffs_guts_initialise() aborted.");
+
+		yaffs_deinitialise(dev);
+		return YAFFS_FAIL;
+	}
+
+	/* Zero out stats */
+	dev->n_page_reads = 0;
+	dev->n_page_writes = 0;
+	dev->n_erasures = 0;
+	dev->n_gc_copies = 0;
+	dev->n_retried_writes = 0;
+
+	dev->n_retired_blocks = 0;
+
+	yaffs_verify_free_chunks(dev);
+	yaffs_verify_blocks(dev);
+
+	/* Clean up any aborted checkpoint data */
+	if (!dev->is_checkpointed && dev->blocks_in_checkpt > 0)
+		yaffs2_checkpt_invalidate(dev);
+
+	yaffs_trace(YAFFS_TRACE_TRACING,
+	  "yaffs: yaffs_guts_initialise() done.");
+	return YAFFS_OK;
+}
+
+void yaffs_deinitialise(struct yaffs_dev *dev)
+{
+	if (dev->is_mounted) {
+		u32 i;
+
+		yaffs_deinit_blocks(dev);
+		yaffs_deinit_tnodes_and_objs(dev);
+		yaffs_summary_deinit(dev);
+
+		if (dev->param.n_caches > 0 && dev->cache) {
+
+			for (i = 0; i < dev->param.n_caches; i++) {
+				kfree(dev->cache[i].data);
+				dev->cache[i].data = NULL;
+			}
+
+			kfree(dev->cache);
+			dev->cache = NULL;
+		}
+
+		kfree(dev->gc_cleanup_list);
+
+		for (i = 0; i < YAFFS_N_TEMP_BUFFERS; i++) {
+			kfree(dev->temp_buffer[i].buffer);
+			dev->temp_buffer[i].buffer = NULL;
+		}
+
+		kfree(dev->checkpt_buffer);
+		dev->checkpt_buffer = NULL;
+		kfree(dev->checkpt_block_list);
+		dev->checkpt_block_list = NULL;
+
+		dev->is_mounted = 0;
+
+		yaffs_deinit_nand(dev);
+	}
+}
+
+int yaffs_count_free_chunks(struct yaffs_dev *dev)
+{
+	int n_free = 0;
+	u32 b;
+	struct yaffs_block_info *blk;
+
+	blk = dev->block_info;
+	for (b = dev->internal_start_block; b <= dev->internal_end_block; b++) {
+		switch (blk->block_state) {
+		case YAFFS_BLOCK_STATE_EMPTY:
+		case YAFFS_BLOCK_STATE_ALLOCATING:
+		case YAFFS_BLOCK_STATE_COLLECTING:
+		case YAFFS_BLOCK_STATE_FULL:
+			n_free +=
+			    (dev->param.chunks_per_block - blk->pages_in_use +
+			     blk->soft_del_pages);
+			break;
+		default:
+			break;
+		}
+		blk++;
+	}
+	return n_free;
+}
+
+int yaffs_get_n_free_chunks(struct yaffs_dev *dev)
+{
+	/* This is what we report to the outside world */
+	int n_free;
+	int n_dirty_caches;
+	int blocks_for_checkpt;
+	u32 i;
+
+	n_free = dev->n_free_chunks;
+	n_free += dev->n_deleted_files;
+
+	/* Now count and subtract the number of dirty chunks in the cache. */
+
+	for (n_dirty_caches = 0, i = 0; i < dev->param.n_caches; i++) {
+		if (dev->cache[i].dirty)
+			n_dirty_caches++;
+	}
+
+	n_free -= n_dirty_caches;
+
+	n_free -=
+	    ((dev->param.n_reserved_blocks + 1) * dev->param.chunks_per_block);
+
+	/* Now figure checkpoint space and report that... */
+	blocks_for_checkpt = yaffs_calc_checkpt_blocks_required(dev);
+
+	n_free -= (blocks_for_checkpt * dev->param.chunks_per_block);
+
+	if (n_free < 0)
+		n_free = 0;
+
+	return n_free;
+}
+
+
+/*
+ * Marshalling functions to get loff_t file sizes into and out of
+ * object headers.
+ */
+void yaffs_oh_size_load(struct yaffs_dev *dev,
+			struct yaffs_obj_hdr *oh,
+			loff_t fsize,
+			int do_endian)
+{
+	oh->file_size_low = FSIZE_LOW(fsize);
+
+	oh->file_size_high = FSIZE_HIGH(fsize);
+
+	if (do_endian) {
+		yaffs_do_endian_u32(dev, &oh->file_size_low);
+		yaffs_do_endian_u32(dev, &oh->file_size_high);
+	}
+}
+
+loff_t yaffs_oh_to_size(struct yaffs_dev *dev, struct yaffs_obj_hdr *oh,
+			int do_endian)
+{
+	loff_t retval;
+
+
+	if (sizeof(loff_t) >= 8 && ~(oh->file_size_high)) {
+		u32 low = oh->file_size_low;
+		u32 high = oh->file_size_high;
+
+		if (do_endian) {
+			yaffs_do_endian_u32 (dev, &low);
+			yaffs_do_endian_u32 (dev, &high);
+		}
+		retval = FSIZE_COMBINE(high, low);
+	} else {
+		u32 low = oh->file_size_low;
+
+		if (do_endian)
+			yaffs_do_endian_u32(dev, &low);
+		retval = (loff_t)low;
+	}
+
+	return retval;
+}
+
+
+void yaffs_count_blocks_by_state(struct yaffs_dev *dev, int bs[10])
+{
+	u32 i;
+	struct yaffs_block_info *bi;
+	int s;
+
+	for(i = 0; i < 10; i++)
+		bs[i] = 0;
+
+	for(i = dev->internal_start_block; i <= dev->internal_end_block; i++) {
+		bi = yaffs_get_block_info(dev, i);
+		s = bi->block_state;
+		if(s > YAFFS_BLOCK_STATE_DEAD || s < YAFFS_BLOCK_STATE_UNKNOWN)
+			bs[0]++;
+		else
+			bs[s]++;
+	}
+}
diff --git a/fs/yaffs2/yaffs_guts.h b/fs/yaffs2/yaffs_guts.h
new file mode 100644
index 0000000..974396f
--- /dev/null
+++ b/fs/yaffs2/yaffs_guts.h
@@ -0,0 +1,1070 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_GUTS_H__
+#define __YAFFS_GUTS_H__
+
+#include "yportenv.h"
+
+#define YAFFS_OK	1
+#define YAFFS_FAIL  0
+
+/* Give us a  Y=0x59,
+ * Give us an A=0x41,
+ * Give us an FF=0xff
+ * Give us an S=0x53
+ * And what have we got...
+ */
+#define YAFFS_MAGIC			0x5941ff53
+
+/*
+ * Tnodes form a tree with the tnodes in "levels"
+ * Levels greater than 0 hold 8 slots which point to other tnodes.
+ * Those at level 0 hold 16 slots which point to chunks in NAND.
+ *
+ * A maximum level of 8 thust supports files of size up to:
+ *
+ * 2^(3*MAX_LEVEL+4)
+ *
+ * Thus a max level of 8 supports files with up to 2^^28 chunks which gives
+ * a maximum file size of around 512Gbytees with 2k chunks.
+ */
+#define YAFFS_NTNODES_LEVEL0		16
+#define YAFFS_TNODES_LEVEL0_BITS	4
+#define YAFFS_TNODES_LEVEL0_MASK	0xf
+
+#define YAFFS_NTNODES_INTERNAL		(YAFFS_NTNODES_LEVEL0 / 2)
+#define YAFFS_TNODES_INTERNAL_BITS	(YAFFS_TNODES_LEVEL0_BITS - 1)
+#define YAFFS_TNODES_INTERNAL_MASK	0x7
+#define YAFFS_TNODES_MAX_LEVEL		8
+#define YAFFS_TNODES_MAX_BITS		(YAFFS_TNODES_LEVEL0_BITS + \
+					YAFFS_TNODES_INTERNAL_BITS * \
+					YAFFS_TNODES_MAX_LEVEL)
+#define YAFFS_MAX_CHUNK_ID		((1 << YAFFS_TNODES_MAX_BITS) - 1)
+
+#define YAFFS_MAX_FILE_SIZE_32		0x7fffffff
+
+/* Constants for YAFFS1 mode */
+#define YAFFS_BYTES_PER_SPARE		16
+#define YAFFS_BYTES_PER_CHUNK		512
+#define YAFFS_CHUNK_SIZE_SHIFT		9
+#define YAFFS_CHUNKS_PER_BLOCK		32
+#define YAFFS_BYTES_PER_BLOCK	(YAFFS_CHUNKS_PER_BLOCK*YAFFS_BYTES_PER_CHUNK)
+
+#define YAFFS_MIN_YAFFS2_CHUNK_SIZE	1024
+#define YAFFS_MIN_YAFFS2_SPARE_SIZE	32
+
+
+
+#define YAFFS_ALLOCATION_NOBJECTS	100
+#define YAFFS_ALLOCATION_NTNODES	100
+#define YAFFS_ALLOCATION_NLINKS		100
+
+#define YAFFS_NOBJECT_BUCKETS		256
+
+#define YAFFS_OBJECT_SPACE		0x40000
+#define YAFFS_MAX_OBJECT_ID		(YAFFS_OBJECT_SPACE - 1)
+
+/* Binary data version stamps */
+#define YAFFS_SUMMARY_VERSION		1
+
+#ifdef CONFIG_YAFFS_UNICODE
+#define YAFFS_MAX_NAME_LENGTH		127
+#define YAFFS_MAX_ALIAS_LENGTH		79
+#else
+#define YAFFS_MAX_NAME_LENGTH		255
+#define YAFFS_MAX_ALIAS_LENGTH		159
+#endif
+
+#define YAFFS_SHORT_NAME_LENGTH		15
+
+/* Some special object ids for pseudo objects */
+#define YAFFS_OBJECTID_ROOT		1
+#define YAFFS_OBJECTID_LOSTNFOUND	2
+#define YAFFS_OBJECTID_UNLINKED		3
+#define YAFFS_OBJECTID_DELETED		4
+
+/* Fake object Id for summary data */
+#define YAFFS_OBJECTID_SUMMARY		0x10
+
+/* Pseudo object ids for checkpointing */
+#define YAFFS_OBJECTID_CHECKPOINT_DATA	0x20
+#define YAFFS_SEQUENCE_CHECKPOINT_DATA	0x21
+
+#define YAFFS_MAX_SHORT_OP_CACHES	20
+
+#define YAFFS_N_TEMP_BUFFERS		6
+
+/* We limit the number attempts at sucessfully saving a chunk of data.
+ * Small-page devices have 32 pages per block; large-page devices have 64.
+ * Default to something in the order of 5 to 10 blocks worth of chunks.
+ */
+#define YAFFS_WR_ATTEMPTS		(5*64)
+
+/* Sequence numbers are used in YAFFS2 to determine block allocation order.
+ * The range is limited slightly to help distinguish bad numbers from good.
+ * This also allows us to perhaps in the future use special numbers for
+ * special purposes.
+ * EFFFFF00 allows the allocation of 8 blocks/second (~1Mbytes) for 15 years,
+ * and is a larger number than the lifetime of a 2GB device.
+ */
+#define YAFFS_LOWEST_SEQUENCE_NUMBER	0x00001000
+#define YAFFS_HIGHEST_SEQUENCE_NUMBER	0xefffff00
+
+/* Special sequence number for bad block that failed to be marked bad */
+#define YAFFS_SEQUENCE_BAD_BLOCK	0xffff0000
+
+/* ChunkCache is used for short read/write operations.*/
+struct yaffs_cache {
+	struct yaffs_obj *object;
+	int chunk_id;
+	int last_use;
+	int dirty;
+	int n_bytes;		/* Only valid if the cache is dirty */
+	int locked;		/* Can't push out or flush while locked. */
+	u8 *data;
+};
+
+/* yaffs1 tags structures in RAM
+ * NB This uses bitfield. Bitfields should not straddle a u32 boundary
+ * otherwise the structure size will get blown out.
+ */
+
+struct yaffs_tags {
+	u32 chunk_id:20;
+	u32 serial_number:2;
+	u32 n_bytes_lsb:10;
+	u32 obj_id:18;
+	u32 ecc:12;
+	u32 n_bytes_msb:2;
+};
+
+union yaffs_tags_union {
+	struct yaffs_tags as_tags;
+	u8  as_bytes[8];
+	u32 as_u32[2];
+};
+
+
+/* Stuff used for extended tags in YAFFS2 */
+
+enum yaffs_ecc_result {
+	YAFFS_ECC_RESULT_UNKNOWN,
+	YAFFS_ECC_RESULT_NO_ERROR,
+	YAFFS_ECC_RESULT_FIXED,
+	YAFFS_ECC_RESULT_UNFIXED
+};
+
+/*
+ * Object type enum:
+ * When this is stored in flash we store it as a u32 instead
+ * to prevent any alignment change issues as compiler variants change.
+ */
+
+enum yaffs_obj_type {
+	YAFFS_OBJECT_TYPE_UNKNOWN,
+	YAFFS_OBJECT_TYPE_FILE,
+	YAFFS_OBJECT_TYPE_SYMLINK,
+	YAFFS_OBJECT_TYPE_DIRECTORY,
+	YAFFS_OBJECT_TYPE_HARDLINK,
+	YAFFS_OBJECT_TYPE_SPECIAL
+};
+
+#define YAFFS_OBJECT_TYPE_MAX YAFFS_OBJECT_TYPE_SPECIAL
+
+struct yaffs_ext_tags {
+	unsigned chunk_used;	/*  Status of the chunk: used or unused */
+	unsigned obj_id;	/* If 0 this is not used */
+	unsigned chunk_id;	/* If 0 this is a header, else a data chunk */
+	unsigned n_bytes;	/* Only valid for data chunks */
+
+	/* The following stuff only has meaning when we read */
+	enum yaffs_ecc_result ecc_result;
+	unsigned block_bad;
+
+	/* YAFFS 1 stuff */
+	unsigned is_deleted;	/* The chunk is marked deleted */
+	unsigned serial_number;	/* Yaffs1 2-bit serial number */
+
+	/* YAFFS2 stuff */
+	unsigned seq_number;	/* The sequence number of this block */
+
+	/* Extra info if this is an object header (YAFFS2 only) */
+
+	unsigned extra_available;	/* Extra info available if not zero */
+	unsigned extra_parent_id;	/* The parent object */
+	unsigned extra_is_shrink;	/* Is it a shrink header? */
+	unsigned extra_shadows;	/* Does this shadow another object? */
+
+	enum yaffs_obj_type extra_obj_type;	/* What object type? */
+
+	loff_t extra_file_size;		/* Length if it is a file */
+	unsigned extra_equiv_id;	/* Equivalent object for a hard link */
+};
+
+/* Spare structure for YAFFS1 */
+struct yaffs_spare {
+	u8 tb0;
+	u8 tb1;
+	u8 tb2;
+	u8 tb3;
+	u8 page_status;		/* set to 0 to delete the chunk */
+	u8 block_status;
+	u8 tb4;
+	u8 tb5;
+	u8 ecc1[3];
+	u8 tb6;
+	u8 tb7;
+	u8 ecc2[3];
+};
+
+/*Special structure for passing through to mtd */
+struct yaffs_nand_spare {
+	struct yaffs_spare spare;
+	int eccres1;
+	int eccres2;
+};
+
+/* Block data in RAM */
+
+enum yaffs_block_state {
+	YAFFS_BLOCK_STATE_UNKNOWN = 0,
+
+	YAFFS_BLOCK_STATE_SCANNING,
+	/* Being scanned */
+
+	YAFFS_BLOCK_STATE_NEEDS_SCAN,
+	/* The block might have something on it (ie it is allocating or full,
+	 * perhaps empty) but it needs to be scanned to determine its true
+	 * state.
+	 * This state is only valid during scanning.
+	 * NB We tolerate empty because the pre-scanner might be incapable of
+	 * deciding
+	 * However, if this state is returned on a YAFFS2 device,
+	 * then we expect a sequence number
+	 */
+
+	YAFFS_BLOCK_STATE_EMPTY,
+	/* This block is empty */
+
+	YAFFS_BLOCK_STATE_ALLOCATING,
+	/* This block is partially allocated.
+	 * At least one page holds valid data.
+	 * This is the one currently being used for page
+	 * allocation. Should never be more than one of these.
+	 * If a block is only partially allocated at mount it is treated as
+	 * full.
+	 */
+
+	YAFFS_BLOCK_STATE_FULL,
+	/* All the pages in this block have been allocated.
+	 * If a block was only partially allocated when mounted we treat
+	 * it as fully allocated.
+	 */
+
+	YAFFS_BLOCK_STATE_DIRTY,
+	/* The block was full and now all chunks have been deleted.
+	 * Erase me, reuse me.
+	 */
+
+	YAFFS_BLOCK_STATE_CHECKPOINT,
+	/* This block is assigned to holding checkpoint data. */
+
+	YAFFS_BLOCK_STATE_COLLECTING,
+	/* This block is being garbage collected */
+
+	YAFFS_BLOCK_STATE_DEAD
+	    /* This block has failed and is not in use */
+};
+
+#define	YAFFS_NUMBER_OF_BLOCK_STATES (YAFFS_BLOCK_STATE_DEAD + 1)
+
+struct yaffs_block_info {
+
+	s32 soft_del_pages:10;	/* number of soft deleted pages */
+	s32 pages_in_use:10;	/* number of pages in use */
+	u32 block_state:4;	/* One of the above block states. */
+				/* NB use unsigned because enum is sometimes
+				 * an int */
+	u32 needs_retiring:1;	/* Data has failed on this block, */
+				/*need to get valid data off and retire*/
+	u32 skip_erased_check:1;/* Skip the erased check on this block */
+	u32 gc_prioritise:1;	/* An ECC check or blank check has failed.
+				   Block should be prioritised for GC */
+	u32 chunk_error_strikes:3;	/* How many times we've had ecc etc
+				failures on this block and tried to reuse it */
+	u32 has_summary:1;	/* The block has a summary */
+
+	u32 has_shrink_hdr:1;	/* This block has at least one shrink header */
+	u32 seq_number;		/* block sequence number for yaffs2 */
+
+};
+
+union yaffs_block_info_union {
+	struct yaffs_block_info bi;
+	u32	as_u32[2];
+};
+
+/* -------------------------- Object structure -------------------------------*/
+/* This is the object structure as stored on NAND */
+
+struct yaffs_obj_hdr {
+	u32 type;  /* enum yaffs_obj_type  */
+
+	/* Apply to everything  */
+	u32 parent_obj_id;
+	u16 sum_no_longer_used;	/* checksum of name. No longer used */
+	YCHAR name[YAFFS_MAX_NAME_LENGTH + 1];
+
+	/* The following apply to all object types except for hard links */
+	u32 yst_mode;		/* protection */
+
+	u32 yst_uid;
+	u32 yst_gid;
+	u32 yst_atime;
+	u32 yst_mtime;
+	u32 yst_ctime;
+
+	/* File size  applies to files only */
+	u32 file_size_low;
+
+	/* Equivalent object id applies to hard links only. */
+	int equiv_id;
+
+	/* Alias is for symlinks only. */
+	YCHAR alias[YAFFS_MAX_ALIAS_LENGTH + 1];
+
+	u32 yst_rdev;	/* stuff for block and char devices (major/min) */
+
+	u32 win_ctime[2];
+	u32 win_atime[2];
+	u32 win_mtime[2];
+
+	u32 inband_shadowed_obj_id;
+	u32 inband_is_shrink;
+
+	u32 file_size_high;
+	u32 reserved[1];
+	int shadows_obj;	/* This object header shadows the
+				specified object if > 0 */
+
+	/* is_shrink applies to object headers written when wemake a hole. */
+	u32 is_shrink;
+
+};
+
+/*--------------------------- Tnode -------------------------- */
+
+struct yaffs_tnode {
+	struct yaffs_tnode *internal[YAFFS_NTNODES_INTERNAL];
+};
+
+/*------------------------  Object -----------------------------*/
+/* An object can be one of:
+ * - a directory (no data, has children links
+ * - a regular file (data.... not prunes :->).
+ * - a symlink [symbolic link] (the alias).
+ * - a hard link
+ */
+
+/* The file variant has three file sizes:
+ *  - file_size : size of file as written into Yaffs - including data in cache.
+ *  - stored_size - size of file as stored on media.
+ *  - shrink_size - size of file that has been shrunk back to.
+ *
+ * The stored_size and file_size might be different because the data written
+ * into the cache will increase the file_size but the stored_size will only
+ * change when the data is actually stored.
+ *
+ */
+struct yaffs_file_var {
+	loff_t file_size;
+	loff_t stored_size;
+	loff_t shrink_size;
+	int top_level;
+	struct yaffs_tnode *top;
+};
+
+struct yaffs_dir_var {
+	struct list_head children;	/* list of child links */
+	struct list_head dirty;	/* Entry for list of dirty directories */
+};
+
+struct yaffs_symlink_var {
+	YCHAR *alias;
+};
+
+struct yaffs_hardlink_var {
+	struct yaffs_obj *equiv_obj;
+	u32 equiv_id;
+};
+
+union yaffs_obj_var {
+	struct yaffs_file_var file_variant;
+	struct yaffs_dir_var dir_variant;
+	struct yaffs_symlink_var symlink_variant;
+	struct yaffs_hardlink_var hardlink_variant;
+};
+
+struct yaffs_obj {
+	u8 deleted:1;		/* This should only apply to unlinked files. */
+	u8 soft_del:1;		/* it has also been soft deleted */
+	u8 unlinked:1;		/* An unlinked file.*/
+	u8 fake:1;		/* A fake object has no presence on NAND. */
+	u8 rename_allowed:1;	/* Some objects cannot be renamed. */
+	u8 unlink_allowed:1;
+	u8 dirty:1;		/* the object needs to be written to flash */
+	u8 valid:1;		/* When the file system is being loaded up, this
+				 * object might be created before the data
+				 * is available
+				 * ie. file data chunks encountered before
+				* the header.
+				 */
+	u8 lazy_loaded:1;	/* This object has been lazy loaded and
+				 * is missing some detail */
+
+	u8 defered_free:1;	/* Object is removed from NAND, but is
+				 * still in the inode cache.
+				 * Free of object is defered.
+				 * until the inode is released.
+				 */
+	u8 being_created:1;	/* This object is still being created
+				 * so skip some verification checks. */
+	u8 is_shadowed:1;	/* This object is shadowed on the way
+				 * to being renamed. */
+
+	u8 xattr_known:1;	/* We know if this has object has xattribs
+				 * or not. */
+	u8 has_xattr:1;		/* This object has xattribs.
+				 * Only valid if xattr_known. */
+
+	u8 serial;		/* serial number of chunk in NAND.*/
+	u16 sum;		/* sum of the name to speed searching */
+
+	struct yaffs_dev *my_dev;	/* The device I'm on */
+
+	struct list_head hash_link;	/* list of objects in hash bucket */
+
+	struct list_head hard_links;	/* hard linked object chain*/
+
+	/* directory structure stuff */
+	/* also used for linking up the free list */
+	struct yaffs_obj *parent;
+	struct list_head siblings;
+
+	/* Where's my object header in NAND? */
+	int hdr_chunk;
+
+	int n_data_chunks;	/* Number of data chunks for this file. */
+
+	u32 obj_id;		/* the object id value */
+
+	u32 yst_mode;
+
+	YCHAR short_name[YAFFS_SHORT_NAME_LENGTH + 1];
+
+#ifdef CONFIG_YAFFS_WINCE
+	u32 win_ctime[2];
+	u32 win_mtime[2];
+	u32 win_atime[2];
+#else
+	u32 yst_uid;
+	u32 yst_gid;
+	u32 yst_atime;
+	u32 yst_mtime;
+	u32 yst_ctime;
+#endif
+
+	u32 yst_rdev;
+
+	void *my_inode;
+
+	u32 variant_type; /* enum yaffs_object_type */
+
+	union yaffs_obj_var variant;
+
+};
+
+struct yaffs_obj_bucket {
+	struct list_head list;
+	int count;
+};
+
+
+/*--------------------- Temporary buffers ----------------
+ *
+ * These are chunk-sized working buffers. Each device has a few.
+ */
+
+struct yaffs_buffer {
+	u8 *buffer;
+	int in_use;
+};
+
+/*----------------- Device ---------------------------------*/
+
+struct yaffs_param {
+	const YCHAR *name;
+
+	/*
+	 * Entry parameters set up way early. Yaffs sets up the rest.
+	 * The structure should be zeroed out before use so that unused
+	 * and default values are zero.
+	 */
+
+	int inband_tags;	/* Use unband tags */
+	u32 total_bytes_per_chunk;	/* Should be >= 512, does not need to
+					 be a power of 2 */
+	u32 chunks_per_block;	/* does not need to be a power of 2 */
+	u32 spare_bytes_per_chunk;	/* spare area size */
+	u32 start_block;	/* Start block we're allowed to use */
+	u32 end_block;		/* End block we're allowed to use */
+	u32 n_reserved_blocks;	/* Tuneable so that we can reduce
+				 * reserved blocks on NOR and RAM. */
+
+	u32 n_caches;		/* If == 0, then short op caching is disabled,
+				 * else the number of short op caches.
+				 */
+	int cache_bypass_aligned; /* If non-zero then bypass the cache for
+				   * aligned writes.
+				   */
+
+	int use_nand_ecc;	/* Flag to decide whether or not to use
+				 * NAND driver ECC on data (yaffs1) */
+	int tags_9bytes;	/* Use 9 byte tags */
+	int no_tags_ecc;	/* Flag to decide whether or not to do ECC
+				 * on packed tags (yaffs2) */
+
+	int is_yaffs2;		/* Use yaffs2 mode on this device */
+
+	int empty_lost_n_found;	/* Auto-empty lost+found directory on mount */
+
+	int refresh_period;	/* How often to check for a block refresh */
+
+	/* Checkpoint control. Can be set before or after initialisation */
+	u8 skip_checkpt_rd;
+	u8 skip_checkpt_wr;
+
+	int enable_xattr;	/* Enable xattribs */
+
+	int max_objects;	/*
+				 * Set to limit the number of objects created.
+				 * 0 = no limit.
+				*/
+
+	int hide_lost_n_found;  /* Set non-zero to hide the lost-n-found dir. */
+
+	int stored_endian; /* 0=cpu endian, 1=little endian, 2=big endian */
+
+	/* The remove_obj_fn function must be supplied by OS flavours that
+	 * need it.
+	 * yaffs direct uses it to implement the faster readdir.
+	 * Linux uses it to protect the directory during unlocking.
+	 */
+	void (*remove_obj_fn) (struct yaffs_obj *obj);
+
+	/* Callback to mark the superblock dirty */
+	void (*sb_dirty_fn) (struct yaffs_dev *dev);
+
+	/*  Callback to control garbage collection. */
+	unsigned (*gc_control_fn) (struct yaffs_dev *dev);
+
+	/* Debug control flags. Don't use unless you know what you're doing */
+	int use_header_file_size;	/* Flag to determine if we should use
+					 * file sizes from the header */
+	int disable_lazy_load;	/* Disable lazy loading on this device */
+	int wide_tnodes_disabled;	/* Set to disable wide tnodes */
+	int disable_soft_del;	/* yaffs 1 only: Set to disable the use of
+				 * softdeletion. */
+
+	int defered_dir_update;	/* Set to defer directory updates */
+
+#ifdef CONFIG_YAFFS_AUTO_UNICODE
+	int auto_unicode;
+#endif
+	int always_check_erased;	/* Force chunk erased check always on */
+
+	int disable_summary;
+	int disable_bad_block_marking;
+
+};
+
+struct yaffs_driver {
+	int (*drv_write_chunk_fn) (struct yaffs_dev *dev, int nand_chunk,
+				   const u8 *data, int data_len,
+				   const u8 *oob, int oob_len);
+	int (*drv_read_chunk_fn) (struct yaffs_dev *dev, int nand_chunk,
+				   u8 *data, int data_len,
+				   u8 *oob, int oob_len,
+				   enum yaffs_ecc_result *ecc_result);
+	int (*drv_erase_fn) (struct yaffs_dev *dev, int block_no);
+	int (*drv_mark_bad_fn) (struct yaffs_dev *dev, int block_no);
+	int (*drv_check_bad_fn) (struct yaffs_dev *dev, int block_no);
+	int (*drv_initialise_fn) (struct yaffs_dev *dev);
+	int (*drv_deinitialise_fn) (struct yaffs_dev *dev);
+};
+
+struct yaffs_tags_handler {
+	int (*write_chunk_tags_fn) (struct yaffs_dev *dev,
+				    int nand_chunk, const u8 *data,
+				    const struct yaffs_ext_tags *tags);
+	int (*read_chunk_tags_fn) (struct yaffs_dev *dev,
+				   int nand_chunk, u8 *data,
+				   struct yaffs_ext_tags *tags);
+
+	int (*query_block_fn) (struct yaffs_dev *dev, int block_no,
+			       enum yaffs_block_state *state,
+			       u32 *seq_number);
+	int (*mark_bad_fn) (struct yaffs_dev *dev, int block_no);
+};
+
+struct yaffs_dev {
+	struct yaffs_param param;
+	struct yaffs_driver drv;
+	struct yaffs_tags_handler tagger;
+
+	/* Context storage. Holds extra OS specific data for this device */
+
+	void *os_context;
+	void *driver_context;
+
+	struct list_head dev_list;
+
+	int ll_init;
+	/* Runtime parameters. Set up by YAFFS. */
+	u32 data_bytes_per_chunk;
+
+	/* Non-wide tnode stuff */
+	u16 chunk_grp_bits;	/* Number of bits that need to be resolved if
+				 * the tnodes are not wide enough.
+				 */
+	u16 chunk_grp_size;	/* == 2^^chunk_grp_bits */
+
+	struct yaffs_tnode *tn_swap_buffer;
+
+	/* Stuff to support wide tnodes */
+	u32 tnode_width;
+	u32 tnode_mask;
+	u32 tnode_size;
+
+	/* Stuff for figuring out file offset to chunk conversions */
+	u32 chunk_shift;	/* Shift value */
+	u32 chunk_div;		/* Divisor after shifting: 1 for 2^n sizes */
+	u32 chunk_mask;		/* Mask to use for power-of-2 case */
+
+	int is_mounted;
+	int read_only;
+	int is_checkpointed;
+	int swap_endian;	/* Stored endian needs endian swap. */
+
+	/* Stuff to support block offsetting to support start block zero */
+	u32 internal_start_block;
+	u32 internal_end_block;
+	int block_offset;
+	int chunk_offset;
+
+	/* Runtime checkpointing stuff */
+	int checkpt_page_seq;	/* running sequence number of checkpt pages */
+	int checkpt_byte_count;
+	int checkpt_byte_offs;
+	u8 *checkpt_buffer;
+	int checkpt_open_write;
+	u32 blocks_in_checkpt;
+	int checkpt_cur_chunk;
+	int checkpt_cur_block;
+	int checkpt_next_block;
+	int *checkpt_block_list;
+	u32 checkpt_max_blocks;
+	u32 checkpt_sum;
+	u32 checkpt_xor;
+
+	int checkpoint_blocks_required;	/* Number of blocks needed to store
+					 * current checkpoint set */
+
+	/* Block Info */
+	struct yaffs_block_info *block_info;
+	u8 *chunk_bits;		/* bitmap of chunks in use */
+	u8 block_info_alt:1;	/* allocated using alternative alloc */
+	u8 chunk_bits_alt:1;	/* allocated using alternative alloc */
+	int chunk_bit_stride;	/* Number of bytes of chunk_bits per block.
+				 * Must be consistent with chunks_per_block.
+				 */
+
+	int n_erased_blocks;
+	int alloc_block;	/* Current block being allocated off */
+	u32 alloc_page;
+	int alloc_block_finder;	/* Used to search for next allocation block */
+
+	/* Object and Tnode memory management */
+	void *allocator;
+	int n_obj;
+	int n_tnodes;
+
+	int n_hardlinks;
+
+	struct yaffs_obj_bucket obj_bucket[YAFFS_NOBJECT_BUCKETS];
+	u32 bucket_finder;
+
+	int n_free_chunks;
+
+	/* Garbage collection control */
+	u32 *gc_cleanup_list;	/* objects to delete at the end of a GC. */
+	u32 n_clean_ups;
+
+	unsigned has_pending_prioritised_gc;	/* We think this device might
+						have pending prioritised gcs */
+	unsigned gc_disable;
+	unsigned gc_block_finder;
+	unsigned gc_dirtiest;
+	unsigned gc_pages_in_use;
+	unsigned gc_not_done;
+	unsigned gc_block;
+	unsigned gc_chunk;
+	unsigned gc_skip;
+	struct yaffs_summary_tags *gc_sum_tags;
+
+	/* Special directories */
+	struct yaffs_obj *root_dir;
+	struct yaffs_obj *lost_n_found;
+
+	int buffered_block;	/* Which block is buffered here? */
+	int doing_buffered_block_rewrite;
+
+	struct yaffs_cache *cache;
+	int cache_last_use;
+
+	/* Stuff for background deletion and unlinked files. */
+	struct yaffs_obj *unlinked_dir;	/* Directory where unlinked and deleted
+					 files live. */
+	struct yaffs_obj *del_dir;	/* Directory where deleted objects are
+					sent to disappear. */
+	struct yaffs_obj *unlinked_deletion;	/* Current file being
+							background deleted. */
+	int n_deleted_files;	/* Count of files awaiting deletion; */
+	int n_unlinked_files;	/* Count of unlinked files. */
+	int n_bg_deletions;	/* Count of background deletions. */
+
+	/* Temporary buffer management */
+	struct yaffs_buffer temp_buffer[YAFFS_N_TEMP_BUFFERS];
+	int max_temp;
+	int temp_in_use;
+	int unmanaged_buffer_allocs;
+	int unmanaged_buffer_deallocs;
+
+	/* yaffs2 runtime stuff */
+	unsigned seq_number;	/* Sequence number of currently
+					allocating block */
+	unsigned oldest_dirty_seq;
+	unsigned oldest_dirty_block;
+
+	/* Block refreshing */
+	int refresh_skip;	/* A skip down counter.
+				 * Refresh happens when this gets to zero. */
+
+	/* Dirty directory handling */
+	struct list_head dirty_dirs;	/* List of dirty directories */
+
+	/* Summary */
+	int chunks_per_summary;
+	struct yaffs_summary_tags *sum_tags;
+
+	/* Statistics */
+	u32 n_page_writes;
+	u32 n_page_reads;
+	u32 n_erasures;
+	u32 n_bad_queries;
+	u32 n_bad_markings;
+	u32 n_erase_failures;
+	u32 n_gc_copies;
+	u32 all_gcs;
+	u32 passive_gc_count;
+	u32 oldest_dirty_gc_count;
+	u32 n_gc_blocks;
+	u32 bg_gcs;
+	u32 n_retried_writes;
+	u32 n_retired_blocks;
+	u32 n_ecc_fixed;
+	u32 n_ecc_unfixed;
+	u32 n_tags_ecc_fixed;
+	u32 n_tags_ecc_unfixed;
+	u32 n_deletions;
+	u32 n_unmarked_deletions;
+	u32 refresh_count;
+	u32 cache_hits;
+	u32 tags_used;
+	u32 summary_used;
+
+};
+
+/*
+ * Checkpointing definitions.
+ */
+
+#define YAFFS_CHECKPOINT_VERSION	8
+
+/* yaffs_checkpt_obj holds the definition of an object as dumped
+ * by checkpointing.
+ */
+
+
+/*  Checkpint object bits in bitfield: offset, length */
+#define CHECKPOINT_VARIANT_BITS		0, 3
+#define CHECKPOINT_DELETED_BITS		3, 1
+#define CHECKPOINT_SOFT_DEL_BITS	4, 1
+#define CHECKPOINT_UNLINKED_BITS	5, 1
+#define CHECKPOINT_FAKE_BITS		6, 1
+#define CHECKPOINT_RENAME_ALLOWED_BITS	7, 1
+#define CHECKPOINT_UNLINK_ALLOWED_BITS	8, 1
+#define CHECKPOINT_SERIAL_BITS		9, 8
+
+struct yaffs_checkpt_obj {
+	int struct_type;
+	u32 obj_id;
+	u32 parent_id;
+	int hdr_chunk;
+	u32 bit_field;
+	int n_data_chunks;
+	loff_t size_or_equiv_obj;
+};
+
+/* The CheckpointDevice structure holds the device information that changes
+ *at runtime and must be preserved over unmount/mount cycles.
+ */
+struct yaffs_checkpt_dev {
+	int struct_type;
+	int n_erased_blocks;
+	int alloc_block;	/* Current block being allocated off */
+	u32 alloc_page;
+	int n_free_chunks;
+
+	int n_deleted_files;	/* Count of files awaiting deletion; */
+	int n_unlinked_files;	/* Count of unlinked files. */
+	int n_bg_deletions;	/* Count of background deletions. */
+
+	/* yaffs2 runtime stuff */
+	unsigned seq_number;	/* Sequence number of currently
+				 * allocating block */
+
+};
+
+struct yaffs_checkpt_validity {
+	int struct_type;
+	u32 magic;
+	u32 version;
+	u32 head;
+};
+
+struct yaffs_shadow_fixer {
+	int obj_id;
+	int shadowed_id;
+	struct yaffs_shadow_fixer *next;
+};
+
+/* Structure for doing xattr modifications */
+struct yaffs_xattr_mod {
+	int set;		/* If 0 then this is a deletion */
+	const YCHAR *name;
+	const void *data;
+	int size;
+	int flags;
+	int result;
+};
+
+/*----------------------- YAFFS Functions -----------------------*/
+
+int yaffs_guts_initialise(struct yaffs_dev *dev);
+void yaffs_deinitialise(struct yaffs_dev *dev);
+
+int yaffs_get_n_free_chunks(struct yaffs_dev *dev);
+
+int yaffs_rename_obj(struct yaffs_obj *old_dir, const YCHAR * old_name,
+		     struct yaffs_obj *new_dir, const YCHAR * new_name);
+
+int yaffs_unlink_obj(struct yaffs_obj *obj);
+
+int yaffs_unlinker(struct yaffs_obj *dir, const YCHAR * name);
+int yaffs_del_obj(struct yaffs_obj *obj);
+struct yaffs_obj *yaffs_retype_obj(struct yaffs_obj *obj,
+				   enum yaffs_obj_type type);
+
+
+int yaffs_get_obj_name(struct yaffs_obj *obj, YCHAR * name, int buffer_size);
+loff_t yaffs_get_obj_length(struct yaffs_obj *obj);
+int yaffs_get_obj_inode(struct yaffs_obj *obj);
+unsigned yaffs_get_obj_type(struct yaffs_obj *obj);
+int yaffs_get_obj_link_count(struct yaffs_obj *obj);
+
+/* File operations */
+int yaffs_file_rd(struct yaffs_obj *obj, u8 * buffer, loff_t offset,
+		  int n_bytes);
+int yaffs_wr_file(struct yaffs_obj *obj, const u8 * buffer, loff_t offset,
+		  int n_bytes, int write_trhrough);
+int yaffs_resize_file(struct yaffs_obj *obj, loff_t new_size);
+
+struct yaffs_obj *yaffs_create_file(struct yaffs_obj *parent,
+				    const YCHAR *name, u32 mode, u32 uid,
+				    u32 gid);
+
+int yaffs_flush_file(struct yaffs_obj *in,
+		     int update_time,
+		     int data_sync,
+		     int discard_cache);
+
+/* Flushing and checkpointing */
+void yaffs_flush_whole_cache(struct yaffs_dev *dev, int discard);
+
+int yaffs_checkpoint_save(struct yaffs_dev *dev);
+int yaffs_checkpoint_restore(struct yaffs_dev *dev);
+
+/* Directory operations */
+struct yaffs_obj *yaffs_create_dir(struct yaffs_obj *parent, const YCHAR *name,
+				   u32 mode, u32 uid, u32 gid);
+struct yaffs_obj *yaffs_find_by_name(struct yaffs_obj *the_dir,
+				     const YCHAR *name);
+struct yaffs_obj *yaffs_find_by_number(struct yaffs_dev *dev, u32 number);
+
+/* Link operations */
+struct yaffs_obj *yaffs_link_obj(struct yaffs_obj *parent, const YCHAR *name,
+				 struct yaffs_obj *equiv_obj);
+
+struct yaffs_obj *yaffs_get_equivalent_obj(struct yaffs_obj *obj);
+
+/* Symlink operations */
+struct yaffs_obj *yaffs_create_symlink(struct yaffs_obj *parent,
+				       const YCHAR *name, u32 mode, u32 uid,
+				       u32 gid, const YCHAR *alias);
+YCHAR *yaffs_get_symlink_alias(struct yaffs_obj *obj);
+
+/* Special inodes (fifos, sockets and devices) */
+struct yaffs_obj *yaffs_create_special(struct yaffs_obj *parent,
+				       const YCHAR *name, u32 mode, u32 uid,
+				       u32 gid, u32 rdev);
+
+int yaffs_set_xattrib(struct yaffs_obj *obj, const YCHAR *name,
+		      const void *value, int size, int flags);
+int yaffs_get_xattrib(struct yaffs_obj *obj, const YCHAR *name, void *value,
+		      int size);
+int yaffs_list_xattrib(struct yaffs_obj *obj, char *buffer, int size);
+int yaffs_remove_xattrib(struct yaffs_obj *obj, const YCHAR *name);
+
+/* Special directories */
+struct yaffs_obj *yaffs_root(struct yaffs_dev *dev);
+struct yaffs_obj *yaffs_lost_n_found(struct yaffs_dev *dev);
+
+void yaffs_handle_defered_free(struct yaffs_obj *obj);
+
+void yaffs_update_dirty_dirs(struct yaffs_dev *dev);
+
+int yaffs_bg_gc(struct yaffs_dev *dev, unsigned urgency);
+
+/* Debug dump  */
+int yaffs_dump_obj(struct yaffs_obj *obj);
+
+void yaffs_guts_test(struct yaffs_dev *dev);
+int yaffs_guts_ll_init(struct yaffs_dev *dev);
+
+
+/* A few useful functions to be used within the core files*/
+void yaffs_chunk_del(struct yaffs_dev *dev, int chunk_id, int mark_flash,
+		     int lyn);
+int yaffs_check_ff(u8 *buffer, int n_bytes);
+void yaffs_handle_chunk_error(struct yaffs_dev *dev,
+			      struct yaffs_block_info *bi);
+
+u8 *yaffs_get_temp_buffer(struct yaffs_dev *dev);
+void yaffs_release_temp_buffer(struct yaffs_dev *dev, u8 *buffer);
+
+struct yaffs_obj *yaffs_find_or_create_by_number(struct yaffs_dev *dev,
+						 int number,
+						 enum yaffs_obj_type type);
+int yaffs_put_chunk_in_file(struct yaffs_obj *in, int inode_chunk,
+			    int nand_chunk, int in_scan);
+void yaffs_set_obj_name(struct yaffs_obj *obj, const YCHAR *name);
+void yaffs_set_obj_name_from_oh(struct yaffs_obj *obj,
+				const struct yaffs_obj_hdr *oh);
+void yaffs_add_obj_to_dir(struct yaffs_obj *directory, struct yaffs_obj *obj);
+YCHAR *yaffs_clone_str(const YCHAR *str);
+void yaffs_link_fixup(struct yaffs_dev *dev, struct list_head *hard_list);
+void yaffs_block_became_dirty(struct yaffs_dev *dev, int block_no);
+int yaffs_update_oh(struct yaffs_obj *in, const YCHAR *name,
+		    int force, int is_shrink, int shadows,
+		    struct yaffs_xattr_mod *xop);
+void yaffs_handle_shadowed_obj(struct yaffs_dev *dev, int obj_id,
+			       int backward_scanning);
+int yaffs_check_alloc_available(struct yaffs_dev *dev, int n_chunks);
+struct yaffs_tnode *yaffs_get_tnode(struct yaffs_dev *dev);
+struct yaffs_tnode *yaffs_add_find_tnode_0(struct yaffs_dev *dev,
+					   struct yaffs_file_var *file_struct,
+					   u32 chunk_id,
+					   struct yaffs_tnode *passed_tn);
+
+int yaffs_do_file_wr(struct yaffs_obj *in, const u8 *buffer, loff_t offset,
+		     int n_bytes, int write_trhrough);
+void yaffs_resize_file_down(struct yaffs_obj *obj, loff_t new_size);
+void yaffs_skip_rest_of_block(struct yaffs_dev *dev);
+
+int yaffs_count_free_chunks(struct yaffs_dev *dev);
+
+struct yaffs_tnode *yaffs_find_tnode_0(struct yaffs_dev *dev,
+				       struct yaffs_file_var *file_struct,
+				       u32 chunk_id);
+
+u32 yaffs_get_group_base(struct yaffs_dev *dev, struct yaffs_tnode *tn,
+			 unsigned pos);
+
+int yaffs_is_non_empty_dir(struct yaffs_obj *obj);
+
+int yaffs_guts_format_dev(struct yaffs_dev *dev);
+
+void yaffs_addr_to_chunk(struct yaffs_dev *dev, loff_t addr,
+				int *chunk_out, u32 *offset_out);
+/*
+ * Marshalling functions to get loff_t file sizes into and out of
+ * object headers.
+ */
+void yaffs_oh_size_load(struct yaffs_dev *dev, struct yaffs_obj_hdr *oh,
+			loff_t fsize, int do_endian);
+loff_t yaffs_oh_to_size(struct yaffs_dev *dev, struct yaffs_obj_hdr *oh,
+			int do_endian);
+loff_t yaffs_max_file_size(struct yaffs_dev *dev);
+
+/*
+ * Debug function to count number of blocks in each state
+ * NB Needs to be called with correct number of integers
+ */
+
+void yaffs_count_blocks_by_state(struct yaffs_dev *dev, int bs[10]);
+
+int yaffs_find_chunk_in_file(struct yaffs_obj *in, int inode_chunk,
+				    struct yaffs_ext_tags *tags);
+
+/*
+ * Define LOFF_T_32_BIT if a 32-bit LOFF_T is being used.
+ * Not serious if you get this wrong - you might just get some warnings.
+*/
+
+#ifdef  LOFF_T_32_BIT
+#define FSIZE_LOW(fsize) (fsize)
+#define FSIZE_HIGH(fsize) 0
+#define FSIZE_COMBINE(high, low) (low)
+#else
+#define FSIZE_LOW(fsize) ((fsize) & 0xffffffff)
+#define FSIZE_HIGH(fsize)(((fsize) >> 32) & 0xffffffff)
+#define FSIZE_COMBINE(high, low) ((((loff_t) (high)) << 32) | \
+					(((loff_t) (low)) & 0xFFFFFFFF))
+#endif
+
+
+#endif
diff --git a/fs/yaffs2/yaffs_linux.h b/fs/yaffs2/yaffs_linux.h
new file mode 100644
index 0000000..c20ab14
--- /dev/null
+++ b/fs/yaffs2/yaffs_linux.h
@@ -0,0 +1,48 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_LINUX_H__
+#define __YAFFS_LINUX_H__
+
+#include "yportenv.h"
+
+struct yaffs_linux_context {
+	struct list_head context_list;	/* List of these we have mounted */
+	struct yaffs_dev *dev;
+	struct super_block *super;
+	struct task_struct *bg_thread;	/* Background thread for this device */
+	int bg_running;
+	struct mutex gross_lock;	/* Gross locking mutex*/
+	u8 *spare_buffer;	/* For mtdif2 use. Don't know the buffer size
+				 * at compile time so we have to allocate it.
+				 */
+	struct list_head search_contexts;
+	struct task_struct *readdir_process;
+	unsigned mount_id;
+	int dirty;
+};
+
+#define yaffs_dev_to_lc(dev) ((struct yaffs_linux_context *)((dev)->os_context))
+#define yaffs_dev_to_mtd(dev) ((struct mtd_info *)((dev)->driver_context))
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 17))
+#define WRITE_SIZE_STR "writesize"
+#define WRITE_SIZE(mtd) ((mtd)->writesize)
+#else
+#define WRITE_SIZE_STR "oobblock"
+#define WRITE_SIZE(mtd) ((mtd)->oobblock)
+#endif
+
+#endif
diff --git a/fs/yaffs2/yaffs_mtdif.c b/fs/yaffs2/yaffs_mtdif.c
new file mode 100644
index 0000000..7c01461
--- /dev/null
+++ b/fs/yaffs2/yaffs_mtdif.c
@@ -0,0 +1,310 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include "yportenv.h"
+
+#include "yaffs_mtdif.h"
+
+#include "linux/mtd/mtd.h"
+#include "linux/types.h"
+#include "linux/time.h"
+#include "linux/mtd/nand.h"
+#include "linux/kernel.h"
+#include "linux/version.h"
+#include "linux/types.h"
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 14, 0))
+#include "uapi/linux/major.h"
+#endif
+
+#include "yaffs_trace.h"
+#include "yaffs_guts.h"
+#include "yaffs_linux.h"
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 2, 0))
+#define MTD_OPS_AUTO_OOB MTD_OOB_AUTO
+#endif
+
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 4, 0))
+#define mtd_erase(m, ei) (m)->erase(m, ei)
+#define mtd_write_oob(m, addr, pops) (m)->write_oob(m, addr, pops)
+#define mtd_read_oob(m, addr, pops) (m)->read_oob(m, addr, pops)
+#define mtd_block_isbad(m, offs) (m)->block_isbad(m, offs)
+#define mtd_block_markbad(m, offs) (m)->block_markbad(m, offs)
+#endif
+
+
+
+int nandmtd_erase_block(struct yaffs_dev *dev, int block_no)
+{
+	struct mtd_info *mtd = yaffs_dev_to_mtd(dev);
+	u32 addr =
+	    ((loff_t) block_no) * dev->param.total_bytes_per_chunk *
+	    dev->param.chunks_per_block;
+	struct erase_info ei;
+	int retval = 0;
+
+	ei.mtd = mtd;
+	ei.addr = addr;
+	ei.len = dev->param.total_bytes_per_chunk * dev->param.chunks_per_block;
+	ei.time = 1000;
+	ei.retries = 2;
+	ei.callback = NULL;
+	ei.priv = (u_long) dev;
+
+	retval = mtd_erase(mtd, &ei);
+
+	if (retval == 0)
+		return YAFFS_OK;
+
+	return YAFFS_FAIL;
+}
+
+
+static 	int yaffs_mtd_write(struct yaffs_dev *dev, int nand_chunk,
+				   const u8 *data, int data_len,
+				   const u8 *oob, int oob_len)
+{
+	struct mtd_info *mtd = yaffs_dev_to_mtd(dev);
+	loff_t addr;
+	struct mtd_oob_ops ops;
+	int retval;
+
+	yaffs_trace(YAFFS_TRACE_MTD,
+			"yaffs_mtd_write(%p, %d, %p, %d, %p, %d)\n",
+			dev, nand_chunk, data, data_len, oob, oob_len);
+
+	if (!data || !data_len) {
+		data = NULL;
+		data_len = 0;
+	}
+
+	if (!oob || !oob_len) {
+		oob = NULL;
+		oob_len = 0;
+	}
+
+	addr = ((loff_t) nand_chunk) * dev->param.total_bytes_per_chunk;
+	memset(&ops, 0, sizeof(ops));
+	ops.mode = MTD_OPS_AUTO_OOB;
+	ops.len = (data) ? data_len : 0;
+	ops.ooblen = oob_len;
+	ops.datbuf = (u8 *)data;
+	ops.oobbuf = (u8 *)oob;
+
+	retval = mtd_write_oob(mtd, addr, &ops);
+	if (retval) {
+		yaffs_trace(YAFFS_TRACE_MTD,
+			"write_oob failed, chunk %d, mtd error %d",
+			nand_chunk, retval);
+	}
+	return retval ? YAFFS_FAIL : YAFFS_OK;
+}
+
+static int yaffs_mtd_read(struct yaffs_dev *dev, int nand_chunk,
+				   u8 *data, int data_len,
+				   u8 *oob, int oob_len,
+				   enum yaffs_ecc_result *ecc_result)
+{
+	struct mtd_info *mtd = yaffs_dev_to_mtd(dev);
+	loff_t addr;
+	struct mtd_oob_ops ops;
+	int retval;
+
+	addr = ((loff_t) nand_chunk) * dev->param.total_bytes_per_chunk;
+	memset(&ops, 0, sizeof(ops));
+	ops.mode = MTD_OPS_AUTO_OOB;
+	ops.len = (data) ? data_len : 0;
+	ops.ooblen = oob_len;
+	ops.datbuf = data;
+	ops.oobbuf = oob;
+
+#if (MTD_VERSION_CODE < MTD_VERSION(2, 6, 20))
+	/* In MTD 2.6.18 to 2.6.19 nand_base.c:nand_do_read_oob() has a bug;
+	 * help it out with ops.len = ops.ooblen when ops.datbuf == NULL.
+	 */
+	ops.len = (ops.datbuf) ? ops.len : ops.ooblen;
+#endif
+	/* Read page and oob using MTD.
+	 * Check status and determine ECC result.
+	 */
+	retval = mtd_read_oob(mtd, addr, &ops);
+	if (retval)
+		yaffs_trace(YAFFS_TRACE_MTD,
+			"read_oob failed, chunk %d, mtd error %d",
+			nand_chunk, retval);
+
+	switch (retval) {
+	case 0:
+		/* no error */
+		if(ecc_result)
+			*ecc_result = YAFFS_ECC_RESULT_NO_ERROR;
+		break;
+
+	case -EUCLEAN:
+		/* MTD's ECC fixed the data */
+		if(ecc_result)
+			*ecc_result = YAFFS_ECC_RESULT_FIXED;
+		dev->n_ecc_fixed++;
+		break;
+
+	case -EBADMSG:
+	default:
+		/* MTD's ECC could not fix the data */
+		dev->n_ecc_unfixed++;
+		if(ecc_result)
+			*ecc_result = YAFFS_ECC_RESULT_UNFIXED;
+		return YAFFS_FAIL;
+	}
+
+	return YAFFS_OK;
+}
+
+static 	int yaffs_mtd_erase(struct yaffs_dev *dev, int block_no)
+{
+	struct mtd_info *mtd = yaffs_dev_to_mtd(dev);
+
+	loff_t addr;
+	struct erase_info ei;
+	int retval = 0;
+	u32 block_size;
+
+	block_size = dev->param.total_bytes_per_chunk *
+		     dev->param.chunks_per_block;
+	addr = ((loff_t) block_no) * block_size;
+
+	ei.mtd = mtd;
+	ei.addr = addr;
+	ei.len = block_size;
+	ei.time = 1000;
+	ei.retries = 2;
+	ei.callback = NULL;
+	ei.priv = (u_long) dev;
+
+	retval = mtd_erase(mtd, &ei);
+
+	if (retval == 0)
+		return YAFFS_OK;
+
+	return YAFFS_FAIL;
+}
+
+static int yaffs_mtd_mark_bad(struct yaffs_dev *dev, int block_no)
+{
+	struct mtd_info *mtd = yaffs_dev_to_mtd(dev);
+	int blocksize = dev->param.chunks_per_block * dev->param.total_bytes_per_chunk;
+	int retval;
+
+	yaffs_trace(YAFFS_TRACE_BAD_BLOCKS, "marking block %d bad", block_no);
+
+	retval = mtd_block_markbad(mtd, (loff_t) blocksize * block_no);
+	return (retval) ? YAFFS_FAIL : YAFFS_OK;
+}
+
+static int yaffs_mtd_check_bad(struct yaffs_dev *dev, int block_no)
+{
+	struct mtd_info *mtd = yaffs_dev_to_mtd(dev);
+	int blocksize = dev->param.chunks_per_block * dev->param.total_bytes_per_chunk;
+	int retval;
+
+	yaffs_trace(YAFFS_TRACE_MTD, "checking block %d bad", block_no);
+
+	retval = mtd_block_isbad(mtd, (loff_t) blocksize * block_no);
+	return (retval) ? YAFFS_FAIL : YAFFS_OK;
+}
+
+static int yaffs_mtd_initialise(struct yaffs_dev *dev)
+{
+	return YAFFS_OK;
+}
+
+static int yaffs_mtd_deinitialise(struct yaffs_dev *dev)
+{
+	return YAFFS_OK;
+}
+
+
+void yaffs_mtd_drv_install(struct yaffs_dev *dev)
+{
+	struct yaffs_driver *drv = &dev->drv;
+
+	drv->drv_write_chunk_fn = yaffs_mtd_write;
+	drv->drv_read_chunk_fn = yaffs_mtd_read;
+	drv->drv_erase_fn = yaffs_mtd_erase;
+	drv->drv_mark_bad_fn = yaffs_mtd_mark_bad;
+	drv->drv_check_bad_fn = yaffs_mtd_check_bad;
+	drv->drv_initialise_fn = yaffs_mtd_initialise;
+	drv->drv_deinitialise_fn = yaffs_mtd_deinitialise;
+}
+
+
+struct mtd_info * yaffs_get_mtd_device(dev_t sdev)
+{
+	struct mtd_info *mtd;
+
+	mtd = yaffs_get_mtd_device(sdev);
+
+	/* Check it's an mtd device..... */
+	if (MAJOR(sdev) != MTD_BLOCK_MAJOR)
+		return NULL;	/* This isn't an mtd device */
+
+	/* Check it's NAND */
+	if (mtd->type != MTD_NANDFLASH) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"yaffs: MTD device is not NAND it's type %d",
+			mtd->type);
+		return NULL;
+	}
+
+	yaffs_trace(YAFFS_TRACE_OS, " %s %d", WRITE_SIZE_STR, WRITE_SIZE(mtd));
+	yaffs_trace(YAFFS_TRACE_OS, " oobsize %d", mtd->oobsize);
+	yaffs_trace(YAFFS_TRACE_OS, " erasesize %d", mtd->erasesize);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 29)
+	yaffs_trace(YAFFS_TRACE_OS, " size %u", mtd->size);
+#else
+	yaffs_trace(YAFFS_TRACE_OS, " size %lld", mtd->size);
+#endif
+
+	return mtd;
+}
+
+int yaffs_verify_mtd(struct mtd_info *mtd, int yaffs_version, int inband_tags)
+{
+	if (yaffs_version == 2) {
+		if ((WRITE_SIZE(mtd) < YAFFS_MIN_YAFFS2_CHUNK_SIZE ||
+		     mtd->oobsize < YAFFS_MIN_YAFFS2_SPARE_SIZE) &&
+		    !inband_tags) {
+			yaffs_trace(YAFFS_TRACE_ALWAYS,
+				"MTD device does not have the right page sizes"
+			);
+			return -1;
+		}
+	} else {
+		if (WRITE_SIZE(mtd) < YAFFS_BYTES_PER_CHUNK ||
+		    mtd->oobsize != YAFFS_BYTES_PER_SPARE) {
+			yaffs_trace(YAFFS_TRACE_ALWAYS,
+				"MTD device does not support have the right page sizes"
+			);
+			return -1;
+		}
+	}
+
+	return 0;
+}
+
+
+void yaffs_put_mtd_device(struct mtd_info *mtd)
+{
+	if(mtd)
+		put_mtd_device(mtd);
+}
diff --git a/fs/yaffs2/yaffs_mtdif.h b/fs/yaffs2/yaffs_mtdif.h
new file mode 100644
index 0000000..9cff224
--- /dev/null
+++ b/fs/yaffs2/yaffs_mtdif.h
@@ -0,0 +1,25 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_MTDIF_H__
+#define __YAFFS_MTDIF_H__
+
+#include "yaffs_guts.h"
+
+void yaffs_mtd_drv_install(struct yaffs_dev *dev);
+struct mtd_info * yaffs_get_mtd_device(dev_t sdev);
+void yaffs_put_mtd_device(struct mtd_info *mtd);
+int yaffs_verify_mtd(struct mtd_info *mtd, int yaffs_version, int inband_tags);
+#endif
diff --git a/fs/yaffs2/yaffs_nameval.c b/fs/yaffs2/yaffs_nameval.c
new file mode 100644
index 0000000..eeb75be
--- /dev/null
+++ b/fs/yaffs2/yaffs_nameval.c
@@ -0,0 +1,230 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+/*
+ * This simple implementation of a name-value store assumes a small number of
+* values and fits into a small finite buffer.
+ *
+ * Each attribute is stored as a record:
+ *  sizeof(size) bytes   record size.
+ *  strnlen+1 bytes name null terminated.
+ *  nbytes    value.
+ *  ----------
+ *  total size  stored in record size
+ *
+ * This code has not been tested with unicode yet.
+ */
+
+#include "yaffs_nameval.h"
+#include "yaffs_guts.h"
+#include "yportenv.h"
+#include "yaffs_endian.h"
+
+static int nval_find(struct yaffs_dev *dev,
+		     const char *xb, int xb_size, const YCHAR *name,
+		     int *exist_size)
+{
+	int pos = 0;
+	s32 size;
+
+	memcpy(&size, xb, sizeof(size));
+	yaffs_do_endian_s32(dev, &size);
+
+	while (size > 0 && (size < xb_size) && (pos + size < xb_size)) {
+		if (!strncmp((YCHAR *) (xb + pos + sizeof(size)),
+				name, size)) {
+			if (exist_size)
+				*exist_size = size;
+			return pos;
+		}
+		pos += size;
+		if (pos < (int)(xb_size - sizeof(size))) {
+			memcpy(&size, xb + pos, sizeof(size));
+			yaffs_do_endian_s32(dev, &size);
+
+		} else
+			size = 0;
+	}
+	if (exist_size)
+		*exist_size = 0;
+	return -ENODATA;
+}
+
+static int nval_used(struct yaffs_dev *dev, const char *xb, int xb_size)
+{
+	int pos = 0;
+	s32 size;
+
+	memcpy(&size, xb + pos, sizeof(size));
+	yaffs_do_endian_s32(dev, &size);
+
+	while (size > 0 && (size < xb_size) && (pos + size < xb_size)) {
+		pos += size;
+		if (pos < (int)(xb_size - sizeof(size))) {
+			memcpy(&size, xb + pos, sizeof(size));
+			yaffs_do_endian_s32(dev, &size);
+		} else
+			size = 0;
+	}
+	return pos;
+}
+
+int nval_del(struct yaffs_dev *dev, char *xb, int xb_size, const YCHAR *name)
+{
+	int pos = nval_find(dev, xb, xb_size, name, NULL);
+	s32 size;
+
+	if (pos < 0 || pos >= xb_size)
+		return -ENODATA;
+
+	/* Find size, shift rest over this record,
+	 * then zero out the rest of buffer */
+	memcpy(&size, xb + pos, sizeof(size));
+	yaffs_do_endian_s32(dev, &size);
+
+	memcpy(xb + pos, xb + pos + size, xb_size - (pos + size));
+	memset(xb + (xb_size - size), 0, size);
+	return 0;
+}
+
+int nval_set(struct yaffs_dev *dev,
+	     char *xb, int xb_size, const YCHAR *name, const char *buf,
+	     int bsize, int flags)
+{
+	int pos;
+	int namelen = strnlen(name, xb_size);
+	int size_exist = 0;
+	int space;
+	int start;
+	s32 reclen;
+	s32 reclen_endianised;
+
+	pos = nval_find(dev, xb, xb_size, name, &size_exist);
+
+	if (flags & XATTR_CREATE && pos >= 0)
+		return -EEXIST;
+	if (flags & XATTR_REPLACE && pos < 0)
+		return -ENODATA;
+
+	start = nval_used(dev, xb, xb_size);
+	space = xb_size - start + size_exist;
+
+	reclen = (sizeof(reclen) + namelen + 1 + bsize);
+
+	if (reclen > space)
+		return -ENOSPC;
+
+	if (pos >= 0) {
+		/* Exists, so delete it. */
+		nval_del(dev, xb, xb_size, name);
+		start = nval_used(dev, xb, xb_size);
+	}
+
+	pos = start;
+
+	reclen_endianised = reclen;
+	yaffs_do_endian_s32(dev, &reclen_endianised);
+	memcpy(xb + pos, &reclen_endianised, sizeof(reclen_endianised));
+	pos += sizeof(reclen_endianised);
+	strncpy((YCHAR *) (xb + pos), name, reclen);
+	pos += (namelen + 1);
+	memcpy(xb + pos, buf, bsize);
+	return 0;
+}
+
+int nval_get(struct yaffs_dev *dev,
+	     const char *xb, int xb_size, const YCHAR * name, char *buf,
+	     int bsize)
+{
+	int pos = nval_find(dev, xb, xb_size, name, NULL);
+	s32 size;
+
+	if (pos >= 0 && pos < xb_size) {
+
+		memcpy(&size, xb + pos, sizeof(size));
+		yaffs_do_endian_s32(dev, &size);
+		pos += sizeof(size);	/* advance past record length */
+		size -= sizeof(size);
+
+		/* Advance over name string */
+		while (xb[pos] && size > 0 && pos < xb_size) {
+			pos++;
+			size--;
+		}
+		/*Advance over NUL */
+		pos++;
+		size--;
+
+		/* If bsize is zero then this is a size query.
+		 * Return the size, but don't copy.
+		 */
+		if (!bsize)
+			return size;
+
+		if (size <= bsize) {
+			memcpy(buf, xb + pos, size);
+			return size;
+		}
+	}
+	if (pos >= 0)
+		return -ERANGE;
+
+	return -ENODATA;
+}
+
+int nval_list(struct yaffs_dev *dev, const char *xb, int xb_size, char *buf, int bsize)
+{
+	int pos = 0;
+	s32 size;
+	int name_len;
+	int ncopied = 0;
+	int filled = 0;
+
+	memcpy(&size, xb + pos, sizeof(size));
+	yaffs_do_endian_s32(dev, &size);
+
+	while (size > (int)(sizeof(size)) &&
+		size <= xb_size &&
+		(pos + size) < xb_size &&
+		!filled) {
+		pos += sizeof(size);
+		size -= sizeof(size);
+		name_len = strnlen((YCHAR *) (xb + pos), size);
+		if (ncopied + name_len + 1 < bsize) {
+			memcpy(buf, xb + pos, name_len * sizeof(YCHAR));
+			buf += name_len;
+			*buf = '\0';
+			buf++;
+			if (sizeof(YCHAR) > 1) {
+				*buf = '\0';
+				buf++;
+			}
+			ncopied += (name_len + 1);
+		} else {
+			filled = 1;
+		}
+		pos += size;
+		if (pos < (int)(xb_size - sizeof(size))) {
+			memcpy(&size, xb + pos, sizeof(size));
+			yaffs_do_endian_s32(dev, &size);
+		}
+		else
+			size = 0;
+	}
+	return ncopied;
+}
+
+int nval_hasvalues(struct yaffs_dev *dev, const char *xb, int xb_size)
+{
+	return nval_used(dev, xb, xb_size) > 0;
+}
diff --git a/fs/yaffs2/yaffs_nameval.h b/fs/yaffs2/yaffs_nameval.h
new file mode 100644
index 0000000..aa05ada
--- /dev/null
+++ b/fs/yaffs2/yaffs_nameval.h
@@ -0,0 +1,33 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __NAMEVAL_H__
+#define __NAMEVAL_H__
+
+#include "yportenv.h"
+
+struct yaffs_dev;
+
+int nval_del(struct yaffs_dev *dev, char *xb, int xb_size, const YCHAR * name);
+int nval_set(struct yaffs_dev *dev,
+	     char *xb, int xb_size, const YCHAR * name, const char *buf,
+	     int bsize, int flags);
+int nval_get(struct yaffs_dev *dev,
+	     const char *xb, int xb_size, const YCHAR * name, char *buf,
+	     int bsize);
+int nval_list(struct yaffs_dev *dev,
+	      const char *xb, int xb_size, char *buf, int bsize);
+int nval_hasvalues(struct yaffs_dev *dev, const char *xb, int xb_size);
+#endif
diff --git a/fs/yaffs2/yaffs_nand.c b/fs/yaffs2/yaffs_nand.c
new file mode 100644
index 0000000..0d8499b
--- /dev/null
+++ b/fs/yaffs2/yaffs_nand.c
@@ -0,0 +1,122 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include "yaffs_nand.h"
+#include "yaffs_tagscompat.h"
+
+#include "yaffs_getblockinfo.h"
+#include "yaffs_summary.h"
+
+static int apply_chunk_offset(struct yaffs_dev *dev, int chunk)
+{
+	return chunk - dev->chunk_offset;
+}
+
+int yaffs_rd_chunk_tags_nand(struct yaffs_dev *dev, int nand_chunk,
+			     u8 *buffer, struct yaffs_ext_tags *tags)
+{
+	int result;
+	struct yaffs_ext_tags local_tags;
+	int flash_chunk = apply_chunk_offset(dev, nand_chunk);
+
+	dev->n_page_reads++;
+
+	/* If there are no tags provided use local tags. */
+	if (!tags)
+		tags = &local_tags;
+
+	result = dev->tagger.read_chunk_tags_fn(dev, flash_chunk, buffer, tags);
+	if (tags && tags->ecc_result > YAFFS_ECC_RESULT_NO_ERROR) {
+
+		struct yaffs_block_info *bi;
+		bi = yaffs_get_block_info(dev,
+					  nand_chunk /
+					  dev->param.chunks_per_block);
+		yaffs_handle_chunk_error(dev, bi);
+	}
+	return result;
+}
+
+int yaffs_wr_chunk_tags_nand(struct yaffs_dev *dev,
+				int nand_chunk,
+				const u8 *buffer, struct yaffs_ext_tags *tags)
+{
+	int result;
+	int flash_chunk = apply_chunk_offset(dev, nand_chunk);
+
+	dev->n_page_writes++;
+
+	if (!tags) {
+		yaffs_trace(YAFFS_TRACE_ERROR, "Writing with no tags");
+		BUG();
+		return YAFFS_FAIL;
+	}
+
+	tags->seq_number = dev->seq_number;
+	tags->chunk_used = 1;
+	yaffs_trace(YAFFS_TRACE_WRITE,
+		"Writing chunk %d tags %d %d",
+		nand_chunk, tags->obj_id, tags->chunk_id);
+
+	result = dev->tagger.write_chunk_tags_fn(dev, flash_chunk,
+							buffer, tags);
+
+	yaffs_summary_add(dev, tags, nand_chunk);
+
+	return result;
+}
+
+int yaffs_mark_bad(struct yaffs_dev *dev, int block_no)
+{
+	block_no -= dev->block_offset;
+	dev->n_bad_markings++;
+
+	if (dev->param.disable_bad_block_marking)
+		return YAFFS_OK;
+
+	return dev->tagger.mark_bad_fn(dev, block_no);
+}
+
+
+int yaffs_query_init_block_state(struct yaffs_dev *dev,
+				 int block_no,
+				 enum yaffs_block_state *state,
+				 u32 *seq_number)
+{
+	block_no -= dev->block_offset;
+	return dev->tagger.query_block_fn(dev, block_no, state, seq_number);
+}
+
+int yaffs_erase_block(struct yaffs_dev *dev, int block_no)
+{
+	int result;
+
+	block_no -= dev->block_offset;
+	dev->n_erasures++;
+	result = dev->drv.drv_erase_fn(dev, block_no);
+	return result;
+}
+
+int yaffs_init_nand(struct yaffs_dev *dev)
+{
+	if (dev->drv.drv_initialise_fn)
+		return dev->drv.drv_initialise_fn(dev);
+	return YAFFS_OK;
+}
+
+int yaffs_deinit_nand(struct yaffs_dev *dev)
+{
+	if (dev->drv.drv_deinitialise_fn)
+		return dev->drv.drv_deinitialise_fn(dev);
+	return YAFFS_OK;
+}
diff --git a/fs/yaffs2/yaffs_nand.h b/fs/yaffs2/yaffs_nand.h
new file mode 100644
index 0000000..804e97a
--- /dev/null
+++ b/fs/yaffs2/yaffs_nand.h
@@ -0,0 +1,39 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_NAND_H__
+#define __YAFFS_NAND_H__
+#include "yaffs_guts.h"
+
+int yaffs_rd_chunk_tags_nand(struct yaffs_dev *dev, int nand_chunk,
+			     u8 *buffer, struct yaffs_ext_tags *tags);
+
+int yaffs_wr_chunk_tags_nand(struct yaffs_dev *dev,
+			     int nand_chunk,
+			     const u8 *buffer, struct yaffs_ext_tags *tags);
+
+int yaffs_mark_bad(struct yaffs_dev *dev, int block_no);
+
+int yaffs_query_init_block_state(struct yaffs_dev *dev,
+				 int block_no,
+				 enum yaffs_block_state *state,
+				 unsigned *seq_number);
+
+int yaffs_erase_block(struct yaffs_dev *dev, int flash_block);
+
+int yaffs_init_nand(struct yaffs_dev *dev);
+int yaffs_deinit_nand(struct yaffs_dev *dev);
+
+#endif
diff --git a/fs/yaffs2/yaffs_packedtags1.c b/fs/yaffs2/yaffs_packedtags1.c
new file mode 100644
index 0000000..0928b8e
--- /dev/null
+++ b/fs/yaffs2/yaffs_packedtags1.c
@@ -0,0 +1,55 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include "yaffs_packedtags1.h"
+#include "yportenv.h"
+
+static const u8 all_ff[20] = {
+	0xff, 0xff, 0xff, 0xff,
+	0xff, 0xff, 0xff, 0xff,
+	0xff, 0xff, 0xff, 0xff,
+	0xff, 0xff, 0xff, 0xff,
+	0xff, 0xff, 0xff, 0xff
+};
+
+void yaffs_pack_tags1(struct yaffs_packed_tags1 *pt,
+		      const struct yaffs_ext_tags *t)
+{
+	pt->chunk_id = t->chunk_id;
+	pt->serial_number = t->serial_number;
+	pt->n_bytes = t->n_bytes;
+	pt->obj_id = t->obj_id;
+	pt->ecc = 0;
+	pt->deleted = (t->is_deleted) ? 0 : 1;
+	pt->unused_stuff = 0;
+	pt->should_be_ff = 0xffffffff;
+}
+
+void yaffs_unpack_tags1(struct yaffs_ext_tags *t,
+			const struct yaffs_packed_tags1 *pt)
+{
+	if (memcmp(all_ff, pt, sizeof(struct yaffs_packed_tags1))) {
+		t->block_bad = 0;
+		if (pt->should_be_ff != 0xffffffff)
+			t->block_bad = 1;
+		t->chunk_used = 1;
+		t->obj_id = pt->obj_id;
+		t->chunk_id = pt->chunk_id;
+		t->n_bytes = pt->n_bytes;
+		t->ecc_result = YAFFS_ECC_RESULT_NO_ERROR;
+		t->is_deleted = (pt->deleted) ? 0 : 1;
+		t->serial_number = pt->serial_number;
+	} else {
+		memset(t, 0, sizeof(struct yaffs_ext_tags));
+	}
+}
diff --git a/fs/yaffs2/yaffs_packedtags1.h b/fs/yaffs2/yaffs_packedtags1.h
new file mode 100644
index 0000000..3015d58
--- /dev/null
+++ b/fs/yaffs2/yaffs_packedtags1.h
@@ -0,0 +1,39 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+/* This is used to pack YAFFS1 tags, not YAFFS2 tags. */
+
+#ifndef __YAFFS_PACKEDTAGS1_H__
+#define __YAFFS_PACKEDTAGS1_H__
+
+#include "yaffs_guts.h"
+
+struct yaffs_packed_tags1 {
+	u32 chunk_id:20;
+	u32 serial_number:2;
+	u32 n_bytes:10;
+	u32 obj_id:18;
+	u32 ecc:12;
+	u32 deleted:1;
+	u32 unused_stuff:1;
+	unsigned should_be_ff;
+
+};
+
+void yaffs_pack_tags1(struct yaffs_packed_tags1 *pt,
+		      const struct yaffs_ext_tags *t);
+void yaffs_unpack_tags1(struct yaffs_ext_tags *t,
+			const struct yaffs_packed_tags1 *pt);
+#endif
diff --git a/fs/yaffs2/yaffs_packedtags2.c b/fs/yaffs2/yaffs_packedtags2.c
new file mode 100644
index 0000000..d5291fc
--- /dev/null
+++ b/fs/yaffs2/yaffs_packedtags2.c
@@ -0,0 +1,208 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include "yaffs_packedtags2.h"
+#include "yportenv.h"
+#include "yaffs_trace.h"
+#include "yaffs_endian.h"
+
+/* This code packs a set of extended tags into a binary structure for
+ * NAND storage
+ */
+
+/* Some of the information is "extra" struff which can be packed in to
+ * speed scanning
+ * This is defined by having the EXTRA_HEADER_INFO_FLAG set.
+ */
+
+/* Extra flags applied to chunk_id */
+
+#define EXTRA_HEADER_INFO_FLAG	0x80000000
+#define EXTRA_SHRINK_FLAG	0x40000000
+#define EXTRA_SHADOWS_FLAG	0x20000000
+#define EXTRA_SPARE_FLAGS	0x10000000
+
+#define ALL_EXTRA_FLAGS		0xf0000000
+
+/* Also, the top 4 bits of the object Id are set to the object type. */
+#define EXTRA_OBJECT_TYPE_SHIFT (28)
+#define EXTRA_OBJECT_TYPE_MASK  ((0x0f) << EXTRA_OBJECT_TYPE_SHIFT)
+
+static void yaffs_dump_packed_tags2_tags_only(
+				const struct yaffs_packed_tags2_tags_only *ptt)
+{
+	yaffs_trace(YAFFS_TRACE_MTD,
+		"packed tags obj %d chunk %d byte %d seq %d",
+		ptt->obj_id, ptt->chunk_id, ptt->n_bytes, ptt->seq_number);
+}
+
+static void yaffs_dump_packed_tags2(const struct yaffs_packed_tags2 *pt)
+{
+	yaffs_dump_packed_tags2_tags_only(&pt->t);
+}
+
+static void yaffs_dump_tags2(const struct yaffs_ext_tags *t)
+{
+	yaffs_trace(YAFFS_TRACE_MTD,
+		"ext.tags eccres %d blkbad %d chused %d obj %d chunk%d byte %d del %d ser %d seq %d",
+		t->ecc_result, t->block_bad, t->chunk_used, t->obj_id,
+		t->chunk_id, t->n_bytes, t->is_deleted, t->serial_number,
+		t->seq_number);
+
+}
+
+static int yaffs_check_tags_extra_packable(const struct yaffs_ext_tags *t)
+{
+	if (t->chunk_id != 0 || !t->extra_available)
+		return 0;
+
+	/* Check if the file size is too long to store */
+	if (t->extra_obj_type == YAFFS_OBJECT_TYPE_FILE &&
+	    (t->extra_file_size >> 31) != 0)
+		return 0;
+	return 1;
+}
+
+void yaffs_pack_tags2_tags_only(struct yaffs_dev *dev,
+				struct yaffs_packed_tags2_tags_only *ptt,
+				const struct yaffs_ext_tags *t)
+{
+	ptt->chunk_id = t->chunk_id;
+	ptt->seq_number = t->seq_number;
+	ptt->n_bytes = t->n_bytes;
+	ptt->obj_id = t->obj_id;
+
+	/* Only store extra tags for object headers.
+	 * If it is a file then only store  if the file size is short\
+	 * enough to fit.
+	 */
+	if (yaffs_check_tags_extra_packable(t)) {
+		/* Store the extra header info instead */
+		/* We save the parent object in the chunk_id */
+		ptt->chunk_id = EXTRA_HEADER_INFO_FLAG | t->extra_parent_id;
+		if (t->extra_is_shrink)
+			ptt->chunk_id |= EXTRA_SHRINK_FLAG;
+		if (t->extra_shadows)
+			ptt->chunk_id |= EXTRA_SHADOWS_FLAG;
+
+		ptt->obj_id &= ~EXTRA_OBJECT_TYPE_MASK;
+		ptt->obj_id |= (t->extra_obj_type << EXTRA_OBJECT_TYPE_SHIFT);
+
+		if (t->extra_obj_type == YAFFS_OBJECT_TYPE_HARDLINK)
+			ptt->n_bytes = t->extra_equiv_id;
+		else if (t->extra_obj_type == YAFFS_OBJECT_TYPE_FILE)
+			ptt->n_bytes = (unsigned) t->extra_file_size;
+		else
+			ptt->n_bytes = 0;
+	}
+
+	yaffs_dump_packed_tags2_tags_only(ptt);
+	yaffs_dump_tags2(t);
+	yaffs_do_endian_packed_tags2(dev, ptt);
+}
+
+void yaffs_pack_tags2(struct yaffs_dev *dev,
+		      struct yaffs_packed_tags2 *pt,
+		      const struct yaffs_ext_tags *t, int tags_ecc)
+{
+	yaffs_pack_tags2_tags_only(dev, &pt->t, t);
+
+	if (tags_ecc)
+		yaffs_ecc_calc_other((unsigned char *)&pt->t,
+				    sizeof(struct yaffs_packed_tags2_tags_only),
+				    &pt->ecc);
+}
+
+void yaffs_unpack_tags2_tags_only(struct yaffs_dev *dev,
+				  struct yaffs_ext_tags *t,
+				  struct yaffs_packed_tags2_tags_only *ptt_ptr)
+{
+	struct yaffs_packed_tags2_tags_only ptt_copy = *ptt_ptr;
+
+	memset(t, 0, sizeof(struct yaffs_ext_tags));
+
+	if (ptt_copy.seq_number == 0xffffffff)
+		return;
+
+	yaffs_do_endian_packed_tags2(dev, &ptt_copy);
+
+	t->block_bad = 0;
+	t->chunk_used = 1;
+	t->obj_id = ptt_copy.obj_id;
+	t->chunk_id = ptt_copy.chunk_id;
+	t->n_bytes = ptt_copy.n_bytes;
+	t->is_deleted = 0;
+	t->serial_number = 0;
+	t->seq_number = ptt_copy.seq_number;
+
+	/* Do extra header info stuff */
+	if (ptt_copy.chunk_id & EXTRA_HEADER_INFO_FLAG) {
+		t->chunk_id = 0;
+		t->n_bytes = 0;
+
+		t->extra_available = 1;
+		t->extra_parent_id = ptt_copy.chunk_id & (~(ALL_EXTRA_FLAGS));
+		t->extra_is_shrink = ptt_copy.chunk_id & EXTRA_SHRINK_FLAG ? 1 : 0;
+		t->extra_shadows = ptt_copy.chunk_id & EXTRA_SHADOWS_FLAG ? 1 : 0;
+		t->extra_obj_type = ptt_copy.obj_id >> EXTRA_OBJECT_TYPE_SHIFT;
+		t->obj_id &= ~EXTRA_OBJECT_TYPE_MASK;
+
+		if (t->extra_obj_type == YAFFS_OBJECT_TYPE_HARDLINK)
+			t->extra_equiv_id = ptt_copy.n_bytes;
+		else
+			t->extra_file_size = ptt_copy.n_bytes;
+	}
+	yaffs_dump_packed_tags2_tags_only(ptt_ptr);
+	yaffs_dump_tags2(t);
+}
+
+void yaffs_unpack_tags2(struct yaffs_dev *dev,
+			struct yaffs_ext_tags *t,
+			struct yaffs_packed_tags2 *pt,
+			int tags_ecc)
+{
+	enum yaffs_ecc_result ecc_result = YAFFS_ECC_RESULT_NO_ERROR;
+
+	if (pt->t.seq_number != 0xffffffff && tags_ecc) {
+		/* Chunk is in use and we need to do ECC */
+
+		struct yaffs_ecc_other ecc;
+		int result;
+		yaffs_ecc_calc_other((unsigned char *)&pt->t,
+				sizeof(struct yaffs_packed_tags2_tags_only),
+				&ecc);
+		result =
+		    yaffs_ecc_correct_other((unsigned char *)&pt->t,
+				sizeof(struct yaffs_packed_tags2_tags_only),
+				&pt->ecc, &ecc);
+		switch (result) {
+		case 0:
+			ecc_result = YAFFS_ECC_RESULT_NO_ERROR;
+			break;
+		case 1:
+			ecc_result = YAFFS_ECC_RESULT_FIXED;
+			break;
+		case -1:
+			ecc_result = YAFFS_ECC_RESULT_UNFIXED;
+			break;
+		default:
+			ecc_result = YAFFS_ECC_RESULT_UNKNOWN;
+		}
+	}
+	yaffs_unpack_tags2_tags_only(dev, t, &pt->t);
+
+	t->ecc_result = ecc_result;
+
+	yaffs_dump_packed_tags2(pt);
+	yaffs_dump_tags2(t);
+}
diff --git a/fs/yaffs2/yaffs_packedtags2.h b/fs/yaffs2/yaffs_packedtags2.h
new file mode 100644
index 0000000..9cafe0e
--- /dev/null
+++ b/fs/yaffs2/yaffs_packedtags2.h
@@ -0,0 +1,51 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+/* This is used to pack YAFFS2 tags, not YAFFS1tags. */
+
+#ifndef __YAFFS_PACKEDTAGS2_H__
+#define __YAFFS_PACKEDTAGS2_H__
+
+#include "yaffs_guts.h"
+#include "yaffs_ecc.h"
+
+struct yaffs_packed_tags2_tags_only {
+	unsigned seq_number;
+	unsigned obj_id;
+	unsigned chunk_id;
+	unsigned n_bytes;
+};
+
+struct yaffs_packed_tags2 {
+	struct yaffs_packed_tags2_tags_only t;
+	struct yaffs_ecc_other ecc;
+};
+
+/* Full packed tags with ECC, used for oob tags */
+void yaffs_pack_tags2(struct yaffs_dev *dev,
+		      struct yaffs_packed_tags2 *pt,
+		      const struct yaffs_ext_tags *t, int tags_ecc);
+void yaffs_unpack_tags2(struct yaffs_dev *dev,
+			struct yaffs_ext_tags *t, struct yaffs_packed_tags2 *pt,
+			int tags_ecc);
+
+/* Only the tags part (no ECC for use with inband tags */
+void yaffs_pack_tags2_tags_only(struct yaffs_dev *dev,
+				struct yaffs_packed_tags2_tags_only *pt,
+				const struct yaffs_ext_tags *t);
+void yaffs_unpack_tags2_tags_only(struct yaffs_dev *dev,
+				  struct yaffs_ext_tags *t,
+				  struct yaffs_packed_tags2_tags_only *pt);
+#endif
diff --git a/fs/yaffs2/yaffs_summary.c b/fs/yaffs2/yaffs_summary.c
new file mode 100644
index 0000000..1e7776b
--- /dev/null
+++ b/fs/yaffs2/yaffs_summary.c
@@ -0,0 +1,310 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+/* Summaries write the useful part of the tags for the chunks in a block into an
+ * an array which is written to the last n chunks of the block.
+ * Reading the summaries gives all the tags for the block in one read. Much
+ * faster.
+ *
+ * Chunks holding summaries are marked with tags making it look like
+ * they are part of a fake file.
+ *
+ * The summary could also be used during gc.
+ *
+ */
+
+#include "yaffs_summary.h"
+#include "yaffs_packedtags2.h"
+#include "yaffs_nand.h"
+#include "yaffs_getblockinfo.h"
+#include "yaffs_bitmap.h"
+
+/*
+ * The summary is built up in an array of summary tags.
+ * This gets written to the last one or two (maybe more) chunks in a block.
+ * A summary header is written as the first part of each chunk of summary data.
+ * The summary header must match or the summary is rejected.
+ */
+
+/* Summary tags don't need the sequence number because that is redundant. */
+struct yaffs_summary_tags {
+	unsigned obj_id;
+	unsigned chunk_id;
+	unsigned n_bytes;
+};
+
+/* Summary header */
+struct yaffs_summary_header {
+	unsigned version;	/* Must match current version */
+	unsigned block;		/* Must be this block */
+	unsigned seq;		/* Must be this sequence number */
+	unsigned sum;		/* Just add up all the bytes in the tags */
+};
+
+
+static void yaffs_summary_clear(struct yaffs_dev *dev)
+{
+	if (!dev->sum_tags)
+		return;
+	memset(dev->sum_tags, 0, dev->chunks_per_summary *
+		sizeof(struct yaffs_summary_tags));
+}
+
+
+void yaffs_summary_deinit(struct yaffs_dev *dev)
+{
+	kfree(dev->sum_tags);
+	dev->sum_tags = NULL;
+	kfree(dev->gc_sum_tags);
+	dev->gc_sum_tags = NULL;
+	dev->chunks_per_summary = 0;
+}
+
+int yaffs_summary_init(struct yaffs_dev *dev)
+{
+	int sum_bytes;
+	int chunks_used; /* Number of chunks used by summary */
+	int sum_tags_bytes;
+
+	sum_bytes = dev->param.chunks_per_block *
+			sizeof(struct yaffs_summary_tags);
+
+	chunks_used = (sum_bytes + dev->data_bytes_per_chunk - 1)/
+			(dev->data_bytes_per_chunk -
+				sizeof(struct yaffs_summary_header));
+
+	dev->chunks_per_summary = dev->param.chunks_per_block - chunks_used;
+	sum_tags_bytes = sizeof(struct yaffs_summary_tags) *
+				dev->chunks_per_summary;
+	dev->sum_tags = kmalloc(sum_tags_bytes, GFP_NOFS);
+	dev->gc_sum_tags = kmalloc(sum_tags_bytes, GFP_NOFS);
+	if (!dev->sum_tags || !dev->gc_sum_tags) {
+		yaffs_summary_deinit(dev);
+		return YAFFS_FAIL;
+	}
+
+	yaffs_summary_clear(dev);
+
+	return YAFFS_OK;
+}
+
+static unsigned yaffs_summary_sum(struct yaffs_dev *dev)
+{
+	u8 *sum_buffer = (u8 *)dev->sum_tags;
+	int i;
+	unsigned sum = 0;
+
+	i = sizeof(struct yaffs_summary_tags) *
+				dev->chunks_per_summary;
+	while (i > 0) {
+		sum += *sum_buffer;
+		sum_buffer++;
+		i--;
+	}
+
+	return sum;
+}
+
+static int yaffs_summary_write(struct yaffs_dev *dev, int blk)
+{
+	struct yaffs_ext_tags tags;
+	u8 *buffer;
+	u8 *sum_buffer = (u8 *)dev->sum_tags;
+	int n_bytes;
+	int chunk_in_nand;
+	int chunk_in_block;
+	int result;
+	int this_tx;
+	struct yaffs_summary_header hdr;
+	int sum_bytes_per_chunk = dev->data_bytes_per_chunk - sizeof(hdr);
+	struct yaffs_block_info *bi = yaffs_get_block_info(dev, blk);
+
+	buffer = yaffs_get_temp_buffer(dev);
+	n_bytes = sizeof(struct yaffs_summary_tags) *
+				dev->chunks_per_summary;
+	memset(&tags, 0, sizeof(struct yaffs_ext_tags));
+	tags.obj_id = YAFFS_OBJECTID_SUMMARY;
+	tags.chunk_id = 1;
+	chunk_in_block = dev->chunks_per_summary;
+	chunk_in_nand = dev->alloc_block * dev->param.chunks_per_block +
+						dev->chunks_per_summary;
+	hdr.version = YAFFS_SUMMARY_VERSION;
+	hdr.block = blk;
+	hdr.seq = bi->seq_number;
+	hdr.sum = yaffs_summary_sum(dev);
+
+	do {
+		this_tx = n_bytes;
+		if (this_tx > sum_bytes_per_chunk)
+			this_tx = sum_bytes_per_chunk;
+		memcpy(buffer, &hdr, sizeof(hdr));
+		memcpy(buffer + sizeof(hdr), sum_buffer, this_tx);
+		tags.n_bytes = this_tx + sizeof(hdr);
+		result = yaffs_wr_chunk_tags_nand(dev, chunk_in_nand,
+						buffer, &tags);
+
+		if (result != YAFFS_OK)
+			break;
+		yaffs_set_chunk_bit(dev, blk, chunk_in_block);
+		bi->pages_in_use++;
+		dev->n_free_chunks--;
+
+		n_bytes -= this_tx;
+		sum_buffer += this_tx;
+		chunk_in_nand++;
+		chunk_in_block++;
+		tags.chunk_id++;
+	} while (result == YAFFS_OK && n_bytes > 0);
+	yaffs_release_temp_buffer(dev, buffer);
+
+
+	if (result == YAFFS_OK)
+		bi->has_summary = 1;
+
+
+	return result;
+}
+
+int yaffs_summary_read(struct yaffs_dev *dev,
+			struct yaffs_summary_tags *st,
+			int blk)
+{
+	struct yaffs_ext_tags tags;
+	u8 *buffer;
+	u8 *sum_buffer = (u8 *)st;
+	int n_bytes;
+	u32 chunk_id;
+	int chunk_in_nand;
+	int chunk_in_block;
+	int result;
+	int this_tx;
+	struct yaffs_summary_header hdr;
+	struct yaffs_block_info *bi = yaffs_get_block_info(dev, blk);
+	int sum_bytes_per_chunk = dev->data_bytes_per_chunk - sizeof(hdr);
+
+	buffer = yaffs_get_temp_buffer(dev);
+	n_bytes = sizeof(struct yaffs_summary_tags) * dev->chunks_per_summary;
+	chunk_in_block = dev->chunks_per_summary;
+	chunk_in_nand = blk * dev->param.chunks_per_block +
+							dev->chunks_per_summary;
+	chunk_id = 1;
+	do {
+		this_tx = n_bytes;
+		if (this_tx > sum_bytes_per_chunk)
+			this_tx = sum_bytes_per_chunk;
+		result = yaffs_rd_chunk_tags_nand(dev, chunk_in_nand,
+						buffer, &tags);
+
+		if (tags.chunk_id != chunk_id ||
+			tags.obj_id != YAFFS_OBJECTID_SUMMARY ||
+			tags.chunk_used == 0 ||
+			tags.ecc_result > YAFFS_ECC_RESULT_FIXED ||
+			tags.n_bytes != (this_tx + sizeof(hdr)))
+				result = YAFFS_FAIL;
+		if (result != YAFFS_OK)
+			break;
+
+		if (st == dev->sum_tags) {
+			/* If we're scanning then update the block info */
+			yaffs_set_chunk_bit(dev, blk, chunk_in_block);
+			bi->pages_in_use++;
+		}
+		memcpy(&hdr, buffer, sizeof(hdr));
+		memcpy(sum_buffer, buffer + sizeof(hdr), this_tx);
+		n_bytes -= this_tx;
+		sum_buffer += this_tx;
+		chunk_in_nand++;
+		chunk_in_block++;
+		chunk_id++;
+	} while (result == YAFFS_OK && n_bytes > 0);
+	yaffs_release_temp_buffer(dev, buffer);
+
+	if (result == YAFFS_OK) {
+		/* Verify header */
+		if (hdr.version != YAFFS_SUMMARY_VERSION ||
+		    hdr.seq != bi->seq_number ||
+		    hdr.sum != yaffs_summary_sum(dev))
+			result = YAFFS_FAIL;
+	}
+
+	if (st == dev->sum_tags && result == YAFFS_OK)
+		bi->has_summary = 1;
+
+	return result;
+}
+
+int yaffs_summary_add(struct yaffs_dev *dev,
+			struct yaffs_ext_tags *tags,
+			int chunk_in_nand)
+{
+	struct yaffs_packed_tags2_tags_only tags_only;
+	struct yaffs_summary_tags *sum_tags;
+	int block_in_nand = chunk_in_nand / dev->param.chunks_per_block;
+	int chunk_in_block = chunk_in_nand % dev->param.chunks_per_block;
+
+	if (!dev->sum_tags)
+		return YAFFS_OK;
+
+	if (chunk_in_block >= 0 && chunk_in_block < dev->chunks_per_summary) {
+		yaffs_pack_tags2_tags_only(dev, &tags_only, tags);
+		sum_tags = &dev->sum_tags[chunk_in_block];
+
+		sum_tags->chunk_id = tags_only.chunk_id;
+		sum_tags->n_bytes = tags_only.n_bytes;
+		sum_tags->obj_id = tags_only.obj_id;
+
+		if (chunk_in_block == dev->chunks_per_summary - 1) {
+			/* Time to write out the summary */
+			yaffs_summary_write(dev, block_in_nand);
+			yaffs_summary_clear(dev);
+			yaffs_skip_rest_of_block(dev);
+		}
+	}
+	return YAFFS_OK;
+}
+
+int yaffs_summary_fetch(struct yaffs_dev *dev,
+			struct yaffs_ext_tags *tags,
+			int chunk_in_block)
+{
+	struct yaffs_packed_tags2_tags_only tags_only;
+	struct yaffs_summary_tags *sum_tags;
+	if (chunk_in_block >= 0 && chunk_in_block < dev->chunks_per_summary) {
+		sum_tags = &dev->sum_tags[chunk_in_block];
+		tags_only.chunk_id = sum_tags->chunk_id;
+		tags_only.n_bytes = sum_tags->n_bytes;
+		tags_only.obj_id = sum_tags->obj_id;
+		yaffs_unpack_tags2_tags_only(dev, tags, &tags_only);
+		return YAFFS_OK;
+	}
+	return YAFFS_FAIL;
+}
+
+void yaffs_summary_gc(struct yaffs_dev *dev, int blk)
+{
+	struct yaffs_block_info *bi = yaffs_get_block_info(dev, blk);
+	u32 i;
+
+	if (!bi->has_summary)
+		return;
+
+	for (i = dev->chunks_per_summary;
+	     i < dev->param.chunks_per_block;
+	     i++) {
+		if (yaffs_check_chunk_bit(dev, blk, i)) {
+			yaffs_clear_chunk_bit(dev, blk, i);
+			bi->pages_in_use--;
+			dev->n_free_chunks++;
+		}
+	}
+}
diff --git a/fs/yaffs2/yaffs_summary.h b/fs/yaffs2/yaffs_summary.h
new file mode 100644
index 0000000..be141d0
--- /dev/null
+++ b/fs/yaffs2/yaffs_summary.h
@@ -0,0 +1,37 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_SUMMARY_H__
+#define __YAFFS_SUMMARY_H__
+
+#include "yaffs_packedtags2.h"
+
+
+int yaffs_summary_init(struct yaffs_dev *dev);
+void yaffs_summary_deinit(struct yaffs_dev *dev);
+
+int yaffs_summary_add(struct yaffs_dev *dev,
+			struct yaffs_ext_tags *tags,
+			int chunk_in_block);
+int yaffs_summary_fetch(struct yaffs_dev *dev,
+			struct yaffs_ext_tags *tags,
+			int chunk_in_block);
+int yaffs_summary_read(struct yaffs_dev *dev,
+			struct yaffs_summary_tags *st,
+			int blk);
+void yaffs_summary_gc(struct yaffs_dev *dev, int blk);
+
+
+#endif
diff --git a/fs/yaffs2/yaffs_tagscompat.c b/fs/yaffs2/yaffs_tagscompat.c
new file mode 100644
index 0000000..e57c2d3
--- /dev/null
+++ b/fs/yaffs2/yaffs_tagscompat.c
@@ -0,0 +1,400 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This file handles yaffs1-style tags to allow compatibility with Yaffs1 style
+ * flash layouts.
+ */
+
+#include "yaffs_guts.h"
+#include "yaffs_tagscompat.h"
+#include "yaffs_ecc.h"
+#include "yaffs_getblockinfo.h"
+#include "yaffs_trace.h"
+#include "yaffs_endian.h"
+
+static void yaffs_handle_rd_data_error(struct yaffs_dev *dev, int nand_chunk);
+
+
+/********** Tags ECC calculations  *********/
+
+void yaffs_calc_tags_ecc(struct yaffs_tags *tags)
+{
+	/* Calculate an ecc */
+	unsigned char *b = ((union yaffs_tags_union *)tags)->as_bytes;
+	unsigned i, j;
+	unsigned ecc = 0;
+	unsigned bit = 0;
+
+	tags->ecc = 0;
+
+	for (i = 0; i < 8; i++) {
+		for (j = 1; j & 0xff; j <<= 1) {
+			bit++;
+			if (b[i] & j)
+				ecc ^= bit;
+		}
+	}
+	tags->ecc = ecc;
+}
+
+int yaffs_check_tags_ecc(struct yaffs_tags *tags)
+{
+	unsigned ecc = tags->ecc;
+
+	yaffs_calc_tags_ecc(tags);
+
+	ecc ^= tags->ecc;
+
+	if (ecc && ecc <= 64) {
+		/* TODO: Handle the failure better. Retire? */
+		unsigned char *b = ((union yaffs_tags_union *)tags)->as_bytes;
+
+		ecc--;
+
+		b[ecc / 8] ^= (1 << (ecc & 7));
+
+		/* Now recvalc the ecc */
+		yaffs_calc_tags_ecc(tags);
+
+		return 1;	/* recovered error */
+	} else if (ecc) {
+		/* Wierd ecc failure value */
+		/* TODO Need to do somethiong here */
+		return -1;	/* unrecovered error */
+	}
+	return 0;
+}
+
+/********** Tags **********/
+
+/*
+ * During tags storing/retireval we use a copy of the tags so that
+ * we can modify the endian etc without damaging the previous structure.
+ */
+static void yaffs_load_tags_to_spare(struct yaffs_dev *dev,
+				     struct yaffs_spare *spare_ptr,
+				     struct yaffs_tags *tags_ptr)
+{
+	union yaffs_tags_union *tu_ptr = (union yaffs_tags_union *)tags_ptr;
+	union yaffs_tags_union tags_stored = *tu_ptr;
+
+	yaffs_calc_tags_ecc(&tags_stored.as_tags);
+
+	yaffs_do_endian_u32(dev, &tags_stored.as_u32[0]);
+	yaffs_do_endian_u32(dev, &tags_stored.as_u32[1]);
+
+	spare_ptr->tb0 = tags_stored.as_bytes[0];
+	spare_ptr->tb1 = tags_stored.as_bytes[1];
+	spare_ptr->tb2 = tags_stored.as_bytes[2];
+	spare_ptr->tb3 = tags_stored.as_bytes[3];
+	spare_ptr->tb4 = tags_stored.as_bytes[4];
+	spare_ptr->tb5 = tags_stored.as_bytes[5];
+	spare_ptr->tb6 = tags_stored.as_bytes[6];
+	spare_ptr->tb7 = tags_stored.as_bytes[7];
+}
+
+static void yaffs_get_tags_from_spare(struct yaffs_dev *dev,
+				      struct yaffs_spare *spare_ptr,
+				      struct yaffs_tags *tags_ptr)
+{
+	union yaffs_tags_union *tu = (union yaffs_tags_union *)tags_ptr;
+	union yaffs_tags_union tags_stored;
+	int result;
+
+	tags_stored.as_bytes[0] = spare_ptr->tb0;
+	tags_stored.as_bytes[1] = spare_ptr->tb1;
+	tags_stored.as_bytes[2] = spare_ptr->tb2;
+	tags_stored.as_bytes[3] = spare_ptr->tb3;
+	tags_stored.as_bytes[4] = spare_ptr->tb4;
+	tags_stored.as_bytes[5] = spare_ptr->tb5;
+	tags_stored.as_bytes[6] = spare_ptr->tb6;
+	tags_stored.as_bytes[7] = spare_ptr->tb7;
+
+	yaffs_do_endian_u32(dev, &tags_stored.as_u32[0]);
+	yaffs_do_endian_u32(dev, &tags_stored.as_u32[1]);
+
+	*tu = tags_stored;
+
+	result = yaffs_check_tags_ecc(tags_ptr);
+	if (result > 0)
+		dev->n_tags_ecc_fixed++;
+	else if (result < 0)
+		dev->n_tags_ecc_unfixed++;
+}
+
+static void yaffs_spare_init(struct yaffs_spare *spare)
+{
+	memset(spare, 0xff, sizeof(struct yaffs_spare));
+}
+
+static int yaffs_wr_nand(struct yaffs_dev *dev,
+			 int nand_chunk, const u8 *data,
+			 struct yaffs_spare *spare)
+{
+	int data_size = dev->data_bytes_per_chunk;
+
+	return dev->drv.drv_write_chunk_fn(dev, nand_chunk,
+				data, data_size,
+				(u8 *) spare, sizeof(*spare));
+}
+
+static int yaffs_rd_chunk_nand(struct yaffs_dev *dev,
+			       int nand_chunk,
+			       u8 *data,
+			       struct yaffs_spare *spare,
+			       enum yaffs_ecc_result *ecc_result,
+			       int correct_errors)
+{
+	int ret_val;
+	struct yaffs_spare local_spare;
+	int data_size;
+	int spare_size;
+	int ecc_result1, ecc_result2;
+	u8 calc_ecc[3];
+
+	if (!spare) {
+		/* If we don't have a real spare, then we use a local one. */
+		/* Need this for the calculation of the ecc */
+		spare = &local_spare;
+	}
+	data_size = dev->data_bytes_per_chunk;
+	spare_size = sizeof(struct yaffs_spare);
+
+	if (dev->param.use_nand_ecc)
+		return dev->drv.drv_read_chunk_fn(dev, nand_chunk,
+						data, data_size,
+						(u8 *) spare, spare_size,
+						ecc_result);
+
+
+	/* Handle the ECC at this level. */
+
+	ret_val = dev->drv.drv_read_chunk_fn(dev, nand_chunk,
+						 data, data_size,
+						 (u8 *)spare, spare_size,
+						NULL);
+	if (!data || !correct_errors)
+		return ret_val;
+
+	/* Do ECC correction if needed. */
+	yaffs_ecc_calc(data, calc_ecc);
+	ecc_result1 = yaffs_ecc_correct(data, spare->ecc1, calc_ecc);
+	yaffs_ecc_calc(&data[256], calc_ecc);
+	ecc_result2 = yaffs_ecc_correct(&data[256], spare->ecc2, calc_ecc);
+
+	if (ecc_result1 > 0) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"**>>yaffs ecc error fix performed on chunk %d:0",
+			nand_chunk);
+		dev->n_ecc_fixed++;
+	} else if (ecc_result1 < 0) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"**>>yaffs ecc error unfixed on chunk %d:0",
+			nand_chunk);
+		dev->n_ecc_unfixed++;
+	}
+
+	if (ecc_result2 > 0) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"**>>yaffs ecc error fix performed on chunk %d:1",
+			nand_chunk);
+		dev->n_ecc_fixed++;
+	} else if (ecc_result2 < 0) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"**>>yaffs ecc error unfixed on chunk %d:1",
+			nand_chunk);
+		dev->n_ecc_unfixed++;
+	}
+
+	if (ecc_result1 || ecc_result2) {
+		/* We had a data problem on this page */
+		yaffs_handle_rd_data_error(dev, nand_chunk);
+	}
+
+	if (ecc_result1 < 0 || ecc_result2 < 0)
+		*ecc_result = YAFFS_ECC_RESULT_UNFIXED;
+	else if (ecc_result1 > 0 || ecc_result2 > 0)
+		*ecc_result = YAFFS_ECC_RESULT_FIXED;
+	else
+		*ecc_result = YAFFS_ECC_RESULT_NO_ERROR;
+
+	return ret_val;
+}
+
+/*
+ * Functions for robustisizing
+ */
+
+static void yaffs_handle_rd_data_error(struct yaffs_dev *dev, int nand_chunk)
+{
+	int flash_block = nand_chunk / dev->param.chunks_per_block;
+
+	/* Mark the block for retirement */
+	yaffs_get_block_info(dev, flash_block + dev->block_offset)->
+		needs_retiring = 1;
+	yaffs_trace(YAFFS_TRACE_ERROR | YAFFS_TRACE_BAD_BLOCKS,
+		"**>>Block %d marked for retirement",
+		flash_block);
+
+	/* TODO:
+	 * Just do a garbage collection on the affected block
+	 * then retire the block
+	 * NB recursion
+	 */
+}
+
+static int yaffs_tags_compat_wr(struct yaffs_dev *dev,
+			 int nand_chunk,
+			 const u8 *data, const struct yaffs_ext_tags *ext_tags)
+{
+	struct yaffs_spare spare;
+	struct yaffs_tags tags;
+
+	yaffs_spare_init(&spare);
+
+	if (ext_tags->is_deleted)
+		spare.page_status = 0;
+	else {
+		tags.obj_id = ext_tags->obj_id;
+		tags.chunk_id = ext_tags->chunk_id;
+
+		tags.n_bytes_lsb = ext_tags->n_bytes & (1024 - 1);
+
+		if (dev->data_bytes_per_chunk >= 1024)
+			tags.n_bytes_msb = (ext_tags->n_bytes >> 10) & 3;
+		else
+			tags.n_bytes_msb = 3;
+
+		tags.serial_number = ext_tags->serial_number;
+
+		if (!dev->param.use_nand_ecc && data) {
+			yaffs_ecc_calc(data, spare.ecc1);
+			yaffs_ecc_calc(&data[256], spare.ecc2);
+		}
+
+		yaffs_load_tags_to_spare(dev, &spare, &tags);
+	}
+	return yaffs_wr_nand(dev, nand_chunk, data, &spare);
+}
+
+static int yaffs_tags_compat_rd(struct yaffs_dev *dev,
+			 int nand_chunk,
+			 u8 *data, struct yaffs_ext_tags *ext_tags)
+{
+	struct yaffs_spare spare;
+	struct yaffs_tags tags;
+	enum yaffs_ecc_result ecc_result = YAFFS_ECC_RESULT_UNKNOWN;
+	static struct yaffs_spare spare_ff;
+	static int init;
+	int deleted;
+
+	if (!init) {
+		memset(&spare_ff, 0xff, sizeof(spare_ff));
+		init = 1;
+	}
+
+	if (!yaffs_rd_chunk_nand(dev, nand_chunk,
+					data, &spare, &ecc_result, 1))
+		return YAFFS_FAIL;
+
+	/* ext_tags may be NULL */
+	if (!ext_tags)
+		return YAFFS_OK;
+
+	deleted = (hweight8(spare.page_status) < 7) ? 1 : 0;
+
+	ext_tags->is_deleted = deleted;
+	ext_tags->ecc_result = ecc_result;
+	ext_tags->block_bad = 0;	/* We're reading it */
+	/* therefore it is not a bad block */
+	ext_tags->chunk_used =
+		memcmp(&spare_ff, &spare, sizeof(spare_ff)) ? 1 : 0;
+
+	if (ext_tags->chunk_used) {
+		yaffs_get_tags_from_spare(dev, &spare, &tags);
+
+		ext_tags->obj_id = tags.obj_id;
+		ext_tags->chunk_id = tags.chunk_id;
+		ext_tags->n_bytes = tags.n_bytes_lsb;
+
+		if (dev->data_bytes_per_chunk >= 1024)
+			ext_tags->n_bytes |=
+				(((unsigned)tags.n_bytes_msb) << 10);
+
+		ext_tags->serial_number = tags.serial_number;
+	}
+
+	return YAFFS_OK;
+}
+
+static int yaffs_tags_compat_mark_bad(struct yaffs_dev *dev, int flash_block)
+{
+	struct yaffs_spare spare;
+
+	memset(&spare, 0xff, sizeof(struct yaffs_spare));
+
+	spare.block_status = 'Y';
+
+	yaffs_wr_nand(dev, flash_block * dev->param.chunks_per_block, NULL,
+		      &spare);
+	yaffs_wr_nand(dev, flash_block * dev->param.chunks_per_block + 1,
+		      NULL, &spare);
+
+	return YAFFS_OK;
+}
+
+static int yaffs_tags_compat_query_block(struct yaffs_dev *dev,
+				  int block_no,
+				  enum yaffs_block_state *state,
+				  u32 *seq_number)
+{
+	struct yaffs_spare spare0, spare1;
+	static struct yaffs_spare spare_ff;
+	static int init;
+	enum yaffs_ecc_result dummy;
+
+	if (!init) {
+		memset(&spare_ff, 0xff, sizeof(spare_ff));
+		init = 1;
+	}
+
+	*seq_number = 0;
+
+	/* Look for bad block markers in the first two chunks */
+	yaffs_rd_chunk_nand(dev, block_no * dev->param.chunks_per_block,
+			    NULL, &spare0, &dummy, 0);
+	yaffs_rd_chunk_nand(dev, block_no * dev->param.chunks_per_block + 1,
+			    NULL, &spare1, &dummy, 0);
+
+	if (hweight8(spare0.block_status & spare1.block_status) < 7)
+		*state = YAFFS_BLOCK_STATE_DEAD;
+	else if (memcmp(&spare_ff, &spare0, sizeof(spare_ff)) == 0)
+		*state = YAFFS_BLOCK_STATE_EMPTY;
+	else
+		*state = YAFFS_BLOCK_STATE_NEEDS_SCAN;
+
+	return YAFFS_OK;
+}
+
+void yaffs_tags_compat_install(struct yaffs_dev *dev)
+{
+	if(dev->param.is_yaffs2)
+		return;
+	if(!dev->tagger.write_chunk_tags_fn)
+		dev->tagger.write_chunk_tags_fn = yaffs_tags_compat_wr;
+	if(!dev->tagger.read_chunk_tags_fn)
+		dev->tagger.read_chunk_tags_fn = yaffs_tags_compat_rd;
+	if(!dev->tagger.query_block_fn)
+		dev->tagger.query_block_fn = yaffs_tags_compat_query_block;
+	if(!dev->tagger.mark_bad_fn)
+		dev->tagger.mark_bad_fn = yaffs_tags_compat_mark_bad;
+}
diff --git a/fs/yaffs2/yaffs_tagscompat.h b/fs/yaffs2/yaffs_tagscompat.h
new file mode 100644
index 0000000..92d298a
--- /dev/null
+++ b/fs/yaffs2/yaffs_tagscompat.h
@@ -0,0 +1,44 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_TAGSCOMPAT_H__
+#define __YAFFS_TAGSCOMPAT_H__
+
+
+#include "yaffs_guts.h"
+
+#if 0
+
+
+int yaffs_tags_compat_wr(struct yaffs_dev *dev,
+			 int nand_chunk,
+			 const u8 *data, const struct yaffs_ext_tags *tags);
+int yaffs_tags_compat_rd(struct yaffs_dev *dev,
+			 int nand_chunk,
+			 u8 *data, struct yaffs_ext_tags *tags);
+int yaffs_tags_compat_mark_bad(struct yaffs_dev *dev, int block_no);
+int yaffs_tags_compat_query_block(struct yaffs_dev *dev,
+				  int block_no,
+				  enum yaffs_block_state *state,
+				  u32 *seq_number);
+
+#endif
+
+
+void yaffs_tags_compat_install(struct yaffs_dev *dev);
+void yaffs_calc_tags_ecc(struct yaffs_tags *tags);
+int yaffs_check_tags_ecc(struct yaffs_tags *tags);
+
+#endif
diff --git a/fs/yaffs2/yaffs_tagsmarshall.c b/fs/yaffs2/yaffs_tagsmarshall.c
new file mode 100644
index 0000000..4a120d8
--- /dev/null
+++ b/fs/yaffs2/yaffs_tagsmarshall.c
@@ -0,0 +1,206 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This file handles the marshalling (ie internal<-->external structure
+ * translation between the internal tags and the stored tags in Yaffs2-style
+ * tags storage.
+ */
+
+#include "yaffs_guts.h"
+#include "yaffs_trace.h"
+#include "yaffs_packedtags2.h"
+
+static int yaffs_tags_marshall_write(struct yaffs_dev *dev,
+				    int nand_chunk, const u8 *data,
+				    const struct yaffs_ext_tags *tags)
+{
+	struct yaffs_packed_tags2 pt;
+	int retval;
+
+	int packed_tags_size =
+	    dev->param.no_tags_ecc ? sizeof(pt.t) : sizeof(pt);
+	void *packed_tags_ptr =
+	    dev->param.no_tags_ecc ? (void *)&pt.t : (void *)&pt;
+
+	yaffs_trace(YAFFS_TRACE_MTD,
+		"yaffs_tags_marshall_write chunk %d data %p tags %p",
+		nand_chunk, data, tags);
+
+	/* For yaffs2 writing there must be both data and tags.
+	 * If we're using inband tags, then the tags are stuffed into
+	 * the end of the data buffer.
+	 */
+	if (!data || !tags)
+		BUG();
+	else if (dev->param.inband_tags) {
+		struct yaffs_packed_tags2_tags_only *pt2tp;
+		pt2tp =
+		    (struct yaffs_packed_tags2_tags_only *)(data +
+							dev->
+							data_bytes_per_chunk);
+		yaffs_pack_tags2_tags_only(dev, pt2tp, tags);
+	} else {
+		yaffs_pack_tags2(dev, &pt, tags, !dev->param.no_tags_ecc);
+	}
+
+	retval = dev->drv.drv_write_chunk_fn(dev, nand_chunk,
+			data, dev->param.total_bytes_per_chunk,
+			(dev->param.inband_tags) ? NULL : packed_tags_ptr,
+			(dev->param.inband_tags) ? 0 : packed_tags_size);
+
+	return retval;
+}
+
+static int yaffs_tags_marshall_read(struct yaffs_dev *dev,
+				   int nand_chunk, u8 *data,
+				   struct yaffs_ext_tags *tags)
+{
+	int retval = 0;
+	int local_data = 0;
+	u8 spare_buffer[100];
+	enum yaffs_ecc_result ecc_result;
+
+	struct yaffs_packed_tags2 pt;
+
+	int packed_tags_size =
+	    dev->param.no_tags_ecc ? sizeof(pt.t) : sizeof(pt);
+	void *packed_tags_ptr =
+	    dev->param.no_tags_ecc ? (void *)&pt.t : (void *)&pt;
+
+	yaffs_trace(YAFFS_TRACE_MTD,
+		"yaffs_tags_marshall_read chunk %d data %p tags %p",
+		nand_chunk, data, tags);
+
+	if (dev->param.inband_tags) {
+		if (!data) {
+			local_data = 1;
+			data = yaffs_get_temp_buffer(dev);
+		}
+	}
+
+	if (dev->param.inband_tags || (data && !tags))
+		retval = dev->drv.drv_read_chunk_fn(dev, nand_chunk,
+					data, dev->param.total_bytes_per_chunk,
+					NULL, 0,
+					&ecc_result);
+	else if (tags)
+		retval = dev->drv.drv_read_chunk_fn(dev, nand_chunk,
+					data, dev->param.total_bytes_per_chunk,
+					spare_buffer, packed_tags_size,
+					&ecc_result);
+	else
+		BUG();
+
+
+	if (retval == YAFFS_FAIL)
+		return YAFFS_FAIL;
+
+	if (dev->param.inband_tags) {
+		if (tags) {
+			struct yaffs_packed_tags2_tags_only *pt2tp;
+			pt2tp =
+				(struct yaffs_packed_tags2_tags_only *)
+				&data[dev->data_bytes_per_chunk];
+			yaffs_unpack_tags2_tags_only(dev, tags, pt2tp);
+		}
+	} else if (tags) {
+		memcpy(packed_tags_ptr, spare_buffer, packed_tags_size);
+		yaffs_unpack_tags2(dev, tags, &pt, !dev->param.no_tags_ecc);
+	}
+
+	if (local_data)
+		yaffs_release_temp_buffer(dev, data);
+
+	if (tags && ecc_result == YAFFS_ECC_RESULT_UNFIXED) {
+		tags->ecc_result = YAFFS_ECC_RESULT_UNFIXED;
+		dev->n_ecc_unfixed++;
+	}
+
+	if (tags && ecc_result == YAFFS_ECC_RESULT_FIXED) {
+		if (tags->ecc_result <= YAFFS_ECC_RESULT_NO_ERROR)
+			tags->ecc_result = YAFFS_ECC_RESULT_FIXED;
+		dev->n_ecc_fixed++;
+	}
+
+	if (ecc_result < YAFFS_ECC_RESULT_UNFIXED)
+		return YAFFS_OK;
+	else
+		return YAFFS_FAIL;
+}
+
+static int yaffs_tags_marshall_query_block(struct yaffs_dev *dev, int block_no,
+			       enum yaffs_block_state *state,
+			       u32 *seq_number)
+{
+	int retval;
+
+	yaffs_trace(YAFFS_TRACE_MTD, "yaffs_tags_marshall_query_block %d",
+			block_no);
+
+	retval = dev->drv.drv_check_bad_fn(dev, block_no);
+
+	if (retval== YAFFS_FAIL) {
+		yaffs_trace(YAFFS_TRACE_MTD, "block is bad");
+
+		*state = YAFFS_BLOCK_STATE_DEAD;
+		*seq_number = 0;
+	} else {
+		struct yaffs_ext_tags t;
+
+		yaffs_tags_marshall_read(dev,
+				    block_no * dev->param.chunks_per_block,
+				    NULL, &t);
+
+		if (t.chunk_used) {
+			*seq_number = t.seq_number;
+			*state = YAFFS_BLOCK_STATE_NEEDS_SCAN;
+		} else {
+			*seq_number = 0;
+			*state = YAFFS_BLOCK_STATE_EMPTY;
+		}
+	}
+
+	yaffs_trace(YAFFS_TRACE_MTD,
+		"block query returns  seq %d state %d",
+		*seq_number, *state);
+
+	if (retval == 0)
+		return YAFFS_OK;
+	else
+		return YAFFS_FAIL;
+}
+
+static int yaffs_tags_marshall_mark_bad(struct yaffs_dev *dev, int block_no)
+{
+	return dev->drv.drv_mark_bad_fn(dev, block_no);
+
+}
+
+
+void yaffs_tags_marshall_install(struct yaffs_dev *dev)
+{
+	if (!dev->param.is_yaffs2)
+		return;
+
+	if (!dev->tagger.write_chunk_tags_fn)
+		dev->tagger.write_chunk_tags_fn = yaffs_tags_marshall_write;
+
+	if (!dev->tagger.read_chunk_tags_fn)
+		dev->tagger.read_chunk_tags_fn = yaffs_tags_marshall_read;
+
+	if (!dev->tagger.query_block_fn)
+		dev->tagger.query_block_fn = yaffs_tags_marshall_query_block;
+
+	if (!dev->tagger.mark_bad_fn)
+		dev->tagger.mark_bad_fn = yaffs_tags_marshall_mark_bad;
+
+}
diff --git a/fs/yaffs2/yaffs_tagsmarshall.h b/fs/yaffs2/yaffs_tagsmarshall.h
new file mode 100644
index 0000000..bf3e68a
--- /dev/null
+++ b/fs/yaffs2/yaffs_tagsmarshall.h
@@ -0,0 +1,22 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_TAGSMARSHALL_H__
+#define __YAFFS_TAGSMARSHALL_H__
+
+#include "yaffs_guts.h"
+void yaffs_tags_marshall_install(struct yaffs_dev *dev);
+
+#endif
diff --git a/fs/yaffs2/yaffs_trace.h b/fs/yaffs2/yaffs_trace.h
new file mode 100644
index 0000000..fd26054
--- /dev/null
+++ b/fs/yaffs2/yaffs_trace.h
@@ -0,0 +1,57 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YTRACE_H__
+#define __YTRACE_H__
+
+extern unsigned int yaffs_trace_mask;
+extern unsigned int yaffs_wr_attempts;
+
+/*
+ * Tracing flags.
+ * The flags masked in YAFFS_TRACE_ALWAYS are always traced.
+ */
+
+#define YAFFS_TRACE_OS			0x00000002
+#define YAFFS_TRACE_ALLOCATE		0x00000004
+#define YAFFS_TRACE_SCAN		0x00000008
+#define YAFFS_TRACE_BAD_BLOCKS		0x00000010
+#define YAFFS_TRACE_ERASE		0x00000020
+#define YAFFS_TRACE_GC			0x00000040
+#define YAFFS_TRACE_WRITE		0x00000080
+#define YAFFS_TRACE_TRACING		0x00000100
+#define YAFFS_TRACE_DELETION		0x00000200
+#define YAFFS_TRACE_BUFFERS		0x00000400
+#define YAFFS_TRACE_NANDACCESS		0x00000800
+#define YAFFS_TRACE_GC_DETAIL		0x00001000
+#define YAFFS_TRACE_SCAN_DEBUG		0x00002000
+#define YAFFS_TRACE_MTD			0x00004000
+#define YAFFS_TRACE_CHECKPOINT		0x00008000
+
+#define YAFFS_TRACE_VERIFY		0x00010000
+#define YAFFS_TRACE_VERIFY_NAND		0x00020000
+#define YAFFS_TRACE_VERIFY_FULL		0x00040000
+#define YAFFS_TRACE_VERIFY_ALL		0x000f0000
+
+#define YAFFS_TRACE_SYNC		0x00100000
+#define YAFFS_TRACE_BACKGROUND		0x00200000
+#define YAFFS_TRACE_LOCK		0x00400000
+#define YAFFS_TRACE_MOUNT		0x00800000
+
+#define YAFFS_TRACE_ERROR		0x40000000
+#define YAFFS_TRACE_BUG			0x80000000
+#define YAFFS_TRACE_ALWAYS		0xf0000000
+
+#endif
diff --git a/fs/yaffs2/yaffs_verify.c b/fs/yaffs2/yaffs_verify.c
new file mode 100644
index 0000000..7a341a2
--- /dev/null
+++ b/fs/yaffs2/yaffs_verify.c
@@ -0,0 +1,540 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include "yaffs_verify.h"
+#include "yaffs_trace.h"
+#include "yaffs_bitmap.h"
+#include "yaffs_getblockinfo.h"
+#include "yaffs_nand.h"
+
+int yaffs_skip_verification(struct yaffs_dev *dev)
+{
+	(void) dev;
+	return !(yaffs_trace_mask &
+		 (YAFFS_TRACE_VERIFY | YAFFS_TRACE_VERIFY_FULL));
+}
+
+static int yaffs_skip_full_verification(struct yaffs_dev *dev)
+{
+	(void) dev;
+	return !(yaffs_trace_mask & (YAFFS_TRACE_VERIFY_FULL));
+}
+
+static int yaffs_skip_nand_verification(struct yaffs_dev *dev)
+{
+	(void) dev;
+	return !(yaffs_trace_mask & (YAFFS_TRACE_VERIFY_NAND));
+}
+
+static const char * const block_state_name[] = {
+	"Unknown",
+	"Needs scan",
+	"Scanning",
+	"Empty",
+	"Allocating",
+	"Full",
+	"Dirty",
+	"Checkpoint",
+	"Collecting",
+	"Dead"
+};
+
+void yaffs_verify_blk(struct yaffs_dev *dev, struct yaffs_block_info *bi, int n)
+{
+	int actually_used;
+	int in_use;
+
+	if (yaffs_skip_verification(dev))
+		return;
+
+	/* Report illegal runtime states */
+	if (bi->block_state >= YAFFS_NUMBER_OF_BLOCK_STATES)
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Block %d has undefined state %d",
+			n, bi->block_state);
+
+	switch (bi->block_state) {
+	case YAFFS_BLOCK_STATE_UNKNOWN:
+	case YAFFS_BLOCK_STATE_SCANNING:
+	case YAFFS_BLOCK_STATE_NEEDS_SCAN:
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Block %d has bad run-state %s",
+			n, block_state_name[bi->block_state]);
+	}
+
+	/* Check pages in use and soft deletions are legal */
+
+	actually_used = bi->pages_in_use - bi->soft_del_pages;
+
+	if (bi->pages_in_use < 0 ||
+	    bi->pages_in_use > (int)dev->param.chunks_per_block ||
+	    bi->soft_del_pages < 0 ||
+	    bi->soft_del_pages > (int)dev->param.chunks_per_block ||
+	    actually_used < 0 || actually_used > (int)dev->param.chunks_per_block)
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Block %d has illegal values pages_in_used %d soft_del_pages %d",
+			n, bi->pages_in_use, bi->soft_del_pages);
+
+	/* Check chunk bitmap legal */
+	in_use = yaffs_count_chunk_bits(dev, n);
+	if (in_use != bi->pages_in_use)
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Block %d has inconsistent values pages_in_use %d counted chunk bits %d",
+			n, bi->pages_in_use, in_use);
+}
+
+void yaffs_verify_collected_blk(struct yaffs_dev *dev,
+				struct yaffs_block_info *bi, int n)
+{
+	yaffs_verify_blk(dev, bi, n);
+
+	/* After collection the block should be in the erased state */
+
+	if (bi->block_state != YAFFS_BLOCK_STATE_COLLECTING &&
+	    bi->block_state != YAFFS_BLOCK_STATE_EMPTY) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"Block %d is in state %d after gc, should be erased",
+			n, bi->block_state);
+	}
+}
+
+void yaffs_verify_blocks(struct yaffs_dev *dev)
+{
+	u32 i;
+	u32 state_count[YAFFS_NUMBER_OF_BLOCK_STATES];
+	int illegal_states = 0;
+
+	if (yaffs_skip_verification(dev))
+		return;
+
+	memset(state_count, 0, sizeof(state_count));
+
+	for (i = dev->internal_start_block; i <= dev->internal_end_block; i++) {
+		struct yaffs_block_info *bi = yaffs_get_block_info(dev, i);
+		yaffs_verify_blk(dev, bi, i);
+
+		if (bi->block_state < YAFFS_NUMBER_OF_BLOCK_STATES)
+			state_count[bi->block_state]++;
+		else
+			illegal_states++;
+	}
+
+	yaffs_trace(YAFFS_TRACE_VERIFY,	"Block summary");
+
+	yaffs_trace(YAFFS_TRACE_VERIFY,
+		"%d blocks have illegal states",
+		illegal_states);
+	if (state_count[YAFFS_BLOCK_STATE_ALLOCATING] > 1)
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Too many allocating blocks");
+
+	for (i = 0; i < YAFFS_NUMBER_OF_BLOCK_STATES; i++)
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"%s %d blocks",
+			block_state_name[i], state_count[i]);
+
+	if (dev->blocks_in_checkpt != state_count[YAFFS_BLOCK_STATE_CHECKPOINT])
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Checkpoint block count wrong dev %d count %d",
+			dev->blocks_in_checkpt,
+			state_count[YAFFS_BLOCK_STATE_CHECKPOINT]);
+
+	if (dev->n_erased_blocks != (int)state_count[YAFFS_BLOCK_STATE_EMPTY])
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Erased block count wrong dev %d count %d",
+			dev->n_erased_blocks,
+			state_count[YAFFS_BLOCK_STATE_EMPTY]);
+
+	if (state_count[YAFFS_BLOCK_STATE_COLLECTING] > 1)
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Too many collecting blocks %d (max is 1)",
+			state_count[YAFFS_BLOCK_STATE_COLLECTING]);
+}
+
+/*
+ * Verify the object header. oh must be valid, but obj and tags may be NULL in
+ * which case those tests will not be performed.
+ */
+void yaffs_verify_oh(struct yaffs_obj *obj, struct yaffs_obj_hdr *oh,
+		     struct yaffs_ext_tags *tags, int parent_check)
+{
+	if (obj && yaffs_skip_verification(obj->my_dev))
+		return;
+
+	if (!(tags && obj && oh)) {
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Verifying object header tags %p obj %p oh %p",
+			tags, obj, oh);
+		return;
+	}
+
+	if (oh->type <= YAFFS_OBJECT_TYPE_UNKNOWN ||
+	    oh->type > YAFFS_OBJECT_TYPE_MAX)
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Obj %d header type is illegal value 0x%x",
+			tags->obj_id, oh->type);
+
+	if (tags->obj_id != obj->obj_id)
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Obj %d header mismatch obj_id %d",
+			tags->obj_id, obj->obj_id);
+
+	/*
+	 * Check that the object's parent ids match if parent_check requested.
+	 *
+	 * Tests do not apply to the root object.
+	 */
+
+	if (parent_check && tags->obj_id > 1 && !obj->parent)
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Obj %d header mismatch parent_id %d obj->parent is NULL",
+			tags->obj_id, oh->parent_obj_id);
+
+	if (parent_check && obj->parent &&
+	    oh->parent_obj_id !=  obj->parent->obj_id &&
+	    (oh->parent_obj_id != YAFFS_OBJECTID_UNLINKED ||
+	     obj->parent->obj_id != YAFFS_OBJECTID_DELETED))
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Obj %d header mismatch parent_id %d parent_obj_id %d",
+			tags->obj_id, oh->parent_obj_id,
+			obj->parent->obj_id);
+
+	if (tags->obj_id > 1 && oh->name[0] == 0)	/* Null name */
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Obj %d header name is NULL",
+			obj->obj_id);
+
+	if (tags->obj_id > 1 && ((u8) (oh->name[0])) == 0xff)	/* Junk name */
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Obj %d header name is 0xff",
+			obj->obj_id);
+}
+
+void yaffs_verify_file(struct yaffs_obj *obj)
+{
+	u32 x;
+	int required_depth;
+	int last_chunk;
+	u32 offset_in_chunk;
+	u32 the_chunk;
+
+	int i;
+	struct yaffs_dev *dev;
+	struct yaffs_ext_tags tags;
+	struct yaffs_tnode *tn;
+	u32 obj_id;
+
+	if (!obj)
+		return;
+
+	if (yaffs_skip_verification(obj->my_dev))
+		return;
+
+	dev = obj->my_dev;
+	obj_id = obj->obj_id;
+
+
+	/* Check file size is consistent with tnode depth */
+	yaffs_addr_to_chunk(dev, obj->variant.file_variant.file_size,
+				&last_chunk, &offset_in_chunk);
+	last_chunk++;
+	x = last_chunk >> YAFFS_TNODES_LEVEL0_BITS;
+	required_depth = 0;
+	while (x > 0) {
+		x >>= YAFFS_TNODES_INTERNAL_BITS;
+		required_depth++;
+	}
+
+	/* Check that the chunks in the tnode tree are all correct.
+	 * We do this by scanning through the tnode tree and
+	 * checking the tags for every chunk match.
+	 */
+
+	if (yaffs_skip_nand_verification(dev))
+		return;
+
+	for (i = 1; i <= last_chunk; i++) {
+		tn = yaffs_find_tnode_0(dev, &obj->variant.file_variant, i);
+
+		if (!tn)
+			continue;
+
+		the_chunk = yaffs_get_group_base(dev, tn, i);
+		if (the_chunk > 0) {
+			yaffs_rd_chunk_tags_nand(dev, the_chunk, NULL,
+						 &tags);
+			if (tags.obj_id != obj_id || tags.chunk_id != (u32)i)
+				yaffs_trace(YAFFS_TRACE_VERIFY,
+					"Object %d chunk_id %d NAND mismatch chunk %d tags (%d:%d)",
+					obj_id, i, the_chunk,
+					tags.obj_id, tags.chunk_id);
+		}
+	}
+}
+
+void yaffs_verify_link(struct yaffs_obj *obj)
+{
+	if (obj && yaffs_skip_verification(obj->my_dev))
+		return;
+
+	/* Verify sane equivalent object */
+}
+
+void yaffs_verify_symlink(struct yaffs_obj *obj)
+{
+	if (obj && yaffs_skip_verification(obj->my_dev))
+		return;
+
+	/* Verify symlink string */
+}
+
+void yaffs_verify_special(struct yaffs_obj *obj)
+{
+	if (obj && yaffs_skip_verification(obj->my_dev))
+		return;
+}
+
+void yaffs_verify_obj(struct yaffs_obj *obj)
+{
+	struct yaffs_dev *dev;
+	u32 chunk_min;
+	u32 chunk_max;
+	u32 chunk_id_ok;
+	u32 chunk_in_range;
+	u32 chunk_wrongly_deleted;
+	u32 chunk_valid;
+
+	if (!obj)
+		return;
+
+	if (obj->being_created)
+		return;
+
+	dev = obj->my_dev;
+
+	if (yaffs_skip_verification(dev))
+		return;
+
+	/* Check sane object header chunk */
+
+	chunk_min = dev->internal_start_block * dev->param.chunks_per_block;
+	chunk_max =
+	    (dev->internal_end_block + 1) * dev->param.chunks_per_block - 1;
+
+	chunk_in_range = (((unsigned)(obj->hdr_chunk)) >= chunk_min &&
+			  ((unsigned)(obj->hdr_chunk)) <= chunk_max);
+	chunk_id_ok = chunk_in_range || (obj->hdr_chunk == 0);
+	chunk_valid = chunk_in_range &&
+	    yaffs_check_chunk_bit(dev,
+				  obj->hdr_chunk / dev->param.chunks_per_block,
+				  obj->hdr_chunk % dev->param.chunks_per_block);
+	chunk_wrongly_deleted = chunk_in_range && !chunk_valid;
+
+	if (!obj->fake && (!chunk_id_ok || chunk_wrongly_deleted))
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Obj %d has chunk_id %d %s %s",
+			obj->obj_id, obj->hdr_chunk,
+			chunk_id_ok ? "" : ",out of range",
+			chunk_wrongly_deleted ? ",marked as deleted" : "");
+
+	if (chunk_valid && !yaffs_skip_nand_verification(dev)) {
+		struct yaffs_ext_tags tags;
+		struct yaffs_obj_hdr *oh;
+		u8 *buffer = yaffs_get_temp_buffer(dev);
+
+		oh = (struct yaffs_obj_hdr *)buffer;
+
+		yaffs_rd_chunk_tags_nand(dev, obj->hdr_chunk, buffer, &tags);
+
+		yaffs_verify_oh(obj, oh, &tags, 1);
+
+		yaffs_release_temp_buffer(dev, buffer);
+	}
+
+	/* Verify it has a parent */
+	if (obj && !obj->fake && (!obj->parent || obj->parent->my_dev != dev)) {
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Obj %d has parent pointer %p which does not look like an object",
+			obj->obj_id, obj->parent);
+	}
+
+	/* Verify parent is a directory */
+	if (obj->parent &&
+	    obj->parent->variant_type != YAFFS_OBJECT_TYPE_DIRECTORY) {
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Obj %d's parent is not a directory (type %d)",
+			obj->obj_id, obj->parent->variant_type);
+	}
+
+	switch (obj->variant_type) {
+	case YAFFS_OBJECT_TYPE_FILE:
+		yaffs_verify_file(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_SYMLINK:
+		yaffs_verify_symlink(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_DIRECTORY:
+		yaffs_verify_dir(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_HARDLINK:
+		yaffs_verify_link(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_SPECIAL:
+		yaffs_verify_special(obj);
+		break;
+	case YAFFS_OBJECT_TYPE_UNKNOWN:
+	default:
+		yaffs_trace(YAFFS_TRACE_VERIFY,
+			"Obj %d has illegaltype %d",
+		   obj->obj_id, obj->variant_type);
+		break;
+	}
+}
+
+void yaffs_verify_objects(struct yaffs_dev *dev)
+{
+	struct yaffs_obj *obj;
+	int i;
+	struct list_head *lh;
+
+	if (yaffs_skip_verification(dev))
+		return;
+
+	/* Iterate through the objects in each hash entry */
+
+	for (i = 0; i < YAFFS_NOBJECT_BUCKETS; i++) {
+		list_for_each(lh, &dev->obj_bucket[i].list) {
+			obj = list_entry(lh, struct yaffs_obj, hash_link);
+			yaffs_verify_obj(obj);
+		}
+	}
+}
+
+void yaffs_verify_obj_in_dir(struct yaffs_obj *obj)
+{
+	struct list_head *lh;
+	struct yaffs_obj *list_obj;
+	int count = 0;
+
+	if (!obj) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS, "No object to verify");
+		BUG();
+		return;
+	}
+
+	if (yaffs_skip_verification(obj->my_dev))
+		return;
+
+	if (!obj->parent) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS, "Object does not have parent");
+		BUG();
+		return;
+	}
+
+	if (obj->parent->variant_type != YAFFS_OBJECT_TYPE_DIRECTORY) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS, "Parent is not directory");
+		BUG();
+	}
+
+	/* Iterate through the objects in each hash entry */
+
+	list_for_each(lh, &obj->parent->variant.dir_variant.children) {
+		list_obj = list_entry(lh, struct yaffs_obj, siblings);
+		yaffs_verify_obj(list_obj);
+		if (obj == list_obj)
+			count++;
+	}
+
+	if (count != 1) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"Object in directory %d times",
+			count);
+		BUG();
+	}
+}
+
+void yaffs_verify_dir(struct yaffs_obj *directory)
+{
+	struct list_head *lh;
+	struct yaffs_obj *list_obj;
+	struct yaffs_dev *dev;
+
+	if (!directory) {
+		BUG();
+		return;
+	}
+
+	dev = directory->my_dev;
+
+	if (!dev) {
+		BUG();
+		return;
+	}
+
+	if (directory == dev->root_dir ||
+	    directory == dev->lost_n_found ||
+	    directory == dev->unlinked_dir ||
+	    directory == dev->del_dir)
+		return;
+
+	if (yaffs_skip_full_verification(directory->my_dev))
+		return;
+
+	if (directory->variant_type != YAFFS_OBJECT_TYPE_DIRECTORY) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"Directory has wrong type: %d",
+			directory->variant_type);
+		BUG();
+	}
+
+	/* Iterate through the objects in each hash entry */
+
+	list_for_each(lh, &directory->variant.dir_variant.children) {
+		list_obj = list_entry(lh, struct yaffs_obj, siblings);
+		if (list_obj->parent != directory) {
+			yaffs_trace(YAFFS_TRACE_ALWAYS,
+				"Object in directory list has wrong parent %p",
+				list_obj->parent);
+			BUG();
+		}
+		yaffs_verify_obj_in_dir(list_obj);
+	}
+}
+
+static int yaffs_free_verification_failures;
+
+void yaffs_verify_free_chunks(struct yaffs_dev *dev)
+{
+	int counted;
+	int difference;
+
+	if (yaffs_skip_verification(dev))
+		return;
+
+	counted = yaffs_count_free_chunks(dev);
+
+	difference = dev->n_free_chunks - counted;
+
+	if (difference) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"Freechunks verification failure %d %d %d",
+			dev->n_free_chunks, counted, difference);
+		yaffs_free_verification_failures++;
+	}
+}
+
+int yaffs_verify_file_sane(struct yaffs_obj *in)
+{
+	(void) in;
+	return YAFFS_OK;
+}
diff --git a/fs/yaffs2/yaffs_verify.h b/fs/yaffs2/yaffs_verify.h
new file mode 100644
index 0000000..4f4af8d
--- /dev/null
+++ b/fs/yaffs2/yaffs_verify.h
@@ -0,0 +1,43 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_VERIFY_H__
+#define __YAFFS_VERIFY_H__
+
+#include "yaffs_guts.h"
+
+void yaffs_verify_blk(struct yaffs_dev *dev, struct yaffs_block_info *bi,
+		      int n);
+void yaffs_verify_collected_blk(struct yaffs_dev *dev,
+				struct yaffs_block_info *bi, int n);
+void yaffs_verify_blocks(struct yaffs_dev *dev);
+
+void yaffs_verify_oh(struct yaffs_obj *obj, struct yaffs_obj_hdr *oh,
+		     struct yaffs_ext_tags *tags, int parent_check);
+void yaffs_verify_file(struct yaffs_obj *obj);
+void yaffs_verify_link(struct yaffs_obj *obj);
+void yaffs_verify_symlink(struct yaffs_obj *obj);
+void yaffs_verify_special(struct yaffs_obj *obj);
+void yaffs_verify_obj(struct yaffs_obj *obj);
+void yaffs_verify_objects(struct yaffs_dev *dev);
+void yaffs_verify_obj_in_dir(struct yaffs_obj *obj);
+void yaffs_verify_dir(struct yaffs_obj *directory);
+void yaffs_verify_free_chunks(struct yaffs_dev *dev);
+
+int yaffs_verify_file_sane(struct yaffs_obj *obj);
+
+int yaffs_skip_verification(struct yaffs_dev *dev);
+
+#endif
diff --git a/fs/yaffs2/yaffs_vfs.c b/fs/yaffs2/yaffs_vfs.c
new file mode 100644
index 0000000..acb0c4a
--- /dev/null
+++ b/fs/yaffs2/yaffs_vfs.c
@@ -0,0 +1,3751 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ * Acknowledgements:
+ * Luc van OostenRyck for numerous patches.
+ * Nick Bane for numerous patches.
+ * Nick Bane for 2.5/2.6 integration.
+ * Andras Toth for mknod rdev issue.
+ * Michael Fischer for finding the problem with inode inconsistency.
+ * Some code bodily lifted from JFFS
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+/*
+ *
+ * This is the file system front-end to YAFFS that hooks it up to
+ * the VFS.
+ *
+ * Special notes:
+ * >> 2.4: sb->u.generic_sbp points to the struct yaffs_dev associated with
+ *         this superblock
+ * >> 2.6: sb->s_fs_info  points to the struct yaffs_dev associated with this
+ *         superblock
+ * >> inode->u.generic_ip points to the associated struct yaffs_obj.
+ */
+
+/*
+ * There are two variants of the VFS glue code. This variant should compile
+ * for any version of Linux.
+ */
+#include <linux/version.h>
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 10))
+#define YAFFS_COMPILE_BACKGROUND
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 23))
+#define YAFFS_COMPILE_FREEZER
+#endif
+#endif
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 28))
+#define YAFFS_COMPILE_EXPORTFS
+#endif
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 35))
+#define YAFFS_USE_SETATTR_COPY
+#define YAFFS_USE_TRUNCATE_SETSIZE
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 35))
+#define YAFFS_HAS_EVICT_INODE
+#endif
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 13)) && \
+    (LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0))
+#define YAFFS_NEW_FOLLOW_LINK 1
+#else
+#define YAFFS_NEW_FOLLOW_LINK 0
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 6, 0))
+#define YAFFS_HAS_WRITE_SUPER
+#endif
+
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19))
+#include <linux/config.h>
+#endif
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/fs.h>
+#include <linux/proc_fs.h>
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 39))
+#include <linux/smp_lock.h>
+#endif
+#include <linux/pagemap.h>
+#include <linux/mtd/mtd.h>
+#include <linux/interrupt.h>
+#include <linux/string.h>
+#include <linux/ctype.h>
+
+#if (YAFFS_NEW_FOLLOW_LINK == 1)
+#include <linux/namei.h>
+#endif
+
+#ifdef YAFFS_COMPILE_EXPORTFS
+#include <linux/exportfs.h>
+#endif
+
+#ifdef YAFFS_COMPILE_BACKGROUND
+#include <linux/kthread.h>
+#include <linux/delay.h>
+#endif
+#ifdef YAFFS_COMPILE_FREEZER
+#include <linux/freezer.h>
+#endif
+
+#include <asm/div64.h>
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+
+#include <linux/statfs.h>
+
+#define UnlockPage(p) unlock_page(p)
+#define Page_Uptodate(page)	test_bit(PG_uptodate, &(page)->flags)
+
+/* FIXME: use sb->s_id instead ? */
+#define yaffs_devname(sb, buf)	bdevname(sb->s_bdev, buf)
+
+#else
+
+#include <linux/locks.h>
+#define	BDEVNAME_SIZE		0
+#define	yaffs_devname(sb, buf)	kdevname(sb->s_dev)
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 5, 0))
+/* added NCB 26/5/2006 for 2.4.25-vrs2-tcl1 kernel */
+#define __user
+#endif
+
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26))
+#define YPROC_ROOT  (&proc_root)
+#else
+#define YPROC_ROOT  NULL
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 26))
+#define Y_INIT_TIMER(a)	init_timer(a)
+#else
+#define Y_INIT_TIMER(a)	init_timer_on_stack(a)
+#endif
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 27))
+#define YAFFS_USE_WRITE_BEGIN_END 1
+#else
+#define YAFFS_USE_WRITE_BEGIN_END 0
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 6, 0))
+#define YAFFS_SUPER_HAS_DIRTY
+#endif
+
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 2, 0))
+#define set_nlink(inode, count)  do { (inode)->i_nlink = (count); } while(0)
+#endif
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 28))
+static uint32_t YCALCBLOCKS(uint64_t partition_size, uint32_t block_size)
+{
+	uint64_t result = partition_size;
+	do_div(result, block_size);
+	return (uint32_t) result;
+}
+#else
+#define YCALCBLOCKS(s, b) ((s)/(b))
+#endif
+
+#include <linux/uaccess.h>
+#include <linux/mtd/mtd.h>
+
+#include "yportenv.h"
+#include "yaffs_trace.h"
+#include "yaffs_guts.h"
+#include "yaffs_attribs.h"
+
+#include "yaffs_linux.h"
+
+#include "yaffs_mtdif.h"
+#include "yaffs_packedtags2.h"
+#include "yaffs_getblockinfo.h"
+
+unsigned int yaffs_trace_mask =
+		YAFFS_TRACE_BAD_BLOCKS |
+		YAFFS_TRACE_ALWAYS |
+		0;
+
+unsigned int yaffs_wr_attempts = YAFFS_WR_ATTEMPTS;
+unsigned int yaffs_auto_checkpoint = 1;
+unsigned int yaffs_gc_control = 1;
+unsigned int yaffs_bg_enable = 1;
+unsigned int yaffs_auto_select = 1;
+/* Module Parameters */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+module_param(yaffs_trace_mask, uint, 0644);
+module_param(yaffs_wr_attempts, uint, 0644);
+module_param(yaffs_auto_checkpoint, uint, 0644);
+module_param(yaffs_gc_control, uint, 0644);
+module_param(yaffs_bg_enable, uint, 0644);
+#else
+MODULE_PARM(yaffs_trace_mask, "i");
+MODULE_PARM(yaffs_wr_attempts, "i");
+MODULE_PARM(yaffs_auto_checkpoint, "i");
+MODULE_PARM(yaffs_gc_control, "i");
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 25))
+/* use iget and read_inode */
+#define Y_IGET(sb, inum) iget((sb), (inum))
+
+#else
+/* Call local equivalent */
+#define YAFFS_USE_OWN_IGET
+#define Y_IGET(sb, inum) yaffs_iget((sb), (inum))
+
+#endif
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 18))
+#define yaffs_inode_to_obj_lv(iptr) ((iptr)->i_private)
+#else
+#define yaffs_inode_to_obj_lv(iptr) ((iptr)->u.generic_ip)
+#endif
+
+#define yaffs_inode_to_obj(iptr) \
+	((struct yaffs_obj *)(yaffs_inode_to_obj_lv(iptr)))
+#define yaffs_dentry_to_obj(dptr) yaffs_inode_to_obj((dptr)->d_inode)
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+#define yaffs_super_to_dev(sb)	((struct yaffs_dev *)sb->s_fs_info)
+#else
+#define yaffs_super_to_dev(sb)	((struct yaffs_dev *)sb->u.generic_sbp)
+#endif
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 5, 0))
+#define Y_CLEAR_INODE(i) clear_inode(i)
+#else
+#define Y_CLEAR_INODE(i) end_writeback(i)
+#endif
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 12, 0))
+#define YAFFS_USE_DIR_ITERATE
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 9, 0))
+#define YAFFS_USE_XATTR
+#endif
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,12,0))
+#define YAFFS_NEW_PROCFS
+#include <linux/seq_file.h>
+#endif
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(4, 8, 0))
+#define PAGE_CACHE_SIZE PAGE_SIZE
+#define PAGE_CACHE_SHIFT PAGE_SHIFT
+#define Y_GET_DENTRY(f) ((f)->f_path.dentry)
+#define page_cache_release put_page
+#define YAFFS_NEW_XATTR 1
+#define YAFFS_NEW_GET_LINK 1
+#else
+#define Y_GET_DENTRY(f) ((f)->f_dentry)
+#define YAFFS_NEW_XATTR 0
+#define YAFFS_NEW_GET_LINK 0
+#endif
+
+#define update_dir_time(dir) do {\
+			(dir)->i_ctime = (dir)->i_mtime = CURRENT_TIME; \
+		} while (0)
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(4, 9, 0))
+static inline int setattr_prepare(struct dentry *dentry, struct iattr *attr)
+{
+	return inode_change_ok(dentry->d_inode, attr);
+}
+#endif
+
+static void yaffs_fill_inode_from_obj(struct inode *inode,
+				      struct yaffs_obj *obj);
+
+
+static void yaffs_gross_lock(struct yaffs_dev *dev)
+{
+	yaffs_trace(YAFFS_TRACE_LOCK, "yaffs locking %p", current);
+	mutex_lock(&(yaffs_dev_to_lc(dev)->gross_lock));
+	yaffs_trace(YAFFS_TRACE_LOCK, "yaffs locked %p", current);
+}
+
+static void yaffs_gross_unlock(struct yaffs_dev *dev)
+{
+	yaffs_trace(YAFFS_TRACE_LOCK, "yaffs unlocking %p", current);
+	mutex_unlock(&(yaffs_dev_to_lc(dev)->gross_lock));
+}
+
+
+static int yaffs_readpage_nolock(struct file *f, struct page *pg)
+{
+	/* Lifted from jffs2 */
+
+	struct yaffs_obj *obj;
+	unsigned char *pg_buf;
+	int ret;
+	loff_t pos = ((loff_t) pg->index) << PAGE_SHIFT;
+	struct yaffs_dev *dev;
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_readpage_nolock at %lld, size %08x",
+		(long long)pos,
+		(unsigned)PAGE_SIZE);
+
+	obj = yaffs_dentry_to_obj(Y_GET_DENTRY(f));
+
+	dev = obj->my_dev;
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+	BUG_ON(!PageLocked(pg));
+#else
+	if (!PageLocked(pg))
+		PAGE_BUG(pg);
+#endif
+
+	pg_buf = kmap(pg);
+	/* FIXME: Can kmap fail? */
+
+	yaffs_gross_lock(dev);
+
+	ret = yaffs_file_rd(obj, pg_buf, pos, PAGE_CACHE_SIZE);
+
+	yaffs_gross_unlock(dev);
+
+	if (ret >= 0)
+		ret = 0;
+
+	if (ret) {
+		ClearPageUptodate(pg);
+		SetPageError(pg);
+	} else {
+		SetPageUptodate(pg);
+		ClearPageError(pg);
+	}
+
+	flush_dcache_page(pg);
+	kunmap(pg);
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_readpage_nolock done");
+	return ret;
+}
+
+static int yaffs_readpage_unlock(struct file *f, struct page *pg)
+{
+	int ret = yaffs_readpage_nolock(f, pg);
+	UnlockPage(pg);
+	return ret;
+}
+
+static int yaffs_readpage(struct file *f, struct page *pg)
+{
+	int ret;
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_readpage");
+	ret = yaffs_readpage_unlock(f, pg);
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_readpage done");
+	return ret;
+}
+
+
+static void yaffs_set_super_dirty_val(struct yaffs_dev *dev, int val)
+{
+	struct yaffs_linux_context *lc = yaffs_dev_to_lc(dev);
+
+	if (lc)
+		lc->dirty = val;
+
+# ifdef YAFFS_SUPER_HAS_DIRTY
+	{
+		struct super_block *sb = lc->super;
+
+		if (sb)
+			sb->s_dirt = val;
+	}
+#endif
+
+}
+
+static void yaffs_set_super_dirty(struct yaffs_dev *dev)
+{
+	yaffs_set_super_dirty_val(dev, 1);
+}
+
+static void yaffs_clear_super_dirty(struct yaffs_dev *dev)
+{
+	yaffs_set_super_dirty_val(dev, 0);
+}
+
+static int yaffs_check_super_dirty(struct yaffs_dev *dev)
+{
+	struct yaffs_linux_context *lc = yaffs_dev_to_lc(dev);
+
+	if (lc && lc->dirty)
+		return 1;
+
+# ifdef YAFFS_SUPER_HAS_DIRTY
+	{
+		struct super_block *sb = lc->super;
+
+		if (sb && sb->s_dirt)
+			return 1;
+	}
+#endif
+	return 0;
+
+}
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+static int yaffs_writepage(struct page *page, struct writeback_control *wbc)
+#else
+static int yaffs_writepage(struct page *page)
+#endif
+{
+	struct yaffs_dev *dev;
+	struct address_space *mapping = page->mapping;
+	struct inode *inode;
+	unsigned long end_index;
+	char *buffer;
+	struct yaffs_obj *obj;
+	int n_written = 0;
+	unsigned n_bytes;
+	loff_t i_size;
+
+	if (!mapping)
+		BUG();
+	inode = mapping->host;
+	if (!inode)
+		BUG();
+	i_size = i_size_read(inode);
+
+	end_index = i_size >> PAGE_CACHE_SHIFT;
+
+	if (page->index < end_index)
+		n_bytes = PAGE_CACHE_SIZE;
+	else {
+		n_bytes = i_size & (PAGE_CACHE_SIZE - 1);
+
+		if (page->index > end_index || !n_bytes) {
+			yaffs_trace(YAFFS_TRACE_OS,
+				"yaffs_writepage at %lld, inode size = %lld!!",
+				((loff_t)page->index) << PAGE_CACHE_SHIFT,
+				inode->i_size);
+			yaffs_trace(YAFFS_TRACE_OS,
+				"                -> don't care!!");
+
+			zero_user_segment(page, 0, PAGE_CACHE_SIZE);
+			set_page_writeback(page);
+			unlock_page(page);
+			end_page_writeback(page);
+			return 0;
+		}
+	}
+
+	if (n_bytes != PAGE_CACHE_SIZE)
+		zero_user_segment(page, n_bytes, PAGE_CACHE_SIZE);
+
+	get_page(page);
+
+	buffer = kmap(page);
+
+	obj = yaffs_inode_to_obj(inode);
+	dev = obj->my_dev;
+	yaffs_gross_lock(dev);
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_writepage at %lld, size %08x",
+		((loff_t)page->index) << PAGE_CACHE_SHIFT, n_bytes);
+	yaffs_trace(YAFFS_TRACE_OS,
+		"writepag0: obj = %lld, ino = %lld",
+		obj->variant.file_variant.file_size, inode->i_size);
+
+	n_written = yaffs_wr_file(obj, buffer,
+				  ((loff_t)page->index) << PAGE_CACHE_SHIFT, n_bytes, 0);
+
+	yaffs_set_super_dirty(dev);
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"writepag1: obj = %lld, ino = %lld",
+		obj->variant.file_variant.file_size, inode->i_size);
+
+	yaffs_gross_unlock(dev);
+
+	kunmap(page);
+	set_page_writeback(page);
+	unlock_page(page);
+	end_page_writeback(page);
+	put_page(page);
+
+	return (n_written == n_bytes) ? 0 : -ENOSPC;
+}
+
+/* Space holding and freeing is done to ensure we have space available for write_begin/end */
+/* For now we just assume few parallel writes and check against a small number. */
+/* Todo: need to do this with a counter to handle parallel reads better */
+
+static ssize_t yaffs_hold_space(struct file *f)
+{
+	struct yaffs_obj *obj;
+	struct yaffs_dev *dev;
+
+	int n_free_chunks;
+
+	obj = yaffs_dentry_to_obj(Y_GET_DENTRY(f));
+
+	dev = obj->my_dev;
+
+	yaffs_gross_lock(dev);
+
+	n_free_chunks = yaffs_get_n_free_chunks(dev);
+
+	yaffs_gross_unlock(dev);
+
+	return (n_free_chunks > 20) ? 1 : 0;
+}
+
+static void yaffs_release_space(struct file *f)
+{
+	struct yaffs_obj *obj;
+	struct yaffs_dev *dev;
+
+	obj = yaffs_dentry_to_obj(Y_GET_DENTRY(f));
+
+	dev = obj->my_dev;
+
+	yaffs_gross_lock(dev);
+
+	yaffs_gross_unlock(dev);
+}
+
+#if (YAFFS_USE_WRITE_BEGIN_END > 0)
+static int yaffs_write_begin(struct file *filp, struct address_space *mapping,
+			     loff_t pos, unsigned len, unsigned flags,
+			     struct page **pagep, void **fsdata)
+{
+	struct page *pg = NULL;
+	pgoff_t index = pos >> PAGE_CACHE_SHIFT;
+
+	int ret = 0;
+	int space_held = 0;
+
+	/* Get a page */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 28)
+	pg = grab_cache_page_write_begin(mapping, index, flags);
+#else
+	pg = __grab_cache_page(mapping, index);
+#endif
+
+	*pagep = pg;
+	if (!pg) {
+		ret = -ENOMEM;
+		goto out;
+	}
+	yaffs_trace(YAFFS_TRACE_OS,
+		"start yaffs_write_begin index %d(%x) uptodate %d",
+		(int)index, (int)index, Page_Uptodate(pg) ? 1 : 0);
+
+	/* Get fs space */
+	space_held = yaffs_hold_space(filp);
+
+	if (!space_held) {
+		ret = -ENOSPC;
+		goto out;
+	}
+
+	/* Update page if required */
+
+	if (!Page_Uptodate(pg))
+		ret = yaffs_readpage_nolock(filp, pg);
+
+	if (ret)
+		goto out;
+
+	/* Happy path return */
+	yaffs_trace(YAFFS_TRACE_OS, "end yaffs_write_begin - ok");
+
+	return 0;
+
+out:
+	yaffs_trace(YAFFS_TRACE_OS,
+		"end yaffs_write_begin fail returning %d", ret);
+	if (space_held)
+		yaffs_release_space(filp);
+	if (pg) {
+		unlock_page(pg);
+		page_cache_release(pg);
+	}
+	return ret;
+}
+
+#else
+
+static int yaffs_prepare_write(struct file *f, struct page *pg,
+			       unsigned offset, unsigned to)
+{
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_prepair_write");
+
+	if (!Page_Uptodate(pg))
+		return yaffs_readpage_nolock(f, pg);
+	return 0;
+}
+#endif
+
+
+static ssize_t yaffs_file_write(struct file *f, const char *buf, size_t n,
+				loff_t * pos)
+{
+	struct yaffs_obj *obj;
+	int n_written;
+	loff_t ipos;
+	struct inode *inode;
+	struct yaffs_dev *dev;
+
+	obj = yaffs_dentry_to_obj(Y_GET_DENTRY(f));
+
+	if (!obj) {
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_file_write: hey obj is null!");
+                return -EINVAL;
+        }
+
+	dev = obj->my_dev;
+
+	yaffs_gross_lock(dev);
+
+	inode = Y_GET_DENTRY(f)->d_inode;
+
+	if (!S_ISBLK(inode->i_mode) && f->f_flags & O_APPEND)
+		ipos = inode->i_size;
+	else
+		ipos = *pos;
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_file_write about to write writing %u(%x) bytes to object %d at %lld",
+		(unsigned)n, (unsigned)n, obj->obj_id, ipos);
+
+	n_written = yaffs_wr_file(obj, buf, ipos, n, 0);
+
+	yaffs_set_super_dirty(dev);
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_file_write: %d(%x) bytes written",
+		(unsigned)n, (unsigned)n);
+
+	if (n_written > 0) {
+		ipos += n_written;
+		*pos = ipos;
+		if (ipos > inode->i_size) {
+			inode->i_size = ipos;
+			inode->i_blocks = (ipos + 511) >> 9;
+
+			yaffs_trace(YAFFS_TRACE_OS,
+				"yaffs_file_write size updated to %lld bytes, %d blocks",
+				ipos, (int)(inode->i_blocks));
+		}
+
+	}
+	yaffs_gross_unlock(dev);
+	return (n_written == 0) && (n > 0) ? -ENOSPC : n_written;
+}
+
+
+#if (YAFFS_USE_WRITE_BEGIN_END > 0)
+static int yaffs_write_end(struct file *filp, struct address_space *mapping,
+			   loff_t pos, unsigned len, unsigned copied,
+			   struct page *pg, void *fsdadata)
+{
+	int ret = 0;
+	void *addr, *kva;
+	uint32_t offset_into_page = pos & (PAGE_CACHE_SIZE - 1);
+
+	kva = kmap(pg);
+	addr = kva + offset_into_page;
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_write_end addr %p pos %lld n_bytes %d",
+		addr, pos, copied);
+
+	ret = yaffs_file_write(filp, addr, copied, &pos);
+
+	if (ret != copied) {
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_write_end not same size ret %d  copied %d",
+			ret, copied);
+		SetPageError(pg);
+	}
+
+	kunmap(pg);
+
+	yaffs_release_space(filp);
+	unlock_page(pg);
+	page_cache_release(pg);
+	return ret;
+}
+#else
+
+static int yaffs_commit_write(struct file *f, struct page *pg, unsigned offset,
+			      unsigned to)
+{
+	void *addr, *kva;
+
+	loff_t pos = (((loff_t) pg->index) << PAGE_CACHE_SHIFT) + offset;
+	int n_bytes = to - offset;
+	int n_written;
+
+	kva = kmap(pg);
+	addr = kva + offset;
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_commit_write addr %p pos %lld n_bytes %d",
+		addr, pos, n_bytes);
+
+	n_written = yaffs_file_write(f, addr, n_bytes, &pos);
+
+	if (n_written != n_bytes) {
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_commit_write not same size n_written %d  n_bytes %d",
+			n_written, n_bytes);
+		SetPageError(pg);
+	}
+	kunmap(pg);
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_commit_write returning %d",
+		n_written == n_bytes ? 0 : n_written);
+
+	return n_written == n_bytes ? 0 : n_written;
+}
+#endif
+
+static struct address_space_operations yaffs_file_address_operations = {
+	.readpage = yaffs_readpage,
+	.writepage = yaffs_writepage,
+#if (YAFFS_USE_WRITE_BEGIN_END > 0)
+	.write_begin = yaffs_write_begin,
+	.write_end = yaffs_write_end,
+#else
+	.prepare_write = yaffs_prepare_write,
+	.commit_write = yaffs_commit_write,
+#endif
+};
+
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 17))
+static int yaffs_file_flush(struct file *file, fl_owner_t id)
+#else
+static int yaffs_file_flush(struct file *file)
+#endif
+{
+	struct yaffs_obj *obj = yaffs_dentry_to_obj(Y_GET_DENTRY(file));
+
+	struct yaffs_dev *dev = obj->my_dev;
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_file_flush object %d (%s)",
+		obj->obj_id,
+		obj->dirty ? "dirty" : "clean");
+
+	yaffs_gross_lock(dev);
+
+	yaffs_flush_file(obj, 1, 0, 0);
+
+	yaffs_gross_unlock(dev);
+
+	return 0;
+}
+
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 39))
+static int yaffs_sync_object(struct file *file, loff_t start, loff_t end, int datasync)
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 34))
+static int yaffs_sync_object(struct file *file, int datasync)
+#else
+static int yaffs_sync_object(struct file *file, struct dentry *dentry,
+			     int datasync)
+#endif
+{
+	struct yaffs_obj *obj;
+	struct yaffs_dev *dev;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 34))
+	struct dentry *dentry = file->f_path.dentry;
+#endif
+
+	obj = yaffs_dentry_to_obj(dentry);
+
+	dev = obj->my_dev;
+
+	yaffs_trace(YAFFS_TRACE_OS | YAFFS_TRACE_SYNC,
+		"yaffs_sync_object");
+	yaffs_gross_lock(dev);
+	yaffs_flush_file(obj, 1, datasync, 0);
+	yaffs_gross_unlock(dev);
+	return 0;
+}
+
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 22))
+static const struct file_operations yaffs_file_operations = {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 16, 0)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	.read = new_sync_read,
+	.write = new_sync_write,
+#endif
+	.read_iter = generic_file_read_iter,
+	.write_iter = generic_file_write_iter,
+#else
+	.read = do_sync_read,
+	.write = do_sync_write,
+	.aio_read = generic_file_aio_read,
+	.aio_write = generic_file_aio_write,
+#endif
+	.mmap = generic_file_mmap,
+	.flush = yaffs_file_flush,
+	.fsync = yaffs_sync_object,
+	.splice_read = generic_file_splice_read,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 16, 0)
+	.splice_write = iter_file_splice_write,
+#else
+	.splice_write = generic_file_splice_write,
+#endif
+	.llseek = generic_file_llseek,
+};
+
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 18))
+
+static const struct file_operations yaffs_file_operations = {
+	.read = do_sync_read,
+	.write = do_sync_write,
+	.aio_read = generic_file_aio_read,
+	.aio_write = generic_file_aio_write,
+	.mmap = generic_file_mmap,
+	.flush = yaffs_file_flush,
+	.fsync = yaffs_sync_object,
+	.sendfile = generic_file_sendfile,
+};
+
+#else
+
+static const struct file_operations yaffs_file_operations = {
+	.read = generic_file_read,
+	.write = generic_file_write,
+	.mmap = generic_file_mmap,
+	.flush = yaffs_file_flush,
+	.fsync = yaffs_sync_object,
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+	.sendfile = generic_file_sendfile,
+#endif
+};
+#endif
+
+
+
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 25))
+static void zero_user_segment(struct page *page, unsigned start, unsigned end)
+{
+	void *kaddr = kmap_atomic(page, KM_USER0);
+	memset(kaddr + start, 0, end - start);
+	kunmap_atomic(kaddr, KM_USER0);
+	flush_dcache_page(page);
+}
+#endif
+
+
+static int yaffs_vfs_setsize(struct inode *inode, loff_t newsize)
+{
+#ifdef YAFFS_USE_TRUNCATE_SETSIZE
+	truncate_setsize(inode, newsize);
+	return 0;
+#else
+	truncate_inode_pages(&inode->i_data, newsize);
+	return 0;
+#endif
+
+}
+
+
+static int yaffs_vfs_setattr(struct inode *inode, struct iattr *attr)
+{
+#ifdef YAFFS_USE_SETATTR_COPY
+	setattr_copy(inode, attr);
+	return 0;
+#else
+	return inode_setattr(inode, attr);
+#endif
+
+}
+
+static int yaffs_setattr(struct dentry *dentry, struct iattr *attr)
+{
+	struct inode *inode = dentry->d_inode;
+	int error = 0;
+	struct yaffs_dev *dev;
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_setattr of object %d",
+		yaffs_inode_to_obj(inode)->obj_id);
+#if 0
+	/* Fail if a requested resize >= 2GB */
+	if (attr->ia_valid & ATTR_SIZE && (attr->ia_size >> 31))
+		error = -EINVAL;
+#endif
+
+	if (error == 0)
+		error = setattr_prepare(dentry, attr);
+	if (error == 0) {
+		int result;
+		if (!error) {
+			error = yaffs_vfs_setattr(inode, attr);
+			yaffs_trace(YAFFS_TRACE_OS, "inode_setattr called");
+			if (attr->ia_valid & ATTR_SIZE) {
+				yaffs_vfs_setsize(inode, attr->ia_size);
+				inode->i_blocks = (inode->i_size + 511) >> 9;
+			}
+		}
+		dev = yaffs_inode_to_obj(inode)->my_dev;
+		if (attr->ia_valid & ATTR_SIZE) {
+			yaffs_trace(YAFFS_TRACE_OS,
+				"resize to %d(%x)",
+				(int)(attr->ia_size),
+				(int)(attr->ia_size));
+		}
+		yaffs_gross_lock(dev);
+		result = yaffs_set_attribs(yaffs_inode_to_obj(inode), attr);
+		if (result == YAFFS_OK) {
+			error = 0;
+		} else {
+			error = -EPERM;
+		}
+		yaffs_gross_unlock(dev);
+
+	}
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_setattr done returning %d", error);
+
+	return error;
+}
+
+#ifdef YAFFS_USE_XATTR
+#if (YAFFS_NEW_XATTR > 0)
+static int yaffs_setxattr(struct dentry *dentry, struct inode *inode,
+		const char *name, const void *value, size_t size, int flags)
+{
+#else
+static int yaffs_setxattr(struct dentry *dentry, const char *name,
+		   const void *value, size_t size, int flags)
+{
+	struct inode *inode = dentry->d_inode;
+#endif
+	int error = 0;
+	struct yaffs_dev *dev;
+	struct yaffs_obj *obj = yaffs_inode_to_obj(inode);
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_setxattr of object %d", obj->obj_id);
+
+	if (error == 0) {
+		int result;
+		dev = obj->my_dev;
+		yaffs_gross_lock(dev);
+		result = yaffs_set_xattrib(obj, name, value, size, flags);
+		if (result == YAFFS_OK)
+			error = 0;
+		else if (result < 0)
+			error = result;
+		yaffs_gross_unlock(dev);
+
+	}
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_setxattr done returning %d", error);
+
+	return error;
+}
+
+#ifdef YAFFS_NEW_XATTR
+static ssize_t yaffs_getxattr(struct dentry * dentry, struct inode *inode,
+	const char *name, void *buff, size_t size)
+{
+#else
+static ssize_t yaffs_getxattr(struct dentry * dentry, const char *name,
+			void *buff, size_t size)
+{
+	struct inode *inode = dentry->d_inode;
+#endif
+	int error = 0;
+	struct yaffs_dev *dev;
+	struct yaffs_obj *obj = yaffs_inode_to_obj(inode);
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_getxattr \"%s\" from object %d",
+		name, obj->obj_id);
+
+	if (error == 0) {
+		dev = obj->my_dev;
+		yaffs_gross_lock(dev);
+		error = yaffs_get_xattrib(obj, name, buff, size);
+		yaffs_gross_unlock(dev);
+
+	}
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_getxattr done returning %d", error);
+
+	return error;
+}
+
+static int yaffs_removexattr(struct dentry *dentry, const char *name)
+{
+	struct inode *inode = dentry->d_inode;
+	int error = 0;
+	struct yaffs_dev *dev;
+	struct yaffs_obj *obj = yaffs_inode_to_obj(inode);
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_removexattr of object %d", obj->obj_id);
+
+	if (error == 0) {
+		int result;
+		dev = obj->my_dev;
+		yaffs_gross_lock(dev);
+		result = yaffs_remove_xattrib(obj, name);
+		if (result == YAFFS_OK)
+			error = 0;
+		else if (result < 0)
+			error = result;
+		yaffs_gross_unlock(dev);
+
+	}
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_removexattr done returning %d", error);
+
+	return error;
+}
+#endif
+
+static ssize_t yaffs_listxattr(struct dentry * dentry, char *buff, size_t size)
+{
+	struct inode *inode = dentry->d_inode;
+	int error = 0;
+	struct yaffs_dev *dev;
+	struct yaffs_obj *obj = yaffs_inode_to_obj(inode);
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_listxattr of object %d", obj->obj_id);
+
+	if (error == 0) {
+		dev = obj->my_dev;
+		yaffs_gross_lock(dev);
+		error = yaffs_list_xattrib(obj, buff, size);
+		yaffs_gross_unlock(dev);
+
+	}
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_listxattr done returning %d", error);
+
+	return error;
+}
+
+
+static const struct inode_operations yaffs_file_inode_operations = {
+	.setattr = yaffs_setattr,
+#ifdef YAFFS_USE_XATTR
+	.setxattr = yaffs_setxattr,
+	.getxattr = yaffs_getxattr,
+	.removexattr = yaffs_removexattr,
+#endif
+	.listxattr = yaffs_listxattr,
+};
+
+
+static int yaffs_readlink(struct dentry *dentry, char __user * buffer,
+			  int buflen)
+{
+	unsigned char *alias;
+	int ret;
+
+	struct yaffs_dev *dev = yaffs_dentry_to_obj(dentry)->my_dev;
+
+	yaffs_gross_lock(dev);
+
+	alias = yaffs_get_symlink_alias(yaffs_dentry_to_obj(dentry));
+
+	yaffs_gross_unlock(dev);
+
+	if (!alias)
+		return -ENOMEM;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 15, 0)
+	ret = vfs_readlink(dentry, buffer, buflen, alias);
+#else
+	ret = readlink_copy(buffer, buflen, alias);
+#endif
+	kfree(alias);
+	return ret;
+}
+
+#if (YAFFS_NEW_GET_LINK == 0)
+#if (YAFFS_NEW_FOLLOW_LINK == 1)
+static void *yaffs_follow_link(struct dentry *dentry, struct nameidata *nd)
+{
+	void *ret;
+#else
+static int yaffs_follow_link(struct dentry *dentry, struct nameidata *nd)
+{
+	int ret
+#endif
+	unsigned char *alias;
+	int ret_int = 0;
+	struct yaffs_dev *dev = yaffs_dentry_to_obj(dentry)->my_dev;
+
+	yaffs_gross_lock(dev);
+
+	alias = yaffs_get_symlink_alias(yaffs_dentry_to_obj(dentry));
+	yaffs_gross_unlock(dev);
+
+	if (!alias) {
+		ret_int = -ENOMEM;
+		goto out;
+	}
+#if (YAFFS_NEW_FOLLOW_LINK == 1)
+	nd_set_link(nd, alias);
+	ret = alias;
+out:
+	if (ret_int)
+		ret = ERR_PTR(ret_int);
+	return ret;
+#else
+	ret = vfs_follow_link(nd, alias);
+	kfree(alias);
+out:
+	if (ret_int)
+		ret = ret_int;
+	return ret;
+#endif
+}
+#else
+static const char *yaffs_get_link(struct dentry *dentry, struct inode *inode, struct delayed_call *done)
+{
+	unsigned char *alias;
+	struct yaffs_dev *dev;
+
+	if (!dentry)
+		return ERR_PTR(-ECHILD);
+
+	dev = yaffs_dentry_to_obj(dentry)->my_dev;
+
+	yaffs_gross_lock(dev);
+
+	alias = yaffs_get_symlink_alias(yaffs_dentry_to_obj(dentry));
+	yaffs_gross_unlock(dev);
+
+	if (!alias)
+		return ERR_PTR(-ENOMEM);
+	set_delayed_call(done, kfree_link, alias);
+	return alias;
+}
+#endif
+
+#ifdef YAFFS_HAS_PUT_INODE
+
+/* For now put inode is just for debugging
+ * Put inode is called when the inode **structure** is put.
+ */
+static void yaffs_put_inode(struct inode *inode)
+{
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_put_inode: ino %d, count %d"),
+		(int)inode->i_ino, atomic_read(&inode->i_count);
+
+}
+#endif
+
+#if (YAFFS_NEW_FOLLOW_LINK == 1)
+void yaffs_put_link(struct dentry *dentry, struct nameidata *nd, void *alias)
+{
+	kfree(alias);
+}
+#endif
+
+static const struct inode_operations yaffs_symlink_inode_operations = {
+	.readlink = yaffs_readlink,
+#if (YAFFS_NEW_GET_LINK == 1)
+	.get_link = yaffs_get_link,
+#else
+	.follow_link = yaffs_follow_link,
+#endif
+#if (YAFFS_NEW_FOLLOW_LINK == 1)
+	.put_link = yaffs_put_link,
+#endif
+	.setattr = yaffs_setattr,
+#ifdef YAFFS_USE_XATTR
+	.setxattr = yaffs_setxattr,
+	.getxattr = yaffs_getxattr,
+	.removexattr = yaffs_removexattr,
+#endif
+	.listxattr = yaffs_listxattr,
+};
+
+#ifdef YAFFS_USE_OWN_IGET
+
+static struct inode *yaffs_iget(struct super_block *sb, unsigned long ino)
+{
+	struct inode *inode;
+	struct yaffs_obj *obj;
+	struct yaffs_dev *dev = yaffs_super_to_dev(sb);
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_iget for %lu", ino);
+
+	inode = iget_locked(sb, ino);
+	if (!inode)
+		return ERR_PTR(-ENOMEM);
+	if (!(inode->i_state & I_NEW))
+		return inode;
+
+	/* NB This is called as a side effect of other functions, but
+	 * we had to release the lock to prevent deadlocks, so
+	 * need to lock again.
+	 */
+
+	yaffs_gross_lock(dev);
+
+	obj = yaffs_find_by_number(dev, inode->i_ino);
+
+	yaffs_fill_inode_from_obj(inode, obj);
+
+	yaffs_gross_unlock(dev);
+
+	unlock_new_inode(inode);
+	return inode;
+}
+
+#else
+
+static void yaffs_read_inode(struct inode *inode)
+{
+	/* NB This is called as a side effect of other functions, but
+	 * we had to release the lock to prevent deadlocks, so
+	 * need to lock again.
+	 */
+
+	struct yaffs_obj *obj;
+	struct yaffs_dev *dev = yaffs_super_to_dev(inode->i_sb);
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_read_inode for %d", (int)inode->i_ino);
+
+	if (current != yaffs_dev_to_lc(dev)->readdir_process)
+		yaffs_gross_lock(dev);
+
+	obj = yaffs_find_by_number(dev, inode->i_ino);
+
+	yaffs_fill_inode_from_obj(inode, obj);
+
+	if (current != yaffs_dev_to_lc(dev)->readdir_process)
+		yaffs_gross_unlock(dev);
+}
+
+#endif
+
+
+
+struct inode *yaffs_get_inode(struct super_block *sb, int mode, int dev,
+			      struct yaffs_obj *obj)
+{
+	struct inode *inode;
+
+	if (!sb) {
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_get_inode for NULL super_block!!");
+		return NULL;
+
+	}
+
+	if (!obj) {
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_get_inode for NULL object!!");
+		return NULL;
+
+	}
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_get_inode for object %d", obj->obj_id);
+
+	inode = Y_IGET(sb, obj->obj_id);
+	if (IS_ERR(inode))
+		return NULL;
+
+	/* NB Side effect: iget calls back to yaffs_read_inode(). */
+	/* iget also increments the inode's i_count */
+	/* NB You can't be holding gross_lock or deadlock will happen! */
+
+	return inode;
+}
+
+
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 29)
+#define YCRED(x) x
+#else
+#define YCRED(x) (x->cred)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3,14,0)
+#define YPROC_uid(p) (YCRED(p)->fsuid)
+#define YPROC_gid(p) (YCRED(p)->fsgid)
+#define EXTRACT_gid(x) x
+#define EXTRACT_uid(x) x
+#define MAKE_gid(x) x
+#define MAKE_uid(x) x
+#else
+#define YPROC_uid(p) from_kuid(&init_user_ns, YCRED(p)->fsuid)
+#define YPROC_gid(p) from_kgid(&init_user_ns, YCRED(p)->fsgid)
+#define EXTRACT_gid(x) from_kgid(&init_user_ns, x)
+#define EXTRACT_uid(x) from_kuid(&init_user_ns, x)
+#define MAKE_gid(x) make_kgid(&init_user_ns, x)
+#define MAKE_uid(x) make_kuid(&init_user_ns, x)
+#endif
+
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 4, 0))
+static int yaffs_mknod(struct inode *dir, struct dentry *dentry, umode_t mode,
+		       dev_t rdev)
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+static int yaffs_mknod(struct inode *dir, struct dentry *dentry, int mode,
+		       dev_t rdev)
+#else
+static int yaffs_mknod(struct inode *dir, struct dentry *dentry, int mode,
+		       int rdev)
+#endif
+{
+	struct inode *inode;
+
+	struct yaffs_obj *obj = NULL;
+	struct yaffs_dev *dev;
+
+	struct yaffs_obj *parent = yaffs_inode_to_obj(dir);
+
+	int error = -ENOSPC;
+	uid_t uid = YPROC_uid(current);
+	gid_t gid =
+	    (dir->i_mode & S_ISGID) ? EXTRACT_gid(dir->i_gid) : YPROC_gid(current);
+
+	if ((dir->i_mode & S_ISGID) && S_ISDIR(mode))
+		mode |= S_ISGID;
+
+	if (parent) {
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_mknod: parent object %d type %d",
+			parent->obj_id, parent->variant_type);
+	} else {
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_mknod: could not get parent object");
+		return -EPERM;
+	}
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_mknod: making oject for %s, mode %x dev %x",
+		dentry->d_name.name, mode, rdev);
+
+	dev = parent->my_dev;
+
+	yaffs_gross_lock(dev);
+
+	switch (mode & S_IFMT) {
+	default:
+		/* Special (socket, fifo, device...) */
+		yaffs_trace(YAFFS_TRACE_OS, "yaffs_mknod: making special");
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+		obj =
+		    yaffs_create_special(parent, dentry->d_name.name, mode, uid,
+					 gid, old_encode_dev(rdev));
+#else
+		obj =
+		    yaffs_create_special(parent, dentry->d_name.name, mode, uid,
+					 gid, rdev);
+#endif
+		break;
+	case S_IFREG:		/* file          */
+		yaffs_trace(YAFFS_TRACE_OS, "yaffs_mknod: making file");
+		obj = yaffs_create_file(parent, dentry->d_name.name, mode, uid,
+					gid);
+		break;
+	case S_IFDIR:		/* directory */
+		yaffs_trace(YAFFS_TRACE_OS, "yaffs_mknod: making directory");
+		obj = yaffs_create_dir(parent, dentry->d_name.name, mode,
+				       uid, gid);
+		break;
+	case S_IFLNK:		/* symlink */
+		yaffs_trace(YAFFS_TRACE_OS, "yaffs_mknod: making symlink");
+		obj = NULL;	/* Do we ever get here? */
+		break;
+	}
+
+	/* Can not call yaffs_get_inode() with gross lock held */
+	yaffs_gross_unlock(dev);
+
+	if (obj) {
+		inode = yaffs_get_inode(dir->i_sb, mode, rdev, obj);
+		d_instantiate(dentry, inode);
+		update_dir_time(dir);
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_mknod created object %d count = %d",
+			obj->obj_id, atomic_read(&inode->i_count));
+		error = 0;
+		yaffs_fill_inode_from_obj(dir, parent);
+	} else {
+		yaffs_trace(YAFFS_TRACE_OS, "yaffs_mknod failed making object");
+		error = -ENOMEM;
+	}
+
+	return error;
+}
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 4, 0))
+static int yaffs_mkdir(struct inode *dir, struct dentry *dentry, umode_t mode)
+#else
+static int yaffs_mkdir(struct inode *dir, struct dentry *dentry, int mode)
+#endif
+{
+	int ret_val;
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_mkdir");
+	ret_val = yaffs_mknod(dir, dentry, mode | S_IFDIR, 0);
+	return ret_val;
+}
+
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 6, 0))
+static int yaffs_create(struct inode *dir, struct dentry *dentry, umode_t mode,
+			bool dummy)
+#elif (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 4, 0))
+static int yaffs_create(struct inode *dir, struct dentry *dentry, umode_t mode,
+			struct nameidata *n)
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+static int yaffs_create(struct inode *dir, struct dentry *dentry, int mode,
+			struct nameidata *n)
+#else
+static int yaffs_create(struct inode *dir, struct dentry *dentry, int mode)
+#endif
+{
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_create");
+	return yaffs_mknod(dir, dentry, mode | S_IFREG, 0);
+}
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 6, 0))
+static struct dentry *yaffs_lookup(struct inode *dir, struct dentry *dentry,
+				   unsigned int dummy)
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+static struct dentry *yaffs_lookup(struct inode *dir, struct dentry *dentry,
+				   struct nameidata *n)
+#else
+static struct dentry *yaffs_lookup(struct inode *dir, struct dentry *dentry)
+#endif
+{
+	struct yaffs_obj *obj;
+	struct inode *inode = NULL;	/* NCB 2.5/2.6 needs NULL here */
+
+	struct yaffs_dev *dev = yaffs_inode_to_obj(dir)->my_dev;
+
+	if (current != yaffs_dev_to_lc(dev)->readdir_process)
+		yaffs_gross_lock(dev);
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_lookup for %d:%s",
+		yaffs_inode_to_obj(dir)->obj_id, dentry->d_name.name);
+
+	obj = yaffs_find_by_name(yaffs_inode_to_obj(dir), dentry->d_name.name);
+
+	obj = yaffs_get_equivalent_obj(obj);	/* in case it was a hardlink */
+
+	/* Can't hold gross lock when calling yaffs_get_inode() */
+	if (current != yaffs_dev_to_lc(dev)->readdir_process)
+		yaffs_gross_unlock(dev);
+
+	if (obj) {
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_lookup found %d", obj->obj_id);
+
+		inode = yaffs_get_inode(dir->i_sb, obj->yst_mode, 0, obj);
+	} else {
+		yaffs_trace(YAFFS_TRACE_OS, "yaffs_lookup not found");
+
+	}
+
+/* added NCB for 2.5/6 compatability - forces add even if inode is
+ * NULL which creates dentry hash */
+	d_add(dentry, inode);
+
+	return NULL;
+}
+
+/*
+ * Create a link...
+ */
+static int yaffs_link(struct dentry *old_dentry, struct inode *dir,
+		      struct dentry *dentry)
+{
+	struct inode *inode = old_dentry->d_inode;
+	struct yaffs_obj *obj = NULL;
+	struct yaffs_obj *link = NULL;
+	struct yaffs_dev *dev;
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_link");
+
+	obj = yaffs_inode_to_obj(inode);
+	dev = obj->my_dev;
+
+	yaffs_gross_lock(dev);
+
+	if (!S_ISDIR(inode->i_mode))	/* Don't link directories */
+		link =
+		    yaffs_link_obj(yaffs_inode_to_obj(dir), dentry->d_name.name,
+				   obj);
+
+	if (link) {
+		set_nlink(old_dentry->d_inode, yaffs_get_obj_link_count(obj));
+		d_instantiate(dentry, old_dentry->d_inode);
+		atomic_inc(&old_dentry->d_inode->i_count);
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_link link count %d i_count %d",
+			old_dentry->d_inode->i_nlink,
+			atomic_read(&old_dentry->d_inode->i_count));
+	}
+
+	yaffs_gross_unlock(dev);
+
+	if (link) {
+		update_dir_time(dir);
+		return 0;
+	}
+
+	return -EPERM;
+}
+
+static int yaffs_symlink(struct inode *dir, struct dentry *dentry,
+			 const char *symname)
+{
+	struct yaffs_obj *obj;
+	struct yaffs_dev *dev;
+	uid_t uid = YPROC_uid(current);
+	gid_t gid =
+	    (dir->i_mode & S_ISGID) ? EXTRACT_gid(dir->i_gid) : YPROC_gid(current);
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_symlink");
+
+	if (strnlen(dentry->d_name.name, YAFFS_MAX_NAME_LENGTH + 1) >
+				YAFFS_MAX_NAME_LENGTH)
+		return -ENAMETOOLONG;
+
+	if (strnlen(symname, YAFFS_MAX_ALIAS_LENGTH + 1) >
+				YAFFS_MAX_ALIAS_LENGTH)
+		return -ENAMETOOLONG;
+
+	dev = yaffs_inode_to_obj(dir)->my_dev;
+	yaffs_gross_lock(dev);
+	obj = yaffs_create_symlink(yaffs_inode_to_obj(dir), dentry->d_name.name,
+				   S_IFLNK | S_IRWXUGO, uid, gid, symname);
+	yaffs_gross_unlock(dev);
+
+	if (obj) {
+		struct inode *inode;
+
+		inode = yaffs_get_inode(dir->i_sb, obj->yst_mode, 0, obj);
+		d_instantiate(dentry, inode);
+		update_dir_time(dir);
+		yaffs_trace(YAFFS_TRACE_OS, "symlink created OK");
+		return 0;
+	} else {
+		yaffs_trace(YAFFS_TRACE_OS, "symlink not created");
+	}
+
+	return -ENOMEM;
+}
+
+/*
+ * The VFS layer already does all the dentry stuff for rename.
+ *
+ * NB: POSIX says you can rename an object over an old object of the same name
+ */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(4, 9, 0))
+static int yaffs_rename(struct inode *old_dir, struct dentry *old_dentry,
+			struct inode *new_dir, struct dentry *new_dentry, unsigned int unused)
+#else
+static int yaffs_rename(struct inode *old_dir, struct dentry *old_dentry,
+			struct inode *new_dir, struct dentry *new_dentry)
+#endif
+{
+	struct yaffs_dev *dev;
+	int ret_val = YAFFS_FAIL;
+	struct yaffs_obj *target;
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_rename");
+	dev = yaffs_inode_to_obj(old_dir)->my_dev;
+
+	yaffs_gross_lock(dev);
+
+	/* Check if the target is an existing directory that is not empty. */
+	target = yaffs_find_by_name(yaffs_inode_to_obj(new_dir),
+				    new_dentry->d_name.name);
+
+	if (target && target->variant_type == YAFFS_OBJECT_TYPE_DIRECTORY &&
+	    !list_empty(&target->variant.dir_variant.children)) {
+
+		yaffs_trace(YAFFS_TRACE_OS, "target is non-empty dir");
+
+		ret_val = YAFFS_FAIL;
+	} else {
+		/* Now does unlinking internally using shadowing mechanism */
+		yaffs_trace(YAFFS_TRACE_OS, "calling yaffs_rename_obj");
+
+		ret_val = yaffs_rename_obj(yaffs_inode_to_obj(old_dir),
+					   old_dentry->d_name.name,
+					   yaffs_inode_to_obj(new_dir),
+					   new_dentry->d_name.name);
+	}
+	yaffs_gross_unlock(dev);
+
+	if (ret_val == YAFFS_OK) {
+		if (target)
+			inode_dec_link_count(new_dentry->d_inode);
+
+		update_dir_time(old_dir);
+		if (old_dir != new_dir)
+			update_dir_time(new_dir);
+		return 0;
+	} else {
+		return -ENOTEMPTY;
+	}
+}
+
+
+
+
+static int yaffs_unlink(struct inode *dir, struct dentry *dentry)
+{
+	int ret_val;
+
+	struct yaffs_dev *dev;
+	struct yaffs_obj *obj;
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_unlink %d:%s",
+		(int)(dir->i_ino), dentry->d_name.name);
+	obj = yaffs_inode_to_obj(dir);
+	dev = obj->my_dev;
+
+	yaffs_gross_lock(dev);
+
+	ret_val = yaffs_unlinker(obj, dentry->d_name.name);
+
+	if (ret_val == YAFFS_OK) {
+		inode_dec_link_count(dentry->d_inode);
+		dir->i_version++;
+		yaffs_gross_unlock(dev);
+		update_dir_time(dir);
+		return 0;
+	}
+	yaffs_gross_unlock(dev);
+	return -ENOTEMPTY;
+}
+
+
+
+static const struct inode_operations yaffs_dir_inode_operations = {
+	.create = yaffs_create,
+	.lookup = yaffs_lookup,
+	.link = yaffs_link,
+	.unlink = yaffs_unlink,
+	.symlink = yaffs_symlink,
+	.mkdir = yaffs_mkdir,
+	.rmdir = yaffs_unlink,
+	.mknod = yaffs_mknod,
+	.rename = yaffs_rename,
+	.setattr = yaffs_setattr,
+	.listxattr = yaffs_listxattr,
+#ifdef YAFFS_USE_XATTR
+	.setxattr = yaffs_setxattr,
+	.getxattr = yaffs_getxattr,
+	.removexattr = yaffs_removexattr,
+#endif
+};
+
+/*-----------------------------------------------------------------*/
+/* Directory search context allows us to unlock access to yaffs during
+ * filldir without causing problems with the directory being modified.
+ * This is similar to the tried and tested mechanism used in yaffs direct.
+ *
+ * A search context iterates along a doubly linked list of siblings in the
+ * directory. If the iterating object is deleted then this would corrupt
+ * the list iteration, likely causing a crash. The search context avoids
+ * this by using the remove_obj_fn to move the search context to the
+ * next object before the object is deleted.
+ *
+ * Many readdirs (and thus seach conexts) may be alive simulateously so
+ * each struct yaffs_dev has a list of these.
+ *
+ * A seach context lives for the duration of a readdir.
+ *
+ * All these functions must be called while yaffs is locked.
+ */
+
+struct yaffs_search_context {
+	struct yaffs_dev *dev;
+	struct yaffs_obj *dir_obj;
+	struct yaffs_obj *next_return;
+	struct list_head others;
+};
+
+/*
+ * yaffs_new_search() creates a new search context, initialises it and
+ * adds it to the device's search context list.
+ *
+ * Called at start of readdir.
+ */
+static struct yaffs_search_context *yaffs_new_search(struct yaffs_obj *dir)
+{
+	struct yaffs_dev *dev = dir->my_dev;
+	struct yaffs_search_context *sc =
+	    kmalloc(sizeof(struct yaffs_search_context), GFP_NOFS);
+	if (sc) {
+		sc->dir_obj = dir;
+		sc->dev = dev;
+		if (list_empty(&sc->dir_obj->variant.dir_variant.children))
+			sc->next_return = NULL;
+		else
+			sc->next_return =
+			    list_entry(dir->variant.dir_variant.children.next,
+				       struct yaffs_obj, siblings);
+		INIT_LIST_HEAD(&sc->others);
+		list_add(&sc->others, &(yaffs_dev_to_lc(dev)->search_contexts));
+	}
+	return sc;
+}
+
+/*
+ * yaffs_search_end() disposes of a search context and cleans up.
+ */
+static void yaffs_search_end(struct yaffs_search_context *sc)
+{
+	if (sc) {
+		list_del(&sc->others);
+		kfree(sc);
+	}
+}
+
+/*
+ * yaffs_search_advance() moves a search context to the next object.
+ * Called when the search iterates or when an object removal causes
+ * the search context to be moved to the next object.
+ */
+static void yaffs_search_advance(struct yaffs_search_context *sc)
+{
+	if (!sc)
+		return;
+
+	if (sc->next_return == NULL ||
+	    list_empty(&sc->dir_obj->variant.dir_variant.children))
+		sc->next_return = NULL;
+	else {
+		struct list_head *next = sc->next_return->siblings.next;
+
+		if (next == &sc->dir_obj->variant.dir_variant.children)
+			sc->next_return = NULL;	/* end of list */
+		else
+			sc->next_return =
+			    list_entry(next, struct yaffs_obj, siblings);
+	}
+}
+
+/*
+ * yaffs_remove_obj_callback() is called when an object is unlinked.
+ * We check open search contexts and advance any which are currently
+ * on the object being iterated.
+ */
+static void yaffs_remove_obj_callback(struct yaffs_obj *obj)
+{
+
+	struct list_head *i;
+	struct yaffs_search_context *sc;
+	struct list_head *search_contexts =
+	    &(yaffs_dev_to_lc(obj->my_dev)->search_contexts);
+
+	/* Iterate through the directory search contexts.
+	 * If any are currently on the object being removed, then advance
+	 * the search context to the next object to prevent a hanging pointer.
+	 */
+	list_for_each(i, search_contexts) {
+		sc = list_entry(i, struct yaffs_search_context, others);
+		if (sc->next_return == obj)
+			yaffs_search_advance(sc);
+	}
+
+}
+
+
+/*-----------------------------------------------------------------*/
+
+#ifdef YAFFS_USE_DIR_ITERATE
+static int yaffs_iterate(struct file *f, struct dir_context *dc)
+{
+	struct yaffs_obj *obj;
+	struct yaffs_dev *dev;
+	struct yaffs_search_context *sc;
+	unsigned long curoffs;
+	struct yaffs_obj *l;
+	int ret_val = 0;
+
+	char name[YAFFS_MAX_NAME_LENGTH + 1];
+
+	obj = yaffs_dentry_to_obj(Y_GET_DENTRY(f));
+	dev = obj->my_dev;
+
+	yaffs_gross_lock(dev);
+
+	yaffs_dev_to_lc(dev)->readdir_process = current;
+
+	sc = yaffs_new_search(obj);
+	if (!sc) {
+		ret_val = -ENOMEM;
+		goto out;
+	}
+
+	if (!dir_emit_dots(f, dc))
+		return 0;
+
+	curoffs = 1;
+
+	while (sc->next_return) {
+		curoffs++;
+		l = sc->next_return;
+		if (curoffs >= dc->pos) {
+			int this_inode = yaffs_get_obj_inode(l);
+			int this_type = yaffs_get_obj_type(l);
+
+			yaffs_get_obj_name(l, name, YAFFS_MAX_NAME_LENGTH + 1);
+			yaffs_trace(YAFFS_TRACE_OS,
+				"yaffs_readdir: %s inode %d",
+				name, yaffs_get_obj_inode(l));
+
+			yaffs_gross_unlock(dev);
+
+			if (!dir_emit(dc,
+				      name,
+				      strlen(name),
+				      this_inode,
+				      this_type)) {
+				yaffs_gross_lock(dev);
+				goto out;
+			}
+
+			yaffs_gross_lock(dev);
+
+			dc->pos++;
+			f->f_pos++;
+		}
+		yaffs_search_advance(sc);
+	}
+
+out:
+	yaffs_search_end(sc);
+	yaffs_dev_to_lc(dev)->readdir_process = NULL;
+	yaffs_gross_unlock(dev);
+
+	return ret_val;
+}
+
+#else
+
+static int yaffs_readdir(struct file *f, void *dirent, filldir_t filldir)
+{
+	struct yaffs_obj *obj;
+	struct yaffs_dev *dev;
+	struct yaffs_search_context *sc;
+	struct inode *inode = Y_GET_DENTRY(f)->d_inode;
+	unsigned long offset, curoffs;
+	struct yaffs_obj *l;
+	int ret_val = 0;
+
+	char name[YAFFS_MAX_NAME_LENGTH + 1];
+
+	obj = yaffs_dentry_to_obj(Y_GET_DENTRY(f));
+	dev = obj->my_dev;
+
+	yaffs_gross_lock(dev);
+
+	yaffs_dev_to_lc(dev)->readdir_process = current;
+
+	offset = f->f_pos;
+
+	sc = yaffs_new_search(obj);
+	if (!sc) {
+		ret_val = -ENOMEM;
+		goto out;
+	}
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_readdir: starting at %d", (int)offset);
+
+	if (offset == 0) {
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_readdir: entry . ino %d",
+			(int)inode->i_ino);
+		yaffs_gross_unlock(dev);
+		if (filldir(dirent, ".", 1, offset, inode->i_ino, DT_DIR) < 0) {
+			yaffs_gross_lock(dev);
+			goto out;
+		}
+		yaffs_gross_lock(dev);
+		offset++;
+		f->f_pos++;
+	}
+	if (offset == 1) {
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_readdir: entry .. ino %d",
+			(int)f->f_dentry->d_parent->d_inode->i_ino);
+		yaffs_gross_unlock(dev);
+		if (filldir(dirent, "..", 2, offset,
+			    f->f_dentry->d_parent->d_inode->i_ino,
+			    DT_DIR) < 0) {
+			yaffs_gross_lock(dev);
+			goto out;
+		}
+		yaffs_gross_lock(dev);
+		offset++;
+		f->f_pos++;
+	}
+
+	curoffs = 1;
+
+	/* If the directory has changed since the open or last call to
+	   readdir, rewind to after the 2 canned entries. */
+	if (f->f_version != inode->i_version) {
+		offset = 2;
+		f->f_pos = offset;
+		f->f_version = inode->i_version;
+	}
+
+	while (sc->next_return) {
+		curoffs++;
+		l = sc->next_return;
+		if (curoffs >= offset) {
+			int this_inode = yaffs_get_obj_inode(l);
+			int this_type = yaffs_get_obj_type(l);
+
+			yaffs_get_obj_name(l, name, YAFFS_MAX_NAME_LENGTH + 1);
+			yaffs_trace(YAFFS_TRACE_OS,
+				"yaffs_readdir: %s inode %d",
+				name, yaffs_get_obj_inode(l));
+
+			yaffs_gross_unlock(dev);
+
+			if (filldir(dirent,
+				    name,
+				    strlen(name),
+				    offset, this_inode, this_type) < 0) {
+				yaffs_gross_lock(dev);
+				goto out;
+			}
+
+			yaffs_gross_lock(dev);
+
+			offset++;
+			f->f_pos++;
+		}
+		yaffs_search_advance(sc);
+	}
+
+out:
+	yaffs_search_end(sc);
+	yaffs_dev_to_lc(dev)->readdir_process = NULL;
+	yaffs_gross_unlock(dev);
+
+	return ret_val;
+}
+
+#endif
+
+static const struct file_operations yaffs_dir_operations = {
+	.read = generic_read_dir,
+#ifdef YAFFS_USE_DIR_ITERATE
+	.iterate = yaffs_iterate,
+#else
+	.readdir = yaffs_readdir,
+#endif
+	.fsync = yaffs_sync_object,
+	.llseek = generic_file_llseek,
+};
+
+static void yaffs_fill_inode_from_obj(struct inode *inode,
+				      struct yaffs_obj *obj)
+{
+	if (inode && obj) {
+
+		/* Check mode against the variant type and attempt to repair if broken. */
+		u32 mode = obj->yst_mode;
+		switch (obj->variant_type) {
+		case YAFFS_OBJECT_TYPE_FILE:
+			if (!S_ISREG(mode)) {
+				obj->yst_mode &= ~S_IFMT;
+				obj->yst_mode |= S_IFREG;
+			}
+
+			break;
+		case YAFFS_OBJECT_TYPE_SYMLINK:
+			if (!S_ISLNK(mode)) {
+				obj->yst_mode &= ~S_IFMT;
+				obj->yst_mode |= S_IFLNK;
+			}
+
+			break;
+		case YAFFS_OBJECT_TYPE_DIRECTORY:
+			if (!S_ISDIR(mode)) {
+				obj->yst_mode &= ~S_IFMT;
+				obj->yst_mode |= S_IFDIR;
+			}
+
+			break;
+		case YAFFS_OBJECT_TYPE_UNKNOWN:
+		case YAFFS_OBJECT_TYPE_HARDLINK:
+		case YAFFS_OBJECT_TYPE_SPECIAL:
+		default:
+			/* TODO? */
+			break;
+		}
+
+		inode->i_flags |= S_NOATIME;
+
+		inode->i_ino = obj->obj_id;
+		inode->i_mode = obj->yst_mode;
+		inode->i_uid = MAKE_uid(obj->yst_uid);
+		inode->i_gid = MAKE_gid(obj->yst_gid);
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19))
+		inode->i_blksize = inode->i_sb->s_blocksize;
+#endif
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+
+		inode->i_rdev = old_decode_dev(obj->yst_rdev);
+		inode->i_atime.tv_sec = (time_t) (obj->yst_atime);
+		inode->i_atime.tv_nsec = 0;
+		inode->i_mtime.tv_sec = (time_t) obj->yst_mtime;
+		inode->i_mtime.tv_nsec = 0;
+		inode->i_ctime.tv_sec = (time_t) obj->yst_ctime;
+		inode->i_ctime.tv_nsec = 0;
+#else
+		inode->i_rdev = obj->yst_rdev;
+		inode->i_atime = obj->yst_atime;
+		inode->i_mtime = obj->yst_mtime;
+		inode->i_ctime = obj->yst_ctime;
+#endif
+		inode->i_size = yaffs_get_obj_length(obj);
+		inode->i_blocks = (inode->i_size + 511) >> 9;
+
+		set_nlink(inode, yaffs_get_obj_link_count(obj));
+
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_fill_inode mode %x uid %d gid %d size %lld count %d",
+			inode->i_mode, obj->yst_uid, obj->yst_gid,
+			inode->i_size, atomic_read(&inode->i_count));
+
+		switch (obj->yst_mode & S_IFMT) {
+		default:	/* fifo, device or socket */
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+			init_special_inode(inode, obj->yst_mode,
+					   old_decode_dev(obj->yst_rdev));
+#else
+			init_special_inode(inode, obj->yst_mode,
+					   (dev_t) (obj->yst_rdev));
+#endif
+			break;
+		case S_IFREG:	/* file */
+			inode->i_op = &yaffs_file_inode_operations;
+			inode->i_fop = &yaffs_file_operations;
+			inode->i_mapping->a_ops =
+			    &yaffs_file_address_operations;
+			break;
+		case S_IFDIR:	/* directory */
+			inode->i_op = &yaffs_dir_inode_operations;
+			inode->i_fop = &yaffs_dir_operations;
+			break;
+		case S_IFLNK:	/* symlink */
+			inode->i_op = &yaffs_symlink_inode_operations;
+			break;
+		}
+
+		yaffs_inode_to_obj_lv(inode) = obj;
+
+		obj->my_inode = inode;
+
+	} else {
+		yaffs_trace(YAFFS_TRACE_OS,
+			"yaffs_fill_inode invalid parameters");
+	}
+
+}
+
+
+
+/*
+ * yaffs background thread functions .
+ * yaffs_bg_thread_fn() the thread function
+ * yaffs_bg_start() launches the background thread.
+ * yaffs_bg_stop() cleans up the background thread.
+ *
+ * NB:
+ * The thread should only run after the yaffs is initialised
+ * The thread should be stopped before yaffs is unmounted.
+ * The thread should not do any writing while the fs is in read only.
+ */
+
+static unsigned yaffs_bg_gc_urgency(struct yaffs_dev *dev)
+{
+	unsigned erased_chunks =
+	    dev->n_erased_blocks * dev->param.chunks_per_block;
+	struct yaffs_linux_context *context = yaffs_dev_to_lc(dev);
+	unsigned scattered = 0;	/* Free chunks not in an erased block */
+
+	if (erased_chunks < dev->n_free_chunks)
+		scattered = (dev->n_free_chunks - erased_chunks);
+
+	if (!context->bg_running)
+		return 0;
+	else if (scattered < (dev->param.chunks_per_block * 2))
+		return 0;
+	else if (erased_chunks > dev->n_free_chunks / 2)
+		return 0;
+	else if (erased_chunks > dev->n_free_chunks / 4)
+		return 1;
+	else
+		return 2;
+}
+
+#ifdef YAFFS_COMPILE_BACKGROUND
+
+void yaffs_background_waker(unsigned long data)
+{
+	wake_up_process((struct task_struct *)data);
+}
+
+static int yaffs_bg_thread_fn(void *data)
+{
+	struct yaffs_dev *dev = (struct yaffs_dev *)data;
+	struct yaffs_linux_context *context = yaffs_dev_to_lc(dev);
+	unsigned long now = jiffies;
+	unsigned long next_dir_update = now;
+	unsigned long next_gc = now;
+	unsigned long expires;
+	unsigned int urgency;
+
+	int gc_result;
+	struct timer_list timer;
+
+	yaffs_trace(YAFFS_TRACE_BACKGROUND,
+		"yaffs_background starting for dev %p", (void *)dev);
+
+#ifdef YAFFS_COMPILE_FREEZER
+	set_freezable();
+#endif
+	while (context->bg_running) {
+		yaffs_trace(YAFFS_TRACE_BACKGROUND, "yaffs_background");
+
+		if (kthread_should_stop())
+			break;
+
+#ifdef YAFFS_COMPILE_FREEZER
+		if (try_to_freeze())
+			continue;
+#endif
+		yaffs_gross_lock(dev);
+
+		now = jiffies;
+
+		if (time_after(now, next_dir_update) && yaffs_bg_enable) {
+			yaffs_update_dirty_dirs(dev);
+			next_dir_update = now + HZ;
+		}
+
+		if (time_after(now, next_gc) && yaffs_bg_enable) {
+			if (!dev->is_checkpointed) {
+				urgency = yaffs_bg_gc_urgency(dev);
+				gc_result = yaffs_bg_gc(dev, urgency);
+				if (urgency > 1)
+					next_gc = now + HZ / 20 + 1;
+				else if (urgency > 0)
+					next_gc = now + HZ / 10 + 1;
+				else
+					next_gc = now + HZ * 2;
+			} else	{
+			        /*
+				 * gc not running so set to next_dir_update
+				 * to cut down on wake ups
+				 */
+				next_gc = next_dir_update;
+                        }
+		}
+		yaffs_gross_unlock(dev);
+#if 1
+		expires = next_dir_update;
+		if (time_before(next_gc, expires))
+			expires = next_gc;
+		if (time_before(expires, now))
+			expires = now + HZ;
+
+		Y_INIT_TIMER(&timer);
+		timer.expires = expires + 1;
+		timer.data = (unsigned long)current;
+		timer.function = yaffs_background_waker;
+
+		set_current_state(TASK_INTERRUPTIBLE);
+		add_timer(&timer);
+		schedule();
+		del_timer_sync(&timer);
+#else
+		msleep(10);
+#endif
+	}
+
+	return 0;
+}
+
+static int yaffs_bg_start(struct yaffs_dev *dev)
+{
+	int retval = 0;
+	struct yaffs_linux_context *context = yaffs_dev_to_lc(dev);
+
+	if (dev->read_only)
+		return -1;
+
+	context->bg_running = 1;
+
+	context->bg_thread = kthread_run(yaffs_bg_thread_fn,
+					 (void *)dev, "yaffs-bg-%d",
+					 context->mount_id);
+
+	if (IS_ERR(context->bg_thread)) {
+		retval = PTR_ERR(context->bg_thread);
+		context->bg_thread = NULL;
+		context->bg_running = 0;
+	}
+	return retval;
+}
+
+static void yaffs_bg_stop(struct yaffs_dev *dev)
+{
+	struct yaffs_linux_context *ctxt = yaffs_dev_to_lc(dev);
+
+	ctxt->bg_running = 0;
+
+	if (ctxt->bg_thread) {
+		kthread_stop(ctxt->bg_thread);
+		ctxt->bg_thread = NULL;
+	}
+}
+#else
+static int yaffs_bg_thread_fn(void *data)
+{
+	return 0;
+}
+
+static int yaffs_bg_start(struct yaffs_dev *dev)
+{
+	return 0;
+}
+
+static void yaffs_bg_stop(struct yaffs_dev *dev)
+{
+}
+#endif
+
+
+static void yaffs_flush_inodes(struct super_block *sb)
+{
+	struct inode *iptr;
+	struct yaffs_obj *obj;
+
+	list_for_each_entry(iptr, &sb->s_inodes, i_sb_list) {
+		obj = yaffs_inode_to_obj(iptr);
+		if (obj) {
+			yaffs_trace(YAFFS_TRACE_OS,
+				"flushing obj %d",
+				obj->obj_id);
+			yaffs_flush_file(obj, 1, 0, 0);
+		}
+	}
+}
+
+static void yaffs_flush_super(struct super_block *sb, int do_checkpoint)
+{
+	struct yaffs_dev *dev = yaffs_super_to_dev(sb);
+	if (!dev)
+		return;
+
+	yaffs_flush_inodes(sb);
+	yaffs_update_dirty_dirs(dev);
+	yaffs_flush_whole_cache(dev, 1);
+	if (do_checkpoint)
+		yaffs_checkpoint_save(dev);
+}
+
+static LIST_HEAD(yaffs_context_list);
+struct mutex yaffs_context_lock;
+
+static void yaffs_put_super(struct super_block *sb)
+{
+	struct yaffs_dev *dev = yaffs_super_to_dev(sb);
+	struct mtd_info *mtd = yaffs_dev_to_mtd(dev);
+
+	yaffs_trace(YAFFS_TRACE_OS | YAFFS_TRACE_ALWAYS,
+			"yaffs_put_super");
+
+	yaffs_trace(YAFFS_TRACE_OS | YAFFS_TRACE_BACKGROUND,
+		"Shutting down yaffs background thread");
+	yaffs_bg_stop(dev);
+	yaffs_trace(YAFFS_TRACE_OS | YAFFS_TRACE_BACKGROUND,
+		"yaffs background thread shut down");
+
+	yaffs_gross_lock(dev);
+
+	yaffs_flush_super(sb, 1);
+
+	yaffs_deinitialise(dev);
+
+	yaffs_gross_unlock(dev);
+
+	mutex_lock(&yaffs_context_lock);
+	list_del_init(&(yaffs_dev_to_lc(dev)->context_list));
+	mutex_unlock(&yaffs_context_lock);
+
+	if (yaffs_dev_to_lc(dev)->spare_buffer) {
+		kfree(yaffs_dev_to_lc(dev)->spare_buffer);
+		yaffs_dev_to_lc(dev)->spare_buffer = NULL;
+	}
+
+	kfree(dev);
+
+	yaffs_put_mtd_device(mtd);
+
+	yaffs_trace(YAFFS_TRACE_OS | YAFFS_TRACE_ALWAYS,
+			"yaffs_put_super done");
+}
+
+
+static unsigned yaffs_gc_control_callback(struct yaffs_dev *dev)
+{
+	return yaffs_gc_control;
+}
+
+
+#ifdef YAFFS_COMPILE_EXPORTFS
+
+static struct inode *yaffs2_nfs_get_inode(struct super_block *sb, uint64_t ino,
+					  uint32_t generation)
+{
+	return Y_IGET(sb, ino);
+}
+
+static struct dentry *yaffs2_fh_to_dentry(struct super_block *sb,
+					  struct fid *fid, int fh_len,
+					  int fh_type)
+{
+	return generic_fh_to_dentry(sb, fid, fh_len, fh_type,
+				    yaffs2_nfs_get_inode);
+}
+
+static struct dentry *yaffs2_fh_to_parent(struct super_block *sb,
+					  struct fid *fid, int fh_len,
+					  int fh_type)
+{
+	return generic_fh_to_parent(sb, fid, fh_len, fh_type,
+				    yaffs2_nfs_get_inode);
+}
+
+struct dentry *yaffs2_get_parent(struct dentry *dentry)
+{
+
+	struct super_block *sb = dentry->d_inode->i_sb;
+	struct dentry *parent = ERR_PTR(-ENOENT);
+	struct inode *inode;
+	unsigned long parent_ino;
+	struct yaffs_obj *d_obj;
+	struct yaffs_obj *parent_obj;
+
+	d_obj = yaffs_inode_to_obj(dentry->d_inode);
+
+	if (d_obj) {
+		parent_obj = d_obj->parent;
+		if (parent_obj) {
+			parent_ino = yaffs_get_obj_inode(parent_obj);
+			inode = Y_IGET(sb, parent_ino);
+
+			if (IS_ERR(inode)) {
+				parent = ERR_CAST(inode);
+			} else {
+				parent = d_obtain_alias(inode);
+				if (!IS_ERR(parent)) {
+					parent = ERR_PTR(-ENOMEM);
+					iput(inode);
+				}
+			}
+		}
+	}
+
+	return parent;
+}
+
+/* Just declare a zero structure as a NULL value implies
+ * using the default functions of exportfs.
+ */
+
+static struct export_operations yaffs_export_ops = {
+	.fh_to_dentry = yaffs2_fh_to_dentry,
+	.fh_to_parent = yaffs2_fh_to_parent,
+	.get_parent = yaffs2_get_parent,
+};
+
+#endif
+
+static void yaffs_unstitch_obj(struct inode *inode, struct yaffs_obj *obj)
+{
+	/* Clear the association between the inode and
+	 * the struct yaffs_obj.
+	 */
+	obj->my_inode = NULL;
+	yaffs_inode_to_obj_lv(inode) = NULL;
+
+	/* If the object freeing was deferred, then the real
+	 * free happens now.
+	 * This should fix the inode inconsistency problem.
+	 */
+	yaffs_handle_defered_free(obj);
+}
+
+#ifdef YAFFS_HAS_EVICT_INODE
+/* yaffs_evict_inode combines into one operation what was previously done in
+ * yaffs_clear_inode() and yaffs_delete_inode()
+ *
+ */
+static void yaffs_evict_inode(struct inode *inode)
+{
+	struct yaffs_obj *obj;
+	struct yaffs_dev *dev;
+	int deleteme = 0;
+
+	obj = yaffs_inode_to_obj(inode);
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_evict_inode: ino %d, count %d %s",
+		(int)inode->i_ino, atomic_read(&inode->i_count),
+		obj ? "object exists" : "null object");
+
+	if (!inode->i_nlink && !is_bad_inode(inode))
+		deleteme = 1;
+	truncate_inode_pages(&inode->i_data, 0);
+	Y_CLEAR_INODE(inode);
+
+	if (deleteme && obj) {
+		dev = obj->my_dev;
+		yaffs_gross_lock(dev);
+		yaffs_del_obj(obj);
+		yaffs_gross_unlock(dev);
+	}
+	if (obj) {
+		dev = obj->my_dev;
+		yaffs_gross_lock(dev);
+		yaffs_unstitch_obj(inode, obj);
+		yaffs_gross_unlock(dev);
+	}
+}
+#else
+
+/* clear is called to tell the fs to release any per-inode data it holds.
+ * The object might still exist on disk and is just being thrown out of the cache
+ * or else the object has actually been deleted and we're being called via
+ * the chain
+ *   yaffs_delete_inode() -> clear_inode()->yaffs_clear_inode()
+ */
+
+static void yaffs_clear_inode(struct inode *inode)
+{
+	struct yaffs_obj *obj;
+	struct yaffs_dev *dev;
+
+	obj = yaffs_inode_to_obj(inode);
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_clear_inode: ino %d, count %d %s",
+		(int)inode->i_ino, atomic_read(&inode->i_count),
+		obj ? "object exists" : "null object");
+
+	if (obj) {
+		dev = obj->my_dev;
+		yaffs_gross_lock(dev);
+		yaffs_unstitch_obj(inode, obj);
+		yaffs_gross_unlock(dev);
+	}
+
+}
+
+/* delete is called when the link count is zero and the inode
+ * is put (ie. nobody wants to know about it anymore, time to
+ * delete the file).
+ * NB Must call clear_inode()
+ */
+static void yaffs_delete_inode(struct inode *inode)
+{
+	struct yaffs_obj *obj = yaffs_inode_to_obj(inode);
+	struct yaffs_dev *dev;
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_delete_inode: ino %d, count %d %s",
+		(int)inode->i_ino, atomic_read(&inode->i_count),
+		obj ? "object exists" : "null object");
+
+	if (obj) {
+		dev = obj->my_dev;
+		yaffs_gross_lock(dev);
+		yaffs_del_obj(obj);
+		yaffs_gross_unlock(dev);
+	}
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 13))
+	truncate_inode_pages(&inode->i_data, 0);
+#endif
+	clear_inode(inode);
+}
+#endif
+
+
+
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 17))
+static int yaffs_statfs(struct dentry *dentry, struct kstatfs *buf)
+{
+	struct yaffs_dev *dev = yaffs_dentry_to_obj(dentry)->my_dev;
+	struct super_block *sb = dentry->d_sb;
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+static int yaffs_statfs(struct super_block *sb, struct kstatfs *buf)
+{
+	struct yaffs_dev *dev = yaffs_super_to_dev(sb);
+#else
+static int yaffs_statfs(struct super_block *sb, struct statfs *buf)
+{
+	struct yaffs_dev *dev = yaffs_super_to_dev(sb);
+#endif
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_statfs");
+
+	yaffs_gross_lock(dev);
+
+	buf->f_type = YAFFS_MAGIC;
+	buf->f_bsize = sb->s_blocksize;
+	buf->f_namelen = 255;
+
+	if (dev->data_bytes_per_chunk & (dev->data_bytes_per_chunk - 1)) {
+		/* Do this if chunk size is not a power of 2 */
+
+		uint64_t bytes_in_dev;
+		uint64_t bytes_free;
+
+		bytes_in_dev =
+		    ((uint64_t)
+		     ((dev->param.end_block - dev->param.start_block +
+		       1))) * ((uint64_t) (dev->param.chunks_per_block *
+					   dev->data_bytes_per_chunk));
+
+		do_div(bytes_in_dev, sb->s_blocksize);	/* bytes_in_dev becomes the number of blocks */
+		buf->f_blocks = bytes_in_dev;
+
+		bytes_free = ((uint64_t) (yaffs_get_n_free_chunks(dev))) *
+		    ((uint64_t) (dev->data_bytes_per_chunk));
+
+		do_div(bytes_free, sb->s_blocksize);
+
+		buf->f_bfree = bytes_free;
+
+	} else if (sb->s_blocksize > dev->data_bytes_per_chunk) {
+
+		buf->f_blocks =
+		    (dev->param.end_block - dev->param.start_block + 1) *
+		    dev->param.chunks_per_block /
+		    (sb->s_blocksize / dev->data_bytes_per_chunk);
+		buf->f_bfree =
+		    yaffs_get_n_free_chunks(dev) /
+		    (sb->s_blocksize / dev->data_bytes_per_chunk);
+	} else {
+		buf->f_blocks =
+		    (dev->param.end_block - dev->param.start_block + 1) *
+		    dev->param.chunks_per_block *
+		    (dev->data_bytes_per_chunk / sb->s_blocksize);
+
+		buf->f_bfree =
+		    yaffs_get_n_free_chunks(dev) *
+		    (dev->data_bytes_per_chunk / sb->s_blocksize);
+	}
+
+	buf->f_files = 0;
+	buf->f_ffree = 0;
+	buf->f_bavail = buf->f_bfree;
+
+	yaffs_gross_unlock(dev);
+	return 0;
+}
+
+
+
+static int yaffs_do_sync_fs(struct super_block *sb, int request_checkpoint)
+{
+
+	struct yaffs_dev *dev = yaffs_super_to_dev(sb);
+	unsigned int oneshot_checkpoint = (yaffs_auto_checkpoint & 4);
+	unsigned gc_urgent = yaffs_bg_gc_urgency(dev);
+	int do_checkpoint;
+	int dirty = yaffs_check_super_dirty(dev);
+
+	yaffs_trace(YAFFS_TRACE_OS | YAFFS_TRACE_SYNC | YAFFS_TRACE_BACKGROUND,
+		"yaffs_do_sync_fs: gc-urgency %d %s %s%s",
+		gc_urgent,
+		dirty ? "dirty" : "clean",
+		request_checkpoint ? "checkpoint requested" : "no checkpoint",
+		oneshot_checkpoint ? " one-shot" : "");
+
+	yaffs_gross_lock(dev);
+	do_checkpoint = ((request_checkpoint && !gc_urgent) ||
+			 oneshot_checkpoint) && !dev->is_checkpointed;
+
+	if (dirty || do_checkpoint) {
+		yaffs_flush_super(sb, !dev->is_checkpointed && do_checkpoint);
+		yaffs_clear_super_dirty(dev);
+		if (oneshot_checkpoint)
+			yaffs_auto_checkpoint &= ~4;
+	}
+	yaffs_gross_unlock(dev);
+
+	return 0;
+}
+
+
+#ifdef YAFFS_HAS_WRITE_SUPER
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 17))
+static void yaffs_write_super(struct super_block *sb)
+#else
+static int yaffs_write_super(struct super_block *sb)
+#endif
+{
+	unsigned request_checkpoint = (yaffs_auto_checkpoint >= 2);
+
+	yaffs_trace(YAFFS_TRACE_OS | YAFFS_TRACE_SYNC | YAFFS_TRACE_BACKGROUND,
+		"yaffs_write_super %s",
+		request_checkpoint ? " checkpt" : "");
+
+	yaffs_do_sync_fs(sb, request_checkpoint);
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 18))
+	return 0;
+#endif
+}
+#endif
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 17))
+static int yaffs_sync_fs(struct super_block *sb, int wait)
+#else
+static int yaffs_sync_fs(struct super_block *sb)
+#endif
+{
+	unsigned request_checkpoint = (yaffs_auto_checkpoint >= 1);
+
+	yaffs_trace(YAFFS_TRACE_OS | YAFFS_TRACE_SYNC,
+		"yaffs_sync_fs%s", request_checkpoint ? " checkpt" : "");
+
+	yaffs_do_sync_fs(sb, request_checkpoint);
+
+	return 0;
+}
+
+/* the function only is used to change dev->read_only when this file system
+ * is remounted.
+ */
+static int yaffs_remount_fs(struct super_block *sb, int *flags, char *data)
+{
+	int read_only = 0;
+	struct mtd_info *mtd;
+	struct yaffs_dev *dev = 0;
+
+	/* Get the device */
+	mtd = get_mtd_device(NULL, MINOR(sb->s_dev));
+	if (!mtd) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"MTD device #%u doesn't appear to exist",
+			MINOR(sb->s_dev));
+		return 1;
+	}
+
+	/* Check it's NAND */
+	if (mtd->type != MTD_NANDFLASH) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"MTD device is not NAND it's type %d",
+			mtd->type);
+		return 1;
+	}
+
+	read_only = ((*flags & MS_RDONLY) != 0);
+	if (!read_only && !(mtd->flags & MTD_WRITEABLE)) {
+		read_only = 1;
+		printk(KERN_INFO
+			"yaffs: mtd is read only, setting superblock read only");
+		*flags |= MS_RDONLY;
+	}
+
+	dev = sb->s_fs_info;
+	dev->read_only = read_only;
+
+	return 0;
+}
+
+static const struct super_operations yaffs_super_ops = {
+	.statfs = yaffs_statfs,
+
+#ifndef YAFFS_USE_OWN_IGET
+	.read_inode = yaffs_read_inode,
+#endif
+#ifdef YAFFS_HAS_PUT_INODE
+	.put_inode = yaffs_put_inode,
+#endif
+	.put_super = yaffs_put_super,
+#ifdef YAFFS_HAS_EVICT_INODE
+	.evict_inode = yaffs_evict_inode,
+#else
+	.delete_inode = yaffs_delete_inode,
+	.clear_inode = yaffs_clear_inode,
+#endif
+	.sync_fs = yaffs_sync_fs,
+#ifdef YAFFS_HAS_WRITE_SUPER
+	.write_super = yaffs_write_super,
+#endif
+	.remount_fs = yaffs_remount_fs,
+};
+
+struct yaffs_options {
+	int inband_tags;
+	int skip_checkpoint_read;
+	int skip_checkpoint_write;
+	int no_cache;
+	int tags_ecc_on;
+	int tags_ecc_overridden;
+	int lazy_loading_enabled;
+	int lazy_loading_overridden;
+	int empty_lost_and_found;
+	int empty_lost_and_found_overridden;
+	int disable_summary;
+};
+
+#define MAX_OPT_LEN 30
+static int yaffs_parse_options(struct yaffs_options *options,
+			       const char *options_str)
+{
+	char cur_opt[MAX_OPT_LEN + 1];
+	int p;
+	int error = 0;
+
+	/* Parse through the options which is a comma seperated list */
+
+	while (options_str && *options_str && !error) {
+		memset(cur_opt, 0, MAX_OPT_LEN + 1);
+		p = 0;
+
+		while (*options_str == ',')
+			options_str++;
+
+		while (*options_str && *options_str != ',') {
+			if (p < MAX_OPT_LEN) {
+				cur_opt[p] = *options_str;
+				p++;
+			}
+			options_str++;
+		}
+
+		if (!strcmp(cur_opt, "inband-tags")) {
+			options->inband_tags = 1;
+		} else if (!strcmp(cur_opt, "tags-ecc-off")) {
+			options->tags_ecc_on = 0;
+			options->tags_ecc_overridden = 1;
+		} else if (!strcmp(cur_opt, "tags-ecc-on")) {
+			options->tags_ecc_on = 1;
+			options->tags_ecc_overridden = 1;
+		} else if (!strcmp(cur_opt, "lazy-loading-off")) {
+			options->lazy_loading_enabled = 0;
+			options->lazy_loading_overridden = 1;
+		} else if (!strcmp(cur_opt, "lazy-loading-on")) {
+			options->lazy_loading_enabled = 1;
+			options->lazy_loading_overridden = 1;
+		} else if (!strcmp(cur_opt, "disable-summary")) {
+			options->disable_summary = 1;
+		} else if (!strcmp(cur_opt, "empty-lost-and-found-off")) {
+			options->empty_lost_and_found = 0;
+			options->empty_lost_and_found_overridden = 1;
+		} else if (!strcmp(cur_opt, "empty-lost-and-found-on")) {
+			options->empty_lost_and_found = 1;
+			options->empty_lost_and_found_overridden = 1;
+		} else if (!strcmp(cur_opt, "no-cache")) {
+			options->no_cache = 1;
+		} else if (!strcmp(cur_opt, "no-checkpoint-read")) {
+			options->skip_checkpoint_read = 1;
+		} else if (!strcmp(cur_opt, "no-checkpoint-write")) {
+			options->skip_checkpoint_write = 1;
+		} else if (!strcmp(cur_opt, "no-checkpoint")) {
+			options->skip_checkpoint_read = 1;
+			options->skip_checkpoint_write = 1;
+		} else {
+			printk(KERN_INFO "yaffs: Bad mount option \"%s\"\n",
+			       cur_opt);
+			error = 1;
+		}
+	}
+
+	return error;
+}
+
+
+static struct dentry *yaffs_make_root(struct inode *inode)
+{
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 4, 0))
+	struct dentry *root = d_alloc_root(inode);
+
+	if (!root)
+		iput(inode);
+
+        return root;
+#else
+        return d_make_root(inode);
+#endif
+}
+
+
+
+
+static struct super_block *yaffs_internal_read_super(int yaffs_version,
+						     struct super_block *sb,
+						     void *data, int silent)
+{
+	int n_blocks;
+	struct inode *inode = NULL;
+	struct dentry *root;
+	struct yaffs_dev *dev = 0;
+	char devname_buf[BDEVNAME_SIZE + 1];
+	struct mtd_info *mtd;
+	int err;
+	char *data_str = (char *)data;
+	struct yaffs_linux_context *context = NULL;
+	struct yaffs_param *param;
+
+	int read_only = 0;
+	int inband_tags = 0;
+
+	struct yaffs_options options;
+
+	unsigned mount_id;
+	int found;
+	struct yaffs_linux_context *context_iterator;
+	struct list_head *l;
+
+	if (!sb) {
+		printk(KERN_INFO "yaffs: sb is NULL\n");
+		return NULL;
+        }
+
+	sb->s_magic = YAFFS_MAGIC;
+	sb->s_op = &yaffs_super_ops;
+	sb->s_flags |= MS_NOATIME;
+
+	read_only = ((sb->s_flags & MS_RDONLY) != 0);
+
+#ifdef YAFFS_COMPILE_EXPORTFS
+	sb->s_export_op = &yaffs_export_ops;
+#endif
+
+	if (!sb->s_dev)
+		printk(KERN_INFO "yaffs: sb->s_dev is NULL\n");
+	else if (!yaffs_devname(sb, devname_buf))
+		printk(KERN_INFO "yaffs: devname is NULL\n");
+	else
+		printk(KERN_INFO "yaffs: dev is %d name is \"%s\" %s\n",
+		       sb->s_dev,
+		       yaffs_devname(sb, devname_buf), read_only ? "ro" : "rw");
+
+	if (!data_str)
+		data_str = "";
+
+	printk(KERN_INFO "yaffs: passed flags \"%s\"\n", data_str);
+
+	memset(&options, 0, sizeof(options));
+
+	if (yaffs_parse_options(&options, data_str)) {
+		/* Option parsing failed */
+		return NULL;
+	}
+
+	sb->s_blocksize = PAGE_CACHE_SIZE;
+	sb->s_blocksize_bits = PAGE_CACHE_SHIFT;
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_read_super: Using yaffs%d", yaffs_version);
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_read_super: block size %d", (int)(sb->s_blocksize));
+
+	yaffs_trace(YAFFS_TRACE_ALWAYS,
+		"yaffs: Attempting MTD mount of %u.%u,\"%s\"",
+		MAJOR(sb->s_dev), MINOR(sb->s_dev),
+		yaffs_devname(sb, devname_buf));
+
+	/* Get the device */
+	mtd = get_mtd_device(NULL, MINOR(sb->s_dev));
+	if (IS_ERR(mtd)) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"yaffs: MTD device %u either not valid or unavailable",
+			MINOR(sb->s_dev));
+		return NULL;
+	}
+
+	if (yaffs_auto_select && yaffs_version == 1 && WRITE_SIZE(mtd) >= 2048) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS, "auto selecting yaffs2");
+		yaffs_version = 2;
+	}
+
+	/* Added NCB 26/5/2006 for completeness */
+	if (yaffs_version == 2 && !options.inband_tags
+	    && WRITE_SIZE(mtd) == 512) {
+		yaffs_trace(YAFFS_TRACE_ALWAYS, "auto selecting yaffs1");
+		yaffs_version = 1;
+	}
+
+	if (mtd->oobavail < sizeof(struct yaffs_packed_tags2) ||
+	    options.inband_tags)
+		inband_tags = 1;
+
+	if(yaffs_verify_mtd(mtd, yaffs_version, inband_tags) < 0)
+		return NULL;
+
+	/* OK, so if we got here, we have an MTD that's NAND and looks
+	 * like it has the right capabilities
+	 * Set the struct yaffs_dev up for mtd
+	 */
+
+	if (!read_only && !(mtd->flags & MTD_WRITEABLE)) {
+		read_only = 1;
+		printk(KERN_INFO
+		       "yaffs: mtd is read only, setting superblock read only\n"
+		);
+		sb->s_flags |= MS_RDONLY;
+	}
+
+	dev = kmalloc(sizeof(struct yaffs_dev), GFP_KERNEL);
+	context = kmalloc(sizeof(struct yaffs_linux_context), GFP_KERNEL);
+
+	if (!dev || !context) {
+		kfree(dev);
+		kfree(context);
+		dev = NULL;
+		context = NULL;
+
+		/* Deep shit could not allocate device structure */
+		yaffs_trace(YAFFS_TRACE_ALWAYS,
+			"yaffs_read_super: Failed trying to allocate struct yaffs_dev."
+		);
+		return NULL;
+	}
+	memset(dev, 0, sizeof(struct yaffs_dev));
+	param = &(dev->param);
+
+	memset(context, 0, sizeof(struct yaffs_linux_context));
+	dev->os_context = context;
+	INIT_LIST_HEAD(&(context->context_list));
+	context->dev = dev;
+	context->super = sb;
+
+	dev->read_only = read_only;
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+	sb->s_fs_info = dev;
+#else
+	sb->u.generic_sbp = dev;
+#endif
+
+
+	dev->driver_context = mtd;
+	param->name = mtd->name;
+
+	/* Set up the memory size parameters.... */
+
+
+	param->n_reserved_blocks = 5;
+	param->n_caches = (options.no_cache) ? 0 : 10;
+	param->inband_tags = inband_tags;
+
+	param->enable_xattr = 1;
+	if (options.lazy_loading_overridden)
+		param->disable_lazy_load = !options.lazy_loading_enabled;
+
+	param->defered_dir_update = 1;
+
+	if (options.tags_ecc_overridden)
+		param->no_tags_ecc = !options.tags_ecc_on;
+
+	param->empty_lost_n_found = 1;
+	param->refresh_period = 500;
+	param->disable_summary = options.disable_summary;
+
+
+#ifdef CONFIG_YAFFS_DISABLE_BAD_BLOCK_MARKING
+	param->disable_bad_block_marking  = 1;
+#endif
+	if (options.empty_lost_and_found_overridden)
+		param->empty_lost_n_found = options.empty_lost_and_found;
+
+	/* ... and the functions. */
+	if (yaffs_version == 2) {
+		param->is_yaffs2 = 1;
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 17))
+		param->total_bytes_per_chunk = mtd->writesize;
+		param->chunks_per_block = mtd->erasesize / mtd->writesize;
+#else
+		param->total_bytes_per_chunk = mtd->oobblock;
+		param->chunks_per_block = mtd->erasesize / mtd->oobblock;
+#endif
+		n_blocks = YCALCBLOCKS(mtd->size, mtd->erasesize);
+
+		param->start_block = 0;
+		param->end_block = n_blocks - 1;
+	} else {
+		param->is_yaffs2 = 0;
+		n_blocks = YCALCBLOCKS(mtd->size,
+			     YAFFS_CHUNKS_PER_BLOCK * YAFFS_BYTES_PER_CHUNK);
+
+		param->chunks_per_block = YAFFS_CHUNKS_PER_BLOCK;
+		param->total_bytes_per_chunk = YAFFS_BYTES_PER_CHUNK;
+	}
+
+	param->start_block = 0;
+	param->end_block = n_blocks - 1;
+
+	yaffs_mtd_drv_install(dev);
+
+	param->sb_dirty_fn = yaffs_set_super_dirty;
+	param->gc_control_fn = yaffs_gc_control_callback;
+
+	yaffs_dev_to_lc(dev)->super = sb;
+
+	param->use_nand_ecc = 1;
+
+	param->skip_checkpt_rd = options.skip_checkpoint_read;
+	param->skip_checkpt_wr = options.skip_checkpoint_write;
+
+	mutex_lock(&yaffs_context_lock);
+	/* Get a mount id */
+	found = 0;
+	for (mount_id = 0; !found; mount_id++) {
+		found = 1;
+		list_for_each(l, &yaffs_context_list) {
+			context_iterator =
+			    list_entry(l, struct yaffs_linux_context,
+				       context_list);
+			if (context_iterator->mount_id == mount_id)
+				found = 0;
+		}
+	}
+	context->mount_id = mount_id;
+
+	list_add_tail(&(yaffs_dev_to_lc(dev)->context_list),
+		      &yaffs_context_list);
+	mutex_unlock(&yaffs_context_lock);
+
+	/* Directory search handling... */
+	INIT_LIST_HEAD(&(yaffs_dev_to_lc(dev)->search_contexts));
+	param->remove_obj_fn = yaffs_remove_obj_callback;
+
+	mutex_init(&(yaffs_dev_to_lc(dev)->gross_lock));
+
+	yaffs_gross_lock(dev);
+
+	err = yaffs_guts_initialise(dev);
+
+	yaffs_trace(YAFFS_TRACE_OS,
+		"yaffs_read_super: guts initialised %s",
+		(err == YAFFS_OK) ? "OK" : "FAILED");
+
+	if (err == YAFFS_OK)
+		yaffs_bg_start(dev);
+
+	if (!context->bg_thread)
+		param->defered_dir_update = 0;
+
+	sb->s_maxbytes = yaffs_max_file_size(dev);
+
+	/* Release lock before yaffs_get_inode() */
+	yaffs_gross_unlock(dev);
+
+	/* Create root inode */
+	if (err == YAFFS_OK)
+		inode = yaffs_get_inode(sb, S_IFDIR | 0755, 0, yaffs_root(dev));
+
+	if (!inode)
+		return NULL;
+
+	inode->i_op = &yaffs_dir_inode_operations;
+	inode->i_fop = &yaffs_dir_operations;
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_read_super: got root inode");
+
+	root = yaffs_make_root(inode);
+
+	if (!root)
+		return NULL;
+
+	sb->s_root = root;
+	if(!dev->is_checkpointed)
+		yaffs_set_super_dirty(dev);
+
+	yaffs_trace(YAFFS_TRACE_ALWAYS,
+		"yaffs_read_super: is_checkpointed %d",
+		dev->is_checkpointed);
+
+	yaffs_trace(YAFFS_TRACE_OS, "yaffs_read_super: done");
+	return sb;
+}
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+static int yaffs_internal_read_super_mtd(struct super_block *sb, void *data,
+					 int silent)
+{
+	return yaffs_internal_read_super(1, sb, data, silent) ? 0 : -EINVAL;
+}
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 39))
+static struct dentry *yaffs_mount(struct file_system_type *fs_type, int flags,
+        const char *dev_name, void *data)
+{
+    return mount_bdev(fs_type, flags, dev_name, data, yaffs_internal_read_super_mtd);
+}
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 17))
+static int yaffs_read_super(struct file_system_type *fs,
+			    int flags, const char *dev_name,
+			    void *data, struct vfsmount *mnt)
+{
+
+	return get_sb_bdev(fs, flags, dev_name, data,
+			   yaffs_internal_read_super_mtd, mnt);
+}
+#else
+static struct super_block *yaffs_read_super(struct file_system_type *fs,
+					    int flags, const char *dev_name,
+					    void *data)
+{
+
+	return get_sb_bdev(fs, flags, dev_name, data,
+			   yaffs_internal_read_super_mtd);
+}
+#endif
+
+static struct file_system_type yaffs_fs_type = {
+	.owner = THIS_MODULE,
+	.name = "yaffs",
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 39))
+        .mount = yaffs_mount,
+#else
+        .get_sb = yaffs_read_super,
+#endif
+     	.kill_sb = kill_block_super,
+	.fs_flags = FS_REQUIRES_DEV,
+};
+#else
+static struct super_block *yaffs_read_super(struct super_block *sb, void *data,
+					    int silent)
+{
+	return yaffs_internal_read_super(1, sb, data, silent);
+}
+
+static DECLARE_FSTYPE(yaffs_fs_type, "yaffs", yaffs_read_super,
+		      FS_REQUIRES_DEV);
+#endif
+
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+static int yaffs2_internal_read_super_mtd(struct super_block *sb, void *data,
+					  int silent)
+{
+	return yaffs_internal_read_super(2, sb, data, silent) ? 0 : -EINVAL;
+}
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 39))
+static struct dentry *yaffs2_mount(struct file_system_type *fs_type, int flags,
+        const char *dev_name, void *data)
+{
+        return mount_bdev(fs_type, flags, dev_name, data, yaffs2_internal_read_super_mtd);
+}
+#elif (LINUX_VERSION_CODE > KERNEL_VERSION(2, 6, 17))
+static int yaffs2_read_super(struct file_system_type *fs,
+			     int flags, const char *dev_name, void *data,
+			     struct vfsmount *mnt)
+{
+	return get_sb_bdev(fs, flags, dev_name, data,
+			   yaffs2_internal_read_super_mtd, mnt);
+}
+#else
+static struct super_block *yaffs2_read_super(struct file_system_type *fs,
+					     int flags, const char *dev_name,
+					     void *data)
+{
+
+	return get_sb_bdev(fs, flags, dev_name, data,
+			   yaffs2_internal_read_super_mtd);
+}
+#endif
+
+static struct file_system_type yaffs2_fs_type = {
+	.owner = THIS_MODULE,
+	.name = "yaffs2",
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 39))
+        .mount = yaffs2_mount,
+#else
+        .get_sb = yaffs2_read_super,
+#endif
+     	.kill_sb = kill_block_super,
+	.fs_flags = FS_REQUIRES_DEV,
+};
+#else
+static struct super_block *yaffs2_read_super(struct super_block *sb,
+					     void *data, int silent)
+{
+	return yaffs_internal_read_super(2, sb, data, silent);
+}
+
+static DECLARE_FSTYPE(yaffs2_fs_type, "yaffs2", yaffs2_read_super,
+		      FS_REQUIRES_DEV);
+#endif
+
+
+static struct proc_dir_entry *my_proc_entry;
+
+static char *yaffs_dump_dev_part0(char *buf, struct yaffs_dev *dev)
+{
+	struct yaffs_param *param = &dev->param;
+	int bs[10];
+
+	yaffs_count_blocks_by_state(dev,bs);
+
+	buf += sprintf(buf, "start_block.......... %d\n", param->start_block);
+	buf += sprintf(buf, "end_block............ %d\n", param->end_block);
+	buf += sprintf(buf, "total_bytes_per_chunk %d\n",
+				param->total_bytes_per_chunk);
+	buf += sprintf(buf, "use_nand_ecc......... %d\n", param->use_nand_ecc);
+	buf += sprintf(buf, "no_tags_ecc.......... %d\n", param->no_tags_ecc);
+	buf += sprintf(buf, "is_yaffs2............ %d\n", param->is_yaffs2);
+	buf += sprintf(buf, "inband_tags.......... %d\n", param->inband_tags);
+	buf += sprintf(buf, "empty_lost_n_found... %d\n",
+				param->empty_lost_n_found);
+	buf += sprintf(buf, "disable_lazy_load.... %d\n",
+				param->disable_lazy_load);
+	buf += sprintf(buf, "disable_bad_block_mrk %d\n",
+				param->disable_bad_block_marking);
+	buf += sprintf(buf, "refresh_period....... %d\n",
+				param->refresh_period);
+	buf += sprintf(buf, "n_caches............. %d\n", param->n_caches);
+	buf += sprintf(buf, "n_reserved_blocks.... %d\n",
+				param->n_reserved_blocks);
+	buf += sprintf(buf, "always_check_erased.. %d\n",
+				param->always_check_erased);
+	buf += sprintf(buf, "\n");
+	buf += sprintf(buf, "block count by state\n");
+	buf += sprintf(buf, "0:%d 1:%d 2:%d 3:%d 4:%d\n",
+				bs[0], bs[1], bs[2], bs[3], bs[4]);
+	buf += sprintf(buf, "5:%d 6:%d 7:%d 8:%d 9:%d\n",
+				bs[5], bs[6], bs[7], bs[8], bs[9]);
+
+	return buf;
+}
+
+static char *yaffs_dump_dev_part1(char *buf, struct yaffs_dev *dev)
+{
+	buf += sprintf(buf, "max file size....... %lld\n",
+				(long long) yaffs_max_file_size(dev));
+	buf += sprintf(buf, "data_bytes_per_chunk. %d\n",
+				dev->data_bytes_per_chunk);
+	buf += sprintf(buf, "chunk_grp_bits....... %d\n", dev->chunk_grp_bits);
+	buf += sprintf(buf, "chunk_grp_size....... %d\n", dev->chunk_grp_size);
+	buf += sprintf(buf, "n_erased_blocks...... %d\n", dev->n_erased_blocks);
+	buf += sprintf(buf, "blocks_in_checkpt.... %d\n",
+				dev->blocks_in_checkpt);
+	buf += sprintf(buf, "\n");
+	buf += sprintf(buf, "n_tnodes............. %d\n", dev->n_tnodes);
+	buf += sprintf(buf, "n_obj................ %d\n", dev->n_obj);
+	buf += sprintf(buf, "n_free_chunks........ %d\n", dev->n_free_chunks);
+	buf += sprintf(buf, "\n");
+	buf += sprintf(buf, "n_page_writes........ %u\n", dev->n_page_writes);
+	buf += sprintf(buf, "n_page_reads......... %u\n", dev->n_page_reads);
+	buf += sprintf(buf, "n_erasures........... %u\n", dev->n_erasures);
+	buf += sprintf(buf, "n_gc_copies.......... %u\n", dev->n_gc_copies);
+	buf += sprintf(buf, "all_gcs.............. %u\n", dev->all_gcs);
+	buf += sprintf(buf, "passive_gc_count..... %u\n",
+				dev->passive_gc_count);
+	buf += sprintf(buf, "oldest_dirty_gc_count %u\n",
+				dev->oldest_dirty_gc_count);
+	buf += sprintf(buf, "n_gc_blocks.......... %u\n", dev->n_gc_blocks);
+	buf += sprintf(buf, "bg_gcs............... %u\n", dev->bg_gcs);
+	buf += sprintf(buf, "n_retried_writes..... %u\n",
+				dev->n_retried_writes);
+	buf += sprintf(buf, "n_retired_blocks..... %u\n",
+				dev->n_retired_blocks);
+	buf += sprintf(buf, "n_ecc_fixed.......... %u\n", dev->n_ecc_fixed);
+	buf += sprintf(buf, "n_ecc_unfixed........ %u\n", dev->n_ecc_unfixed);
+	buf += sprintf(buf, "n_tags_ecc_fixed..... %u\n",
+				dev->n_tags_ecc_fixed);
+	buf += sprintf(buf, "n_tags_ecc_unfixed... %u\n",
+				dev->n_tags_ecc_unfixed);
+	buf += sprintf(buf, "cache_hits........... %u\n", dev->cache_hits);
+	buf += sprintf(buf, "n_deleted_files...... %u\n", dev->n_deleted_files);
+	buf += sprintf(buf, "n_unlinked_files..... %u\n",
+				dev->n_unlinked_files);
+	buf += sprintf(buf, "refresh_count........ %u\n", dev->refresh_count);
+	buf += sprintf(buf, "n_bg_deletions....... %u\n", dev->n_bg_deletions);
+	buf += sprintf(buf, "tags_used............ %u\n", dev->tags_used);
+	buf += sprintf(buf, "summary_used......... %u\n", dev->summary_used);
+
+	return buf;
+}
+
+static int yaffs_proc_read(char *page,
+			   char **start,
+			   off_t offset, int count, int *eof, void *data)
+{
+	struct list_head *item;
+	char *buf = page;
+	int step = offset;
+	int n = 0;
+
+	/* Get proc_file_read() to step 'offset' by one on each sucessive call.
+	 * We use 'offset' (*ppos) to indicate where we are in dev_list.
+	 * This also assumes the user has posted a read buffer large
+	 * enough to hold the complete output; but that's life in /proc.
+	 */
+
+	*(int *)start = 1;
+
+	/* Print header first */
+	if (step == 0)
+		buf +=
+		    sprintf(buf, "Multi-version YAFFS\n");
+	else if (step == 1)
+		buf += sprintf(buf, "\n");
+	else {
+		step -= 2;
+
+		mutex_lock(&yaffs_context_lock);
+
+		/* Locate and print the Nth entry.  Order N-squared but N is small. */
+		list_for_each(item, &yaffs_context_list) {
+			struct yaffs_linux_context *dc =
+			    list_entry(item, struct yaffs_linux_context,
+				       context_list);
+			struct yaffs_dev *dev = dc->dev;
+
+			if (n < (step & ~1)) {
+				n += 2;
+				continue;
+			}
+			if ((step & 1) == 0) {
+				buf +=
+				    sprintf(buf, "\nDevice %d \"%s\"\n", n,
+					    dev->param.name);
+				buf = yaffs_dump_dev_part0(buf, dev);
+			} else {
+				buf = yaffs_dump_dev_part1(buf, dev);
+                        }
+
+			break;
+		}
+		mutex_unlock(&yaffs_context_lock);
+	}
+
+	return buf - page < count ? buf - page : count;
+}
+
+/**
+ * Set the verbosity of the warnings and error messages.
+ *
+ * Note that the names can only be a..z or _ with the current code.
+ */
+
+static struct {
+	char *mask_name;
+	unsigned mask_bitfield;
+} mask_flags[] = {
+	{"allocate", YAFFS_TRACE_ALLOCATE},
+	{"always", YAFFS_TRACE_ALWAYS},
+	{"background", YAFFS_TRACE_BACKGROUND},
+	{"bad_blocks", YAFFS_TRACE_BAD_BLOCKS},
+	{"buffers", YAFFS_TRACE_BUFFERS},
+	{"bug", YAFFS_TRACE_BUG},
+	{"checkpt", YAFFS_TRACE_CHECKPOINT},
+	{"deletion", YAFFS_TRACE_DELETION},
+	{"erase", YAFFS_TRACE_ERASE},
+	{"error", YAFFS_TRACE_ERROR},
+	{"gc_detail", YAFFS_TRACE_GC_DETAIL},
+	{"gc", YAFFS_TRACE_GC},
+	{"lock", YAFFS_TRACE_LOCK},
+	{"mtd", YAFFS_TRACE_MTD},
+	{"nandaccess", YAFFS_TRACE_NANDACCESS},
+	{"os", YAFFS_TRACE_OS},
+	{"scan_debug", YAFFS_TRACE_SCAN_DEBUG},
+	{"scan", YAFFS_TRACE_SCAN},
+	{"mount", YAFFS_TRACE_MOUNT},
+	{"tracing", YAFFS_TRACE_TRACING},
+	{"sync", YAFFS_TRACE_SYNC},
+	{"write", YAFFS_TRACE_WRITE},
+	{"verify", YAFFS_TRACE_VERIFY},
+	{"verify_nand", YAFFS_TRACE_VERIFY_NAND},
+	{"verify_full", YAFFS_TRACE_VERIFY_FULL},
+	{"verify_all", YAFFS_TRACE_VERIFY_ALL},
+	{"all", 0xffffffff},
+	{"none", 0},
+	{NULL, 0},
+};
+
+#define MAX_MASK_NAME_LENGTH 40
+static int yaffs_proc_write_trace_options(struct file *file, const char *buf,
+					  unsigned long count)
+{
+	unsigned rg = 0, mask_bitfield;
+	char *end;
+	char *mask_name;
+	const char *x;
+	char substring[MAX_MASK_NAME_LENGTH + 1];
+	int i;
+	int done = 0;
+	int add, len = 0;
+	int pos = 0;
+
+	rg = yaffs_trace_mask;
+
+	while (!done && (pos < count)) {
+		done = 1;
+		while ((pos < count) && isspace(buf[pos]))
+			pos++;
+
+		switch (buf[pos]) {
+		case '+':
+		case '-':
+		case '=':
+			add = buf[pos];
+			pos++;
+			break;
+
+		default:
+			add = ' ';
+			break;
+		}
+		mask_name = NULL;
+
+		mask_bitfield = simple_strtoul(buf + pos, &end, 0);
+
+		if (end > buf + pos) {
+			mask_name = "numeral";
+			len = end - (buf + pos);
+			pos += len;
+			done = 0;
+		} else {
+			for (x = buf + pos, i = 0;
+			     (*x == '_' || (*x >= 'a' && *x <= 'z')) &&
+			     i < MAX_MASK_NAME_LENGTH; x++, i++, pos++)
+				substring[i] = *x;
+			substring[i] = '\0';
+
+			for (i = 0; mask_flags[i].mask_name != NULL; i++) {
+				if (strcmp(substring, mask_flags[i].mask_name)
+				    == 0) {
+					mask_name = mask_flags[i].mask_name;
+					mask_bitfield =
+					    mask_flags[i].mask_bitfield;
+					done = 0;
+					break;
+				}
+			}
+		}
+
+		if (mask_name != NULL) {
+			done = 0;
+			switch (add) {
+			case '-':
+				rg &= ~mask_bitfield;
+				break;
+			case '+':
+				rg |= mask_bitfield;
+				break;
+			case '=':
+				rg = mask_bitfield;
+				break;
+			default:
+				rg |= mask_bitfield;
+				break;
+			}
+		}
+	}
+
+	yaffs_trace_mask = rg | YAFFS_TRACE_ALWAYS;
+
+	printk(KERN_DEBUG "new trace = 0x%08X\n", yaffs_trace_mask);
+
+	if (rg & YAFFS_TRACE_ALWAYS) {
+		for (i = 0; mask_flags[i].mask_name != NULL; i++) {
+			char flag;
+			flag = ((rg & mask_flags[i].mask_bitfield) ==
+				mask_flags[i].mask_bitfield) ? '+' : '-';
+			printk(KERN_DEBUG "%c%s\n", flag,
+			       mask_flags[i].mask_name);
+		}
+	}
+
+	return count;
+}
+
+/* Debug strings are of the form:
+ * .bnnn         print info on block n
+ * .cobjn,chunkn print nand chunk id for objn:chunkn
+ */
+
+static int yaffs_proc_debug_write(struct file *file, const char *buf,
+					  unsigned long count)
+{
+
+	char str[100];
+	char *p0;
+	char *p1;
+	long p1_val;
+	long p0_val;
+	char cmd;
+	struct list_head *item;
+
+	memset(str, 0, sizeof(str));
+	memcpy(str, buf, min((size_t)count, sizeof(str) -1));
+
+	cmd = str[1];
+
+	p0 = str + 2;
+
+	p1 = p0;
+
+	while (*p1 && *p1 != ',') {
+		p1++;
+	}
+	*p1 = '\0';
+	p1++;
+
+	p0_val = simple_strtol(p0, NULL, 0);
+	p1_val = simple_strtol(p1, NULL, 0);
+
+
+	mutex_lock(&yaffs_context_lock);
+
+	/* Locate and print the Nth entry.  Order N-squared but N is small. */
+	list_for_each(item, &yaffs_context_list) {
+		struct yaffs_linux_context *dc =
+		    list_entry(item, struct yaffs_linux_context,
+			       context_list);
+		struct yaffs_dev *dev = dc->dev;
+
+		if (cmd == 'b') {
+			struct yaffs_block_info *bi;
+
+			bi = yaffs_get_block_info(dev,p0_val);
+
+			if(bi) {
+				printk("Block %d: state %d, retire %d, use %d, seq %d\n",
+					(int)p0_val, bi->block_state,
+					bi->needs_retiring, bi->pages_in_use,
+					bi->seq_number);
+			}
+		} else if (cmd == 'c') {
+			struct yaffs_obj *obj;
+			int nand_chunk;
+
+			obj = yaffs_find_by_number(dev, p0_val);
+			if (!obj)
+				printk("No obj %d\n", (int)p0_val);
+			else {
+				if(p1_val == 0)
+					nand_chunk = obj->hdr_chunk;
+				else
+					nand_chunk =
+						yaffs_find_chunk_in_file(obj,
+							p1_val, NULL);
+				printk("Nand chunk for %d:%d is %d\n",
+					(int)p0_val, (int)p1_val, nand_chunk);
+			}
+		}
+	}
+
+	mutex_unlock(&yaffs_context_lock);
+
+	return count;
+}
+
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 14, 0))
+static int yaffs_proc_write(struct file *file, const char *buf,
+			    unsigned long count, void *ppos)
+#else
+static ssize_t yaffs_proc_write(struct file *file, const char __user *buf,
+			    size_t count, loff_t *ppos)
+#endif
+{
+	if (buf[0] == '.')
+		return yaffs_proc_debug_write(file, buf, count);
+	return yaffs_proc_write_trace_options(file, buf, count);
+}
+
+/* Stuff to handle installation of file systems */
+struct file_system_to_install {
+	struct file_system_type *fst;
+	int installed;
+};
+
+static struct file_system_to_install fs_to_install[] = {
+	{&yaffs_fs_type, 0},
+	{&yaffs2_fs_type, 0},
+	{NULL, 0}
+};
+
+
+#ifdef YAFFS_NEW_PROCFS
+static int yaffs_proc_show(struct seq_file *m, void *v)
+{
+	/* FIXME: Unify in a better way? */
+	char buffer[512];
+	char *start;
+	int len;
+
+	len = yaffs_proc_read(buffer, &start, 0, sizeof(buffer), NULL, NULL);
+	seq_puts(m, buffer);
+	return 0;
+}
+
+static int yaffs_proc_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, yaffs_proc_show, NULL);
+}
+
+static struct file_operations procfs_ops = {
+	.owner = THIS_MODULE,
+	.open  = yaffs_proc_open,
+	.read  = seq_read,
+	.write = yaffs_proc_write,
+};
+
+static int yaffs_procfs_init(void)
+{
+	/* Install the proc_fs entries */
+	my_proc_entry = proc_create("yaffs",
+				    S_IRUGO | S_IFREG,
+				    YPROC_ROOT,
+				    &procfs_ops);
+
+	if (my_proc_entry) {
+		return 0;
+	} else {
+		return -ENOMEM;
+	}
+}
+
+#else
+
+
+static int yaffs_procfs_init(void)
+{
+	/* Install the proc_fs entries */
+	my_proc_entry = create_proc_entry("yaffs",
+					  S_IRUGO | S_IFREG, YPROC_ROOT);
+
+	if (my_proc_entry) {
+		my_proc_entry->write_proc = yaffs_proc_write;
+		my_proc_entry->read_proc = yaffs_proc_read;
+		my_proc_entry->data = NULL;
+		return 0;
+	} else {
+		return -ENOMEM;
+	}
+}
+
+#endif
+
+
+static int __init init_yaffs_fs(void)
+{
+	int error = 0;
+	struct file_system_to_install *fsinst;
+
+	yaffs_trace(YAFFS_TRACE_ALWAYS,
+		"yaffs Installing.");
+
+	mutex_init(&yaffs_context_lock);
+
+	error = yaffs_procfs_init();
+	if (error)
+		return error;
+
+	/* Now add the file system entries */
+
+	fsinst = fs_to_install;
+
+	while (fsinst->fst && !error) {
+		error = register_filesystem(fsinst->fst);
+		if (!error)
+			fsinst->installed = 1;
+		fsinst++;
+	}
+
+	/* Any errors? uninstall  */
+	if (error) {
+		fsinst = fs_to_install;
+
+		while (fsinst->fst) {
+			if (fsinst->installed) {
+				unregister_filesystem(fsinst->fst);
+				fsinst->installed = 0;
+			}
+			fsinst++;
+		}
+	}
+
+	return error;
+}
+
+static void __exit exit_yaffs_fs(void)
+{
+
+	struct file_system_to_install *fsinst;
+
+	yaffs_trace(YAFFS_TRACE_ALWAYS,
+		"yaffs removing.");
+
+	remove_proc_entry("yaffs", YPROC_ROOT);
+
+	fsinst = fs_to_install;
+
+	while (fsinst->fst) {
+		if (fsinst->installed) {
+			unregister_filesystem(fsinst->fst);
+			fsinst->installed = 0;
+		}
+		fsinst++;
+	}
+}
+
+module_init(init_yaffs_fs)
+    module_exit(exit_yaffs_fs)
+
+    MODULE_DESCRIPTION("YAFFS2 - a NAND specific flash file system");
+MODULE_AUTHOR("Charles Manning, Aleph One Ltd., 2002-2011");
+MODULE_LICENSE("GPL");
diff --git a/fs/yaffs2/yaffs_yaffs1.c b/fs/yaffs2/yaffs_yaffs1.c
new file mode 100644
index 0000000..0cdc8c8
--- /dev/null
+++ b/fs/yaffs2/yaffs_yaffs1.c
@@ -0,0 +1,424 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include "yaffs_yaffs1.h"
+#include "yportenv.h"
+#include "yaffs_trace.h"
+#include "yaffs_bitmap.h"
+#include "yaffs_getblockinfo.h"
+#include "yaffs_nand.h"
+#include "yaffs_attribs.h"
+
+int yaffs1_scan(struct yaffs_dev *dev)
+{
+	struct yaffs_ext_tags tags;
+	u32 blk;
+	int result;
+	int chunk;
+	u32 c;
+	int deleted;
+	enum yaffs_block_state state;
+	LIST_HEAD(hard_list);
+	struct yaffs_block_info *bi;
+	u32 seq_number;
+	struct yaffs_obj_hdr *oh;
+	struct yaffs_obj *in;
+	struct yaffs_obj *parent;
+	int alloc_failed = 0;
+	struct yaffs_shadow_fixer *shadow_fixers = NULL;
+	u8 *chunk_data;
+
+	yaffs_trace(YAFFS_TRACE_SCAN,
+		"yaffs1_scan starts  intstartblk %d intendblk %d...",
+		dev->internal_start_block, dev->internal_end_block);
+
+	chunk_data = yaffs_get_temp_buffer(dev);
+
+	dev->seq_number = YAFFS_LOWEST_SEQUENCE_NUMBER;
+
+	/* Scan all the blocks to determine their state */
+	bi = dev->block_info;
+	for (blk = dev->internal_start_block; blk <= dev->internal_end_block;
+	     blk++) {
+		yaffs_clear_chunk_bits(dev, blk);
+		bi->pages_in_use = 0;
+		bi->soft_del_pages = 0;
+
+		yaffs_query_init_block_state(dev, blk, &state, &seq_number);
+
+		bi->block_state = state;
+		bi->seq_number = seq_number;
+
+		if (bi->seq_number == YAFFS_SEQUENCE_BAD_BLOCK)
+			bi->block_state = state = YAFFS_BLOCK_STATE_DEAD;
+
+		yaffs_trace(YAFFS_TRACE_SCAN_DEBUG,
+			"Block scanning block %d state %d seq %d",
+			blk, state, seq_number);
+
+		if (state == YAFFS_BLOCK_STATE_DEAD) {
+			yaffs_trace(YAFFS_TRACE_BAD_BLOCKS,
+				"block %d is bad", blk);
+		} else if (state == YAFFS_BLOCK_STATE_EMPTY) {
+			yaffs_trace(YAFFS_TRACE_SCAN_DEBUG, "Block empty ");
+			dev->n_erased_blocks++;
+			dev->n_free_chunks += dev->param.chunks_per_block;
+		}
+		bi++;
+	}
+
+	/* For each block.... */
+	for (blk = dev->internal_start_block;
+	     !alloc_failed && blk <= dev->internal_end_block; blk++) {
+
+		cond_resched();
+
+		bi = yaffs_get_block_info(dev, blk);
+		state = bi->block_state;
+
+		deleted = 0;
+
+		/* For each chunk in each block that needs scanning.... */
+		for (c = 0;
+			!alloc_failed && c < dev->param.chunks_per_block &&
+			state == YAFFS_BLOCK_STATE_NEEDS_SCAN; c++) {
+			/* Read the tags and decide what to do */
+			chunk = blk * dev->param.chunks_per_block + c;
+
+			result = yaffs_rd_chunk_tags_nand(dev, chunk, NULL,
+							  &tags);
+
+			if (result != YAFFS_OK)
+				continue;
+			/* Let's have a good look at this chunk... */
+
+			if (tags.ecc_result == YAFFS_ECC_RESULT_UNFIXED ||
+			    tags.is_deleted) {
+				/* YAFFS1 only...
+				 * A deleted chunk
+				 */
+				deleted++;
+				dev->n_free_chunks++;
+			} else if (!tags.chunk_used) {
+				/* An unassigned chunk in the block
+				 * This means that either the block is empty or
+				 * this is the one being allocated from
+				 */
+
+				if (c == 0) {
+					/* We're looking at the first chunk in
+					 *the block so the block is unused */
+					state = YAFFS_BLOCK_STATE_EMPTY;
+					dev->n_erased_blocks++;
+				} else {
+					/* this is the block being allocated */
+					yaffs_trace(YAFFS_TRACE_SCAN,
+						" Allocating from %d %d",
+						blk, c);
+					state = YAFFS_BLOCK_STATE_ALLOCATING;
+					dev->alloc_block = blk;
+					dev->alloc_page = c;
+					dev->alloc_block_finder = blk;
+
+				}
+
+				dev->n_free_chunks +=
+				    (dev->param.chunks_per_block - c);
+			} else if (tags.chunk_id > 0) {
+				/* chunk_id > 0 so it is a data chunk... */
+				unsigned int endpos;
+
+				yaffs_set_chunk_bit(dev, blk, c);
+				bi->pages_in_use++;
+
+				in = yaffs_find_or_create_by_number(dev,
+							tags.obj_id,
+							YAFFS_OBJECT_TYPE_FILE);
+				/* PutChunkIntoFile checks for a clash
+				 * (two data chunks with the same chunk_id).
+				 */
+
+				if (!in)
+					alloc_failed = 1;
+
+				if (in) {
+					if (!yaffs_put_chunk_in_file
+					    (in, tags.chunk_id, chunk, 1))
+						alloc_failed = 1;
+				}
+
+				endpos =
+				    (tags.chunk_id - 1) *
+				    dev->data_bytes_per_chunk +
+				    tags.n_bytes;
+				if (in &&
+				    in->variant_type ==
+				     YAFFS_OBJECT_TYPE_FILE &&
+				    in->variant.file_variant.stored_size <
+				      endpos) {
+					in->variant.file_variant.stored_size =
+					    endpos;
+					if (!dev->param.use_header_file_size) {
+						in->variant.
+						    file_variant.file_size =
+						    in->variant.
+						    file_variant.stored_size;
+					}
+
+				}
+			} else {
+				/* chunk_id == 0, so it is an ObjectHeader.
+				 * Make the object
+				 */
+				yaffs_set_chunk_bit(dev, blk, c);
+				bi->pages_in_use++;
+
+				result = yaffs_rd_chunk_tags_nand(dev, chunk,
+								  chunk_data,
+								  NULL);
+
+				oh = (struct yaffs_obj_hdr *)chunk_data;
+
+				in = yaffs_find_by_number(dev, tags.obj_id);
+				if (in && in->variant_type != oh->type) {
+					/* This should not happen, but somehow
+					 * Wev'e ended up with an obj_id that
+					 * has been reused but not yet deleted,
+					 * and worse still it has changed type.
+					 * Delete the old object.
+					 */
+
+					yaffs_del_obj(in);
+					in = NULL;
+				}
+
+				in = yaffs_find_or_create_by_number(dev,
+								tags.obj_id,
+								oh->type);
+
+				if (!in)
+					alloc_failed = 1;
+
+				if (in && oh->shadows_obj > 0) {
+
+					struct yaffs_shadow_fixer *fixer;
+					fixer =
+						kmalloc(sizeof
+						(struct yaffs_shadow_fixer),
+						GFP_NOFS);
+					if (fixer) {
+						fixer->next = shadow_fixers;
+						shadow_fixers = fixer;
+						fixer->obj_id = tags.obj_id;
+						fixer->shadowed_id =
+						    oh->shadows_obj;
+						yaffs_trace(YAFFS_TRACE_SCAN,
+							" Shadow fixer: %d shadows %d",
+							fixer->obj_id,
+							fixer->shadowed_id);
+
+					}
+
+				}
+
+				if (in && in->valid) {
+					/* We have already filled this one.
+					 * We have a duplicate and need to
+					 * resolve it. */
+
+					unsigned existing_serial = in->serial;
+					unsigned new_serial =
+					    tags.serial_number;
+
+					if (((existing_serial + 1) & 3) ==
+					    new_serial) {
+						/* Use new one - destroy the
+						 * exisiting one */
+						yaffs_chunk_del(dev,
+								in->hdr_chunk,
+								1, __LINE__);
+						in->valid = 0;
+					} else {
+						/* Use existing - destroy
+						 * this one. */
+						yaffs_chunk_del(dev, chunk, 1,
+								__LINE__);
+					}
+				}
+
+				if (in && !in->valid &&
+				    (tags.obj_id == YAFFS_OBJECTID_ROOT ||
+				     tags.obj_id ==
+				     YAFFS_OBJECTID_LOSTNFOUND)) {
+					/* We only load some info, don't fiddle
+					 * with directory structure */
+					in->valid = 1;
+					in->variant_type = oh->type;
+
+					in->yst_mode = oh->yst_mode;
+					yaffs_load_attribs(in, oh);
+					in->hdr_chunk = chunk;
+					in->serial = tags.serial_number;
+
+				} else if (in && !in->valid) {
+					/* we need to load this info */
+
+					in->valid = 1;
+					in->variant_type = oh->type;
+
+					in->yst_mode = oh->yst_mode;
+					yaffs_load_attribs(in, oh);
+					in->hdr_chunk = chunk;
+					in->serial = tags.serial_number;
+
+					yaffs_set_obj_name_from_oh(in, oh);
+					in->dirty = 0;
+
+					/* directory stuff...
+					 * hook up to parent
+					 */
+
+					parent =
+					    yaffs_find_or_create_by_number
+					    (dev, oh->parent_obj_id,
+					     YAFFS_OBJECT_TYPE_DIRECTORY);
+					if (!parent)
+						alloc_failed = 1;
+					if (parent && parent->variant_type ==
+					    YAFFS_OBJECT_TYPE_UNKNOWN) {
+						/* Set up as a directory */
+						parent->variant_type =
+						    YAFFS_OBJECT_TYPE_DIRECTORY;
+						INIT_LIST_HEAD(&parent->
+							variant.dir_variant.
+							children);
+					} else if (!parent ||
+						parent->variant_type !=
+						YAFFS_OBJECT_TYPE_DIRECTORY) {
+						/* Hoosterman, a problem....
+						 * We're trying to use a
+						 * non-directory as a directory
+						 */
+
+						yaffs_trace(YAFFS_TRACE_ERROR,
+							"yaffs tragedy: attempting to use non-directory as a directory in scan. Put in lost+found."
+							);
+						parent = dev->lost_n_found;
+					}
+
+					yaffs_add_obj_to_dir(parent, in);
+
+					switch (in->variant_type) {
+					case YAFFS_OBJECT_TYPE_UNKNOWN:
+						/* Todo got a problem */
+						break;
+					case YAFFS_OBJECT_TYPE_FILE:
+						if (dev->param.
+						    use_header_file_size)
+							in->variant.
+							file_variant.file_size
+							= yaffs_oh_to_size(dev, oh, 0);
+						break;
+					case YAFFS_OBJECT_TYPE_HARDLINK:
+						in->variant.
+						    hardlink_variant.equiv_id =
+						    oh->equiv_id;
+						list_add(&in->hard_links,
+								&hard_list);
+						break;
+					case YAFFS_OBJECT_TYPE_DIRECTORY:
+						/* Do nothing */
+						break;
+					case YAFFS_OBJECT_TYPE_SPECIAL:
+						/* Do nothing */
+						break;
+					case YAFFS_OBJECT_TYPE_SYMLINK:
+						in->variant.symlink_variant.
+						    alias =
+						    yaffs_clone_str(oh->alias);
+						if (!in->variant.
+						    symlink_variant.alias)
+							alloc_failed = 1;
+						break;
+					}
+				}
+			}
+		}
+
+		if (state == YAFFS_BLOCK_STATE_NEEDS_SCAN) {
+			/* If we got this far while scanning,
+			 * then the block is fully allocated. */
+			state = YAFFS_BLOCK_STATE_FULL;
+		}
+
+		if (state == YAFFS_BLOCK_STATE_ALLOCATING) {
+			/* If the block was partially allocated then
+			 * treat it as fully allocated. */
+			state = YAFFS_BLOCK_STATE_FULL;
+			dev->alloc_block = -1;
+		}
+
+		bi->block_state = state;
+
+		/* Now let's see if it was dirty */
+		if (bi->pages_in_use == 0 &&
+		    !bi->has_shrink_hdr &&
+		    bi->block_state == YAFFS_BLOCK_STATE_FULL)
+			yaffs_block_became_dirty(dev, blk);
+	}
+
+	/* Ok, we've done all the scanning.
+	 * Fix up the hard link chains.
+	 * We should now have scanned all the objects, now it's time to add
+	 * these hardlinks.
+	 */
+
+	yaffs_link_fixup(dev, &hard_list);
+
+	/*
+	 * Fix up any shadowed objects.
+	 * There should not be more than one of these.
+	 */
+	{
+		struct yaffs_shadow_fixer *fixer;
+		struct yaffs_obj *obj;
+
+		while (shadow_fixers) {
+			fixer = shadow_fixers;
+			shadow_fixers = fixer->next;
+			/* Complete the rename transaction by deleting the
+			 * shadowed object then setting the object header
+			 to unshadowed.
+			 */
+			obj = yaffs_find_by_number(dev, fixer->shadowed_id);
+			if (obj)
+				yaffs_del_obj(obj);
+
+			obj = yaffs_find_by_number(dev, fixer->obj_id);
+
+			if (obj)
+				yaffs_update_oh(obj, NULL, 1, 0, 0, NULL);
+
+			kfree(fixer);
+		}
+	}
+
+	yaffs_release_temp_buffer(dev, chunk_data);
+
+	if (alloc_failed)
+		return YAFFS_FAIL;
+
+	yaffs_trace(YAFFS_TRACE_SCAN, "yaffs1_scan ends");
+
+	return YAFFS_OK;
+}
diff --git a/fs/yaffs2/yaffs_yaffs1.h b/fs/yaffs2/yaffs_yaffs1.h
new file mode 100644
index 0000000..97e2fdd
--- /dev/null
+++ b/fs/yaffs2/yaffs_yaffs1.h
@@ -0,0 +1,22 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_YAFFS1_H__
+#define __YAFFS_YAFFS1_H__
+
+#include "yaffs_guts.h"
+int yaffs1_scan(struct yaffs_dev *dev);
+
+#endif
diff --git a/fs/yaffs2/yaffs_yaffs2.c b/fs/yaffs2/yaffs_yaffs2.c
new file mode 100644
index 0000000..47fa8eb
--- /dev/null
+++ b/fs/yaffs2/yaffs_yaffs2.c
@@ -0,0 +1,1712 @@
+/*
+ * YAFFS: Yet Another Flash File System. A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include "yaffs_guts.h"
+#include "yaffs_trace.h"
+#include "yaffs_yaffs2.h"
+#include "yaffs_checkptrw.h"
+#include "yaffs_bitmap.h"
+#include "yaffs_nand.h"
+#include "yaffs_getblockinfo.h"
+#include "yaffs_verify.h"
+#include "yaffs_attribs.h"
+#include "yaffs_summary.h"
+#include "yaffs_endian.h"
+
+/*
+ * Checkpoints are really no benefit on very small partitions.
+ *
+ * To save space on small partitions don't bother with checkpoints unless
+ * the partition is at least this big.
+ */
+#define YAFFS_CHECKPOINT_MIN_BLOCKS 60
+#define YAFFS_SMALL_HOLE_THRESHOLD 4
+
+/*
+ * Oldest Dirty Sequence Number handling.
+ */
+
+/* yaffs_calc_oldest_dirty_seq()
+ * yaffs2_find_oldest_dirty_seq()
+ * Calculate the oldest dirty sequence number if we don't know it.
+ */
+void yaffs_calc_oldest_dirty_seq(struct yaffs_dev *dev)
+{
+	u32 i;
+	unsigned seq;
+	unsigned block_no = 0;
+	struct yaffs_block_info *b;
+
+	if (!dev->param.is_yaffs2)
+		return;
+
+	/* Find the oldest dirty sequence number. */
+	seq = dev->seq_number + 1;
+	b = dev->block_info;
+	for (i = dev->internal_start_block; i <= dev->internal_end_block; i++) {
+		if (b->block_state == YAFFS_BLOCK_STATE_FULL &&
+		    (u32)(b->pages_in_use - b->soft_del_pages) <
+		    dev->param.chunks_per_block &&
+		    b->seq_number < seq) {
+			seq = b->seq_number;
+			block_no = i;
+		}
+		b++;
+	}
+
+	if (block_no) {
+		dev->oldest_dirty_seq = seq;
+		dev->oldest_dirty_block = block_no;
+	}
+}
+
+void yaffs2_find_oldest_dirty_seq(struct yaffs_dev *dev)
+{
+	if (!dev->param.is_yaffs2)
+		return;
+
+	if (!dev->oldest_dirty_seq)
+		yaffs_calc_oldest_dirty_seq(dev);
+}
+
+/*
+ * yaffs_clear_oldest_dirty_seq()
+ * Called when a block is erased or marked bad. (ie. when its seq_number
+ * becomes invalid). If the value matches the oldest then we clear
+ * dev->oldest_dirty_seq to force its recomputation.
+ */
+void yaffs2_clear_oldest_dirty_seq(struct yaffs_dev *dev,
+				   struct yaffs_block_info *bi)
+{
+
+	if (!dev->param.is_yaffs2)
+		return;
+
+	if (!bi || bi->seq_number == dev->oldest_dirty_seq) {
+		dev->oldest_dirty_seq = 0;
+		dev->oldest_dirty_block = 0;
+	}
+}
+
+/*
+ * yaffs2_update_oldest_dirty_seq()
+ * Update the oldest dirty sequence number whenever we dirty a block.
+ * Only do this if the oldest_dirty_seq is actually being tracked.
+ */
+void yaffs2_update_oldest_dirty_seq(struct yaffs_dev *dev, unsigned block_no,
+				    struct yaffs_block_info *bi)
+{
+	if (!dev->param.is_yaffs2)
+		return;
+
+	if (dev->oldest_dirty_seq) {
+		if (dev->oldest_dirty_seq > bi->seq_number) {
+			dev->oldest_dirty_seq = bi->seq_number;
+			dev->oldest_dirty_block = block_no;
+		}
+	}
+}
+
+int yaffs_block_ok_for_gc(struct yaffs_dev *dev, struct yaffs_block_info *bi)
+{
+
+	if (!dev->param.is_yaffs2)
+		return 1;	/* disqualification only applies to yaffs2. */
+
+	if (!bi->has_shrink_hdr)
+		return 1;	/* can gc */
+
+	yaffs2_find_oldest_dirty_seq(dev);
+
+	/* Can't do gc of this block if there are any blocks older than this
+	 * one that have discarded pages.
+	 */
+	return (bi->seq_number <= dev->oldest_dirty_seq);
+}
+
+/*
+ * yaffs2_find_refresh_block()
+ * periodically finds the oldest full block by sequence number for refreshing.
+ * Only for yaffs2.
+ */
+u32 yaffs2_find_refresh_block(struct yaffs_dev *dev)
+{
+	u32 b;
+	u32 oldest = 0;
+	u32 oldest_seq = 0;
+	struct yaffs_block_info *bi;
+
+	if (!dev->param.is_yaffs2)
+		return oldest;
+
+	/*
+	 * If refresh period < 10 then refreshing is disabled.
+	 */
+	if (dev->param.refresh_period < 10)
+		return oldest;
+
+	/*
+	 * Fix broken values.
+	 */
+	if (dev->refresh_skip > dev->param.refresh_period)
+		dev->refresh_skip = dev->param.refresh_period;
+
+	if (dev->refresh_skip > 0)
+		return oldest;
+
+	/*
+	 * Refresh skip is now zero.
+	 * We'll do a refresh this time around....
+	 * Update the refresh skip and find the oldest block.
+	 */
+	dev->refresh_skip = dev->param.refresh_period;
+	dev->refresh_count++;
+	bi = dev->block_info;
+	for (b = dev->internal_start_block; b <= dev->internal_end_block; b++) {
+
+		if (bi->block_state == YAFFS_BLOCK_STATE_FULL) {
+
+			if (oldest < 1 || bi->seq_number < oldest_seq) {
+				oldest = b;
+				oldest_seq = bi->seq_number;
+			}
+		}
+		bi++;
+	}
+
+	if (oldest > 0) {
+		yaffs_trace(YAFFS_TRACE_GC,
+			"GC refresh count %d selected block %d with seq_number %d",
+			dev->refresh_count, oldest, oldest_seq);
+	}
+
+	return oldest;
+}
+
+int yaffs2_checkpt_required(struct yaffs_dev *dev)
+{
+	int nblocks;
+
+	if (!dev->param.is_yaffs2)
+		return 0;
+
+	nblocks = dev->internal_end_block - dev->internal_start_block + 1;
+
+	return !dev->param.skip_checkpt_wr &&
+	    !dev->read_only && (nblocks >= YAFFS_CHECKPOINT_MIN_BLOCKS);
+}
+
+int yaffs_calc_checkpt_blocks_required(struct yaffs_dev *dev)
+{
+	int retval;
+	int n_bytes = 0;
+	int n_blocks;
+	int dev_blocks;
+
+	if (!dev->param.is_yaffs2)
+		return 0;
+
+	if (!dev->checkpoint_blocks_required && yaffs2_checkpt_required(dev)) {
+		/* Not a valid value so recalculate */
+		dev_blocks = dev->param.end_block - dev->param.start_block + 1;
+		n_bytes += sizeof(struct yaffs_checkpt_validity);
+		n_bytes += sizeof(struct yaffs_checkpt_dev);
+		n_bytes += dev_blocks * sizeof(struct yaffs_block_info);
+		n_bytes += dev_blocks * dev->chunk_bit_stride;
+		n_bytes +=
+		    (sizeof(struct yaffs_checkpt_obj) + sizeof(u32)) *
+		    dev->n_obj;
+		n_bytes += (dev->tnode_size + sizeof(u32)) * dev->n_tnodes;
+		n_bytes += sizeof(struct yaffs_checkpt_validity);
+		n_bytes += sizeof(u32);	/* checksum */
+
+		/* Round up and add 2 blocks to allow for some bad blocks,
+		 * so add 3 */
+
+		n_blocks =
+		    (n_bytes /
+		     (dev->data_bytes_per_chunk *
+		      dev->param.chunks_per_block)) + 3;
+
+		dev->checkpoint_blocks_required = n_blocks;
+	}
+
+	retval = dev->checkpoint_blocks_required - dev->blocks_in_checkpt;
+	if (retval < 0)
+		retval = 0;
+	return retval;
+}
+
+/*--------------------- Checkpointing --------------------*/
+
+static void yaffs2_do_endian_validity_marker(struct yaffs_dev *dev,
+					     struct yaffs_checkpt_validity *v)
+{
+
+	if (!dev->swap_endian)
+		return;
+	v->struct_type = swap_s32(v->struct_type);
+	v->magic = swap_u32(v->magic);
+	v->version = swap_u32(v->version);
+	v->head = swap_u32(v->head);
+}
+
+static int yaffs2_wr_checkpt_validity_marker(struct yaffs_dev *dev, int head)
+{
+	struct yaffs_checkpt_validity cp;
+
+	memset(&cp, 0, sizeof(cp));
+
+	cp.struct_type = sizeof(cp);
+	cp.magic = YAFFS_MAGIC;
+	cp.version = YAFFS_CHECKPOINT_VERSION;
+	cp.head = (head) ? 1 : 0;
+
+	yaffs2_do_endian_validity_marker(dev, &cp);
+
+	return (yaffs2_checkpt_wr(dev, &cp, sizeof(cp)) == sizeof(cp)) ? 1 : 0;
+}
+
+static int yaffs2_rd_checkpt_validity_marker(struct yaffs_dev *dev, int head)
+{
+	struct yaffs_checkpt_validity cp;
+	int ok;
+
+	ok = (yaffs2_checkpt_rd(dev, &cp, sizeof(cp)) == sizeof(cp));
+	yaffs2_do_endian_validity_marker(dev, &cp);
+
+	if (ok)
+		ok = (cp.struct_type == sizeof(cp)) &&
+		    (cp.magic == YAFFS_MAGIC) &&
+		    (cp.version == YAFFS_CHECKPOINT_VERSION) &&
+		    (cp.head == ((head) ? 1 : 0));
+	return ok ? 1 : 0;
+}
+
+static void yaffs2_dev_to_checkpt_dev(struct yaffs_checkpt_dev *cp,
+				      struct yaffs_dev *dev)
+{
+	cp->struct_type = sizeof(*cp);
+
+	cp->n_erased_blocks = dev->n_erased_blocks;
+	cp->alloc_block = dev->alloc_block;
+	cp->alloc_page = dev->alloc_page;
+	cp->n_free_chunks = dev->n_free_chunks;
+
+	cp->n_deleted_files = dev->n_deleted_files;
+	cp->n_unlinked_files = dev->n_unlinked_files;
+	cp->n_bg_deletions = dev->n_bg_deletions;
+	cp->seq_number = dev->seq_number;
+
+}
+
+static void yaffs_checkpt_dev_to_dev(struct yaffs_dev *dev,
+				     struct yaffs_checkpt_dev *cp)
+{
+	dev->n_erased_blocks = cp->n_erased_blocks;
+	dev->alloc_block = cp->alloc_block;
+	dev->alloc_page = cp->alloc_page;
+	dev->n_free_chunks = cp->n_free_chunks;
+
+	dev->n_deleted_files = cp->n_deleted_files;
+	dev->n_unlinked_files = cp->n_unlinked_files;
+	dev->n_bg_deletions = cp->n_bg_deletions;
+	dev->seq_number = cp->seq_number;
+}
+
+static void yaffs2_do_endian_checkpt_dev(struct yaffs_dev *dev,
+				     struct yaffs_checkpt_dev *cp)
+{
+	if (!dev->swap_endian)
+		return;
+	cp->struct_type = swap_s32(cp->struct_type);
+	cp->n_erased_blocks = swap_s32(cp->n_erased_blocks);
+	cp->alloc_block = swap_s32(cp->alloc_block);
+	cp->alloc_page = swap_u32(cp->alloc_page);
+	cp->n_free_chunks = swap_s32(cp->n_free_chunks);
+	cp->n_deleted_files = swap_s32(cp->n_deleted_files);
+	cp->n_unlinked_files = swap_s32(cp->n_unlinked_files);
+	cp->n_bg_deletions = swap_s32(cp->n_bg_deletions);
+}
+
+static int yaffs2_wr_checkpt_dev(struct yaffs_dev *dev)
+{
+	struct yaffs_checkpt_dev cp;
+	u32 n_bytes;
+	u32 n_blocks = dev->internal_end_block - dev->internal_start_block + 1;
+	int ok;
+	u32 i;
+	union yaffs_block_info_union bu;
+
+	/* Write device runtime values */
+	yaffs2_dev_to_checkpt_dev(&cp, dev);
+	yaffs2_do_endian_checkpt_dev(dev, &cp);
+
+	ok = (yaffs2_checkpt_wr(dev, &cp, sizeof(cp)) == sizeof(cp));
+	if (!ok)
+		return 0;
+
+	/* Write block info. */
+	if (!dev->swap_endian) {
+		n_bytes = n_blocks * sizeof(struct yaffs_block_info);
+		ok = (yaffs2_checkpt_wr(dev, dev->block_info, n_bytes) ==
+			(int)n_bytes);
+	} else {
+		/*
+		 * Need to swap the endianisms. We can't do this in place
+		 * since that would damage live data,
+		 * so write one block info at a time using a copy.
+		 */
+		for (i = 0; i < n_blocks && ok; i++) {
+			bu.bi = dev->block_info[i];
+			bu.as_u32[0] = swap_u32(bu.as_u32[0]);
+			bu.as_u32[1] = swap_u32(bu.as_u32[1]);
+			ok = (yaffs2_checkpt_wr(dev, &bu, sizeof(bu)) == sizeof(bu));
+		}
+	}
+
+	if (!ok)
+		return 0;
+
+	/*
+	 * Write chunk bits. Chunk bits are in bytes so
+	 * no endian conversion is needed.
+	 */
+	n_bytes = n_blocks * dev->chunk_bit_stride;
+	ok = (yaffs2_checkpt_wr(dev, dev->chunk_bits, n_bytes) ==
+		(int)n_bytes);
+
+	return ok ? 1 : 0;
+}
+
+static int yaffs2_rd_checkpt_dev(struct yaffs_dev *dev)
+{
+	struct yaffs_checkpt_dev cp;
+	u32 n_bytes;
+	u32 n_blocks =
+	    (dev->internal_end_block - dev->internal_start_block + 1);
+	int ok;
+
+	ok = (yaffs2_checkpt_rd(dev, &cp, sizeof(cp)) == sizeof(cp));
+	if (!ok)
+		return 0;
+	yaffs2_do_endian_checkpt_dev(dev, &cp);
+
+	if (cp.struct_type != sizeof(cp))
+		return 0;
+
+	yaffs_checkpt_dev_to_dev(dev, &cp);
+
+	n_bytes = n_blocks * sizeof(struct yaffs_block_info);
+
+	ok = (yaffs2_checkpt_rd(dev, dev->block_info, n_bytes) ==
+		(int)n_bytes);
+
+	if (!ok)
+		return 0;
+
+	if (dev->swap_endian) {
+		/* The block info can just be handled as a list of u32s. */
+		u32 *as_u32 = (u32 *) dev->block_info;
+		u32 n_u32s = n_bytes/sizeof(u32);
+		u32 i;
+
+		for (i=0; i < n_u32s; i++)
+			as_u32[i] = swap_u32(as_u32[i]);
+	}
+
+	n_bytes = n_blocks * dev->chunk_bit_stride;
+
+	ok = (yaffs2_checkpt_rd(dev, dev->chunk_bits, n_bytes) ==
+		(int)n_bytes);
+
+
+	return ok ? 1 : 0;
+}
+
+
+static void yaffs2_checkpt_obj_bit_assign(struct yaffs_checkpt_obj *cp,
+					  int bit_offset,
+					  int bit_width,
+					  u32 value)
+{
+	u32 and_mask;
+
+	and_mask = ((1<<bit_width)-1) << bit_offset;
+
+	cp->bit_field &= ~and_mask;
+	cp->bit_field |= ((value << bit_offset) & and_mask);
+}
+
+static u32 yaffs2_checkpt_obj_bit_get(struct yaffs_checkpt_obj *cp,
+				      int bit_offset,
+				      int bit_width)
+{
+	u32 and_mask;
+
+	and_mask = ((1<<bit_width)-1);
+
+	return (cp->bit_field >> bit_offset) & and_mask;
+}
+
+static void yaffs2_obj_checkpt_obj(struct yaffs_checkpt_obj *cp,
+				   struct yaffs_obj *obj)
+{
+	cp->obj_id = obj->obj_id;
+	cp->parent_id = (obj->parent) ? obj->parent->obj_id : 0;
+	cp->hdr_chunk = obj->hdr_chunk;
+
+	yaffs2_checkpt_obj_bit_assign(cp, CHECKPOINT_VARIANT_BITS, obj->variant_type);
+	yaffs2_checkpt_obj_bit_assign(cp, CHECKPOINT_DELETED_BITS, obj->deleted);
+	yaffs2_checkpt_obj_bit_assign(cp, CHECKPOINT_SOFT_DEL_BITS, obj->soft_del);
+	yaffs2_checkpt_obj_bit_assign(cp, CHECKPOINT_UNLINKED_BITS, obj->unlinked);
+	yaffs2_checkpt_obj_bit_assign(cp, CHECKPOINT_FAKE_BITS, obj->fake);
+	yaffs2_checkpt_obj_bit_assign(cp, CHECKPOINT_RENAME_ALLOWED_BITS, obj->rename_allowed);
+	yaffs2_checkpt_obj_bit_assign(cp, CHECKPOINT_UNLINK_ALLOWED_BITS, obj->unlink_allowed);
+	yaffs2_checkpt_obj_bit_assign(cp, CHECKPOINT_SERIAL_BITS, obj->serial);
+
+	cp->n_data_chunks = obj->n_data_chunks;
+
+	if (obj->variant_type == YAFFS_OBJECT_TYPE_FILE)
+		cp->size_or_equiv_obj = obj->variant.file_variant.file_size;
+	else if (obj->variant_type == YAFFS_OBJECT_TYPE_HARDLINK)
+		cp->size_or_equiv_obj = obj->variant.hardlink_variant.equiv_id;
+}
+
+static int yaffs2_checkpt_obj_to_obj(struct yaffs_obj *obj,
+				     struct yaffs_checkpt_obj *cp)
+{
+	struct yaffs_obj *parent;
+	u32 cp_variant_type = yaffs2_checkpt_obj_bit_get(cp, CHECKPOINT_VARIANT_BITS);
+
+	if (obj->variant_type != cp_variant_type) {
+		yaffs_trace(YAFFS_TRACE_ERROR,
+			"Checkpoint read object %d type %d chunk %d does not match existing object type %d",
+			cp->obj_id, cp_variant_type, cp->hdr_chunk,
+			obj->variant_type);
+		return 0;
+	}
+
+	obj->obj_id = cp->obj_id;
+
+	if (cp->parent_id)
+		parent = yaffs_find_or_create_by_number(obj->my_dev,
+						cp->parent_id,
+						YAFFS_OBJECT_TYPE_DIRECTORY);
+	else
+		parent = NULL;
+
+	if (parent) {
+		if (parent->variant_type != YAFFS_OBJECT_TYPE_DIRECTORY) {
+			yaffs_trace(YAFFS_TRACE_ALWAYS,
+				"Checkpoint read object %d parent %d type %d chunk %d Parent type, %d, not directory",
+				cp->obj_id, cp->parent_id,
+				cp_variant_type, cp->hdr_chunk,
+				parent->variant_type);
+			return 0;
+		}
+		yaffs_add_obj_to_dir(parent, obj);
+	}
+
+	obj->hdr_chunk = cp->hdr_chunk;
+
+	obj->variant_type = yaffs2_checkpt_obj_bit_get(cp, CHECKPOINT_VARIANT_BITS);
+	obj->deleted = yaffs2_checkpt_obj_bit_get(cp, CHECKPOINT_DELETED_BITS);
+	obj->soft_del = yaffs2_checkpt_obj_bit_get(cp, CHECKPOINT_SOFT_DEL_BITS);
+	obj->unlinked = yaffs2_checkpt_obj_bit_get(cp, CHECKPOINT_UNLINKED_BITS);
+	obj->fake = yaffs2_checkpt_obj_bit_get(cp, CHECKPOINT_FAKE_BITS);
+	obj->rename_allowed = yaffs2_checkpt_obj_bit_get(cp, CHECKPOINT_RENAME_ALLOWED_BITS);
+	obj->unlink_allowed = yaffs2_checkpt_obj_bit_get(cp, CHECKPOINT_UNLINK_ALLOWED_BITS);
+	obj->serial = yaffs2_checkpt_obj_bit_get(cp, CHECKPOINT_SERIAL_BITS);
+
+	obj->n_data_chunks = cp->n_data_chunks;
+
+	if (obj->variant_type == YAFFS_OBJECT_TYPE_FILE) {
+		obj->variant.file_variant.file_size = cp->size_or_equiv_obj;
+		obj->variant.file_variant.stored_size = cp->size_or_equiv_obj;
+	} else if (obj->variant_type == YAFFS_OBJECT_TYPE_HARDLINK) {
+		obj->variant.hardlink_variant.equiv_id = cp->size_or_equiv_obj;
+	}
+	if (obj->hdr_chunk > 0)
+		obj->lazy_loaded = 1;
+	return 1;
+}
+
+static void yaffs2_do_endian_tnode(struct yaffs_dev *dev, struct yaffs_tnode *tn)
+{
+	int i;
+	u32 *as_u32 = (u32 *)tn;
+	int tnode_size_u32 = dev->tnode_size / sizeof(u32);
+
+	if (!dev->swap_endian)
+		return;
+	/* Swap all the tnode data as u32s to fix endianisms. */
+	for (i = 0; i<tnode_size_u32; i++)
+		as_u32[i] = swap_u32(as_u32[i]);
+}
+
+struct yaffs_tnode *yaffs2_do_endian_tnode_copy(struct yaffs_dev *dev,
+					       struct yaffs_tnode *tn)
+{
+	if (!dev->swap_endian)
+		return tn;
+
+	memcpy(dev->tn_swap_buffer, tn, dev->tnode_size);
+	tn = dev->tn_swap_buffer;
+
+	yaffs2_do_endian_tnode(dev, tn);
+
+	return tn;
+}
+
+static int yaffs2_checkpt_tnode_worker(struct yaffs_obj *in,
+				       struct yaffs_tnode *tn, u32 level,
+				       int chunk_offset)
+{
+	int i;
+	struct yaffs_dev *dev = in->my_dev;
+	int ok = 1;
+	u32 base_offset;
+
+	if (!tn)
+		return 1;
+
+	if (level > 0) {
+		for (i = 0; i < YAFFS_NTNODES_INTERNAL && ok; i++) {
+			if (!tn->internal[i])
+				continue;
+			ok = yaffs2_checkpt_tnode_worker(in,
+				 tn->internal[i],
+				 level - 1,
+				 (chunk_offset <<
+				  YAFFS_TNODES_INTERNAL_BITS) + i);
+		}
+		return ok;
+	}
+
+	/* Level 0 tnode */
+	base_offset = chunk_offset << YAFFS_TNODES_LEVEL0_BITS;
+	yaffs_do_endian_u32(dev, &base_offset);
+
+	ok = (yaffs2_checkpt_wr(dev, &base_offset, sizeof(base_offset)) ==
+			sizeof(base_offset));
+	if (ok) {
+		/*
+		 * NB Can't do an in-place endian swizzle since that would
+		 * damage current tnode data.
+		 * If a tnode endian conversion is required we do a copy.
+		 */
+		tn = yaffs2_do_endian_tnode_copy(dev, tn);
+		ok = (yaffs2_checkpt_wr(dev, tn, dev->tnode_size) ==
+			(int)dev->tnode_size);
+	}
+	return ok;
+}
+
+static int yaffs2_wr_checkpt_tnodes(struct yaffs_obj *obj)
+{
+	u32 end_marker = ~0;
+	int ok = 1;
+
+	if (obj->variant_type != YAFFS_OBJECT_TYPE_FILE)
+		return ok;
+
+	ok = yaffs2_checkpt_tnode_worker(obj,
+					 obj->variant.file_variant.top,
+					 obj->variant.file_variant.
+					 top_level, 0);
+	if (ok)
+		ok = (yaffs2_checkpt_wr(obj->my_dev, &end_marker,
+				sizeof(end_marker)) == sizeof(end_marker));
+
+	return ok ? 1 : 0;
+}
+
+static int yaffs2_rd_checkpt_tnodes(struct yaffs_obj *obj)
+{
+	u32 base_chunk;
+	int ok = 1;
+	struct yaffs_dev *dev = obj->my_dev;
+	struct yaffs_file_var *file_stuct_ptr = &obj->variant.file_variant;
+	struct yaffs_tnode *tn;
+	int nread = 0;
+
+	ok = (yaffs2_checkpt_rd(dev, &base_chunk, sizeof(base_chunk)) ==
+	      sizeof(base_chunk));
+
+	yaffs_do_endian_u32(dev, &base_chunk);
+
+	while (ok && (~base_chunk)) {
+		nread++;
+		/* Read level 0 tnode */
+
+		tn = yaffs_get_tnode(dev);
+		if (tn) {
+			ok = (yaffs2_checkpt_rd(dev, tn, dev->tnode_size) ==
+				(int)dev->tnode_size);
+			yaffs2_do_endian_tnode(dev, tn);
+		}
+		else
+			ok = 0;
+
+		if (tn && ok)
+			ok = yaffs_add_find_tnode_0(dev,
+						    file_stuct_ptr,
+						    base_chunk, tn) ? 1 : 0;
+
+		if (ok) {
+			ok = (yaffs2_checkpt_rd
+			      (dev, &base_chunk,
+			       sizeof(base_chunk)) == sizeof(base_chunk));
+			yaffs_do_endian_u32(dev, &base_chunk);
+		}
+
+	}
+
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+		"Checkpoint read tnodes %d records, last %d. ok %d",
+		nread, base_chunk, ok);
+
+	return ok ? 1 : 0;
+}
+
+
+static void yaffs2_do_endian_checkpt_obj(struct yaffs_dev *dev,
+					 struct yaffs_checkpt_obj *cp)
+{
+	if (!dev->swap_endian)
+		return;
+	cp->struct_type = swap_s32(cp->struct_type);
+	cp->obj_id = swap_u32(cp->obj_id);
+	cp->parent_id = swap_u32(cp->parent_id);
+	cp->hdr_chunk = swap_s32(cp->hdr_chunk);
+	cp->bit_field = swap_u32(cp->bit_field);
+	cp->n_data_chunks = swap_s32(cp->n_data_chunks);
+	cp->size_or_equiv_obj = swap_loff_t(cp->size_or_equiv_obj);
+}
+
+static int yaffs2_wr_checkpt_objs(struct yaffs_dev *dev)
+{
+	struct yaffs_obj *obj;
+	struct yaffs_checkpt_obj cp;
+	int i;
+	int ok = 1;
+	struct list_head *lh;
+	u32 cp_variant_type;
+
+	/* Iterate through the objects in each hash entry,
+	 * dumping them to the checkpointing stream.
+	 */
+
+	for (i = 0; ok && i < YAFFS_NOBJECT_BUCKETS; i++) {
+		list_for_each(lh, &dev->obj_bucket[i].list) {
+			obj = list_entry(lh, struct yaffs_obj, hash_link);
+			if (!obj->defered_free) {
+				yaffs2_obj_checkpt_obj(&cp, obj);
+				cp.struct_type = sizeof(cp);
+				cp_variant_type = yaffs2_checkpt_obj_bit_get(
+						&cp, CHECKPOINT_VARIANT_BITS);
+				yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+					"Checkpoint write object %d parent %d type %d chunk %d obj addr %p",
+					cp.obj_id, cp.parent_id,
+					cp_variant_type, cp.hdr_chunk, obj);
+
+				yaffs2_do_endian_checkpt_obj (dev, &cp);
+				ok = (yaffs2_checkpt_wr(dev, &cp,
+						sizeof(cp)) == sizeof(cp));
+
+				if (ok &&
+					obj->variant_type ==
+					YAFFS_OBJECT_TYPE_FILE)
+					ok = yaffs2_wr_checkpt_tnodes(obj);
+			}
+		}
+	}
+
+	/* Dump end of list */
+	memset(&cp, 0xff, sizeof(struct yaffs_checkpt_obj));
+	cp.struct_type = sizeof(cp);
+	yaffs2_do_endian_checkpt_obj (dev, &cp);
+
+	if (ok)
+		ok = (yaffs2_checkpt_wr(dev, &cp, sizeof(cp)) == sizeof(cp));
+
+	return ok ? 1 : 0;
+}
+
+static int yaffs2_rd_checkpt_objs(struct yaffs_dev *dev)
+{
+	struct yaffs_obj *obj;
+	struct yaffs_checkpt_obj cp;
+	int ok = 1;
+	int done = 0;
+	u32 cp_variant_type;
+	LIST_HEAD(hard_list);
+
+
+	while (ok && !done) {
+		ok = (yaffs2_checkpt_rd(dev, &cp, sizeof(cp)) == sizeof(cp));
+		yaffs2_do_endian_checkpt_obj (dev, &cp);
+
+		if (cp.struct_type != sizeof(cp)) {
+			yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+				"struct size %d instead of %d ok %d",
+				cp.struct_type, (int)sizeof(cp), ok);
+			ok = 0;
+		}
+
+		cp_variant_type = yaffs2_checkpt_obj_bit_get(
+						&cp, CHECKPOINT_VARIANT_BITS);
+		yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"Checkpoint read object %d parent %d type %d chunk %d ",
+			cp.obj_id, cp.parent_id, cp_variant_type,
+			cp.hdr_chunk);
+
+		if (ok && cp.obj_id == (u32)(~0)) {
+			done = 1;
+		} else if (ok) {
+			obj =
+			    yaffs_find_or_create_by_number(dev, cp.obj_id,
+							   cp_variant_type);
+			if (obj) {
+				ok = yaffs2_checkpt_obj_to_obj(obj, &cp);
+				if (!ok)
+					break;
+				if (obj->variant_type ==
+					YAFFS_OBJECT_TYPE_FILE) {
+					ok = yaffs2_rd_checkpt_tnodes(obj);
+				} else if (obj->variant_type ==
+					YAFFS_OBJECT_TYPE_HARDLINK) {
+					list_add(&obj->hard_links, &hard_list);
+				}
+			} else {
+				ok = 0;
+			}
+		}
+	}
+
+	if (ok)
+		yaffs_link_fixup(dev, &hard_list);
+
+	return ok ? 1 : 0;
+}
+
+static int yaffs2_wr_checkpt_sum(struct yaffs_dev *dev)
+{
+	u32 checkpt_sum;
+	int ok;
+
+	yaffs2_get_checkpt_sum(dev, &checkpt_sum);
+
+	yaffs_do_endian_u32(dev, &checkpt_sum);
+
+	ok = (yaffs2_checkpt_wr(dev, &checkpt_sum, sizeof(checkpt_sum)) ==
+		sizeof(checkpt_sum));
+
+	if (!ok)
+		return 0;
+
+	return 1;
+}
+
+static int yaffs2_rd_checkpt_sum(struct yaffs_dev *dev)
+{
+	u32 checkpt_sum0;
+	u32 checkpt_sum1;
+	int ok;
+
+	yaffs2_get_checkpt_sum(dev, &checkpt_sum0);
+
+	ok = (yaffs2_checkpt_rd(dev, &checkpt_sum1, sizeof(checkpt_sum1)) ==
+		sizeof(checkpt_sum1));
+
+	if (!ok)
+		return 0;
+	yaffs_do_endian_u32(dev, &checkpt_sum1);
+
+	if (checkpt_sum0 != checkpt_sum1)
+		return 0;
+
+	return 1;
+}
+
+static int yaffs2_wr_checkpt_data(struct yaffs_dev *dev)
+{
+	int ok = 1;
+
+	if (!yaffs2_checkpt_required(dev)) {
+		yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"skipping checkpoint write");
+		ok = 0;
+	}
+
+	if (ok)
+		ok = yaffs2_checkpt_open(dev, 1);
+
+	if (ok) {
+		yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"write checkpoint validity");
+		ok = yaffs2_wr_checkpt_validity_marker(dev, 1);
+	}
+	if (ok) {
+		yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"write checkpoint device");
+		ok = yaffs2_wr_checkpt_dev(dev);
+	}
+	if (ok) {
+		yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"write checkpoint objects");
+		ok = yaffs2_wr_checkpt_objs(dev);
+	}
+	if (ok) {
+		yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"write checkpoint validity");
+		ok = yaffs2_wr_checkpt_validity_marker(dev, 0);
+	}
+
+	if (ok)
+		ok = yaffs2_wr_checkpt_sum(dev);
+
+	if (!yaffs_checkpt_close(dev))
+		ok = 0;
+
+	if (ok)
+		dev->is_checkpointed = 1;
+	else
+		dev->is_checkpointed = 0;
+
+	return dev->is_checkpointed;
+}
+
+static int yaffs2_rd_checkpt_data(struct yaffs_dev *dev)
+{
+	int ok = 1;
+
+	if (!dev->param.is_yaffs2)
+		ok = 0;
+
+	if (ok && dev->param.skip_checkpt_rd) {
+		yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"skipping checkpoint read");
+		ok = 0;
+	}
+
+	if (ok)
+		ok = yaffs2_checkpt_open(dev, 0); /* open for read */
+
+	if (ok) {
+		yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"read checkpoint validity");
+		ok = yaffs2_rd_checkpt_validity_marker(dev, 1);
+	}
+	if (ok) {
+		yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"read checkpoint device");
+		ok = yaffs2_rd_checkpt_dev(dev);
+	}
+	if (ok) {
+		yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"read checkpoint objects");
+		ok = yaffs2_rd_checkpt_objs(dev);
+	}
+	if (ok) {
+		yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"read checkpoint validity");
+		ok = yaffs2_rd_checkpt_validity_marker(dev, 0);
+	}
+
+	if (ok) {
+		ok = yaffs2_rd_checkpt_sum(dev);
+		yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+			"read checkpoint checksum %d", ok);
+	}
+
+	if (!yaffs_checkpt_close(dev))
+		ok = 0;
+
+	if (ok)
+		dev->is_checkpointed = 1;
+	else
+		dev->is_checkpointed = 0;
+
+	return ok ? 1 : 0;
+}
+
+void yaffs2_checkpt_invalidate(struct yaffs_dev *dev)
+{
+	if (dev->is_checkpointed || dev->blocks_in_checkpt > 0) {
+		dev->is_checkpointed = 0;
+		yaffs2_checkpt_invalidate_stream(dev);
+	}
+	if (dev->param.sb_dirty_fn)
+		dev->param.sb_dirty_fn(dev);
+}
+
+int yaffs_checkpoint_save(struct yaffs_dev *dev)
+{
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+		"save entry: is_checkpointed %d",
+		dev->is_checkpointed);
+
+	yaffs_verify_objects(dev);
+	yaffs_verify_blocks(dev);
+	yaffs_verify_free_chunks(dev);
+
+	if (!dev->is_checkpointed) {
+		yaffs2_checkpt_invalidate(dev);
+		yaffs2_wr_checkpt_data(dev);
+	}
+
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT | YAFFS_TRACE_MOUNT,
+		"save exit: is_checkpointed %d",
+		dev->is_checkpointed);
+
+	return dev->is_checkpointed;
+}
+
+int yaffs2_checkpt_restore(struct yaffs_dev *dev)
+{
+	int retval;
+
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+		"restore entry: is_checkpointed %d",
+		dev->is_checkpointed);
+
+	retval = yaffs2_rd_checkpt_data(dev);
+
+	if (dev->is_checkpointed) {
+		yaffs_verify_objects(dev);
+		yaffs_verify_blocks(dev);
+		yaffs_verify_free_chunks(dev);
+	}
+
+	yaffs_trace(YAFFS_TRACE_CHECKPOINT,
+		"restore exit: is_checkpointed %d",
+		dev->is_checkpointed);
+
+	return retval;
+}
+
+/* End of checkpointing */
+
+/* Hole handling logic for truncate past end of file */
+
+int yaffs2_handle_hole(struct yaffs_obj *obj, loff_t new_size)
+{
+	/* if new_size > old_file_size.
+	 * We're going to be writing a hole.
+	 * If the hole is small then write zeros otherwise write a start
+	 * of hole marker.
+	 */
+	loff_t old_file_size;
+	loff_t increase;
+	int small_hole;
+	int result = YAFFS_OK;
+	struct yaffs_dev *dev = NULL;
+	u8 *local_buffer = NULL;
+	int small_increase_ok = 0;
+
+	if (!obj)
+		return YAFFS_FAIL;
+
+	if (obj->variant_type != YAFFS_OBJECT_TYPE_FILE)
+		return YAFFS_FAIL;
+
+	dev = obj->my_dev;
+
+	/* Bail out if not yaffs2 mode */
+	if (!dev->param.is_yaffs2)
+		return YAFFS_OK;
+
+	old_file_size = obj->variant.file_variant.file_size;
+
+	if (new_size <= old_file_size)
+		return YAFFS_OK;
+
+	increase = new_size - old_file_size;
+
+	if (increase < YAFFS_SMALL_HOLE_THRESHOLD * dev->data_bytes_per_chunk &&
+	    yaffs_check_alloc_available(dev, YAFFS_SMALL_HOLE_THRESHOLD + 1))
+		small_hole = 1;
+	else
+		small_hole = 0;
+
+	if (small_hole)
+		local_buffer = yaffs_get_temp_buffer(dev);
+
+	if (local_buffer) {
+		/* fill hole with zero bytes */
+		loff_t pos = old_file_size;
+		int this_write;
+		int written;
+		memset(local_buffer, 0, dev->data_bytes_per_chunk);
+		small_increase_ok = 1;
+
+		while (increase > 0 && small_increase_ok) {
+			this_write = increase;
+			if (this_write > (int)dev->data_bytes_per_chunk)
+				this_write = dev->data_bytes_per_chunk;
+			written =
+			    yaffs_do_file_wr(obj, local_buffer, pos, this_write,
+					     0);
+			if (written == this_write) {
+				pos += this_write;
+				increase -= this_write;
+			} else {
+				small_increase_ok = 0;
+			}
+		}
+
+		yaffs_release_temp_buffer(dev, local_buffer);
+
+		/* If out of space then reverse any chunks we've added */
+		if (!small_increase_ok)
+			yaffs_resize_file_down(obj, old_file_size);
+	}
+
+	if (!small_increase_ok &&
+	    obj->parent &&
+	    obj->parent->obj_id != YAFFS_OBJECTID_UNLINKED &&
+	    obj->parent->obj_id != YAFFS_OBJECTID_DELETED) {
+		/* Write a hole start header with the old file size */
+		yaffs_update_oh(obj, NULL, 0, 1, 0, NULL);
+	}
+
+	return result;
+}
+
+/* Yaffs2 scanning */
+
+struct yaffs_block_index {
+	int seq;
+	int block;
+};
+
+static int yaffs2_ybicmp(const void *a, const void *b)
+{
+	int aseq = ((struct yaffs_block_index *)a)->seq;
+	int bseq = ((struct yaffs_block_index *)b)->seq;
+	int ablock = ((struct yaffs_block_index *)a)->block;
+	int bblock = ((struct yaffs_block_index *)b)->block;
+
+	if (aseq == bseq)
+		return ablock - bblock;
+
+	return aseq - bseq;
+}
+
+static inline int yaffs2_scan_chunk(struct yaffs_dev *dev,
+		struct yaffs_block_info *bi,
+		int blk, int chunk_in_block,
+		int *found_chunks,
+		u8 *chunk_data,
+		struct list_head *hard_list,
+		int summary_available)
+{
+	struct yaffs_obj_hdr *oh;
+	struct yaffs_obj *in;
+	struct yaffs_obj *parent;
+	int equiv_id;
+	loff_t file_size;
+	int is_shrink;
+	int is_unlinked;
+	struct yaffs_ext_tags tags;
+	int result;
+	int alloc_failed = 0;
+	int chunk = blk * dev->param.chunks_per_block + chunk_in_block;
+	struct yaffs_file_var *file_var;
+	struct yaffs_hardlink_var *hl_var;
+	struct yaffs_symlink_var *sl_var;
+
+	if (summary_available) {
+		result = yaffs_summary_fetch(dev, &tags, chunk_in_block);
+		tags.seq_number = bi->seq_number;
+	}
+
+	if (!summary_available || tags.obj_id == 0) {
+		result = yaffs_rd_chunk_tags_nand(dev, chunk, NULL, &tags);
+		dev->tags_used++;
+	} else {
+		dev->summary_used++;
+	}
+
+	if (result == YAFFS_FAIL)
+		yaffs_trace(YAFFS_TRACE_SCAN,
+				"Could not get tags for chunk %d\n", chunk);
+	/* Let's have a good look at this chunk... */
+
+	if (!tags.chunk_used) {
+		/* An unassigned chunk in the block.
+		 * If there are used chunks after this one, then
+		 * it is a chunk that was skipped due to failing
+		 * the erased check. Just skip it so that it can
+		 * be deleted.
+		 * But, more typically, We get here when this is
+		 * an unallocated chunk and his means that
+		 * either the block is empty or this is the one
+		 * being allocated from
+		 */
+
+		if (*found_chunks) {
+			/* This is a chunk that was skipped due
+			 * to failing the erased check */
+		} else if (chunk_in_block == 0) {
+			/* We're looking at the first chunk in
+			 * the block so the block is unused */
+			bi->block_state = YAFFS_BLOCK_STATE_EMPTY;
+			dev->n_erased_blocks++;
+		} else {
+			if (bi->block_state == YAFFS_BLOCK_STATE_NEEDS_SCAN ||
+			    bi->block_state == YAFFS_BLOCK_STATE_ALLOCATING) {
+				if (dev->seq_number == bi->seq_number) {
+					/* Allocating from this block*/
+					yaffs_trace(YAFFS_TRACE_SCAN,
+					    " Allocating from %d %d",
+					    blk, chunk_in_block);
+
+					bi->block_state =
+						YAFFS_BLOCK_STATE_ALLOCATING;
+					dev->alloc_block = blk;
+					dev->alloc_page = chunk_in_block;
+					dev->alloc_block_finder = blk;
+				} else {
+					/* This is a partially written block
+					 * that is not the current
+					 * allocation block.
+					 */
+					yaffs_trace(YAFFS_TRACE_SCAN,
+						"Partially written block %d detected. gc will fix this.",
+						blk);
+				}
+			}
+		}
+
+		dev->n_free_chunks++;
+
+	} else if (tags.ecc_result ==
+		YAFFS_ECC_RESULT_UNFIXED) {
+		yaffs_trace(YAFFS_TRACE_SCAN,
+			" Unfixed ECC in chunk(%d:%d), chunk ignored",
+			blk, chunk_in_block);
+			dev->n_free_chunks++;
+	} else if (tags.obj_id > YAFFS_MAX_OBJECT_ID ||
+		   tags.chunk_id > YAFFS_MAX_CHUNK_ID ||
+		   tags.obj_id == YAFFS_OBJECTID_SUMMARY ||
+		   (tags.chunk_id > 0 &&
+		     tags.n_bytes > dev->data_bytes_per_chunk) ||
+		   tags.seq_number != bi->seq_number) {
+		yaffs_trace(YAFFS_TRACE_SCAN,
+			"Chunk (%d:%d) with bad tags:obj = %d, chunk_id = %d, n_bytes = %d, ignored",
+			blk, chunk_in_block, tags.obj_id,
+			tags.chunk_id, tags.n_bytes);
+		dev->n_free_chunks++;
+	} else if (tags.chunk_id > 0) {
+		/* chunk_id > 0 so it is a data chunk... */
+		loff_t endpos;
+		loff_t chunk_base = (tags.chunk_id - 1) *
+					dev->data_bytes_per_chunk;
+
+		*found_chunks = 1;
+
+		yaffs_set_chunk_bit(dev, blk, chunk_in_block);
+		bi->pages_in_use++;
+
+		in = yaffs_find_or_create_by_number(dev,
+					tags.obj_id,
+					YAFFS_OBJECT_TYPE_FILE);
+		if (!in)
+			/* Out of memory */
+			alloc_failed = 1;
+
+		if (in &&
+		    in->variant_type == YAFFS_OBJECT_TYPE_FILE &&
+		    chunk_base < in->variant.file_variant.shrink_size) {
+			/* This has not been invalidated by
+			 * a resize */
+			if (!yaffs_put_chunk_in_file(in, tags.chunk_id,
+								chunk, -1))
+				alloc_failed = 1;
+
+			/* File size is calculated by looking at
+			 * the data chunks if we have not
+			 * seen an object header yet.
+			 * Stop this practice once we find an
+			 * object header.
+			 */
+			endpos = chunk_base + tags.n_bytes;
+
+			if (!in->valid &&
+			    in->variant.file_variant.stored_size < endpos) {
+				in->variant.file_variant.
+				    stored_size = endpos;
+				in->variant.file_variant.
+				    file_size = endpos;
+			}
+		} else if (in) {
+			/* This chunk has been invalidated by a
+			 * resize, or a past file deletion
+			 * so delete the chunk*/
+			yaffs_chunk_del(dev, chunk, 1, __LINE__);
+		}
+	} else {
+		/* chunk_id == 0, so it is an ObjectHeader.
+		 * Thus, we read in the object header and make
+		 * the object
+		 */
+		*found_chunks = 1;
+
+		yaffs_set_chunk_bit(dev, blk, chunk_in_block);
+		bi->pages_in_use++;
+
+		oh = NULL;
+		in = NULL;
+
+		if (tags.extra_available) {
+			in = yaffs_find_or_create_by_number(dev,
+					tags.obj_id,
+					tags.extra_obj_type);
+			if (!in)
+				alloc_failed = 1;
+		}
+
+		if (!in ||
+		    (!in->valid && dev->param.disable_lazy_load) ||
+		    tags.extra_shadows ||
+		    (!in->valid && (tags.obj_id == YAFFS_OBJECTID_ROOT ||
+				 tags.obj_id == YAFFS_OBJECTID_LOSTNFOUND))) {
+
+			/* If we don't have  valid info then we
+			 * need to read the chunk
+			 * TODO In future we can probably defer
+			 * reading the chunk and living with
+			 * invalid data until needed.
+			 */
+
+			result = yaffs_rd_chunk_tags_nand(dev,
+						  chunk,
+						  chunk_data,
+						  NULL);
+
+			oh = (struct yaffs_obj_hdr *)chunk_data;
+
+			yaffs_do_endian_oh(dev, oh);
+
+			if (dev->param.inband_tags) {
+				/* Fix up the header if they got
+				 * corrupted by inband tags */
+				oh->shadows_obj =
+				    oh->inband_shadowed_obj_id;
+				oh->is_shrink =
+				    oh->inband_is_shrink;
+			}
+
+			if (!in) {
+				in = yaffs_find_or_create_by_number(dev,
+							tags.obj_id, oh->type);
+				if (!in)
+					alloc_failed = 1;
+			}
+		}
+
+		if (!in) {
+			/* TODO Hoosterman we have a problem! */
+			yaffs_trace(YAFFS_TRACE_ERROR,
+				"yaffs tragedy: Could not make object for object  %d at chunk %d during scan",
+				tags.obj_id, chunk);
+			return YAFFS_FAIL;
+		}
+
+		if (in->valid) {
+			/* We have already filled this one.
+			 * We have a duplicate that will be
+			 * discarded, but we first have to suck
+			 * out resize info if it is a file.
+			 */
+			if ((in->variant_type == YAFFS_OBJECT_TYPE_FILE) &&
+				((oh && oh->type == YAFFS_OBJECT_TYPE_FILE) ||
+				 (tags.extra_available &&
+				  tags.extra_obj_type == YAFFS_OBJECT_TYPE_FILE)
+				)) {
+				loff_t this_size = (oh) ?
+					yaffs_oh_to_size(dev, oh, 0) :
+					tags.extra_file_size;
+				u32 parent_obj_id = (oh) ?
+					(u32)oh->parent_obj_id :
+					tags.extra_parent_id;
+
+				is_shrink = (oh) ?
+					oh->is_shrink :
+					tags.extra_is_shrink;
+
+				/* If it is deleted (unlinked
+				 * at start also means deleted)
+				 * we treat the file size as
+				 * being zeroed at this point.
+				 */
+				if (parent_obj_id == YAFFS_OBJECTID_DELETED ||
+				    parent_obj_id == YAFFS_OBJECTID_UNLINKED) {
+					this_size = 0;
+					is_shrink = 1;
+				}
+
+				if (is_shrink &&
+				    in->variant.file_variant.shrink_size >
+				    this_size)
+					in->variant.file_variant.shrink_size =
+					this_size;
+
+				if (is_shrink)
+					bi->has_shrink_hdr = 1;
+			}
+			/* Use existing - destroy this one. */
+			yaffs_chunk_del(dev, chunk, 1, __LINE__);
+		}
+
+		if (!in->valid && in->variant_type !=
+		    (oh ? oh->type : tags.extra_obj_type)) {
+			yaffs_trace(YAFFS_TRACE_ERROR,
+				"yaffs tragedy: Bad type, %d != %d, for object %d at chunk %d during scan",
+				oh ? oh->type : tags.extra_obj_type,
+				in->variant_type, tags.obj_id,
+				chunk);
+			in = yaffs_retype_obj(in, oh ? oh->type : tags.extra_obj_type);
+		}
+
+		if (!in->valid &&
+		    (tags.obj_id == YAFFS_OBJECTID_ROOT ||
+		     tags.obj_id == YAFFS_OBJECTID_LOSTNFOUND)) {
+			/* We only load some info, don't fiddle
+			 * with directory structure */
+			in->valid = 1;
+
+			if (oh) {
+				in->yst_mode = oh->yst_mode;
+				yaffs_load_attribs(in, oh);
+				in->lazy_loaded = 0;
+			} else {
+				in->lazy_loaded = 1;
+			}
+			in->hdr_chunk = chunk;
+
+		} else if (!in->valid) {
+			/* we need to load this info */
+			in->valid = 1;
+			in->hdr_chunk = chunk;
+			if (oh) {
+				in->variant_type = oh->type;
+				in->yst_mode = oh->yst_mode;
+				yaffs_load_attribs(in, oh);
+
+				if (oh->shadows_obj > 0)
+					yaffs_handle_shadowed_obj(dev,
+					     oh->shadows_obj, 1);
+
+				yaffs_set_obj_name_from_oh(in, oh);
+				parent = yaffs_find_or_create_by_number(dev,
+						oh->parent_obj_id,
+						YAFFS_OBJECT_TYPE_DIRECTORY);
+				file_size = yaffs_oh_to_size(dev, oh, 0);
+				is_shrink = oh->is_shrink;
+				equiv_id = oh->equiv_id;
+			} else {
+				in->variant_type = tags.extra_obj_type;
+				parent = yaffs_find_or_create_by_number(dev,
+						tags.extra_parent_id,
+						YAFFS_OBJECT_TYPE_DIRECTORY);
+				file_size = tags.extra_file_size;
+				is_shrink = tags.extra_is_shrink;
+				equiv_id = tags.extra_equiv_id;
+				in->lazy_loaded = 1;
+			}
+			in->dirty = 0;
+
+			if (!parent)
+				alloc_failed = 1;
+
+			/* directory stuff...
+			 * hook up to parent
+			 */
+
+			if (parent &&
+			    parent->variant_type == YAFFS_OBJECT_TYPE_UNKNOWN) {
+				/* Set up as a directory */
+				parent->variant_type =
+					YAFFS_OBJECT_TYPE_DIRECTORY;
+				INIT_LIST_HEAD(&parent->
+						variant.dir_variant.children);
+			} else if (!parent ||
+				   parent->variant_type !=
+					YAFFS_OBJECT_TYPE_DIRECTORY) {
+				/* Hoosterman, another problem....
+				 * Trying to use a non-directory as a directory
+				 */
+
+				yaffs_trace(YAFFS_TRACE_ERROR,
+					"yaffs tragedy: attempting to use non-directory as a directory in scan. Put in lost+found."
+					);
+				parent = dev->lost_n_found;
+			}
+			yaffs_add_obj_to_dir(parent, in);
+
+			is_unlinked = (parent == dev->del_dir) ||
+					(parent == dev->unlinked_dir);
+
+			if (is_shrink)
+				/* Mark the block */
+				bi->has_shrink_hdr = 1;
+
+			/* Note re hardlinks.
+			 * Since we might scan a hardlink before its equivalent
+			 * object is scanned we put them all in a list.
+			 * After scanning is complete, we should have all the
+			 * objects, so we run through this list and fix up all
+			 * the chains.
+			 */
+
+			switch (in->variant_type) {
+			case YAFFS_OBJECT_TYPE_UNKNOWN:
+				/* Todo got a problem */
+				break;
+			case YAFFS_OBJECT_TYPE_FILE:
+				file_var = &in->variant.file_variant;
+				if (file_var->stored_size < file_size) {
+					/* This covers the case where the file
+					 * size is greater than the data held.
+					 * This will happen if the file is
+					 * resized to be larger than its
+					 * current data extents.
+					 */
+					file_var->file_size = file_size;
+					file_var->stored_size = file_size;
+				}
+
+				if (file_var->shrink_size > file_size)
+					file_var->shrink_size = file_size;
+
+				break;
+			case YAFFS_OBJECT_TYPE_HARDLINK:
+				hl_var = &in->variant.hardlink_variant;
+				if (!is_unlinked) {
+					hl_var->equiv_id = equiv_id;
+					list_add(&in->hard_links, hard_list);
+				}
+				break;
+			case YAFFS_OBJECT_TYPE_DIRECTORY:
+				/* Do nothing */
+				break;
+			case YAFFS_OBJECT_TYPE_SPECIAL:
+				/* Do nothing */
+				break;
+			case YAFFS_OBJECT_TYPE_SYMLINK:
+				sl_var = &in->variant.symlink_variant;
+				if (oh) {
+					sl_var->alias =
+					    yaffs_clone_str(oh->alias);
+					if (!sl_var->alias)
+						alloc_failed = 1;
+				}
+				break;
+			}
+		}
+	}
+	return alloc_failed ? YAFFS_FAIL : YAFFS_OK;
+}
+
+int yaffs2_scan_backwards(struct yaffs_dev *dev)
+{
+	u32 blk;
+	int block_iter;
+	int start_iter;
+	int end_iter;
+	int n_to_scan = 0;
+	enum yaffs_block_state state;
+	int c;
+	LIST_HEAD(hard_list);
+	struct yaffs_block_info *bi;
+	u32 seq_number;
+	int n_blocks = dev->internal_end_block - dev->internal_start_block + 1;
+	u8 *chunk_data;
+	int found_chunks;
+	int alloc_failed = 0;
+	struct yaffs_block_index *block_index = NULL;
+	int alt_block_index = 0;
+	int summary_available;
+
+	yaffs_trace(YAFFS_TRACE_SCAN,
+		"yaffs2_scan_backwards starts  intstartblk %d intendblk %d...",
+		dev->internal_start_block, dev->internal_end_block);
+
+	dev->seq_number = YAFFS_LOWEST_SEQUENCE_NUMBER;
+
+	block_index =
+		kmalloc(n_blocks * sizeof(struct yaffs_block_index), GFP_NOFS);
+
+	if (!block_index) {
+		block_index =
+		    vmalloc(n_blocks * sizeof(struct yaffs_block_index));
+		alt_block_index = 1;
+	}
+
+	if (!block_index) {
+		yaffs_trace(YAFFS_TRACE_SCAN,
+			"yaffs2_scan_backwards() could not allocate block index!"
+			);
+		return YAFFS_FAIL;
+	}
+
+	dev->blocks_in_checkpt = 0;
+
+	chunk_data = yaffs_get_temp_buffer(dev);
+
+	/* Scan all the blocks to determine their state */
+	bi = dev->block_info;
+	for (blk = dev->internal_start_block; blk <= dev->internal_end_block;
+	     blk++) {
+		yaffs_clear_chunk_bits(dev, blk);
+		bi->pages_in_use = 0;
+		bi->soft_del_pages = 0;
+
+		yaffs_query_init_block_state(dev, blk, &state, &seq_number);
+
+		bi->block_state = state;
+		bi->seq_number = seq_number;
+
+		if (bi->seq_number == YAFFS_SEQUENCE_CHECKPOINT_DATA)
+			bi->block_state = YAFFS_BLOCK_STATE_CHECKPOINT;
+		if (bi->seq_number == YAFFS_SEQUENCE_BAD_BLOCK)
+			bi->block_state = YAFFS_BLOCK_STATE_DEAD;
+
+		yaffs_trace(YAFFS_TRACE_SCAN_DEBUG,
+			"Block scanning block %d state %d seq %d",
+			blk, bi->block_state, seq_number);
+
+		if (bi->block_state == YAFFS_BLOCK_STATE_CHECKPOINT) {
+			dev->blocks_in_checkpt++;
+
+		} else if (bi->block_state == YAFFS_BLOCK_STATE_DEAD) {
+			yaffs_trace(YAFFS_TRACE_BAD_BLOCKS,
+				"block %d is bad", blk);
+		} else if (bi->block_state == YAFFS_BLOCK_STATE_EMPTY) {
+			yaffs_trace(YAFFS_TRACE_SCAN_DEBUG, "Block empty ");
+			dev->n_erased_blocks++;
+			dev->n_free_chunks += dev->param.chunks_per_block;
+		} else if (bi->block_state ==
+				YAFFS_BLOCK_STATE_NEEDS_SCAN) {
+			/* Determine the highest sequence number */
+			if (seq_number >= YAFFS_LOWEST_SEQUENCE_NUMBER &&
+			    seq_number < YAFFS_HIGHEST_SEQUENCE_NUMBER) {
+				block_index[n_to_scan].seq = seq_number;
+				block_index[n_to_scan].block = blk;
+				n_to_scan++;
+				if (seq_number >= dev->seq_number)
+					dev->seq_number = seq_number;
+			} else {
+				/* TODO: Nasty sequence number! */
+				yaffs_trace(YAFFS_TRACE_SCAN,
+					"Block scanning block %d has bad sequence number %d",
+					blk, seq_number);
+			}
+		}
+		bi++;
+	}
+
+	yaffs_trace(YAFFS_TRACE_ALWAYS, "%d blocks to be sorted...", n_to_scan);
+
+	cond_resched();
+
+	/* Sort the blocks by sequence number */
+	sort(block_index, n_to_scan, sizeof(struct yaffs_block_index),
+		   yaffs2_ybicmp, NULL);
+
+	cond_resched();
+
+	yaffs_trace(YAFFS_TRACE_SCAN, "...done");
+
+	/* Now scan the blocks looking at the data. */
+	start_iter = 0;
+	end_iter = n_to_scan - 1;
+	yaffs_trace(YAFFS_TRACE_SCAN_DEBUG, "%d blocks to scan", n_to_scan);
+
+	/* For each block.... backwards */
+	for (block_iter = end_iter;
+	     !alloc_failed && block_iter >= start_iter;
+	     block_iter--) {
+		/* Cooperative multitasking! This loop can run for so
+		   long that watchdog timers expire. */
+		cond_resched();
+
+		/* get the block to scan in the correct order */
+		blk = block_index[block_iter].block;
+		bi = yaffs_get_block_info(dev, blk);
+
+		summary_available = yaffs_summary_read(dev, dev->sum_tags, blk);
+
+		/* For each chunk in each block that needs scanning.... */
+		found_chunks = 0;
+		if (summary_available)
+			c = dev->chunks_per_summary - 1;
+		else
+			c = dev->param.chunks_per_block - 1;
+
+		for (/* c is already initialised */;
+		     !alloc_failed && c >= 0 &&
+		     (bi->block_state == YAFFS_BLOCK_STATE_NEEDS_SCAN ||
+		      bi->block_state == YAFFS_BLOCK_STATE_ALLOCATING);
+		      c--) {
+			/* Scan backwards...
+			 * Read the tags and decide what to do
+			 */
+			if (yaffs2_scan_chunk(dev, bi, blk, c,
+					&found_chunks, chunk_data,
+					&hard_list, summary_available) ==
+					YAFFS_FAIL)
+				alloc_failed = 1;
+		}
+
+		if (bi->block_state == YAFFS_BLOCK_STATE_NEEDS_SCAN) {
+			/* If we got this far while scanning, then the block
+			 * is fully allocated. */
+			bi->block_state = YAFFS_BLOCK_STATE_FULL;
+		}
+
+		/* Now let's see if it was dirty */
+		if (bi->pages_in_use == 0 &&
+		    !bi->has_shrink_hdr &&
+		    bi->block_state == YAFFS_BLOCK_STATE_FULL) {
+			yaffs_block_became_dirty(dev, blk);
+		}
+	}
+
+	yaffs_skip_rest_of_block(dev);
+
+	if (alt_block_index)
+		vfree(block_index);
+	else
+		kfree(block_index);
+
+	/* Ok, we've done all the scanning.
+	 * Fix up the hard link chains.
+	 * We have scanned all the objects, now it's time to add these
+	 * hardlinks.
+	 */
+	yaffs_link_fixup(dev, &hard_list);
+
+	yaffs_release_temp_buffer(dev, chunk_data);
+
+	if (alloc_failed)
+		return YAFFS_FAIL;
+
+	yaffs_trace(YAFFS_TRACE_SCAN, "yaffs2_scan_backwards ends");
+
+	return YAFFS_OK;
+}
diff --git a/fs/yaffs2/yaffs_yaffs2.h b/fs/yaffs2/yaffs_yaffs2.h
new file mode 100644
index 0000000..2363bfd
--- /dev/null
+++ b/fs/yaffs2/yaffs_yaffs2.h
@@ -0,0 +1,39 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YAFFS_YAFFS2_H__
+#define __YAFFS_YAFFS2_H__
+
+#include "yaffs_guts.h"
+
+void yaffs_calc_oldest_dirty_seq(struct yaffs_dev *dev);
+void yaffs2_find_oldest_dirty_seq(struct yaffs_dev *dev);
+void yaffs2_clear_oldest_dirty_seq(struct yaffs_dev *dev,
+				   struct yaffs_block_info *bi);
+void yaffs2_update_oldest_dirty_seq(struct yaffs_dev *dev, unsigned block_no,
+				    struct yaffs_block_info *bi);
+int yaffs_block_ok_for_gc(struct yaffs_dev *dev, struct yaffs_block_info *bi);
+u32 yaffs2_find_refresh_block(struct yaffs_dev *dev);
+int yaffs2_checkpt_required(struct yaffs_dev *dev);
+int yaffs_calc_checkpt_blocks_required(struct yaffs_dev *dev);
+
+void yaffs2_checkpt_invalidate(struct yaffs_dev *dev);
+int yaffs2_checkpt_save(struct yaffs_dev *dev);
+int yaffs2_checkpt_restore(struct yaffs_dev *dev);
+
+int yaffs2_handle_hole(struct yaffs_obj *obj, loff_t new_size);
+int yaffs2_scan_backwards(struct yaffs_dev *dev);
+
+#endif
diff --git a/fs/yaffs2/yportenv.h b/fs/yaffs2/yportenv.h
new file mode 100644
index 0000000..8975af3
--- /dev/null
+++ b/fs/yaffs2/yportenv.h
@@ -0,0 +1,85 @@
+/*
+ * YAFFS: Yet another Flash File System . A NAND-flash specific file system.
+ *
+ * Copyright (C) 2002-2011 Aleph One Ltd.
+ *   for Toby Churchill Ltd and Brightstar Engineering
+ *
+ * Created by Charles Manning <charles@aleph1.co.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU Lesser General Public License version 2.1 as
+ * published by the Free Software Foundation.
+ *
+ * Note: Only YAFFS headers are LGPL, YAFFS C code is covered by GPL.
+ */
+
+#ifndef __YPORTENV_H__
+#define __YPORTENV_H__
+
+/*
+ * Define the MTD version in terms of Linux Kernel versions
+ * This allows yaffs to be used independantly of the kernel
+ * as well as with it.
+ */
+
+#define MTD_VERSION(a, b, c) (((a) << 16) + ((b) << 8) + (c))
+
+#ifdef YAFFS_OUT_OF_TREE
+#include "moduleconfig.h"
+#endif
+
+#include <linux/version.h>
+#define MTD_VERSION_CODE LINUX_VERSION_CODE
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2, 6, 19))
+#include <linux/config.h>
+#endif
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/sched.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+#include <linux/vmalloc.h>
+#include <linux/xattr.h>
+#include <linux/list.h>
+#include <linux/types.h>
+#include <linux/fs.h>
+#include <linux/stat.h>
+#include <linux/sort.h>
+#include <linux/bitops.h>
+
+/*  These type wrappings are used to support Unicode names in WinCE. */
+#define YCHAR char
+#define YUCHAR unsigned char
+#define _Y(x)     x
+
+#define YAFFS_LOSTNFOUND_NAME		"lost+found"
+#define YAFFS_LOSTNFOUND_PREFIX		"obj"
+
+
+#define YAFFS_ROOT_MODE			0755
+#define YAFFS_LOSTNFOUND_MODE		0700
+
+#if (LINUX_VERSION_CODE > KERNEL_VERSION(2, 5, 0))
+#define Y_CURRENT_TIME CURRENT_TIME.tv_sec
+#define Y_TIME_CONVERT(x) (x).tv_sec
+#else
+#define Y_CURRENT_TIME CURRENT_TIME
+#define Y_TIME_CONVERT(x) (x)
+#endif
+
+#define compile_time_assertion(assertion) \
+	({ int x = __builtin_choose_expr(assertion, 0, (void)0); (void) x; })
+
+
+#define yaffs_printf(msk, fmt, ...) \
+	printk(KERN_DEBUG "yaffs: " fmt "\n", ##__VA_ARGS__)
+
+#define yaffs_trace(msk, fmt, ...) do { \
+	if (yaffs_trace_mask & (msk)) \
+		printk(KERN_DEBUG "yaffs: " fmt "\n", ##__VA_ARGS__); \
+} while (0)
+
+
+#endif
diff --git a/include/dt-bindings/clock/hi3516a-clock.h b/include/dt-bindings/clock/hi3516a-clock.h
new file mode 100644
index 0000000..2de87a4
--- /dev/null
+++ b/include/dt-bindings/clock/hi3516a-clock.h
@@ -0,0 +1,110 @@
+/*
+ * Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef __DTS_HI3516A_CLOCK_H
+#define __DTS_HI3516A_CLOCK_H
+
+/* clk in CRG */
+/* fixed rate clocks */
+#define HI3516A_INNER_CLK_OFFSET 64
+#define HI3516A_FIXED_3M        65
+#define HI3516A_FIXED_6M        66
+#define HI3516A_FIXED_13P5M     67
+#define HI3516A_FIXED_24M       68
+#define HI3516A_FIXED_25M       69
+#define HI3516A_FIXED_27M       70
+#define HI3516A_FIXED_37P125M   71
+#define HI3516A_FIXED_50M       72
+#define HI3516A_FIXED_74P25M    73
+#define HI3516A_FIXED_75M       74
+#define HI3516A_FIXED_99M       75
+#define HI3516A_FIXED_100M      76
+#define HI3516A_FIXED_125M      77
+#define HI3516A_FIXED_145M      78
+#define HI3516A_FIXED_148P5M	79
+#define HI3516A_FIXED_150M      80
+#define HI3516A_FIXED_194M      81
+#define HI3516A_FIXED_198M      82
+#define HI3516A_FIXED_200M      83
+#define HI3516A_FIXED_229M      84
+#define HI3516A_FIXED_237M      85
+#define HI3516A_FIXED_242M      86
+#define HI3516A_FIXED_250M      87
+#define HI3516A_FIXED_297M      88
+#define HI3516A_FIXED_300M      89
+#define HI3516A_FIXED_333M      90
+#define HI3516A_FIXED_400M      91
+#define HI3516A_FIXED_500M      92
+#define HI3516A_FIXED_594M      93
+#define HI3516A_FIXED_600M      94
+#define HI3516A_FIXED_726P25M   95
+#define HI3516A_FIXED_750M      96
+#define HI3516A_FIXED_900M      97
+#define HI3516A_FIXED_1000M     98
+#define HI3516A_FIXED_1188M     99
+
+/* mux clocks */
+#define HI3516A_SYSAXI_CLK		0
+#define HI3516A_SNOR_MUX        1
+#define HI3516A_SNAND_MUX       2
+#define HI3516A_NAND_MUX        3
+#define HI3516A_UART_MUX        4
+#define HI3516A_ETH_PHY_MUX		5
+#define HI3516A_A7_MUX          6
+#define HI3516A_MMC0_MUX        7
+#define HI3516A_MMC1_MUX        8
+#define HI3516A_USB2_CTRL_UTMI0_REQ     9
+#define HI3516A_USB2_HRST_REQ           10
+
+/* gate clocks */
+#define HI3516A_SNOR_CLK		15
+#define HI3516A_SNAND_CLK		16
+#define HI3516A_NAND_CLK		17
+#define HI3516A_UART0_CLK		18
+#define HI3516A_UART1_CLK		19
+#define HI3516A_UART2_CLK		20
+#define HI3516A_UART3_CLK		21
+#define HI3516A_ETH_CLK			22
+#define HI3516A_ETH_MACIF_CLK	23
+#define HI3516A_MMC0_CLK		24
+#define HI3516A_MMC1_CLK        25
+#define HI3516A_SPI0_CLK		26
+#define HI3516A_SPI1_CLK        27
+#define HI3516A_DMAC_CLK		28
+
+/* pll clock */
+#define HI3516A_APLL_CLK		30
+
+#define HI3516A_CRG_NR_CLKS     128
+#define HI3516A_CRG_NR_RSTS     0x12c
+
+/* clock in system control */
+/* mux clocks */
+#define HI3516A_TIME0_0_CLK     1
+#define HI3516A_TIME0_1_CLK     2
+#define HI3516A_TIME1_2_CLK     3
+#define HI3516A_TIME1_3_CLK     4
+#define HI3516A_TIME2_4_CLK     5
+#define HI3516A_TIME2_5_CLK     6
+#define HI3516A_TIME3_6_CLK     7
+#define HI3516A_TIME3_7_CLK     8
+
+#define HI3516A_SYS_NR_CLKS     10
+#define HI3516A_SYS_NR_RSTS     0x10
+
+#endif  /* __DTS_HI3516A_CLOCK_H */
diff --git a/include/dt-bindings/clock/hi3536dv100-clock.h b/include/dt-bindings/clock/hi3536dv100-clock.h
new file mode 100644
index 0000000..71b9038
--- /dev/null
+++ b/include/dt-bindings/clock/hi3536dv100-clock.h
@@ -0,0 +1,82 @@
+/*
+ * Copyright (c) 2016-2017 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ */
+
+#ifndef __DTS_HI3536DV100_CLOCK_H
+#define __DTS_HI3536DV100_CLOCK_H
+
+/* clk in Hi3536D CRG */
+/* fixed rate clocks */
+#define HI3536DV100_FIXED_3M		1
+#define HI3536DV100_FIXED_6M		2
+#define HI3536DV100_FIXED_12M		3
+#define HI3536DV100_FIXED_24M		4
+#define HI3536DV100_FIXED_50M		5
+#define HI3536DV100_FIXED_83P3M		6
+#define HI3536DV100_FIXED_100M		7
+#define HI3536DV100_FIXED_125M		8
+#define HI3536DV100_FIXED_148P5M	9
+#define HI3536DV100_FIXED_150M		10
+#define HI3536DV100_FIXED_200M		11
+#define HI3536DV100_FIXED_250M		12
+#define HI3536DV100_FIXED_300M		13
+#define HI3536DV100_FIXED_324M		14
+#define HI3536DV100_FIXED_342M		15
+#define HI3536DV100_FIXED_375M		16
+#define HI3536DV100_FIXED_400M		17
+#define HI3536DV100_FIXED_448M		18
+#define HI3536DV100_FIXED_500M		19
+#define HI3536DV100_FIXED_540M		20
+#define HI3536DV100_FIXED_600M		21
+#define HI3536DV100_FIXED_750M		22
+#define HI3536DV100_FIXED_1500M		23
+
+/* mux clocks */
+#define HI3536DV100_SYSAXI_CLK		24
+#define HI3536DV100_SYSAPB_CLK		25
+#define HI3536DV100_FMC_MUX			26
+#define HI3536DV100_UART_MUX		27
+
+/* gate clocks */
+#define HI3536DV100_UART0_CLK		28
+#define HI3536DV100_UART1_CLK		29
+#define HI3536DV100_UART2_CLK		30
+#define HI3536DV100_FMC_CLK			31
+#define HI3536DV100_ETH0_CLK		32
+#define HI3536DV100_ETH0_PHY_CLK	33
+#define HI3536DV100_USB2_BUS_CLK	34
+#define HI3536DV100_USB2_CLK		35
+#define HI3536DV100_SATA_CLK		36
+#define HI3536DV100_DMAC_CLK		37
+
+#define HI3536DV100_CRG_NR_CLKS		40
+#define HI3536DV100_CRG_NR_RSTS		0x200
+
+/* clock in system control */
+/* mux clocks */
+#define HI3536DV100_TIME0_0_CLK		1
+#define HI3536DV100_TIME0_1_CLK		2
+#define HI3536DV100_TIME1_2_CLK		3
+#define HI3536DV100_TIME1_3_CLK		4
+#define HI3536DV100_TIME2_4_CLK		5
+#define HI3536DV100_TIME2_5_CLK		6
+#define HI3536DV100_TIME3_6_CLK		7
+#define HI3536DV100_TIME3_7_CLK		8
+
+#define HI3536DV100_SYS_NR_CLKS		10
+#define HI3536DV100_SYS_NR_RSTS		0x10
+#endif	/* __DTS_HI3536DV100_CLOCK_H */
diff --git a/include/linux/dma-mapping.h b/include/linux/dma-mapping.h
index 08528af..7fb344f 100644
--- a/include/linux/dma-mapping.h
+++ b/include/linux/dma-mapping.h
@@ -705,6 +705,8 @@ dma_mark_declared_memory_occupied(struct device *dev,
 /*
  * Managed DMA API
  */
+void hi_dmac_map_area(const void *kaddr, size_t size,
+			enum dma_data_direction dir);
 extern void *dmam_alloc_coherent(struct device *dev, size_t size,
 				 dma_addr_t *dma_handle, gfp_t gfp);
 extern void dmam_free_coherent(struct device *dev, size_t size, void *vaddr,
diff --git a/include/linux/fs.h b/include/linux/fs.h
index 2f63d44..dd88ded 100644
--- a/include/linux/fs.h
+++ b/include/linux/fs.h
@@ -941,9 +941,9 @@ static inline struct file *get_file(struct file *f)
 /* Page cache limit. The filesystems should put that into their s_maxbytes 
    limits, otherwise bad things can happen in VM. */ 
 #if BITS_PER_LONG==32
-#define MAX_LFS_FILESIZE	(((loff_t)PAGE_SIZE << (BITS_PER_LONG-1))-1)
+#define MAX_LFS_FILESIZE	((loff_t)ULONG_MAX << PAGE_SHIFT)
 #elif BITS_PER_LONG==64
-#define MAX_LFS_FILESIZE 	((loff_t)0x7fffffffffffffffLL)
+#define MAX_LFS_FILESIZE 	((loff_t)LLONG_MAX)
 #endif
 
 #define FL_POSIX	1
diff --git a/include/linux/hidmac.h b/include/linux/hidmac.h
new file mode 100644
index 0000000..bf291be
--- /dev/null
+++ b/include/linux/hidmac.h
@@ -0,0 +1,135 @@
+/******************************************************************************
+ *    COPYRIGHT (C) 2013 Hisilicon
+ *    All rights reserved.
+ * ***
+ *    Create 2013-08-23
+ *
+ ******************************************************************************/
+#ifndef __DMAC_H__
+#define __DMAC_H__
+
+#define DMAC_ERROR_BASE		100
+#define DMAC_CHN_SUCCESS	(DMAC_ERROR_BASE+0x10)
+
+#ifdef CONFIG_HI_DMAC
+extern int dma_driver_init(void);
+extern int dmac_channelclose(unsigned int channel);
+extern int dmac_channelstart(unsigned int u32channel);
+extern int dmac_channel_allocate(void *pisr);
+
+extern int dmac_start_m2p(unsigned int channel, unsigned int pmemaddr,
+			unsigned int uwperipheralid,
+			unsigned int uwnumtransfers,
+			unsigned int next_lli_addr);
+extern int dmac_m2p_transfer(unsigned int memaddr,
+			unsigned int uwperipheralid, unsigned int length);
+extern int dmac_channel_free(unsigned int channel);
+extern int do_dma_m2p(unsigned int mem_addr, unsigned int peripheral_addr,
+		unsigned int length);
+extern int do_dma_p2m(unsigned int mem_addr, unsigned int peripheral_addr,
+		unsigned int length);
+extern int dmac_wait(int channel);
+extern int dmac_start_m2m(unsigned int channel, unsigned int psource,
+			unsigned int pdest, unsigned int uwnumtransfers);
+extern int dmac_m2m_transfer(unsigned int source,
+			unsigned int dest, unsigned int length);
+extern int dmac_register_isr(unsigned int channel, void *pisr);
+extern int free_dmalli_space(unsigned int *ppheadlli, unsigned int page_num);
+extern int dmac_start_llim2p(unsigned int channel, unsigned int *pfirst_lli,
+				unsigned int uwperipheralid);
+extern int dmac_buildllim2m(unsigned int *ppheadlli, unsigned int pdest,
+				unsigned int psource,
+				unsigned int totaltransfersize,
+				unsigned int uwnumtransfers);
+extern int dmac_start_llim2m(unsigned int channel, unsigned int *pfirst_lli);
+extern int allocate_dmalli_space(unsigned int *ppheadlli,
+					unsigned int page_num);
+
+extern int do_dma_llim2m_isp(unsigned int *source,
+		unsigned int *dest,
+		unsigned int *length,
+		unsigned int num);
+
+#else /* !CONFIG_HI_DMAC */
+static inline int dma_driver_init(void) { return 0; }
+static inline int dmac_channelclose(unsigned int channel) { return 0; }
+static inline int dmac_channelstart(unsigned int u32channel) { return 0; }
+static inline int dmac_channel_allocate(void *pisr) { return 0; }
+
+static inline int dmac_start_m2p(unsigned int channel, unsigned int pmemaddr,
+		unsigned int uwperipheralid,
+		unsigned int uwnumtransfers,
+		unsigned int next_lli_addr)
+{ return 0; }
+
+static inline int dmac_m2p_transfer(unsigned int memaddr,
+		unsigned int uwperipheralid, unsigned int length)
+{ return 0; }
+
+static inline int dmac_channel_free(unsigned int channel) { return 0; }
+
+int do_dma_m2p(unsigned int mem_addr, unsigned int peripheral_addr,
+		unsigned int length)
+{ return 0; }
+
+static inline int do_dma_p2m(unsigned int mem_addr,
+		unsigned int peripheral_addr,
+		unsigned int length)
+{ return 0; }
+
+static inline int dmac_wait(int channel) { return 0; }
+
+static inline int dmac_start_m2m(unsigned int channel, unsigned int psource,
+		unsigned int pdest, unsigned int uwnumtransfers)
+{ return 0; }
+
+static inline int dmac_m2m_transfer(unsigned int source,
+		unsigned int dest, unsigned int length)
+{ return 0; }
+
+static inline int dmac_register_isr(unsigned int channel, void *pisr)
+{ return 0; }
+
+static inline  int free_dmalli_space(unsigned int *ppheadlli,
+		unsigned int page_num)
+{ return 0; }
+
+static inline  int dmac_start_llim2p(unsigned int channel,
+		unsigned int *pfirst_lli,
+		unsigned int uwperipheralid)
+{ return 0; }
+
+static inline int dmac_buildllim2m(unsigned int *ppheadlli, unsigned int pdest,
+		unsigned int psource,
+		unsigned int totaltransfersize,
+		unsigned int uwnumtransfers)
+{ return 0; }
+
+static inline int dmac_start_llim2m(unsigned int channel,
+		unsigned int *pfirst_lli)
+{ return 0; }
+
+static inline int allocate_dmalli_space(unsigned int *ppheadlli,
+		unsigned int page_num)
+{ return 0; }
+
+static inline int do_dma_llim2m_isp(unsigned int *source,
+		unsigned int *dest,
+		unsigned int *length,
+		unsigned int num)
+{ return 0; }
+#endif /* CONFIG_HI_DMAC */
+
+/*structure for LLI*/
+typedef struct dmac_lli {
+	/*source address*/
+	unsigned int src_addr;
+	/*destination address*/
+	unsigned int dst_addr;
+	/*pointer to next LLI*/
+	unsigned int next_lli;
+	/*control word*/
+	unsigned int lli_transfer_ctrl;
+} dmac_lli;
+
+#endif
diff --git a/include/linux/i2c.h b/include/linux/i2c.h
index 6422eef..493dbc8 100644
--- a/include/linux/i2c.h
+++ b/include/linux/i2c.h
@@ -553,6 +553,9 @@ struct i2c_adapter {
 	const struct i2c_lock_operations *lock_ops;
 	struct rt_mutex bus_lock;
 	struct rt_mutex mux_lock;
+#ifdef CONFIG_ARCH_HISI_BVT
+	spinlock_t spinlock;
+#endif
 
 	int timeout;			/* in jiffies */
 	int retries;
diff --git a/include/linux/mfd/hisi_fmc.h b/include/linux/mfd/hisi_fmc.h
new file mode 100644
index 0000000..e12c628
--- /dev/null
+++ b/include/linux/mfd/hisi_fmc.h
@@ -0,0 +1,516 @@
+/*
+ * Header file for HiSilicon Flash Memory Controller Driver
+ *
+ * Copyright (c) 2016 HiSilicon Technologies Co., Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#ifndef __HISI_FMC_H
+#define __HISI_FMC_H
+
+#include <linux/compiler.h>
+#include <linux/clk.h>
+#include <linux/mutex.h>
+#include <linux/bitops.h>
+
+/*****************************************************************************/
+#define _512B					(512)
+#define _1K					(1024)
+#define _2K					(2048)
+#define _4K					(4096)
+#define _8K					(8192)
+#define _16K					(16384)
+#define _32K					(32768)
+#define _64K					(0x10000UL)
+#define _128K					(0x20000UL)
+#define _256K					(0x40000UL)
+#define _512K					(0x80000UL)
+#define _1M					(0x100000UL)
+#define _2M					(0x200000UL)
+#define _4M					(0x400000UL)
+#define _8M					(0x800000UL)
+#define _16M					(0x1000000UL)
+#define _32M					(0x2000000UL)
+#define _64M					(0x4000000UL)
+#define _128M					(0x8000000UL)
+#define _256M					(0x10000000UL)
+#define _512M					(0x20000000UL)
+#define _1G					(0x40000000ULL)
+#define _2G					(0x80000000ULL)
+#define _4G					(0x100000000ULL)
+#define _8G					(0x200000000ULL)
+#define _16G					(0x400000000ULL)
+#define _64G					(0x1000000000ULL)
+
+/*****************************************************************************/
+/* HIFMC REG MAP */
+/*****************************************************************************/
+#define FMC_CFG					0x00
+#define FMC_CFG_SPI_NAND_SEL(_type)		(((_size) & 0x3) << 11)
+#define SPI_NOR_ADDR_MODE			BIT(10)
+#define FMC_CFG_OP_MODE_MASK			BIT_MASK(0)
+#define FMC_CFG_OP_MODE_BOOT			0
+#define FMC_CFG_OP_MODE_NORMAL			1
+#define SPI_NOR_ADDR_MODE_3BYTES		(0x0 << 10)
+#define SPI_NOR_ADDR_MODE_4BYTES		(0x1 << 10)
+
+#define FMC_CFG_BLOCK_SIZE(_size)		(((_size) & 0x3) << 8)
+#define FMC_CFG_ECC_TYPE(_type)			(((_type) & 0x7) << 5)
+#define FMC_CFG_PAGE_SIZE(_size)		(((_size) & 0x3) << 3)
+#define FMC_CFG_FLASH_SEL(_type)		(((_type) & 0x3) << 1)
+#define FMC_CFG_OP_MODE(_mode)			((_mode) & 0x1)
+
+#define SPI_NAND_MFR_OTHER			0x0
+#define SPI_NAND_MFR_WINBOND			0x1
+#define SPI_NAND_MFR_ESMT			0x2
+#define SPI_NAND_MFR_MICRON			0x3
+
+#define SPI_NAND_SEL_SHIFT			11
+#define SPI_NAND_SEL_MASK			(0x3 << SPI_NAND_SEL_SHIFT)
+
+#define SPI_NOR_ADDR_MODE_3_BYTES		0x0
+#define SPI_NOR_ADDR_MODE_4_BYTES		0x1
+
+#define SPI_NOR_ADDR_MODE_SHIFT			10
+#define SPI_NOR_ADDR_MODE_MASK			(0x1 << SPI_NOR_ADDR_MODE_SHIFT)
+
+#define BLOCK_SIZE_64_PAGE			0x0
+#define BLOCK_SIZE_128_PAGE			0x1
+#define BLOCK_SIZE_256_PAGE			0x2
+#define BLOCK_SIZE_512_PAGE			0x3
+
+#define BLOCK_SIZE_MASK				(0x3 << 8)
+
+#define ECC_TYPE_0BIT				0x0
+#define ECC_TYPE_8BIT				0x1
+#define ECC_TYPE_16BIT				0x2
+#define ECC_TYPE_24BIT				0x3
+#define ECC_TYPE_28BIT				0x4
+#define ECC_TYPE_40BIT				0x5
+#define ECC_TYPE_64BIT				0x6
+
+#define ECC_TYPE_SHIFT				5
+#define ECC_TYPE_MASK				(0x7 << ECC_TYPE_SHIFT)
+
+#define PAGE_SIZE_2KB				0x0
+#define PAGE_SIZE_4KB				0x1
+#define PAGE_SIZE_8KB				0x2
+#define PAGE_SIZE_16KB				0x3
+
+#define PAGE_SIZE_SHIFT				3
+#define PAGE_SIZE_MASK				(0x3 << PAGE_SIZE_SHIFT)
+
+#define FLASH_TYPE_SPI_NOR			0x0
+#define FLASH_TYPE_SPI_NAND			0x1
+#define FLASH_TYPE_NAND				0x2
+#define FLASH_TYPE_UNKNOWN			0x3
+
+#define FLASH_TYPE_SEL_MASK			(0x3 << 1)
+#define GET_SPI_FLASH_TYPE(_reg)		(((_reg) >> 1) & 0x3)
+
+/*****************************************************************************/
+#define FMC_GLOBAL_CFG				0x04
+#define FMC_GLOBAL_CFG_WP_ENABLE		BIT(6)
+#define FMC_GLOBAL_CFG_RANDOMIZER_EN		(1 << 2)
+#define FLASH_TYPE_SEL_MASK			(0x3 << 1)
+#define FMC_CFG_FLASH_SEL(_type)		(((_type) & 0x3) << 1)
+
+/*****************************************************************************/
+#define FMC_SPI_TIMING_CFG			0x08
+#define TIMING_CFG_TCSH(nr)			(((nr) & 0xf) << 8)
+#define TIMING_CFG_TCSS(nr)			(((nr) & 0xf) << 4)
+#define TIMING_CFG_TSHSL(nr)			((nr) & 0xf)
+
+#define CS_HOLD_TIME				0x6
+#define CS_SETUP_TIME				0x6
+#define CS_DESELECT_TIME			0xf
+
+/*****************************************************************************/
+#define FMC_PND_PWIDTH_CFG			0x0c
+#define PWIDTH_CFG_RW_HCNT(_n)			(((_n) & 0xf) << 8)
+#define PWIDTH_CFG_R_LCNT(_n)			(((_n) & 0xf) << 4)
+#define PWIDTH_CFG_W_LCNT(_n)			((_n) & 0xf)
+
+#define RW_H_WIDTH				(0xa)
+#define R_L_WIDTH				(0xa)
+#define W_L_WIDTH				(0xa)
+
+/*****************************************************************************/
+#define FMC_INT					0x18
+#define FMC_INT_AHB_OP				BIT(7)
+#define FMC_INT_WR_LOCK				BIT(6)
+#define FMC_INT_DMA_ERR				BIT(5)
+#define FMC_INT_ERR_ALARM			BIT(4)
+#define FMC_INT_ERR_INVALID			BIT(3)
+#define FMC_INT_ERR_INVALID_MASK		(0x8)
+#define FMC_INT_ERR_VALID			BIT(2)
+#define FMC_INT_ERR_VALID_MASK			(0x4)
+#define FMC_INT_OP_FAIL				BIT(1)
+#define FMC_INT_OP_DONE				BIT(0)
+
+/*****************************************************************************/
+#define FMC_INT_EN				0x1c
+#define FMC_INT_EN_AHB_OP			BIT(7)
+#define FMC_INT_EN_WR_LOCK			BIT(6)
+#define FMC_INT_EN_DMA_ERR			BIT(5)
+#define FMC_INT_EN_ERR_ALARM			BIT(4)
+#define FMC_INT_EN_ERR_INVALID			BIT(3)
+#define FMC_INT_EN_ERR_VALID			BIT(2)
+#define FMC_INT_EN_OP_FAIL			BIT(1)
+#define FMC_INT_EN_OP_DONE			BIT(0)
+
+/*****************************************************************************/
+#define FMC_INT_CLR				0x20
+#define FMC_INT_CLR_AHB_OP			BIT(7)
+#define FMC_INT_CLR_WR_LOCK			BIT(6)
+#define FMC_INT_CLR_DMA_ERR			BIT(5)
+#define FMC_INT_CLR_ERR_ALARM			BIT(4)
+#define FMC_INT_CLR_ERR_INVALID			BIT(3)
+#define FMC_INT_CLR_ERR_VALID			BIT(2)
+#define FMC_INT_CLR_OP_FAIL			BIT(1)
+#define FMC_INT_CLR_OP_DONE			BIT(0)
+
+#define FMC_INT_CLR_ALL				0xff
+
+/*****************************************************************************/
+#define FMC_CMD					0x24
+#define FMC_CMD_CMD2(_cmd)			(((_cmd) & 0xff) << 8)
+#define FMC_CMD_CMD1(_cmd)			((_cmd) & 0xff)
+
+/*****************************************************************************/
+#define FMC_ADDRH				0x28
+#define FMC_ADDRH_SET(_addr)			((_addr) & 0xff)
+
+/*****************************************************************************/
+#define FMC_ADDRL				0x2c
+#define FMC_ADDRL_BLOCK_MASK(_page)		((_page) & 0xffffffc0)
+#define FMC_ADDRL_BLOCK_H_MASK(_page)		(((_page) & 0xffff) << 16)
+#define FMC_ADDRL_BLOCK_L_MASK(_page)		((_page) & 0xffc0)
+
+#define READ_ID_ADDR				0x00
+#define PROTECT_ADDR				0xa0
+#define FEATURE_ADDR				0xb0
+#define STATUS_ADDR					0xc0
+/*****************************************************************************/
+#define FMC_OP_CFG				0x30
+#define OP_CFG_FM_CS(_cs)			((_cs) << 11)
+#define OP_CFG_FORCE_CS_EN(_en)			((_en) << 10)
+#define OP_CFG_MEM_IF_TYPE(_type)		(((_type) & 0x7) << 7)
+#define OP_CFG_ADDR_NUM(_addr)			(((_addr) & 0x7) << 4)
+#define OP_CFG_DUMMY_NUM(_dummy)		((_dummy) & 0xf)
+
+#define IF_TYPE_SHIFT				7
+#define IF_TYPE_MASK				(0x7 << IF_TYPE_SHIFT)
+
+#define READ_ID_ADDR_NUM			1
+#define FEATURES_OP_ADDR_NUM			1
+#define STD_OP_ADDR_NUM				3
+
+/*****************************************************************************/
+#define FMC_SPI_OP_ADDR				0x34
+
+/*****************************************************************************/
+#define FMC_DATA_NUM				0x38
+#define FMC_DATA_NUM_CNT(_n)			((_n) & 0x3fff)
+
+#define SPI_NOR_SR_LEN				1 /* Status Register length */
+#define SPI_NOR_CR_LEN				1 /* Config Register length */
+#define FEATURES_DATA_LEN			1
+#define READ_OOB_BB_LEN				1
+
+#define PROTECT_BRWD_MASK			BIT(7)
+#define PROTECT_BP3_MASK			BIT(6)
+#define PROTECT_BP2_MASK			BIT(5)
+#define PROTECT_BP1_MASK			BIT(4)
+#define PROTECT_BP0_MASK			BIT(3)
+
+#define ANY_BP_ENABLE(_val)			((PROTECT_BP3_MASK & _val) \
+						|| (PROTECT_BP2_MASK & _val) \
+						|| (PROTECT_BP1_MASK & _val) \
+						|| (PROTECT_BP0_MASK & _val))
+
+#define ALL_BP_MASK				(PROTECT_BP3_MASK \
+						| PROTECT_BP2_MASK \
+						| PROTECT_BP1_MASK \
+						| PROTECT_BP0_MASK)
+
+#define FEATURE_ECC_ENABLE		        (1 << 4)
+#define FEATURE_QE_ENABLE			(1 << 0)
+
+/*****************************************************************************/
+#define FMC_OP					0x3c
+#define FMC_OP_DUMMY_EN				BIT(8)
+#define FMC_OP_CMD1_EN				BIT(7)
+#define FMC_OP_ADDR_EN				BIT(6)
+#define FMC_OP_WRITE_DATA_EN			BIT(5)
+#define FMC_OP_CMD2_EN				BIT(4)
+#define FMC_OP_WAIT_READY_EN			BIT(3)
+#define FMC_OP_READ_DATA_EN			BIT(2)
+#define FMC_OP_READ_STATUS_EN			BIT(1)
+#define FMC_OP_REG_OP_START			BIT(0)
+
+/*****************************************************************************/
+#define FMC_DMA_LEN				0x40
+#define FMC_DMA_LEN_SET(_len)			((_len) & 0x0fffffff)
+
+/*****************************************************************************/
+#define FMC_DMA_AHB_CTRL			0x48
+#define FMC_DMA_AHB_CTRL_DMA_PP_EN		BIT(3)
+#define FMC_DMA_AHB_CTRL_BURST16_EN		BIT(2)
+#define FMC_DMA_AHB_CTRL_BURST8_EN		BIT(1)
+#define FMC_DMA_AHB_CTRL_BURST4_EN		BIT(0)
+
+#define ALL_BURST_ENABLE			(FMC_DMA_AHB_CTRL_BURST16_EN \
+						| FMC_DMA_AHB_CTRL_BURST8_EN \
+						| FMC_DMA_AHB_CTRL_BURST4_EN)
+
+#define FMC_DMA_ADDR_OFFSET			4096
+
+/*****************************************************************************/
+#define FMC_DMA_SADDR_D0			0x4c
+#define HIFMC_DMA_MAX_LEN			(4096)
+#define HIFMC_DMA_MASK				(HIFMC_DMA_MAX_LEN - 1)
+
+/*****************************************************************************/
+#define FMC_DMA_SADDR_D1			0x50
+
+/*****************************************************************************/
+#define FMC_DMA_SADDR_D2			0x54
+
+/*****************************************************************************/
+#define FMC_DMA_SADDR_D3			0x58
+
+/*****************************************************************************/
+#define FMC_DMA_SADDR_OOB			0x5c
+
+#ifdef CONFIG_64BIT
+/*****************************************************************************/
+#define FMC_DMA_SADDRH_D0                       0x200
+#define FMC_DMA_SADDRH_SHIFT                    0x3LL
+#define FMC_DMA_SADDRH_MASK                     (FMC_DMA_SADDRH_SHIFT << 32)
+
+/*****************************************************************************/
+#define FMC_DMA_SADDRH_OOB                      0x210
+#endif
+
+/*****************************************************************************/
+#define FMC_DMA_BLK_SADDR			0x60
+#define FMC_DMA_BLK_SADDR_SET(_addr)		((_addr) & 0xffffff)
+
+/*****************************************************************************/
+#define FMC_DMA_BLK_LEN				0x64
+#define FMC_DMA_BLK_LEN_SET(_len)		((_len) & 0xffff)
+
+/*****************************************************************************/
+#define FMC_OP_CTRL				0x68
+#define OP_CTRL_RD_OPCODE(code)		(((code) & 0xff) << 16)
+#define OP_CTRL_WR_OPCODE(code)		(((code) & 0xff) << 8)
+#define OP_CTRL_RD_OP_SEL(_op)          	(((_op) & 0x3) << 4)
+#define OP_CTRL_DMA_OP(_type)			((_type) << 2)
+#define OP_CTRL_RW_OP(op)		((op) << 1)
+#define OP_CTRL_DMA_OP_READY		BIT(0)
+
+#define RD_OP_READ_ALL_PAGE			0x0
+#define RD_OP_READ_OOB				0x1
+#define RD_OP_BLOCK_READ			0x2
+
+#define RD_OP_SHIFT				4
+#define RD_OP_MASK				(0x3 << RD_OP_SHIFT)
+
+#define OP_TYPE_DMA				0x0
+#define OP_TYPE_REG				0x1
+
+#define FMC_OP_READ				0x0
+#define FMC_OP_WRITE				0x1
+#define RW_OP_READ				0x0
+#define RW_OP_WRITE				0x1
+
+/*****************************************************************************/
+#define FMC_OP_PARA				0x70
+#define FMC_OP_PARA_RD_OOB_ONLY			BIT(1)
+
+/*****************************************************************************/
+#define FMC_BOOT_SET				0x74
+#define FMC_BOOT_SET_DEVICE_ECC_EN		BIT(3)
+#define FMC_BOOT_SET_BOOT_QUAD_EN		BIT(1)
+
+/*****************************************************************************/
+#define FMC_STATUS				0xac
+
+/*****************************************************************************/
+#ifndef FMC_VERSION
+#define FMC_VERSION				0xbc
+#endif
+
+/* Hifmc IP version */
+#ifndef HIFMC_VER_100
+#define HIFMC_VER_100				(0x100)
+#endif
+
+/*****************************************************************************/
+/* DMA address align with 32 bytes. */
+#define FMC_DMA_ALIGN                           32
+
+#define FMC_CHIP_DELAY                          25
+/*****************************************************************************/
+#define HIFMC_ECC_ERR_NUM0_BUF0			0xc0
+#define GET_ECC_ERR_NUM(_i, _reg)		(((_reg) >> ((_i) * 8)) & 0xff)
+
+#define DISABLE               0
+#define ENABLE                1
+
+/*****************************************************************************/
+#define HIFMC_REG_ADDRESS_LEN			0x200
+
+/*****************************************************************************/
+#define FMC_MAX_READY_WAIT_JIFFIES		(HZ)
+
+#define MAX_SPI_NOR_ID_LEN			8
+#define MAX_NAND_ID_LEN				8
+#define MAX_SPI_NAND_ID_LEN			3
+
+#define GET_OP					0
+#define SET_OP					1
+
+#define STATUS_ECC_MASK				(0x3 << 4)
+#define STATUS_P_FAIL_MASK			(1 << 3)
+#define STATUS_E_FAIL_MASK			(1 << 2)
+#define STATUS_WEL_MASK				(1 << 1)
+#define STATUS_OIP_MASK				(1 << 0)
+
+/*****************************************************************************/
+#define FMC_VERSION				0xbc
+
+/* Hifmc IP version */
+#define HIFMC_VER_100				(0x100)
+
+#define CONFIG_SPI_NAND_MAX_CHIP_NUM		(1)
+
+#define CONFIG_HIFMC100_MAX_NAND_CHIP	(1)
+
+/*****************************************************************************/
+#define GET_PAGE_INDEX(host) \
+	                ((host->addr_value[0] >> 16) | (host->addr_value[1] << 16))
+/*****************************************************************************/
+#define HIFMC_MAX_CHIP_NUM		2
+
+extern unsigned char hifmc_cs_user[];
+
+/*****************************************************************************/
+#define hifmc_readl(_host, _reg) \
+	(readl((char *)_host->regbase + (_reg)))
+
+#define hifmc_readb( _addr) \
+	(readb((void __iomem *)(_addr)))
+
+#define hifmc_readw( _addr) \
+	(readw((void __iomem *)(_addr)))
+
+#define hifmc_writel(_host, _reg, _value) \
+	(writel((u_int)(_value), ((char *)_host->regbase + (_reg))))
+
+#define hifmc_writeb(_val, _addr) \
+	(writeb((u_int)(_val), ((char *)_addr)))
+
+/*****************************************************************************/
+#define FMC_WAIT_TIMEOUT 0x1000000
+
+#define FMC_CMD_WAIT_CPU_FINISH(_host) \
+	do { \
+		unsigned regval, timeout = FMC_WAIT_TIMEOUT * 2; \
+		do { \
+			regval = hifmc_readl((_host), FMC_OP); \
+			--timeout; \
+		} while ((regval & FMC_OP_REG_OP_START) && timeout); \
+		if (!timeout) \
+			pr_info("Error: Wait cmd cpu finish timeout!\n"); \
+	} while (0)
+
+/*****************************************************************************/
+#define FMC_DMA_WAIT_INT_FINISH(_host) \
+	do { \
+		unsigned regval, timeout = FMC_WAIT_TIMEOUT; \
+		do { \
+			regval = hifmc_readl((_host), FMC_INT); \
+			--timeout; \
+		} while ((!(regval & FMC_INT_OP_DONE) && timeout)); \
+		if (!timeout) \
+			pr_info("Error: Wait dma int finish timeout!\n"); \
+	} while (0)
+
+/*****************************************************************************/
+#define FMC_DMA_WAIT_CPU_FINISH(_host) \
+	do { \
+		unsigned regval, timeout = FMC_WAIT_TIMEOUT; \
+		do { \
+			regval = hifmc_readl((_host), FMC_OP_CTRL); \
+			--timeout; \
+		} while ((regval & OP_CTRL_DMA_OP_READY) && timeout); \
+		if (!timeout) \
+			pr_info("Error: Wait dma cpu finish timeout!\n"); \
+	} while (0)
+
+/*****************************************************************************/
+#define BT_DBG		0	/* Boot init debug print */
+#define ER_DBG		0	/* Erase debug print */
+#define WR_DBG		0	/* Write debug print */
+#define RD_DBG		0	/* Read debug print */
+#define QE_DBG		0	/* Quad Enable debug print */
+#define OP_DBG		0	/* OP command debug print */
+#define DMA_DB		0	/* DMA read or write debug print */
+#define AC_DBG		0	/* 3-4byte Address Cycle */
+#define SR_DBG		0	/* Status Register debug print */
+#define CR_DBG		0	/* Config Register debug print */
+#define FT_DBG		0	/* Features debug print */
+#define WE_DBG		0	/* Write Enable debug print */
+#define BP_DBG		0	/* Block Protection debug print */
+#define EC_DBG		0	/* enable/disable ecc0 and randomizer */
+#define PM_DBG		0	/* power management debug */
+
+#define FMC_PR(_type, _fmt, arg...) \
+	do { \
+		if (_type) \
+			DB_MSG(_fmt, ##arg) \
+	} while (0)
+
+#define DB_MSG(_fmt, arg...) \
+	pr_info("%s(%d): " _fmt, __func__, __LINE__, ##arg);
+
+#define DB_BUG(fmt, args...) \
+	do { \
+		pr_info("%s(%d): BUG: " fmt, __FILE__, __LINE__, ##args); \
+		while (1) \
+			; \
+	} while (0)
+
+/*****************************************************************************/
+enum hifmc_iftype {
+	IF_TYPE_STD,
+	IF_TYPE_DUAL,
+	IF_TYPE_DIO,
+	IF_TYPE_QUAD,
+	IF_TYPE_QIO,
+};
+
+struct hisi_fmc {
+	void __iomem *regbase;
+	void __iomem *iobase;
+	struct clk *clk;
+	struct mutex lock;
+};
+
+struct hifmc_cmd_op {
+	unsigned char cs;
+	unsigned char cmd;
+	unsigned char l_cmd;
+	unsigned char addr_h;
+	unsigned int addr_l;
+	unsigned int data_no;
+	unsigned short option;
+	unsigned short op_cfg;
+};
+
+#endif /*__HISI_FMC_H*/
diff --git a/include/linux/mtd/nand.h b/include/linux/mtd/nand.h
index d8905a2..27f5c74 100644
--- a/include/linux/mtd/nand.h
+++ b/include/linux/mtd/nand.h
@@ -80,6 +80,7 @@ int nand_unlock(struct mtd_info *mtd, loff_t ofs, uint64_t len);
 #define NAND_CMD_READOOB	0x50
 #define NAND_CMD_ERASE1		0x60
 #define NAND_CMD_STATUS		0x70
+#define NAND_CMD_STATUS_MULTI	0x71
 #define NAND_CMD_SEQIN		0x80
 #define NAND_CMD_RNDIN		0x85
 #define NAND_CMD_READID		0x90
@@ -87,6 +88,7 @@ int nand_unlock(struct mtd_info *mtd, loff_t ofs, uint64_t len);
 #define NAND_CMD_PARAM		0xec
 #define NAND_CMD_GET_FEATURES	0xee
 #define NAND_CMD_SET_FEATURES	0xef
+#define NAND_CMD_SYNC_RESET	0xfc
 #define NAND_CMD_RESET		0xff
 
 #define NAND_CMD_LOCK		0x2a
@@ -925,9 +927,16 @@ static inline void nand_set_controller_data(struct nand_chip *chip, void *priv)
 #define NAND_MFR_AMD		0x01
 #define NAND_MFR_MACRONIX	0xc2
 #define NAND_MFR_EON		0x92
+#define NAND_MFR_WINBOND	0xef
+#define NAND_MFR_ATO		0x9b
+#define NAND_MFR_MXIC		0xc2
+#define NAND_MFR_ALL_FLASH	0xc1
+#define NAND_MFR_PARAGON	0xa1
 #define NAND_MFR_SANDISK	0x45
 #define NAND_MFR_INTEL		0x89
 #define NAND_MFR_ATO		0x9b
+#define NAND_MFR_GD_ESMT	0xc8
+#define NAND_MFR_HEYANGTEK	0xc9
 
 /* The maximum expected count of bytes in the NAND ID sequence */
 #define NAND_MAX_ID_LEN 8
diff --git a/include/linux/mtd/spi-nor.h b/include/linux/mtd/spi-nor.h
index c425c7b..f66420c 100644
--- a/include/linux/mtd/spi-nor.h
+++ b/include/linux/mtd/spi-nor.h
@@ -12,7 +12,6 @@
 
 #include <linux/bitops.h>
 #include <linux/mtd/cfi.h>
-#include <linux/mtd/mtd.h>
 
 /*
  * Manufacturer IDs
@@ -21,13 +20,50 @@
  * Sometimes these are the same as CFI IDs, but sometimes they aren't.
  */
 #define SNOR_MFR_ATMEL		CFI_MFR_ATMEL
-#define SNOR_MFR_GIGADEVICE	0xc8
 #define SNOR_MFR_INTEL		CFI_MFR_INTEL
 #define SNOR_MFR_MICRON		CFI_MFR_ST /* ST Micro <--> Micron */
 #define SNOR_MFR_MACRONIX	CFI_MFR_MACRONIX
 #define SNOR_MFR_SPANSION	CFI_MFR_AMD
 #define SNOR_MFR_SST		CFI_MFR_SST
-#define SNOR_MFR_WINBOND	0xef /* Also used by some Spansion */
+#define SNOR_MFR_EON		CFI_MFR_EON
+#define SNOR_MFR_WINBOND	0xef
+#define SNOR_MFR_ESMT		0x8c
+#define SNOR_MFR_GD		0xc8
+
+/* Flash set the RESET# from */
+#define SPI_NOR_SR_RST_MASK	BIT(7)
+#define SPI_NOR_GET_RST(val)	(((val) & SPI_NOR_SR_RST_MASK) >> 7)
+#define SPI_NOR_SET_RST(val)    ((val) | SPI_NOR_SR_RST_MASK)
+
+/* Flash block protect */
+#ifdef CONFIG_HISI_SPI_BLOCK_PROTECT
+#define _2M				(0x200000UL)
+#define _4M				(0x400000UL)
+#define _8M				(0x800000UL)
+#define _16M				(0x1000000UL)
+#define _32M				(0x2000000UL)
+
+#define BP_NUM_3                        3
+#define BP_NUM_4                        4
+
+#define DEBUG_SPI_NOR_BP	0
+
+#define SPI_NOR_SR_SRWD_SHIFT	7
+#define SPI_NOR_SR_SRWD_MASK	(1 << SPI_NOR_SR_SRWD_SHIFT)
+
+#define SPI_NOR_SR_BP0_SHIFT    2
+#define SPI_NOR_SR_BP_WIDTH_4   0xf
+#define SPI_NOR_SR_BP_MASK_4    (SPI_NOR_SR_BP_WIDTH_4 << SPI_NOR_SR_BP0_SHIFT)
+
+#define SPI_NOR_SR_BP_WIDTH_3   0x7
+#define SPI_NOR_SR_BP_MASK_3    (SPI_NOR_SR_BP_WIDTH_3 << SPI_NOR_SR_BP0_SHIFT)
+
+#define SPI_NOR_SR_TB_SHIFT	3
+#define SPI_NOR_SR_TB_MASK	(1 << SPI_NOR_SR_TB_SHIFT)
+
+#define LOCK_LEVEL_MAX(bp_num)	(((0x01) << bp_num) - 1)
+
+#endif /* CONFIG_SPI_BLOCK_PROTECT */
 
 /*
  * Note on opcode nomenclature: some opcodes have a format like
@@ -40,27 +76,42 @@
 /* Flash opcodes. */
 #define SPINOR_OP_WREN		0x06	/* Write enable */
 #define SPINOR_OP_RDSR		0x05	/* Read status register */
+#define SPINOR_OP_RDSR2		0x35    /* Read Status Register-2 */
+#define SPINOR_OP_RDSR3		0x15    /* Read Status Register-3 */
 #define SPINOR_OP_WRSR		0x01	/* Write status register 1 byte */
+#define SPINOR_OP_WRSR2		0x31    /* Write Status Register-2 1 byte*/
+#define SPINOR_OP_WRSR3		0x11    /* Write Status Register-3 1 byte*/
 #define SPINOR_OP_READ		0x03	/* Read data bytes (low frequency) */
 #define SPINOR_OP_READ_FAST	0x0b	/* Read data bytes (high frequency) */
-#define SPINOR_OP_READ_1_1_2	0x3b	/* Read data bytes (Dual SPI) */
-#define SPINOR_OP_READ_1_1_4	0x6b	/* Read data bytes (Quad SPI) */
+#define SPINOR_OP_READ_1_1_2	0x3b	/* Read data bytes (Dual Output SPI) */
+#define SPINOR_OP_READ_1_2_2	0xbb	/* Read data bytes (Dual I/O SPI) */
+#define SPINOR_OP_READ_1_1_4	0x6b	/* Read data bytes (Quad Output SPI) */
+#define SPINOR_OP_READ_1_4_4	0xeb	/* Read data bytes (Quad I/O SPI) */
 #define SPINOR_OP_PP		0x02	/* Page program (up to 256 bytes) */
+#define SPINOR_OP_PP_1_1_4	0x32	/* Quad page program */
+#define SPINOR_OP_PP_1_4_4	0x38	/* Quad page program */
 #define SPINOR_OP_BE_4K		0x20	/* Erase 4KiB block */
 #define SPINOR_OP_BE_4K_PMC	0xd7	/* Erase 4KiB block on PMC chips */
 #define SPINOR_OP_BE_32K	0x52	/* Erase 32KiB block */
 #define SPINOR_OP_CHIP_ERASE	0xc7	/* Erase whole flash chip */
 #define SPINOR_OP_SE		0xd8	/* Sector erase (usually 64KiB) */
 #define SPINOR_OP_RDID		0x9f	/* Read JEDEC ID */
+#define SPINOR_OP_RDSFDP	0x5a	/* Read SFDP */
 #define SPINOR_OP_RDCR		0x35	/* Read configuration register */
 #define SPINOR_OP_RDFSR		0x70	/* Read flag status register */
 
 /* 4-byte address opcodes - used on Spansion and some Macronix flashes. */
-#define SPINOR_OP_READ4		0x13	/* Read data bytes (low frequency) */
-#define SPINOR_OP_READ4_FAST	0x0c	/* Read data bytes (high frequency) */
-#define SPINOR_OP_READ4_1_1_2	0x3c	/* Read data bytes (Dual SPI) */
-#define SPINOR_OP_READ4_1_1_4	0x6c	/* Read data bytes (Quad SPI) */
+#define SPINOR_OP_READ_4B	0x13	/* Read data bytes (low frequency) */
+#define SPINOR_OP_READ_FAST_4B	0x0c	/* Read data bytes (high frequency) */
+#define SPINOR_OP_READ_1_1_2_4B	0x3c	/* Read data bytes (Dual Output SPI) */
+#define SPINOR_OP_READ_1_2_2_4B	0xbc	/* Read data bytes (Dual I/O SPI) */
+#define SPINOR_OP_READ_1_1_4_4B	0x6c	/* Read data bytes (Quad Output SPI) */
+#define SPINOR_OP_READ_1_4_4_4B	0xec	/* Read data bytes (Quad I/O SPI) */
 #define SPINOR_OP_PP_4B		0x12	/* Page program (up to 256 bytes) */
+#define SPINOR_OP_PP_1_1_4_4B	0x34	/* Quad page program */
+#define SPINOR_OP_PP_1_4_4_4B	0x3e	/* Quad page program */
+#define SPINOR_OP_BE_4K_4B	0x21	/* Erase 4KiB block */
+#define SPINOR_OP_BE_32K_4B	0x5c	/* Erase 32KiB block */
 #define SPINOR_OP_SE_4B		0xdc	/* Sector erase (usually 64KiB) */
 
 /* Used for SST flashes only. */
@@ -73,12 +124,20 @@
 #define SPINOR_OP_EX4B		0xe9	/* Exit 4-byte mode */
 
 /* Used for Spansion flashes only. */
+#define SPINOR_OP_BRRD		0x16	/* Bank register write */
 #define SPINOR_OP_BRWR		0x17	/* Bank register write */
 
+/* Used for GigaDevice flashes only. */
+#define SPINOR_OP_WRCR		0x31	/* Config register write */
+
 /* Used for Micron flashes only. */
 #define SPINOR_OP_RD_EVCR      0x65    /* Read EVCR register */
 #define SPINOR_OP_WD_EVCR      0x61    /* Write EVCR register */
 
+/* Software reset code */
+#define SPINOR_ENABLE_RESET	0x66	/* Enable reset */
+#define SPINOR_OP_RESET		0x99	/* Reset */
+
 /* Status Register bits. */
 #define SR_WIP			BIT(0)	/* Write in progress */
 #define SR_WEL			BIT(1)	/* Write enable latch */
@@ -92,6 +151,7 @@
 #define SR_QUAD_EN_MX		BIT(6)	/* Macronix Quad I/O */
 
 /* Enhanced Volatile Configuration Register bits */
+#define EVCR_DUAL_EN_MICRON	BIT(6)	/* Micron Dual I/O */
 #define EVCR_QUAD_EN_MICRON	BIT(7)	/* Micron Quad I/O */
 
 /* Flag Status Register bits */
@@ -100,11 +160,105 @@
 /* Configuration Register bits. */
 #define CR_QUAD_EN_SPAN		BIT(1)	/* Spansion Quad I/O */
 
-enum read_mode {
-	SPI_NOR_NORMAL = 0,
-	SPI_NOR_FAST,
-	SPI_NOR_DUAL,
-	SPI_NOR_QUAD,
+/* Supported modes */
+enum spi_nor_mode_index {
+	/* Sorted by ascending priority order */
+	SNOR_MIDX_SLOW = 0,
+	SNOR_MIDX_1_1_1,
+	SNOR_MIDX_1_1_2,
+	SNOR_MIDX_1_2_2,
+	SNOR_MIDX_1_1_4,
+	SNOR_MIDX_1_4_4,
+
+	SNOR_MIDX_MAX
+};
+
+#define SNOR_MODE_SLOW		BIT(SNOR_MIDX_SLOW)
+#define SNOR_MODE_1_1_1		BIT(SNOR_MIDX_1_1_1)
+#define SNOR_MODE_1_1_2		BIT(SNOR_MIDX_1_1_2)
+#define SNOR_MODE_1_2_2		BIT(SNOR_MIDX_1_2_2)
+#define SNOR_MODE_1_1_4		BIT(SNOR_MIDX_1_1_4)
+#define SNOR_MODE_1_4_4		BIT(SNOR_MIDX_1_4_4)
+
+struct spi_nor_modes {
+	u32	rd_modes;	/* supported SPI modes for (Fast) Read */
+	u32	wr_modes;	/* supported SPI modes for Page Program */
+};
+
+struct spi_nor_read_op {
+	u8	num_mode_clocks;
+	u8	num_wait_states;
+	u8	opcode;
+};
+
+#define SNOR_OP_READ(_num_mode_clocks, _num_wait_states, _opcode) \
+	{							  \
+		.num_mode_clocks = _num_mode_clocks,		  \
+		.num_wait_states = _num_wait_states,		  \
+		.opcode = _opcode,				  \
+	}
+
+struct spi_nor_erase_type {
+	u8	size;	/* specifies 'N' so erase size = 2^N */
+	u8	opcode;
+};
+
+#define SNOR_OP_ERASE(_size, _opcode) { .size = _size, .opcode = _opcode }
+#define SNOR_OP_ERASE_64K(_opcode) SNOR_OP_ERASE(0x10, _opcode)
+#define SNOR_OP_ERASE_32K(_opcode) SNOR_OP_ERASE(0x0f, _opcode)
+#define SNOR_OP_ERASE_4K(_opcode)  SNOR_OP_ERASE(0x0c, _opcode)
+
+struct spi_nor;
+
+#define SNOR_MAX_ERASE_TYPES	4
+
+struct spi_nor_basic_flash_parameter {
+	/* Fast Read settings */
+	u32				rd_modes;
+	struct spi_nor_read_op		reads[SNOR_MIDX_MAX];
+
+	/* Page Program settings */
+	u32				wr_modes;
+	u8				page_programs[SNOR_MIDX_MAX];
+
+	/* Sector Erase settings */
+	struct spi_nor_erase_type	erase_types[SNOR_MAX_ERASE_TYPES];
+
+	int (*enable_quad_io)(struct spi_nor *nor);
+};
+
+#define SNOR_PROTO_CODE_OFF	8
+#define SNOR_PROTO_CODE_MASK	GENMASK(11, 8)
+#define SNOR_PROTO_CODE_TO_PROTO(code) \
+	(((code) << SNOR_PROTO_CODE_OFF) & SNOR_PROTO_CODE_MASK)
+#define SNOR_PROTO_CODE_FROM_PROTO(proto) \
+	((((u32)(proto)) & SNOR_PROTO_CODE_MASK) >> SNOR_PROTO_CODE_OFF)
+
+#define SNOR_PROTO_ADDR_OFF	4
+#define SNOR_PROTO_ADDR_MASK	GENMASK(7, 4)
+#define SNOR_PROTO_ADDR_TO_PROTO(addr) \
+	(((addr) << SNOR_PROTO_ADDR_OFF) & SNOR_PROTO_ADDR_MASK)
+#define SNOR_PROTO_ADDR_FROM_PROTO(proto) \
+	((((u32)(proto)) & SNOR_PROTO_ADDR_MASK) >> SNOR_PROTO_ADDR_OFF)
+
+#define SNOR_PROTO_DATA_OFF	0
+#define SNOR_PROTO_DATA_MASK	GENMASK(3, 0)
+#define SNOR_PROTO_DATA_TO_PROTO(data) \
+	(((data) << SNOR_PROTO_DATA_OFF) & SNOR_PROTO_DATA_MASK)
+#define SNOR_PROTO_DATA_FROM_PROTO(proto) \
+	((((u32)(proto)) & SNOR_PROTO_DATA_MASK) >> SNOR_PROTO_DATA_OFF)
+
+#define SNOR_PROTO(code, addr, data)	  \
+	(SNOR_PROTO_CODE_TO_PROTO(code) |   \
+	 SNOR_PROTO_ADDR_TO_PROTO(addr) | \
+	 SNOR_PROTO_DATA_TO_PROTO(data))
+
+enum spi_nor_protocol {
+	SNOR_PROTO_1_1_1 = SNOR_PROTO(1, 1, 1),	/* SPI */
+	SNOR_PROTO_1_1_2 = SNOR_PROTO(1, 1, 2),	/* Dual Output */
+	SNOR_PROTO_1_2_2 = SNOR_PROTO(1, 2, 2),	/* Dual IO */
+	SNOR_PROTO_1_1_4 = SNOR_PROTO(1, 1, 4),	/* Quad Output */
+	SNOR_PROTO_1_4_4 = SNOR_PROTO(1, 4, 4),	/* Quad IO */
 };
 
 #define SPI_NOR_MAX_CMD_SIZE	8
@@ -121,20 +275,26 @@ enum spi_nor_option_flags {
 	SNOR_F_HAS_SR_TB	= BIT(1),
 };
 
+struct mtd_info;
+
 /**
  * struct spi_nor - Structure for defining a the SPI NOR layer
  * @mtd:		point to a mtd_info structure
  * @lock:		the lock for the read/write/erase/lock/unlock operations
  * @dev:		point to a spi device, or a spi nor controller device.
+ * @flash_node:		point to a device node describing this flash instance.
  * @page_size:		the page size of the SPI NOR
  * @addr_width:		number of address bytes
  * @erase_opcode:	the opcode for erasing a sector
  * @read_opcode:	the read opcode
  * @read_dummy:		the dummy needed by the read operation
  * @program_opcode:	the program opcode
- * @flash_read:		the mode of the read
  * @sst_write_second:	used by the SST write operation
  * @flags:		flag options for the current SPI-NOR (SNOR_F_*)
+ * @erase_proto:	the SPI protocol used by erase operations
+ * @read_proto:		the SPI protocol used by read operations
+ * @write_proto:	the SPI protocol used by write operations
+ * @reg_proto		the SPI protocol used by read_reg/write_reg operations
  * @cmd_buf:		used by the write_reg
  * @prepare:		[OPTIONAL] do some preparations for the
  *			read/write/erase/lock/unlock operations
@@ -157,13 +317,16 @@ struct spi_nor {
 	struct mtd_info		mtd;
 	struct mutex		lock;
 	struct device		*dev;
+	struct device_node	*flash_node;
 	u32			page_size;
 	u8			addr_width;
 	u8			erase_opcode;
 	u8			read_opcode;
 	u8			read_dummy;
 	u8			program_opcode;
-	enum read_mode		flash_read;
+	enum spi_nor_protocol	erase_proto;
+	enum spi_nor_protocol	read_proto;
+	enum spi_nor_protocol	write_proto;
 	bool			sst_write_second;
 	u32			flags;
 	u8			cmd_buf[SPI_NOR_MAX_CMD_SIZE];
@@ -183,6 +346,11 @@ struct spi_nor {
 	int (*flash_unlock)(struct spi_nor *nor, loff_t ofs, uint64_t len);
 	int (*flash_is_locked)(struct spi_nor *nor, loff_t ofs, uint64_t len);
 
+#ifdef CONFIG_HISI_SPI_BLOCK_PROTECT
+	unsigned int end_addr;
+	unsigned int lock_level_max;
+	unsigned char level;
+#endif
 	void *priv;
 };
 
@@ -201,7 +369,7 @@ static inline struct device_node *spi_nor_get_flash_node(struct spi_nor *nor)
  * spi_nor_scan() - scan the SPI NOR
  * @nor:	the spi_nor structure
  * @name:	the chip type name
- * @mode:	the read mode supported by the driver
+ * @modes:	the SPI modes supported by the controller driver
  *
  * The drivers can use this fuction to scan the SPI NOR.
  * In the scanning, it will try to get all the necessary information to
@@ -211,6 +379,12 @@ static inline struct device_node *spi_nor_get_flash_node(struct spi_nor *nor)
  *
  * Return: 0 for success, others for failure.
  */
-int spi_nor_scan(struct spi_nor *nor, const char *name, enum read_mode mode);
+int spi_nor_scan(struct spi_nor *nor, const char *name,
+		 struct spi_nor_modes *modes);
+void spi_nor_driver_shutdown(struct spi_nor *nor);
+#ifdef CONFIG_PM
+int spi_nor_suspend(struct spi_nor *nor, pm_message_t state);
+int spi_nor_resume(struct spi_nor *nor);
+#endif
 
 #endif
diff --git a/include/linux/phy.h b/include/linux/phy.h
index 6c9b1e0..b08bcf7 100644
--- a/include/linux/phy.h
+++ b/include/linux/phy.h
@@ -829,6 +829,10 @@ int phy_register_fixup_for_id(const char *bus_id,
 int phy_register_fixup_for_uid(u32 phy_uid, u32 phy_uid_mask,
 			       int (*run)(struct phy_device *));
 
+int phy_unregister_fixup(const char *bus_id, u32 phy_uid, u32 phy_uid_mask);
+int phy_unregister_fixup_for_id(const char *bus_id);
+int phy_unregister_fixup_for_uid(u32 phy_uid, u32 phy_uid_mask);
+
 int phy_init_eee(struct phy_device *phydev, bool clk_stop_enable);
 int phy_get_eee_err(struct phy_device *phydev);
 int phy_ethtool_set_eee(struct phy_device *phydev, struct ethtool_eee *data);
diff --git a/include/linux/spi/spi.h b/include/linux/spi/spi.h
index 4b743ac..54eeb07 100644
--- a/include/linux/spi/spi.h
+++ b/include/linux/spi/spi.h
@@ -233,6 +233,8 @@ struct spi_transfer;
  * @remove: Unbinds this driver from the spi device
  * @shutdown: Standard shutdown callback used during system state
  *	transitions such as powerdown/halt and kexec
+ * @suspend: Standard suspend callback used during system state transitions
+ * @resume: Standard resume callback used during system state transitions
  * @driver: SPI device drivers should initialize the name and owner
  *	field of this structure.
  *
@@ -253,6 +255,8 @@ struct spi_driver {
 	int			(*probe)(struct spi_device *spi);
 	int			(*remove)(struct spi_device *spi);
 	void			(*shutdown)(struct spi_device *spi);
+	int			(*suspend)(struct spi_device *spi, pm_message_t mesg);
+	int			(*resume)(struct spi_device *spi);
 	struct device_driver	driver;
 };
 
diff --git a/include/uapi/linux/i2c-dev.h b/include/uapi/linux/i2c-dev.h
index 2f05e66..e68dbb9 100644
--- a/include/uapi/linux/i2c-dev.h
+++ b/include/uapi/linux/i2c-dev.h
@@ -50,6 +50,9 @@
 
 #define I2C_PEC		0x0708	/* != 0 to use PEC with SMBus */
 #define I2C_SMBUS	0x0720	/* SMBus transfer */
+#define I2C_16BIT_REG	0x0709	/* 16BIT REG WIDTH */
+#define I2C_16BIT_DATA	0x070a	/* 16BIT DATA WIDTH */
+#define I2C_DMA		0x070b	/* DMA mode */
 
 
 /* This is the structure as used in the I2C_SMBUS ioctl call */
diff --git a/include/uapi/linux/i2c.h b/include/uapi/linux/i2c.h
index 009e27b..4195a49 100644
--- a/include/uapi/linux/i2c.h
+++ b/include/uapi/linux/i2c.h
@@ -71,12 +71,19 @@ struct i2c_msg {
 #define I2C_M_RD		0x0001	/* read data, from slave to master */
 					/* I2C_M_RD is guaranteed to be 0x0001! */
 #define I2C_M_TEN		0x0010	/* this is a ten bit chip address */
+#define I2C_M_NOSTART		0x4000	/* if I2C_FUNC_PROTOCOL_MANGLING */
+#define I2C_M_REV_DIR_ADDR	0x2000	/* if I2C_FUNC_PROTOCOL_MANGLING */
+#define I2C_M_IGNORE_NAK	0x1000	/* if I2C_FUNC_PROTOCOL_MANGLING */
 #define I2C_M_RECV_LEN		0x0400	/* length will be first received byte */
 #define I2C_M_NO_RD_ACK		0x0800	/* if I2C_FUNC_PROTOCOL_MANGLING */
 #define I2C_M_IGNORE_NAK	0x1000	/* if I2C_FUNC_PROTOCOL_MANGLING */
 #define I2C_M_REV_DIR_ADDR	0x2000	/* if I2C_FUNC_PROTOCOL_MANGLING */
 #define I2C_M_NOSTART		0x4000	/* if I2C_FUNC_NOSTART */
 #define I2C_M_STOP		0x8000	/* if I2C_FUNC_PROTOCOL_MANGLING */
+#define I2C_M_RECV_LEN		0x0400	/* length will be first received byte */
+#define I2C_M_16BIT_REG		0x0002	/* indicate reg bit-width is 16bit */
+#define I2C_M_16BIT_DATA	0x0008	/* indicate data bit-width is 16bit */
+#define I2C_M_DMA		0x0004	/* indicate use dma mode */
 	__u16 len;		/* msg length				*/
 	__u8 *buf;		/* pointer to msg data			*/
 };
diff --git a/net/core/sock.c b/net/core/sock.c
index 1989b3d..221edb6 100644
--- a/net/core/sock.c
+++ b/net/core/sock.c
@@ -1957,7 +1957,11 @@ int sock_cmsg_send(struct sock *sk, struct msghdr *msg,
 EXPORT_SYMBOL(sock_cmsg_send);
 
 /* On 32bit arches, an skb frag is limited to 2^15 */
+#if defined(CONFIG_ARCH_HI3516A)
+#define SKB_FRAG_PAGE_ORDER	0
+#else
 #define SKB_FRAG_PAGE_ORDER	get_order(32768)
+#endif
 
 /**
  * skb_page_frag_refill - check that a page_frag contains enough room
diff --git a/net/ipv6/output_core.c b/net/ipv6/output_core.c
index e9065b8..abb2c30 100644
--- a/net/ipv6/output_core.c
+++ b/net/ipv6/output_core.c
@@ -78,7 +78,7 @@ EXPORT_SYMBOL(ipv6_select_ident);
 
 int ip6_find_1stfragopt(struct sk_buff *skb, u8 **nexthdr)
 {
-	u16 offset = sizeof(struct ipv6hdr);
+	unsigned int offset = sizeof(struct ipv6hdr);
 	unsigned int packet_len = skb_tail_pointer(skb) -
 		skb_network_header(skb);
 	int found_rhdr = 0;
@@ -86,6 +86,7 @@ int ip6_find_1stfragopt(struct sk_buff *skb, u8 **nexthdr)
 
 	while (offset <= packet_len) {
 		struct ipv6_opt_hdr *exthdr;
+		unsigned int len;
 
 		switch (**nexthdr) {
 
@@ -111,7 +112,10 @@ int ip6_find_1stfragopt(struct sk_buff *skb, u8 **nexthdr)
 
 		exthdr = (struct ipv6_opt_hdr *)(skb_network_header(skb) +
 						 offset);
-		offset += ipv6_optlen(exthdr);
+		len = ipv6_optlen(exthdr);
+		if (len + offset >= IPV6_MAXPLEN)
+			return -EINVAL;
+		offset += len;
 		*nexthdr = &exthdr->nexthdr;
 	}
 
diff --git a/scripts/setlocalversion b/scripts/setlocalversion
index 966dd39..91f9d49 100755
--- a/scripts/setlocalversion
+++ b/scripts/setlocalversion
@@ -1,4 +1,4 @@
-#!/bin/sh
+#/bin/sh
 #
 # This scripts adds local version information from the version
 # control systems git, mercurial (hg) and subversion (svn).
@@ -153,6 +153,7 @@ if test ! "$srctree" -ef .; then
 	res="$res$(collect_files "$srctree"/localversion*)"
 fi
 
+LOCALVERSION=
 # CONFIG_LOCALVERSION and LOCALVERSION (if set)
 res="${res}${CONFIG_LOCALVERSION}${LOCALVERSION}"
 
