diff -drupN a/arch/arm/common/mcpm_entry.c b/arch/arm/common/mcpm_entry.c
--- a/arch/arm/common/mcpm_entry.c	2018-08-06 17:23:04.000000000 +0300
+++ b/arch/arm/common/mcpm_entry.c	2022-06-12 05:28:14.000000000 +0300
@@ -185,7 +185,7 @@ static arch_spinlock_t mcpm_lock = __ARC
 
 static int mcpm_cpu_use_count[MAX_NR_CLUSTERS][MAX_CPUS_PER_CLUSTER];
 
-static inline bool mcpm_cluster_unused(unsigned int cluster)
+bool mcpm_cluster_unused(unsigned int cluster)
 {
 	int i, cnt;
 	for (i = 0, cnt = 0; i < MAX_CPUS_PER_CLUSTER; i++)
@@ -227,6 +227,8 @@ int mcpm_cpu_power_up(unsigned int cpu,
 
 	if (cluster_is_down)
 		ret = platform_ops->cluster_powerup(cluster);
+	if (ret)
+		mcpm_cpu_use_count[cluster][cpu]--;
 	if (cpu_is_down && !ret)
 		ret = platform_ops->cpu_powerup(cpu, cluster);
 
@@ -236,6 +238,7 @@ int mcpm_cpu_power_up(unsigned int cpu,
 }
 
 typedef void (*phys_reset_t)(unsigned long);
+extern void disable_cci_snoops(unsigned int cluster_id);
 
 void mcpm_cpu_power_down(void)
 {
@@ -269,6 +272,7 @@ void mcpm_cpu_power_down(void)
 		arch_spin_unlock(&mcpm_lock);
 		platform_ops->cluster_cache_disable();
 		__mcpm_outbound_leave_critical(cluster, CLUSTER_DOWN);
+		disable_cci_snoops(cluster);
 	} else {
 		if (cpu_going_down)
 			platform_ops->cpu_powerdown_prepare(cpu, cluster);
