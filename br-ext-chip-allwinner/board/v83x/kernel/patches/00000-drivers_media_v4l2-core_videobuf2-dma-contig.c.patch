diff -drupN a/drivers/media/v4l2-core/videobuf2-dma-contig.c b/drivers/media/v4l2-core/videobuf2-dma-contig.c
--- a/drivers/media/v4l2-core/videobuf2-dma-contig.c	2018-08-06 17:23:04.000000000 +0300
+++ b/drivers/media/v4l2-core/videobuf2-dma-contig.c	2022-06-12 05:28:14.000000000 +0300
@@ -21,6 +21,16 @@
 #include <media/videobuf2-dma-contig.h>
 #include <media/videobuf2-memops.h>
 
+#define SUNXI_MEM
+
+#ifdef SUNXI_MEM
+#include <linux/ion.h>
+#include <linux/ion_sunxi.h>
+#include <linux/dma-mapping.h>
+
+char *ion_name = "ion_video_buf";
+struct ion_client *sunxi_ion_client_create(const char *name);
+
 struct vb2_dc_buf {
 	struct device			*dev;
 	void				*vaddr;
@@ -39,8 +49,122 @@ struct vb2_dc_buf {
 
 	/* DMABUF related */
 	struct dma_buf_attachment	*db_attach;
+	struct ion_client *client;
+	struct ion_handle *handle;
+	struct dma_buf *dmabuf;
 };
 
+static int ion_alloc_coherent(struct vb2_dc_buf *mem)
+{
+	unsigned int flags = ION_FLAG_CACHED | ION_FLAG_CACHED_NEEDS_SYNC;
+	int ret;
+
+	mem->client = sunxi_ion_client_create(ion_name);
+	if (IS_ERR_OR_NULL(mem->client)) {
+		dev_err(mem->dev, "sunxi_ion_client_create failed!!");
+		return -ENOMEM;
+	}
+#if defined CONFIG_SUNXI_IOMMU && defined CONFIG_VIN_IOMMU
+	/* IOMMU */
+	mem->handle = ion_alloc(mem->client, mem->size, PAGE_SIZE,
+				ION_HEAP_SYSTEM_MASK, flags);
+
+#else
+	/* CMA or CARVEOUT */
+	mem->handle = ion_alloc(mem->client, mem->size, PAGE_SIZE,
+				ION_HEAP_TYPE_DMA_MASK |
+				ION_HEAP_CARVEOUT_MASK, flags);
+#endif
+	if (IS_ERR_OR_NULL(mem->handle)) {
+		dev_err(mem->dev, "ion_alloc failed!!");
+		goto err_alloc;
+	}
+
+	mem->vaddr = ion_map_kernel(mem->client, mem->handle);
+	if (IS_ERR_OR_NULL(mem->vaddr))	{
+		dev_err(mem->dev, "ion_map_kernel failed!!\n");
+		goto err_map_kernel;
+	}
+
+#if defined CONFIG_SUNXI_IOMMU && defined CONFIG_VIN_IOMMU
+	/* IOMMU */
+	ret = dma_map_sg_attrs(mem->dev, mem->handle->buffer->sg_table->sgl,
+				mem->handle->buffer->sg_table->nents, DMA_BIDIRECTIONAL,
+				DMA_ATTR_SKIP_CPU_SYNC);
+	if (ret != 1) {
+		dev_err(mem->dev, "dma map sg fail!!\n");
+		goto err_phys;
+	}
+	mem->dma_addr = sg_dma_address(mem->handle->buffer->sg_table->sgl);
+#else
+	/* CMA or CARVEOUT */
+	ret = ion_phys(mem->client, mem->handle, (ion_phys_addr_t *)&mem->dma_addr,
+			 (size_t *)&mem->size);
+	if (ret) {
+		dev_err(mem->dev, "ion_phys failed!!\n");
+		goto err_phys;
+	}
+#endif
+
+	mem->dmabuf = ion_share_dma_buf(mem->client, mem->handle);
+	if (IS_ERR(mem->dmabuf)) {
+		dev_err(mem->dev, "ion_share_dma_buf failed!!\n");
+		goto err_phys;
+	}
+
+	return 0;
+err_phys:
+	ion_unmap_kernel(mem->client, mem->handle);
+err_map_kernel:
+	ion_free(mem->client, mem->handle);
+err_alloc:
+	ion_client_destroy(mem->client);
+	return -ENOMEM;
+}
+static void ion_free_coherent(struct vb2_dc_buf *mem)
+{
+	if (IS_ERR_OR_NULL(mem->client) || IS_ERR_OR_NULL(mem->handle)
+	   || IS_ERR_OR_NULL(mem->vaddr))
+		return;
+
+#if defined CONFIG_SUNXI_IOMMU && defined CONFIG_VIN_IOMMU
+	dma_unmap_sg_attrs(mem->dev, mem->handle->buffer->sg_table->sgl, mem->handle->buffer->sg_table->nents,
+				mem->dma_dir, DMA_ATTR_SKIP_CPU_SYNC);
+#endif
+	dma_buf_put(mem->dmabuf);
+	ion_unmap_kernel(mem->client, mem->handle);
+	ion_free(mem->client, mem->handle);
+	ion_client_destroy(mem->client);
+}
+
+static int ion_mmap_coherent(struct vb2_dc_buf *mem,
+				struct vm_area_struct *vma)
+{
+	return dma_buf_mmap(mem->dmabuf, vma, 0);
+}
+
+#else
+struct vb2_dc_buf {
+	struct device			*dev;
+	void				*vaddr;
+	unsigned long			size;
+	void				*cookie;
+	dma_addr_t			dma_addr;
+	unsigned long			attrs;
+	enum dma_data_direction		dma_dir;
+	struct sg_table			*dma_sgt;
+	struct frame_vector		*vec;
+
+	/* MMAP related */
+	struct vb2_vmarea_handler	handler;
+	atomic_t			refcount;
+	struct sg_table			*sgt_base;
+
+	/* DMABUF related */
+	struct dma_buf_attachment	*db_attach;
+};
+#endif
+
 /*********************************************/
 /*        scatterlist table functions        */
 /*********************************************/
@@ -68,7 +192,6 @@ static unsigned long vb2_dc_get_contiguo
 static void *vb2_dc_cookie(void *buf_priv)
 {
 	struct vb2_dc_buf *buf = buf_priv;
-
 	return &buf->dma_addr;
 }
 
@@ -78,7 +201,6 @@ static void *vb2_dc_vaddr(void *buf_priv
 
 	if (!buf->vaddr && buf->db_attach)
 		buf->vaddr = dma_buf_vmap(buf->db_attach->dmabuf);
-
 	return buf->vaddr;
 }
 
@@ -99,7 +221,7 @@ static void vb2_dc_prepare(void *buf_pri
 		return;
 
 	dma_sync_sg_for_device(buf->dev, sgt->sgl, sgt->orig_nents,
-			       buf->dma_dir);
+		buf->dma_dir);
 }
 
 static void vb2_dc_finish(void *buf_priv)
@@ -129,8 +251,12 @@ static void vb2_dc_put(void *buf_priv)
 		sg_free_table(buf->sgt_base);
 		kfree(buf->sgt_base);
 	}
+#ifdef SUNXI_MEM
+	ion_free_coherent(buf);
+#else
 	dma_free_attrs(buf->dev, buf->size, buf->cookie, buf->dma_addr,
-		       buf->attrs);
+		buf->attrs);
+#endif
 	put_device(buf->dev);
 	kfree(buf);
 }
@@ -139,6 +265,7 @@ static void *vb2_dc_alloc(struct device
 			  unsigned long size, enum dma_data_direction dma_dir,
 			  gfp_t gfp_flags)
 {
+
 	struct vb2_dc_buf *buf;
 
 	if (WARN_ON(!dev))
@@ -150,8 +277,15 @@ static void *vb2_dc_alloc(struct device
 
 	if (attrs)
 		buf->attrs = attrs;
+#ifdef SUNXI_MEM
+	buf->size = size;
+	buf->dev = get_device(dev);
+	ion_alloc_coherent(buf);
+	buf->cookie = buf->vaddr;
+#else
 	buf->cookie = dma_alloc_attrs(dev, size, &buf->dma_addr,
 					GFP_KERNEL | gfp_flags, buf->attrs);
+#endif
 	if (!buf->cookie) {
 		dev_err(dev, "dma_alloc_coherent of size %ld failed\n", size);
 		kfree(buf);
@@ -191,9 +325,12 @@ static int vb2_dc_mmap(void *buf_priv, s
 	 */
 	vma->vm_pgoff = 0;
 
+#ifdef SUNXI_MEM
+	ret = ion_mmap_coherent(buf, vma);
+#else
 	ret = dma_mmap_attrs(buf->dev, vma, buf->cookie,
 		buf->dma_addr, buf->size, buf->attrs);
-
+#endif
 	if (ret) {
 		pr_err("Remapping memory failed, error: %d\n", ret);
 		return ret;
@@ -289,7 +426,7 @@ static struct sg_table *vb2_dc_dmabuf_op
 
 	mutex_lock(lock);
 
-	sgt = &attach->sgt;
+	sgt = &(attach->sgt);
 	/* return previously mapped sg table */
 	if (attach->dma_dir == dma_dir) {
 		mutex_unlock(lock);
